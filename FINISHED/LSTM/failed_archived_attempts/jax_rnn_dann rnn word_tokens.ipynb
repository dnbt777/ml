{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import random as rand\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "sequence_length = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiment:\n",
    "get my posts\n",
    "input: nothing\n",
    "output: a post\n",
    "\n",
    "experiment:\n",
    "video generator\n",
    "input: blank transparent canvas\n",
    "output: the next frame of the video\n",
    "do a several convolution skip connections on each step (adds changes to each frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replies:\n",
      "@VictorTaelin ive found sonnet 3.5v2 to be surprisingly good at coding. upgraded my tools from v1 to v2 and all of a sudden i have to reprompt it like 1/3rd the time\n",
      "@dgant &lt;script src=\"gifeditor.mp3\" type=\"application/json\"&gt;\n",
      "@bozo10n ðŸ’ª\n",
      "@sunsettler experimentation games are the best\n",
      "\n",
      "Posts:\n",
      "compression always feels so satisfying https://t.co/mM5acJxydL\n",
      "it only takes one line of code to make a gifboard btw https://t.co/hFlPyNTvRm\n",
      "RT @calbch: @kuberdenis entrepreneurship is the ultimative vehicle for personal development\n",
      "just two idiots playing a game of chess https://t.co/USjWySv3W9\n"
     ]
    }
   ],
   "source": [
    "# process tweet data\n",
    "import json\n",
    "\n",
    "# Load the tweets.js file\n",
    "with open('./tweets.js', 'r', encoding='utf-8') as file:\n",
    "    # Skip the JavaScript assignment and load only the JSON part\n",
    "    content = file.read()\n",
    "    json_data = content.split('=', 1)[1].strip()  # Extract the JSON part after `=`\n",
    "    json_data = json_data.rstrip(';')  # Remove trailing semicolon if present\n",
    "    tweets_data = json.loads(json_data)\n",
    "\n",
    "# Initialize lists for replies and posts\n",
    "replies = []\n",
    "posts = []\n",
    "\n",
    "# Process each tweet in the dataset\n",
    "for tweet_obj in tweets_data:\n",
    "    tweet = tweet_obj[\"tweet\"]\n",
    "    \n",
    "    if \"in_reply_to_status_id_str\" in tweet and tweet[\"in_reply_to_status_id_str\"]:\n",
    "        # It's a reply\n",
    "        replies.append({\n",
    "            \"id\": tweet[\"id_str\"],\n",
    "            \"text\": tweet[\"full_text\"],\n",
    "            \"in_reply_to\": tweet[\"in_reply_to_status_id_str\"],\n",
    "            \"user\": tweet.get(\"in_reply_to_screen_name\", None),\n",
    "            \"created_at\": tweet[\"created_at\"]\n",
    "        })\n",
    "    else:\n",
    "        # It's a standalone post\n",
    "        posts.append({\n",
    "            \"id\": tweet[\"id_str\"],\n",
    "            \"text\": tweet[\"full_text\"],\n",
    "            \"created_at\": tweet[\"created_at\"]\n",
    "        })\n",
    "\n",
    "# Output the results\n",
    "print(\"Replies:\")\n",
    "for reply in replies[:4]:\n",
    "    print(reply[\"text\"])\n",
    "\n",
    "print(\"\\nPosts:\")\n",
    "for post in posts[:4]:\n",
    "    print(post[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10111 tokens\n",
      "loaded 3914 posts.\n"
     ]
    }
   ],
   "source": [
    "# set up and process data\n",
    "post_limit = -1\n",
    "\n",
    "stop_char = \"ðŸ›‘\"\n",
    "all_posts = [\n",
    "  \"reply: \" + reply[\"text\"] + stop_char for reply in replies[:post_limit]\n",
    "]\n",
    "all_posts.extend(\n",
    "  [\n",
    "    \"post: \" + post[\"text\"] + stop_char for post in posts[:post_limit]\n",
    "  ]\n",
    ")\n",
    "rand.shuffle(all_posts)\n",
    "\n",
    "\n",
    "def get_words(post):\n",
    "  # break up into alhpanum words, space, and special chars like !?# etc.\n",
    "  # \"what the Dog DOO1in? (idk)\" => ['what', ' ', the, ' ', Dog, ' ', 'Doo1in', '?', ' ', '(', 'idk', ')']\n",
    "  tokens = []\n",
    "  token = ''\n",
    "  append_token = False\n",
    "  for i, c in enumerate(post):\n",
    "    if i == len(post) - 1:\n",
    "      append_token = True\n",
    "    if c.isalnum():\n",
    "      token += c\n",
    "    else:\n",
    "      if token != '': tokens.append(token)\n",
    "      token = ''\n",
    "      token += c\n",
    "      append_token = True\n",
    "    if append_token:\n",
    "      append_token = False\n",
    "      tokens.append(token)\n",
    "      token = ''\n",
    "  return tokens\n",
    "\n",
    "from functools import reduce\n",
    "vocab = sorted(list(set(\n",
    "  reduce(\n",
    "    lambda A, B: A.union(B),\n",
    "    map(lambda post: set(get_words(post)), all_posts)\n",
    "))))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"{vocab_size} tokens\")\n",
    "\n",
    "translations = {\n",
    "  \"encode\" : dict([(w, t) for w, t in zip(vocab, range(len(vocab)))]),\n",
    "  \"decode\" : dict([(t, w) for w, t in zip(vocab, range(len(vocab)))])\n",
    "}\n",
    "\n",
    "token = lambda w: translations[\"encode\"][w] # char to token\n",
    "word = lambda t: translations[\"decode\"][int(t)] # token to char\n",
    "encode = lambda ws: jnp.array([token(w) for w in get_words(ws)])\n",
    "decode = lambda ts: \"\".join([word(t) for t in ts])\n",
    "\n",
    "\n",
    "post_token_sets = [encode(post) for post in all_posts]\n",
    "\n",
    "print(f\"loaded {len(post_token_sets)} posts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7931   496     1   500   852     1   719     1  5836     1  2462     1\n",
      "  5236     1  2964     0     0  1273     1  6882     1  7940     1  9126\n",
      "     1  3233     0     0  1273     1  9141     1  9982     1  3321     1\n",
      "  8307     1  1165     1  3069     1  5591     1  9982     1  7481     1\n",
      "  6941     1  6178     1  7109     1  7478     1  9364     1  9985     1\n",
      "  2811     1  3041     1  9985     1  2946     1  6300 10103]\n"
     ]
    }
   ],
   "source": [
    "print(post_token_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train functions\n",
    "# init rnn params\n",
    "# inputs ()\n",
    "def init_rnn_params(key, input_shape, hidden_shape, output_shape):\n",
    "  keys = random.split(key, 3*sequence_length)\n",
    "  rnn_params = {\n",
    "    # xW means shape of W is (input, output)\n",
    "    # hW and xW should output the shape of h.\n",
    "    str(n) : {\n",
    "      \"Whh\" : random.normal(keys[3*n + 0], shape=(hidden_shape[0], hidden_shape[0])) * jnp.sqrt(2 / hidden_shape[0]),\n",
    "      \"Whx\" : random.normal(keys[3*n + 1], shape=(input_shape[0], hidden_shape[0])) * jnp.sqrt(2 / input_shape[0]),\n",
    "      \"Why\" : random.normal(keys[3*n + 2], shape=(hidden_shape[0], output_shape[0])) * jnp.sqrt(2 / hidden_shape[0])\n",
    "    }\n",
    "    for n in range(sequence_length + 1) # +1 for the empty sequence at the start\n",
    "  }\n",
    "  return rnn_params\n",
    "\n",
    "@jax.jit\n",
    "def step_start(rnn_params, x):\n",
    "  hidden_shape = rnn_params[str(0)][\"Whh\"].shape[0]\n",
    "  h = jnp.zeros(hidden_shape)\n",
    "  y, h = step(rnn_params, h, x, n=str(0))\n",
    "  return y, h\n",
    "\n",
    "def step(rnn_params, h, x, n):\n",
    "  z = h @ rnn_params[n][\"Whh\"] + x @ rnn_params[n][\"Whx\"]\n",
    "  h = jax.nn.tanh(z)\n",
    "  y = h @ rnn_params[n][\"Why\"]\n",
    "  return y, h\n",
    "\n",
    "@jax.jit\n",
    "def forward(rnn_params, xbow):\n",
    "  # for now, recreate karpathy's example\n",
    "  # lma -> mao\n",
    "  ys = []\n",
    "  yi, h = step_start(rnn_params, xbow[0]) # try to predict the first token\n",
    "  h = jax.nn.tanh(h)\n",
    "  ys.append(yi)\n",
    "  for n in range(1, len(xbow)):\n",
    "    y, h = step(rnn_params, h, xbow[n], n=str(n)) # try to predict i+1th token\n",
    "    ys.append(y)\n",
    "\n",
    "  return jnp.array(ys)\n",
    "\n",
    "\n",
    "def init_embedding_params(key, model_dim):\n",
    "  keys = random.split(key, 10)\n",
    "  embedding_params = {\n",
    "    \"layer_1\" : {\n",
    "      \"w\" : random.normal(keys[0], shape=(1, model_dim)),\n",
    "      \"b\" : jnp.zeros((model_dim,)),\n",
    "      }\n",
    "  }\n",
    "  return embedding_params\n",
    "\n",
    "# learned embeddings\n",
    "\"\"\"\n",
    "@jax.jit\n",
    "def embed_tokens(embedding_params, tokens):\n",
    "  # ts[:, None] turns it from [t, t, t, t] to [[t], [t], [t], [t]]. as it should be, a row vector. transpose but for 1d vec.\n",
    "  x = tokens[:, None] @ embedding_params[\"layer_1\"][\"w\"] + embedding_params[\"layer_1\"][\"b\"]\n",
    "  return x\n",
    "\"\"\"\n",
    "\n",
    "# one hot embeddings\n",
    "@jax.jit\n",
    "def embed_tokens(tokens):\n",
    "  return jax.nn.one_hot(tokens, vocab_size)\n",
    "\n",
    "def embed_chars(chars):\n",
    "  tokens = encode(chars)\n",
    "  return embed_tokens(tokens)\n",
    "\n",
    "@jax.jit\n",
    "def get_loss(rnn_params, xtokens, ytokens):\n",
    "  xbow = embed_tokens(xtokens)\n",
    "  logits = forward(rnn_params, xbow)\n",
    "  ytokens_one_hot = jax.nn.one_hot(ytokens, len(logits[0]))\n",
    "  cross_entropies = -jnp.sum(jax.nn.log_softmax(logits, axis=-1) * ytokens_one_hot, axis=-1)\n",
    "  net_cross_entropy_loss = jnp.sum(cross_entropies)\n",
    "  return net_cross_entropy_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 100000 posts\n",
      "batch    0  loss=376.5325  steps/s=2.91  prediction: \"UR BROBLEM GREEN https://t.co/mstazBvsCM\" => \"STIISYOORRBBBRMEEEhEENNNt:tt/:///st/B.cz\"\n",
      "batch    1  loss=302.9848  steps/s=98.30  prediction: \" is a wild computational rabbithole man.\" => \"tnha si i   wepmmdputaabtlanrabblbt himm\"\n",
      "batch    2  loss=330.2311  steps/s=98.33  prediction: \"e algo show you a lot more similar posts\" => \" stkesdtgg \n",
      "haoyyuuu yluom aeressmuar  p\"\n",
      "batch    4  loss=327.4581  steps/s=104.01  prediction: \"ouraging way, not stressful for the kid)\" => \" gngggagng a. ,n   ttttsssstrfrf  r te )\"\n",
      "batch    5  loss=315.5818  steps/s=103.42  prediction: \"ding blocks that make it up, recursively\" => \" thb bblinb c tsbtktkmmtta u,,pe ru vvve\"\n",
      "batch    6  loss=348.8446  steps/s=98.56  prediction: \"per solid learning loop, love it love it\" => \"lyudlð—¼SdSuupSðŸ§ ssuSleararnrâ€œgggp,orpvðŸ°vvðŸ›‘\"\n",
      "batch    7  loss=351.6792  steps/s=104.76  prediction: \"em all the cool ML stuff out there thatâ€¦\" => \"  he l ll a e oooMMLLo fffuuuuu t hteetâ€¦\"\n",
      "batch    8  loss=359.5000  steps/s=101.79  prediction: \"sts w good content from this perspective\" => \"    toiossod  oo tcnc fttftå§mð˜€rrirrð—ªpRð—ªt\"\n",
      "batch    9  loss=293.4900  steps/s=105.23  prediction: \"to someone on X, its laggy when it plays\" => \" ndtsoooooomeoXX        gsgyggyyh ii l y\"\n",
      "batch   10  loss=360.9878  steps/s=103.81  prediction: \"ective, its significantly more efficient\" => \" cpeevviiti,sis,iiici ï¸cntn a  effffefec\"\n",
      "batch   11  loss=355.1512  steps/s=105.73  prediction: \"ard to realize. lies are really blinding\" => \"lih  o e  tizz zeles es ,Ê€earer ð—¯llili r\"\n",
      "batch   12  loss=420.4705  steps/s=102.51  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \" emihttvið˜‚ngr ðŸ¤¦ttig\n",
      "sn\n",
      "\n",
      "\n",
      "::/ts.p.VVCWWHH\"\n",
      "batch   13  loss=425.1634  steps/s=104.15  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"etts:(:/q:6B6fqqBND:XDXXq.pt.coAR3sXVQA3\"\n",
      "batch   15  loss=386.8564  steps/s=105.60  prediction: \" she got into medschool after graduating\" => \"tSSS..sð—¿Hâ™‚tH ng3 tottddccosldflf  rlrrgd\"\n",
      "batch   16  loss=395.7365  steps/s=101.18  prediction: \"just happen to have sicilian parents lol\" => \"one wSvhuspppiitthhtvicpsiciiaan paeraot\"\n",
      "batch   17  loss=377.0148  steps/s=105.57  prediction: \"mes there are 10x rewards for doing this\" => \"eteme\n",
      "m ttres raF10xxxte rew0å§w1ðŸ˜­do ddð—²g\"\n",
      "batch   18  loss=385.8186  steps/s=101.59  prediction: \"t leak info from the stream accidentally\" => \"oi ardkrtkå§orfoâ€krohskðŸ˜¤e sá´€m af estidesm\"\n",
      "batch   19  loss=366.7488  steps/s=104.23  prediction: \"elated to status games or zero sum games\" => \" a reedttdtso ts ugmmemmoâ˜ zztrzrtusgammu\"\n",
      "batch   20  loss=420.2952  steps/s=94.30  prediction: \"igABAP np bro, you should write more man\" => \"t Al.PwiPggBABAAPðŸ˜¢yorbymdu[?zouiterm;raÊ€\"\n",
      "batch   21  loss=435.7062  steps/s=103.07  prediction: \"ews on the internet\n",
      "id say it worked lol\" => \"pteosAnNn9eBeonnr4r \n",
      "\n",
      "\n",
      "hdð˜tt}É´4swwrrk]Zo\"\n",
      "batch   22  loss=438.9292  steps/s=94.40  prediction: \"P get him toys, play w him, lasts longer\" => \"rf BPu@diw em,hiP9ðŸ˜Ž,yll yiwy á´„,,ta,thnre\"\n",
      "batch   23  loss=454.8260  steps/s=101.35  prediction: \" that outputs its own weights and biases\" => \"irai tqoGh dGMus m s wtwwitshatssn anbbb\"\n",
      "batch   24  loss=358.5779  steps/s=105.32  prediction: \"going into space man its truly beautiful\" => \" ln  aoå§nd ito sppgee?asn mtm nuuis eauu\"\n",
      "batch   25  loss=335.8405  steps/s=105.22  prediction: \"reevaluating concepts you often overlook\" => \"elaal va pngrug cogtgpno yoU efâ€œ afop sl\"\n",
      "batch   26  loss=387.2361  steps/s=105.42  prediction: \"ng i correctly understood what you meant\" => \"ts\n",
      "i )i)icorr É´'\n",
      "y)PtoðŸŽ‰rrsodâ€œwrwoa eyotr\"\n",
      "batch   27  loss=366.9601  steps/s=104.75  prediction: \"aise), and we'd end up in the same place\" => \"cn/pesis, dhdn'e'd en) ep)d 'n nht/memsh\"\n",
      "batch   28  loss=319.3250  steps/s=103.56  prediction: \"while his chess opponents mind went 3fps\" => \"   mhf hi   sssssepppoponennnn   m w wtt\"\n",
      "batch   29  loss=255.8877  steps/s=103.60  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \"g eana aaa       ffppppt////ttJJMM44622U\"\n",
      "batch   30  loss=296.5856  steps/s=102.32  prediction: \"change it up a bit from the ol .txt file\" => \"eoaaeeeh        ui ttbbftttooo o...xxlll\"\n",
      "batch   31  loss=282.6267  steps/s=104.19  prediction: \"having kids, etc) may be only palliative\" => \"engc sovvikiisgss      y e yyyyallllaaai\"\n",
      "batch   32  loss=416.7010  steps/s=106.05  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"la#kar# #gng iigggitttty////.pd:p8ZZc3XX\"\n",
      "batch   33  loss=318.3843  steps/s=99.12  prediction: \"e irl. i dare u. https://t.co/NEk2CLBwti\" => \"attoeoi  idd.rr. e   tt/:t.p///NN.2LLCBB\"\n",
      "batch   34  loss=433.4603  steps/s=96.89  prediction: \" I know!!! I laughed so hard when it hit\" => \"@oWooa kIo!I!!w!hh hhh  h dd d o hh  tit\"\n",
      "batch   35  loss=304.4914  steps/s=103.45  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf?k.....eeep   ii na ||     rt krrkidii\"\n",
      "batch   37  loss=258.0387  steps/s=104.82  prediction: \"ne was right the rates arent high enough\" => \"tlaaa    s  hhhtttteeeeaaaaeeeeegg h  nn\"\n",
      "batch   38  loss=262.9374  steps/s=101.94  prediction: \"above average in to get above avg skills\" => \"neexllavvvaar r     ggttttoooee aa  gvvk\"\n",
      "batch   39  loss=422.6281  steps/s=101.79  prediction: \"/t.co/lBwBETlxDd cats are insane animals\" => \"t@t//s:/BBBBlEllcDcccxtaaa   aannnnniaaa\"\n",
      "batch   40  loss=385.4317  steps/s=99.86  prediction: \"ant believe I havent been napping before\" => \"nu cenbeeieeenIieIannvvbeennnenpppanLbge\"\n",
      "batch   41  loss=262.9867  steps/s=101.71  prediction: \"the beta (should be around the 25th)\n",
      ": D\" => \"he o eebttth(ooslulb  a uddd    255h2hh)\"\n",
      "batch   42  loss=284.8646  steps/s=105.48  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \"tuenedddd-ooerrrrc\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "t//tt/t:pjOOjcjdR\"\n",
      "batch   43  loss=357.8089  steps/s=96.57  prediction: \"nDEKR he confused plurality for majority\" => \"tonjERKKKc nnn   eeuuulllll         rrjr\"\n",
      "batch   44  loss=274.9297  steps/s=101.18  prediction: \" cs maps btw? would love to see pictures\" => \"toul  c s ss??wwww  llll oooooeeeeettuuu\"\n",
      "batch   45  loss=269.4092  steps/s=106.00  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"e gi iiiigsslllllttttt\n",
      "tppp/o/:OA6VVVOGG\"\n",
      "batch   46  loss=358.8592  steps/s=104.59  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"g. tt.:tXXXXcMMchTTTt3Pp/tttto/QQ/tlll9l\"\n",
      "batch   47  loss=496.7646  steps/s=103.60  prediction: \"ou get like 5 seconds to shoot your shot\" => \"udayl u lle 555kee nosssot  h o5o u   uo\"\n",
      "batch   48  loss=387.4499  steps/s=103.84  prediction: \"G SUB 30 BABYYYY https://t.co/E87r3E6tgg\" => \"IVF)eGU 3BBBYYYYYYYAht /t/://t/.777EE336\"\n",
      "batch   49  loss=369.6763  steps/s=105.40  prediction: \"ut you neeeeeed execution skill yourself\" => \"dðŸ›‘DwF/k0D0GzkAS0Y)B3)iy\n",
      "AGAFYY3:p3EAx:/Y\"\n",
      "batch   50  loss=397.8880  steps/s=103.35  prediction: \"nd then vcs give u money for some reason\" => \" i tnnennn  nvvvg     eenoonofoerererrss\"\n",
      "batch   51  loss=304.1294  steps/s=105.73  prediction: \" relationship where you never lie to her\" => \"waaa  anonniiiiwhheeeeey      veeevo  te\"\n",
      "batch   52  loss=285.2730  steps/s=105.52  prediction: \"n clarity from practicing visualizationâ€¦\" => \" tinnn itttrryyr mfaacciiiigvgvaaazzaanâ€¦\"\n",
      "batch   53  loss=341.6014  steps/s=104.01  prediction: \"the community give me energy to do these\" => \"ho ho  ommmctniiiigy eeeeeenny     otttt\"\n",
      "batch   54  loss=583.8149  steps/s=41.88  prediction: \"ly: @pepegawitch https://t.co/SATxjQ6nk5\" => \"o e  mmmmongtiigc  etenn:/nyyc SSoTjjQ6s\"\n",
      "batch   55  loss=461.5228  steps/s=135.13  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"epl@pncnprytc   ec  cmp 5f5 f LLLp  hMol\"\n",
      "batch   57  loss=335.3247  steps/s=104.64  prediction: \"bly helps that they have a faster ai now\" => \"eabllyypy hhhhttttt  aaeaaaaaaa s      r\"\n",
      "batch   58  loss=541.1418  steps/s=81.24  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eblarlpart@nnbkkkesssddss ii it ras  195\"\n",
      "batch   59  loss=309.3808  steps/s=106.19  prediction: \"ressure either turns to dust or to a gem\" => \"esrrssreeeeee    rurt t   ssosotroo     \"\n",
      "batch   60  loss=440.8191  steps/s=63.00  prediction: \"@liljuuliet this https://t.co/MmuaB56dUP\" => \"BaðŸ’ªqBð—¶BJJJ@zkJ@@k@g;k&d~gq0q1qqw0b1L9qq1\"\n",
      "batch   61  loss=256.3979  steps/s=106.73  prediction: \" local optima solution they got stuck in\" => \"taiyoooolollaaal miititotton     gttstuc\"\n",
      "batch   62  loss=401.9140  steps/s=103.98  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/stt/..cUUUTcOOOOGmdept/s///e/zczRzzVLdC\"\n",
      "batch   63  loss=495.5575  steps/s=104.77  prediction: \"ublic Refining my problem finder program\" => \"sldnicluRYnnnnni U  yppe mlbbfmrrrO Oorm\"\n",
      "batch   64  loss=378.9415  steps/s=82.25  prediction: \"omeik that is super super super cool wtf\" => \"npkioio e  k t tsppsruprrrsssup  eooscor\"\n",
      "batch   65  loss=277.0549  steps/s=105.33  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"l ydadaaann      ii\"\"\"eee  cctotonnntnna\"\n",
      "batch   66  loss=361.4194  steps/s=103.93  prediction: \"boards to learn the keys other ppl used)\" => \"eleaarddt   e   tt   eekkkyhy r  pppp us\"\n",
      "batch   67  loss=663.7723  steps/s=101.53  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"dOOOOOOOOOOOOOOOOKOCUGNtttt/////DDJJJEEE\"\n",
      "batch   69  loss=877.8121  steps/s=84.90  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \": @ cc_ccccdcc  \n",
      "h hp:ppt:/to/o/KtKINGxG\"\n",
      "batch   70  loss=489.8987  steps/s=105.28  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: eexr ss   u amaartmttttt/.9.9Rpp888u\"\n",
      "batch   71  loss=402.3341  steps/s=101.54  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"epapr r iaaal laen\n",
      "hts\n",
      "h//:t.t.cDtDJJY3d\"\n",
      "batch   72  loss=578.1496  steps/s=89.06  prediction: \"icCapital COMMENCE OPERATION BRAIN DRAIN\" => \"na /ppptalltaMMEEECEN:CNROANINRBNNIIAANN\"\n",
      "batch   73  loss=290.2672  steps/s=104.83  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" urrrrr ayay  ssss\n",
      "r\n",
      "shtttttt/tXXLLLccFF\"\n",
      "batch   74  loss=294.9890  steps/s=103.81  prediction: \"l release results soonish #buildinpublic\" => \"ei\n",
      "lllreeeeeerssssss  ooo i##iiiiiuublll\"\n",
      "batch   75  loss=307.2766  steps/s=103.70  prediction: \"pl make it interesting/fun/useful? dunno\" => \"eo l  lkek iiiieeetttengnnn////ffu??ssse\"\n",
      "batch   76  loss=463.1895  steps/s=102.32  prediction: \"his\n",
      "Lets build some cool stuff. So hyped\" => \"i id \n",
      "\n",
      " ttttsddsddlo oool  sfto ffff .. \"\n",
      "batch   77  loss=299.5493  steps/s=103.36  prediction: \" own instead of relying on school for it\" => \"irowonnninnisse eee yylyfo o ooooooon h \"\n",
      "batch   78  loss=388.5148  steps/s=94.59  prediction: \"07 .-.. ..-. --. --. --. --. --. --. --.\" => \"x a7a-......--..---  --  -- - - -------ðŸ›‘\"\n",
      "batch   79  loss=306.6770  steps/s=101.93  prediction: \"a wave of weird suspensions going around\" => \"nne omooawawwawe    d sssssniigngnnnnnnn\"\n",
      "batch   80  loss=391.8799  steps/s=107.00  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \"tbt@aoa  m eeheem mh eehm\n",
      "\n",
      "manr \n",
      "  r yyðŸ›‘\"\n",
      "batch   81  loss=283.3126  steps/s=104.11  prediction: \"reevaluating concepts you often overlook\" => \"eph elllaaaiigignccnttto o  oy eeeeeeooo\"\n",
      "batch   82  loss=430.3477  steps/s=92.60  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" ewggB@@@AwPbb_yeyseuuY pd uhhshooohnnhw\"\n",
      "batch   83  loss=397.7703  steps/s=90.15  prediction: \"dup QUICK do something that doesnt scale\" => \" pzu eQUI KKCC  o dooiihitth  ossssntsnl\"\n",
      "batch   85  loss=368.5598  steps/s=103.99  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"termrmrma t   i ))tppptss:////.s...AQA8Y\"\n",
      "batch   86  loss=291.7715  steps/s=104.51  prediction: \"etting up a fake verification system etc\" => \"rstttggnn      uuafeffiiiiiiieccsssttttt\"\n",
      "batch   87  loss=487.1819  steps/s=63.56  prediction: \"@nlevnet that's a great thought actually\" => \"la+++11++++++++Y1+Y+++++++++++++++++++++\"\n",
      "batch   88  loss=318.3933  steps/s=112.31  prediction: \"ee time lately\n",
      "\n",
      "it has a long ways to go\" => \"r eeeeemei taltl\n",
      "\n",
      "\n",
      "\n",
      "at aa       wwwgoggg\"\n",
      "batch   89  loss=359.3704  steps/s=95.37  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \"ghwnnhcbhooocb  eeeb abakcnc ykyeebb   ðŸ˜Ž\"\n",
      "batch   90  loss=333.6389  steps/s=99.50  prediction: \"t lately\n",
      "\n",
      "Your RPA loop is pretty useful\" => \"hiltallty\n",
      "\n",
      "\n",
      "\n",
      "o\n",
      " RPAAPo     ppprrreteeuuu\"\n",
      "batch   91  loss=293.6091  steps/s=104.26  prediction: \", how much info could you get from that?\" => \" iia,, mh c hccccooou      y   fgftttttt\"\n",
      "batch   92  loss=272.1950  steps/s=102.59  prediction: \"bank account evaporate like a black hole\" => \"asu  aacccccnnn  oootaatteee  lllkkkab  \"\n",
      "batch   93  loss=322.3102  steps/s=100.53  prediction: \"concept, yes\n",
      "\n",
      "2/3 depends on the concept\" => \"aigncceccttce\n",
      "\n",
      "\n",
      "233/eyedddds   e   enneo\"\n",
      "batch   94  loss=282.2443  steps/s=102.58  prediction: \"n for games (more encouraging?) but canâ€¦\" => \"gwnoooo   aamm(mr(eeeeeeoogggg??nuu    â€¦\"\n",
      "batch   95  loss=443.7749  steps/s=103.93  prediction: \"Incredibly based\n",
      "https://t.co/IOxblXKnJv\" => \"tnTBIciiiiibbbd dasdtttt/:////..c/ObXKKJ\"\n",
      "batch   96  loss=425.4073  steps/s=103.28  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \".c ftasmiiha***gsjhhtt::pttt.//KKKcIIImq\"\n",
      "batch   97  loss=396.2682  steps/s=41.63  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"lfllaaaehhhhhh w   thsss//pcto.oxpImmmJm\"\n",
      "batch   98  loss=382.4663  steps/s=111.14  prediction: \"tbh, i like having control over my tools\" => \" folrhl i ii   kivð˜ gogn oootor   mtotol\"\n",
      "batch   99  loss=355.4691  steps/s=88.05  prediction: \"ach_ @pixqc that's smart. will try this.\" => \"kbcab_@h@pqqcapaa'}st srr    tlltyy tits\"\n",
      "batch  100  loss=392.3533  steps/s=104.84  prediction: \"velsio's\n",
      "\n",
      "just gotta keep building, bros\" => \"anreðŸ’ªvv''s\n",
      "ss\n",
      "e\n",
      "ugtto tttk  epkbiið—²g,jb,\"\n",
      "batch  101  loss=337.3325  steps/s=105.01  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"eugeeiigistillllillttttÉ´/////ooA66VOOSGG\"\n",
      "batch  103  loss=356.9421  steps/s=57.13  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"ty 6i sssseeeoreothpph/pt/.cc//coocXQQQT\"\n",
      "batch  104  loss=368.4890  steps/s=107.62  prediction: \" apart and send each one off to an agent\" => \"soaataataa    eddneee ne hoooo  of faann\"\n",
      "batch  105  loss=364.4120  steps/s=104.12  prediction: \"e WAY more effective\n",
      "\n",
      "global optima gang\" => \"cvi  WYYrrr eeeefffvccvv\n",
      "ooaooollliaaggg\"\n",
      "batch  106  loss=347.3732  steps/s=99.97  prediction: \"ont need sleep, your mind goes wide open\" => \"n  oudddd eeeee p    r u mi oeo oidwwede\"\n",
      "batch  107  loss=339.6742  steps/s=105.42  prediction: \"snt, now i think and focus waaaay better\" => \"leepðŸ¤£AZ'á´¡dWd\n",
      "CkpðŸ˜¤pWIw,W\n",
      "tá´ðŸ§ ,â™‚,ð˜‚,â€œmfIð—¶á´hðŸ›‘\"\n",
      "batch  108  loss=359.7866  steps/s=97.56  prediction: \"Some Tal games are real art masterpieces\" => \" on o T T aaelaaae sea lrrrðŸ“ˆðŸ˜¢a l emstecð—¯\"\n",
      "batch  109  loss=418.5008  steps/s=85.60  prediction: \"y_builds i wouldrather shootmyself loool\" => \":c@sbislggiiuuu ðŸŽ‰iaðŸ‘uhðŸ˜rhttðŸ“ˆmsðŸ‘€sooyÊ€oá´oÉ´\"\n",
      "batch  110  loss=416.2111  steps/s=91.17  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"rsuulddayyLELLSTOOOOOOOOsooeeelcbcbkbbro\"\n",
      "batch  111  loss=377.7670  steps/s=105.90  prediction: \"y its been a useful learning experience?\" => \"ou a  us sea aeeuueulufllearnnxrerá´epee?\"\n",
      "batch  112  loss=390.5783  steps/s=96.12  prediction: \"Lynx the less you talk the more you walk\" => \"LCèµ°æˆ‘ÊŸkPPbj~}{â€¦u\n",
      "á´‡ð—¿ðŸ«¡ÉªðŸ¤”jÉ´%\n",
      "ð—µðŸ¤¯;â™‚x~xðŸ«¡}á´ð—¼xð—¯??\"\n",
      "batch  113  loss=387.4903  steps/s=105.94  prediction: \"yo grand children at 85. gps kids r busy\" => \"  g d5yn ndacddrrriaa88  .   pp  ss   ds\"\n",
      "batch  115  loss=318.0221  steps/s=104.68  prediction: \"ments as opposed to making the user wait\" => \" nenmsas*app opo o ooo mn  tn  heeu   wr\"\n",
      "batch  116  loss=363.6364  steps/s=104.65  prediction: \"g/take a break from dopamine-exhaustingâ€¦\" => \" eaaidaaa   e k rrrrooomopmp--exxaeauniâ€¦\"\n",
      "batch  117  loss=343.9589  steps/s=98.90  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"rerrr oaaaaatiinnniLIVVEEE\n",
      "ooo  ffftttti\"\n",
      "batch  118  loss=418.1483  steps/s=25.65  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" rcraoaaacctiin\n",
      "nIL VEEE\n",
      "\n",
      " ooo4 fNOtreeC\"\n",
      "batch  119  loss=413.9189  steps/s=107.99  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \"   eeeoo siigupgpwtwwttp:h////HKTKTKZzjE\"\n",
      "batch  120  loss=400.1859  steps/s=29.93  prediction: \"ply: @sunsettler https://t.co/8FPo1elzOu\" => \"oele sunssseunp  htpp::/t..t./KFPP/zjzEO\"\n",
      "batch  121  loss=459.3067  steps/s=115.10  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \"nfice o no ohA nS)hAARet(::/tcQQo/JJncnR\"\n",
      "batch  122  loss=413.7653  steps/s=105.01  prediction: \"just think your program into existence?\"\" => \"uuet t jjsc dujjkksjnk hnð˜€gðŸ‘sðŸ˜Žm!sá´‡t gxðŸ˜†á´‡\"\n",
      "batch  123  loss=490.1003  steps/s=103.54  prediction: \"thought I would\n",
      "\n",
      "Now, I shall take tomoâ€¦\" => \" an hhhIuI â€â€ugotdN\n",
      "\n",
      "\n",
      " ,,,, shsll  alott\"\n",
      "batch  124  loss=440.4399  steps/s=99.34  prediction: \"lly great post and great advice. thanks!\" => \"o: : gll á´‡oå€‘oa popd grea dedv a.vatick !\"\n",
      "batch  125  loss=406.8527  steps/s=105.68  prediction: \" for most models\n",
      "https://t.co/US1Fvcybrh\" => \"cmpfoo foottmstd s\n",
      "hst#\n",
      "::/ht!s.UUS1FcS1\"\n",
      "batch  126  loss=548.1957  steps/s=103.29  prediction: \"ot which will drain your web3 wallet. hâ€¦\" => \"nolalllnndboad ancwnccllc a3n3cohuu33b33\"\n",
      "batch  127  loss=452.0202  steps/s=103.63  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"c ast a syurIuacr;asâ€6syl:hs:pco/5T/Tj9j\"\n",
      "batch  128  loss=426.4130  steps/s=37.78  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"l:s y@aeayactcruyouAsa/:t.c.ðŸš€5s5T5aj93U3\"\n",
      "batch  130  loss=403.1409  steps/s=145.26  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"eplj2r lroelic thhkpks/t .c:/g.5ctpHH3AA\"\n",
      "batch  131  loss=449.2065  steps/s=77.50  prediction: \"minus9 This is my new favorite edm track\" => \"pr@@o Nis999hhhn ikmpsy&ntw:.voovitHHdAm\"\n",
      "batch  132  loss=417.8310  steps/s=106.39  prediction: \"ut what it meant https://t.co/XYAZfowlv5\" => \" o  ohot uwameatt eoneh:/ pcs//YYZZâ™‚XAAA\"\n",
      "batch  134  loss=521.7798  steps/s=99.79  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"zmeri rgeggGLLLEEXUUURMMILFFLLEREMM GGLG\"\n",
      "batch  137  loss=520.5699  steps/s=98.17  prediction: \"p chats and 4chan are two i can think of\" => \"lyghhh  aaa444cans ca artooi4re  ttnin i\"\n",
      "batch  138  loss=382.5294  steps/s=104.16  prediction: \"hings way easier\n",
      "https://t.co/SoZ8VeXTFk\" => \"angtingno ayyysrsste\n",
      "ttps\n",
      "///pSZ\n",
      "8VZVZ:X\"\n",
      "batch  139  loss=409.9660  steps/s=97.79  prediction: \"the man just liked big words and spirals\" => \"hrm emmau jaytsesseabaeb wlwd wrgdsonrr \"\n",
      "batch  140  loss=428.2130  steps/s=11.12  prediction: \"reply: @Brycicle77 polnareff could never\" => \"ephssynmahðŸ¤·n aâ€¦knuyjjjbibyd lggwâ€¦hans np\"\n",
      "batch  141  loss=365.7922  steps/s=147.46  prediction: \" wtf is a monoidal field\n",
      "\n",
      "i want to know\" => \"@wgdmmetf ut a#fas mnâ€™ldfiiafeeiblsnwa\n",
      "w\"\n",
      "batch  142  loss=348.3469  steps/s=101.26  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"mhi  eise\n",
      "dfsding ivv\n",
      "dcmnaaer}vvgviðŸ¤¦asp\"\n",
      "batch  143  loss=445.0588  steps/s=104.00  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"tostotallhQQCWWZZxj/(xc/(w ab(1x.n  n5(C\"\n",
      "batch  144  loss=483.1055  steps/s=101.44  prediction: \"lad its helpful man, which did you read?\" => \"ln iiss aidss  iZfllmmh,m(mmilwmcd ddyy \"\n",
      "batch  145  loss=489.1585  steps/s=103.11  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"ttaloottUh4.t./oLs4t4Lr:/A.chh2psAL/tozJ\"\n",
      "batch  146  loss=464.6762  steps/s=100.64  prediction: \"now how to do it https://t.co/y5LFqaVw5b\" => \"twtnkw tow do dt'otokit dh pdLp.poqy5L5V\"\n",
      "batch  147  loss=386.1823  steps/s=105.34  prediction: \"the behavior, forming a habit eventually\" => \"hii ohtineb,vðŸ˜¢vorbffrforgibg,abhbitrvebu\"\n",
      "batch  148  loss=380.6904  steps/s=101.44  prediction: \" have another tweet promoting AB testing\" => \"tetive va enavewnerenrpot ptttABBBAtitin\"\n",
      "batch  149  loss=386.1688  steps/s=101.20  prediction: \"and then pivot to doing a project in zig\" => \"rdsnndn tehep oviioptÊœodggoi aojjjettecz\"\n",
      "batch  150  loss=369.3269  steps/s=102.97  prediction: \"ark a bit so i felt like writing this up\" => \"nd  hme sitkeeeið˜rhðŸ¤”m kfke{wbikeekriðŸ˜¢ieâ€\"\n",
      "batch  151  loss=400.5482  steps/s=102.37  prediction: \"ate? i mean i can guess, but.. nice work\" => \"rishata? iow?ð—¶???mtan i#mhrigbecð—¯, nucu \"\n",
      "batch  152  loss=401.4222  steps/s=90.42  prediction: \"mannak Duh they used the hydraulic press\" => \"aly on Du DnhkDfuD?utedthsydyy.b uhdoapl\"\n",
      "batch  153  loss=407.5267  steps/s=102.59  prediction: \"gh Ive been wanting to do a wasm project\" => \"ltlyuoagIvIðŸŒ‘bIbphw wa ngwtutgedo wgwa pg\"\n",
      "batch  154  loss=367.6550  steps/s=104.09  prediction: \"s but I strongly believe in it long term\" => \" c owe  useIrnurb bbyiovgnð—¯nn bblgvgvoeg\"\n",
      "batch  155  loss=481.6080  steps/s=103.35  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/r.soo  zyoZolhIj/:s::::/.c.zzZZZZgjbbjQ\"\n",
      "batch  156  loss=472.5715  steps/s=105.67  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"@r  esdaaIe 4rmmI\n",
      "a4n dnlolvdtggg  gaFel\"\n",
      "batch  157  loss=356.8812  steps/s=100.92  prediction: \"ng so you can automate ruining your life\" => \" \n",
      " ndgios cuucaunnattnmta$etuðŸš€iyrgrnâ€™ rr\"\n",
      "batch  158  loss=474.6924  steps/s=105.66  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yt e teel c pc cffjopffk2\n",
      "\n",
      "\n",
      "ee\n",
      "dttdoodon\"\n",
      "batch  159  loss=413.3411  steps/s=104.76  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \" ps///chc.RTTOOWWPPPS))hTO&OP/L.toS)BBBx\"\n",
      "batch  160  loss=655.0651  steps/s=101.59  prediction: \"e yup same did exactly this, worked well\" => \"play nesylWTwyp)amacnixaWOlcaxxxyxhwsykR\"\n",
      "batch  161  loss=510.9725  steps/s=87.85  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \"pyy@ drrw OhdahTaThwtkk ahanRRTT ttbemw!\"\n",
      "batch  162  loss=454.6458  steps/s=106.99  prediction: \" @btwphones whoa https://t.co/dCCbEgrV7b\" => \"@_ha@@twshes@Os@etppkftpp:t/ ..ooTbC/bV7\"\n",
      "batch  163  loss=520.5903  steps/s=96.84  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"tel@kr@i @qxxxFIIFpEEIHTFFOODDOCGIGGSINN\"\n",
      "batch  164  loss=593.4844  steps/s=99.14  prediction: \"n pick your own time though its flexible\" => \"tmtuay popk pnukpyyouroNn trtTmm htihs G\"\n",
      "batch  165  loss=475.9263  steps/s=97.30  prediction: \"utter if i&lt;n: https://t.co/yZ8fEWwfzs\" => \"scBtte   i&&t;;keftti::pt//p../o8ZEffWWz\"\n",
      "batch  167  loss=543.9431  steps/s=100.08  prediction: \"wesome looking pieces though, im jealous\" => \"igAAljlt@PwBuAki;&;jklnompAhouwn,pku/h8a\"\n",
      "batch  168  loss=385.8794  steps/s=105.75  prediction: \"ions for agents\n",
      "Sounds v similar to this\" => \"nn  fs tir wðŸ°fnaguStsnt\n",
      "uiusidrlSvim\n",
      "rlv\"\n",
      "batch  169  loss=419.4839  steps/s=104.84  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \" if dm iEEMSL_evievaidanfnd__dcddotnstSi\"\n",
      "batch  171  loss=367.6082  steps/s=100.83  prediction: \" it seems like a fire worth playing with\" => \"dl ieesesln selmkftf fere woltpyali pngy\"\n",
      "batch  172  loss=331.9414  steps/s=100.45  prediction: \" said it was his last email, he meant it\" => \"@e he   ia WaiWwss hest laall,ihemle im \"\n",
      "batch  173  loss=376.6531  steps/s=105.41  prediction: \"ks for me though. Carbs make me sluggish\" => \" ri rfrrstkorrmt t. C.r.Chbabo me Cr e i\"\n",
      "batch  174  loss=381.7036  steps/s=97.25  prediction: \"xoki How do I know this isnt a lie tho ðŸ¤”\" => \"^ksseal Hokt oiI oI nonw h is s nna ahðŸ¤” \"\n",
      "batch  175  loss=382.8372  steps/s=97.24  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \"hsor@ i tjAknckmTm mA nmsATTt  oorissiðŸ¤”ðŸ‘\"\n",
      "batch  176  loss=383.8690  steps/s=103.55  prediction: \"ey once, will play otb w friends usually\" => \" a unuu,  yyenew,wccðŸ‘Œlaï¸patoâ€o y ffrdeå€‘n\"\n",
      "batch  177  loss=452.2478  steps/s=106.27  prediction: \"us @BasedBeffJezos Some are on the money\" => \"s @nb sasBeBoJ@sezBokSSmreaom reseme tho\"\n",
      "batch  178  loss=479.9536  steps/s=76.11  prediction: \"yMazza my favorite systems administrator\" => \":o@ yMzzeasBJ mvvrivza yysrdmte smarhdrr\"\n",
      "batch  179  loss=435.5852  steps/s=106.55  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lyVVpse rthi\"H Hv\"tv(Hm\"emvvadoel aah  s\"\n",
      "batch  180  loss=358.4108  steps/s=106.26  prediction: \"above average in to get above avg skills\" => \"n le aoeve abá´¡ ggirnvðŸ‘€ogá´‡einabvova akikk\"\n",
      "batch  181  loss=414.9290  steps/s=71.55  prediction: \"izmobly circle gang is TRULY unstoppable\" => \"mgeob@ olyeclrrce tieðŸŽ‰æˆ‘TUULYRULYeaatlopt\"\n",
      "batch  182  loss=386.8748  steps/s=110.67  prediction: \"t. have they found the piece yet or what\" => \" ttah.hte  ttveyffo f ehdndYcet  eet  ww\"\n",
      "batch  183  loss=357.1030  steps/s=99.79  prediction: \"es courage\n",
      "lack of courage is a weakness\" => \"Mta csecoue[ge\n",
      "k cl uu reueaueagepasklck\"\n",
      "batch  184  loss=396.1479  steps/s=105.67  prediction: \"are is definitely a great career for you\" => \"te wtrareridssðŸŽ‰csâ€¦il!iyfgnggtecpcðŸ˜Ž!reeor\"\n",
      "batch  185  loss=478.8285  steps/s=101.67  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"rpl `o k``knå§ `ð—±uðŸš€itnsi/ pn`e55.:ï¸/59:TI\"\n",
      "batch  186  loss=467.5081  steps/s=104.40  prediction: \"/t.co/vfpikXycuH https://t.co/HIjM4H1lEy\" => \"/tc\n",
      "cstps )XX/c/pXXXXc/X/HHyHs:Hhj:41.pE\"\n",
      "batch  187  loss=419.5977  steps/s=105.12  prediction: \"per curious to see what youre working on\" => \"elir rer i ei to,te swhpwiyhð—»ycat reerko\"\n",
      "batch  188  loss=403.4091  steps/s=94.71  prediction: \"ncredibly mesmerizing to watch. dang bro\" => \" seciedvbDDrDDrdllzzebmesrngitnðŸ“‰wztag. d\"\n",
      "batch  189  loss=400.3240  steps/s=97.02  prediction: \"daily Whats your roadmap for learning ml\" => \" cucilyaWhachdl uaorWadsamdp ffop laenll\"\n",
      "batch  190  loss=342.0328  steps/s=103.49  prediction: \"orce you to clean to avoid embarrassment\" => \"f rrooey oyo ou aalc navodr dddbbararase\"\n",
      "batch  191  loss=395.9000  steps/s=105.17  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n to ypp) g)vd dvgdeoð—ªssisevrhfinbiteebb\"\n",
      "batch  192  loss=408.4236  steps/s=95.06  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"giBBA Agg ipyyisysoogmm:tptpp:/.N6/q06kq\"\n",
      "batch  193  loss=461.1669  steps/s=105.41  prediction: \" going straight there out of highschool)\" => \"(ahae gnig ishaihh tohreshouigofr hgscsc\"\n",
      "batch  194  loss=331.3871  steps/s=52.67  prediction: \": @IterIntellectus here have another one\" => \" @e:itg ItIeleghtctgsrrigtavafe oto heos\"\n",
      "batch  195  loss=372.1597  steps/s=107.08  prediction: \"er. you thaw the skill out when its time\" => \" eer.oe y towwawha .ryl uku weuw eisi ii\"\n",
      "batch  196  loss=349.6447  steps/s=102.82  prediction: \"so i havent used anything like webgl yet\" => \" sss i  io #veeâ€œennet aa yhiyvðŸ˜¢siwgl eðŸš€y\"\n",
      "batch  197  loss=377.2815  steps/s=97.94  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \"gtenipip ey x dâ€œy dpyo::/piatppZZp65:xNU\"\n",
      "batch  199  loss=451.2906  steps/s=99.49  prediction: \"mcignore feature https://t.co/oLseuf2uxS\" => \"ulac  nign fhxmeaaurr /s:po:./h.cL.coL2u\"\n",
      "batch  200  loss=433.6833  steps/s=99.64  prediction: \"ight go back to ML stuff instead of this\" => \"ndim g bt bo iacM ok Mo /tgf sicso id id\"\n",
      "batch  201  loss=463.8055  steps/s=77.09  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"inR@bib_VVlk CCCgGPPLTaLTL dneofofep rop\"\n",
      "batch  202  loss=458.1965  steps/s=106.34  prediction: \"z and ctrl+y now https://t.co/1AII6b45hG\" => \" ict ttz +++nch+a+tan+n+wyhhop11+I66/45/\"\n",
      "batch  203  loss=569.5563  steps/s=102.78  prediction: \" at 5:10 or something I just go til 9:10\" => \"Inat tt i 00:ta emseo0oIijhgg :ust lt9:9\"\n",
      "batch  204  loss=353.8094  steps/s=102.91  prediction: \"e are, so it has a ton of ripple effects\" => \" toow  oo s oheitwsoi á´„oinnf finppfaefðŸ’ªf\"\n",
      "batch  205  loss=445.4047  steps/s=101.98  prediction: \"arning, josh waitzkin\n",
      "\n",
      "Gigacracked books\" => \"ra h oo  ,ornsi ,air,\n",
      "\n",
      "GGag kkctteznjabz\"\n",
      "batch  206  loss=455.7743  steps/s=95.25  prediction: \"us @yacineMTB nonononononononononononono\" => \"n riiusnsyuMTTBnjMTcone ononon sohokonhw\"\n",
      "batch  207  loss=485.3660  steps/s=100.09  prediction: \" your own game engine\n",
      "challenge accepted\" => \"@oP tr r urnyguPr cnme\n",
      "m\n",
      "nwneichgehaenep\"\n",
      "batch  208  loss=384.9608  steps/s=103.38  prediction: \"ing vidya except w only positive effects\" => \"n imgdi r vyixy peðŸ˜Žc wnpwos ð˜otisxveitsc\"\n",
      "batch  209  loss=382.2949  steps/s=21.41  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" livgdd d vxcxc peðŸ˜Žn wcwwoytðŸ˜vtivxoeittc\"\n",
      "batch  210  loss=370.9571  steps/s=109.11  prediction: \"no responses or just \"cool!\" Or whatever\" => \"  tke  o  eupprnupnå§\"rjjlj!\"\"O\"l!\"á´„!OO o\"\n",
      "batch  211  loss=422.1866  steps/s=103.41  prediction: \"but its ok bc I know theyre high density\" => \"um te  ttsokkbckIIbnosehheot hhyg  iirsd\"\n",
      "batch  212  loss=377.7690  steps/s=11.54  prediction: \"reply: @graffioh HA thats really awesome\" => \"eam btte euNckIbcsoIktIb tncyInb dggI tw\"\n",
      "batch  213  loss=382.7045  steps/s=107.78  prediction: \"by removing a bit does not increase theâ€¦\" => \"exiiybe mitonb vðŸ¤£pgtadgddoeoisctcasrrbâ€¦e\"\n",
      "batch  214  loss=385.1503  steps/s=102.72  prediction: \"amount of time, or did you just enjoy it\" => \"  aituun uettiam1, of oc fiuejju2juetjyd\"\n",
      "batch  215  loss=370.0411  steps/s=102.65  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \"rti s prrtmeps\n",
      "ioðŸ¤£\n",
      "a\n",
      "ðŸ¤£ aarricomQxrtxstmx\"\n",
      "batch  216  loss=363.1566  steps/s=104.15  prediction: \"complete projects than 20 half done ones\" => \"t \n",
      "\n",
      "wte e ehyvmjrðŸ“‰tshts 2020200laldod0cn\"\n",
      "batch  217  loss=367.9762  steps/s=97.37  prediction: \"im gonna read the whole library of babel\" => \"n m  m no ogaarahhe hhlâ€ollblabbbeb hn ðŸ›‘\"\n",
      "batch  218  loss=366.7425  steps/s=103.99  prediction: \"ve to or weak squares/pieces etc etc etc\" => \"ilrvi ce esuueakumqu/qqq/qikuwqvutrið—¶,pi\"\n",
      "batch  219  loss=340.4067  steps/s=103.93  prediction: \"go, the name.. none of that shit matters\" => \"oooo,   heentt...o o aehfhnt th tamtmtht\"\n",
      "batch  221  loss=381.8792  steps/s=105.34  prediction: \"s principle imo\n",
      "\n",
      "https://t.co/VzXUJ8r5oL\" => \" ops nn poihli\n",
      "l\n",
      "ptmip::/moooVVVXXJX8z5L\"\n",
      "batch  222  loss=418.6765  steps/s=101.58  prediction: \"utomatically imagine letters as colored?\" => \"r u ataaaaiyð—²timaiiaggme lle als  cocoe?\"\n",
      "batch  223  loss=462.9669  steps/s=103.29  prediction: \"e broth its much better\n",
      "How you been man\" => \" hiobnoot eih  hth bbctHHtttt toou oenbr\"\n",
      "batch  224  loss=401.0146  steps/s=104.62  prediction: \"t habit of reaching for my phone is gone\" => \" tthbbah     frc c cnrg  rm y mnn e on  \"\n",
      "batch  225  loss=329.2094  steps/s=104.89  prediction: \"put work in, etc https://t.co/8ZjkHbRuMG\" => \"uou llp w   kk ,,n ttth:://c..88ZZjHRRRM\"\n",
      "batch  226  loss=439.1178  steps/s=98.20  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"ee eloyeek lingnghá´€thpsps:tpootoc33A0j.j\"\n",
      "batch  227  loss=397.9284  steps/s=104.76  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"g }n?nn2:en n rrohhtt e r qdaa,rrppa,e##\"\n",
      "batch  228  loss=780.5051  steps/s=101.59  prediction: \"indie game of the year im calling it now\" => \"n @L ii eee e fomf  hayir ce lllllig  in\"\n",
      "batch  229  loss=355.5775  steps/s=101.36  prediction: \"resting, what kinds of tools has he made\" => \"eplklgreslibg,odham kmnes?yfgrgrlrgk,kwk\"\n",
      "batch  230  loss=287.4696  steps/s=101.44  prediction: \"ure the first man on mars thats so crazy\" => \"neeuyyy   rrrtrttt nnmaaa saha sss  r rz\"\n",
      "batch  231  loss=341.1973  steps/s=103.57  prediction: \"ull potential. That would be surprising.\" => \"ruef l lottitt...TT tala ul   budrrrrrsi\"\n",
      "batch  232  loss=320.1572  steps/s=104.34  prediction: \"t progress/mistakes made/lessons learned\" => \" ppptprrrss///sttttmmmaeaeeeesssss ll  n\"\n",
      "batch  233  loss=342.7530  steps/s=105.15  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \"itu (unttt8((((((..8k....y8k.b8$)0w)0(8:\"\n",
      "batch  235  loss=313.8933  steps/s=103.73  prediction: \" for hrs and hrs and the time just flies\" => \"pooorrrrr    hhhasdaa s  h eeeettm t jis\"\n",
      "batch  236  loss=280.1704  steps/s=68.88  prediction: \" @pilpulon will release v1 at some point\" => \"ppyfpp@ppnnonis i lleeeeet1vvj ssss oepðŸ›‘\"\n",
      "batch  237  loss=330.5039  steps/s=49.37  prediction: \"ply: @dgant wild https://t.co/0HTLsAprAT\" => \"ly:::i@laanwwiillllesesv/vtt  0HHTLoppAðŸ›‘\"\n",
      "batch  238  loss=360.9065  steps/s=148.29  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \"df@mmjumweejjjbbybhjttttp///c.99/ZZooRRm\"\n",
      "batch  239  loss=318.3366  steps/s=105.17  prediction: \"cy and then work up to really short ones\" => \"oncnnyy h het hhww  k prrrra ll llyloooe\"\n",
      "batch  240  loss=294.1320  steps/s=104.63  prediction: \"how u get llms to make huge projects btw\" => \"isss    og lletg   mtm ameee   reojcrcst\"\n",
      "batch  241  loss=338.8156  steps/s=30.40  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"le w  ouueetllte  tttak:// e rjjjvWHH1Tz\"\n",
      "batch  242  loss=294.8070  steps/s=125.51  prediction: \"ick and no login and as free as possible\" => \"s uck k   nnndoniindaaa   f  ssssessspsi\"\n",
      "batch  243  loss=451.0682  steps/s=96.49  prediction: \"@yacineMTB bedrock aws, us-west-whatever\" => \"cs1y3cncciTbBbeÊœcc   sss,,,--w--wksteevv\"\n",
      "batch  244  loss=395.0123  steps/s=76.25  prediction: \"kaysh No I have to run the code manually\" => \"ebakasoN N  Ih  vho o r  thcceeo  uaaaal\"\n",
      "batch  245  loss=327.4832  steps/s=106.67  prediction: \"dates/incentives to fund ai safety stuff\" => \" ieaaee/eneenctetsttt  d    uffndd yssff\"\n",
      "batch  246  loss=351.9320  steps/s=105.39  prediction: \", or if claude is in an india region tho\" => \" tir   , aaafdcue  e   n  nniaa  eaggnoo\"\n",
      "batch  247  loss=435.4845  steps/s=102.08  prediction: \"s man. i try to keep it real as they say\" => \"ia  t m  n  tttrt k  ee  rierra  tehaeys\"\n",
      "batch  248  loss=418.8092  steps/s=50.91  prediction: \": @EsotericCofe what are you working on?\" => \" @sm:sn.triCCooyefe phatr yaaaswowaryshðŸ›‘\"\n",
      "batch  249  loss=354.5578  steps/s=108.84  prediction: \" life during hard times\n",
      "Thank God for it\" => \"my e  e eididerddr ti m TTh\n",
      "anGGk noo   \"\n",
      "batch  250  loss=377.9974  steps/s=103.05  prediction: \"his was a super helpful technique for me\" => \"a it tss ssa s  uepppeulfel feqqeehhð—µ  e\"\n",
      "batch  251  loss=333.6392  steps/s=100.65  prediction: \"e others (including your past self) with\" => \" t  inursi(QgfðŸ˜†uyðŸ˜Ž((((fffa(&(m((((#=&hâ€™m\"\n",
      "batch  252  loss=437.1220  steps/s=104.16  prediction: \" they secretly exercise and dont tell us\" => \"ial h e stelyyet ereðŸ¤¦lrseirð˜‚deddðŸ’ªd tqel \"\n",
      "batch  253  loss=393.7329  steps/s=102.72  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"cpecc akapacaoaotglgtht:/ph//..1T01BBcIz\"\n",
      "batch  254  loss=477.2901  steps/s=104.45  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" e onf l aro)â€œusdðŸ‘€jlljwrnjjujj flsjðŸ˜¢å§ðŸ‘Œod\"\n",
      "batch  256  loss=332.8806  steps/s=103.97  prediction: \"the canvas match the white tetris shapes\" => \"h    eeaaavaaacctthh h w w etttiiiiisss \"\n",
      "batch  257  loss=289.6729  steps/s=103.81  prediction: \"o him) and he begged to pay me to use it\" => \"mlsoii  n  h  eeggggdddbda     tttoo   e\"\n",
      "batch  258  loss=374.5450  steps/s=104.24  prediction: \"owed em all\n",
      "How tf do you find these ppl\" => \"tnendeeeel llHHw    d  ooo fyfu dttteeep\"\n",
      "batch  259  loss=390.6490  steps/s=46.76  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \" cues@ em d\n",
      "dn @s@@tty00000nii nnses s ðŸ›‘\"\n",
      "batch  260  loss=403.8995  steps/s=126.43  prediction: \"neMTB @justalexoki the rise of carmacine\" => \"ts @yBiM@Bjsasaoooaaloiiireeeeoer raaacr\"\n",
      "batch  261  loss=295.9843  steps/s=70.61  prediction: \"justalexoki its tpot, all lowercase only\" => \"apy:juasaxtxiitiittt   palll  rraaawenne\"\n",
      "batch  262  loss=270.8015  steps/s=107.00  prediction: \"hange your brain. something to think abt\" => \"owscca ygyuuaubanbnroo..iiiinttthhhh hh \"\n",
      "batch  263  loss=280.0121  steps/s=101.65  prediction: \" of your day your brain will work better\" => \"tfseeooyoooyyyuuurrrrab iiiiwnwlll bbotb\"\n",
      "batch  264  loss=311.0234  steps/s=104.60  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"l tutttt    pppeenenmmmmrtoffaaaaan\n",
      "nee \"\n",
      "batch  265  loss=390.9022  steps/s=65.66  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"puldpoutiix@x@iqqhrhtttp\n",
      "////n/qqq/RRljðŸ›‘\"\n",
      "batch  266  loss=291.1133  steps/s=107.32  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" ta a nn www''iiiiiiiii\n",
      "eee      !rrrrll\"\n",
      "batch  267  loss=309.0984  steps/s=103.33  prediction: \"whereas, its easy to tell which is timeâ€¦\" => \"oemeraisesssss s     ttttewllwhhihiii   \"\n",
      "batch  268  loss=377.9026  steps/s=99.15  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"wedag\n",
      "gdhu dtttttrrrrdhww    IwIaassssnn\"\n",
      "batch  269  loss=281.4832  steps/s=103.67  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"g sdnaaaa      oofipptttttth//cVVV4458JJ\"\n",
      "batch  270  loss=376.9183  steps/s=39.36  prediction: \"ly: @0xbingllm we gettin it we gettin it\" => \"y n  n0   oggffppeettttii//ccc/f4g8t.ifr\"\n",
      "batch  271  loss=446.3074  steps/s=115.68  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" h f fp   5wtcscssstssss::p/...cKK/cS11F\"\n",
      "batch  272  loss=325.9872  steps/s=98.65  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \"i tetuu ynniss w\n",
      "ww\n",
      "sssahh ttthh t o  pc\"\n",
      "batch  273  loss=667.6265  steps/s=102.68  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"@uv  O5%% TETSSOOGTT L Gtttt/ccBB/66DD:9\"\n",
      "batch  274  loss=389.8633  steps/s=100.52  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"is vdeemaadaaaaabaehaptts\n",
      "//.:///ZZAALLg\"\n",
      "batch  275  loss=320.3646  steps/s=104.70  prediction: \"never I see that in mc, programming, etc\" => \"sveeeeew r     tttt     mm,rrmmmmm,,nggc\"\n",
      "batch  276  loss=296.0834  steps/s=104.16  prediction: \" a lot will impact the rest of your life\" => \"tna  a   lllliimi tttt eeee  o ooo orrrf\"\n",
      "batch  277  loss=348.1125  steps/s=104.18  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \"  tsssssiiiig-gtt--&tpp  epsadsisssggggt\"\n",
      "batch  278  loss=602.4573  steps/s=97.70  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"taLLyLEOLOO!!!O!OOSron ouun   aaeeeeeemðŸ›‘\"\n",
      "batch  280  loss=324.4627  steps/s=104.42  prediction: \"lity, not others, for what is true/false\" => \"y pniyi,oottttt, , s rrhhh w    istaa//e\"\n",
      "batch  281  loss=226.8836  steps/s=20.55  prediction: \"eply: @sunsettler you are the dan herder\" => \" lryl oo otttt er srrfhhe  h  aae/eereee\"\n",
      "batch  282  loss=300.8553  steps/s=110.18  prediction: \"ed around the data that flows through it\" => \" rsoamdnnun    haaaatttttt     fhroouuhh\"\n",
      "batch  283  loss=311.9170  steps/s=103.21  prediction: \"your brain doesnt have weird hooks in it\" => \"our  r rrrnrnonoo   avveeeeewhhhi  soiii\"\n",
      "batch  284  loss=442.7849  steps/s=103.16  prediction: \"on every monday and thursday of the week\" => \" noon ee vvooyyynmaadddadrd au  tttf hee\"\n",
      "batch  285  loss=290.6955  steps/s=104.57  prediction: \" games because we trusted each other lol\" => \"aemeeaaabaeaeesess u u tttttcettthhtrroo\"\n",
      "batch  286  loss=493.3429  steps/s=81.19  prediction: \"cows a truly great ideasguy will execute\" => \"o  djss c u  l lg ttteaeasg sygylleee eðŸ›‘\"\n",
      "batch  287  loss=724.9064  steps/s=13.97  prediction: \"reply: @helscom OF NOTHING\n",
      "IN PARTICULAR\" => \"epoysj@ oll  lylr ttteaegsgwiyllllexe eðŸ›‘\"\n",
      "batch  288  loss=317.8642  steps/s=107.28  prediction: \"ss I need to do keyboard input from it..\" => \"t ll  eneee   ddd oooybyybrriuppp    i t\"\n",
      "batch  289  loss=289.7811  steps/s=104.62  prediction: \"s Chat with your cat in the hat on a mat\" => \" sljtCwwwttiiiu  ur aa aitt  hhhhaaa  aa\"\n",
      "batch  290  loss=575.4498  steps/s=94.79  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \" :â€zXL!0H(:@L:A4)_N8A)4MO!zN5VH.z(CYO?!!\"\n",
      "batch  291  loss=296.1101  steps/s=104.38  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"hne sl,l,lle     oooootttttrrrnn    tetb\"\n",
      "batch  293  loss=542.8943  steps/s=100.27  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \"staFZaA\n",
      "Fpeeii'sllsttttteeeaxxpppssse't'\"\n",
      "batch  294  loss=290.6035  steps/s=69.50  prediction: \"doomslide its over needleinhaystack bros\" => \"uoy@oosdmiii  t  rr eeeeennlliasayaabcck\"\n",
      "batch  295  loss=480.8158  steps/s=105.83  prediction: \"bile and desktop https://t.co/f8MrtrXK28\" => \"ednblbe  ddd  kkkottptppsssp/..8.88rrXX2\"\n",
      "batch  296  loss=294.0363  steps/s=104.52  prediction: \"t (for example working when youre tired)\" => \"hsro(((r  mmeeeeewwwogi wg nnn erreereee\"\n",
      "batch  297  loss=463.4794  steps/s=105.55  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"d eeee p htssssgUh hPPPttttt////Sc/SGG.h\"\n",
      "batch  298  loss=578.6339  steps/s=99.27  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"L SIGNALLGAG SIAL    : Att/tsc/RR/oSiiPe\"\n",
      "batch  299  loss=290.5765  steps/s=105.00  prediction: \"tion WAY more than if its someone else's\" => \" fos   Y YY  mm   hniiiiff  sssoeeeeeesn\"\n",
      "batch  300  loss=293.4707  steps/s=97.69  prediction: \"credibly cool to see this project evolve\" => \"anaiitllcccllloooo   teees hshrojteejoee\"\n",
      "batch  301  loss=439.8470  steps/s=95.99  prediction: \"eos Oh I know :) https://t.co/aV1q8nmIEk\" => \"rnvehOhO   ooo::o)h)ht:tt///o/./V/qqaq1I\"\n",
      "batch  302  loss=314.2906  steps/s=102.10  prediction: \" what fever dream anime your pfp is from\" => \"ti u thtffwrrereeaeaam mm m y yffippffpr\"\n",
      "batch  303  loss=503.6692  steps/s=95.58  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \"plt1 1 1 i ii   :::lhtDttpttt.///c33Gttt\"\n",
      "batch  304  loss=322.6982  steps/s=103.55  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"aveeee r  vrwrioonnnttsss///////TSThT9a.\"\n",
      "batch  305  loss=360.2053  steps/s=104.14  prediction: \"d \"compress\" anything into 1 byte (veryâ€¦\" => \" a\"uoooolmppsssssnnnnniiigi t 111 yee(ey\"\n",
      "batch  306  loss=429.6181  steps/s=104.96  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tts a  eeopawwrJ*  tuðŸ˜Žtoo--oddt uutibtâ€¦\"\n",
      "batch  307  loss=518.7681  steps/s=104.47  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"butg  t!t!!!!!L!!GGGtt h:t///..OOOhRq.38\"\n",
      "batch  308  loss=555.7934  steps/s=102.60  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \"staZiopppF''leuullliileevaxaexex lseesec\"\n",
      "batch  309  loss=446.5350  steps/s=96.17  prediction: \" takes a lot of work and years of it tho\" => \"@yaeae  â€¦a a o  oorkoo      ryrs   o tt \"\n",
      "batch  310  loss=345.7705  steps/s=102.98  prediction: \"der the hood the better you can innovate\" => \"ens  eeehhhddtoto  teeeerr r  y annnnnaa\"\n",
      "batch  311  loss=325.0024  steps/s=98.62  prediction: \"rip\n",
      "\n",
      "he open sourced it to @crypt0x_0 ig\" => \"usaaprpeepep\n",
      "oooo ucec i  t@@tttt00__00x\"\n",
      "batch  312  loss=279.3099  steps/s=44.71  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \": @\n",
      "@222eeinnnn chT itittrcddiyyccxco tt\"\n",
      "batch  313  loss=381.8843  steps/s=119.89  prediction: \"ein @DrBrianKeating yea he made a portal\" => \"ptni@DDrrrrBKKKiaiiinaaeeee   eaa mm rmo\"\n",
      "batch  314  loss=374.0843  steps/s=103.82  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"uctc\n",
      "\n",
      "d eeeeee     tttssss/:/:p.pVVHHTT0\"\n",
      "batch  315  loss=293.3962  steps/s=100.08  prediction: \"lves and destroy it all for local optima\" => \"ysssssavaddd n  tttttt  ll oooooalo  cai\"\n",
      "batch  316  loss=434.0101  steps/s=105.74  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e otee  tttsssassi... .,  ,, ,  ,-11,,1-\"\n",
      "batch  318  loss=309.2315  steps/s=104.26  prediction: \"ast 3 weeks so development has been slow\" => \"ne ta33eeese    ss eeoeeopommmta nenenss\"\n",
      "batch  319  loss=442.0497  steps/s=104.60  prediction: \"kers #math #saas https://t.co/99Y0IouvaF\" => \"eihekea#aa### saassttstttpp/.//99YY/IIoo\"\n",
      "batch  320  loss=302.1223  steps/s=103.64  prediction: \"our life if you make work look like this\" => \"ur u ieiiiff f    oaemekkkkwooklllk    i\"\n",
      "batch  321  loss=332.5096  steps/s=104.96  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"wini t ttt +kkk   idddooroossi h    ?   \"\n",
      "batch  322  loss=306.2204  steps/s=104.43  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"t initotttt  rsssse\n",
      "v\n",
      "v\n",
      "\n",
      "l\n",
      "\n",
      "llekaaaaalll\"\n",
      "batch  323  loss=353.5290  steps/s=103.25  prediction: \"pi key and throw it in the settings\n",
      "done\" => \" w ii  i y   nhhhhttt  i    eeetttnsssnn\"\n",
      "batch  324  loss=333.9589  steps/s=104.72  prediction: \"BOIII zombies i fucking love zombies bro\" => \"ioOsIIOOO B  zs biiiicccloolgooozmembbb \"\n",
      "batch  325  loss=372.3340  steps/s=85.68  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"skk k@   cmmiiiil ee eeemsennnnnnass m s\"\n",
      "batch  326  loss=383.2537  steps/s=105.26  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \"pT w  e hh hsstssttttttpptst///::444q4hZ\"\n",
      "batch  327  loss=346.6435  steps/s=105.25  prediction: \"mentals can be really really hard to see\" => \"yobamanaaaa     eeelllberryyarar     tte\"\n",
      "batch  328  loss=422.1574  steps/s=105.71  prediction: \"saas #developers https://t.co/GmrQaIKpLs\" => \" ilaa#s#aeee eepsehshtt::/:t//.GGGQQoKKI\"\n",
      "batch  329  loss=357.2904  steps/s=102.57  prediction: \"ting the entire GOL industry as we speak\" => \"hm rritgttennereee LiLL i trrss     weee\"\n",
      "batch  330  loss=341.5438  steps/s=104.98  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"sell     aapaawwwelhltst:tttt//pMMpp.d5E\"\n",
      "batch  331  loss=402.9051  steps/s=104.73  prediction: \"w, weve been going for a few weeks or so\" => \"eotwww  eeeeee nnnggi    fff rwweeeerros\"\n",
      "batch  332  loss=316.3523  steps/s=105.36  prediction: \"ang out in tunisia every once in a while\" => \"vgt     gnnuutiiiiiisee eev e enn     ww\"\n",
      "batch  333  loss=436.7166  steps/s=104.86  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"erenereeeep--t-\n",
      "dddddd aaaatc ec bss  o \"\n",
      "batch  334  loss=315.2528  steps/s=101.86  prediction: \"change it up a bit from the ol .txt file\" => \"o thweee       ipt ttpttr   o  o lttftxl\"\n",
      "batch  335  loss=302.6733  steps/s=102.03  prediction: \"if you have enough courage to go for it.\" => \"nai y   hhhuavveheheouugggeea   oooorftt\"\n",
      "batch  336  loss=290.0201  steps/s=103.25  prediction: \"better generalizer than the classic MLP?\" => \"aatteeteeeeerriaziizihh  httt tllcccscMM\"\n",
      "batch  337  loss=309.0273  steps/s=103.15  prediction: \"cially long term stuff,  makes it harder\" => \"iefullllllyy  n   tttuus m ma      a err\"\n",
      "batch  340  loss=324.7101  steps/s=105.09  prediction: \"000000000000000000000001% of the new one\" => \" 00000000000000000000000000.%11y.     on\"\n",
      "batch  341  loss=377.8767  steps/s=104.97  prediction: \"tal clarity and less of a need for sleep\" => \"onsrttrlallaaaa  d  ssss   neeednd  oool\"\n",
      "batch  342  loss=294.1821  steps/s=105.31  prediction: \"how u get llms to make huge projects btw\" => \"is sh ww ullllltttoomm   kee  g oeejsstt\"\n",
      "batch  343  loss=381.2002  steps/s=104.10  prediction: \" pieces until you have solved the puzzle\" => \"doeepeeecciitulluu      ovvvvooeldde z z\"\n",
      "batch  344  loss=477.1502  steps/s=97.94  prediction: \"Incredibly based\n",
      "https://t.co/IOxblXKnJv\" => \" ennneeedrbbbbdledddttt:t:////:.IccxIXxn\"\n",
      "batch  345  loss=991.2484  steps/s=82.48  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"X/nIHUTLKKLEEFEEFRRR :pt::s//cccWZZZG9G9\"\n",
      "batch  346  loss=455.3026  steps/s=108.45  prediction: \"future wife, dayum\n",
      "\n",
      "happy for you brotha\" => \"ocAduuf uee e  yyyy\n",
      "\n",
      "\n",
      "aappppfyru uoorohh\"\n",
      "batch  347  loss=362.5124  steps/s=105.04  prediction: \"kind of just whatever I want to pivot to\" => \" ytrdss  ojujut tttwheev aII    t oottoo\"\n",
      "batch  348  loss=646.4698  steps/s=100.37  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"@oeeOPOP TTLL  SGE  TEhhttp///:BYYYV6DDK\"\n",
      "batch  349  loss=321.2900  steps/s=104.51  prediction: \"re much lower on time than your opponent\" => \"e ofuuuu   wewoo rommtmtht ttha  ooooonn\"\n",
      "batch  350  loss=286.2806  steps/s=100.41  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"inn   iticieymfeeeee     lleeeenegtgtii \"\n",
      "batch  351  loss=309.1444  steps/s=104.09  prediction: \" the time and not spread important info?\" => \"te elhietteaaa     noopddpppppsaatttiiio\"\n",
      "batch  352  loss=325.4586  steps/s=105.35  prediction: \"your life (which is what happened to me)\" => \"aariroffffi((iii i  whhhh a  aaaeettt  p\"\n",
      "batch  353  loss=271.4853  steps/s=103.51  prediction: \"egression to my past actions and results\" => \"  rersssssro     otttttaaatiannnns sss e\"\n",
      "batch  354  loss=384.3179  steps/s=105.55  prediction: \"allenge\n",
      "however: https://t.co/TzbAuUlGIG\" => \"ycya lolhheeheev::wvtttt/s/ro///zTToUGbU\"\n",
      "batch  355  loss=454.7794  steps/s=99.50  prediction: \"houlda stuck to planting apple trees smh\" => \"alors sssutut tttk llttnappaapgag atesss\"\n",
      "batch  356  loss=295.6943  steps/s=104.91  prediction: \"ot even remotely the same as a beginners\" => \"f s eoevevnntttrttlelh e  aaaaa   sseeee\"\n",
      "batch  357  loss=356.8208  steps/s=104.59  prediction: \" drains your energy by paying attentionâ€¦\" => \"ihtinirry y y  rrreeeyyyybeagaaattttttin\"\n",
      "batch  358  loss=341.0721  steps/s=103.22  prediction: \" then maybe do a bit of chess, or watchâ€¦\" => \"ouu hthn bbee aaa    ooo  ieiesssssstwth\"\n",
      "batch  359  loss=326.1327  steps/s=106.74  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \" oruuuui innga wwww\n",
      "a\n",
      "\n",
      "httttt    rffrrcc\"\n",
      "batch  361  loss=424.2029  steps/s=98.52  prediction: \"y childhood was nuketown 2025 and python\" => \":pybccfchhdddww     ootonwkk2505nnn  ddn\"\n",
      "batch  362  loss=342.0356  steps/s=104.12  prediction: \"'ll see models get good at outputting it\" => \"reh 'ee e  eeossss tggdgott ttttuuuttiii\"\n",
      "batch  363  loss=429.2437  steps/s=71.82  prediction: \"HSVSphere just barely hit max call depth\" => \"E' yeSHSheShs j ttt b  l haaaauaxxlll  ðŸ›‘\"\n",
      "batch  364  loss=369.5016  steps/s=106.52  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \".. .fo    d\n",
      "\n",
      "\n",
      "\n",
      "dlllkiido eeeet uasugssse\"\n",
      "batch  365  loss=295.7353  steps/s=98.30  prediction: \" busy so i havent been posting much my b\" => \"seee uu      oyaavbeeeneeetppiii  tumm m\"\n",
      "batch  367  loss=296.6227  steps/s=98.31  prediction: \"metimes you gotta take one for the cause\" => \"ubomimeseee  o ottttaaaa a  oo eeeh haec\"\n",
      "batch  368  loss=311.5496  steps/s=37.37  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"y s@me@yei ggtTB  aa   kkeee nnnnn    ue\"\n",
      "batch  369  loss=289.6057  steps/s=106.90  prediction: \"started begging me to let him pay for it\" => \"elltatddddgggggee        ttimiii h o o f\"\n",
      "batch  370  loss=299.8323  steps/s=105.15  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"ttecd    9o9m,mpkeesssees s   dllllddcct\"\n",
      "batch  371  loss=308.9044  steps/s=104.57  prediction: \"people skills of almost everyone ive met\" => \"aneeppp  lllllss   oooo seeeeveeernv eee\"\n",
      "batch  372  loss=345.7067  steps/s=102.88  prediction: \"ective, its significantly more efficient\" => \" a riipiitstssiiiiiinnnnncc yyrffffeeeec\"\n",
      "batch  373  loss=281.4377  steps/s=103.80  prediction: \" of twitter it usually means engineering\" => \"tf aaawttttiiii   uuuulll saseennnneeegg\"\n",
      "batch  374  loss=331.3910  steps/s=105.76  prediction: \"rong tho, my confidence is only like 70%\" => \"  owg gohhoo  ,nyncnfcceeii n    ylllk7%\"\n",
      "batch  375  loss=285.5877  steps/s=104.62  prediction: \"endeavors im going to do til ive done it\" => \".oennavveseee iiggg   ooo otti iii l nnn\"\n",
      "batch  376  loss=401.3296  steps/s=103.67  prediction: \" be cool to find some other players here\" => \"wos e wlo   o    nnn  eoeoeehrpprrrshhee\"\n",
      "batch  377  loss=324.6381  steps/s=103.61  prediction: \" software used that widely is so awesome\" => \"th vffotgww s   e ttttwdee lii     sseee\"\n",
      "batch  378  loss=271.8667  steps/s=102.39  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \" af coff on   eeeeter\n",
      "\n",
      "\n",
      "\n",
      "o\n",
      "oaannn    aaf\"\n",
      "batch  379  loss=513.7463  steps/s=11.14  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eplaffll   o  eeettpp\n",
      "\n",
      "o\n",
      "ooaaann     aff\"\n",
      "batch  381  loss=382.2593  steps/s=113.49  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"beelccccpaaaaroootttttt://///h..T1Tcc0gz\"\n",
      "batch  382  loss=297.6055  steps/s=105.33  prediction: \"al of life that pays some huge dividends\" => \"nh tffflll e  ttthaaaaoooo  eeegeiiidddd\"\n",
      "batch  383  loss=337.5887  steps/s=103.89  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"l nidiiiiivvulzzlle tttsttp:pp/cXcNNNYLY\"\n",
      "batch  384  loss=303.2405  steps/s=103.77  prediction: \"a decision making incongruency somewhere\" => \"lssc eeeeidinannnkgggogggoonnccuyyemeeee\"\n",
      "batch  386  loss=395.8567  steps/s=101.18  prediction: \"of work every monday and thursday brotha\" => \" 1oooor  kwweeeymmyyynaadda  nhauu sbbhh\"\n",
      "batch  387  loss=684.1762  steps/s=97.96  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \"6h SuuSueruuppprrr oooBBBgg LRO WWTTSPSU\"\n",
      "batch  388  loss=344.0189  steps/s=103.98  prediction: \"we need shape rotator models already smh\" => \"orfpeeew\n",
      "       aaatottooooodlllreda dsa\"\n",
      "batch  389  loss=305.8254  steps/s=100.98  prediction: \"o actually understand the program better\" => \"n wao actulutuuynrndddttt   errraaaageet\"\n",
      "batch  390  loss=273.2314  steps/s=105.08  prediction: \"he audiobook content is better than both\" => \"eug auuaoooooookkknnnt t  tettee   hbbhh\"\n",
      "batch  391  loss=502.4165  steps/s=60.47  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"th a __________1n11hh ssssskkcuhcseeeesg\"\n",
      "batch  392  loss=362.2849  steps/s=111.62  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \"g  snaaaatttttttth\n",
      "\n",
      "haheeegng   nn n nxe\"\n",
      "batch  393  loss=282.4120  steps/s=102.77  prediction: \" stream but i do my actual job and stuff\" => \"t ot teeabau     d myauauacucocob j   sf\"\n",
      "batch  394  loss=399.6890  steps/s=103.26  prediction: \"C $ they raisedâ€¦ https://t.co/8AMjPz3k5K\" => \"oh llVeheehyhaaesâ€¦â€¦â€¦ttss://ph///M8AcMzz5\"\n",
      "batch  395  loss=306.7278  steps/s=105.70  prediction: \"irl. So in irl it is probably not as bad\" => \"na ai  iiiSiillli    rrrroobbboooaaa    \"\n",
      "batch  396  loss=929.8537  steps/s=77.97  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"aS HHEEKEEKKFFF MRRtptssstt:.////oG99llE\"\n",
      "batch  397  loss=312.5540  steps/s=106.62  prediction: \"be allocate some time to do fun projects\" => \"uriyaalllleeeem e   mtt tto     ddfppprc\"\n",
      "batch  398  loss=297.2365  steps/s=104.36  prediction: \"mes there are 10x rewards for doing this\" => \"es  eseeeerrr      x01aarrrwrrdd oooo ii\"\n",
      "batch  399  loss=348.0370  steps/s=102.61  prediction: \" is actually happening behind the scenes\" => \"ft w aaaacs  lllppppnnnnihiii hhh   eeee\"\n",
      "batch  400  loss=544.9288  steps/s=97.46  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"onainie@  aajsjjjesoBeeLEL  GOOOOOOOOOOO\"\n",
      "batch  402  loss=502.9464  steps/s=97.76  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"py  errroooooo   aD\n",
      "\n",
      "\n",
      "\n",
      "ittoooootott  bbb\"\n",
      "batch  403  loss=298.5274  steps/s=104.02  prediction: \" not abt to read through all of its code\" => \"io  mooaab t t tttrrrrhhgarhlll     fffd\"\n",
      "batch  404  loss=329.5635  steps/s=102.75  prediction: \"ting should not be taking customer calls\" => \" ro in nnhhdooo o   tttkakggunneesem  cl\"\n",
      "batch  405  loss=345.4247  steps/s=11.30  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"e lcunnnih dooo l t eakknkgiunsee mm ccl\"\n",
      "batch  406  loss=283.5165  steps/s=129.70  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"uneo     aaaaittonnnno nru   eee\n",
      "\n",
      "\n",
      "\n",
      "baaa\"\n",
      "batch  407  loss=562.7171  steps/s=76.89  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" s uiAAAAgBn@  Pcch htttt//:///.coUUY/mU\"\n",
      "batch  408  loss=514.0549  steps/s=107.32  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"@e ttaa fff reee hfddhpsths/o.p.:2 2BQJJ\"\n",
      "batch  409  loss=338.9204  steps/s=103.82  prediction: \"at the beginning\n",
      "https://t.co/3p7b8v9xhe\" => \"c  tt   \n",
      "heeennnighhihtt:t/t://:/ptp3v3h\"\n",
      "batch  410  loss=328.7271  steps/s=104.23  prediction: \"r, it felt a little linkediny over there\" => \"e tiii    ee  tttltlllliiikennn e v veer\"\n",
      "batch  411  loss=738.7719  steps/s=10.59  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"e  ii   i t   tttlllllieeeknnnn e   veer\"\n",
      "batch  412  loss=330.0652  steps/s=107.31  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"bgfhyrciiiicgaallnggWanWhhhWappp   ssssâ€¦\"\n",
      "batch  413  loss=341.7620  steps/s=104.09  prediction: \"most rather just.. not have a device tbh\" => \"ea doaaaarrrttttt....    h   eevvvaveedt\"\n",
      "batch  414  loss=313.5044  steps/s=102.72  prediction: \"hinks he might pick up in future decades\" => \"eninhh   keiighgipiipp    uuuuuff ceddde\"\n",
      "batch  415  loss=257.5477  steps/s=102.62  prediction: \"g us to blow our fears out of proportion\" => \" tt sss  oowoowwll  frrrr rtf foooooppot\"\n",
      "batch  416  loss=319.7285  steps/s=98.31  prediction: \"ontend ai stuff is pretty cool. followed\" => \"nrffonnnn    ttuii f  i ttte oo ooololoc\"\n",
      "batch  420  loss=300.4615  steps/s=104.33  prediction: \"n while still being consistent each week\" => \"danraciiwiilllllbte  ngnnssstttteee  eee\"\n",
      "batch  421  loss=308.0755  steps/s=102.46  prediction: \"can be done in browser on frontend cheap\" => \"i\n",
      " \n",
      "\n",
      "n  nn  de  ebeboorrww   oonnnddddee\"\n",
      "batch  422  loss=314.0516  steps/s=104.59  prediction: \" fast eventually. i know this from chess\" => \"fuerreeeeettuulllll   n nkoiiiihfooormss\"\n",
      "batch  423  loss=457.0449  steps/s=100.09  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"nd r222099nataaalltttty/::/.////p1.89.mE\"\n",
      "batch  424  loss=345.7184  steps/s=102.56  prediction: \" of all time itd be sebby and his 9 alts\" => \"t0lfow       tttttidd ebbbe          99s\"\n",
      "batch  425  loss=314.6789  steps/s=101.17  prediction: \"am and it doesnt mess your sleep up much\" => \"m 9 9add d    t neesessss   u eeeuupppu \"\n",
      "batch  426  loss=301.8401  steps/s=103.75  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"thnpi      follllllaeeeeeccc    nnnn ttx\"\n",
      "batch  427  loss=296.6106  steps/s=96.81  prediction: \"ait to see what you cook up with giz inc\" => \"nt w ttt  weeeee  oooooouuuuu    hwgiiiz\"\n",
      "batch  428  loss=282.6931  steps/s=103.74  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"cle lkeee  ahhhttctttr ddrriaaag mmffooo\"\n",
      "batch  429  loss=289.0354  steps/s=101.02  prediction: \"honorary denis\n",
      "\n",
      "and got gelato in venice\" => \"is lnaoarrrndddiaan \n",
      "\n",
      "\n",
      " gggeett t taeien\"\n",
      "batch  430  loss=331.6664  steps/s=104.40  prediction: \" i found it really hard for some things.\" => \"ioa.i   nnddideeelllrarrrrrr  oooohhhtss\"\n",
      "batch  431  loss=261.1761  steps/s=103.71  prediction: \"d so i felt the need to post the way out\" => \"win      lltlteeeeen    ooootttthh     w\"\n",
      "batch  432  loss=335.9890  steps/s=105.21  prediction: \"ncredibly painful, so a great motivator.\" => \"dtoe r.biiliinnnlplu    a,aaaaeottttttrt\"\n",
      "batch  433  loss=313.9085  steps/s=104.19  prediction: \"e info produced by exploring new options\" => \" u e   i oooopddddeeepxpxpxx  nnnoowoooo\"\n",
      "batch  434  loss=610.6344  steps/s=100.68  prediction: \"7AHwatHv6Y was really really really good\" => \"7.A/tcAHvHvvYaaYaa   llllllyyrrrlllala  \"\n",
      "batch  435  loss=304.7110  steps/s=105.53  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"otgew iigiyylllllttttts\n",
      "st//poo/6/Ac.SG6\"\n",
      "batch  436  loss=384.4244  steps/s=105.69  prediction: \" srsly the golden age of building things\" => \"t wlsllll r  theeeeeed g    ddiiiiugnnnn\"\n",
      "batch  437  loss=498.9435  steps/s=99.16  prediction: \" giz tarantinos alt?????? this shit fire\" => \"teizzz gaaaannnnnst????????????thttt  ii\"\n",
      "batch  438  loss=370.2656  steps/s=97.23  prediction: \"farming simulator but with a circle tool\" => \"ecktaiiigimms aluuuuutttit h  iicccccrea\"\n",
      "batch  439  loss=267.9695  steps/s=104.32  prediction: \"egression to my past actions and results\" => \" oorrsssssgt m    tyypataaaaannn ddsssss\"\n",
      "batch  440  loss=315.7853  steps/s=106.17  prediction: \"eel free to run ideas by me whenever btw\" => \"  tnefeeee   rru  ou dds    ymeeeeeebvww\"\n",
      "batch  441  loss=310.2266  steps/s=103.12  prediction: \"r something as small as starting on boot\" => \"ewonm eeoeohhssssm  llaaa  stttttnnn   b\"\n",
      "batch  442  loss=321.7662  steps/s=104.77  prediction: \"n clarity from practicing visualizationâ€¦\" => \" ten  ttttrrrryp  cpccciiiivggvalaaazzin\"\n",
      "batch  443  loss=241.1477  steps/s=101.76  prediction: \"ure the first man on mars thats so crazy\" => \"neeeeu      ttts  nnnmmaa   hhsssss o  o\"\n",
      "batch  444  loss=665.5441  steps/s=103.26  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \"etep   oooodff d   ooollsooooooooooss   \"\n",
      "batch  445  loss=347.5143  steps/s=104.54  prediction: \"xample\n",
      "Do this and then train them on it\" => \" seimeeeloeDDDihh    hnnnttataa    e   i\"\n",
      "batch  446  loss=270.6218  steps/s=103.84  prediction: \"tler where would you say you are on this\" => \" eeeetterrwwwe ed u ooyyyyuoaooa       t\"\n",
      "batch  447  loss=466.5841  steps/s=104.24  prediction: \"orking feels a bit more stale without it\" => \" e,ncinnnn      lbbitteettsaaala  itttti\"\n",
      "batch  448  loss=269.1417  steps/s=103.16  prediction: \"he audiobook content is better than both\" => \"ot atuuuiooooookinnnnni   ttteetee b bhh\"\n",
      "batch  449  loss=402.9688  steps/s=100.34  prediction: \"igABAP has selo made the circle tool yet\" => \"needAPAPAAAs sss   aeeeeee cccc  rtloooo\"\n",
      "batch  450  loss=322.8189  steps/s=102.24  prediction: \"ught it was a cool idea so i speedran it\" => \"d tguhgt    aaaaaooooiiios  sssedeedpp  \"\n",
      "batch  451  loss=364.8087  steps/s=102.48  prediction: \" windows update almost bricked my laptop\" => \"i)  2wwwowwwsuuuaaeaamsmb  rcckk    yppp\"\n",
      "batch  452  loss=431.6828  steps/s=102.50  prediction: \"/t.co/KAmykVYFyw https://t.co/Fg3PbzaDJZ\" => \"v.httt..:cyKVVyyYAythttp//::tt/F: cb.b J\"\n",
      "batch  453  loss=326.9074  steps/s=104.41  prediction: \"s principle imo\n",
      "\n",
      "https://t.co/VzXUJ8r5oL\" => \" dnw iiiipnpcpepemmhhtm::tt.:.c//VVVVo5U\"\n",
      "batch  454  loss=330.2833  steps/s=104.23  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"ti  iggiiii#i\n",
      "h#heeeeksaaSSS###aannnneer\"\n",
      "batch  455  loss=407.4565  steps/s=101.12  prediction: \" w as in why tf would you use white mode\" => \"@irep    wwwwn  y fffoyyuuuuo   wwt eted\"\n",
      "batch  456  loss=367.5284  steps/s=102.46  prediction: \"bly helps that they have a faster ai now\" => \"eerblyypesh hhttthtehheeavavavvssf a  so\"\n",
      "batch  457  loss=437.6054  steps/s=98.96  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \"gt ge   b   ddddadottptpt::o////pocox6N5\"\n",
      "batch  458  loss=441.0845  steps/s=94.42  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \"tnnr@jjC AAAk A  nnnkknT   o oopno tiist\"\n",
      "batch  459  loss=445.2769  steps/s=52.91  prediction: \": @angkul07 Super awesome\n",
      "Haha over 9000\" => \" @ina@knkcc SS.eeeaaaaooom aHaaaatvrr 00\"\n",
      "batch  460  loss=405.2003  steps/s=132.89  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \": RTgsalsgx:ggoku  oddd  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ooot hchh\"\n",
      "batch  461  loss=291.6801  steps/s=61.17  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"@justeteheooohrr hhahhh    ooott   v uuu\"\n",
      "batch  462  loss=343.8250  steps/s=110.65  prediction: \" been the difference, in your experience\" => \"@aa ebeee tet ffffnneie,n  ,  r  exxreee\"\n",
      "batch  463  loss=284.9912  steps/s=103.24  prediction: \"your time for fruitful endeavors instead\" => \"ouy uiiii  m ffffrffutuu eeeenvavnnnsssa\"\n",
      "batch  465  loss=318.1072  steps/s=96.06  prediction: \"7 make money so you can make video games\" => \"- ciieemmmee oooyyoy  n  aacmmmdddvvdmmg\"\n",
      "batch  466  loss=443.0653  steps/s=94.46  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"eplj:looonnngggggh htttttnt/:/h///A3oAd1\"\n",
      "batch  467  loss=465.6427  steps/s=102.34  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"/.pt\n",
      "/.t.dq99Zqo8EEphEph/t//c//.:PPIczPI\"\n",
      "batch  468  loss=299.1360  steps/s=101.60  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yd aea\n",
      "\n",
      "cmcmcuuuu     oooowrywuuurrttrtr\"\n",
      "batch  469  loss=422.5075  steps/s=98.74  prediction: \"yeah, tunisia... carthage would be nice\"\" => \": ..eaa ua,,aia. ....aaaagggg u     eeee\"\n",
      "batch  470  loss=254.8244  steps/s=102.58  prediction: \"system is non being at the limit of time\" => \"fauctysss     oeennnnib     t liiiim   m\"\n",
      "batch  471  loss=400.7386  steps/s=97.21  prediction: \"pin it locked up https://t.co/ULHT2ys50k\" => \"ls:   i   l kkcc pptut:t:/p//c//LcTHTL5T\"\n",
      "batch  472  loss=289.3622  steps/s=95.71  prediction: \"king spheres are infinitely many circles\" => \"enctocggpessssrre    iiiiiin nnyynm  ccc\"\n",
      "batch  473  loss=357.7744  steps/s=103.77  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"\n",
      "inrrnnnhnhhsstss\n",
      "tt\n",
      "tppt:\n",
      "/:/o/ZNJZ.uVK\"\n",
      "batch  474  loss=302.9437  steps/s=59.69  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"tfn @etteeeooorrhhhihh/h   ooooJlVju  uðŸ›‘\"\n",
      "batch  475  loss=433.9108  steps/s=109.02  prediction: \"s/hacks??????? follow me on linkedin btw\" => \"?tric/kk?a??????????slloooo    innnnniin\"\n",
      "batch  476  loss=293.4583  steps/s=105.58  prediction: \"ounts for new lengths of weeks/months ig\" => \"uk ommu  f f   enennlts ww  weeeoommsshh\"\n",
      "batch  477  loss=348.0427  steps/s=103.81  prediction: \" have to reprompt it like 1/3rd the time\" => \"a ddeeee veiooppptptttiii    1k//eehe3ee\"\n",
      "batch  478  loss=300.4207  steps/s=104.01  prediction: \" function w gpt3.5 instead of uppercaseâ€¦\" => \"tiieietnnn      wg33i555ttts   ppppeeeee\"\n",
      "batch  479  loss=316.2912  steps/s=103.84  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \"rn nieoo  iii  cc ttttthts////cAA.ODffff\"\n",
      "batch  480  loss=305.0696  steps/s=102.96  prediction: \" and realized idk what it actually means\" => \"hfu,dd , aaaeiiiddd     ttttttalclluuuuy\"\n",
      "batch  481  loss=351.6516  steps/s=103.06  prediction: \" windows update almost bricked my laptop\" => \"iima iiwwoddaauaaeeomttttt brerb  my llp\"\n",
      "batch  482  loss=362.6282  steps/s=105.19  prediction: \"ed, its worth at least giving a shot tho\" => \" asee,d,, sttttt  h llaasiivigggga    th\"\n",
      "batch  483  loss=239.2834  steps/s=21.38  prediction: \"eply: @sunsettler you are the dan herder\" => \" lae d ssssttttr  lll a ivvivannn   thho\"\n",
      "batch  484  loss=318.2758  steps/s=108.77  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" thogwi aaaaannsssttttsp/:pp////.lJjjjjz\"\n",
      "batch  485  loss=348.9444  steps/s=104.03  prediction: \"ys a bad thing just good to keep in mind\" => \" ysssa     bdtt  gtgjguu t ooo  oei iiid\"\n",
      "batch  486  loss=352.3923  steps/s=95.27  prediction: \"king stuff part of twitter is so fun wtf\" => \"es mm_nsnffu afffftfottttwriii  sss s st\"\n",
      "batch  487  loss=273.1712  steps/s=97.67  prediction: \"hnote uuuh i have a license for thse sir\" => \"oostaeeeuuhhhhh   eaav eeeessff   rsss  \"\n",
      "batch  488  loss=295.8302  steps/s=104.88  prediction: \"mance feedback you hear abt friendly ppl\" => \"ortrfeeeeeeaccccc     yaaaaabarrrreyeypp\"\n",
      "batch  489  loss=276.4314  steps/s=38.39  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"\n",
      "Im e sccdnmn yyky okhaaabbbrrikdddd pll\"\n",
      "batch  490  loss=288.7342  steps/s=139.20  prediction: \"f you can read graphs youre already ngmi\" => \"otcfw oyy  aaaa  darr p  u uy rrrreyrdy \"\n",
      "batch  491  loss=304.5937  steps/s=103.70  prediction: \" can instantly runit w the runit command\" => \"io c    nnanaatltytiii      urunnnnncmmn\"\n",
      "batch  492  loss=283.6314  steps/s=102.79  prediction: \"ny depressions ripple to other countries\" => \" raeyyyreesssssiiipppi  oo ot tettetrrrc\"\n",
      "batch  493  loss=380.1644  steps/s=99.36  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \"osuldllluuu yeeeeesstppp://////.S.jjSxSx\"\n",
      "batch  494  loss=362.1624  steps/s=101.66  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \" sfpsattttoohhhhaoo ottnneereee  y fulii\"\n",
      "batch  495  loss=274.2460  steps/s=103.93  prediction: \"entation, the cooler everything will get\" => \"s yetoinn,ttt, ooooc eeeerrrehyhhgllgilg\"\n",
      "batch  496  loss=507.0112  steps/s=104.09  prediction: \"dnt acct for maintenance/electricity tho\" => \" t adccccttt    antnnnnaeaeee/ccciiitttt\"\n",
      "batch  497  loss=309.4143  steps/s=105.78  prediction: \"er important first step towards progress\" => \"rnspodpprrmrr  iftttsss  t   awrprrrrros\"\n",
      "batch  498  loss=303.9350  steps/s=104.04  prediction: \"my efficiency. But overall cause its fun\" => \"akto ffyfyccccciye.... va  lla a eesssus\"\n",
      "batch  499  loss=378.3155  steps/s=76.42  prediction: \"am_Kantor actually something came up rip\" => \"t m ua_aanaaaaaallllt  eoohhccngg  ue  r\"\n",
      "batch  500  loss=343.2591  steps/s=105.25  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n ripspis   a...o aaa wt          gonnnn\"\n",
      "batch  503  loss=284.3852  steps/s=103.69  prediction: \"im how fun the funny computer things are\" => \"s  hwwww     uuuunnnffymfocoe tttthiirre\"\n",
      "batch  504  loss=477.6117  steps/s=86.64  prediction: \"ettler @gizmobly https://t.co/ZVEh9zCAgb\" => \"p y:snettirerllmyylttttp:////ccVoEZVzzCA\"\n",
      "batch  505  loss=442.3764  steps/s=100.61  prediction: \"th @wordgrammer i love large lean models\" => \" ah @l  raarmrrgr mee  lllrele eaa  e el\"\n",
      "batch  506  loss=291.7589  steps/s=105.30  prediction: \"of those bc there are uncountably many c\" => \"uutam oooohchhheeeer   r cnuunnabbaaat c\"\n",
      "batch  507  loss=353.6393  steps/s=97.31  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \" el:nloooknokiigghhhttttp:p/p///.yyy2xxf\"\n",
      "batch  508  loss=363.3748  steps/s=102.07  prediction: \"ding up the drive thru for 1000 episodes\" => \" t ild      dp edeeehhhrrrrf  0 000 oooe\"\n",
      "batch  509  loss=304.0922  steps/s=99.12  prediction: \"mes? maybe you could make a mod you want\" => \"ens am??yeyyye  uuoo uu  aaaa ddddo oooo\"\n",
      "batch  510  loss=344.2229  steps/s=46.22  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \"  namssje aaoooooOO   kook  od   y iwhtðŸ›‘\"\n",
      "batch  511  loss=316.3741  steps/s=112.30  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"si i ifffffsottuo   tss:ttttp///UUySXSX8\"\n",
      "batch  512  loss=300.8759  steps/s=104.39  prediction: \" arent tired when you dont have caffeine\" => \"ill  eetttrrrrdnnn y     oohhhua aaafffe\"\n",
      "batch  513  loss=489.4441  steps/s=37.63  prediction: \"ly: @IsntTrivial https://t.co/5iBit5syTv\" => \"e  ae ttnrrTiihh hhh dooo haav  5cfeeeeðŸ›‘\"\n",
      "batch  514  loss=286.6329  steps/s=107.82  prediction: \"t immensely and give you new information\" => \"hapttmmmeeeeennn     yy    eeeinnnffoooo\"\n",
      "batch  515  loss=846.5512  steps/s=100.30  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"BAlloGBLAGO OOOOOOOOOTSS//://///..VkVook\"\n",
      "batch  516  loss=368.6447  steps/s=104.50  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "soa\n",
      "ooohdd kda iyyaaa savc  rwrr oktwww\"\n",
      "batch  517  loss=494.1146  steps/s=90.72  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \"  any@tte@e@@cenTTttttpttt:p/o//9oooo/33\"\n",
      "batch  518  loss=316.2450  steps/s=40.16  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @ @eacciiMeeiitBMss /m.m/ccc9osQQ3QvðŸ›‘\"\n",
      "batch  519  loss=295.8870  steps/s=106.99  prediction: \" could approximate non linear functionsâ€¦\" => \"tyttt aaappppoooxaimmmn nnnnne   fafiicn\"\n",
      "batch  520  loss=292.8587  steps/s=87.51  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"t jslokooiiir    rnootttt  rrrrr     ssðŸ›‘\"\n",
      "batch  521  loss=406.3007  steps/s=101.24  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" alme eeeiccckaaa a   mmpt//c/c//R:cBmUU\"\n",
      "batch  523  loss=238.5544  steps/s=103.18  prediction: \" into local files when you need to build\" => \"tnet iioooollll  eeeee ww  nnn eedouuuud\"\n",
      "batch  524  loss=323.6942  steps/s=98.90  prediction: \"ing\n",
      "\"ai, make me a pacman game in sokol\"\" => \"tntoi mi\"aaim,m ,    aaaaaamm     nnnkno\"\n",
      "batch  525  loss=320.7572  steps/s=103.99  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"dte a\n",
      "aaaann    ieeixieee ca\"antcnntoann\"\n",
      "batch  526  loss=273.8294  steps/s=85.54  prediction: \"amebedan since ports dont allow weapons.\" => \"db a@eeeamiincccoops oototssl lllwww ooo\"\n",
      "batch  527  loss=814.0986  steps/s=90.32  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"eeaE TLISE E  RF  RRtttsp:pho////zWz9ii.\"\n",
      "batch  528  loss=420.9996  steps/s=102.34  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \" t L n       beeerthttthtp//////FFcFF6WW\"\n",
      "batch  529  loss=266.3504  steps/s=104.67  prediction: \"int as fast as possible on loop, idk tho\" => \"ng paa  aa assssssssooobbblllooopii,i dd\"\n",
      "batch  530  loss=452.4038  steps/s=103.64  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"toshh    uuu u athhiiti24422   thttts:tp\"\n",
      "batch  531  loss=384.7660  steps/s=101.96  prediction: \"z and ctrl+y now https://t.co/1AII6b45hG\" => \" rt+la zr+rr+ynnw wttttptpp/c//1IIIIc1b6\"\n",
      "batch  532  loss=409.8005  steps/s=87.90  prediction: \"igABAP np bro, you should write more man\" => \"cdwrBiAABnnP  bo,y  yhhuu l   wdw rrmmmm\"\n",
      "batch  533  loss=270.1100  steps/s=105.45  prediction: \"ly using the word prior kinda wrong here\" => \"yaeliyysu   g     rrrrroriiididinnnnnnrr\"\n",
      "batch  535  loss=832.0636  steps/s=11.09  prediction: \"reply: @helscom OF NOTHING\n",
      "IN PARTICULAR\" => \"eplbryss l  e     rrrrroiiki ik nn nnrrr\"\n",
      "batch  536  loss=299.4081  steps/s=163.91  prediction: \"er cool shit bro gl w your phd\n",
      "\n",
      "followed\" => \"piyaoooc  h   t       wwyuuruupp\n",
      "\n",
      "h\n",
      "o\n",
      "dd\"\n",
      "batch  539  loss=364.5693  steps/s=104.49  prediction: \"ame by making his brain care abt it more\" => \"sthsmf aa  i  iiii  bbnnnrraaaaab   itmt\"\n",
      "batch  540  loss=290.8075  steps/s=103.92  prediction: \" bc random twitter guy said itd be funny\" => \"iemeb cccdrrttttttiir    y y idid     nn\"\n",
      "batch  541  loss=308.6596  steps/s=105.23  prediction: \"erscores the importance of curating andâ€¦\" => \"nt. sdsrrrreeeheoioottt  o ccfrarrnannnn\"\n",
      "batch  542  loss=480.5450  steps/s=38.72  prediction: \"ly: @justalexoki https://t.co/bQLKyhfmhI\" => \"iisdurreuteeioio tttppco:fccrauuuLLi hâ€¦â€¦\"\n",
      "batch  543  loss=320.7532  steps/s=107.44  prediction: \"t info, hence why I expanded past papers\" => \"hatttnffh  eee  h    yywxppepaaaadappp  \"\n",
      "batch  544  loss=307.3557  steps/s=106.04  prediction: \"ich is a great way to find opportunities\" => \"nieyih      gggwaaaay   et dooppptttpiip\"\n",
      "batch  545  loss=531.3223  steps/s=98.34  prediction: \"w many GFLOPS? Are these legal in CA????\" => \"hlulow G   FOOPOPr?r?eeeeee ll ll l  n??\"\n",
      "batch  546  loss=303.9524  steps/s=103.91  prediction: \"n for games (more encouraging?) but canâ€¦\" => \" whPo o  a smmm(((reeeeegugggngnuu?  )b)\"\n",
      "batch  547  loss=409.1539  steps/s=105.64  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" tkel nnenneeegggâ€¦tttâ€¦thp/s////BB.40Bmyu\"\n",
      "batch  548  loss=294.9115  steps/s=105.51  prediction: \"d this on there\n",
      "\n",
      "guard your signals boys\" => \"entn    hohthhtteggeerrraruuy   isss sls\"\n",
      "batch  549  loss=539.8551  steps/s=30.99  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly:dd oootttteeegeerruy\n",
      "ur   oinan lbolb\"\n",
      "batch  550  loss=317.0089  steps/s=108.83  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tdni:ijjvnvelwl\n",
      "h wwa yn  rrrNee TN naaJ\"\n",
      "batch  551  loss=532.3646  steps/s=22.40  prediction: \"reply: @calbach_ https://t.co/Gyx4pLqxKX\" => \"eply:iinvvnelyl h wpn  /  rr NNe   Ta\"aa\"\n",
      "batch  552  loss=596.8094  steps/s=112.63  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \" eeG  oooooofddf   lloiooooooooooooo s E\"\n",
      "batch  553  loss=433.0835  steps/s=10.96  prediction: \"reply: @5handilya See you thurs brotha ðŸ«¡\" => \"ects  ooooodod f lllooos ooooooooos   EE\"\n",
      "batch  554  loss=330.1311  steps/s=113.75  prediction: \"ey once, will play otb w friends usually\" => \" iWnnoeyeeec,wllllp  y  wbb iiffftuususs\"\n",
      "batch  555  loss=333.6967  steps/s=104.49  prediction: \" to me except this feels 100x better fug\" => \"shm  m e exeeppttt       ls0000s1eee ftf\"\n",
      "batch  556  loss=514.1282  steps/s=103.97  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"ly: aooeedCeTTTTTATDphpE///t./t..h.EuI22\"\n",
      "batch  557  loss=290.1839  steps/s=105.52  prediction: \" to put in effort to unwire it (nbd tho)\" => \"mow  ttt    ueeefffotoonrrrrw      ttttt\"\n",
      "batch  558  loss=273.5191  steps/s=105.33  prediction: \" sets? that sounds right but im not sure\" => \"crcosssstttts   sssssdrggguuui       nnn\"\n",
      "batch  559  loss=301.8526  steps/s=106.47  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tner aaaa     rrrrrcccttt(eeeiiii\n",
      "d\n",
      "hhh\n",
      "\"\n",
      "batch  560  loss=362.6723  steps/s=104.22  prediction: \"m repeatedly\n",
      "\n",
      "What have you learned btw?\" => \"egm heeeeeeamalahaWhhaa vvv     uoneedeb\"\n",
      "batch  561  loss=333.5201  steps/s=103.14  prediction: \"er/common, insurance will drive adoption\" => \"ta b//ccmmnnnnnonncca  iiwillievvdddeeaa\"\n",
      "batch  562  loss=333.4592  steps/s=99.37  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"@a n  aaaaaaemmdnnnnd   ll v  tttteeeeel\"\n",
      "batch  564  loss=276.1677  steps/s=102.76  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \"fbahlii llvlasssaannniiiii ttesusus\n",
      "lll\n",
      "\"\n",
      "batch  565  loss=264.4875  steps/s=102.21  prediction: \"ntext into a computation to make it pure\" => \"g t attnxtt   o  oaoattttoommmmo     uue\"\n",
      "batch  566  loss=319.4536  steps/s=102.40  prediction: \"ng to caffeine+building/studying for fun\" => \"g+gi+mo affffa i+i+ii+innuddddtnggyyy   \"\n",
      "batch  567  loss=474.3946  steps/s=103.21  prediction: \"is not true loss https://t.co/VvtOa0Aau2\" => \"n  so o intttullusttstt:://:/hotttVv0.Ov\"\n",
      "batch  568  loss=332.0287  steps/s=71.62  prediction: \"EsotericCofe i think i could add that in\" => \" ssnlitrueCeeee  hhiii ii  o  ddddddda t\"\n",
      "batch  569  loss=258.0831  steps/s=109.22  prediction: \"rner u can actually set them to 2x speed\" => \"ea rnr  c naaaacualllctttttt       ssxse\"\n",
      "batch  570  loss=309.4696  steps/s=102.16  prediction: \"f many useful things i can build for ppl\" => \" rht youuuuuufefnhhnsiii     nclabbl  pp\"\n",
      "batch  571  loss=358.7840  steps/s=104.57  prediction: \" group or build 100x stuff and start one\" => \"aa rrggr oouuoo b dd 001sfffffddsattt   \"\n",
      "batch  572  loss=303.8839  steps/s=101.50  prediction: \"e an llm code its actually just this guy\" => \" y  aav llmlooe   ccccttttsjsjuus       \"\n",
      "batch  573  loss=336.8489  steps/s=104.27  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"teeerrreeoaao\n",
      "ooo         reracceek3kdll\"\n",
      "batch  574  loss=290.4624  steps/s=98.98  prediction: \" off with a basic template and modify it\" => \"@taorffff  aaaa aibit tetteaaaeem dd iii\"\n",
      "batch  575  loss=330.4853  steps/s=104.65  prediction: \" possible, at least quote and add a take\" => \"trnosasill,aaa ,aaaeetttqte qnndadadddaa\"\n",
      "batch  576  loss=301.3725  steps/s=98.17  prediction: \"atched this 8 times\n",
      "actually cannot stop\" => \"lthtttehhhhi 8 ii8im8ttt\n",
      "allllcaaannttoo\"\n",
      "batch  577  loss=606.9892  steps/s=102.85  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"co lnnnnnliebmb  + G htttt:.//cpcccOiXHz\"\n",
      "batch  578  loss=336.9945  steps/s=103.95  prediction: \"and notice way more over time\n",
      "I suspectâ€¦\" => \"t y nndd   caawa yoooerrermvmv mm \n",
      "ssss\n",
      "\"\n",
      "batch  579  loss=356.9983  steps/s=101.11  prediction: \"reat book, glad youre enjoying it so far\" => \"ea s gtaboooog,    yuueeeeoeyeiiiin    r\"\n",
      "batch  580  loss=274.4229  steps/s=98.57  prediction: \"tony no but id be down rn for some games\" => \"t knnooy oo   bbb ddd     wwrrrooo  eeem\"\n",
      "batch  581  loss=298.5580  steps/s=102.76  prediction: \"assume that had a large effect back then\" => \"ss.I smmseathhhaa       eeeeffeffccctcct\"\n",
      "batch  582  loss=288.9425  steps/s=102.43  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \"o  pttre ellliiinn\n",
      "\n",
      "\n",
      "Feeeoooooo\n",
      "gd Y rur\"\n",
      "batch  583  loss=284.1114  steps/s=104.06  prediction: \"d this on there\n",
      "\n",
      "guard your signals boys\" => \"efnna   oohhhttstne\n",
      "eu\n",
      "ruuuyy ss ss  o b\"\n",
      "batch  585  loss=302.6777  steps/s=103.25  prediction: \"better generalizer than the classic MLP?\" => \" eLL teeeerrrraazzzizzh hh      ccccssML\"\n",
      "batch  586  loss=377.5357  steps/s=104.04  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"boi  ee  muumuuanann    pcpllrririnonnny\"\n",
      "batch  587  loss=552.9587  steps/s=63.94  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"IodeIuuwwaBAP    i tulliieeuuu of!!!!!!!\"\n",
      "batch  588  loss=313.6922  steps/s=108.74  prediction: \"ay simpler, but also much more effective\" => \" , os lspip,mubbb a  uum mmmcrrooefffeee\"\n",
      "batch  590  loss=349.8979  steps/s=102.37  prediction: \"rusted with this https://t.co/78lPrhtd11\" => \"obdsteed  e thhhhhhtttss/t/////. pPPlr11\"\n",
      "batch  591  loss=277.2472  steps/s=103.22  prediction: \" talking drains your energy for building\" => \"bom\n",
      "adl   kiinnii yryy eeeyggorrf   uuii\"\n",
      "batch  592  loss=331.9760  steps/s=97.44  prediction: \"! wanted to do something a bit different\" => \"!i Anna!wttddddooo     sg     iiii ifeed\"\n",
      "batch  593  loss=279.8575  steps/s=102.72  prediction: \"in but u see it everywhere after a while\" => \"se to   uuusss  eeevevevehrrrrrrrra  aaa\"\n",
      "batch  594  loss=354.1570  steps/s=103.13  prediction: \"times and pick up new details every timâ€¦\" => \"hka t n0nniid   pp     eeeaasaaellltttii\"\n",
      "batch  596  loss=568.9518  steps/s=38.55  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"ho   0aaapgpk lp u eðŸ˜sws:al..cse9yiyvmAE\"\n",
      "batch  597  loss=341.9139  steps/s=119.66  prediction: \"od simclusters chosen principle engineer\" => \"u  o  smssscsrctcceeehrrnnnniippieiieeee\"\n",
      "batch  598  loss=365.1718  steps/s=105.14  prediction: \"insanely OP\n",
      "One idea is to build usefulâ€¦\" => \"lssnneyyyylllOPPPeeeiiii     ttbbduuuuul\"\n",
      "batch  599  loss=340.0376  steps/s=106.53  prediction: \"ney OR something extremely useful to you\" => \"d e ey Rmoooeeesgeggtteeeemlyy uuuu  y y\"\n",
      "batch  600  loss=305.8831  steps/s=105.64  prediction: \"mething to run from (getting called out)\" => \"echb\n",
      "mhhttto  n    frmmg(tttttiieee c  l\"\n",
      "batch  602  loss=336.3875  steps/s=100.79  prediction: \"t just means youre on par with a supergm\" => \"orss jjtmmm  ssuueoononn  rrrpaa  pupuup\"\n",
      "batch  603  loss=361.7780  steps/s=96.85  prediction: \"ncredibly mesmerizing to watch. dang bro\" => \"gsBeniiirc  eeemmmriizz nwwtt  . .aag..o\"\n",
      "batch  604  loss=372.1951  steps/s=60.20  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"@tcna @Myye mrrrrzagf.IIt aaaddddngn ggðŸ›‘\"\n",
      "batch  605  loss=327.6032  steps/s=105.59  prediction: \"freedom fighters. ppl who wanted freedom\" => \" egr eefff   rhrrrppppp h wwwwt a eeeeed\"\n",
      "batch  606  loss=289.4301  steps/s=106.50  prediction: \"hich might mean making changes, so, yes?\" => \"ang,hhihhhmmmmmm aaannnkicgggc s,,,,ssss\"\n",
      "batch  607  loss=338.1769  steps/s=102.39  prediction: \"owing that your food supply doesnt scale\" => \"uswnnkgtttttt y ooooo uuuus dppddsssslle\"\n",
      "batch  609  loss=320.9760  steps/s=103.33  prediction: \"ool\n",
      "\n",
      "Maybe youll be the dude to crack it\" => \" cmoo, \n",
      "\n",
      "\n",
      "yyyy\n",
      "llbb    eeeeeedddt  t cc \"\n",
      "batch  610  loss=458.0291  steps/s=104.77  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"imouueeeeurrryoo   g  aaaassssns   aaubb\"\n",
      "batch  611  loss=322.8305  steps/s=104.83  prediction: \"s how to do this w reasonable efficiency\" => \",ion o        ttwwh hhsssnnabeeeeffiiicc\"\n",
      "batch  612  loss=669.1370  steps/s=98.08  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"aen_npSLOOOOOOSS!!!duudd ikn  naaaeesaay\"\n",
      "batch  613  loss=326.7017  steps/s=103.48  prediction: \"ttin you do all that stuff, drop out etc\" => \"euhetott         ll ltttauuuafs, f  oo  \"\n",
      "batch  614  loss=432.6633  steps/s=104.56  prediction: \"ebsite https://t.co/fKvh5jFnKh somewhere\" => \"nss ieeeethttt/:/p//chcvc/KKK55hjhooFh e\"\n",
      "batch  615  loss=338.1284  steps/s=104.48  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"bl . i( ((h\"\"a\"\"\"tttt  ooo  ,)k, rkkbu â€¦\"\n",
      "batch  616  loss=351.1183  steps/s=104.89  prediction: \"king progress. Now i see it eeeverywhere\" => \"aabmkkgggoorrrsss       eieeeeeeeet vwvr\"\n",
      "batch  617  loss=284.0918  steps/s=104.74  prediction: \" selected\n",
      "\n",
      "Or better yet skip selection?\" => \"tist ltcceeeeeOe\n",
      "ttrrree      sssseeeeii\"\n",
      "batch  619  loss=278.0808  steps/s=104.31  prediction: \" of how i debug and catch inefficiencies\" => \"i aa y    ooodbbbdgd aaccaahnnfffiiiieee\"\n",
      "batch  620  loss=425.2347  steps/s=103.65  prediction: \"a fckton of time https://t.co/HOKGcS3zKn\" => \"vso a  k fffo o   etttpp::/p.....HcccKcc\"\n",
      "batch  621  loss=303.0757  steps/s=104.59  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"y roheeehhrrragggtttttteehhhhtt\n",
      "\n",
      "ss\n",
      "suuu\"\n",
      "batch  622  loss=410.5357  steps/s=22.51  prediction: \"eply: @Nominus9 a unicorn would fix tpot\" => \"y re ehh rrra   a t tctehhttty\n",
      "y\n",
      "i\n",
      "uuuod\"\n",
      "batch  623  loss=355.5704  steps/s=162.71  prediction: \"eMTB How long until dingbots can do this\" => \"pln: @TBw w   oonnlllniidnno sonnn     t\"\n",
      "batch  624  loss=236.1212  steps/s=98.60  prediction: \"stening to the sidetweets podcast at 1am\" => \"uestnnniiittt    eeeeeeewttssdotcaaaaa1a\"\n",
      "batch  625  loss=366.8256  steps/s=47.65  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \": @c:rcttyt00  hhhh wdtoopoooraaddidd  ðŸ›‘\"\n",
      "batch  626  loss=317.1876  steps/s=107.26  prediction: \"for typos and a list of other dumb stuff\" => \"t+c hf o yss  aaaa  t   ttoooohrrd  uuuf\"\n",
      "batch  627  loss=269.0029  steps/s=86.15  prediction: \"t only people named dan will have access\" => \"ocntynnppppolleeeend ddnaa  lwala  veeea\"\n",
      "batch  628  loss=329.3188  steps/s=82.73  prediction: \"xluciusv cool cool goal\n",
      "progress so far?\" => \"tc:lluuuuuoooooooclloo lggggrrrrsssscaaa\"\n",
      "batch  629  loss=385.8840  steps/s=105.25  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"m.  xffiifiillosgoso\n",
      "\n",
      "\n",
      "sph//:ttttNt11hh1\"\n",
      "batch  630  loss=340.3071  steps/s=103.81  prediction: \" drains your energy by paying attentionâ€¦\" => \"thynnr yyyrrrrourreeyyyy  bbnaaaatttttnt\"\n",
      "batch  631  loss=268.1330  steps/s=101.12  prediction: \"see more details as you unblur an image.\" => \":ulfe eeeeemmdddaasss   uuuuuubnnn aaaga\"\n",
      "batch  634  loss=318.2944  steps/s=100.50  prediction: \"y noticed the last time i was there, lol\" => \"Mfiinltl e        stttt  i  i w seeeeerl\"\n",
      "batch  635  loss=302.8750  steps/s=105.16  prediction: \"nt properties. huts dont have penthouses\" => \"  frergppppttee..h   s   hth  a nnveheee\"\n",
      "batch  636  loss=282.2101  steps/s=45.27  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \"  mer @rtte0._ hhs  ouuuuovv reenmindisðŸ›‘\"\n",
      "batch  637  loss=277.4452  steps/s=115.35  prediction: \"nt true they wouldnt put it in the title\" => \"t  ttta  eeee uuuwyydddu ttt     niitttt\"\n",
      "batch  638  loss=331.5642  steps/s=99.60  prediction: \"reat book, glad youre enjoying it so far\" => \"eplhracrtoobo,,k   dreeeeyyynjnin       \"\n",
      "batch  639  loss=333.9308  steps/s=105.29  prediction: \", write one sentence after another, andâ€¦\" => \" ,wo wr  eeeeennnnnneette     aorrrrr,nn\"\n",
      "batch  640  loss=311.4123  steps/s=101.19  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" t  ci  fffdddbb ttttthhhsps/p...ocPNFyN\"\n",
      "batch  641  loss=307.5350  steps/s=104.08  prediction: \"r these very cool words. well said, dang\" => \")emdeohf sreeeeeyoooowswwwdlllsssdddddaa\"\n",
      "batch  642  loss=318.9506  steps/s=102.61  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"l ain iiuuuaallelezestssst//p////XNXXBBB\"\n",
      "batch  643  loss=279.0923  steps/s=104.94  prediction: \"best ways to improve for stuff like this\" => \"u ofetttsss    iimppooooorrffff     kiii\"\n",
      "batch  644  loss=294.5992  steps/s=99.76  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" imylybayyeeee   a    liilhiiiipp eeceee\"\n",
      "batch  645  loss=419.8086  steps/s=106.35  prediction: \"y fundamentals are hidden in plain sight\" => \" hann nmamntaaeate t eâ€™dhâ€iir  iinnð—¶iï¸ht\"\n",
      "batch  646  loss=563.1734  steps/s=104.20  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"pimsn(ceaeðŸ›‘ð—µUS)ðŸ°ðŸ˜†IS)wSc(U(USIá´€SSðŸ˜‰S)I)^y(\"\n",
      "batch  648  loss=497.9308  steps/s=104.86  prediction: \"ont like tech leave\n",
      "\n",
      "bulking and cutting\" => \"st att   tk}eèµ°ðŸ˜elecvvc#\n",
      "\n",
      "ilðŸ¤£bauðŸ“‰ du   ut\"\n",
      "batch  649  loss=517.5259  steps/s=100.44  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"wagiaA@oooolloool rnngr na pd ^pph whiwr\"\n",
      "batch  650  loss=500.6885  steps/s=51.36  prediction: \": @djcows you can make the jungle levels\" => \" @iddzbljcp@zzzð—°ðŸ°zð—°gyÊŸpbkryð—±\n",
      "u[jwndauðŸ¤£ð—µg\"\n",
      "batch  651  loss=437.1414  steps/s=105.85  prediction: \"en hook it up to a domain and everything\" => \"c n ev   ooo p pp a o toiaadn anvð—¿nvvnðŸ‘Œh\"\n",
      "batch  652  loss=473.7731  steps/s=101.22  prediction: \"re. Turns out it actually had a solution\" => \" cecuru.eT TpspsTou.â€¦rT.Tc.T.rlyodtdisol\"\n",
      "batch  653  loss=354.4272  steps/s=104.63  prediction: \"re obvious. some are really hard to see.\" => \"nilro oovosssssm m  rrrreaaalraa  l  dd.\"\n",
      "batch  654  loss=273.1832  steps/s=97.15  prediction: \" is nice. idk much about distros tho lol\" => \"mpnnnisi    .  ccc   uuuboodbtoto osoooo\"\n",
      "batch  655  loss=271.0886  steps/s=104.36  prediction: \"ut from having 1/3rd the progress per hr\" => \"rnetuoo  fmhhgg1//33vvg   r rrrreeesssss\"\n",
      "batch  656  loss=283.1506  steps/s=101.25  prediction: \"te well is a powerful powerful advantage\" => \"o oooewelw    wwwwpsssofrreufuule lvaaad\"\n",
      "batch  657  loss=317.8123  steps/s=101.32  prediction: \"ny part of a much bigger long term thing\" => \" s nn\n",
      "        a   hchgggggg    eee   ttt\"\n",
      "batch  658  loss=300.1587  steps/s=101.68  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"  roi i heggwwwwnwwwtyt:ttt//tBWWVKKFF.o\"\n",
      "batch  659  loss=385.3169  steps/s=100.88  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \" icunittt siiisl  ipptttttt.////EQ991O11\"\n",
      "batch  660  loss=372.8553  steps/s=72.80  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"yd @luwwAABPPl0pnnppppppppppppLLpfffyi  \"\n",
      "batch  661  loss=371.1986  steps/s=107.85  prediction: \"e chunking strategy. Good luck tomorrow!\" => \"spy lhhthnnnnntttggteGGoooo      coorrrr\"\n",
      "batch  662  loss=322.4849  steps/s=99.38  prediction: \"and down\n",
      "Long term trend is what matters\" => \"n o \n",
      "onudonnonngo\n",
      " trrret    wwwt aatttt\"\n",
      "batch  663  loss=374.8380  steps/s=107.11  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \"ouuloek ' iiaaaarraryrssrxttthceeee   nn\"\n",
      "batch  665  loss=347.2880  steps/s=105.22  prediction: \"r months or yrs\n",
      "\n",
      "https://t.co/7N4QDEMGnO\" => \"kee mo  or rrrrsshh\n",
      "\n",
      "ttst:/p/./7N444/MMM\"\n",
      "batch  666  loss=364.1677  steps/s=73.94  prediction: \"justalexoki its tpot, all lowercase only\" => \"ustojtssssaakii\n",
      "t  ptt lllllllolcwQweooðŸ›‘\"\n",
      "batch  667  loss=383.5636  steps/s=106.27  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" 0       5441......]1,  yxxxxaam(mmm  o)\"\n",
      "batch  668  loss=319.5989  steps/s=103.18  prediction: \"s how to do this w reasonable efficiency\" => \",onn s   o    ttww hh  ssanbbeeeeffiiicc\"\n",
      "batch  670  loss=281.0697  steps/s=102.51  prediction: \"o him) and he begged to pay me to use it\" => \" gss hi)  h)h eeegggeedd     y   t o  t \"\n",
      "batch  672  loss=306.1248  steps/s=106.27  prediction: \" monday\n",
      "\n",
      "5am (your timezone) is best imo\" => \"aronao omdm\n",
      "\n",
      "a\n",
      " au u   ozzooeiiie)ess   \"\n",
      "batch  673  loss=333.7798  steps/s=96.47  prediction: \" more cracked by the day, love to see it\" => \"@elti tecccccre   beedddaaaaa eto  e ee \"\n",
      "batch  674  loss=243.9240  steps/s=86.64  prediction: \"t only people named dan will have access\" => \"iiGi onnooppllll eadandnnllllwwavaaacccs\"\n",
      "batch  675  loss=311.5699  steps/s=104.92  prediction: \"y clip of polnareff LBJing up the stairs\" => \" im tllp   oopooffffanBJJnLng     eettta\"\n",
      "batch  677  loss=412.7125  steps/s=103.87  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \" y nee t ttttsssii... ,,,, ,    1 - 1111\"\n",
      "batch  678  loss=288.7159  steps/s=104.06  prediction: \"mance feedback you hear abt friendly ppl\" => \"onebrfefeeecaccad       aaaa  beerrellpp\"\n",
      "batch  679  loss=336.4817  steps/s=53.98  prediction: \": @yacineMTB jak creep is a real problem\" => \" @nre cannidM Bkk   heeeb   rreeelylplle\"\n",
      "batch  680  loss=293.8971  steps/s=106.81  prediction: \"you find God, the truth, and help people\" => \" en wu  d Gddd G ttttthhhhh    eepeppppl\"\n",
      "batch  681  loss=313.2927  steps/s=99.87  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"ost oraoaoaattiiinnII\n",
      "\n",
      "VEEE      fffttee\"\n",
      "batch  682  loss=275.6093  steps/s=104.76  prediction: \"to work on things that make sense to you\" => \"h ege  ooornnnnnnttttthtaahassssseeee   \"\n",
      "batch  683  loss=298.1855  steps/s=103.92  prediction: \"ay simpler, but also much more effective\" => \"m,p nsspilleee bb a, uuuummmoooroeefffee\"\n",
      "batch  684  loss=357.5042  steps/s=103.04  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"pnchsssssissseetetttt\n",
      "\n",
      "\n",
      ":/://..c26cQE266\"\n",
      "batch  685  loss=354.1236  steps/s=85.50  prediction: \"ex Only if you get a lobotomy afterwards\" => \"nl tnnxOddl  yyyf      ooltoooaa ttararr\"\n",
      "batch  686  loss=295.0688  steps/s=105.19  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \"et toot t     ddaggg n e eeed\n",
      "e\n",
      "nnioof f\"\n",
      "batch  687  loss=501.6130  steps/s=86.31  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"en  giybz wkkkkk??? tttttpto//cXXccRRRWH\"\n",
      "batch  688  loss=285.8206  steps/s=104.67  prediction: \"hink about a post before responding lool\" => \" th t titbaaaa   oob oofeeeerrrrnnnnnooo\"\n",
      "batch  689  loss=312.1896  steps/s=100.22  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"to t hh h v   iinnnimxx\n",
      "e\n",
      "eeeegggguuteii\"\n",
      "batch  690  loss=355.6545  steps/s=83.93  prediction: \"by_builds another $20 trillion to ludwig\" => \"lglbbuvuuulssneeee $2tt     r  oolloolow\"\n",
      "batch  691  loss=252.0965  steps/s=104.33  prediction: \"lms\n",
      "and lots and lots of trial and error\" => \"ylsaaldddlssss     o   oot  fllaaaaarrrr\"\n",
      "batch  692  loss=411.0293  steps/s=75.30  prediction: \"asedBeffJezos log(followers)/account age\" => \"nepw BdBffeBeezooz(olllllorrsrs)ccccuuoðŸ›‘\"\n",
      "batch  693  loss=272.4981  steps/s=15.85  prediction: \"reply: @djcows leveraged short positions\" => \"eply:Beffeeezellol(gllllgrorras)cc/uuouðŸ›‘\"\n",
      "batch  694  loss=268.9077  steps/s=108.82  prediction: \"ything rewarding that follows from that)\" => \" inaie   rrrrwwggigtttttt  lofflloo   mm\"\n",
      "batch  695  loss=683.5845  steps/s=99.71  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"IQHEEI E EEN M AA  PP     :://ttthhtYwYU\"\n",
      "batch  696  loss=318.4457  steps/s=105.02  prediction: \".. would love to be proven wrong on this\" => \"   ys.wwwloll      eeeovvoorrrroonnnn   \"\n",
      "batch  697  loss=295.9628  steps/s=100.11  prediction: \"f many useful things i can build for ppl\" => \"irht o mmuuuuuffennniii      ncllbld dpp\"\n",
      "batch  698  loss=265.3403  steps/s=104.89  prediction: \"will exhaust this reward bc its not real\" => \"ill oilwxaxxahhhssstterrrr   biiic tttta\"\n",
      "batch  700  loss=318.2322  steps/s=97.78  prediction: \"an that sounds like such a relaxing time\" => \"ntta t t annsssssd sssk     eaaaaexliiii\"\n",
      "batch  701  loss=359.9259  steps/s=100.16  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \"r  sess  rrr  ollliknggnnfn    2111    o\"\n",
      "batch  702  loss=365.6929  steps/s=102.07  prediction: \"he making a dingboard clone or something\" => \"i \n",
      "e\n",
      "\n",
      "hiiikaannngngddoddolooc       meen\"\n",
      "batch  703  loss=290.5883  steps/s=99.54  prediction: \"an that sounds like such a relaxing time\" => \"z r ttata assssu u    u      aaaaaaxxxii\"\n",
      "batch  704  loss=302.9941  steps/s=105.70  prediction: \"If are not one, you stand out like crazy\" => \"NdeI)m \n",
      "I  oonnne     taaauuudd     kkic\"\n",
      "batch  705  loss=418.1887  steps/s=100.42  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"tie t  ffffffreeeehhhdstt///.//...2XBQcO\"\n",
      "batch  706  loss=380.0506  steps/s=103.25  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"nl wiww\n",
      "ennoon     tttt::th:hcHHo/H/csc.\"\n",
      "batch  707  loss=306.2212  steps/s=104.54  prediction: \"k checked him out, followed, thanks mate\" => \" aooko\n",
      "kehehhch hi t,folllo,,wwwdt  aaaa\"\n",
      "batch  708  loss=545.9742  steps/s=102.38  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"taypmll  e ee equsht:s:ssss//t/cp/.bCCZb\"\n",
      "batch  709  loss=300.5815  steps/s=105.71  prediction: \"minds me of that old gpt engineer script\" => \",ktddmi\n",
      "\n",
      "ee     ttoooo      nneeeeeggrrp\"\n",
      "batch  710  loss=432.4001  steps/s=102.61  prediction: \"/t.co/3niiW6u2N4 https://t.co/AMiuse1VEj\" => \"Ke s/t:/iiiiiWii264ut:hpttt.ttcAMoMuss1e\"\n",
      "batch  711  loss=412.2842  steps/s=94.45  prediction: \"builds 2012 but yet blunders mate in one\" => \"tclyobluu01212s    bbbuuueeee smee     n\"\n",
      "batch  712  loss=317.0809  steps/s=104.65  prediction: \" know any easy way to work with cuda btw\" => \"sooy nnnnwnnaawayyy     wsoottttiiiu  dd\"\n",
      "batch  713  loss=334.6131  steps/s=104.00  prediction: \" i.e. p(death in car | not risky driver)\" => \"drike?..eeee   ii aaaan||n   rtrrkrrdivv\"\n",
      "batch  714  loss=328.6545  steps/s=105.22  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"aus\n",
      "\n",
      "mm\"\"\"g&&&cc;ccd\n",
      "\n",
      "\n",
      "t\n",
      "tttttnun;uisss \"\n",
      "batch  715  loss=399.1151  steps/s=99.93  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \"e;gt-t;;iiiffbbrr\n",
      "oorrr      i , msssssp\"\n",
      "batch  716  loss=335.8100  steps/s=105.95  prediction: \"but openai is cringe so obviously sonnet\" => \"urgg  u p n  iiiiinnsss oooooovu  sssynn\"\n",
      "batch  719  loss=353.7550  steps/s=104.73  prediction: \" up to do multiple iterations of editing\" => \"ts  tt    oduuumllpiiietttterarooo  foii\"\n",
      "batch  720  loss=387.3870  steps/s=105.09  prediction: \"ess while retaining the same information\" => \"   oeshililwweiiiiinnn  taa eeeeesmmrooo\"\n",
      "batch  722  loss=431.2005  steps/s=99.18  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" tru nkn   GIIththhtttppp/:/:t:cvEaaPCCðŸ›‘\"\n",
      "batch  723  loss=308.4284  steps/s=106.60  prediction: \"rs a question i've been unable to crackâ€¦\" => \"eve\n",
      "saao uqu iii'''eeeeeenbbn      otacc\"\n",
      "batch  724  loss=396.6533  steps/s=103.24  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \"mwoofsssccmcmee....bddttttt://::tccZZZsZ\"\n",
      "batch  725  loss=337.8009  steps/s=104.48  prediction: \"n and id 100% recommend it over The Goal\" => \"ssrdadn  iii0 00ddo%ommmedo ee  rTr hhhe\"\n",
      "batch  726  loss=404.6396  steps/s=104.16  prediction: \"/t.co/3niiW6u2N4 https://t.co/AMiuse1VEj\" => \"t .ec/tt:iiiii6NNN2Ntttttt.././A/coMssVe\"\n",
      "batch  727  loss=314.1650  steps/s=104.06  prediction: \"ng to caffeine+building/studying for fun\" => \"giggmg aaffffaai+ie+enbnnuududddggtsy  n\"\n",
      "batch  729  loss=325.4219  steps/s=102.94  prediction: \"ying/whatever, every monday and thursday\" => \":giiuww/ttttta,vveevrrrrryyaadndnndhhaas\"\n",
      "batch  730  loss=270.1564  steps/s=103.83  prediction: \"go, the name.. none of that shit matters\" => \"otde ,,  nnneeemnnn...o. htthhttttttatts\"\n",
      "batch  732  loss=480.9679  steps/s=102.36  prediction: \"load this prompt https://t.co/Ug4apoNeat\" => \"ouaa lol     sppprhttttts:s....U//U/ppaa\"\n",
      "batch  733  loss=306.9812  steps/s=101.85  prediction: \"ems like you have. thanks for sharing it\" => \" i  ellk  y     hhe.hhaahnnknff ssrrrnni\"\n",
      "batch  734  loss=295.7069  steps/s=101.66  prediction: \" of your day your brain will work better\" => \"tret  oooou yyyuurrrrba    iiwwwwllbobbt\"\n",
      "batch  735  loss=313.0979  steps/s=104.76  prediction: \"what's needed to  step out of reactivitâ€¦\" => \" as )iwaaeaeee't dt tt oooooo   ffttetii\"\n",
      "batch  736  loss=276.4105  steps/s=104.42  prediction: \"experience but i work w someone who does\" => \" a  peeeennc       rrr wwrk ooooom   eee\"\n",
      "batch  737  loss=284.5950  steps/s=105.12  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"tebm lell     rrrttttsss///////..DoDDbXX\"\n",
      "batch  739  loss=328.4191  steps/s=101.98  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"inn00tbreeeahaMM\n",
      "akhkhddd efffeeeeii  rc\"\n",
      "batch  741  loss=313.6696  steps/s=103.83  prediction: \"caveman do xyz?\"\n",
      "https://t.co/TlhgHoICNd\" => \"ant aac  dddddzzy?h\n",
      "\n",
      "h\n",
      "tttpts.///s/HHoTC\"\n",
      "batch  742  loss=262.5096  steps/s=104.44  prediction: \"ful defensive ai to guard you in cyber,â€¦\" => \" w prruffeeees   ii    dddddoouaayyyyrrr\"\n",
      "batch  743  loss=316.5054  steps/s=104.13  prediction: \"ow readable zig is. how does ak do it???\" => \"s hhwrraaaaeell ziii    ooooo  dd    ???\"\n",
      "batch  744  loss=286.4126  steps/s=102.83  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"s  a  sbllrryyy   tttthpp/p/////cccssGWW\"\n",
      "batch  745  loss=307.5165  steps/s=101.28  prediction: \"or always posting these, they're great ðŸ‘\" => \"resa aaalaylsssoooiiigheeehhhhee'eggee r\"\n",
      "batch  746  loss=325.7929  steps/s=100.54  prediction: \"pounds over time vs disappears instantly\" => \"ltnpuuoomdd    eevvs sssisppese ssssinnn\"\n",
      "batch  747  loss=371.9158  steps/s=102.14  prediction: \"encoded url that leads to discord invite\" => \"p e reenddrrrttttllllla    dsddodooiiiiv\"\n",
      "batch  748  loss=707.9241  steps/s=104.93  prediction: \"needed to dl this. meme delivery service\" => \"ke weonedddd d tti hihmme.leeeiveserrvrv\"\n",
      "batch  749  loss=326.3653  steps/s=103.52  prediction: \"tournaments, etc\n",
      "https://t.co/JA1SHygLtH\" => \" s,lya eemeen,,,tettt\n",
      "tph\n",
      "scc///J1oSJSoL\"\n",
      "batch  750  loss=359.9554  steps/s=108.37  prediction: \"d 1995 type sites are such a great style\" => \" caxl199199   tpsssee   rc   arrraasatty\"\n",
      "batch  751  loss=300.2283  steps/s=104.90  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"ie L,,,3ssssschjjjuâ€¦uuttt:t/ieAtoA/oACCV\"\n",
      "batch  752  loss=385.0628  steps/s=103.84  prediction: \"w, weve been going for a few weeks or so\" => \"eo   we eeeebb nnngg     fffffwwoweee ss\"\n",
      "batch  753  loss=282.2453  steps/s=106.12  prediction: \"how u get llms to make huge projects btw\" => \"i  as     gllllttotmmmmmmeeee geejrscsjt\"\n",
      "batch  754  loss=279.1551  steps/s=80.83  prediction: \"zmobly has selo made the circle tool yet\" => \"mh w@gzeyyaass  m ae deeeh dccccr oooo  \"\n",
      "batch  755  loss=351.8414  steps/s=54.93  prediction: \"y: @astroButter @karpathy @MagnusCarlsen\" => \": @: @aatorBtteme daaahhhtcyM@Mg otlCelðŸ›‘\"\n",
      "batch  756  loss=310.4558  steps/s=122.56  prediction: \"king one open rn just cause of this post\" => \"etaakinnnnono o   e jjuuuusssa   tf hoso\"\n",
      "batch  757  loss=373.7819  steps/s=104.14  prediction: \"tter the more it is aligned with reality\" => \"ee  br teeerr   t  siiii aaaaddht eeeeii\"\n",
      "batch  758  loss=304.4531  steps/s=104.95  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" tlt   iikuiiivvovedtttt:t/tt///O:UUUw88\"\n",
      "batch  759  loss=339.6918  steps/s=103.20  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"no.  eceerrrrgttBeeeeeee eeeeexeececelll\"\n",
      "batch  760  loss=289.8584  steps/s=100.13  prediction: \"ntiers out there we dont even know about\" => \"eiroriiiooot ttteeee  w  d ennnnnooooouu\"\n",
      "batch  761  loss=250.1137  steps/s=105.06  prediction: \"mannak Duh they used the hydraulic press\" => \"eldnanaakuuhhh  uu d eee  hhh d uuurrrrc\"\n",
      "batch  762  loss=298.1530  steps/s=102.63  prediction: \"enjoyable is such a gargantuan advantage\" => \"pungsnjjeeee ssss    agaggaauuunaantnnaa\"\n",
      "batch  763  loss=354.3706  steps/s=105.83  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"h s///RphRRRhRWWOPShhStuttttt/t/c/ctVDs9\"\n",
      "batch  764  loss=289.1353  steps/s=105.09  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"rinl h aaaarsssrrcddddk00   eeeebbbtttt \"\n",
      "batch  766  loss=283.4848  steps/s=98.48  prediction: \"surely you will not regret this decision\" => \"twsu ltyyuyuullll     rrrrrtrtii  eeeiii\"\n",
      "batch  767  loss=268.6331  steps/s=102.87  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"er e       eeeeoooccccnghhiiiiiff\n",
      " f\n",
      "\n",
      "ee\"\n",
      "batch  768  loss=458.3893  steps/s=93.76  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \":wy:vgk-gb---rtthhhhttt :::////YYGGYY.JJ\"\n",
      "batch  769  loss=387.2816  steps/s=103.71  prediction: \"tw (207kb total) https://t.co/nU8w0UL8jm\" => \"e  oet2b7b7ktttttttt)tthh)::hoo//888Uw88\"\n",
      "batch  770  loss=308.1377  steps/s=104.92  prediction: \"dering doing another one of these monday\" => \" lns iinggdgggnnn ooroee      otheeeesnn\"\n",
      "batch  772  loss=270.2789  steps/s=105.17  prediction: \" games because we trusted each other lol\" => \"arlema a aabbsseeeeuuu wtetececchhhhcooo\"\n",
      "batch  773  loss=266.5994  steps/s=104.60  prediction: \"nd me tracks and ill render them for you\" => \"e nn eeeettcraaakksd   lllnlreeeemm   oo\"\n",
      "batch  774  loss=279.1588  steps/s=100.47  prediction: \"ntiers out there we dont even know about\" => \"erTonirioo tttt eeeee d  nnnnnnvnookoooo\"\n",
      "batch  775  loss=267.7807  steps/s=105.85  prediction: \"e money now bc you can get 10x more done\" => \" em me nnno   yyyccccc     e11g00xx oooo\"\n",
      "batch  776  loss=294.5286  steps/s=105.82  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tc andaaa     rrrrocccttteeeeiii\n",
      "\n",
      "\n",
      "d hh \"\n",
      "batch  777  loss=428.9116  steps/s=103.65  prediction: \"nthwave channel: https://t.co/0b7orVHqb3\" => \"diretaat wvnnnnnhhht: ::tttt//ttc070VVbV\"\n",
      "batch  779  loss=354.7506  steps/s=102.50  prediction: \"nt and then generate a new one each time\" => \"dh  an ttt    eeeeeeegaa  an nweeeeeo ht\"\n",
      "batch  780  loss=326.0185  steps/s=104.10  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"mhee fi tt.      e eebbllubuubu    teeee\"\n",
      "batch  781  loss=430.1552  steps/s=93.59  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \"e\"d :gAAuaAaAooo l  ooorro???aBsssssseee\"\n",
      "batch  782  loss=277.3575  steps/s=103.84  prediction: \" use commonly are invisible fundamentals\" => \"tsttp  eusmommonmynnnniiiiibbbb  aeeanna\"\n",
      "batch  783  loss=328.1212  steps/s=99.20  prediction: \"ressive overload\n",
      "https://t.co/q7aR3FUGAr\" => \"ores ssevvveeorroodphtttt////..cqaRq33RG\"\n",
      "batch  784  loss=277.8407  steps/s=102.70  prediction: \"ness should get\n",
      "otherwise skill issue ig\" => \"c srssssi     e goohhtrtwweiiiills ssss \"\n",
      "batch  785  loss=275.3808  steps/s=102.28  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \"er, tt   lliillil\n",
      "\n",
      "\n",
      "FFeeeeooooogg\n",
      "\n",
      " \n",
      "ruu\"\n",
      "batch  787  loss=271.5859  steps/s=100.90  prediction: \"xist simultaneously sometimes, its crazy\" => \"ast tx iisisttueulllssoommemesei,e,i    \"\n",
      "batch  789  loss=302.7374  steps/s=103.72  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"1mta nadccallluooooo\n",
      "kkwwwkdnn  c c s sc\"\n",
      "batch  790  loss=270.5828  steps/s=102.61  prediction: \"ood at noticing things, would be so kino\" => \"ut  e    nniiiinntinnn hw gwuwwlb      o\"\n",
      "batch  791  loss=574.7960  steps/s=24.88  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" lbggo  tttiititttthhh wguwooww bb sbeoo\"\n",
      "batch  792  loss=283.5336  steps/s=118.91  prediction: \"o feel cool writing in an alien language\" => \" wmetteetoollllcwwtiiiiign nnnaaaaaggggg\"\n",
      "batch  793  loss=283.4811  steps/s=102.97  prediction: \"cks things into place, great feeling lol\" => \"asckt hiigsssnnnnn lll  ,,eeeeeeeefgglll\"\n",
      "batch  794  loss=285.0187  steps/s=102.49  prediction: \" is a wild computational rabbithole man.\" => \"sna cc   cwcccccaauttootaaaaabbbblllhhmm\"\n",
      "batch  796  loss=264.6078  steps/s=104.29  prediction: \"ything rewarding that follows from that)\" => \" imevn errrrraiidghttttt   oofffofo    m\"\n",
      "batch  797  loss=334.5825  steps/s=103.87  prediction: \"k in college it worked for me super well\" => \"ecbbui ciilleeellooooo k rrrr   eeeuepee\"\n",
      "batch  798  loss=302.1575  steps/s=100.27  prediction: \"hich might mean making changes, so, yes?\" => \"at w,i hhhhm m   aaannnngcggggeess,,,sss\"\n",
      "batch  799  loss=278.3958  steps/s=103.45  prediction: \"s changing how I think abt models a lot.\" => \" \n",
      "aaaniaggghnhn     niiIttt kkoo aa  l s\"\n",
      "batch  800  loss=309.6115  steps/s=93.46  prediction: \"eMTB i wonder which anime pfp is his alt\" => \"r ynBBiB   ooo iihhhc aaiammpppp iissii \"\n",
      "batch  802  loss=280.0638  steps/s=105.39  prediction: \"ta but those with a data engine: iteratâ€¦\" => \"h det  tttuaswwwh hhhaaaaa tiennniiieeet\"\n",
      "batch  803  loss=356.7265  steps/s=103.27  prediction: \"r you call this) https://t.co/l6jyM49oCP\" => \" wuaevoaall l lthhhtttssst////cccj66jj44\"\n",
      "batch  804  loss=315.9962  steps/s=101.38  prediction: \"ly know how many angels fit on a pinhead\" => \"l: lywylkwwwooooaaaa nnnfff    i  iinnnn\"\n",
      "batch  805  loss=277.7327  steps/s=104.45  prediction: \"mpeg tho but not if i rely heavily on it\" => \" e f n ff     ttttt    iiieeeeeeyyllll l\"\n",
      "batch  806  loss=303.3636  steps/s=104.20  prediction: \"y its been a useful learning experience?\" => \"oilsuyssssieeeeeaafullllnnnnnr  eeexeeee\"\n",
      "batch  807  loss=312.5506  steps/s=44.68  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \"oi s  bjteaeaa iuu Oh rno  rrerxriigph ðŸ›‘\"\n",
      "batch  808  loss=230.1071  steps/s=23.87  prediction: \"reply: @Wooltard the gradients must flow\" => \"osly: bjteeean  uOOhh oooo rrxrxriigphcðŸ›‘\"\n",
      "batch  810  loss=258.1431  steps/s=119.15  prediction: \"e readme was a good read on ai reasoning\" => \"rpcr tree m  aa      roooooooa   aannnnn\"\n",
      "batch  811  loss=270.8565  steps/s=103.42  prediction: \"el you save\n",
      "\n",
      "hmm interesting interesting\" => \"  o e ul u oaahmmmm\n",
      "\n",
      "eeeeeniiningeeerrsg\"\n",
      "batch  812  loss=268.7366  steps/s=101.92  prediction: \"o nothing for now but funny number go up\" => \"rnspeetotn nonfo  o   ffwnnnuuuuubb     \"\n",
      "batch  813  loss=406.2113  steps/s=104.14  prediction: \"igh, make schizo\n",
      "// TODO remove appendix\" => \"n tq oo, ,k  ssscz\n",
      "z//cOOOOT Oeeeeppppee\"\n",
      "batch  814  loss=314.8898  steps/s=99.39  prediction: \"uper loudly but yea. it helps w thinking\" => \"r not uuullllo yybyyee  ttttee   hhiwwnn\"\n",
      "batch  815  loss=564.9457  steps/s=10.00  prediction: \"reply: @gizmobly https://t.co/Lz4uSVD7Gv\" => \"eptys uulllood yyty et  tttele   hiiinnn\"\n",
      "batch  816  loss=286.2402  steps/s=109.31  prediction: \"r coding lol. And some chess. Great move\" => \"acðŸŽ‰3ioi nn    lllld.A A eesssseGG.GeG a \"\n",
      "batch  817  loss=412.4722  steps/s=102.08  prediction: \"n.. animate it bros. that's 60fps almost\" => \"d &tehtaaaamtttt    b  ttttstshhh   pmmm\"\n",
      "batch  818  loss=278.9715  steps/s=105.76  prediction: \"in places where i found better solutions\" => \"ngpffclpacceeweee e fff uu ttttttsoooooo\"\n",
      "batch  819  loss=249.1866  steps/s=104.62  prediction: \"he audiobook content is better than both\" => \"oughtsauoooooookkknnnntt  ttteeeee  bbhh\"\n",
      "batch  820  loss=357.5034  steps/s=101.25  prediction: \"w! I love hearing what works/what doesnt\" => \"nt! etII I  eehean waaawwrrrkkth/htttsss\"\n",
      "batch  821  loss=301.5898  steps/s=101.28  prediction: \"ed me understand https://t.co/LHjT6ITtSs\" => \"d hd p eeeeeurnndnststtps//:/..LcHTTTT6L\"\n",
      "batch  822  loss=465.6166  steps/s=21.13  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"w! d m  mmmranddnstpt:t////c/LcjcTHTc6LS\"\n",
      "batch  823  loss=348.9353  steps/s=121.71  prediction: \"there like this?\n",
      "https://t.co/ZF2p1Q4n6L\" => \"  ut reee  kiiihhhttt??tt??tp/osZpFFpQQ1\"\n",
      "batch  824  loss=334.6410  steps/s=105.21  prediction: \"yo grand children at 85. gps kids r busy\" => \"  on y nnnadddddria       ..gggpssss s  \"\n",
      "batch  825  loss=285.2237  steps/s=93.60  prediction: \"le77 if they install the meat addon, yes\" => \"ytc@ani77 h    yttnallltleeeeaaddddaatyy\"\n",
      "batch  826  loss=321.2134  steps/s=97.66  prediction: \"Simple p5. Will look into matter though.\" => \"aS yrl pepp  WlWll liiooooottttttt   rhh\"\n",
      "batch  827  loss=298.5062  steps/s=97.50  prediction: \"xe only the strongest can take this path\" => \"otcis  y y   t ennnsssgn   aa    t   s  \"\n",
      "batch  828  loss=426.0468  steps/s=21.25  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \"ptyyy@ oyteheetnntstssonntaca    sk  thh\"\n",
      "batch  829  loss=403.0522  steps/s=112.15  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \" t\n",
      "hs/:.11GGc1qEnElCiCttttttc////ocK888D\"\n",
      "batch  830  loss=293.8080  steps/s=104.59  prediction: \"y fundamentals are hidden in plain sight\" => \" manm annaaaddaaseee dedd  iii innnnnsis\"\n",
      "batch  831  loss=441.5629  steps/s=102.76  prediction: \": hold my beer.\n",
      " https://t.co/isMZrTmuiT\" => \" gaca  hh   eeee e tttt.//////tssssssiii\"\n",
      "batch  832  loss=275.5410  steps/s=105.15  prediction: \"ty) so they can be free to chase rewards\" => \"  eaa  s yyy a aace eeeee    cthccrrraaa\"\n",
      "batch  835  loss=335.9108  steps/s=101.23  prediction: \"\n",
      "\n",
      "Huh didnt know you could change your @\" => \"\n",
      "n it \n",
      "uHhtd dnnnoooooouooocccclhyyygy  \"\n",
      "batch  836  loss=281.1377  steps/s=104.94  prediction: \"e and @grok both came from that, I think\" => \"nomenenaa  gggboooobtc  mmmffhhttttt  t \"\n",
      "batch  837  loss=302.8951  steps/s=104.31  prediction: \"tly overlooking\n",
      "\n",
      "https://t.co/LodKIC2izF\" => \"hyye yelllooo okkgg\n",
      "\n",
      "ppttttc///.LcccLszK\"\n",
      "batch  838  loss=372.1270  steps/s=99.40  prediction: \"tic strategy\n",
      "Positional chess type stuff\" => \"hcSssistttaaar\n",
      "ePPiiPooooeessss     tttt\"\n",
      "batch  839  loss=281.6046  steps/s=102.81  prediction: \"cially long term stuff,  makes it harder\" => \" neefellllcyn     tttts    mfmfs k a arr\"\n",
      "batch  840  loss=312.0656  steps/s=104.96  prediction: \"freedom fighters. ppl who wanted freedom\" => \"o ge 2aeffgggg rhr.ppp.h www w  t aeeedd\"\n",
      "batch  841  loss=333.0579  steps/s=104.41  prediction: \"sing way more efficient/scalable methods\" => \" neucun  wyyreeeefffiiiicccnaaaaalltteem\"\n",
      "batch  842  loss=243.7514  steps/s=84.80  prediction: \"amebedan since ports dont allow weapons.\" => \"kiyt @aeennnnn     s too t  lloowwwweesðŸ›‘\"\n",
      "batch  843  loss=824.8148  steps/s=105.71  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \" aEO A  VMMVPPMEE  EELtt////t:s..YYYoYkc\"\n",
      "batch  844  loss=290.7452  steps/s=104.22  prediction: \" could approximate non linear functionsâ€¦\" => \"teatot aaappppoxxrxim  nnnnnne     uunnn\"\n",
      "batch  845  loss=278.5419  steps/s=103.54  prediction: \"just start working, and it doesnt matter\" => \"ust tststtttuarrwiii,nn   dddddo    tatt\"\n",
      "batch  846  loss=298.5190  steps/s=103.47  prediction: \"engagement-bait generating llm finetunes\" => \" oaeageennnnna---tte-eiiig g lll   nnnee\"\n",
      "batch  847  loss=301.3859  steps/s=100.98  prediction: \"u actually did the work so youre chillin\" => \"p  oaauaaaa ytddd       ooooorrrreeehehi\"\n",
      "batch  849  loss=262.0793  steps/s=104.08  prediction: \"d into using dishonest middlewit tactics\" => \" berpr uusinniiiinnssss  ddddeeetttttiic\"\n",
      "batch  850  loss=288.1869  steps/s=103.24  prediction: \"ntil finally training on unzoomed images\" => \"  oousnnlllllfiiiiiiinnnn    oooooguggme\"\n",
      "batch  851  loss=310.5221  steps/s=104.38  prediction: \"leneck is my lack of knowledge of opengl\" => \"y\n",
      " hheeeccc   ll kk  kkooooollww    geeg\"\n",
      "batch  852  loss=292.9240  steps/s=104.50  prediction: \"hat light mode is good for you. i don't!\" => \"in  t hit  gddod  ggoooood   orr. . dddo\"\n",
      "batch  853  loss=321.2596  steps/s=103.43  prediction: \"output less verbose/convoluted solutions\" => \"vv\n",
      "etuuoet     eeee/s//vooo/ollrt n utts\"\n",
      "batch  854  loss=356.4434  steps/s=98.83  prediction: \" this pic of him https://t.co/IPAvfCvWwd\" => \"@eadet iii  h h  hfttttt/////::IPoPPfvvv\"\n",
      "batch  855  loss=307.0698  steps/s=104.53  prediction: \"me good advice\n",
      "What do you think of him?\" => \"  lo sooddddvaaeccaW\n",
      "      ytihhohko of \"\n",
      "batch  857  loss=307.0361  steps/s=105.79  prediction: \"ntellectus To beat paranoia, accept risk\" => \"d h oeeellllts    Taoaaaaaooiaar,ccca,ap\"\n",
      "batch  858  loss=350.0151  steps/s=103.75  prediction: \"orn to make cash forced to consooolidate\" => \"v  o\n",
      "Br      aaaeo ohfeefococcoooooondnd\"\n",
      "batch  859  loss=285.2166  steps/s=105.05  prediction: \"r these very cool words. well said, dang\" => \"tt\n",
      "eehhf rrrvyeveooooowrww. lllldddddaaa\"\n",
      "batch  860  loss=284.0797  steps/s=104.05  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"ih o titttlllssss\n",
      "\n",
      "\n",
      "mm\n",
      "\n",
      "  kgn nooo  eeff\"\n",
      "batch  861  loss=322.5626  steps/s=100.25  prediction: \"a have hella nostalgia in like 10yrs bro\" => \"zyi\n",
      "waahheeaaa oolllaaaagniiiii   1s0ysr\"\n",
      "batch  862  loss=392.0522  steps/s=98.04  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \";cbee tt;nngLaa ggggg t ///t/t..sqqq888j\"\n",
      "batch  863  loss=267.6951  steps/s=106.59  prediction: \" of how i debug and catch inefficiencies\" => \"mast s     wwwidddddg ncccaannfffiiiieee\"\n",
      "batch  864  loss=318.3611  steps/s=105.03  prediction: \"ed, its worth at least giving a shot tho\" => \"  otese ,s,tttttth    a  iiiggggaa    tt\"\n",
      "batch  865  loss=319.7491  steps/s=103.57  prediction: \"robably easier/quicker ways to learn tho\" => \"e arerpbaaayeeeeeeuiiiirrrk w     oaatoo\"\n",
      "batch  866  loss=343.0309  steps/s=98.20  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"eksoalo oYooYuu      nnnnllllln eeeeerrr\"\n",
      "batch  867  loss=341.7499  steps/s=104.49  prediction: \"amming you can make bigger leaps though.\" => \"nebenm2ggiionnnnaa     bbkeeeelellrpohhh\"\n",
      "batch  868  loss=254.7292  steps/s=104.84  prediction: \"vision how great itll be once youre done\" => \"e it enooooo h    tttte eeeee lc  urrooo\"\n",
      "batch  869  loss=320.1903  steps/s=100.16  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" iyff IInnnIkkkss  s ffffeeeeewtyyyppaaa\"\n",
      "batch  870  loss=258.7052  steps/s=103.85  prediction: \" regarded so take that w a grain of salt\" => \"ii ekbddddrraaaa    tttt    waagggo o ss\"\n",
      "batch  871  loss=292.5551  steps/s=99.98  prediction: \"ols is kinda like cookie clicker but irl\" => \"fi ioosiiisi ikkkiccalooeccccckk ik   rr\"\n",
      "batch  872  loss=295.0676  steps/s=93.18  prediction: \"skill issue lol, just go outside of time\" => \"kz  slliisssi sel,juu   ouuootsstddoi  f\"\n",
      "batch  873  loss=290.3219  steps/s=92.97  prediction: \"ath dependence can be used strategically\" => \"cc da@pnpeeeenneccncnee    s ssssaaarral\"\n",
      "batch  874  loss=345.3937  steps/s=89.51  prediction: \"072 im super glad man! love to hear that\" => \"0 hnns7xx  p pmaaaaaad ! !l vv   oe hhhh\"\n",
      "batch  875  loss=311.8476  steps/s=105.31  prediction: \"de it one of the best ive had in a while\" => \" cy itt    oo ofoeeebbttv hh  ii      ni\"\n",
      "batch  876  loss=438.9684  steps/s=101.90  prediction: \"expected him to be maybe 55 or something\" => \" s naeeex    ttttt mmmmbb5555  5oooooeee\"\n",
      "batch  877  loss=325.9725  steps/s=59.48  prediction: \" @0xluffyb unfunded? then do it unfunded\" => \"I0e0pxcuuffffuuundddddee    ooo  etuunnn\"\n",
      "batch  879  loss=272.0092  steps/s=108.08  prediction: \"oud to yourself, or in your imagination)\" => \" t lo u ooo rrrs,,frf   y  iiiiiiiaaaann\"\n",
      "batch  880  loss=343.0895  steps/s=71.21  prediction: \"2wlearning Great stuff man, keep pushing\" => \")cue aerrlaaiiGGG  ttfffft  mmmgppppet)ðŸ›‘\"\n",
      "batch  881  loss=257.3711  steps/s=108.53  prediction: \"\n",
      "\n",
      "good potential source of cool projects\" => \"ro  daadooottptttnaaee     ooooooorrrrcc\"\n",
      "batch  882  loss=259.3926  steps/s=74.10  prediction: \"is would make a really cool pfp actually\" => \"nhwgs p   meeea    rlallyoool fpp     ll\"\n",
      "batch  883  loss=316.7038  steps/s=110.41  prediction: \"x reddit is the strange people attractor\" => \" l txrrdddi tt    sstrrtteepppp paatttra\"\n",
      "batch  885  loss=479.6291  steps/s=102.78  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \"  t  iiGGOHemppp  stsspsh:h////ozZc.zZcc\"\n",
      "batch  890  loss=285.0375  steps/s=104.24  prediction: \" arent tired when you dont have caffeine\" => \"stu  attttrrrteennyy    d  oohha aaafffe\"\n",
      "batch  891  loss=267.6609  steps/s=104.61  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"aarfdtrmreeeooov adyyy \n",
      "\n",
      "     tt ooorrrl\"\n",
      "batch  892  loss=257.2546  steps/s=103.62  prediction: \"seless to ppl who dont know them already\" => \" rua lese ppppp   oooo w twtttnn mmm dra\"\n",
      "batch  893  loss=520.6226  steps/s=103.49  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \"ofa ma7aac7iiiiii\n",
      "\n",
      ")ttttt:t/:cc//.2FFqcF\"\n",
      "batch  894  loss=345.4434  steps/s=104.04  prediction: \"ool looking games, and get more interest\" => \" lco foo lkkggggm annaaae eeeeee ttrrrre\"\n",
      "batch  895  loss=261.0153  steps/s=104.64  prediction: \" in those days will have had it too easy\" => \"ma\n",
      "d\n",
      "  ss   ddaaaaayhlllhhhh     tttoooo\"\n",
      "batch  896  loss=312.0928  steps/s=103.97  prediction: \"ed, its worth at least giving a shot tho\" => \" ean s,  , owttttth     aaiiggggv     th\"\n",
      "batch  897  loss=385.2848  steps/s=100.37  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"kaka@yyttuaaIIltss_s    keeerrrrrsCsisss\"\n",
      "batch  898  loss=333.4924  steps/s=104.09  prediction: \"ed in joining, repeat these instructions\" => \"sieteiniiiinnnoo  geeeeeeeettsssttttiiii\"\n",
      "batch  899  loss=291.6571  steps/s=103.86  prediction: \" to animate a NN https://t.co/JdnKMowlAa\" => \"tatem  nammaaaaNNNNNttttt/h////oJ.KooKJd\"\n",
      "batch  900  loss=265.2458  steps/s=104.97  prediction: \"dibly efficient and powerful compression\" => \" mgefogffffcceiiinn      wpwplooooprrrre\"\n",
      "batch  902  loss=267.5670  steps/s=105.43  prediction: \"es success, but there is a causal factor\" => \"   tuesssscccc,  tttteeee    cuaaaaaaacc\"\n",
      "batch  903  loss=300.9619  steps/s=101.43  prediction: \"the man stretches his mind and his limbs\" => \" e0xi   nt ttttcehhsssshmi    ddd   mmmi\"\n",
      "batch  904  loss=257.5343  steps/s=100.54  prediction: \"honorary denis\n",
      "\n",
      "and got gelato in venice\" => \"i aenonrrrrryedaadd\n",
      "\n",
      "dd ggg tttoo    nee\"\n",
      "batch  905  loss=255.5768  steps/s=103.83  prediction: \"veryone in the past was a caveman/moron\"\" => \"e u vyeennnnn    ttttaaaas  ascvccmmmoen\"\n",
      "batch  906  loss=264.0559  steps/s=103.51  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \"ern dp    llllniiiieeF\n",
      "\n",
      "\n",
      "oooooooY\n",
      "dY uur\"\n",
      "batch  907  loss=273.6059  steps/s=101.45  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"oatannnaaac\n",
      "\n",
      "sss\n",
      "korro  iiddddviv,,,aaaa\"\n",
      "batch  908  loss=298.9628  steps/s=105.15  prediction: \"her is metagocnition (for your own mind)\" => \"es pel\n",
      " eee  ooiiiinnnnoooff(rrrrr   umm\"\n",
      "batch  909  loss=262.2943  steps/s=105.64  prediction: \" good at developing your own techniquesâ€¦\" => \"aettnto     dddveveeppoooooonr ttnnuuuqe\"\n",
      "batch  910  loss=254.4250  steps/s=105.06  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" ofesofnugnnneeeeettttttsss///..PPch1111\"\n",
      "batch  911  loss=365.2096  steps/s=93.72  prediction: \" its crack bro. be careful. i warned you\" => \"o0x _x crcrrrrk bbb. c          l       \"\n",
      "batch  912  loss=291.4155  steps/s=104.74  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"ihink nggg    yyyyooststtt//p./.HccKKK33\"\n",
      "batch  913  loss=286.7955  steps/s=100.10  prediction: \" least its not opengl like this poor kid\" => \"iua etattsss     eonnolllliiiiiiiiiipkik\"\n",
      "batch  914  loss=268.1639  steps/s=103.25  prediction: \" and realized idk what it actually means\" => \"ibuftddda zezaizdddi      ttttaallllcucu\"\n",
      "batch  915  loss=344.1366  steps/s=104.60  prediction: \"/t.co/emubOEhMKJ https://t.co/Fxx5eUVcPp\" => \"thpco//.eeueuuEEEbJhhhttttt.////xxxx/F5V\"\n",
      "batch  916  loss=475.6524  steps/s=101.89  prediction: \"eople want. Nowâ€ https://t.co/yxXaaiHzQ1\" => \" siseepeewt   N.N â€tttt:t::/o.///XatXXaW\"\n",
      "batch  917  loss=327.1696  steps/s=65.21  prediction: \"@IterIntellectus have you brrrytt today?\" => \"joegeItnnelellâ€ chh    yvy  rrrrryttttty\"\n",
      "batch  918  loss=284.6832  steps/s=108.86  prediction: \"e rotators\n",
      "\n",
      "we color c, e, f, g the same\" => \" r \n",
      "rotttttsoss  oo\n",
      "ccc\n",
      "   ,,,    eeeeee\"\n",
      "batch  919  loss=283.5936  steps/s=105.20  prediction: \"nomic than discord id switch immediately\" => \"gnkeioogg nniiccdddd    siwwhhmmmmmittte\"\n",
      "batch  920  loss=256.1071  steps/s=104.39  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \" sha rhotttteeeeeee trsrrrrrppeeeetteuuu\"\n",
      "batch  921  loss=388.4617  steps/s=103.93  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"ged  ouuoo1       I jjejjeeeeesssssnonn \"\n",
      "batch  922  loss=460.7565  steps/s=100.58  prediction: \"u helped a ton, hugely appreciate it bro\" => \"r11_1y1     pe  ,,,uu,llappppeaeeiiiittt\"\n",
      "batch  923  loss=296.6756  steps/s=102.17  prediction: \"k x's video compression is getting to it\" => \"uIink'kixii   ooooosssseiiiii iigggtttt \"\n",
      "batch  924  loss=260.2749  steps/s=104.56  prediction: \"r) instead of giving you an easy way out\" => \"e er))evn i    ffigggvvv a  aaayyyyy   w\"\n",
      "batch  925  loss=274.9340  steps/s=105.89  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"rh\n",
      "thaaaaaasssssrrdddkk    beeebbbbtttt \"\n",
      "batch  926  loss=275.2326  steps/s=105.27  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \"trolg l  k k eyy,,,,uuuttttllny,oprriiee\"\n",
      "batch  928  loss=359.7578  steps/s=21.77  prediction: \"eply: @mynamebedan head completely empty\" => \"slroyikkknkeeeee,,uguttttolllyy py eppee\"\n",
      "batch  929  loss=258.3245  steps/s=113.15  prediction: \" and realized idk what it actually means\" => \"atufe,f aazzzeiidddd      atttaaullllu y\"\n",
      "batch  930  loss=370.4925  steps/s=104.47  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \"n sfeeesssnnnnnbn wttttt//t/h/sh.HcTZEEE\"\n",
      "batch  932  loss=323.0329  steps/s=99.93  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"fsuret tiNiNcc\n",
      "\n",
      "neeeeTeee sannaaaangiss \"\n",
      "batch  934  loss=329.8938  steps/s=105.06  prediction: \"uff like explore exploit basically daily\" => \"se sfnfeeeeellxlexxpxppoio iiaaalllllca \"\n",
      "batch  935  loss=362.7256  steps/s=99.36  prediction: \" lol positive feedback loops are awesome\" => \"ieatesolliiiiieeeeeeaabcbkooo a   aaasss\"\n",
      "batch  936  loss=248.0298  steps/s=104.62  prediction: \"t you are in fact to blame for everyoneâ€¦\" => \"hat y uuu      nafftttttobb  m  eeerrrve\"\n",
      "batch  937  loss=247.4528  steps/s=105.85  prediction: \"dual input vector or a set of input data\" => \"iiid iauuu vv  cccoorr     tt ttftfnnnaa\"\n",
      "batch  940  loss=367.9433  steps/s=102.98  prediction: \"python or c??? ðŸ¤” https://t.co/XQktKXHLU2\" => \"er opdoh      c???ðŸ¤” htðŸ¤”::::c//////XXXXHk\"\n",
      "batch  941  loss=459.5730  steps/s=99.92  prediction: \"prob 2.5M tokens\n",
      "https://t.co/6FbmJG4MmF\" => \"l :i   b b5. tkktsttttsssst/p/noc/.6GGmm\"\n",
      "batch  942  loss=298.9091  steps/s=104.95  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"\n",
      "t2)A\n",
      "\n",
      "sseettt     hhhe   ersxfaaxep    \"\n",
      "batch  943  loss=342.2222  steps/s=103.92  prediction: \"darin and english which they are meh at)\" => \" sptarannnnadddii hhhhhh      eeeeeee  a\"\n",
      "batch  944  loss=302.9114  steps/s=97.56  prediction: \"oger @sunsettler @tunient baller name xD\" => \"rld @ grreeestteet@@@ttnnnntlllllnan  e \"\n",
      "batch  945  loss=254.6216  steps/s=104.76  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \"rsioneeellgtt''hhhhtttt:p/////cKKKcKooYY\"\n",
      "batch  946  loss=247.6046  steps/s=103.08  prediction: \"uture w her, and what that would be like\" => \"t thierr      e ,whaaaaaatttt   d  lllbb\"\n",
      "batch  947  loss=415.1284  steps/s=73.24  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"nour@ asssn    hhhtttt    :p//.o.cceeie4\"\n",
      "batch  950  loss=474.4550  steps/s=105.23  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tnte5eddddiswlllpppttoppby rrrr  ut ssss\"\n",
      "batch  951  loss=272.5231  steps/s=105.47  prediction: \"usually good metrics, good feedback, etc\" => \"f  oge lllya    edeeeeggo,ooodddecbbekcc\"\n",
      "batch  952  loss=320.2507  steps/s=101.46  prediction: \"gh Ive been wanting to do a wasm project\" => \"o bae heeeeeeennnnnna  t    aaaaaooomjjp\"\n",
      "batch  953  loss=380.6693  steps/s=103.06  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"tlte st/t o     il5t0tt0:k/////.cccRRR4R\"\n",
      "batch  954  loss=328.9426  steps/s=104.89  prediction: \" and can be much more useful to increase\" => \"ssabnb        ccummmmmueeeuuuo     c sss\"\n",
      "batch  955  loss=284.5906  steps/s=104.43  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \"apphhp\n",
      "\n",
      "\n",
      "um eeevvhhhhhr e  i   isiiisttt\"\n",
      "batch  956  loss=254.8115  steps/s=105.17  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \" nf hof   nn  eeeeeer\n",
      "o\n",
      "\n",
      "\n",
      "t\n",
      "nnnnn     aa\"\n",
      "batch  957  loss=363.7373  steps/s=99.55  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"h .   t  nnnnuuuuehhtttp/////:t.ccUUCjjc\"\n",
      "batch  959  loss=340.8203  steps/s=98.47  prediction: \"s man. i try to keep it real as they say\" => \".arktann   nttt tkkkeeeeeerrr aa      yy\"\n",
      "batch  960  loss=274.0484  steps/s=105.41  prediction: \"ing ive wanted in life lol, complete 180\" => \"vllyvli g  neeee    iiiii llllooooceeeee\"\n",
      "batch  961  loss=295.8654  steps/s=99.16  prediction: \"e go all the blindfold web dev positions\" => \" t aa     lllllllbooodddbbbe ee  ooooiii\"\n",
      "batch  962  loss=286.1470  steps/s=105.33  prediction: \"fected, i hope none of my followers were\" => \"a e ae e  ,    ooonnnnnn    mfoofllwwwee\"\n",
      "batch  963  loss=258.8554  steps/s=105.75  prediction: \" on bookmarks from people similar to you\" => \"bbae booookkkssrrmmmffppppp elllliii ooo\"\n",
      "batch  964  loss=371.9315  steps/s=101.27  prediction: \"python or c??? ðŸ¤” https://t.co/XQktKXHLU2\" => \"loo pyy      c??? ??ðŸ¤”tttt:::/:/.:cQXK.LK\"\n",
      "batch  965  loss=647.1919  steps/s=91.64  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"esp\n",
      "seMBT T P A  EDDUp/U//ttc//jojLoLjiH\"\n",
      "batch  966  loss=302.8761  steps/s=58.32  prediction: \": @yacineMTB better start skilling up ig\" => \" @eMc @iiPeT DDCCttttstttssssssiiiPin  i\"\n",
      "batch  967  loss=247.5427  steps/s=112.94  prediction: \"r been a better time to be a corn kernel\" => \"es nehebbbb beeeetrt  e t    a a noknnnn\"\n",
      "batch  968  loss=271.0279  steps/s=102.60  prediction: \"ng term\n",
      "\n",
      "Best signal to work on for sure\" => \"g  l ltr\n",
      "\n",
      "\n",
      "BBeeggsssstt     oooo krrrrrr\"\n",
      "batch  969  loss=226.6785  steps/s=98.24  prediction: \"feeling than automating hrs of work away\" => \" ketNetggnn nnaaatttttmnnrrr   f ooowwaa\"\n",
      "batch  971  loss=271.0110  steps/s=78.44  prediction: \"odor_io worst metric youve heard so far?\" => \" ee er _iroowootmrrr      vvvhoeeee     \"\n",
      "batch  972  loss=306.4692  steps/s=106.73  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"end tyi eeeeeeeeehhhppptt:t:///c/Mcz1111\"\n",
      "batch  973  loss=276.0607  steps/s=94.21  prediction: \"irak seems fine to me (i am brainwashed)\" => \"ted a essseese eft mmmee em(mmmaaaaaaniðŸ›‘\"\n",
      "batch  974  loss=256.7903  steps/s=105.06  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \" lklkiah--dddhhnnnngg\n",
      "\n",
      "\n",
      "ttttttg       he\"\n",
      "batch  975  loss=263.6072  steps/s=104.87  prediction: \"useful analogies that show up everywhere\" => \"n  heu uaaallllegg httthhhh     wvvweeer\"\n",
      "batch  977  loss=258.9191  steps/s=101.24  prediction: \"ven a bit is a huge anti pattern i think\" => \"emeneaf  iiiii aa g gee   ttttttnn  iiih\"\n",
      "batch  978  loss=289.8635  steps/s=69.14  prediction: \"@JsonBasedman just veto their veto, easy\" => \"IteinniaeBaasshuuu jsvvttteierrirr ee,eðŸ›‘\"\n",
      "batch  980  loss=321.1229  steps/s=111.94  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yc @Colllaaa07777eeeaaaatttatt aa a  we \"\n",
      "batch  981  loss=298.8750  steps/s=105.83  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"elondethabaaaassss   dlllleeeeeearvaPbbb\"\n",
      "batch  982  loss=249.2433  steps/s=104.53  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \"\n",
      "cihhtrmedd\n",
      "\n",
      "\n",
      "ss\n",
      "\n",
      "\n",
      "ss   da       nnnaioo\"\n",
      "batch  983  loss=362.2369  steps/s=98.11  prediction: \"n just do things https://t.co/909bTHzmml\" => \"detset jo     ts sstthhphhs/////..990TzT\"\n",
      "batch  984  loss=294.5665  steps/s=101.90  prediction: \"ems like you have. thanks for sharing it\" => \"pt ileel y      evv..hhahhannsfssrrrni i\"\n",
      "batch  985  loss=251.7247  steps/s=99.26  prediction: \"farming simulator but with a circle tool\" => \" llxsoirmmimuuugurrutu ttt    iiiacccolo\"\n",
      "batch  986  loss=321.7979  steps/s=99.13  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"ulygoooo\n",
      "\n",
      "ll\n",
      "e         aaakkuuuodd   tt2\"\n",
      "batch  987  loss=254.5279  steps/s=103.61  prediction: \"then add audio and make it a vid editor.\" => \"  oos dddaad        aaaeek       dddddtt\"\n",
      "batch  989  loss=291.9495  steps/s=91.19  prediction: \"eMTB I see slop poasting is the meta now\" => \"p h:inM T eessssoopppssstiisss   eeee   \"\n",
      "batch  990  loss=534.6003  steps/s=103.24  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \"P HTAv A sssssiiiii oooooossee dd  ddddd\"\n",
      "batch  991  loss=287.1304  steps/s=104.87  prediction: \"e context, like words, strengthen ideas?\" => \"tc o reecctt,,tkkk rwwwsssrrrrtennnneeed\"\n",
      "batch  992  loss=249.8704  steps/s=104.33  prediction: \"n just build cool fun stuff all the time\" => \"tawher suubssbcclllllolffffffu   t  ttll\"\n",
      "batch  993  loss=441.2617  steps/s=100.30  prediction: \"rackpad &gt;&gt; 3 monitors + pc + mouse\" => \"ecabaj+apk&d&&g;;;g33t  tt        +++  s\"\n",
      "batch  994  loss=296.5591  steps/s=104.15  prediction: \" different on your OS. you can google em\" => \"iee tefeffffrrooooo OO  yuOu . coooooo  \"\n",
      "batch  995  loss=253.4756  steps/s=103.31  prediction: \"ppl who got rich playing 0 sum games tho\" => \"re luopooooo ghhhh rciigigig  00mmmmssms\"\n",
      "batch  996  loss=577.5461  steps/s=11.35  prediction: \"reply: @0xluffyb https://t.co/Qs8R6GnjEa\" => \"ed l tpoooo  gh h cpiiggiyi0  ggmmmmssms\"\n",
      "batch  997  loss=320.9415  steps/s=118.96  prediction: \"te wow\n",
      "\n",
      "followed https://t.co/riXL2UlhdY\" => \" pype wwwwoooo\n",
      "el\n",
      "letdst///t/tt..cciii22\"\n",
      "batch  998  loss=362.2141  steps/s=100.74  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \"eshhgnggog v oooollhlthttcs/t/.tSccz.bz4\"\n",
      "batch  999  loss=263.8861  steps/s=104.12  prediction: \"like there's more of a person there, idk\" => \" teekeeeeeee'''rrrr       ooossseeeerrr,\"\n",
      "batch 1000  loss=380.4569  steps/s=63.52  prediction: \"@startupmillyair https://t.co/QgfnCndCQA\" => \"Pnrpshtrrrtiiiiiyoyitttt:tan.//.hnnnCdCk\"\n",
      "batch 1001  loss=279.1151  steps/s=106.32  prediction: \"itor as I was with 2 screens and a mouse\" => \"onm\n",
      "n oo      swwww       2ssseeaaaaa   \"\n",
      "batch 1002  loss=265.3996  steps/s=104.76  prediction: \"s principle imo\n",
      "\n",
      "https://t.co/VzXUJ8r5oL\" => \"tdo nsiiiirrppppeeehh\n",
      "t\n",
      "ttttto/.ozVXU8Uo\"\n",
      "batch 1003  loss=314.1759  steps/s=88.18  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \":y@tr_cddd     oohhhhhh:///.cc/cccII8NKG\"\n",
      "batch 1004  loss=261.8965  steps/s=104.61  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \"t illoedde\n",
      "\n",
      "o\"\n",
      "   \"nnnnn   poeeeeeeeiii!\"\n",
      "batch 1007  loss=227.2498  steps/s=103.66  prediction: \" to put in effort to unwire it (nbd tho)\" => \"mho  o tt     eeetfffoooorrriii  ( ( btt\"\n",
      "batch 1008  loss=272.8859  steps/s=103.02  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" es\n",
      "eeeeeeeeseisssAAA \n",
      "aRssseeeeeei \n",
      "  6\"\n",
      "batch 1009  loss=215.1924  steps/s=103.31  prediction: \"ppl who got rich playing 0 sum games tho\" => \"rlilrel oooo  hhhh  cciiiii  0   aammmm \"\n",
      "batch 1010  loss=322.7084  steps/s=73.93  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"r  rohoJgllliaiiilla      vssnn\n",
      "n\n",
      "\n",
      "\n",
      "lloo\"\n",
      "batch 1011  loss=264.2221  steps/s=106.21  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"ysle\n",
      "rl\n",
      "\n",
      "\n",
      "teeee      uttttthhleess ss  a\"\n",
      "batch 1012  loss=271.2879  steps/s=103.38  prediction: \" from scratch, and a bit of transformers\" => \"faop orrroccccca,,aa       tttttnfffnrsr\"\n",
      "batch 1013  loss=240.6600  steps/s=104.04  prediction: \"he pot of gold at the end of the rainbow\" => \"act rpoo  oooood   tttheeee        annnn\"\n",
      "batch 1014  loss=325.9894  steps/s=103.94  prediction: \"??\n",
      "\n",
      "oh wow it is https://t.co/dShiVDjfFr\" => \"\n",
      "I\n",
      "oeore\n",
      "wwwwo      ttttt//////tt.ihShij\"\n",
      "batch 1015  loss=332.2327  steps/s=53.92  prediction: \": @0xluffyb graphics programming be like\" => \" @earshoo     iihhthii/ppproo.omiidiDVDðŸ›‘\"\n",
      "batch 1016  loss=274.5101  steps/s=106.79  prediction: \"mentals can be really really hard to see\" => \"enbamesaaaaaa   eeelllleelryyyarar      \"\n",
      "batch 1018  loss=213.9376  steps/s=104.21  prediction: \"s w java and python and studying for fun\" => \"tart,g  jjaaaaaaannnnnnddddddyyy       u\"\n",
      "batch 1019  loss=221.5668  steps/s=104.63  prediction: \"ered into something super super powerful\" => \" esst eetooooootttinnnnssssuupppppeeeeee\"\n",
      "batch 1020  loss=193.1352  steps/s=105.34  prediction: \" local optima solution they got stuck in\" => \"te tttoooooolllllllliiittttt       tt  c\"\n",
      "batch 1021  loss=230.2626  steps/s=99.99  prediction: \"om gpt10 how strong could you make gpt2?\" => \"u na fm   p11h0oootooooo    uuuu    g kk\"\n",
      "batch 1022  loss=229.8812  steps/s=102.84  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \"etsarf  US ggggnnns\n",
      "\n",
      "\n",
      "\n",
      "aaaeee i       oo\"\n",
      "batch 1023  loss=185.3873  steps/s=100.88  prediction: \"category so the rule is to tell everyone\" => \"an tte  rr           e     ttllllleeeeee\"\n",
      "batch 1024  loss=217.5972  steps/s=105.28  prediction: \"er important first step towards progress\" => \"r spu /pprrrrrrrrtttttttts   s swrrrrrrr\"\n",
      "batch 1025  loss=235.4582  steps/s=63.23  prediction: \"@jamstack_guru Speed of launches as well\" => \"gois msjaattg_uuuu  eee ooaaaaaannsseseðŸ›‘\"\n",
      "batch 1026  loss=256.1717  steps/s=106.19  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \" eeettrtttx\n",
      "IIrreeeeee hhhiiiin      ggg\"\n",
      "batch 1027  loss=198.5717  steps/s=62.80  prediction: \": @archived_videos definitely the latter\" => \" @NuttIIhhheveedddd dddiiiii     tt ottt\"\n",
      "batch 1028  loss=235.7259  steps/s=106.61  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \" ano  eerrr56%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5%ttt/t////t..E007s7s\"\n",
      "batch 1029  loss=198.2338  steps/s=101.73  prediction: \"e enlightened than me, i need to wake up\" => \" ,ly le eeeennnnhhhtt      eeeeeee      \"\n",
      "batch 1030  loss=189.5621  steps/s=50.48  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"   rme ttniehthht     iiineeedda aat    \"\n",
      "batch 1031  loss=217.5623  steps/s=109.21  prediction: \" on linkedin will be typing in lowercase\" => \"tneyynnnn   iiiilllll       ii  nnwwwwne\"\n",
      "batch 1032  loss=203.9161  steps/s=104.45  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ndieI nntthhhhiiiIII      CCCCss ssAA A \"\n",
      "batch 1033  loss=184.7965  steps/s=102.44  prediction: \"e seen it from all possible perspectives\" => \" hheeeeee           llllllllssbpppppeeee\"\n",
      "batch 1034  loss=172.3584  steps/s=45.31  prediction: \"y: @andyduboc genius concept for a piece\" => \"ou heeannduoooo llllsssooobppprrrreeiecc\"\n",
      "batch 1035  loss=293.8747  steps/s=107.44  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"toE tL/ttt.jjChhhQWWWaaaab((   1 1 5 eee\"\n",
      "batch 1036  loss=200.3732  steps/s=105.01  prediction: \"this. or you can win by trading seats wâ€¦\" => \"h ybuoi   o          nnnnyyaaaaaaaaaasss\"\n",
      "batch 1037  loss=169.8523  steps/s=102.84  prediction: \" able to do this approach w gpus anyways\" => \"we bbbee      tttttaaaaaaahhpppp    wwww\"\n",
      "batch 1038  loss=215.6417  steps/s=104.20  prediction: \"\n",
      "\n",
      "Huh didnt know you could change your @\" => \"\n",
      "r  o v\n",
      "Hiittttd noo ooouooocccc        \"\n",
      "batch 1039  loss=177.6992  steps/s=104.60  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"hen oft nnnnnniiiimmm\n",
      "\n",
      "\n",
      "\n",
      "ooooooooo rgggg\"\n",
      "batch 1040  loss=310.1183  steps/s=100.65  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"nmabrartttt  G LTTLERUR UIIIEFRLLLLLNNNR\"\n",
      "batch 1041  loss=293.6440  steps/s=97.49  prediction: \"2 and a monkey pfp too.. this is bananas\" => \"0 2  2     aa     ppppooo.....ttiiissssa\"\n",
      "batch 1042  loss=260.3472  steps/s=99.67  prediction: \"ecursive thread\n",
      "\n",
      "https://t.co/sc1GSL4fJx\" => \"p y:t@tiirrrhehhhhhhttt\n",
      "t//////ssssscSS1\"\n",
      "batch 1043  loss=251.1533  steps/s=103.25  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"eope\n",
      "/tttttUIUIMMhhhpppppptt////DOOOOOJA\"\n",
      "batch 1044  loss=185.0486  steps/s=102.97  prediction: \"on\n",
      "\n",
      "im guessing you do that a lot to huh\" => \"r  ittm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ssssgguuooooo      tttttthh\"\n",
      "batch 1045  loss=181.0632  steps/s=102.33  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"tegeneeell       ttttttttss:://////DDDjX\"\n",
      "batch 1046  loss=190.7087  steps/s=102.15  prediction: \" instead of main https://t.co/K187NvFlSA\" => \"tsstentttte           ttttttt/////Kc/17F\"\n",
      "batch 1047  loss=221.1089  steps/s=93.65  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \"u sniohooohhhh  ggggggssgeso\n",
      "\n",
      "\n",
      "W\n",
      "Willl ðŸ›‘\"\n",
      "batch 1048  loss=225.4243  steps/s=86.95  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \"rfy:         ooooooottttttttt://///PPNNN\"\n",
      "batch 1049  loss=207.9388  steps/s=102.34  prediction: \"ellectus @gfodor https://t.co/Emux6iPInC\" => \"rl I telltttecggffhhhhttt////////mmm6Exx\"\n",
      "batch 1050  loss=191.1758  steps/s=103.29  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tfsassapppooo    sssttttttt)iwwwwwaaaaaa\"\n",
      "batch 1051  loss=186.7237  steps/s=105.36  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"em i ((iddddeeeeeetttttttt///////cc35YKs\"\n",
      "batch 1052  loss=194.8051  steps/s=103.16  prediction: \"n\n",
      "Meet the new boss\n",
      "Same as the old boss\" => \"  sin  eeeeeeeee     ssssssssS        oo\"\n",
      "batch 1053  loss=171.1215  steps/s=104.39  prediction: \"cast he became push hands world champion\" => \"knf ho hsssceeeeeeeeaahhhh       dddddpp\"\n",
      "batch 1054  loss=203.7608  steps/s=103.42  prediction: \" srsly the golden age of building things\" => \"aoo,ls sss         eeeeegg    dddddiiiii\"\n",
      "batch 1057  loss=214.0431  steps/s=91.14  prediction: \"5 custom tools speed things up a TON tbh\" => \" \", s7x tttoooooooooeeeeesiiiiu         \"\n",
      "batch 1058  loss=166.8723  steps/s=102.81  prediction: \"like a really really interesting project\" => \"yn  D e      llllllllyyyyrrreeeeiiiitntt\"\n",
      "batch 1059  loss=238.3302  steps/s=99.70  prediction: \" giz tarantinos alt?????? this shit fire\" => \"@i ziz g   aaaaaaatttt?tt???????tstts  i\"\n",
      "batch 1062  loss=228.0713  steps/s=101.00  prediction: \"here you go mate\n",
      "https://t.co/oR4fVr3TMW\" => \"ela Yeee         ooohhttttttttt/////RoV4\"\n",
      "batch 1063  loss=170.6262  steps/s=103.40  prediction: \"ttin you do all that stuff, drop out etc\" => \"   yod       o         tttttttffffuuu   \"\n",
      "batch 1065  loss=172.2969  steps/s=104.11  prediction: \"er? What does that corner look like? Etc\" => \" ets r rWrW     tttttttoooooooooookkkkkl\"\n",
      "batch 1066  loss=170.1686  steps/s=95.46  prediction: \"pmillyair lichess is like 200 elo higher\" => \"ly: @saalllllliillsssssss      0000    e\"\n",
      "batch 1067  loss=201.5516  steps/s=98.94  prediction: \"yup totally agree. Very powerful mindset\" => \":u@suau      aaaal eeeeeeyyrrrrrrrr rr  \"\n",
      "batch 1068  loss=154.6539  steps/s=90.47  prediction: \"ntellectus To beat paranoia, accept risk\" => \" reaaHtltltttteee      aaaaaaaaaaaaccccc\"\n",
      "batch 1069  loss=169.2318  steps/s=104.68  prediction: \"is new wave of RL stuff im seeing lately\" => \"n bh\n",
      "     wwwww       ffffff  sse iieeee\"\n",
      "batch 1070  loss=164.7544  steps/s=89.88  prediction: \"qc Based, a true warrior of the zig army\" => \"c,e t  aae aaaa    uurrrrrrrrro       gg\"\n",
      "batch 1071  loss=176.5426  steps/s=105.26  prediction: \", write one sentence after another, andâ€¦\" => \" wbd d       eeeeeeeeeneeeetttttttt   aa\"\n",
      "batch 1072  loss=153.9966  steps/s=105.06  prediction: \"ing ive wanted in life lol, complete 180\" => \"nenyvtiivvvii            lllllllllleeeee\"\n",
      "batch 1073  loss=171.7782  steps/s=104.84  prediction: \"ks suuuuper well\n",
      "https://t.co/kQAcIS3etz\" => \"i,s   s uuuuuuuuullllllpppptt///////cccc\"\n",
      "batch 1074  loss=159.0649  steps/s=100.50  prediction: \"almost as bad as jan blocking his bishop\" => \" d bbloossss   aaaaaaa a               i\"\n",
      "batch 1075  loss=139.8101  steps/s=99.55  prediction: \"trained though through practice, luckily\" => \" ea cbta   ee hhhhhhhhhhhhrrrrrrcccccccc\"\n",
      "batch 1077  loss=157.6917  steps/s=103.70  prediction: \"ks never knows\n",
      "Or... something like that\" => \"e t nccnkkkkkkkkerrr........sss         \"\n",
      "batch 1078  loss=158.3888  steps/s=104.81  prediction: \"ful if youre a complete beginner like me\" => \"er in i fffff          eeeeeeeeeeeeeeeee\"\n",
      "batch 1080  loss=131.8732  steps/s=97.14  prediction: \"is i need to make golden gate tetris bot\" => \"n , tennii               gggggg  eettttt\"\n",
      "batch 1081  loss=198.5378  steps/s=105.57  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tude eeeeeeeee      ttttttttttttt////SSS\"\n",
      "batch 1082  loss=145.4778  steps/s=104.11  prediction: \"do all of those\n",
      "\n",
      "https://t.co/C4hXOs7hck\" => \"  boy        oooooooooottttttttt///////h\"\n",
      "batch 1083  loss=140.1481  steps/s=103.80  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" t s oooooott               ddddeeeeeeee\"\n",
      "batch 1084  loss=122.6329  steps/s=29.80  prediction: \"ply: @calbch do it\n",
      "i double dog dare you\" => \"lye  ooottt              dddddeeeeeeeeee\"\n",
      "batch 1085  loss=135.6753  steps/s=57.14  prediction: \"eply: @mynamebedan head completely empty\" => \" loo  otttt       t   d ddedddeeeeeeeeee\"\n",
      "batch 1086  loss=163.5142  steps/s=108.52  prediction: \"f us have jobs)\n",
      "\n",
      "https://t.co/qTcrhcfjBM\" => \" y  o o             ssssssstttt////////c\"\n",
      "batch 1087  loss=153.3147  steps/s=89.89  prediction: \"neMTB i dream in ai generated js slop :/\" => \"  t  t a                 tteeeeeeeccjjjs\"\n",
      "batch 1088  loss=140.8101  steps/s=103.87  prediction: \"sed to sound like the opposite of curses\" => \" d tel                        oooooooooo\"\n",
      "batch 1089  loss=142.8862  steps/s=104.72  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"h e )o               tttttttttttttttt///\"\n",
      "batch 1090  loss=148.0009  steps/s=103.19  prediction: \"ve you ever worked for a fast food chain\" => \"e  loul        eeeeee                   \"\n",
      "batch 1091  loss=126.1856  steps/s=103.44  prediction: \" to get tons of llms to output good code\" => \"thee  tttttttttt                oooooooo\"\n",
      "batch 1092  loss=130.3996  steps/s=74.75  prediction: \"paeoh do it man!! making games is so fun\" => \"lr: oe oooo         m         gg o      \"\n",
      "batch 1093  loss=138.6216  steps/s=107.97  prediction: \"n theres ppl who dont code like this????\" => \" t t moeeeeeeee                         \"\n",
      "batch 1094  loss=128.4585  steps/s=105.31  prediction: \"ot even remotely the same as a beginners\" => \"u ssis     eeeeeeeeeeeeeeeee            \"\n",
      "batch 1095  loss=133.6707  steps/s=96.59  prediction: \"daily Whats your roadmap for learning ml\" => \" nt  ee e                 a a aaaaaannnn\"\n",
      "batch 1096  loss=137.4917  steps/s=104.22  prediction: \"many roadblocks trying to automate stuff\" => \"er  i               oo oo   ooootttttttt\"\n",
      "batch 1097  loss=175.4349  steps/s=83.82  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"u t   ooooooaa   y    OOOOOOoooto      t\"\n",
      "batch 1098  loss=146.8985  steps/s=105.90  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \": @naanaaaaassssssss                    \"\n",
      "batch 1099  loss=138.9894  steps/s=99.91  prediction: \" set at 5mins by default when unblocking\" => \"tid dt                                nn\"\n",
      "batch 1100  loss=143.3690  steps/s=105.75  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "Id   e                                 \"\n",
      "batch 1101  loss=136.7270  steps/s=104.08  prediction: \"essing\n",
      "You help cure that if you do this\" => \"  e esesssssssss                        \"\n",
      "batch 1102  loss=127.6244  steps/s=45.77  prediction: \"y: @thevalidcode Was just gonna say this\" => \": @ eeesssssss                          \"\n",
      "batch 1103  loss=132.7724  steps/s=107.32  prediction: \" and use it on everything\n",
      "\n",
      "epiphany trap\" => \"tnm et                     eeeeeeeeeennn\"\n",
      "batch 1104  loss=169.1811  steps/s=76.05  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"n  st e            tthhttttteiiiiiiiiipp\"\n",
      "batch 1105  loss=128.9638  steps/s=106.18  prediction: \" feel to be a tier above elon @teodor_io\" => \"toa  e                             eeeee\"\n",
      "batch 1106  loss=126.9577  steps/s=103.50  prediction: \"have primitives if you look close enough\" => \"e   i iviiiiiiiiiiiiiiiiii           ooo\"\n",
      "batch 1107  loss=134.7130  steps/s=57.87  prediction: \" @sunsettler all my homies HATE openings\" => \"tpeev iiiiiiiiiii        o         ooooo\"\n",
      "batch 1108  loss=133.8626  steps/s=108.01  prediction: \"ining data. The loss went down over time\" => \"n tetennnaaaaaaaaaaa                    \"\n",
      "batch 1109  loss=126.7697  steps/s=104.74  prediction: \"o make a significant impact on your life\" => \"ug a a          iiiiiiiiiiiiii          \"\n",
      "batch 1110  loss=195.3797  steps/s=102.86  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e e                                    ?\"\n",
      "batch 1111  loss=179.8513  steps/s=100.28  prediction: \" procedural NeRF https://t.co/A06xxbVMPi\" => \"tTa e lllllllllllllFFFF       ttt///////\"\n",
      "batch 1112  loss=164.6815  steps/s=11.20  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"ese : @llllllllllFFFFFF      ttt///////x\"\n",
      "batch 1113  loss=141.1870  steps/s=152.81  prediction: \" a friend that did this for a CS project\" => \"tna               t tttttttt            \"\n",
      "batch 1114  loss=155.7702  steps/s=100.72  prediction: \"meone should make a zig finetune dataset\" => \"ere @looooooooooooo                   ee\"\n",
      "batch 1116  loss=138.3364  steps/s=104.89  prediction: \" loss (erroneously a vector) as a scalar\" => \"tei eh         ooooooo                  \"\n",
      "batch 1117  loss=194.5135  steps/s=11.01  prediction: \"reply: @mov_axbx https://t.co/Cmpmv44btj\" => \"epl d         ooooooo     oo            \"\n",
      "batch 1118  loss=122.1656  steps/s=110.90  prediction: \"ink thats gonna be a massive rabbit hole\" => \"n  i  tttttttttt              aaaaabbbbb\"\n",
      "batch 1119  loss=134.1703  steps/s=97.62  prediction: \"see more details as you unblur an image.\" => \"  i             eeee                    \"\n",
      "batch 1120  loss=169.4295  steps/s=21.57  prediction: \"eply: @kayzee_ow https://t.co/y0ck4lbyrK\" => \" lo: @          ee                      \"\n",
      "batch 1121  loss=160.0500  steps/s=144.29  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u@ e e7                tttt//tt t//////\"\n",
      "batch 1122  loss=144.2225  steps/s=96.58  prediction: \"a Meet the new boss\n",
      "Same as the old boss\" => \"ns oo 7a     eeeeeeeeeee  sssssssssss   \"\n",
      "batch 1123  loss=145.1895  steps/s=100.33  prediction: \"nvestor\n",
      "\n",
      "Simpleagreementforfuture Equity\" => \"  m i  nnnnnn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1124  loss=138.4668  steps/s=100.76  prediction: \"ill consider leaning into it more though\" => \"ng n                 iiiniiiiiiii       \"\n",
      "batch 1126  loss=128.1556  steps/s=103.61  prediction: \"ly  small gif editing, it should be fine\" => \"y:  co       llllll           i         \"\n",
      "batch 1127  loss=129.3424  steps/s=97.25  prediction: \"iplying cells literally changed my life.\" => \"nl  e llllllllllllllllllllllllllll      \"\n",
      "batch 1128  loss=137.2294  steps/s=104.90  prediction: \"per curious to see what youre working on\" => \"lr\n",
      "  ia                                 \"\n",
      "batch 1129  loss=134.0868  steps/s=101.28  prediction: \" pried the shift key off w a screwdriver\" => \"tapeaaaa                                \"\n",
      "batch 1130  loss=149.5739  steps/s=100.06  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"tn                         sssssss//////\"\n",
      "batch 1131  loss=134.7248  steps/s=100.30  prediction: \"great great thurs\n",
      "key was blocking x lol\" => \"   i    ggg  tttttttttttttt             \"\n",
      "batch 1132  loss=136.3638  steps/s=103.64  prediction: \"ey once, will play otb w friends usually\" => \"                                        \"\n",
      "batch 1133  loss=167.3088  steps/s=99.62  prediction: \" procedural NeRF https://t.co/A06xxbVMPi\" => \"tra y lllllrllrrr           tttt////////\"\n",
      "batch 1134  loss=143.7272  steps/s=104.99  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"e gee          eeeeeeeeeeeeeeeeeeeeeeett\"\n",
      "batch 1135  loss=135.5963  steps/s=105.05  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"ly: @m                       eeeeeeaa   \"\n",
      "batch 1136  loss=147.2434  steps/s=100.84  prediction: \" w as in why tf would you use white mode\" => \"taeeere                                 \"\n",
      "batch 1137  loss=139.1561  steps/s=101.66  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"r    onoooooooooooo          eeeeeeeeeee\"\n",
      "batch 1138  loss=149.0103  steps/s=61.41  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"ltdpoenoo oooooooo       eeeeee   eeeooo\"\n",
      "batch 1139  loss=137.8156  steps/s=111.23  prediction: \"dering what was on that list, thanks man\" => \" va  na      wwwwwww             ttttttt\"\n",
      "batch 1140  loss=129.8494  steps/s=104.81  prediction: \"iterate certain ppl, but those are large\" => \"ne  o l     attttttt      tttt          \"\n",
      "batch 1141  loss=148.9866  steps/s=99.58  prediction: \"nally get monads\n",
      "https://t.co/lYN3cpV8JV\" => \" MTB t                 ttttttttttttt////\"\n",
      "batch 1142  loss=130.5393  steps/s=101.81  prediction: \"u can build in a week is actually insane\" => \"sf oom                                  \"\n",
      "batch 1143  loss=146.9091  steps/s=101.57  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"  e    veeeeeeeeeettttttttttttttttt/////\"\n",
      "batch 1144  loss=184.8363  steps/s=102.67  prediction: \" QUICK delete this before sphere sees it\" => \"teoe  r reeeeeeeetttteeeeeetesseeeeeeree\"\n",
      "batch 1145  loss=140.6578  steps/s=105.45  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  lo     rrrrrrrrreeeeeeeeeeoooooooooll\"\n",
      "batch 1146  loss=176.0127  steps/s=102.12  prediction: \"cost) is probably a better way to put it\" => \"aml bleeeeetiiiibbbbbbbbbbbbb           \"\n",
      "batch 1147  loss=160.5678  steps/s=105.50  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \" &f g g                         gggggggg\"\n",
      "batch 1148  loss=166.1045  steps/s=11.31  prediction: \"reply: @ludwigABAP @0xluffyb just be you\" => \"ep og n                        ggggggggg\"\n",
      "batch 1149  loss=144.2459  steps/s=52.56  prediction: \"reply: @cachecrab ah, the french defense\" => \"eplog n                  t    ggggggggg \"\n",
      "batch 1150  loss=136.9630  steps/s=108.05  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" trits                                  \"\n",
      "batch 1151  loss=145.9621  steps/s=100.18  prediction: \"Lynx the less you talk the more you walk\" => \"o o w t                      t          \"\n",
      "batch 1153  loss=130.4496  steps/s=76.34  prediction: \"cows a truly great ideasguy will execute\" => \"irc                   ttt            lll\"\n",
      "batch 1154  loss=129.3798  steps/s=106.78  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"&rta                                    \"\n",
      "batch 1155  loss=152.0930  steps/s=92.31  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"x 0uy t t         eeeeeeee          oooo\"\n",
      "batch 1156  loss=159.7639  steps/s=101.19  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"@ete t         ffff         ttttt///////\"\n",
      "batch 1157  loss=134.3255  steps/s=100.11  prediction: \"term, informative/useful is more memetic\" => \" xne  h        n  iiieeeeeeeeeee emmmmmm\"\n",
      "batch 1158  loss=142.6498  steps/s=104.30  prediction: \"ed something about that, not sure though\" => \"      eeeeeeeeeeee        tttttttttttttt\"\n",
      "batch 1160  loss=137.4069  steps/s=83.54  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \" y s  eeeeennn u         ooooooooo ooo  \"\n",
      "batch 1161  loss=161.8103  steps/s=23.68  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"uthseheeennnnn  n        ooooooo o  oo  \"\n",
      "batch 1162  loss=131.2738  steps/s=75.78  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"ly: @u eennnnn  nn    oo ooooooo o   t  \"\n",
      "batch 1163  loss=136.1445  steps/s=106.84  prediction: \" works if you did it right, or it doesnt\" => \"th t                                    \"\n",
      "batch 1164  loss=128.3807  steps/s=104.11  prediction: \"r, it felt a little linkediny over there\" => \"e iy: ttttttttttttttttttlllllllli    eee\"\n",
      "batch 1165  loss=136.8535  steps/s=105.12  prediction: \"per curious to see what youre working on\" => \"lr    a                                 \"\n",
      "batch 1166  loss=161.2450  steps/s=103.68  prediction: \"hackers #buildinpublic #developers #SaaS\" => \"et steeeeeeeeeiiiiiiiiiiiiiiiiiieeeeeeee\"\n",
      "batch 1167  loss=243.6375  steps/s=101.68  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"S   W t  EEEEETTTTTTTT           ///////\"\n",
      "batch 1169  loss=160.1877  steps/s=96.82  prediction: \"joane College is super early in life tbh\" => \"istm  TT                                \"\n",
      "batch 1170  loss=131.9240  steps/s=100.22  prediction: \"nt know if you were wrong abt everything\" => \"de nettooo           wwwwww            e\"\n",
      "batch 1171  loss=134.3955  steps/s=105.55  prediction: \"g real and distracted from the adventure\" => \" tec                  ddddddd         ee\"\n",
      "batch 1172  loss=129.5453  steps/s=101.20  prediction: \" quarter is another kinda similar banger\" => \"te  eeee                          iiiiaa\"\n",
      "batch 1173  loss=146.5523  steps/s=104.37  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"eplye  e                            iiii\"\n",
      "batch 1174  loss=135.7723  steps/s=102.23  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"eli        eeeeeeeeeee                  \"\n",
      "batch 1175  loss=167.1074  steps/s=103.99  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"some  \n",
      "///////////tttttt                \"\n",
      "batch 1176  loss=174.7534  steps/s=104.18  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \"  tT\n",
      " DDD AAAAAAAAAAA              /////\"\n",
      "batch 1177  loss=150.9725  steps/s=101.89  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \"    t ttttttttttttttttttttttttttt///////\"\n",
      "batch 1178  loss=130.8458  steps/s=105.23  prediction: \" way you perceive the world and yourself\" => \"tae                   eeeeeeee          \"\n",
      "batch 1179  loss=137.8443  steps/s=104.11  prediction: \"ective if that's what you're referencing\" => \" ie e  eeeeeeee           t  '''    eeee\"\n",
      "batch 1180  loss=135.0453  steps/s=51.89  prediction: \": @teodor_io funny number go up type shi\" => \" @aa0eeee iiiii    t    '''      eeeeeee\"\n",
      "batch 1181  loss=128.9541  steps/s=108.15  prediction: \"that was probably its entire purpose lol\" => \" ehi ietttttttttt                       \"\n",
      "batch 1182  loss=171.2668  steps/s=102.16  prediction: \" 4min miles, need to know whats possible\" => \"ttt i                                   \"\n",
      "batch 1184  loss=138.2985  steps/s=94.10  prediction: \"y based. how do you compile zig to wasm?\" => \":c@gi m               ooooooo     o     \"\n",
      "batch 1185  loss=138.3446  steps/s=97.90  prediction: \"yacine needs a dingboard wrap on his car\" => \":c@ge 0y000  e   d     ddddd            \"\n",
      "batch 1186  loss=130.1087  steps/s=104.77  prediction: \" different distribution of training data\" => \"tov eeeeeeeeeeeeeeeettiiiiiiiiiiiiiiiiii\"\n",
      "batch 1187  loss=175.6201  steps/s=99.45  prediction: \"ein @DrBrianKeating yea he made a portal\" => \" ntee@iiiiiiiiiinnnnnnnnne  aaaaaaaa    \"\n",
      "batch 1188  loss=136.7496  steps/s=100.16  prediction: \" to make it better before (if) I release\" => \"th e eeeee          eeeeeeeeeeeee   eeee\"\n",
      "batch 1189  loss=138.2095  steps/s=93.24  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"h n neeeee tttttr t  or     oo      eeee\"\n",
      "batch 1190  loss=110.1688  steps/s=72.48  prediction: \"sunsettler hes locked in to the outdoors\" => \" nnet sstttttrrrr   oooo oooooo oo  oodd\"\n",
      "batch 1191  loss=129.4871  steps/s=106.56  prediction: \" selected\n",
      "\n",
      "Or better yet skip selection?\" => \"tu  nnttttttteeeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1192  loss=187.7070  steps/s=97.92  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"oWS7  saEEEEEOOOOOOOOOOOtttt            \"\n",
      "batch 1193  loss=138.8666  steps/s=99.12  prediction: \" cs maps btw? would love to see pictures\" => \"ta   o                                  \"\n",
      "batch 1194  loss=141.5398  steps/s=106.47  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "oa  ur    n                            \"\n",
      "batch 1195  loss=131.9620  steps/s=104.52  prediction: \"every useful thing I do the cooler it is\" => \" e e  eeeeeeeeeeeee                     \"\n",
      "batch 1196  loss=125.1011  steps/s=98.66  prediction: \"hnote uuuh i have a license for thse sir\" => \"esee rseeuuuuuuuuu             ee      s\"\n",
      "batch 1197  loss=130.3527  steps/s=103.98  prediction: \"then add audio and make it a vid editor.\" => \" e  d o     dddddddddddaaaa             \"\n",
      "batch 1198  loss=129.4361  steps/s=104.42  prediction: \"knesses and imbalances, using space, etc\" => \"e glniieeeeeeeeeeaaaaaaaasssssssssssssss\"\n",
      "batch 1199  loss=136.4526  steps/s=105.85  prediction: \"ve to somewhere else\n",
      "\n",
      "idk just a thought\" => \"e te  e    oeeeeeeeeeeeeeeeeeeee        \"\n",
      "batch 1200  loss=130.7111  steps/s=105.53  prediction: \"ting your axioms can bring immense alpha\" => \"  t ereaaaaaaaaaaaaaa                   \"\n",
      "batch 1201  loss=134.6808  steps/s=105.18  prediction: \"be helpful, so I recommend taking a look\" => \"et d bbbbllllllll                       \"\n",
      "batch 1202  loss=180.5491  steps/s=105.04  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OO\n",
      "\n",
      "a                       tttt////////\"\n",
      "batch 1203  loss=140.2815  steps/s=96.38  prediction: \"tters job was a good man\n",
      "\n",
      "God is amazing\" => \"  t   sssss               aooooooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "batch 1204  loss=178.6821  steps/s=21.19  prediction: \"eply: @yacineMTB https://t.co/ONnUwL3VIM\" => \" lyt   ssss            /  aooooooo\n",
      "\n",
      "\n",
      "\n",
      "an\"\n",
      "batch 1205  loss=138.0910  steps/s=108.67  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"th   i                        aaaaaaaaaa\"\n",
      "batch 1206  loss=200.8200  steps/s=21.29  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" l i                        aaaaaaaaaaaa\"\n",
      "batch 1207  loss=133.6057  steps/s=113.03  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"tn tt         lllllllllllllllllllllllll \"\n",
      "batch 1208  loss=130.7849  steps/s=101.67  prediction: \"interested to hear how well it works our\" => \"n  ni             eeeeeeeee             \"\n",
      "batch 1209  loss=131.5603  steps/s=90.39  prediction: \"bly same, llms are so much faster though\" => \"ey  ii eeeee  e e                      r\"\n",
      "batch 1210  loss=133.3810  steps/s=103.77  prediction: \" wasnt paying attention during that part\" => \"ta t            aaaaatttttnnnnnnnnnntttt\"\n",
      "batch 1212  loss=127.6419  steps/s=104.46  prediction: \"through hoops\n",
      "\n",
      "its harder, until its not\" => \" enoe    hhhhhhhhhhhhhhhhhhh            \"\n",
      "batch 1213  loss=128.5733  steps/s=73.96  prediction: \"unsettler Ive made a few, its fun indeed\" => \"   t  thhoooooo              ,,   i    n\"\n",
      "batch 1214  loss=148.3397  steps/s=106.21  prediction: \"nt ask for almost bricked my work laptop\" => \"  hh a                                  \"\n",
      "batch 1215  loss=128.9961  steps/s=98.04  prediction: \"feeling than automating hrs of work away\" => \" r   eeeee     a  aaaaaaaa             o\"\n",
      "batch 1217  loss=175.7200  steps/s=58.74  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tMeett eeete     atttttttt     ooo     w\"\n",
      "batch 1218  loss=130.2225  steps/s=114.61  prediction: \"ke getting flashbanged by your teammates\" => \"  a rtiiiiiiiii     gggggggg            \"\n",
      "batch 1219  loss=128.7509  steps/s=98.01  prediction: \" is nice. idk much about distros tho lol\" => \"tt e  nnnn                           ttt\"\n",
      "batch 1220  loss=151.5755  steps/s=101.16  prediction: \"s man. i try to keep it real as they say\" => \" ar   a                                 \"\n",
      "batch 1221  loss=151.5856  steps/s=104.14  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nt t o           ttttttttttt/////////ttt\"\n",
      "batch 1222  loss=135.1463  steps/s=105.78  prediction: \"hings and learn from that\n",
      "\n",
      "yea, idk, lol\" => \"en  t                        aaaaaaaa   \"\n",
      "batch 1223  loss=151.7750  steps/s=104.27  prediction: \"ke half my followers came from shoutouts\" => \"e l lllllllllllllllllll             oooo\"\n",
      "batch 1224  loss=168.3709  steps/s=95.07  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nA AP  Ayyyygyyyyyyyyyooooooo  ooottt///\"\n",
      "batch 1225  loss=135.9370  steps/s=50.33  prediction: \": @sunsettler SAP is gonna go hella hard\" => \" @Auo uyyyggggyy  o   ss ooooo//////////\"\n",
      "batch 1226  loss=133.0377  steps/s=110.72  prediction: \"ve you been unlocking yourself each time\" => \"e  io               nnnnnnnnnnn  eeee ee\"\n",
      "batch 1227  loss=135.0257  steps/s=100.59  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"@tld l                                  \"\n",
      "batch 1228  loss=136.1445  steps/s=97.78  prediction: \"end to work, and they pretend to pay us\"\" => \" tl: @ee                                \"\n",
      "batch 1229  loss=136.8654  steps/s=101.41  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"y  @du               ttttttttttttttt////\"\n",
      "batch 1230  loss=131.7710  steps/s=101.38  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \" et e        aaaaaaaaaaaaaaaaaaaaa    ee\"\n",
      "batch 1231  loss=122.8465  steps/s=104.53  prediction: \"they are more than happy to pay for them\" => \"he    eeeeeeeeeee                       \"\n",
      "batch 1232  loss=126.7849  steps/s=98.65  prediction: \"s Chat with your cat in the hat on a mat\" => \" tf t e                                 \"\n",
      "batch 1233  loss=140.6853  steps/s=104.12  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes              tttttttttttttttttttt///\"\n",
      "batch 1234  loss=135.6827  steps/s=105.28  prediction: \"it anymore. Now she can go get groceries\" => \"n  ad a                                 \"\n",
      "batch 1235  loss=132.3159  steps/s=103.20  prediction: \"would be insanely useful to do this with\" => \"itlme ioooo          eee                \"\n",
      "batch 1236  loss=132.5832  steps/s=103.96  prediction: \"se? seems like death spiral potential no\" => \"  ee eeeeeeeeeeeeeeeeeee                \"\n",
      "batch 1237  loss=138.2924  steps/s=72.39  prediction: \"xluffyb Its almost side project saturday\" => \" ee  eee          s sssss    pppptttttta\"\n",
      "batch 1239  loss=123.9297  steps/s=108.12  prediction: \"t leak info from the stream accidentally\" => \"hins                                  aa\"\n",
      "batch 1240  loss=175.0255  steps/s=94.19  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \"AP 0a                               EEEE\"\n",
      "batch 1241  loss=129.4997  steps/s=103.35  prediction: \"setup is going to be a bit different tho\" => \" l    o                                 \"\n",
      "batch 1242  loss=146.6993  steps/s=102.11  prediction: \"l. but really, I have absolutely no clue\" => \"y  ugnp                        lllllllll\"\n",
      "batch 1243  loss=129.1574  steps/s=101.23  prediction: \"o feel cool writing in an alien language\" => \" ta   e                           nnnnnn\"\n",
      "batch 1244  loss=135.8411  steps/s=104.21  prediction: \"a recent nvim noob Tutor is super useful\" => \"nm   y                                uu\"\n",
      "batch 1245  loss=140.0461  steps/s=103.42  prediction: \"owing that your food supply doesnt scale\" => \"u  i   tttttttttt              oo       \"\n",
      "batch 1246  loss=144.1171  steps/s=100.60  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y w@wsssssssssssssssssssssstttttttt/////\"\n",
      "batch 1247  loss=156.9490  steps/s=99.68  prediction: \"zzl\n",
      "\n",
      "Or maybe he got it from someone idk\" => \"moBu r  zzzzz                           \"\n",
      "batch 1248  loss=142.4275  steps/s=104.68  prediction: \"ion==intelligence is wild rabbithole man\" => \"nn o...ssssiiiinniiiiiiiiiiiiiiiiiiiiiil\"\n",
      "batch 1250  loss=163.2463  steps/s=82.48  prediction: \"wlearning \"Pricing it in\" now 15% faster\" => \"iesseonnnnnnnniniiiiiiiiiiii  i         \"\n",
      "batch 1251  loss=127.6621  steps/s=75.07  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"tpre nneeenriiiiiiiiiiii                \"\n",
      "batch 1252  loss=128.1535  steps/s=105.97  prediction: \"useful directions to take the project in\" => \"sefgfeeeeeeeeeeeeee    t ttttttttt tt   \"\n",
      "batch 1253  loss=150.3862  steps/s=104.14  prediction: \"amming you can make bigger leaps though.\" => \"n  n2                       gggg        \"\n",
      "batch 1254  loss=138.5105  steps/s=100.28  prediction: \", Heaven and hell are both one step away\" => \" iot g     aaaaaaeeeee ee               \"\n",
      "batch 1255  loss=126.6193  steps/s=104.69  prediction: \"he result, its equivalent to convolution\" => \"er  rrrrrr               ttttttttttttttt\"\n",
      "batch 1256  loss=127.5238  steps/s=104.92  prediction: \" for  processing info and learning stuff\" => \"to   o                        nnnnnnnnnn\"\n",
      "batch 1257  loss=152.0359  steps/s=97.80  prediction: \" stuff! Thanks, hope yours went well man\" => \"tot   oooo ssss                         \"\n",
      "batch 1258  loss=126.4901  steps/s=78.02  prediction: \"oppflightkid That could be helpful yeah!\" => \"ut s fpfffff k hTT              eellllll\"\n",
      "batch 1259  loss=124.9637  steps/s=82.25  prediction: \"@nlevnet that's a great thought actually\" => \"yrcpflttthttthhhh               elllllll\"\n",
      "batch 1260  loss=140.1721  steps/s=106.62  prediction: \"building logic gates and RAM and whatnot\" => \"ut l  bbbb                              \"\n",
      "batch 1261  loss=130.4627  steps/s=103.67  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "teat                                   \"\n",
      "batch 1262  loss=135.0071  steps/s=104.92  prediction: \"do 16hrs tmrw, test this and report back\" => \"  a t                   ttt             \"\n",
      "batch 1263  loss=150.9517  steps/s=101.97  prediction: \"papers\n",
      "ooh definitely examples are great\" => \"lr: @              eeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1264  loss=129.6159  steps/s=102.12  prediction: \"d size to whatever you want which helps.\" => \" at i                         wwwwwwhhhh\"\n",
      "batch 1265  loss=127.8003  steps/s=104.74  prediction: \"ink not tho, I believe in synthetic data\" => \"ng b      ttt                           \"\n",
      "batch 1266  loss=132.6572  steps/s=102.21  prediction: \"d xD but maybe its trying to communicate\" => \" s s l                                 t\"\n",
      "batch 1267  loss=132.4944  steps/s=104.01  prediction: \"m parts of your brain will want to do it\" => \"eae  r rrrrrtrr rrrrrr                  \"\n",
      "batch 1268  loss=140.4948  steps/s=103.07  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"   to     ooooooooo      ttttttt////////\"\n",
      "batch 1269  loss=134.3069  steps/s=104.66  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \"ue      00      0000000000              \"\n",
      "batch 1270  loss=190.3373  steps/s=99.79  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \" tato/oto\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sssseeeeeeeeeeeeeeeeee\"\n",
      "batch 1271  loss=172.8354  steps/s=86.97  prediction: \"by_builds another $20 trillion to ludwig\" => \"e  sssbebbillssllttteteeee lllllllllli  \"\n",
      "batch 1272  loss=135.0564  steps/s=105.03  prediction: \"ploring become really clear to your mind\" => \"ly:  oa        eeeeeeeeeeelllllll       \"\n",
      "batch 1273  loss=218.2295  steps/s=104.56  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \"2,10zzTTTlll00MMMMMMMMMMLLLLL00000tttttt\"\n",
      "batch 1274  loss=136.4438  steps/s=103.08  prediction: \"er important first step towards progress\" => \"     o         rrrrrttttttttttttttttrrrr\"\n",
      "batch 1275  loss=129.3307  steps/s=103.92  prediction: \"ything rewarding that follows from that)\" => \"  @a iiiiieerrrrrrrrrrrr                \"\n",
      "batch 1277  loss=145.1425  steps/s=105.14  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"t..cet////////ttttttttttttttttt/////////\"\n",
      "batch 1278  loss=164.0121  steps/s=97.57  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"etll: @tnnnnnnnthhhhh8888hhh  hhh       \"\n",
      "batch 1279  loss=128.5423  steps/s=104.78  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"eply     rrreeeeettttttttttteeeetttteeee\"\n",
      "batch 1280  loss=167.2355  steps/s=21.03  prediction: \"eply: @rcx86 Thank God\n",
      "I hope nobody did\" => \" lsa  rrrrreeeeettttttttttereettttteeeee\"\n",
      "batch 1281  loss=142.9606  steps/s=114.57  prediction: \" that initially seemed meaningless to me\" => \"the e e        iiiiiiiieeeeeeeeeeeeeeeee\"\n",
      "batch 1282  loss=130.0678  steps/s=95.80  prediction: \"daily Whats your roadmap for learning ml\" => \" s he lliiaaaaaa          aaaaaaaa      \"\n",
      "batch 1283  loss=153.6232  steps/s=45.48  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @l lllhiaaayy      aa     rraaaann    \"\n",
      "batch 1284  loss=145.1519  steps/s=116.10  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"es y                  eeeeeeee  ttt/////\"\n",
      "batch 1286  loss=134.5837  steps/s=104.31  prediction: \"n a bit and just work later into the day\" => \"grho                              tttttt\"\n",
      "batch 1287  loss=129.5784  steps/s=100.92  prediction: \"s on the first? only read the abs so far\" => \" ilt  tt     tttt                       \"\n",
      "batch 1288  loss=134.9126  steps/s=103.89  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \" a                    eeeeeeeeeeeee iiii\"\n",
      "batch 1289  loss=136.3551  steps/s=105.94  prediction: \"e WAY more effective\n",
      "\n",
      "global optima gang\" => \" li i          eeeeeeeeeeeeeeeeeee      \"\n",
      "batch 1290  loss=128.8579  steps/s=104.38  prediction: \"started begging me to let him pay for it\" => \" al  t        gggggggggg                \"\n",
      "batch 1291  loss=186.1576  steps/s=24.93  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" lo  ttt     gggggggggge                \"\n",
      "batch 1292  loss=137.0906  steps/s=107.46  prediction: \"lity, not others, for what is true/false\" => \"ymt  r                                  \"\n",
      "batch 1293  loss=121.9743  steps/s=47.31  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  n    t  ttttt                         \"\n",
      "batch 1294  loss=138.2032  steps/s=109.84  prediction: \" learning how things work under the hood\" => \"tare aa                                 \"\n",
      "batch 1295  loss=128.8130  steps/s=101.24  prediction: \"onscious does work in the background idk\" => \"n y m bb  oosssssssooooo                \"\n",
      "batch 1297  loss=138.8124  steps/s=103.58  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \"e p opooooo\n",
      "\n",
      "\n",
      "\n",
      "                         \"\n",
      "batch 1299  loss=160.5114  steps/s=101.94  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \" on \n",
      " oooo                              \"\n",
      "batch 1300  loss=153.0080  steps/s=97.73  prediction: \"y childhood was nuketown 2025 and python\" => \":moy               h  oo      nn n      \"\n",
      "batch 1301  loss=160.5053  steps/s=99.51  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" e    hhhhhhes   ss  s                  \"\n",
      "batch 1302  loss=175.8294  steps/s=96.89  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"   i iiiii    rrr  rrrrrpttttttt////////\"\n",
      "batch 1303  loss=185.7770  steps/s=98.31  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \"  isieuuuuuuuuuuuuuuupp    ooooo OOOOTTT\"\n",
      "batch 1304  loss=143.5648  steps/s=106.00  prediction: \"e building an army of tiny little robots\" => \" s o                                    \"\n",
      "batch 1305  loss=139.2835  steps/s=75.04  prediction: \"oppflightkid That could be helpful yeah!\" => \"   O  iiiiiiiiii                lllllltt\"\n",
      "batch 1306  loss=160.9529  steps/s=108.73  prediction: \"EDM and caffeine\n",
      "https://t.co/xSA2QsenCw\" => \"Ts : in                tttttttt/////////\"\n",
      "batch 1307  loss=170.0722  steps/s=100.80  prediction: \" ðŸ¤” I need to work on my marketing skills\" => \"tjt  e                                kk\"\n",
      "batch 1308  loss=128.4860  steps/s=103.43  prediction: \"eft\n",
      "right looks right\n",
      "its a miracle init\" => \"   :lolllllllll       tttttttttiiiiiiiii\"\n",
      "batch 1309  loss=168.1861  steps/s=104.74  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"s gpniiiiii######aaaaaaaaasssssstt//////\"\n",
      "batch 1310  loss=134.3346  steps/s=105.47  prediction: \"et back up and get back at it eventually\" => \" e i  a                               tt\"\n",
      "batch 1311  loss=165.3221  steps/s=28.91  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly:  it                              ttt\"\n",
      "batch 1312  loss=148.5798  steps/s=108.35  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \" tdtse;;;;;gggggggtttttttttttt          \"\n",
      "batch 1313  loss=144.6344  steps/s=78.89  prediction: \"minus9 hmm still pixels on my end, weird\" => \"age&lt;gmmtmmmmmmmt tt xx               \"\n",
      "batch 1315  loss=136.6049  steps/s=105.99  prediction: \"t the truth/reality?\n",
      "\n",
      "sounds paradoxical\" => \" astpe       tttttttttttttttttttt\n",
      "\n",
      "aaaaa\"\n",
      "batch 1316  loss=141.9027  steps/s=101.02  prediction: \"em man, I had to share, its a crazy tool\" => \" ep  @                                  \"\n",
      "batch 1317  loss=148.3530  steps/s=79.72  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" ;et_t                       ????sssssss\"\n",
      "batch 1318  loss=123.2012  steps/s=61.37  prediction: \"y: @andyduboc genius concept for a piece\" => \": @aa  A                ????? ssssssssee\"\n",
      "batch 1319  loss=139.7559  steps/s=106.87  prediction: \"ve gradient it lives in? Something else?\" => \"ero ti  iiiiiiiiiiiiiiiiiiiii         ee\"\n",
      "batch 1320  loss=126.0387  steps/s=103.18  prediction: \"our life if you make work look like this\" => \"u    e                             kkkkk\"\n",
      "batch 1321  loss=137.9198  steps/s=104.35  prediction: \"ably already figured out some of my plan\" => \"ne  eeoooo     yyyyy                    \"\n",
      "batch 1322  loss=128.6452  steps/s=104.22  prediction: \"ing and shipping is gonna grow immensely\" => \"ng on   nnnppppppppppiiiinngggggg       \"\n",
      "batch 1323  loss=152.8274  steps/s=103.54  prediction: \"ork\n",
      "Until it did https://t.co/nY6zvVWYaH\" => \"u dnii        iiiitttttttttttttttttt////\"\n",
      "batch 1324  loss=131.9140  steps/s=105.73  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"eph                          ssuuuuussss\"\n",
      "batch 1325  loss=126.5522  steps/s=102.54  prediction: \"s. let the people decide. for danmocracy\" => \"  tet seeeeeeeeeeeeeeeeeeeeeeeeee ee   c\"\n",
      "batch 1326  loss=130.5086  steps/s=105.07  prediction: \"y areas of corporate world it seems like\" => \":a nue                 rrrrrrr          \"\n",
      "batch 1327  loss=141.7874  steps/s=103.67  prediction: \"d posted some CRAZY progress\n",
      "LETS GET IT\" => \" i        ddd                ssssssssss \"\n",
      "batch 1328  loss=131.6104  steps/s=104.74  prediction: \"iration theres some awesome ppl in there\" => \"n  nn  iiiiiiiiiir   eeeeeeeeeeeeeeeeeee\"\n",
      "batch 1329  loss=141.1887  steps/s=95.96  prediction: \"ki i have an idea but it will cost $1600\" => \"en jtiiiiiiee        a                  \"\n",
      "batch 1330  loss=140.2926  steps/s=104.66  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd toeeaaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1331  loss=153.7798  steps/s=99.12  prediction: \"its how i learned most of my tech skills\" => \"n  ue                                   \"\n",
      "batch 1332  loss=132.5918  steps/s=103.76  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \"n ibiaaaaaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oooooooo\"\n",
      "batch 1333  loss=124.7713  steps/s=104.88  prediction: \"had an eye for it meant maybe its useful\" => \"en  t                                   \"\n",
      "batch 1334  loss=138.2722  steps/s=105.78  prediction: \"snt, now i think and focus waaaay better\" => \" ee tt                           aaaaaaa\"\n",
      "batch 1335  loss=133.9917  steps/s=101.15  prediction: \"izing for optimizing for the right thing\" => \"n   e         iiiiiiiiiiiiiiiii         \"\n",
      "batch 1336  loss=152.7864  steps/s=100.50  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"e toep eeeeeeeeeeeeeeeoootttttttt///////\"\n",
      "batch 1337  loss=126.5411  steps/s=102.85  prediction: \"you have to learn in order to build them\" => \" ur                                     \"\n",
      "batch 1338  loss=128.3861  steps/s=102.13  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"eraaaa                                  \"\n",
      "batch 1339  loss=230.8921  steps/s=103.96  prediction: \"ST BACKPROPAGATE https://t.co/eFVShlRgdK\" => \"  o T BBBBBBBAAAAAAAAAAA        ////////\"\n",
      "batch 1340  loss=154.6188  steps/s=99.07  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e ly: @oo                               \"\n",
      "batch 1341  loss=140.3596  steps/s=101.78  prediction: \" is actually happening behind the scenes\" => \"@nee            aaaaaaaaaaaannnnnnnnneee\"\n",
      "batch 1342  loss=138.6878  steps/s=46.30  prediction: \"y: @astroButter @karpathy @MagnusCarlsen\" => \": @ e        ataaaaaaaaaahhnnnnnnn eneee\"\n",
      "batch 1343  loss=125.7327  steps/s=85.33  prediction: \": @moh1xabc i cooked so hard i burned it\" => \" @l @  attattt   aapaapphhh  nnn n eeeee\"\n",
      "batch 1346  loss=137.6169  steps/s=108.00  prediction: \"tebooks with 45 cells each, 4 docker imâ€¦\" => \" do e noooooooooo                       \"\n",
      "batch 1347  loss=127.9679  steps/s=103.94  prediction: \"d building things with skills new to you\" => \" at in      iiiiiiiiiiiiiiiiiiii        \"\n",
      "batch 1348  loss=140.9389  steps/s=104.72  prediction: \"the community give me energy to do these\" => \" e  e t                eeeeeeeeeeee     \"\n",
      "batch 1349  loss=131.4086  steps/s=104.95  prediction: \"whereas, its easy to tell which is timeâ€¦\" => \"ait  t  ttttteesssssssss                \"\n",
      "batch 1350  loss=147.5664  steps/s=101.53  prediction: \"(uvw)\n",
      "each cube contains a subcube (xyz)\" => \"ink\n",
      "ee         cccccccccccc      bbbbuub\"\n",
      "batch 1351  loss=147.4706  steps/s=99.82  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"td teett  ppppppsssssssssssssssttt//////\"\n",
      "batch 1352  loss=136.8427  steps/s=105.73  prediction: \"s of useful packages python would be ded\" => \" ai                                     \"\n",
      "batch 1353  loss=138.5090  steps/s=37.84  prediction: \"ly: @shurensha Done. Great advice. Ty ty\" => \"y   a                                   \"\n",
      "batch 1354  loss=129.3515  steps/s=127.06  prediction: \" gotchu fam\n",
      "sending the link as we speak\" => \"to n  e e              ee   nnnn        \"\n",
      "batch 1356  loss=136.8873  steps/s=102.34  prediction: \"is phrase and you will see it everywhere\" => \"n  rereeeeeeeee                      eee\"\n",
      "batch 1357  loss=139.9388  steps/s=101.95  prediction: \"at's definitely part of the current meta\" => \"n aeler     eeeeeettttttttt             \"\n",
      "batch 1358  loss=132.5199  steps/s=101.65  prediction: \"ill consider leaning into it more though\" => \"ne  d               iiinnnnniiiii       \"\n",
      "batch 1359  loss=141.1803  steps/s=104.11  prediction: \"rs automatically slap that down to 10fps\" => \"e eve        aaaaaaaaaaaaaaaaaaaatt     \"\n",
      "batch 1360  loss=154.8046  steps/s=79.62  prediction: \"x140201 @teodor_io start with the Gospel\" => \"erfrst0000000attoooooaaattttttttt       \"\n",
      "batch 1361  loss=134.0797  steps/s=105.92  prediction: \"as soon as there are melons in the shop)\" => \"ne                          e           \"\n",
      "batch 1362  loss=132.3561  steps/s=103.79  prediction: \"to a prompt, auto copied to my clipboard\" => \"                           ooo          \"\n",
      "batch 1363  loss=149.0569  steps/s=98.55  prediction: \"utput brothers karamazov, word for word\"\" => \"t  tA  uu t tttttttttrrrrrrrrrrrrrrrrrrr\"\n",
      "batch 1364  loss=163.3402  steps/s=105.92  prediction: \"bile and desktop https://t.co/f8MrtrXK28\" => \"etl sl  dddddddddddd     ttttttttt/////t\"\n",
      "batch 1365  loss=137.5652  steps/s=96.07  prediction: \"lex code across multiple (simple!) Files\" => \"ym o  o                       llllllllll\"\n",
      "batch 1366  loss=132.6500  steps/s=108.00  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"th g tttttttttttttttttaaaaaaaahhhhhhhhhh\"\n",
      "batch 1367  loss=127.6462  steps/s=103.35  prediction: \"e are, so it has a ton of ripple effects\" => \" t r  a                                 \"\n",
      "batch 1368  loss=124.5601  steps/s=104.15  prediction: \"ffect has it had on you? im very curious\" => \" eh e                                   \"\n",
      "batch 1370  loss=133.3603  steps/s=103.09  prediction: \"r tweet was epictetus's two handles idea\" => \"ewty  @       eeeeeeeeeeettttttttttt  ss\"\n",
      "batch 1371  loss=153.7909  steps/s=95.89  prediction: \"Thanks for joining! You guys are awesome\" => \"BeIih                o   o           eaa\"\n",
      "batch 1372  loss=130.8771  steps/s=103.17  prediction: \"ed hard at improving, mostly by studying\" => \"  y                                    y\"\n",
      "batch 1373  loss=131.4413  steps/s=104.28  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h  rr  o  ooooooooooooooo               \"\n",
      "batch 1374  loss=126.2347  steps/s=101.97  prediction: \"ld me, no clue lool\n",
      "\n",
      "its good to be back\" => \"y e@eoeee            llllllooooooooooooo\"\n",
      "batch 1375  loss=190.5030  steps/s=30.14  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @eoe          llllllloooooooooooo   \"\n",
      "batch 1377  loss=136.0140  steps/s=108.17  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"ni e ezmmmmiiiiii       tttttttttt//////\"\n",
      "batch 1378  loss=137.0402  steps/s=104.10  prediction: \"ace to both physical and mental reality.\" => \"ne nos                            aaaaaa\"\n",
      "batch 1379  loss=139.5226  steps/s=101.80  prediction: \"om gpt10 how strong could you make gpt2?\" => \"u : tatt                   oooooo       \"\n",
      "batch 1380  loss=138.7484  steps/s=100.14  prediction: \"free could help too if thats the problem\" => \" em otuuuuuuu                           \"\n",
      "batch 1381  loss=199.4881  steps/s=96.61  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tfc e                 tttttttttttt//////\"\n",
      "batch 1382  loss=126.0264  steps/s=104.52  prediction: \"etter but pretty good time bender though\" => \"  yo       tttttttttttttttttt           \"\n",
      "batch 1384  loss=140.8352  steps/s=99.31  prediction: \"king one open rn just cause of this post\" => \"enlerrCC                                \"\n",
      "batch 1385  loss=132.9397  steps/s=101.51  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \" e    i         iii i     sssssssssss   \"\n",
      "batch 1386  loss=181.9518  steps/s=29.24  prediction: \"ply: @sunsettler https://t.co/VV0NoHhCJz\" => \"lyt   i      iiii    s ssstssssssss     \"\n",
      "batch 1387  loss=119.6183  steps/s=114.27  prediction: \"tput something as unexpected as possible\" => \" l  t ttttttttttt         eeeeeeeeeeesss\"\n",
      "batch 1388  loss=136.4050  steps/s=103.90  prediction: \"e, i would also have liked to be yacine\"\" => \"                                        \"\n",
      "batch 1389  loss=136.4406  steps/s=102.31  prediction: \"ave been trying to compress these lately\" => \"cin n                            eeeeeee\"\n",
      "batch 1390  loss=130.2932  steps/s=103.87  prediction: \"eel free to run ideas by me whenever btw\" => \" t i  eeeeeeee                    eeeeee\"\n",
      "batch 1391  loss=137.2819  steps/s=81.93  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \" ieh  eeeee                      ee     \"\n",
      "batch 1392  loss=144.6667  steps/s=105.05  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly: @r                                oo\"\n",
      "batch 1393  loss=128.1129  steps/s=103.59  prediction: \"works for the first time is the most fun\" => \"ar    l                                 \"\n",
      "batch 1395  loss=126.7819  steps/s=102.11  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"e tilii                          iiiiiii\"\n",
      "batch 1396  loss=125.4374  steps/s=103.83  prediction: \"its bad but, it has pros you can play to\" => \"nh    s                                 \"\n",
      "batch 1397  loss=138.7393  steps/s=94.87  prediction: \"le77 if they install the meat addon, yes\" => \"yn @sii                           aa  aa\"\n",
      "batch 1398  loss=133.2865  steps/s=101.81  prediction: \"just happen to have sicilian parents lol\" => \"ust e e                           aaaa  \"\n",
      "batch 1399  loss=126.9852  steps/s=103.93  prediction: \"u ship cool things and make ppl have fun\" => \"sc tth                                  \"\n",
      "batch 1400  loss=129.0146  steps/s=98.68  prediction: \"ould get my ass handed to me for suuuure\" => \"   h                                  uu\"\n",
      "batch 1401  loss=129.4213  steps/s=103.98  prediction: \"good idea but whatever, i wanna have fun\" => \" r   n                           aaaaaaa\"\n",
      "batch 1402  loss=124.9558  steps/s=102.89  prediction: \"p infested regions of their latent space\" => \"ls:  o       eeeeeeeeeeeeee             \"\n",
      "batch 1403  loss=125.2533  steps/s=99.29  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @eeeeeeeeeerrrrrrrr               \"\n",
      "batch 1405  loss=142.7543  steps/s=103.89  prediction: \"e but it really is super flawed probably\" => \" lii   e                                \"\n",
      "batch 1406  loss=126.0848  steps/s=104.04  prediction: \"e the reward dips down below the average\" => \" ae   eeeeeeeeeeeeedddddddd             \"\n",
      "batch 1407  loss=136.2496  steps/s=103.67  prediction: \" since llms are not great with zig (ime)\" => \"tas                                     \"\n",
      "batch 1408  loss=135.5243  steps/s=88.03  prediction: \"neMTB @justalexoki the rise of carmacine\" => \"gMca   lls           eee               i\"\n",
      "batch 1409  loss=135.3898  steps/s=104.48  prediction: \"y cool implications, seems like it would\" => \":ciyae           iiiiiiiiiiiisssiii     \"\n",
      "batch 1410  loss=120.1396  steps/s=80.98  prediction: \"arcyan now you can make pokemon real too\" => \"ne on      c   ooo      m   kkke        \"\n",
      "batch 1411  loss=129.1594  steps/s=105.23  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng \n",
      "nneeeeeeeetttttttttttaaaaaaaaaaaaaaa\"\n",
      "batch 1412  loss=130.2466  steps/s=102.76  prediction: \"d this on there\n",
      "\n",
      "guard your signals boys\" => \" st an                                  \"\n",
      "batch 1413  loss=129.7722  steps/s=103.14  prediction: \"ce for an american traveling there soon?\" => \"ompnet        aaaaaaaaaaaaaaaaa rrreeeee\"\n",
      "batch 1414  loss=128.3306  steps/s=104.96  prediction: \" just be a webpage visit, its in browser\" => \"iu  ll                           iiiiiii\"\n",
      "batch 1415  loss=136.5957  steps/s=104.55  prediction: \"ing I wasted yrs not improving my skills\" => \"ng a                                    \"\n",
      "batch 1416  loss=151.5789  steps/s=104.31  prediction: \" mon), celebrating someones bday on both\" => \"ao                     eeeeeeeeeeeeeoooo\"\n",
      "batch 1417  loss=125.0938  steps/s=103.19  prediction: \"l possible golden gate bridge existences\" => \"yf oal        lllllll       eeeeeeeeeeee\"\n",
      "batch 1418  loss=128.5810  steps/s=91.64  prediction: \"nis @sunsettler sun yearns for the mines\" => \" t h  sssssssssssssseeee   e      ee    \"\n",
      "batch 1419  loss=194.5142  steps/s=65.13  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"atbrosbssseeeeessssst ttt   r           \"\n",
      "batch 1420  loss=137.9678  steps/s=107.79  prediction: \" absolutely mind blowing post all around\" => \"tlotla               ll                 \"\n",
      "batch 1421  loss=136.9552  steps/s=104.79  prediction: \"ncredibly painful, so a great motivator.\" => \"dihot cccccc   iiiiii                   \"\n",
      "batch 1422  loss=125.5906  steps/s=99.62  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \" tcI  eee            aaooooo  oooooaaaaa\"\n",
      "batch 1423  loss=142.7202  steps/s=105.21  prediction: \"e thing, not just messing around with it\" => \" tiat tttttttttt                        \"\n",
      "batch 1424  loss=137.9633  steps/s=103.27  prediction: \"s of adults\"\n",
      "\n",
      "i very often think of that\" => \" a00                                    \"\n",
      "batch 1425  loss=141.9495  steps/s=101.01  prediction: \" this long lost treasure of a song, damn\" => \"thr r                                   \"\n",
      "batch 1426  loss=138.8598  steps/s=25.51  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" lf                                     \"\n",
      "batch 1427  loss=133.3881  steps/s=110.07  prediction: \" (by trusting in ideas) and testing them\" => \"tytse  ttttttttt                        \"\n",
      "batch 1428  loss=150.8817  steps/s=97.52  prediction: \"ased. Me neither. This is the way to go.\" => \"n tyoteeeeeeeee   eeee                  \"\n",
      "batch 1429  loss=120.4232  steps/s=97.41  prediction: \"an esopost to english translator service\" => \"nisr weeee                 s tttttssssss\"\n",
      "batch 1431  loss=150.6497  steps/s=103.81  prediction: \"insanely OP\n",
      "One idea is to build usefulâ€¦\" => \"ngs a elllllnnnnnnnnnnn                 \"\n",
      "batch 1433  loss=133.5141  steps/s=104.64  prediction: \"our sword and over time makes you deadly\" => \"u in                                    \"\n",
      "batch 1434  loss=128.5167  steps/s=105.31  prediction: \"ume instead of a flat surface of a wafer\" => \"t  i                      fffffffffffffa\"\n",
      "batch 1435  loss=140.1273  steps/s=79.91  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \"   i e eeeeee      a               aaa  \"\n",
      "batch 1436  loss=166.5110  steps/s=106.67  prediction: \"gonna humble him\n",
      "https://t.co/HUMAzXB4rm\" => \" noa  u               mmtttttt/////////t\"\n",
      "batch 1437  loss=135.8188  steps/s=82.72  prediction: \"kul07 Nothing beats the classic todo.txt\" => \"i g u           hhhhtttttttttttccccssstt\"\n",
      "batch 1438  loss=138.5884  steps/s=105.88  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"h e  \n",
      "                 ttttttttttt//////\"\n",
      "batch 1439  loss=136.2921  steps/s=102.70  prediction: \"unctional adults that they interact with\" => \" d  se                tttttttttttttttttt\"\n",
      "batch 1440  loss=139.1600  steps/s=104.36  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt  ese      ff             ttt/////////\"\n",
      "batch 1441  loss=133.7137  steps/s=106.22  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"t                       ttttttt///////tt\"\n",
      "batch 1442  loss=155.3117  steps/s=102.31  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tude                         ///////////\"\n",
      "batch 1443  loss=135.1393  steps/s=100.61  prediction: \"efforts\n",
      "\n",
      "mcafee still remained installed\" => \" eteeeeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "fffffeeeeeeeeeeeeeeelll\"\n",
      "batch 1444  loss=163.5281  steps/s=103.59  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"do citt////////ttttttttttttt////////////\"\n",
      "batch 1445  loss=150.9843  steps/s=101.65  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" sr s sss???????????????kk              \"\n",
      "batch 1447  loss=139.9788  steps/s=103.66  prediction: \"amount of time, or did you just enjoy it\" => \"ne i                                    \"\n",
      "batch 1448  loss=143.6865  steps/s=103.63  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nn t tt                                 \"\n",
      "batch 1449  loss=133.9722  steps/s=100.95  prediction: \"ire effing timeline is circle tool posts\" => \"n   ne       eeeeeeeiiiiiiiiiiiiiii     \"\n",
      "batch 1450  loss=132.1768  steps/s=103.27  prediction: \"chnical debt kind of effect over time. F\" => \"oiin  h                             eeee\"\n",
      "batch 1451  loss=164.1856  steps/s=100.24  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"n  er        ttt tttttttttttttttttttttt/\"\n",
      "batch 1452  loss=142.8884  steps/s=101.67  prediction: \"blue, someone is working harder than you\" => \"ue   ee  eeeeeeeeeee                    \"\n",
      "batch 1454  loss=131.5599  steps/s=103.27  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"eph                           suuuuuusss\"\n",
      "batch 1456  loss=123.1372  steps/s=101.47  prediction: \" to get tons of llms to output good code\" => \"aheet tttttttttt                oooooooo\"\n",
      "batch 1457  loss=167.2057  steps/s=97.28  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tunenn                   ttttttttttttt//\"\n",
      "batch 1458  loss=134.9905  steps/s=102.89  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \"enp onooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    a    \"\n",
      "batch 1459  loss=142.6753  steps/s=104.48  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" a  fnnn                                \"\n",
      "batch 1460  loss=135.3957  steps/s=102.95  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"np           lllllllllllllllllllllllll  \"\n",
      "batch 1462  loss=140.3055  steps/s=105.12  prediction: \" by talking abt half done projects. BOOM\" => \"aeee                                    \"\n",
      "batch 1463  loss=202.5644  steps/s=11.62  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"esonr                                   \"\n",
      "batch 1464  loss=131.7279  steps/s=113.61  prediction: \" of your day your brain will work better\" => \"ane t                                   \"\n",
      "batch 1467  loss=139.8097  steps/s=101.68  prediction: \"Tex prob huge dollars in anti drone bots\" => \" x t eeeeeeeeeee eee                    \"\n",
      "batch 1468  loss=130.2278  steps/s=103.44  prediction: \"ich is a great way to find opportunities\" => \"ne    iiiii                             \"\n",
      "batch 1469  loss=202.4456  steps/s=10.99  prediction: \"reply: @gizmobly https://t.co/Lz4uSVD7Gv\" => \"ept i iiiii                            t\"\n",
      "batch 1470  loss=201.4688  steps/s=129.62  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"N     NGGGSLGGLLLLLLGNALLLSt/ttttt//////\"\n",
      "batch 1471  loss=175.4303  steps/s=98.71  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"ene cnnnn                        ddddddd\"\n",
      "batch 1472  loss=154.3113  steps/s=103.71  prediction: \"ooks like from someone elses perspective\" => \"urha              ooooooooeeeeeeeeeeeeee\"\n",
      "batch 1473  loss=137.7681  steps/s=105.24  prediction: \"ould help large numbers of ppl if solved\" => \"r  erer     lllllllll                   \"\n",
      "batch 1474  loss=139.2103  steps/s=100.14  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"tod            aaaaaaaaaaaa             \"\n",
      "batch 1475  loss=180.8279  steps/s=48.04  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \"  @ _        aaaaaaa                    \"\n",
      "batch 1476  loss=118.6057  steps/s=119.07  prediction: \"o the door the instant she hears it open\" => \"rt n t t              tttt              \"\n",
      "batch 1477  loss=148.2549  steps/s=100.39  prediction: \"s a crazy valuable source of improvement\" => \" daftaaaaaaaaaaaaaaaaaa                 \"\n",
      "batch 1478  loss=137.4476  steps/s=106.25  prediction: \", how much info could you get from that?\" => \" and i                                  \"\n",
      "batch 1479  loss=139.4544  steps/s=101.47  prediction: \"blue, someone is working harder than you\" => \"ei   eeeeeeeeeeeeeeeee                  \"\n",
      "batch 1480  loss=134.8153  steps/s=105.31  prediction: \"y fundamentals are hidden in plain sight\" => \" m naayyymmmmnnnaaaaaaaa                \"\n",
      "batch 1481  loss=139.6858  steps/s=104.72  prediction: \"s a man wanna build his own.. everything\" => \" asraaaaaaaaaaaaaaaaa                   \"\n",
      "batch 1483  loss=125.2143  steps/s=104.17  prediction: \"rself or others interested in something?\" => \"eot of     oooo    rrrreeeeeeeeeeeeeeeee\"\n",
      "batch 1484  loss=138.4249  steps/s=103.27  prediction: \"ductive. Its something im working on too\" => \" doso                          iiiii    \"\n",
      "batch 1485  loss=134.1606  steps/s=105.24  prediction: \" tons of stuff, for yrs, and that worked\" => \"ah t  t             ffffffff            \"\n",
      "batch 1486  loss=137.4816  steps/s=105.52  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"ls  e                tttttttttttt///////\"\n",
      "batch 1487  loss=131.1978  steps/s=105.01  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"tt                ttttttttttttttt///////\"\n",
      "batch 1489  loss=133.0314  steps/s=104.38  prediction: \"uff and just pretending to do side stuff\" => \"   l                    nnn             \"\n",
      "batch 1490  loss=130.9928  steps/s=104.01  prediction: \"an explanation that made sense to me lol\" => \"n   t           nnnnnaaaaaaaaaaa        \"\n",
      "batch 1491  loss=135.0808  steps/s=102.72  prediction: \"like there's more of a person there, idk\" => \"yteoasllleeeeeeeeeeeee                  \"\n",
      "batch 1492  loss=132.1618  steps/s=103.16  prediction: \"ion ability. should be trained first tbh\" => \"nn io l llllllliiilll                   \"\n",
      "batch 1493  loss=149.0622  steps/s=100.82  prediction: \"wesome looking pieces though, im jealous\" => \"agAB Pillllll oooooeeeeeeeeeee          \"\n",
      "batch 1494  loss=129.1336  steps/s=104.42  prediction: \"so they get into an unending doom spiral\" => \" ni t tttttttttttt       nnnnnnnnnnnnnn \"\n",
      "batch 1495  loss=157.1944  steps/s=97.50  prediction: \"eadme updates :( https://t.co/FAmcprLRrm\" => \" lia       eeeee          ttttttttt/////\"\n",
      "batch 1496  loss=128.3867  steps/s=104.59  prediction: \"ling down on stuff I initially dismissed\" => \"yt o  o   o                     iiiiiiii\"\n",
      "batch 1498  loss=125.3351  steps/s=103.41  prediction: \" not abt to read through all of its code\" => \"te   s                                  \"\n",
      "batch 1499  loss=145.9521  steps/s=104.13  prediction: \"ift camera to dogs perspective = dataset\" => \"n otg                            eeeeeee\"\n",
      "batch 1500  loss=141.3838  steps/s=100.56  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"t  tr t                      eeeeeeeemem\"\n",
      "batch 1501  loss=158.8314  steps/s=105.19  prediction: \"us @BasedBeffJezos Some are on the money\" => \"sl@ketssssssseeBBBBeeeeeeeeeeeeeee      \"\n",
      "batch 1502  loss=128.4743  steps/s=83.39  prediction: \"ochenko curious, can you elaborate more?\" => \"nteb sbbBeeeeeees sooo          o  ooooo\"\n",
      "batch 1503  loss=125.1610  steps/s=66.20  prediction: \" @pilpulon will release v1 at some point\" => \"@beb bbcceuuuuu o    o          a  ooeeo\"\n",
      "batch 1504  loss=160.6506  steps/s=109.32  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" @bn  'nnn\"\"\"\"\"  o oo                   \"\n",
      "batch 1505  loss=143.1182  steps/s=103.58  prediction: \"e building an army of tiny little robots\" => \" soo                                    \"\n",
      "batch 1506  loss=131.1199  steps/s=104.00  prediction: \"t on bad apple vs python library anyways\" => \"hat tt                               yyy\"\n",
      "batch 1507  loss=245.9314  steps/s=99.69  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"russt          !!!!!!!!!!!! lll         \"\n",
      "batch 1508  loss=133.7383  steps/s=103.29  prediction: \"eres so little time to things in the day\" => \"   eeeeee        tttttttttttttttt       \"\n",
      "batch 1509  loss=130.4590  steps/s=105.40  prediction: \" you called it. may as well draft it now\" => \"to e o                                  \"\n",
      "batch 1510  loss=128.8048  steps/s=105.42  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taiegitiiiiiii                          \"\n",
      "batch 1511  loss=137.5019  steps/s=104.41  prediction: \"ttin you do all that stuff, drop out etc\" => \"h s  n utt                              \"\n",
      "batch 1512  loss=157.7106  steps/s=86.29  prediction: \"Veraciety We're goin alright, we're goin\" => \"ar  i  eee                              \"\n",
      "batch 1513  loss=142.6398  steps/s=101.22  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \"hnn  @eeeeeeee  ooo   oo  annnaaoooooooo\"\n",
      "batch 1514  loss=130.2938  steps/s=105.46  prediction: \"nk could handle a variable player count)\" => \"g hor                  aaaaaaaaaaaaaaaaa\"\n",
      "batch 1515  loss=140.6723  steps/s=105.11  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  h D           tttttttttttttt////////\"\n",
      "batch 1516  loss=142.4326  steps/s=102.16  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"n  a           aaaaaaaaaa               \"\n",
      "batch 1518  loss=126.6752  steps/s=104.78  prediction: \" fly everywhere\n",
      "\n",
      "idk how lidar works btw\" => \"tu hh          eeeeeeeeeeeeee     ww  ww\"\n",
      "batch 1519  loss=146.3528  steps/s=104.43  prediction: \"he goated advice https://t.co/gZx1K1OtSg\" => \"a th t                ttttttttttt///////\"\n",
      "batch 1521  loss=276.8290  steps/s=102.94  prediction: \" but I learned\n",
      "\n",
      "ð—ªð—µð—¶ð—°ð—µ ð—¼ð—»ð—² ð˜€ð—¼ð˜‚ð—»ð—±ð˜€ ð—¯ð—²ð˜ð˜ð—²ð—¿?\" => \"tui                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "               \"\n",
      "batch 1522  loss=143.0410  steps/s=62.80  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"tdi           \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                     \"\n",
      "batch 1523  loss=149.5600  steps/s=114.62  prediction: \"77 oh whoa i didnt know abt tabs, thanks\" => \" 0 tt   77777                           \"\n",
      "batch 1524  loss=136.5914  steps/s=105.92  prediction: \"put work in, etc https://t.co/8ZjkHbRuMG\" => \"ltt e i                tttttttttt///////\"\n",
      "batch 1525  loss=158.9620  steps/s=101.42  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"n, se                ttttttttttt////////\"\n",
      "batch 1526  loss=133.5342  steps/s=105.69  prediction: \"layer type stuff, but going even further\" => \"yw e e                                  \"\n",
      "batch 1527  loss=124.5815  steps/s=101.13  prediction: \"u were in vim, it should start the timer\" => \"sc tr                              ttttt\"\n",
      "batch 1528  loss=127.6298  steps/s=11.25  prediction: \"reply: @justalexoki He is the goat fr fr\" => \" poy:                              ttttt\"\n",
      "batch 1529  loss=136.1393  steps/s=110.91  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"toora t                    tttttttttt///\"\n",
      "batch 1530  loss=144.7206  steps/s=101.87  prediction: \"o church\n",
      "Starting everything immediately\" => \"nf noe oo     tttttttttttttttttttteiiiii\"\n",
      "batch 1531  loss=138.4335  steps/s=104.63  prediction: \"amount of time, or did you just enjoy it\" => \"le    i                                 \"\n",
      "batch 1532  loss=132.9232  steps/s=102.78  prediction: \" like 1hr ago lol\n",
      "\n",
      "also is that your dog\" => \"tiii ii               llllllll          \"\n",
      "batch 1534  loss=135.2291  steps/s=100.47  prediction: \"nds so good\n",
      "Edm piano doesnt even matter\" => \"   eni   ooooooooooooooooooooooo        \"\n",
      "batch 1535  loss=131.7576  steps/s=105.37  prediction: \" is better than lots of ppl not starting\" => \"tt  esssssseeeeeee                    tt\"\n",
      "batch 1536  loss=150.3979  steps/s=103.79  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \" meri llllllllllllllll111110000?????????\"\n",
      "batch 1537  loss=131.6629  steps/s=46.29  prediction: \"y: @_diginova i served my time in x jail\" => \": @nolliiiii ll  11111110000?????       \"\n",
      "batch 1538  loss=148.7268  steps/s=114.30  prediction: \"s after monads.. https://t.co/V7s73DqEAF\" => \" a s   s             ....tt........t////\"\n",
      "batch 1539  loss=153.0251  steps/s=83.15  prediction: \"atedro @gizmobly https://t.co/IFzJo2qtyj\" => \"nkeoo eee  oooo   tttttttt/////////////F\"\n",
      "batch 1540  loss=143.3040  steps/s=106.32  prediction: \"on chunking showed higher level playersâ€¦\" => \"  e  s              hhhhhhhhhhhhheeeeeee\"\n",
      "batch 1541  loss=127.2205  steps/s=101.02  prediction: \" tool yet tho. selo has circle supremacy\" => \"thl t                                  c\"\n",
      "batch 1543  loss=168.3667  steps/s=35.92  prediction: \"ply: @dgant wild https://t.co/0HTLsAprAT\" => \"ly: @l     t                         ccc\"\n",
      "batch 1544  loss=131.8836  steps/s=108.60  prediction: \"e forever with a simple 5min interaction\" => \" fi  oeeeeeeeeeeee               iiiiiii\"\n",
      "batch 1545  loss=133.6107  steps/s=104.00  prediction: \" in terms of your thoughts in each \"era\"\" => \"tt e                                    \"\n",
      "batch 1546  loss=130.3303  steps/s=98.95  prediction: \"nt know if you were wrong abt everything\" => \"ge   tuu              wwwww         eeee\"\n",
      "batch 1547  loss=140.0659  steps/s=105.09  prediction: \" right now its just learning on the side\" => \"ae  r                            nn     \"\n",
      "batch 1548  loss=166.2590  steps/s=99.45  prediction: \"1 @yacineMTB just dmd you the term sheet\" => \" hL e r@@@@@@                           \"\n",
      "batch 1549  loss=161.5710  steps/s=102.59  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"toaoeett/////////tttttttttt///////////DD\"\n",
      "batch 1550  loss=141.0294  steps/s=100.49  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"emlc:opoooooooo     tttttttttttttt//////\"\n",
      "batch 1551  loss=145.4314  steps/s=103.87  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" woa       ttttttttttttt tt   tttt      \"\n",
      "batch 1552  loss=144.1608  steps/s=105.48  prediction: \"/t.co/zlto3SBYwd https://t.co/Izzdx8c2HJ\" => \"tthoe ttttt//////ttttttttttt///////zzzzz\"\n",
      "batch 1553  loss=142.2015  steps/s=100.70  prediction: \"right words can change entire industries\" => \"etly:p@                         nnnnnnnn\"\n",
      "batch 1554  loss=148.8015  steps/s=101.88  prediction: \"r you call this) https://t.co/l6jyM49oCP\" => \"echt                     ttttttttttttt//\"\n",
      "batch 1555  loss=143.7219  steps/s=102.59  prediction: \"ad to give some direction/motivation tho\" => \"ne    t                  eeeiiiiiiiiiiii\"\n",
      "batch 1556  loss=142.3628  steps/s=105.63  prediction: \"lf of that was way off. all good tho nbd\" => \"yo                       fffff          \"\n",
      "batch 1557  loss=136.2102  steps/s=102.28  prediction: \" up and down\n",
      "\n",
      "Youre always in the middle\" => \"@l   t                                  \"\n",
      "batch 1558  loss=158.7521  steps/s=103.86  prediction: \" blindfolded and win 80% (timur garayev)\" => \"aa  l  lllllllllldddddddddd             \"\n",
      "batch 1559  loss=134.4264  steps/s=101.42  prediction: \"ranoid to install an extension like that\" => \"ecly:o@ooooooooo            nnnnnnnnnnnn\"\n",
      "batch 1560  loss=177.2041  steps/s=98.81  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \"  o: @oo  SS@@@@@@@                     \"\n",
      "batch 1561  loss=129.5971  steps/s=105.22  prediction: \"that leads nowhere + info that clustersâ€¦\" => \"heseie                                  \"\n",
      "batch 1562  loss=135.9970  steps/s=96.42  prediction: \"nism oooh possibly, thats a good thought\" => \" ls is ssooooooooooooooo                \"\n",
      "batch 1563  loss=131.8389  steps/s=104.96  prediction: \" ppl twist your arm behind your back lol\" => \"trtett ttttt                            \"\n",
      "batch 1564  loss=130.6652  steps/s=103.99  prediction: \"d to take over the years\n",
      "\n",
      "4 minute miles\" => \" ta tt            eeeeeeeeeeee          \"\n",
      "batch 1565  loss=137.0228  steps/s=104.34  prediction: \", how much info could you get from that?\" => \" aod i                                  \"\n",
      "batch 1566  loss=163.8238  steps/s=64.64  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"ladwik ii ii                   oo   !!!!\"\n",
      "batch 1567  loss=221.1913  steps/s=112.30  prediction: \"RAFT clone?????? https://t.co/LpT9VeD8p0\" => \"  @ a          ????????????tttttttttt/pp\"\n",
      "batch 1568  loss=138.2998  steps/s=104.11  prediction: \"ern of multiplied KPIs pop up semi-often\" => \"  it        tttt           ppppppppppp  \"\n",
      "batch 1569  loss=199.9741  steps/s=104.47  prediction: \" (to learn zig): https://t.co/tIgeHjq28P\" => \"tttsoqoooo                 ttttttttt////\"\n",
      "batch 1571  loss=139.5923  steps/s=104.29  prediction: \"to fill them in fast, like you mentioned\" => \"h s tt                                  \"\n",
      "batch 1572  loss=129.7864  steps/s=101.73  prediction: \"e drew your whole country as the soyjack\" => \" t :                                    \"\n",
      "batch 1573  loss=156.2310  steps/s=99.64  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"ept a      00000000000                oo\"\n",
      "batch 1574  loss=133.3618  steps/s=71.38  prediction: \" @llamapuckey never visit sf without jug\" => \"tma  aaa000000     ee             ooooou\"\n",
      "batch 1575  loss=132.5444  steps/s=109.10  prediction: \"tups are hidden in the fog 2 moves ahead\" => \"hinf s stt                              \"\n",
      "batch 1576  loss=136.9584  steps/s=96.91  prediction: \"anks maaan. i want it to load SUPER fast\" => \"ntne  saaaaaaaaaaaaaa                  a\"\n",
      "batch 1577  loss=135.4927  steps/s=104.65  prediction: \" since llms are not great with zig (ime)\" => \"tts i                                   \"\n",
      "batch 1578  loss=133.7744  steps/s=101.37  prediction: \"ct\n",
      "\n",
      "also, interesting advice in the clip\" => \"a ea tooooooooooooeeeeettttiiiiiiii   ii\"\n",
      "batch 1579  loss=127.5641  steps/s=104.42  prediction: \"e are, so it has a ton of ripple effects\" => \" t    a                                 \"\n",
      "batch 1580  loss=152.1051  steps/s=105.18  prediction: \"ng up every word you hear more than once\" => \"   wo  o                                \"\n",
      "batch 1581  loss=134.7287  steps/s=104.15  prediction: \"n is a great way to beat some addictions\" => \"gtwoi issst                             \"\n",
      "batch 1582  loss=163.0630  steps/s=105.25  prediction: \"tler good knight https://t.co/lACUcp7zMH\" => \" e  isisttt           tttttttttttottoocc\"\n",
      "batch 1583  loss=127.5353  steps/s=86.13  prediction: \"_software its c to wasm using emscripten\" => \"punlettoooo       tttt     ssssssccccccc\"\n",
      "batch 1584  loss=135.0415  steps/s=105.77  prediction: \"ly when you try to build the thing again\" => \"y:  l c                                 \"\n",
      "batch 1585  loss=130.9766  steps/s=104.95  prediction: \"he gamer would make for some great games\" => \"e  o r                                  \"\n",
      "batch 1587  loss=133.8355  steps/s=101.18  prediction: \"the man stretches his mind and his limbs\" => \" e  a x          e                      \"\n",
      "batch 1588  loss=122.1354  steps/s=95.29  prediction: \"nes @micsolana same for my history class\" => \"gs  a       cces aasssaa              ss\"\n",
      "batch 1589  loss=139.5292  steps/s=100.00  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"enits                        tttt///////\"\n",
      "batch 1590  loss=133.7387  steps/s=103.29  prediction: \" is a wild computational rabbithole man.\" => \"t a ps                    aaaaaaaaaaaaaa\"\n",
      "batch 1591  loss=134.5889  steps/s=103.86  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" ii f  llaaaaaaaaaaabbbb    aaaaaaaaaaaa\"\n",
      "batch 1592  loss=144.3185  steps/s=105.26  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"to.assst/////////ttttttttttt//////////PP\"\n",
      "batch 1593  loss=160.3199  steps/s=84.63  prediction: \"ownbad Sweet! Glad it worked, which one?\" => \"r ltsa/aaoooSSSSSSttttt ttttttttwwochhhh\"\n",
      "batch 1595  loss=154.2018  steps/s=92.01  prediction: \"ebsirak @yacineMTB alexander could never\" => \" uy: @daaeeaaaaa              w cddd    \"\n",
      "batch 1596  loss=136.7782  steps/s=108.11  prediction: \" I know!!! I laughed so hard when it hit\" => \"t alaa ooa !!!!!!               d       \"\n",
      "batch 1597  loss=128.0534  steps/s=105.51  prediction: \"ly  small gif editing, it should be fine\" => \"y: el                        iii        \"\n",
      "batch 1598  loss=131.2573  steps/s=104.53  prediction: \"s aside though, why wouldn't that work?)\" => \" aoo eessssssss     hhhhhhh             \"\n",
      "batch 1599  loss=152.8611  steps/s=101.41  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \"  yeeeeeeeeeeee                         \"\n",
      "batch 1600  loss=124.4676  steps/s=28.77  prediction: \"ply: @10x_er he saw food and came runnin\" => \"ly: @oeeeee   e                         \"\n",
      "batch 1601  loss=136.5405  steps/s=143.78  prediction: \"7 make money so you can make video games\" => \"  dceee  e           oo                 \"\n",
      "batch 1602  loss=136.4626  steps/s=20.33  prediction: \"eply: @rcx86 Thank God\n",
      "I hope nobody did\" => \" ly: @e77ee         oo                  \"\n",
      "batch 1603  loss=148.5544  steps/s=124.89  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"   torarrrrrrrrrrr   tttttttttt   ///222\"\n",
      "batch 1604  loss=126.7107  steps/s=97.93  prediction: \"but openai is cringe so obviously sonnet\" => \"et eatt          iiiiiiii   iooooooooooo\"\n",
      "batch 1605  loss=129.7085  steps/s=104.37  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l:n  w                   ttttttttttttttt\"\n",
      "batch 1606  loss=128.2469  steps/s=104.24  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" t tt sssssssssssseeeeeeeeee            \"\n",
      "batch 1607  loss=128.1908  steps/s=103.92  prediction: \"n sheeps clothing is probably enough tbh\" => \" sa ee                                  \"\n",
      "batch 1608  loss=126.9685  steps/s=104.66  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" ,    eeeeeeeeeee                tttttt \"\n",
      "batch 1609  loss=130.3000  steps/s=98.56  prediction: \"ers had a username but idk his name name\" => \"  ee  eee                               \"\n",
      "batch 1610  loss=129.6687  steps/s=103.39  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \"et   o ooooo                         eee\"\n",
      "batch 1611  loss=136.0728  steps/s=103.22  prediction: \"his was a super helpful technique for me\" => \"eve tt                           eeeeeee\"\n",
      "batch 1612  loss=137.2976  steps/s=104.15  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \"  ss i ttttrr                       oooo\"\n",
      "batch 1613  loss=129.1306  steps/s=95.28  prediction: \"imated stills have finally been defeated\" => \"ne ar aaaan              lllllllllee eee\"\n",
      "batch 1614  loss=131.1464  steps/s=103.15  prediction: \"\n",
      "then do your own experiments from there\" => \"\n",
      "hhs n nnnoooooooooooo        eeee   eee\"\n",
      "batch 1615  loss=190.2350  steps/s=29.19  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly:e@n nnoooooooo o      eeeeeeee   eree\"\n",
      "batch 1616  loss=135.7433  steps/s=107.18  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efl d \n",
      "eee           ssssssssssssscccc  \"\n",
      "batch 1617  loss=133.9008  steps/s=100.91  prediction: \"t really is a long term + hard work game\" => \"hsO  fee                                \"\n",
      "batch 1619  loss=150.0400  steps/s=102.39  prediction: \"you get used to it and overcome the fear\" => \":uoa                                  ee\"\n",
      "batch 1620  loss=148.4328  steps/s=102.69  prediction: \"ree simple moves to DESTROY any opponent\" => \"ep2y: @  eeeeeeeeeeeeee                 \"\n",
      "batch 1621  loss=134.7196  steps/s=104.15  prediction: \"ill you get better at as you practice it\" => \"nl aa                                   \"\n",
      "batch 1622  loss=120.4871  steps/s=94.18  prediction: \"resy you can already talk to one of them\" => \"eply: @ ee         aaaaaaaaa            \"\n",
      "batch 1623  loss=181.9776  steps/s=87.15  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \" ae y looaaaaaaaaaa             oooooooo\"\n",
      "batch 1624  loss=138.3448  steps/s=105.11  prediction: \"ath dependence can be used strategically\" => \"r  aoaaaaaa   eeeeeeeeeeeeee    ss  ee s\"\n",
      "batch 1625  loss=157.6944  steps/s=100.21  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \"ark le             ?????hhhttttt////////\"\n",
      "batch 1626  loss=140.7853  steps/s=101.24  prediction: \" a while before I add it to the site tho\" => \"@l li llll                              \"\n",
      "batch 1627  loss=127.8798  steps/s=100.27  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"rli ttheeeeeehhheehhhheeeeeeeeeeeeeeeeee\"\n",
      "batch 1628  loss=123.6489  steps/s=97.84  prediction: \"ler its always an :x day here on twitter\" => \"y  @sttttttttaaa  aa  a                e\"\n",
      "batch 1629  loss=127.7452  steps/s=104.26  prediction: \" information for improvement, like above\" => \"tsa l    aaaaooooooooooooooooooommm   ee\"\n",
      "batch 1630  loss=141.1683  steps/s=105.42  prediction: \" easy to use too\n",
      "https://t.co/EjkhiWdtX3\" => \"t nen               tttttttttt/////////t\"\n",
      "batch 1631  loss=154.9154  steps/s=104.25  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" a ea  eeeeeeeeeeeee  nnnttttttttt//////\"\n",
      "batch 1632  loss=174.5797  steps/s=44.48  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"e s e  eeeeeeee    tttttttttt//////////B\"\n",
      "batch 1633  loss=137.4585  steps/s=136.80  prediction: \" a friend that did this for a CS project\" => \"t  e              tttttttttt            \"\n",
      "batch 1634  loss=122.8161  steps/s=102.81  prediction: \" and the quote tweet is the reply itself\" => \"t  ttt tttttttttteeeeeeeeeeeeeeeeeeeee  \"\n",
      "batch 1635  loss=136.9970  steps/s=105.66  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" ioese,eeeeeeeeeeeeeeeeeeeettttt////////\"\n",
      "batch 1636  loss=152.2146  steps/s=97.51  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"t essesaaaaaaaaaaattttttttt///////////RR\"\n",
      "batch 1637  loss=132.7288  steps/s=100.42  prediction: \"ont need sleep, your mind goes wide open\" => \"nc  ee      eeeeeeeeee                  \"\n",
      "batch 1638  loss=172.6630  steps/s=73.40  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"snneneM   eeeeeeeee                    e\"\n",
      "batch 1639  loss=132.1510  steps/s=108.53  prediction: \" can see something 1000000x better to do\" => \"tat eaaaa                00000000000    \"\n",
      "batch 1640  loss=136.6366  steps/s=105.22  prediction: \"m scratch in numpy like i did w backprop\" => \"elt  t                                  \"\n",
      "batch 1641  loss=127.5974  steps/s=102.50  prediction: \"seful instances of delayed gratification\" => \" alo             sss       eeeeeeeeaaaaa\"\n",
      "batch 1642  loss=138.5687  steps/s=103.96  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"etw u      ooooooo                     t\"\n",
      "batch 1643  loss=144.9628  steps/s=103.83  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"ena                                     \"\n",
      "batch 1645  loss=131.7179  steps/s=99.94  prediction: \"efforts\n",
      "\n",
      "mcafee still remained installed\" => \" ele eeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eeeeeeeeeeeeeeeeeeeel\"\n",
      "batch 1646  loss=125.8242  steps/s=104.92  prediction: \"anning on putting this in an actual bot?\" => \"n  pooonnnnnnnnnnnnnnnnn i              \"\n",
      "batch 1647  loss=132.5269  steps/s=105.02  prediction: \"c too much attention + hasnt been solved\" => \"arlie          tttttttttttt             \"\n",
      "batch 1648  loss=127.7369  steps/s=103.21  prediction: \"lgorithms\n",
      "Get better learning algorithms\" => \"earny            tttttttteeeeeeeeeerrrrr\"\n",
      "batch 1649  loss=160.3361  steps/s=100.75  prediction: \"arning a lot and building a lot\n",
      "\n",
      "love it\" => \"rn il lO\n",
      "\n",
      "\n",
      "\n",
      "                            \"\n",
      "batch 1650  loss=135.5776  steps/s=102.11  prediction: \"ns you get the yellow letters on lichess\" => \"g tla                     eeeeeeeeeeeeee\"\n",
      "batch 1651  loss=138.1027  steps/s=104.67  prediction: \"ms' meaning more straightforward success\" => \"e ble e'''''emmmmmmmmmm   rrrrrrrrrrrrrr\"\n",
      "batch 1652  loss=145.1328  steps/s=100.55  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \" th a r  d          dddd                \"\n",
      "batch 1653  loss=153.9990  steps/s=104.38  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"ood ta UUUUU       tttttttttttttttt/////\"\n",
      "batch 1654  loss=151.8201  steps/s=105.04  prediction: \"on adding sound!\n",
      "https://t.co/7jVECuxgpx\" => \"r i ioa     nnnnnnnnnnnnnnnnnnnot///////\"\n",
      "batch 1655  loss=140.1866  steps/s=102.32  prediction: \"ably already figured out some of my plan\" => \"te w yooo     yyyyyy                    \"\n",
      "batch 1656  loss=151.7459  steps/s=54.38  prediction: \": @0x77er some likes are worth 100 likes\" => \" @l hly  ay      e            o         \"\n",
      "batch 1657  loss=139.1830  steps/s=105.80  prediction: \"hemes\n",
      "John waitzkin called this chunking\" => \"e t eaatteeeeeeeeennnnnnn               \"\n",
      "batch 1658  loss=142.4754  steps/s=104.60  prediction: \"king progress. Now i see it eeeverywhere\" => \"i a  t                          eeeeeeee\"\n",
      "batch 1659  loss=126.8348  steps/s=104.39  prediction: \"on mars we will make this a top priority\" => \"r   oo                                  \"\n",
      "batch 1660  loss=140.6414  steps/s=100.41  prediction: \" flick of the wrist instead of traveling\" => \"to i                                  tt\"\n",
      "batch 1661  loss=136.2522  steps/s=105.50  prediction: \" is actually happening behind the scenes\" => \"tn ew             aaaaaaa    nnnnnh  nne\"\n",
      "batch 1662  loss=141.0782  steps/s=98.51  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"  s  s       aaaaaaaaaaaaaadaaaaaaaaalal\"\n",
      "batch 1663  loss=127.8026  steps/s=99.77  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"y  @ststtttttt    iiii         aaaaaaaaa\"\n",
      "batch 1664  loss=147.1585  steps/s=102.47  prediction: \"t may be helpful https://t.co/vWFRQhJmDt\" => \" io ns                  ttttttttttt/////\"\n",
      "batch 1665  loss=144.9312  steps/s=103.97  prediction: \", write one sentence after another, andâ€¦\" => \" aid               eeeeeeeeeeeeeeeeeeeen\"\n",
      "batch 1666  loss=132.3785  steps/s=103.46  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"gy  ro    eeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 1667  loss=161.1430  steps/s=78.14  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" htrernnnnns  s s s    r                \"\n",
      "batch 1668  loss=135.8583  steps/s=123.74  prediction: \" a friend that did this for a CS project\" => \"tn a  a                                 \"\n",
      "batch 1671  loss=141.8134  steps/s=103.46  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \"ir sun             ttttttttttttttt//////\"\n",
      "batch 1672  loss=155.5337  steps/s=78.22  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"lalnnttoooo       tttttttt//////////ooII\"\n",
      "batch 1673  loss=137.3104  steps/s=107.15  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"  bcnttceeeeeeeeeeeeeeeeeettttttt///////\"\n",
      "batch 1674  loss=190.2427  steps/s=102.55  prediction: \" audio too\n",
      "\n",
      "I really felt that beat drop\" => \"t IOO p                                 \"\n",
      "batch 1675  loss=131.4447  steps/s=98.45  prediction: \"ideos Its good to be back on the streets\" => \"tp a  iiooooooooooooo                  t\"\n",
      "batch 1676  loss=154.5159  steps/s=103.57  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"nh                                    oo\"\n",
      "batch 1678  loss=137.1170  steps/s=89.29  prediction: \"eigecamry @sunsettler shredded that shit\" => \" ty:   e            tsttteh     eeedd   \"\n",
      "batch 1679  loss=135.4048  steps/s=105.34  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"yy e e                  ttttttttttttt///\"\n",
      "batch 1680  loss=135.2757  steps/s=103.35  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tfta s sss ssssssssssssssss          aaa\"\n",
      "batch 1681  loss=144.6141  steps/s=104.90  prediction: \"nfidence\n",
      "\n",
      "\"idk\" is often the best belief\" => \" edltcieeeeeeeeeeiiiiiii\"\"\"eeeeeeeeeeeee\"\n",
      "batch 1682  loss=136.8506  steps/s=104.42  prediction: \"ht them the openscad to make the pulleys\" => \"e roi    hhhhhhh                        \"\n",
      "batch 1683  loss=123.5069  steps/s=100.76  prediction: \"r than age sounds like a skill issue tbh\" => \"ebly: @t                      k   slllss\"\n",
      "batch 1684  loss=136.4562  steps/s=104.48  prediction: \" works when I ask it for complex changes\" => \"to e ll wwwwww                          \"\n",
      "batch 1685  loss=120.1196  steps/s=103.07  prediction: \"tput something as unexpected as possible\" => \" ro t  tttttttttt          eeeeeeeeeesss\"\n",
      "batch 1686  loss=129.7201  steps/s=103.76  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"tput tttttttttttttttttaaaaaaaahhhhhhhhhh\"\n",
      "batch 1687  loss=135.2903  steps/s=104.17  prediction: \"ective, its significantly more efficient\" => \" hyt o       iiiiiiiiiiiiiiiiiiiiiiiifff\"\n",
      "batch 1688  loss=154.8312  steps/s=106.14  prediction: \"us @BasedBeffJezos Some are on the money\" => \"s @nss sssssseeBBBBeeeeeeeeeeeeeee      \"\n",
      "batch 1689  loss=130.2314  steps/s=104.28  prediction: \"seless to ppl who dont know them already\" => \"  eeeesesssssss                         \"\n",
      "batch 1690  loss=146.7558  steps/s=103.20  prediction: \"though who knows\n",
      "https://t.co/YpddagC5uf\" => \" \n",
      "     aa hhhhhhhhhhhhhhhhtttttttt//////\"\n",
      "batch 1691  loss=133.4913  steps/s=104.98  prediction: \"lls that help me do other ml experiments\" => \"ee ne                             eeeeee\"\n",
      "batch 1692  loss=139.2009  steps/s=102.45  prediction: \"es gets rounded up to 0.1s\n",
      "\n",
      "why? idk man\" => \"  ee  eeeeeeeeeee                       \"\n",
      "batch 1693  loss=138.8893  steps/s=102.35  prediction: \" is actually happening behind the scenes\" => \"tn ew            aaaaaaaaaa  nnnnnhhn nn\"\n",
      "batch 1694  loss=140.2404  steps/s=104.78  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \" r sen             tttttttttttttttt/////\"\n",
      "batch 1695  loss=146.6023  steps/s=105.39  prediction: \"ight radius\n",
      "Hmm 5px or 5%? Maybe 4.9%...\" => \"ne                                      \"\n",
      "batch 1697  loss=123.7100  steps/s=79.32  prediction: \"TB strategy is an abstraction of tactics\" => \"B ns   ttttttt             aaaa         \"\n",
      "batch 1698  loss=154.3451  steps/s=88.66  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eely: @rrrrr       00    r      tt      \"\n",
      "batch 1699  loss=134.6700  steps/s=105.73  prediction: \"ch though if i cant fix a particular bug\" => \"h    ththhhhhhh                        a\"\n",
      "batch 1700  loss=148.4760  steps/s=74.80  prediction: \"wlearning \"Pricing it in\" now 15% faster\" => \"hy hhtwwh   i i    iiiii          a   aa\"\n",
      "batch 1702  loss=145.7742  steps/s=86.89  prediction: \"koslib Also just saw the Eu/acc, respect\" => \"ed  t ii i    i    i              aa  rr\"\n",
      "batch 1703  loss=131.9125  steps/s=107.18  prediction: \"erscores the importance of curating andâ€¦\" => \" ei e eeeeeeeeeeeeeeeeeee               \"\n",
      "batch 1704  loss=134.5677  steps/s=104.09  prediction: \"ll be easy to remember every single move\" => \"yi  alllllll          eeeeeeeeeeeeeeeeee\"\n",
      "batch 1705  loss=132.5875  steps/s=104.39  prediction: \"uch  there would be to take into account\" => \"s ean                                   \"\n",
      "batch 1706  loss=133.3938  steps/s=103.64  prediction: \"r these very cool words. well said, dang\" => \"e(le  t                 oooo            \"\n",
      "batch 1707  loss=130.0259  steps/s=95.67  prediction: \"ler its always an :x day here on twitter\" => \"y  @tuteeee                             \"\n",
      "batch 1708  loss=146.5719  steps/s=104.09  prediction: \" that initially seemed meaningless to me\" => \"the u       iiiiiiiiiiieeeeeeeeeeeeeeeee\"\n",
      "batch 1709  loss=140.9753  steps/s=104.35  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"afnn                   tttttttttt///////\"\n",
      "batch 1710  loss=128.3914  steps/s=102.96  prediction: \"ide stuff on top of normal operations ig\" => \"ne   d                oooooooooooooooooo\"\n",
      "batch 1711  loss=157.9801  steps/s=105.00  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t    0                               nnn\"\n",
      "batch 1713  loss=159.7134  steps/s=101.05  prediction: \"tloader ah another tool builder, love it\" => \" e    ooooooooooooooooooooo     olloooll\"\n",
      "batch 1714  loss=131.1946  steps/s=103.98  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" n aaaa       aaaaaaaaaa   sssttt///////\"\n",
      "batch 1715  loss=134.2727  steps/s=99.96  prediction: \"e\n",
      "\n",
      "i need to try your coffee shop tactic\" => \" \n",
      "a:   eeeeeeeee                        \"\n",
      "batch 1716  loss=132.0779  steps/s=104.20  prediction: \"ep/useful and you become Christian again\" => \" lye eeeeeeeeeeeee                      \"\n",
      "batch 1717  loss=133.7668  steps/s=101.42  prediction: \"efforts\n",
      "\n",
      "mcafee still remained installed\" => \" eteeteee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffffeeeeeeeeeeeeeeeell\"\n",
      "batch 1718  loss=146.5272  steps/s=102.59  prediction: \"azy like that. Cheers my English brother\" => \"n. ehe                                 h\"\n",
      "batch 1719  loss=141.0394  steps/s=104.91  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes              tttttttttttttttttt/////\"\n",
      "batch 1720  loss=136.7897  steps/s=98.94  prediction: \"s9 and of course, its subscription based\" => \"  it   oo         ttssssssssssssssssciii\"\n",
      "batch 1721  loss=158.2312  steps/s=105.54  prediction: \"his ~10yrs ago w py\n",
      "Learn by doing WORKS\" => \"ene s  tttt                             \"\n",
      "batch 1722  loss=171.0908  steps/s=47.05  prediction: \"y: @tabtab0x_0 @Brycicle77 never mouse ðŸ«¡\" => \"  @. t~tttt                             \"\n",
      "batch 1723  loss=140.1012  steps/s=136.60  prediction: \"y based. how do you compile zig to wasm?\" => \" grs  tbbbbbb          oo     o         \"\n",
      "batch 1724  loss=132.3092  steps/s=105.31  prediction: \", thank God we can function at all loool\" => \" are e                                  \"\n",
      "batch 1725  loss=133.0895  steps/s=103.89  prediction: \"n getting rid of the phone really is key\" => \"gcelaa                                  \"\n",
      "batch 1726  loss=129.7845  steps/s=103.58  prediction: \"no responses or just \"cool!\" Or whatever\" => \"greee t             sssssooooooo        \"\n",
      "batch 1727  loss=129.6366  steps/s=105.78  prediction: \"that leads nowhere + info that clustersâ€¦\" => \"heo ie                                  \"\n",
      "batch 1728  loss=145.1149  steps/s=105.70  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"h to/ttt/////////hhhhhtttttt///////////R\"\n",
      "batch 1729  loss=148.3368  steps/s=103.28  prediction: \"ugh\n",
      "\n",
      "but lud should be up there for sure\" => \"rwi  o     uuuuuuuuuuuuuuuu             \"\n",
      "batch 1730  loss=140.6094  steps/s=105.58  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"th  e                                   \"\n",
      "batch 1731  loss=144.9237  steps/s=104.51  prediction: \"ks.. 90% correct https://t.co/t9unPUcvje\" => \"  o            rrrrrrrrrrttttttttttt////\"\n",
      "batch 1732  loss=130.3474  steps/s=105.02  prediction: \" just be a webpage visit, its in browser\" => \"iu  ll l                        iiiiiiii\"\n",
      "batch 1733  loss=137.5428  steps/s=86.20  prediction: \"kul07 Nothing beats the classic todo.txt\" => \"     ll         b         tts i   ssssst\"\n",
      "batch 1734  loss=134.8419  steps/s=104.54  prediction: \"nt and then generate a new one each time\" => \"  gl  e       nnnnneeeeeeeeeeeeeeeeee   \"\n",
      "batch 1735  loss=134.7849  steps/s=102.48  prediction: \"om the distribution of (single response)\" => \"n  frfff        tttiiiiiiiiiiiiiii     s\"\n",
      "batch 1736  loss=125.7894  steps/s=102.10  prediction: \"pen theatre stairs door and ruin the run\" => \"lng @ t                       rrr       \"\n",
      "batch 1737  loss=117.6502  steps/s=100.34  prediction: \"n in the ass to get it to stop shuffling\" => \" MTB a                       tttttttt   \"\n",
      "batch 1738  loss=134.5211  steps/s=56.71  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"ta                     t    t           \"\n",
      "batch 1741  loss=142.1761  steps/s=109.07  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \" ro  au  lllllllll         tttttttttt///\"\n",
      "batch 1742  loss=145.4994  steps/s=104.82  prediction: \"f undulation. You probably already knowâ€¦\" => \" I  r             uuuooooooooooaaaaaaaaa\"\n",
      "batch 1744  loss=140.9333  steps/s=102.90  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \" d e le      ee             ttttttt/////\"\n",
      "batch 1745  loss=129.4190  steps/s=105.65  prediction: \"n sheeps clothing is probably enough tbh\" => \"gsaloes                                 \"\n",
      "batch 1746  loss=131.7834  steps/s=72.92  prediction: \"unsettler Ive made a few, its fun indeed\" => \"st s  ssseeeeeee                       n\"\n",
      "batch 1747  loss=178.1059  steps/s=109.42  prediction: \"ng jai??? Instantly 10x more interesting\" => \" 8   a        ????????                  \"\n",
      "batch 1749  loss=192.1290  steps/s=99.49  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"P PABASINNNGNNNLLLLLLNALLLL  tttttt/////\"\n",
      "batch 1750  loss=138.1654  steps/s=105.16  prediction: \"ate, but I think about this all the time\" => \"nine       tttttt      ttttt            \"\n",
      "batch 1751  loss=137.3505  steps/s=104.12  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" eleleleeeeeeeeeeeeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttt///////\"\n",
      "batch 1752  loss=203.1493  steps/s=20.52  prediction: \"eply: @yacineMTB https://t.co/H0UMjZbPTA\" => \" lleloleeeeeeeeeeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttt/////////\"\n",
      "batch 1753  loss=140.5439  steps/s=157.62  prediction: \"yb is this founder mode or manager mode?\" => \" uel lff         tttss /ttdooooooo   oaðŸ›‘\"\n",
      "batch 1754  loss=128.9017  steps/s=102.90  prediction: \"et good at the ones youre not so good at\" => \"  aneae                          ooooooo\"\n",
      "batch 1755  loss=132.5101  steps/s=101.43  prediction: \" except waaay too short of chunks hahaha\" => \"txallll    aaaaaaaaaaa                hh\"\n",
      "batch 1756  loss=144.7373  steps/s=48.61  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \"  @ ll  eeaaaaaa                   hhhhh\"\n",
      "batch 1757  loss=132.3094  steps/s=106.44  prediction: \"pick any domain/topic there are usuallyâ€¦\" => \"lrt  o                 iiii             \"\n",
      "batch 1758  loss=144.1981  steps/s=98.08  prediction: \"e IRL, its fundamentals all the way down\" => \" tya aaaaa                 aaaaaaaaalll \"\n",
      "batch 1759  loss=139.6968  steps/s=101.65  prediction: \"rs? and the keychain is for a parachute?\" => \"e  oes sss                           aaa\"\n",
      "batch 1760  loss=139.7370  steps/s=105.50  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" tA tto                           yyyooo\"\n",
      "batch 1761  loss=166.1145  steps/s=103.89  prediction: \"on every monday and thursday of the week\" => \"   o                        ddd         \"\n",
      "batch 1762  loss=126.1826  steps/s=104.23  prediction: \"atterns so we should do (description ofâ€¦\" => \"t ahat            s               d  ooo\"\n",
      "batch 1763  loss=141.9381  steps/s=98.09  prediction: \" was truly L tier. not L tier but L tier\" => \"th t t                                  \"\n",
      "batch 1764  loss=129.7335  steps/s=102.46  prediction: \" did not answer. he just kept on yapping\" => \"tapa                                    \"\n",
      "batch 1765  loss=161.8528  steps/s=96.18  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" t e t           o ooooooo ttttttttt////\"\n",
      "batch 1766  loss=129.4483  steps/s=104.17  prediction: \"ces for speed and it makes the game wild\" => \"h ee c c   eeeeeeeee                    \"\n",
      "batch 1767  loss=124.5798  steps/s=102.89  prediction: \"e\n",
      "graphics programming is so awesome man\" => \" \n",
      "s p        rrrrrrrrrrrrggggg        mm\"\n",
      "batch 1768  loss=139.3982  steps/s=101.29  prediction: \"thats a good one, comparing with experts\" => \"he    eaa              oooooo           \"\n",
      "batch 1769  loss=142.0434  steps/s=100.50  prediction: \" wtf, hes goated https://t.co/o1FdLtmzSj\" => \"te e                 tttttttttttttttt//t\"\n",
      "batch 1770  loss=131.9033  steps/s=101.94  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"that aa             a                   \"\n",
      "batch 1771  loss=131.8974  steps/s=99.41  prediction: \"r model architecture not based on tokens\" => \"ealy: @       eeeeeeeeeeettteeee        \"\n",
      "batch 1773  loss=132.5233  steps/s=102.83  prediction: \" play instead of making random moves lol\" => \"to t t             aaaaaaaaaaa          \"\n",
      "batch 1775  loss=132.2700  steps/s=104.58  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \":ap o                                   \"\n",
      "batch 1776  loss=149.6681  steps/s=104.44  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"t.acrctttt////////tttttCtt/////////////t\"\n",
      "batch 1777  loss=140.4775  steps/s=99.12  prediction: \"l remember the book much better too. ime\" => \"yb  aoooommmmeeeeeeeeeeee    e e        \"\n",
      "batch 1778  loss=131.8992  steps/s=105.48  prediction: \"e rotators\n",
      "\n",
      "we color c, e, f, g the same\" => \" tao     oooooooooooooooooo             \"\n",
      "batch 1779  loss=166.8120  steps/s=96.71  prediction: \"ellectus @gfodor https://t.co/Emux6iPInC\" => \" ro: @ettetteeeooooooo oo      ttt  //  \"\n",
      "batch 1781  loss=134.5847  steps/s=104.87  prediction: \" so I invested my time into that instead\" => \"ttreerooo                          ttttt\"\n",
      "batch 1782  loss=244.7652  steps/s=102.61  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"e c    SSSSSSSSGGGGGGGG      tttt//////3\"\n",
      "batch 1783  loss=162.9696  steps/s=101.74  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" (ooo''nnnnnn\"\n",
      "\n",
      "\n",
      "ooooooo                \"\n",
      "batch 1784  loss=134.8527  steps/s=86.98  prediction: \"alla_dev its over, mitch has been sealed\" => \"tl    laaaaaaa ooo          m m     eeee\"\n",
      "batch 1785  loss=142.7377  steps/s=105.97  prediction: \"he HTML/CSS to render (show) the webpage\" => \"e  se                                 ee\"\n",
      "batch 1787  loss=133.8123  steps/s=98.28  prediction: \"s the magic of doing things from scratch\" => \" col   t                                \"\n",
      "batch 1788  loss=142.1044  steps/s=101.42  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" ly: @aaaaaaaaaawllllllllllllllllllliiii\"\n",
      "batch 1789  loss=148.3909  steps/s=104.40  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne l  llllllll            tttttttttt////\"\n",
      "batch 1790  loss=130.6479  steps/s=104.19  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"   oro   eeeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 1791  loss=134.7279  steps/s=103.70  prediction: \"nvm then, enjoy your rain water counting\" => \" esapottttttt                           \"\n",
      "batch 1792  loss=131.9898  steps/s=50.16  prediction: \": @archived_videos definitely the latter\" => \" @got ht               n              nn\"\n",
      "batch 1793  loss=124.0115  steps/s=111.23  prediction: \"d useful stuff better with the new tools\" => \" ss uuuu uuuuuuufffffff tttttttttttttttt\"\n",
      "batch 1794  loss=129.6595  steps/s=105.06  prediction: \"t on bad apple vs python library anyways\" => \"hot tt                               yyy\"\n",
      "batch 1795  loss=123.9485  steps/s=104.68  prediction: \"ginal returns idea seems to pop up a lot\" => \" no                   eeeeeeee          \"\n",
      "batch 1796  loss=128.7014  steps/s=105.06  prediction: \"ything rewarding that follows from that)\" => \" hma iiiiieeerrrrrrrrrrr                \"\n",
      "batch 1797  loss=185.8751  steps/s=81.06  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"h n eyerrgrra77            t            \"\n",
      "batch 1798  loss=129.4185  steps/s=105.84  prediction: \" linux like it hallucinated csgo or doom\" => \"te  llllllllllllllllllliiiiiii          \"\n",
      "batch 1799  loss=135.4336  steps/s=104.74  prediction: \"gram faster which made him have more fun\" => \" ee      rrr               hhhhhhhh     \"\n",
      "batch 1801  loss=182.7511  steps/s=104.99  prediction: \"w many GFLOPS? Are these legal in CA????\" => \"ark a                      eeeeeeeee    \"\n",
      "batch 1802  loss=150.5346  steps/s=104.36  prediction: \" srsly the golden age of building things\" => \"te                                      \"\n",
      "batch 1803  loss=122.7705  steps/s=100.61  prediction: \"tart over again with a new hard problem?\" => \"h ,  l                                  \"\n",
      "batch 1804  loss=143.7637  steps/s=104.46  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u ao o                        0000     \"\n",
      "batch 1805  loss=145.9898  steps/s=103.95  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" mi  8      llllllllll     tttttt///////\"\n",
      "batch 1806  loss=132.6673  steps/s=102.30  prediction: \" stream but i do my actual job and stuff\" => \"to t t                                  \"\n",
      "batch 1807  loss=139.2417  steps/s=100.12  prediction: \" flick of the wrist instead of traveling\" => \"to i P                            t tttt\"\n",
      "batch 1808  loss=120.3092  steps/s=104.88  prediction: \"tput something as unexpected as possible\" => \" ra t tttttttttt          eeeeeeeeeessss\"\n",
      "batch 1809  loss=148.5062  steps/s=63.10  prediction: \" more to 400! Been a crazy two weeks lol\" => \"to t tooott o       eee  eeeee   esssses\"\n",
      "batch 1810  loss=129.2023  steps/s=112.36  prediction: \"ust linux mints built in text editor lol\" => \"t i                i iiiiiii  tttttttttt\"\n",
      "batch 1811  loss=130.6476  steps/s=78.44  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \"  ut  suu iiiii iiiiiii  i t tttttt llll\"\n",
      "batch 1812  loss=137.2632  steps/s=109.30  prediction: \"builds mcdonalds just wants to grill man\" => \"ett eusbbbiiii ll                       \"\n",
      "batch 1813  loss=131.5088  steps/s=95.56  prediction: \"nis @startupmillyair pretty solid rating\" => \" u  ttesdddsssssslsttlllll tt           \"\n",
      "batch 1814  loss=133.8335  steps/s=102.51  prediction: \"it playable on lichess and post the link\" => \"n       lllllllllllll                   \"\n",
      "batch 1815  loss=127.6917  steps/s=103.67  prediction: \" that is not working out for some reason\" => \"to e h                        oooooooooo\"\n",
      "batch 1816  loss=139.5630  steps/s=104.51  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"00c  t      aaaaaaaaaa   oooooo cccc    \"\n",
      "batch 1817  loss=131.6643  steps/s=104.00  prediction: \"verything that happens to everyone else'\" => \"erynee ee   ttttttttttttttt     eeeeeeee\"\n",
      "batch 1818  loss=120.6539  steps/s=104.28  prediction: \"nd of mental ownership over the codebase\" => \"g i  e                            eeeeee\"\n",
      "batch 1819  loss=147.7370  steps/s=96.92  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"o t    oooooooooaaaaaaaa              ee\"\n",
      "batch 1820  loss=143.5289  steps/s=103.44  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"tn                 tttttttttttttt///////\"\n",
      "batch 1821  loss=130.0970  steps/s=104.98  prediction: \"house? where is your phone charger? etc)\" => \"ereeoo                                re\"\n",
      "batch 1822  loss=126.7488  steps/s=86.39  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \" oteoo hhhehes   ooo  ooo     ssrrr rr t\"\n",
      "batch 1823  loss=153.0705  steps/s=93.67  prediction: \"wigABAP a friendly virus. one that talks\" => \"htt   h               i  ss  sss    tttt\"\n",
      "batch 1824  loss=123.5066  steps/s=106.62  prediction: \"he going gets tough, the tough get going\" => \"erreheeeee ee    gggggggggttgtttgggggggg\"\n",
      "batch 1825  loss=134.0125  steps/s=102.13  prediction: \" I wouldnt know, maybe someone else does\" => \"a                          ooooooeeeeeee\"\n",
      "batch 1826  loss=137.3726  steps/s=82.92  prediction: \"eigecamry @sunsettler shredded that shit\" => \" n : @              n ssseeeeeeeeeeddeee\"\n",
      "batch 1827  loss=151.9525  steps/s=103.91  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ne on ddd                ttttttttt//////\"\n",
      "batch 1828  loss=131.0128  steps/s=104.09  prediction: \"d its helped man. i shpuld sleep too lol\" => \" ia                                    l\"\n",
      "batch 1829  loss=125.6749  steps/s=104.90  prediction: \" think it applies to others that do this\" => \"th            iiiiii       ttttttttttttt\"\n",
      "batch 1830  loss=123.5830  steps/s=102.36  prediction: \"y noticed the last time i was there, lol\" => \" fzniiiiiiiiieeeeeettttt                \"\n",
      "batch 1831  loss=125.4414  steps/s=99.82  prediction: \"ood at noticing things, would be so kino\" => \"ur  ttgtttttttttttttttggiiii            \"\n",
      "batch 1832  loss=137.4275  steps/s=106.58  prediction: \"learn thing -&gt; compress thing, repeat\" => \"y   ysrnnnnnnnnnnnnnnnggg               \"\n",
      "batch 1833  loss=128.5704  steps/s=93.59  prediction: \" thanks man! i should uh sleep more yeah\" => \"toun naaaaaaaaa               h     eeee\"\n",
      "batch 1834  loss=147.2613  steps/s=101.07  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"nd t o tt prpppssssssssssssssssttt//////\"\n",
      "batch 1835  loss=138.2668  steps/s=104.82  prediction: \"e gets servers/multiplayer working too..\" => \" i : @     eeeeeeeeeeeeeeeeeeerrrrrrrrrr\"\n",
      "batch 1836  loss=133.9744  steps/s=97.05  prediction: \"th @wordgrammer i love large lean models\" => \" it  iaeeeerrrrrrrrrrrrlrr   llll l ee l\"\n",
      "batch 1837  loss=135.2932  steps/s=104.97  prediction: \" eat. 500cal ea =&gt; 1500 extra cal/day\" => \"tnea e                  00000000        \"\n",
      "batch 1839  loss=167.0996  steps/s=95.24  prediction: \"Rohit @archived_videos @discord its fake\" => \"Tn@t   aaaaa a     a      e         dd  \"\n",
      "batch 1840  loss=132.1031  steps/s=56.39  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"tLet  aaoaaar      eo  dd ededd cc      \"\n",
      "batch 1841  loss=130.5441  steps/s=108.43  prediction: \"sicily, i hope to see the island one day\" => \" ffrm iiiiiiiii                         \"\n",
      "batch 1843  loss=122.5430  steps/s=78.90  prediction: \"arcyan now you can make pokemon real too\" => \"nis  i i                    eeee oeee   \"\n",
      "batch 1844  loss=127.9312  steps/s=104.60  prediction: \" try to figure out why your brain worksâ€¦\" => \"th t t                                rr\"\n",
      "batch 1845  loss=134.1653  steps/s=105.00  prediction: \"imative vehicle for personal development\" => \"ne i  iiiiiiiiiiiii  eeeeeee  eeeeeeeeee\"\n",
      "batch 1846  loss=214.3257  steps/s=10.84  prediction: \"reply: @pixqc ok https://t.co/7zZszIGt52\" => \"epii  iiiiiiiiiiii   eeeeee   eeeeeeeeee\"\n",
      "batch 1847  loss=227.6538  steps/s=162.53  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"o  phreEEEEEEEEOOOOOOOOOOOO             \"\n",
      "batch 1848  loss=134.0107  steps/s=103.75  prediction: \"t channel you found that effing exploded\" => \"hae  ke                           ffffff\"\n",
      "batch 1849  loss=139.3324  steps/s=102.07  prediction: \" windows update almost bricked my laptop\" => \"th i i              a                   \"\n",
      "batch 1850  loss=127.8034  steps/s=101.44  prediction: \"ely definitely worth messing around with\" => \" ytiiiieiiiiiiiiieeeeeeeeeeee           \"\n",
      "batch 1851  loss=145.6429  steps/s=96.25  prediction: \"ure Beautiful, and great choice of music\" => \"re i eeeeeeeeeeeet                      \"\n",
      "batch 1852  loss=148.3618  steps/s=103.78  prediction: \"norary dan if i can be an honorary denis\" => \" re   a                                 \"\n",
      "batch 1854  loss=164.5436  steps/s=105.31  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" ae t    ,,,,,,,,,   ........    xxxxxxx\"\n",
      "batch 1855  loss=148.8169  steps/s=95.50  prediction: \"Lets go. Hoppin on now. The grind begins\" => \" ae         .                           \"\n",
      "batch 1856  loss=135.6521  steps/s=100.90  prediction: \" on linkedin will be typing in lowercase\" => \"@n  ee eennnnnnnnnnn                    \"\n",
      "batch 1857  loss=126.1452  steps/s=109.11  prediction: \"tony learns domain expansion in season 5\" => \"  t   o     nnnnnnnnnnnnnnnnnnnnnnnnnnnn\"\n",
      "batch 1858  loss=137.6430  steps/s=103.37  prediction: \"plex projects in it but it was super fun\" => \"ly   e   eeeeee                         \"\n",
      "batch 1860  loss=129.0138  steps/s=104.52  prediction: \"cially long term stuff,  makes it harder\" => \"omle e                                  \"\n",
      "batch 1862  loss=134.0678  steps/s=104.59  prediction: \"ally understand the problem and the goal\" => \"nk  ooo                                 \"\n",
      "batch 1863  loss=166.9070  steps/s=104.26  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"tt.l  \n",
      "ttt///////tttttttt               \"\n",
      "batch 1864  loss=156.2081  steps/s=104.78  prediction: \"o\n",
      "Learn by doing, get compounding skills\" => \" \n",
      " ars                         ooooggggn\"\n",
      "batch 1865  loss=149.5522  steps/s=20.68  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" lyhs                        ooo ggggnnn\"\n",
      "batch 1866  loss=142.1632  steps/s=109.80  prediction: \"ks for me though. Carbs make me sluggish\" => \"e e e                                   \"\n",
      "batch 1867  loss=130.3938  steps/s=104.18  prediction: \"ession youll do something until its done\" => \"  ee  eeeeeeee  ooooooooooooo           \"\n",
      "batch 1868  loss=121.6785  steps/s=52.69  prediction: \": @teodor_io funny number go up type shi\" => \" @Sueeoeoooo ooooooooo o                \"\n",
      "batch 1869  loss=139.3621  steps/s=106.70  prediction: \"d first..still a bit cloudy but got theâ€¦\" => \" tha         ..                         \"\n",
      "batch 1870  loss=149.1117  steps/s=96.67  prediction: \"nus9 Thats super useful to know actually\" => \"d  im    ssssssssssssssuuuuuuu          \"\n",
      "batch 1871  loss=117.0072  steps/s=19.98  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @  ssssssssssssus uuuuu            \"\n",
      "batch 1872  loss=130.3925  steps/s=115.56  prediction: \"nd stop you from seeking rewards in life\" => \"d eB              ooooo                 \"\n",
      "batch 1873  loss=134.8423  steps/s=98.64  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"ti  u                       sssss       \"\n",
      "batch 1874  loss=131.6913  steps/s=103.92  prediction: \"e forever with a simple 5min interaction\" => \" sin eeeeeeeeeeee               iiiiiiii\"\n",
      "batch 1875  loss=129.0735  steps/s=68.92  prediction: \"EsotericCofe i think i could add that in\" => \"aS la seeeeee       i       i       ittt\"\n",
      "batch 1876  loss=133.8910  steps/s=107.01  prediction: \" possible, at least quote and add a take\" => \"tree ssssssssssllll                 aaaa\"\n",
      "batch 1877  loss=124.1669  steps/s=104.09  prediction: \"you into thinking hes an anime character\" => \" uo ti                    nnnnnnn       \"\n",
      "batch 1878  loss=134.7942  steps/s=103.90  prediction: \"makes it an order of magnitude harder...\" => \"ama na                                dr\"\n",
      "batch 1879  loss=133.2117  steps/s=105.39  prediction: \"our sword and over time makes you deadly\" => \"n io                                    \"\n",
      "batch 1880  loss=151.3773  steps/s=99.38  prediction: \"en helpful!! ah nice addition, good idea\" => \"  y:                              dddddd\"\n",
      "batch 1881  loss=140.1083  steps/s=104.16  prediction: \"is new wave of RL stuff im seeing lately\" => \"n  th                                   \"\n",
      "batch 1882  loss=135.6401  steps/s=105.10  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n  i                            iiiiiiii\"\n",
      "batch 1883  loss=161.9220  steps/s=74.02  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"noin o            oot   ttttittittiiiiii\"\n",
      "batch 1884  loss=153.4911  steps/s=106.53  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \"hon i  llllllllllllllll111000000????????\"\n",
      "batch 1885  loss=129.0008  steps/s=101.74  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"u            oooooooooooooohhhaa    ssss\"\n",
      "batch 1886  loss=125.7839  steps/s=100.87  prediction: \"u decide to start building it initially?\" => \"twde  edddd                    iiiiiiiii\"\n",
      "batch 1887  loss=176.3567  steps/s=64.13  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"grbeodeddd ddddt   tttttttittiiiiiiiiiii\"\n",
      "batch 1888  loss=129.1457  steps/s=31.21  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" ly: @eddd ddddt  ttttttttittiiiiiiiiiii\"\n",
      "batch 1890  loss=137.3329  steps/s=116.39  prediction: \" the code in my head like an interpreter\" => \"@hdnhrn                              eee\"\n",
      "batch 1891  loss=140.4746  steps/s=102.35  prediction: \"ollowed you on li\n",
      "my lichess is @dnbt777\" => \"ulo looooooooooooool                    \"\n",
      "batch 1892  loss=134.8792  steps/s=103.45  prediction: \" since llms are not great with zig (ime)\" => \"@ts                                     \"\n",
      "batch 1893  loss=130.4558  steps/s=100.13  prediction: \"n pick your own time though its flexible\" => \"gMta                                  ii\"\n",
      "batch 1894  loss=135.0842  steps/s=102.22  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"@ e  o                   ttttttt////////\"\n",
      "batch 1895  loss=130.6108  steps/s=101.61  prediction: \"rappers around statistical distributions\" => \"enly: @  rrrrrrrrrrsssssssstttttttttttti\"\n",
      "batch 1896  loss=126.2730  steps/s=94.42  prediction: \"izo with that soundtrack its hard not to\" => \"ne o stttt tt  ttttttttttttttttiiitti   \"\n",
      "batch 1897  loss=137.9567  steps/s=105.51  prediction: \"a recent nvim noob Tutor is super useful\" => \"nmod                                  uu\"\n",
      "batch 1898  loss=135.3730  steps/s=101.04  prediction: \" realize big companies innovated anymore\" => \"@esddoddd            iiiiiiiiiinnnnnnnnn\"\n",
      "batch 1899  loss=130.8265  steps/s=105.35  prediction: \"to someone on X, its laggy when it plays\" => \"h u   i                                 \"\n",
      "batch 1900  loss=127.7733  steps/s=104.68  prediction: \"en get way too absorbed into one of them\" => \"  I                       oooooooooooooo\"\n",
      "batch 1901  loss=135.9999  steps/s=104.36  prediction: \"ed for editing videos would be so goated\" => \"  o  eeeeeeeeeeeeeeiiiiiii              \"\n",
      "batch 1903  loss=138.6521  steps/s=105.16  prediction: \" an extremely powerful idea when applied\" => \"t r               eeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1904  loss=146.5748  steps/s=103.34  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" sr  iss/???????????????kk              \"\n",
      "batch 1905  loss=149.6394  steps/s=100.73  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y  @sssssssssssssssss  ssstttt//////////\"\n",
      "batch 1906  loss=138.3730  steps/s=101.74  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"ni aeettaaaaaaaaaaaanaaaaaaaaaaa      LL\"\n",
      "batch 1907  loss=176.9016  steps/s=63.98  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"yacingaggaaaannn       a            !Loo\"\n",
      "batch 1908  loss=126.2856  steps/s=108.17  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"ne al          eeeeeeeeeeeeeerrrrrrrrraa\"\n",
      "batch 1909  loss=126.4549  steps/s=21.12  prediction: \"eply: @tunahorse21 its really that good?\" => \" ly  l        eeeeeeeeeeeeerrrrrarraaaal\"\n",
      "batch 1910  loss=181.8139  steps/s=123.98  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"nm al           TTTT        EEEEELLLLLLL\"\n",
      "batch 1911  loss=136.6463  steps/s=104.99  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"nl yoee                                 \"\n",
      "batch 1912  loss=147.6904  steps/s=104.83  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \"hasil           oooooooooooonnnnnnnn    \"\n",
      "batch 1913  loss=141.7670  steps/s=103.66  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"nA  o o               eeeeeeeeeeeeeeeeee\"\n",
      "batch 1914  loss=128.8981  steps/s=93.74  prediction: \"upmillyair microsoft is a faulty company\" => \" sogo o rrriiiiirrrri                 yy\"\n",
      "batch 1915  loss=128.6861  steps/s=105.72  prediction: \"able for whoever owns the algorithm/site\" => \"neor  eeeeeeeeeeeeeeeeee                \"\n",
      "batch 1916  loss=145.0726  steps/s=100.66  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \" c  ze              aa  ooo             \"\n",
      "batch 1917  loss=194.4861  steps/s=21.89  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly  @           aa oo  oto             \"\n",
      "batch 1920  loss=124.8200  steps/s=129.07  prediction: \"im how fun the funny computer things are\" => \"ne                                      \"\n",
      "batch 1921  loss=129.0321  steps/s=105.82  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" oi  offffff             tttttt/////////\"\n",
      "batch 1922  loss=130.2525  steps/s=104.79  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"yy ei l  lll                         aaa\"\n",
      "batch 1924  loss=129.7439  steps/s=102.14  prediction: \"e unbelievably interesting and beautiful\" => \" c in         bbbbbeeeeeeeeeeennnnnnnnnn\"\n",
      "batch 1926  loss=119.9115  steps/s=69.49  prediction: \"notmoeezm gotta love the non specificity\" => \"dttg  oeeeeeee   eeeeeeeeeennnnnnnniiiii\"\n",
      "batch 1927  loss=131.2355  steps/s=106.62  prediction: \"t immensely and give you new information\" => \" ing  e                                 \"\n",
      "batch 1930  loss=115.8731  steps/s=10.80  prediction: \"reply: @calbch its the year of the monad\" => \"eplimi                                 n\"\n",
      "batch 1931  loss=155.1702  steps/s=113.75  prediction: \"nonstop about that compression challenge\" => \"g  o nonnnnnnnnnotttttttttttttooooooooo \"\n",
      "batch 1932  loss=179.5005  steps/s=66.33  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" thi sonno t   tttttttttttssoooooco  oee\"\n",
      "batch 1933  loss=133.3249  steps/s=112.46  prediction: \"honorary denis\n",
      "\n",
      "and got gelato in venice\" => \"esk t e             nnnn nn n           \"\n",
      "batch 1934  loss=205.8172  steps/s=98.90  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \"uGae      OOOOOOIIII NN          v    ii\"\n",
      "batch 1935  loss=133.8445  steps/s=103.15  prediction: \"e soda\n",
      "\n",
      "actually nvm this one tastes meh\" => \" j eee     aaaaaaaaaaaaaaa              \"\n",
      "batch 1936  loss=147.6804  steps/s=102.21  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  ce ceeeeeeeeeeee        tttttttt//////\"\n",
      "batch 1937  loss=141.7336  steps/s=103.87  prediction: \"eakens your life-problem solving ability\" => \" n t  n                eeeeeelllllllllll\"\n",
      "batch 1938  loss=157.8301  steps/s=104.82  prediction: \"boards to learn the keys other ppl used)\" => \"eta  aaaa                               \"\n",
      "batch 1939  loss=138.3023  steps/s=103.30  prediction: \"t the truth/reality?\n",
      "\n",
      "sounds paradoxical\" => \" is  e      ttttttttttttttttttttt\n",
      "raaaaa\"\n",
      "batch 1940  loss=125.6192  steps/s=100.63  prediction: \"hine now. unless anybody has a spare one\" => \"atki         nnnnnnnnnnnnn              \"\n",
      "batch 1941  loss=133.7899  steps/s=102.70  prediction: \"racticing self control leads to strength\" => \"eply: @c00    c  cccc                   \"\n",
      "batch 1942  loss=165.4966  steps/s=102.42  prediction: \"up man youre gonna go far over the years\" => \"seie                                    \"\n",
      "batch 1944  loss=132.9322  steps/s=104.99  prediction: \" personally make you a funny monkey meme\" => \"@la     lllllllllll                     \"\n",
      "batch 1945  loss=166.7874  steps/s=99.62  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"m b_  iiiiiiiieggggg&&&&&;;;;;;;ggggtttt\"\n",
      "batch 1947  loss=163.2604  steps/s=96.73  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \" iy: @ e ee   ttttttttttttttttttttt/////\"\n",
      "batch 1948  loss=152.6472  steps/s=99.71  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"ezi   nnnn                         ddddd\"\n",
      "batch 1949  loss=139.3625  steps/s=103.34  prediction: \" end of the task off worked for you too?\" => \"@ dtietetee                fffff     ooo\"\n",
      "batch 1950  loss=134.3609  steps/s=104.98  prediction: \" only improve by improving their skills)\" => \"@fe ts                        iiiiiiiiii\"\n",
      "batch 1951  loss=141.3913  steps/s=105.02  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" ts              tttttttttttttttttttt///\"\n",
      "batch 1952  loss=172.8965  steps/s=104.45  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" t ttccccccccccccceeeeeettttttttt///////\"\n",
      "batch 1953  loss=133.5833  steps/s=100.08  prediction: \"the replies here\n",
      "https://t.co/9TNeUoLw5k\" => \" el           eeeeeeeeeeeeeettttttttt///\"\n",
      "batch 1954  loss=136.3889  steps/s=104.98  prediction: \"g the cursor with your hands using video\" => \" ih  lllll                              \"\n",
      "batch 1955  loss=138.9938  steps/s=102.18  prediction: \" w as in why tf would you use white mode\" => \"to eep                                  \"\n",
      "batch 1956  loss=138.7820  steps/s=100.59  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \" co e           dddddddddddddhootttttttt\"\n",
      "batch 1957  loss=126.7744  steps/s=102.98  prediction: \" stream but i do my actual job and stuff\" => \"tt ee                                   \"\n",
      "batch 1958  loss=142.8660  steps/s=102.39  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e t  \n",
      "Rtttttt                           \"\n",
      "batch 1959  loss=128.5540  steps/s=105.63  prediction: \"ont like tech leave\n",
      "\n",
      "bulking and cutting\" => \"nt t  ttttttt       eeeeeeeeeeeee     nn\"\n",
      "batch 1960  loss=131.2306  steps/s=104.59  prediction: \" software used that widely is so awesome\" => \"tui a                                   \"\n",
      "batch 1961  loss=133.4764  steps/s=104.38  prediction: \"d all the aliases for commands to bashrc\" => \" oe  t aaa  aaaaa                       \"\n",
      "batch 1962  loss=149.6665  steps/s=100.90  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"enahcan n                       dddddddd\"\n",
      "batch 1963  loss=144.2034  steps/s=96.34  prediction: \"d 1995 type sites are such a great style\" => \" an_! aa                s               \"\n",
      "batch 1964  loss=159.2317  steps/s=58.78  prediction: \" @brianf3rnandez @crungulism Like 20mins\" => \"tana   999            ssr               \"\n",
      "batch 1965  loss=132.9920  steps/s=109.58  prediction: \"ely matters when the post is this useful\" => \" lar tteeeeeeeeeeeeeeeee             sss\"\n",
      "batch 1966  loss=134.1109  steps/s=98.98  prediction: \"ick and no login and as free as possible\" => \"ne s                nnn                s\"\n",
      "batch 1967  loss=134.0723  steps/s=105.53  prediction: \"y do what sounds more interesting to you\" => \" th ob                                  \"\n",
      "batch 1968  loss=134.2866  steps/s=102.46  prediction: \"hinks he might pick up in future decades\" => \"en hi iihhhhhhhhhh                      \"\n",
      "batch 1969  loss=140.1321  steps/s=104.04  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes              tttttttttttttttttttt///\"\n",
      "batch 1970  loss=135.4754  steps/s=105.05  prediction: \"ys end up thinking \"nah they would justâ€¦\" => \"  o a                   nnnnnnn         \"\n",
      "batch 1971  loss=140.1969  steps/s=103.26  prediction: \"well\n",
      "\n",
      "maxing it out is worth considering\" => \"ite  nn                                i\"\n",
      "batch 1972  loss=157.7905  steps/s=104.86  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" conostt                    tttt////////\"\n",
      "batch 1973  loss=127.9144  steps/s=104.96  prediction: \" some but its not easy to put into words\" => \"tee s                                 t \"\n",
      "batch 1974  loss=126.3758  steps/s=100.95  prediction: \"o beta testers, and the world soon after\" => \" s eee   tttttttttttttt                 \"\n",
      "batch 1975  loss=146.1704  steps/s=96.56  prediction: \" stuff! Thanks, hope yours went well man\" => \"toe   o     ss                          \"\n",
      "batch 1976  loss=132.2914  steps/s=105.00  prediction: \"has any non-json, ask for json in prompt\" => \"en so          nnnnnnnnn                \"\n",
      "batch 1977  loss=133.7251  steps/s=102.97  prediction: \"to save this for later in case I forget\"\" => \"h s  e                                  \"\n",
      "batch 1978  loss=151.1830  steps/s=102.46  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" nh oaaaaanssss   aar    rr          ee \"\n",
      "batch 1979  loss=133.7186  steps/s=104.76  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \" dyy            uuuuuuuhhhhhhhhhhhhhh   \"\n",
      "batch 1980  loss=134.0342  steps/s=103.89  prediction: \"esting example of goodharting the reward\" => \"  btttttteeeeeeeeeeeeeee ooooooo        \"\n",
      "batch 1981  loss=134.0064  steps/s=104.76  prediction: \"hitectures. it only finds different MLPs\" => \"anN nvneeeeeeeeetttt                    \"\n",
      "batch 1982  loss=136.5070  steps/s=104.92  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" rn t ltlllllnnnnnnnnnnnnttttttttttt////\"\n",
      "batch 1984  loss=144.1880  steps/s=104.25  prediction: \"darin and english which they are meh at)\" => \" ne  xp     nnnnnnnnnnn      hhhhhhhhhh \"\n",
      "batch 1985  loss=135.2323  steps/s=104.79  prediction: \" you should waste money\n",
      "&lt;/caveats&gt;\" => \"toy y                             aaaaa&\"\n",
      "batch 1986  loss=124.9323  steps/s=101.93  prediction: \" put you so far ahead its not even funny\" => \"to   ol                                 \"\n",
      "batch 1987  loss=147.8539  steps/s=103.35  prediction: \"amming you can make bigger leaps though.\" => \"n  t2 5                      gg         \"\n",
      "batch 1988  loss=134.6304  steps/s=99.81  prediction: \"king stuff part of twitter is so fun wtf\" => \"en   g 0                tt      tt      \"\n",
      "batch 1990  loss=143.3951  steps/s=99.24  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" py: @aaaaaaaawwwwwllllllllllllllllliiii\"\n",
      "batch 1991  loss=134.8996  steps/s=104.39  prediction: \" so I invested my time into that instead\" => \"ttreeoooo                         tttttt\"\n",
      "batch 1992  loss=156.1258  steps/s=105.28  prediction: \"ood combo for stuff like this, ive found\" => \" m 4ooo ooooooooooooo f                 \"\n",
      "batch 1993  loss=135.3575  steps/s=104.05  prediction: \" this era where breaches happen so often\" => \"to   e iii          eeeeeeeeeeeeeeeeeeee\"\n",
      "batch 1994  loss=225.7819  steps/s=104.11  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OT  RGONNNOONNNNNN               ///////\"\n",
      "batch 1995  loss=135.1200  steps/s=103.11  prediction: \" sum bros.. pivot, its worth it trust me\" => \"te s           ..                 tttttt\"\n",
      "batch 1996  loss=139.3764  steps/s=104.74  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n alo o   rrrrrrrreeeeeeeeeeeoooooooooll\"\n",
      "batch 1997  loss=147.2846  steps/s=103.19  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"in iiiiiiisssssssssssttttttttt//////////\"\n",
      "batch 1999  loss=135.4949  steps/s=105.13  prediction: \"ly harder than the last. repeat forever.\" => \"e: i   hhhhhhhhhhhhhhhh            eeeee\"\n",
      "batch 2000  loss=131.2313  steps/s=104.73  prediction: \" my chess elo to give data that it works\" => \"ii e                              tttttt\"\n",
      "batch 2001  loss=125.8986  steps/s=104.64  prediction: \"you have to learn in order to build them\" => \" ur s                                   \"\n",
      "batch 2002  loss=183.4243  steps/s=87.70  prediction: \"ettler @gizmobly https://t.co/3UPliJk8JG\" => \"  a: @  tt                ttttt oo tt   \"\n",
      "batch 2003  loss=136.4686  steps/s=105.85  prediction: \"ongrats on finishing the moon easter egg\" => \"n  ahtaaaaaaaa  nnnnnnnnnnnnnnnn nn  eee\"\n",
      "batch 2004  loss=140.6667  steps/s=104.87  prediction: \"e we figure out that sleeping is a thing\" => \" ianneeeeeeeee                          \"\n",
      "batch 2005  loss=147.3886  steps/s=101.17  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"iotl ttllll             tttttttttt//////\"\n",
      "batch 2006  loss=134.3175  steps/s=99.87  prediction: \" I wouldnt know, maybe someone else does\" => \"i                         ooooooooeeeeee\"\n",
      "batch 2007  loss=129.2323  steps/s=105.21  prediction: \"at you mentioned. Variety and reloading.\" => \"nk,  o        nnnnnnnnnn              aa\"\n",
      "batch 2008  loss=142.1326  steps/s=100.05  prediction: \"ey sandwich has been achieved internally\" => \"   nrr                    ae eeeeeeeeeee\"\n",
      "batch 2009  loss=139.6422  steps/s=105.28  prediction: \"how it is in c++. Trace them rays brotha\" => \" \n",
      "e  e                                  \"\n",
      "batch 2010  loss=156.7079  steps/s=99.67  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" ss:              oooo  ttttttttttt/////\"\n",
      "batch 2011  loss=157.8938  steps/s=78.61  prediction: \"rchived_videos @LimkarRohit @discord LOL\" => \"eely: @ ooiiooooooooo  tttttt///tVVVVooo\"\n",
      "batch 2012  loss=133.3402  steps/s=105.04  prediction: \"this. or you can win by trading seats wâ€¦\" => \" e                                      \"\n",
      "batch 2013  loss=124.6105  steps/s=103.52  prediction: \"s of lib arts classes they make you take\" => \" aes eeeeee        sssssssssss          \"\n",
      "batch 2014  loss=141.4399  steps/s=102.54  prediction: \" windows update almost bricked my laptop\" => \"sh i i       ddddd                      \"\n",
      "batch 2015  loss=134.6729  steps/s=57.92  prediction: \" @pr0timr @btwphones Will post once done\" => \"s) i w    d    aaaa                     \"\n",
      "batch 2016  loss=179.4931  steps/s=114.64  prediction: \"1 @yacineMTB just dmd you the term sheet\" => \") 2 0 y@yy       ee                     \"\n",
      "batch 2017  loss=176.1413  steps/s=10.74  prediction: \"reply: @gizmobly https://t.co/dgCgB3AN81\" => \"eply: @y@y     j e                     e\"\n",
      "batch 2019  loss=136.8076  steps/s=107.49  prediction: \"me good advice\n",
      "What do you think of him?\" => \"e ta                ddddooooooo         \"\n",
      "batch 2020  loss=126.4377  steps/s=105.43  prediction: \", usually because you border more things\" => \" and ne        eeeeee  uuuuuuu          \"\n",
      "batch 2021  loss=156.7712  steps/s=101.12  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n  ititttttiiiiiiiiiiiiiizzzziiiiiii    \"\n",
      "batch 2022  loss=126.7279  steps/s=105.48  prediction: \"t, bc you can edit/delete prompt history\" => \"  r  eatt                   eeeeeeeeeett\"\n",
      "batch 2023  loss=132.4699  steps/s=100.69  prediction: \"but i followed just in case you do pivot\" => \"ec                                      \"\n",
      "batch 2024  loss=135.4611  steps/s=100.34  prediction: \"x reddit is the strange people attractor\" => \" ua eeeeeeeeeeeeetttt      eeeeeeeeeeett\"\n",
      "batch 2025  loss=127.3689  steps/s=101.50  prediction: \"fundamentals is a smart smart smart move\" => \" r tin    aaaaaaa             ssssssmmmm\"\n",
      "batch 2026  loss=157.4233  steps/s=105.06  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne e   MMssssssss  @@@@@rrrrrrrrrrrrrrrr\"\n",
      "batch 2027  loss=126.6914  steps/s=102.17  prediction: \"an is usually to attack so imma do that\"\" => \"nd s                                    \"\n",
      "batch 2028  loss=132.4430  steps/s=104.26  prediction: \" here is valuable, the sooner the better\" => \"tae yye                    eee eeeeeeeee\"\n",
      "batch 2029  loss=132.7233  steps/s=100.90  prediction: \" to make it better before (if) I release\" => \"the  ee             teteeeeeeeee    eeee\"\n",
      "batch 2030  loss=195.6840  steps/s=11.12  prediction: \"reply: @pixqc ok https://t.co/7zZszIGt52\" => \"eply: @             teeeeeeeeee     e ee\"\n",
      "batch 2031  loss=128.6797  steps/s=109.12  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"too   rr rrrr        ssssss             \"\n",
      "batch 2032  loss=161.2787  steps/s=100.99  prediction: \"? i actually dont know anything abt groq\" => \" ii  t ?????                   nnnnnnnn \"\n",
      "batch 2033  loss=126.3931  steps/s=104.72  prediction: \"hat \"group photo\" means several entities\" => \"et   t                           eeeeeee\"\n",
      "batch 2034  loss=158.4521  steps/s=101.64  prediction: \" grows ur skills\n",
      "https://t.co/9ZBc4ushgS\" => \"to t  t            sssssssssstttt///////\"\n",
      "batch 2035  loss=155.0820  steps/s=103.62  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \"a o  sooooooooo            ///////////tt\"\n",
      "batch 2036  loss=137.7268  steps/s=103.86  prediction: \", how much info could you get from that?\" => \" ao  i                                  \"\n",
      "batch 2037  loss=146.9395  steps/s=98.00  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \" se reatt                               \"\n",
      "batch 2039  loss=142.9749  steps/s=101.22  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"tate                tttttttttttttttt////\"\n",
      "batch 2040  loss=132.6587  steps/s=103.18  prediction: \" (by trusting in ideas) and testing them\" => \"tythe   tttttttt                        \"\n",
      "batch 2041  loss=128.7351  steps/s=102.75  prediction: \"g correct (fingers crossed its this one)\" => \" a e e rrrrrrrrrrrrrrrrrrrrrrrssssssssss\"\n",
      "batch 2042  loss=130.6038  steps/s=96.79  prediction: \"xe only the strongest can take this path\" => \" ri igggg                  tt tttt      \"\n",
      "batch 2043  loss=133.3716  steps/s=104.01  prediction: \"e, i would also have liked to be yacine\"\" => \"                                        \"\n",
      "batch 2044  loss=118.0398  steps/s=101.30  prediction: \" a cross section now that you mention it\" => \"t kd k                                  \"\n",
      "batch 2045  loss=131.2773  steps/s=104.61  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"a aeinnnnnnnn                      ttttt\"\n",
      "batch 2046  loss=141.5959  steps/s=105.77  prediction: \"xperience that will make me live longer)\" => \" l      eeeeeeeeeeeeeee            lllll\"\n",
      "batch 2047  loss=131.1486  steps/s=104.58  prediction: \"your time for fruitful endeavors instead\" => \" u  o                 fffffffff  rrr  ee\"\n",
      "batch 2048  loss=131.5070  steps/s=105.04  prediction: \"se? seems like death spiral potential no\" => \"  ee eeeeeeeeeeeeeeeeeee                \"\n",
      "batch 2050  loss=135.6668  steps/s=105.07  prediction: \"ay simpler, but also much more effective\" => \"n   o                                   \"\n",
      "batch 2052  loss=130.6919  steps/s=96.72  prediction: \"ok me a second but damn thats a good one\" => \"u y S  eee                              \"\n",
      "batch 2053  loss=136.2579  steps/s=100.24  prediction: \"he stopped existing after the last frame\" => \"e e            eeeeee eeee eeeeettttttt \"\n",
      "batch 2054  loss=225.5221  steps/s=100.51  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"t.@oe tt/////////tttttttttt/////////////\"\n",
      "batch 2055  loss=135.7804  steps/s=105.06  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n  a                           iiiiiiiii\"\n",
      "batch 2056  loss=136.5827  steps/s=104.95  prediction: \"ting up prints, never had a problem w it\" => \"ho a                                    \"\n",
      "batch 2057  loss=137.5487  steps/s=105.46  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" ii  ct       aaaaaatttttttttttttt//////\"\n",
      "batch 2058  loss=131.5503  steps/s=102.09  prediction: \" pool (at least once seems cold tho ngl)\" => \"trtt o                    eeeeeeee      \"\n",
      "batch 2060  loss=174.8042  steps/s=105.13  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns   s                tttttttttttt//////\"\n",
      "batch 2061  loss=172.3359  steps/s=104.52  prediction: \"dnt acct for maintenance/electricity tho\" => \" yn                    annnnnneccccccccc\"\n",
      "batch 2062  loss=134.5464  steps/s=106.12  prediction: \"ang out in tunisia every once in a while\" => \"nd e                                    \"\n",
      "batch 2063  loss=147.3111  steps/s=100.88  prediction: \"nally get monads\n",
      "https://t.co/lYN3cpV8JV\" => \" MTBn  e                ttttttttt///////\"\n",
      "batch 2064  loss=135.0940  steps/s=105.25  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"am H  eeeeeeeeee         aaaaaaaaaaa    \"\n",
      "batch 2065  loss=142.7703  steps/s=102.56  prediction: \"so much better than ppl who dont anyways\" => \"  oo o                                  \"\n",
      "batch 2066  loss=143.2542  steps/s=104.85  prediction: \"te correctly lol\n",
      "https://t.co/0eYn1IVGOH\" => \"hrg pte       cccccttttttttttt//////////\"\n",
      "batch 2067  loss=153.4047  steps/s=103.80  prediction: \"us @BasedBeffJezos Some are on the money\" => \"s @n@sssssssseeeBBeeeeeeeeeeeeeeee      \"\n",
      "batch 2068  loss=132.2031  steps/s=103.21  prediction: \" deadlines dont really get done the same\" => \"@oi   o   ddddddddddd                  e\"\n",
      "batch 2069  loss=126.7896  steps/s=68.82  prediction: \"@yacineMTB so youre no longer locked in?\" => \"tayiaoteeedde       e  e     e   e    ee\"\n",
      "batch 2070  loss=121.7656  steps/s=107.23  prediction: \"ark a bit so i felt like writing this up\" => \"le a                         iiiiiiiiiii\"\n",
      "batch 2071  loss=145.9279  steps/s=100.93  prediction: \"y the paper i thought it was a neat read\" => \":tilp     pppppp      h                 \"\n",
      "batch 2072  loss=135.6893  steps/s=105.40  prediction: \"ly when you try to build the thing again\" => \"y                                       \"\n",
      "batch 2073  loss=132.9342  steps/s=105.14  prediction: \"the behavior, forming a habit eventually\" => \"he  igeeeeeeee                          \"\n",
      "batch 2074  loss=137.2661  steps/s=104.74  prediction: \"per curious to see what youre working on\" => \"lrt tsa                                 \"\n",
      "batch 2075  loss=132.7473  steps/s=102.45  prediction: \" (by trusting in ideas) and testing them\" => \"ty st  ttttttttt                        \"\n",
      "batch 2076  loss=166.5841  steps/s=11.97  prediction: \"reply: @ludwigABAP @0xluffyb just be you\" => \"ep  y  sttttttt                         \"\n",
      "batch 2077  loss=155.0796  steps/s=121.82  prediction: \"ock your 1000th follower and stay at 999\" => \" h te e            00000000lo           \"\n",
      "batch 2078  loss=181.5265  steps/s=31.29  prediction: \"ply: @cto_junior https://t.co/BLe9cxo4Bp\" => \"ly: @iu          0000000oooooo          \"\n",
      "batch 2079  loss=154.0691  steps/s=108.19  prediction: \"ng up every word you hear more than once\" => \"g  wo                                   \"\n",
      "batch 2080  loss=135.1209  steps/s=105.48  prediction: \"rong tho, my confidence is only like 70%\" => \"edrto                                   \"\n",
      "batch 2081  loss=128.5022  steps/s=102.16  prediction: \"learn lean just so i can make lean jokes\" => \"y  w  l                                 \"\n",
      "batch 2083  loss=136.0265  steps/s=99.15  prediction: \"ely grinded like mad towards His mission\" => \" llallllleeeeeeeeeeee      dddddd      s\"\n",
      "batch 2084  loss=127.6091  steps/s=105.60  prediction: \"retty great as well, hes also on youtube\" => \"eplio                                   \"\n",
      "batch 2086  loss=133.7826  steps/s=99.63  prediction: \" for yourself they pay dividends forever\" => \"touoooooooooooooo                     ee\"\n",
      "batch 2087  loss=142.6238  steps/s=101.16  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"@oo      nnnnnnnnnnooooooooooo          \"\n",
      "batch 2088  loss=132.3852  steps/s=105.30  prediction: \"t (for example working when youre tired)\" => \"hcoush oooooooooooooo                   \"\n",
      "batch 2089  loss=150.8349  steps/s=105.94  prediction: \"nch @yacineMTB let the a b testing BEGIN\" => \" idosc    ccc       e   ee              \"\n",
      "batch 2091  loss=140.1048  steps/s=103.17  prediction: \"ike a combinatoric sized pain in the ass\" => \"ne o                iiiiiiiiiiiiiiiii   \"\n",
      "batch 2092  loss=133.2785  steps/s=104.04  prediction: \"te how much some debuffs will damage yoâ€¦\" => \" p    etttt                             \"\n",
      "batch 2093  loss=130.8447  steps/s=105.32  prediction: \"ions you choose, like oregon or whatever\" => \"nf roo ooooooooooooooooooooooooooo     e\"\n",
      "batch 2094  loss=129.0215  steps/s=99.38  prediction: \"surely you will not regret this decision\" => \" t   oaaas                             e\"\n",
      "batch 2095  loss=185.9356  steps/s=99.07  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"et   ononnnyyy        .........ttt//////\"\n",
      "batch 2096  loss=137.4058  steps/s=105.40  prediction: \"mething to run from (getting called out)\" => \"athsnveeeeeeee                          \"\n",
      "batch 2097  loss=127.3891  steps/s=46.67  prediction: \"y: @thevalidcode Was just gonna say this\" => \"  @aeeeeee      o       ttggggnn       t\"\n",
      "batch 2098  loss=120.7742  steps/s=122.41  prediction: \"for getting me to read this btw, its fun\" => \" rm ntn                                 \"\n",
      "batch 2099  loss=128.5550  steps/s=105.24  prediction: \"orthless. you find the gold when you dig\" => \"ned seessssssssssss                     \"\n",
      "batch 2100  loss=137.0040  steps/s=105.00  prediction: \")\n",
      "RAG would be very useful for requestsâ€¦\" => \"\n",
      " ott rrrr                           eee\"\n",
      "batch 2101  loss=144.5942  steps/s=101.44  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \"hln cr     aaaaaaaaattttttttttttt///////\"\n",
      "batch 2102  loss=140.6262  steps/s=103.05  prediction: \"ts one of the fundamentals of everything\" => \"h nt r                          eeeeeeee\"\n",
      "batch 2103  loss=138.1897  steps/s=103.70  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"teatan   pppaaaaaaaaaaattttttttttt//////\"\n",
      "batch 2104  loss=141.6540  steps/s=100.73  prediction: \"g through dingboard clone phase again ig\" => \" BAP tiggggggggggggg  ooooo             \"\n",
      "batch 2105  loss=131.7840  steps/s=104.53  prediction: \" so that the context switch is seamless.\" => \"to                  tttttttttttttt  ssss\"\n",
      "batch 2106  loss=131.3469  steps/s=105.87  prediction: \"ful info have you learned from it so far\" => \" l  nlluu                               \"\n",
      "batch 2107  loss=166.7095  steps/s=97.06  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"tseu aaaaaaaaaaaaa a a    ttt  tttt/////\"\n",
      "batch 2108  loss=122.3423  steps/s=56.20  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tshu aaaaaa aa       tttttttt//////11111\"\n",
      "batch 2109  loss=142.6729  steps/s=114.20  prediction: \"s if you do both\n",
      "https://t.co/EXEA72MrEm\" => \" aua                     tttttt/////EEEE\"\n",
      "batch 2110  loss=146.4785  steps/s=100.04  prediction: \"tings, and speeding up my workflow, you?\" => \" lt  eeeee   eeeeeeeee                  \"\n",
      "batch 2111  loss=116.8970  steps/s=99.60  prediction: \"n in the ass to get it to stop shuffling\" => \"gtgs aa                        t ttttttt\"\n",
      "batch 2112  loss=123.2661  steps/s=97.53  prediction: \"ttler experimentation games are the best\" => \" eas ae  eeeteeeeeetttttttttt           \"\n",
      "batch 2113  loss=131.4317  steps/s=103.13  prediction: \" of your day your brain will work better\" => \"@ne te                                  \"\n",
      "batch 2114  loss=119.8677  steps/s=105.91  prediction: \"ink thats gonna be a massive rabbit hole\" => \"ng     tttttttttt             aaaaaabbbb\"\n",
      "batch 2115  loss=173.7313  steps/s=105.02  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" o .cqccccccccccc           ooooo///////\"\n",
      "batch 2116  loss=132.5494  steps/s=105.31  prediction: \"file editing program, will show vid soon\" => \" l ii    iiiiiiiiiiiiiiiiii  lll        \"\n",
      "batch 2117  loss=139.1960  steps/s=104.58  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"ty   e      ,,,,,,         sstttttttttt/\"\n",
      "batch 2119  loss=135.7582  steps/s=103.14  prediction: \"al of life that pays some huge dividends\" => \"nln                                     \"\n",
      "batch 2120  loss=165.3945  steps/s=104.35  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..oo oooooo/////tttttttttttt///////////\"\n",
      "batch 2121  loss=132.9791  steps/s=105.60  prediction: \"o get those kinds of sessions more often\" => \"rl                        ssssssssssssss\"\n",
      "batch 2122  loss=147.8878  steps/s=100.81  prediction: \"high quality patches they send to FFmpeg\" => \"en  th    h            hh               \"\n",
      "batch 2125  loss=134.5501  steps/s=104.87  prediction: \"If are not one, you stand out like crazy\" => \"  e e                                   \"\n",
      "batch 2126  loss=139.5993  steps/s=11.49  prediction: \"reply: @graffioh HA thats really awesome\" => \"e tse                                   \"\n",
      "batch 2127  loss=134.5931  steps/s=115.68  prediction: \"r the ceo and coo\n",
      "\n",
      "17.5hr day today lool\" => \"esoso f               ooo             oo\"\n",
      "batch 2128  loss=168.5971  steps/s=103.02  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"to    ee             t   t t tttttttoo88\"\n",
      "batch 2129  loss=141.0857  steps/s=98.93  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "ffoo                          cccc     \"\n",
      "batch 2130  loss=132.1062  steps/s=102.76  prediction: \" is a wild computational rabbithole man.\" => \"t   pa                    aaaaaaaaaaaaaa\"\n",
      "batch 2131  loss=137.4446  steps/s=102.30  prediction: \" and functional, genius place for a blog\" => \"tnre               nnnnnnnnnnnn         \"\n",
      "batch 2132  loss=131.2795  steps/s=100.94  prediction: \"so much to develop it? regulatory maybe?\" => \"                                        \"\n",
      "batch 2133  loss=153.3368  steps/s=100.43  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"to   ot            ttttttttttttttttttttt\"\n",
      "batch 2134  loss=124.9181  steps/s=103.67  prediction: \" to get tons of llms to output good code\" => \"theet tttttttttt                oooooooo\"\n",
      "batch 2135  loss=134.8341  steps/s=100.67  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" tn t t        aaaaa   aaarraarrrraaaaag\"\n",
      "batch 2136  loss=134.3364  steps/s=104.01  prediction: \" fundamentals.  Take the time to invest.\" => \"too o       tt   aaaaaa                 \"\n",
      "batch 2137  loss=127.1654  steps/s=104.26  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" y    eeeeeeeeeee                tttttt \"\n",
      "batch 2138  loss=132.4524  steps/s=100.67  prediction: \" for yourself they pay dividends forever\" => \"to doooooooooooo                   ddddd\"\n",
      "batch 2139  loss=151.3686  steps/s=103.94  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"n  e eeeeeeeeeiiiiiiii   tttttttttttttt/\"\n",
      "batch 2140  loss=147.4404  steps/s=37.71  prediction: \"ly: @Purring_Lynx Good addition for sure\" => \"y: @reeeeeiiiiiii       ttttttttttt/////\"\n",
      "batch 2141  loss=134.6144  steps/s=128.90  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"ork  P rr          ooo     ooooooooo ooo\"\n",
      "batch 2142  loss=136.8719  steps/s=104.75  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  nn                       llllllllllll\"\n",
      "batch 2143  loss=172.8700  steps/s=103.45  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \"hc     a                                \"\n",
      "batch 2144  loss=170.6194  steps/s=97.16  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \" @   auuuuuuuuuuuuuuu        LL  LOOOOOO\"\n",
      "batch 2145  loss=131.8552  steps/s=103.61  prediction: \"n, tons of alpha is already in your head\" => \"  ntonttttttt            aaaaa          \"\n",
      "batch 2146  loss=133.8654  steps/s=105.50  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \"or   id      iiiiiiiisssssssstttttttt///\"\n",
      "batch 2147  loss=153.6249  steps/s=11.24  prediction: \"reply: @AaronPeddle Very very good point\" => \"e  i        iiiiiiiisssssssstttttttt////\"\n",
      "batch 2148  loss=244.2319  steps/s=138.85  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"obyti          !!!!!!!!!!!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       \"\n",
      "batch 2149  loss=133.7746  steps/s=103.84  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" tep eeeeeeeeeenn nnnnnnn        ttttttt\"\n",
      "batch 2150  loss=153.3644  steps/s=103.24  prediction: \"fects the rest of the day. Cheers brotha\" => \"or   f   tteteeeetttt                   \"\n",
      "batch 2151  loss=148.3769  steps/s=105.57  prediction: \"on adding sound!\n",
      "https://t.co/7jVECuxgpx\" => \"r a  oa     nnnnnnnnnnnnnnnnnnoot///////\"\n",
      "batch 2152  loss=142.8730  steps/s=105.10  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nl . t                                  \"\n",
      "batch 2153  loss=132.0244  steps/s=104.85  prediction: \"erscores the importance of curating andâ€¦\" => \" ei e eeeeeeeeeeeeeeeeeee               \"\n",
      "batch 2154  loss=141.2951  steps/s=104.19  prediction: \"mpactful on actual success for me though\" => \"echi                    ccccccccc       \"\n",
      "batch 2156  loss=137.6135  steps/s=103.95  prediction: \"eal interview round, not as a standalone\" => \" lil  e   eeeeeeeeeeee                aa\"\n",
      "batch 2157  loss=156.1451  steps/s=101.99  prediction: \"ge w git commits\n",
      "https://t.co/aMMtiAGLQh\" => \" zm                ttttttttttttttttttttt\"\n",
      "batch 2158  loss=153.7961  steps/s=102.37  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu ccg                7777722///////////\"\n",
      "batch 2159  loss=146.9163  steps/s=85.11  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"omcl              tt tt/////////////t.ff\"\n",
      "batch 2160  loss=165.1204  steps/s=105.17  prediction: \"is not true loss https://t.co/VvtOa0Aau2\" => \"n    ssssssssssssssssssssttttttttttttttt\"\n",
      "batch 2161  loss=132.4049  steps/s=104.84  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"  g\n",
      " is                                 \"\n",
      "batch 2162  loss=129.9888  steps/s=100.43  prediction: \"nd stop you from seeking rewards in life\" => \"gi hed               o                  \"\n",
      "batch 2163  loss=139.8081  steps/s=105.54  prediction: \"how it is in c++. Trace them rays brotha\" => \"ese  e                                  \"\n",
      "batch 2164  loss=172.6687  steps/s=105.02  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"ord\n",
      "t\n",
      "uwwwwwwwww             ttt////////\"\n",
      "batch 2165  loss=141.3142  steps/s=104.44  prediction: \"s and $billions\n",
      "\n",
      "https://t.co/JAfCka4QWD\" => \" aa ed dddddddddd   ssssssssstttttttt///\"\n",
      "batch 2166  loss=124.8433  steps/s=104.51  prediction: \"uscle and you get better as you practice\" => \"th  t                                   \"\n",
      "batch 2167  loss=135.3309  steps/s=103.47  prediction: \"ant use it for what i need to work on :(\" => \"nd                                      \"\n",
      "batch 2168  loss=122.2617  steps/s=102.98  prediction: \"e latent space of \"make things ppl want\"\" => \" aan                                    \"\n",
      "batch 2169  loss=118.2732  steps/s=98.90  prediction: \" said it was his last email, he meant it\" => \"ttethehe                                \"\n",
      "batch 2170  loss=153.3087  steps/s=102.77  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yk                      eeeeeeeeeeeeeeee\"\n",
      "batch 2171  loss=135.3977  steps/s=43.81  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \": @                   feeeeeeeeeeeoocccc\"\n",
      "batch 2172  loss=133.4944  steps/s=113.33  prediction: \"am and it doesnt mess your sleep up much\" => \"ne\n",
      " a                                   \"\n",
      "batch 2173  loss=165.9923  steps/s=99.33  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"se a   ssssoonnnnnnnnnnnnttttttttttttttt\"\n",
      "batch 2174  loss=134.6827  steps/s=100.28  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"epge                      tttt//////////\"\n",
      "batch 2175  loss=143.3630  steps/s=99.68  prediction: \"rse21 doing is a fundamental of learning\" => \"ealy: @aaaa                          aaa\"\n",
      "batch 2176  loss=124.8180  steps/s=103.55  prediction: \"change it up a bit from the ol .txt file\" => \"haseo                                   \"\n",
      "batch 2177  loss=131.5605  steps/s=104.08  prediction: \"just point to concepts and arent reality\" => \"ust                                     \"\n",
      "batch 2178  loss=141.1136  steps/s=101.26  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \"h s cs       aaaaattttttttttttttttt/////\"\n",
      "batch 2179  loss=125.5914  steps/s=101.94  prediction: \"e\n",
      "graphics programming is so awesome man\" => \"  c           rrrrrrrrrrrgggggg      mmm\"\n",
      "batch 2180  loss=139.1292  steps/s=102.31  prediction: \"many roadblocks trying to automate stuff\" => \"er hif          ooooooooooo ooootttttttt\"\n",
      "batch 2181  loss=144.1769  steps/s=102.35  prediction: \"makes a comeback they get a large reward\" => \"enes i                                 e\"\n",
      "batch 2182  loss=130.0918  steps/s=99.16  prediction: \"and then pivot to doing a project in zig\" => \"td sa                                   \"\n",
      "batch 2183  loss=180.3514  steps/s=103.12  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" aio                                    \"\n",
      "batch 2185  loss=174.9170  steps/s=103.64  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OOO\n",
      "                        ttttttttt///\"\n",
      "batch 2186  loss=129.0793  steps/s=102.92  prediction: \"ive impact on me yrs after i had to stop\" => \"ne i    iiii                            \"\n",
      "batch 2187  loss=152.8696  steps/s=104.15  prediction: \"ng up every word you hear more than once\" => \"g  wor                                  \"\n",
      "batch 2188  loss=126.5171  steps/s=103.27  prediction: \" the dark forest from the 3 body problem\" => \"the te                                  \"\n",
      "batch 2189  loss=141.5323  steps/s=100.34  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  fe o eeeeeeeeeeeeetttttttttttt        \"\n",
      "batch 2190  loss=130.8860  steps/s=105.04  prediction: \" of how i debug and catch inefficiencies\" => \"tf                                 iiicc\"\n",
      "batch 2191  loss=121.3156  steps/s=101.30  prediction: \"category so the rule is to tell everyone\" => \"onig o oooooooo                        e\"\n",
      "batch 2192  loss=135.2546  steps/s=20.97  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly:  ooeooooe    e                   ee\"\n",
      "batch 2193  loss=142.4081  steps/s=117.13  prediction: \" have been goin up too. Things are movin\" => \"taa                                     \"\n",
      "batch 2194  loss=149.0301  steps/s=102.78  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"too oooooooooollllll                   h\"\n",
      "batch 2195  loss=138.2510  steps/s=103.90  prediction: \"ally fun/challenging/interesting for ppl\" => \"nt n   a  aaaaaalllllllnnnnnnnnnnnnnnnnn\"\n",
      "batch 2196  loss=177.0225  steps/s=96.80  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tnct cinnnn        t  ttttttt//////////t\"\n",
      "batch 2197  loss=129.0679  steps/s=105.53  prediction: \"ong term advantage) you consolidate andâ€¦\" => \"u'  .. .         aaaaaaaaa       ooooooo\"\n",
      "batch 2198  loss=148.8207  steps/s=101.32  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"e to peeeeeeeeeeeeeeooooootptttttttooo//\"\n",
      "batch 2199  loss=133.8120  steps/s=102.39  prediction: \"like a really really interesting project\" => \"yn  see ee      llllllllllllleeeeeeeeeee\"\n",
      "batch 2200  loss=131.9341  steps/s=103.92  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" ne ai                       eeeeeeeeeee\"\n",
      "batch 2202  loss=130.9897  steps/s=104.07  prediction: \"ed hard at improving, mostly by studying\" => \"  y                                    y\"\n",
      "batch 2203  loss=126.4427  steps/s=101.23  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"thataaa ttttttt                         \"\n",
      "batch 2204  loss=136.8070  steps/s=96.82  prediction: \" job adding the australian language pack\" => \"turt t                  aaaaaaaaaaaaaaaa\"\n",
      "batch 2205  loss=132.1930  steps/s=105.24  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o  m                                  \"\n",
      "batch 2206  loss=148.3273  steps/s=90.31  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eyoy: @      1   0000           eeeee  e\"\n",
      "batch 2207  loss=143.4883  steps/s=104.32  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e ng eneeeeeeeeeeeeeee                 e\"\n",
      "batch 2208  loss=161.0540  steps/s=103.81  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t.do\n",
      "it///////tttttttttttttttt//////////\"\n",
      "batch 2209  loss=145.6940  steps/s=101.49  prediction: \"looking fractals https://t.co/PNG9vTa8x5\" => \"yk  i ooooooooo      ttttttttttt////////\"\n",
      "batch 2210  loss=147.9091  steps/s=102.67  prediction: \"... and 4\n",
      "\n",
      "idk about other spaces though\" => \"  a   ........                          \"\n",
      "batch 2211  loss=133.9624  steps/s=103.68  prediction: \"sed to sound like the opposite of curses\" => \" r lel                          oooooooo\"\n",
      "batch 2212  loss=137.1972  steps/s=104.02  prediction: \"tournaments, etc\n",
      "https://t.co/JA1SHygLtH\" => \"h  ny n   atttttttttttttttttttttttttttt/\"\n",
      "batch 2214  loss=133.4957  steps/s=106.08  prediction: \"an get immense alpha if you keep zooming\" => \"nd oo                                   \"\n",
      "batch 2215  loss=137.0573  steps/s=104.95  prediction: \" different on your OS. you can google em\" => \"tor te                                  \"\n",
      "batch 2216  loss=143.1654  steps/s=96.95  prediction: \"BAP lud the goat herder back at it again\" => \"ry iceee                               a\"\n",
      "batch 2217  loss=135.5368  steps/s=104.16  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yn  d        lllllllllllllllssssttt/////\"\n",
      "batch 2218  loss=142.7631  steps/s=102.54  prediction: \"coordinates are busted\n",
      "just buy new ones\" => \"omla  a aaaaaaaaaaaaa  eeeeeeee         \"\n",
      "batch 2219  loss=138.7205  steps/s=101.20  prediction: \"l, titan, stable diffusion, a few others\" => \"y  sirr       attttttttt iiii           \"\n",
      "batch 2220  loss=131.9178  steps/s=105.47  prediction: \"pick any domain/topic there are usuallyâ€¦\" => \"lnt  o                 iiii             \"\n",
      "batch 2221  loss=147.5701  steps/s=104.50  prediction: \"ame by making his brain care abt it more\" => \"nt og                                   \"\n",
      "batch 2222  loss=133.1153  steps/s=103.43  prediction: \"ut from having 1/3rd the progress per hr\" => \"n                             rrrrrrrrrr\"\n",
      "batch 2223  loss=129.3796  steps/s=102.46  prediction: \"e first img generation models rolled out\" => \" g                        eeeeeeeeeellll\"\n",
      "batch 2224  loss=154.2658  steps/s=102.00  prediction: \" goes over the massive 4096 token window\" => \"to  sssoooooooo       eee               \"\n",
      "batch 2225  loss=102.8208  steps/s=103.56  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"toOOOOO                 ???????      EEE\"\n",
      "batch 2226  loss=137.4114  steps/s=103.46  prediction: \"s how to do this w reasonable efficiency\" => \" oeno  oooooooo                      eee\"\n",
      "batch 2227  loss=131.2974  steps/s=104.73  prediction: \"ressures me to say things I dont believe\" => \"epf a                                   \"\n",
      "batch 2228  loss=177.4056  steps/s=88.11  prediction: \"ettler @gizmobly https://t.co/ZVEh9zCAgb\" => \" tao  sseeeet        ttt t tttt   /tteee\"\n",
      "batch 2229  loss=157.9908  steps/s=105.06  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"/..o\n",
      "ttttt////////ttttttttttt///////////\"\n",
      "batch 2230  loss=145.9866  steps/s=105.37  prediction: \"f us have jobs)\n",
      "\n",
      "https://t.co/qTcrhcfjBM\" => \" ah om                ssstttttttttt/////\"\n",
      "batch 2231  loss=153.9701  steps/s=101.75  prediction: \"ns must magnetically align their protons\" => \"  t   iii      iiiilllllllllllllll  l   \"\n",
      "batch 2232  loss=144.3172  steps/s=59.64  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"t6  iiss    sss llllllllllllliii    rr  \"\n",
      "batch 2233  loss=123.3524  steps/s=95.83  prediction: \"@yacineMTB so youre no longer locked in?\" => \"sacinoMss  s    lll yll  llleii     oo ðŸ›‘\"\n",
      "batch 2234  loss=150.7736  steps/s=113.21  prediction: \"wtf\n",
      "Your project sounds very interesting\" => \"ohk    aa       rrrroo oooo       eeeeee\"\n",
      "batch 2235  loss=145.7427  steps/s=97.32  prediction: \"athy @paulg @ylecun Been blocked by lex?\" => \"n   atr@@@@@@@@@@@@@@u       eeeeeeeeeee\"\n",
      "batch 2236  loss=149.0966  steps/s=98.27  prediction: \"Grats!!! Always awesome to see successes\" => \"ood  avaaa!!!!!!!!!   a      ee ee eeses\"\n",
      "batch 2237  loss=133.9769  steps/s=103.18  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"ep2y: @    aaaaaaaaaa rrrrrrrrrrrrrrreee\"\n",
      "batch 2238  loss=189.2473  steps/s=102.53  prediction: \"needed to dl this. meme delivery service\" => \"   h                     eeeeeeeeeeeeeee\"\n",
      "batch 2239  loss=151.9760  steps/s=100.56  prediction: \"de!!! Huge achievement\n",
      "\n",
      "What did u study\" => \"    eeddduu!!!!!!!eeeeeeeeeeeeeee       \"\n",
      "batch 2240  loss=130.6200  steps/s=99.66  prediction: \"ental growth is king. get that bread son\" => \" te                                     \"\n",
      "batch 2241  loss=131.4971  steps/s=101.20  prediction: \"rappers around statistical distributions\" => \"enlym @    rrrrrrrrssssssssassststtiiiii\"\n",
      "batch 2242  loss=124.4368  steps/s=94.98  prediction: \"nis @sunsettler sun yearns for the mines\" => \"gnaa rssssssssssssssttttt     s   ttr   \"\n",
      "batch 2243  loss=131.8212  steps/s=104.71  prediction: \"e a data pipeline that scrapes data. Orâ€¦\" => \" d           aaaaa aaaa   aaaaaaaaaaaaaa\"\n",
      "batch 2244  loss=134.8886  steps/s=104.75  prediction: \"cool ML/studying/building posts are gone\" => \"oliet        ooooooooouiiiiiiiiiiiiiiggg\"\n",
      "batch 2245  loss=165.5250  steps/s=102.09  prediction: \"(im not mexican) https://t.co/PYTZ3vBjrX\" => \"ittg 0 oo    mmmmmnnnnnn ttttt//////////\"\n",
      "batch 2246  loss=141.8638  steps/s=105.35  prediction: \" up to do multiple iterations of editing\" => \"tne  t                 tttttttttttiiiiii\"\n",
      "batch 2247  loss=131.9590  steps/s=103.88  prediction: \" is a wild computational rabbithole man.\" => \"t   paa                   aaaaaaaaaaaaaa\"\n",
      "batch 2248  loss=128.0549  steps/s=104.62  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \" rt  a               eeeeeeeeeo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ooo\"\n",
      "batch 2249  loss=129.2036  steps/s=104.87  prediction: \"ession youll do something until its done\" => \"   e  eeeeeeee  ooooooooooooo           \"\n",
      "batch 2250  loss=126.0684  steps/s=105.25  prediction: \" or not so i dont have much data on that\" => \"tfo  o                                  \"\n",
      "batch 2251  loss=137.3430  steps/s=104.46  prediction: \". seems like a fancy type of hard coding\" => \" ohe  eeeeeeeeeeeeee                    \"\n",
      "batch 2252  loss=126.8710  steps/s=103.61  prediction: \"cond while avoiding exhausting the first\" => \"oul7e                iiiiiiiiiiiiiiiiiii\"\n",
      "batch 2253  loss=145.1611  steps/s=103.76  prediction: \"E gambits dude\n",
      "Punish mode is goated too\" => \" So_eam                                 \"\n",
      "batch 2254  loss=138.4178  steps/s=102.27  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"ya @siiiiiirrrrr                        \"\n",
      "batch 2255  loss=158.7617  steps/s=98.65  prediction: \"shiridesu 100 raspberry pis would fix me\" => \"  o Siheeeeeeee                         \"\n",
      "batch 2256  loss=154.4343  steps/s=102.85  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"r  no                                  T\"\n",
      "batch 2257  loss=131.2996  steps/s=55.66  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @txll      dd     aaa    rrr       TTTT\"\n",
      "batch 2258  loss=135.2479  steps/s=109.47  prediction: \"ay simpler, but also much more effective\" => \"r  et                                   \"\n",
      "batch 2259  loss=164.6846  steps/s=103.06  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"t..oot t//////////ttttttttt////////////t\"\n",
      "batch 2260  loss=160.2719  steps/s=84.28  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ng  o nggggcccpppptttttttttttttnnn     o\"\n",
      "batch 2261  loss=135.1664  steps/s=105.41  prediction: \" You can hide these with adblock i think\" => \"te  oo oo                               \"\n",
      "batch 2262  loss=145.5853  steps/s=101.96  prediction: \"y the paper i thought it was a neat read\" => \" tile      ppp                          \"\n",
      "batch 2263  loss=133.7985  steps/s=106.15  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tne  eedddddddd        rrrrrrrrrrr      \"\n",
      "batch 2264  loss=134.8309  steps/s=102.83  prediction: \"ready having better days from this stuff\" => \"eplya aaaaaaaaaaa                       \"\n",
      "batch 2265  loss=135.8983  steps/s=103.36  prediction: \"er useful building block to get good at.\" => \"          uuuuuuuuuuuu                  \"\n",
      "batch 2266  loss=122.7788  steps/s=98.96  prediction: \" of the tier lists of all time, for sure\" => \"tfu                                     \"\n",
      "batch 2267  loss=131.7887  steps/s=100.75  prediction: \"Building scratch from scratch in scratch\" => \" y ieeeiiiiiiiiiss        cccccccccccrcc\"\n",
      "batch 2268  loss=123.0438  steps/s=102.13  prediction: \"all of the theories that we could invent\" => \"leene                                   \"\n",
      "batch 2269  loss=128.2948  steps/s=29.75  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: @            e   hhtt               \"\n",
      "batch 2270  loss=152.6208  steps/s=110.84  prediction: \"h has made me more productive\n",
      "\n",
      "Enjoy bro\" => \"aI e                          eeeeeee\n",
      "\n",
      "\n",
      "\"\n",
      "batch 2271  loss=131.7009  steps/s=105.34  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"g    eta                       eeeeeeeee\"\n",
      "batch 2274  loss=138.0011  steps/s=79.91  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"epoyn @          aaae eeeee    eee ttttt\"\n",
      "batch 2276  loss=138.4109  steps/s=104.65  prediction: \"sk for, then train them to ask, then act\" => \" e t                 t ttt              \"\n",
      "batch 2277  loss=133.9805  steps/s=105.13  prediction: \"ave been trying to compress these lately\" => \"te ol                           eeeeeeee\"\n",
      "batch 2278  loss=128.6643  steps/s=100.81  prediction: \" they secretly exercise and dont tell us\" => \"toeb eeeeeeeeeeeeeeeeeeeeeeeeeee  e     \"\n",
      "batch 2279  loss=141.8518  steps/s=104.25  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \" oC g n                         gggggggg\"\n",
      "batch 2280  loss=152.0110  steps/s=101.68  prediction: \"sist... bait.... https://t.co/FSXHHMMAoD\" => \" tustt................ttttttttttttt/////\"\n",
      "batch 2281  loss=146.0240  steps/s=99.51  prediction: \"a get my future kids on this kinda stuff\" => \"tneeee                                  \"\n",
      "batch 2282  loss=127.3898  steps/s=102.03  prediction: \"e unbelievably interesting and beautiful\" => \" wg e         bbbbbeeeeeeeeeeeeennnneeee\"\n",
      "batch 2284  loss=130.9478  steps/s=104.32  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of  off ffff            tttttttt///////\"\n",
      "batch 2285  loss=151.0033  steps/s=103.48  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"too ooloollllllllooo                    \"\n",
      "batch 2286  loss=140.1390  steps/s=104.46  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"h e  e                 ttttttttttt//////\"\n",
      "batch 2287  loss=129.0833  steps/s=101.89  prediction: \"in there for sure\n",
      "Those guys are awesome\" => \"ng repeeeeee         r r               e\"\n",
      "batch 2288  loss=189.4698  steps/s=32.41  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly: ee eeee   rr  rrre                ee\"\n",
      "batch 2289  loss=193.6404  steps/s=134.94  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"toee er        OOOOO!!!!!!!             \"\n",
      "batch 2290  loss=151.0168  steps/s=104.93  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"pedi mmmmmm   ''''''''''                \"\n",
      "batch 2291  loss=149.7246  steps/s=100.81  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"e ly: @                               w \"\n",
      "batch 2292  loss=126.7646  steps/s=11.23  prediction: \"reply: @yacineMTB google necessary being\" => \"eply: @                   oo          wo\"\n",
      "batch 2293  loss=133.1581  steps/s=107.67  prediction: \"ss I need to do keyboard input from it..\" => \"t   .l                                  \"\n",
      "batch 2295  loss=143.7004  steps/s=102.11  prediction: \"azy like that. Cheers my English brother\" => \"n  o e                                  \"\n",
      "batch 2296  loss=138.1150  steps/s=102.21  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lo  n errrrrrrrrrrro\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IIII         \"\n",
      "batch 2297  loss=141.5080  steps/s=104.08  prediction: \"ting should not be taking customer calls\" => \" rn i  coooooooooo                      \"\n",
      "batch 2298  loss=135.8558  steps/s=104.40  prediction: \"de it one of the best ive had in a while\" => \"  h  iiii                               \"\n",
      "batch 2299  loss=131.5496  steps/s=104.17  prediction: \"ns the returns are high on more of it :)\" => \"   is h                                 \"\n",
      "batch 2301  loss=151.9385  steps/s=102.46  prediction: \" a day\n",
      "weekdays usually like 9am to 10pm\" => \"t 3k          aaaaaaaaaayyyyyllllll     \"\n",
      "batch 2302  loss=158.0449  steps/s=103.16  prediction: \"fects the rest of the day. Cheers brotha\" => \" nhe       eeeeeetttttt                 \"\n",
      "batch 2303  loss=217.0033  steps/s=105.58  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"ys 0.e0))))))))))))...(((((((...........\"\n",
      "batch 2304  loss=148.7001  steps/s=101.95  prediction: \"ate? i mean i can guess, but.. nice work\" => \"n r,e2                                  \"\n",
      "batch 2306  loss=135.1978  steps/s=105.05  prediction: \"dless memory related errors (impossible)\" => \" y  oe      mmmmmeeeeeeeeerrrrrrrrrrrrss\"\n",
      "batch 2307  loss=143.6521  steps/s=71.21  prediction: \"aulg We like memoizing physical patterns\" => \"nl  e em     eeeeeeeeeerrrrrr   ssssssss\"\n",
      "batch 2308  loss=131.4478  steps/s=107.03  prediction: \"se? seems like death spiral potential no\" => \"  ee eeeeeeeeeeeeeeeeeee                \"\n",
      "batch 2309  loss=135.9028  steps/s=102.17  prediction: \"g i can make some insanely helpful stuff\" => \" h  ei                          eeeeeee \"\n",
      "batch 2310  loss=190.0326  steps/s=94.41  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \"   i ii aaa aaa      nnnmmmessseesssssff\"\n",
      "batch 2311  loss=128.2244  steps/s=102.22  prediction: \"sing llms to their full potential rn tbh\" => \" n   e                                tt\"\n",
      "batch 2313  loss=130.9967  steps/s=84.91  prediction: \"phones Thanks man! its going well so far\" => \"lo: @ e                      tt        l\"\n",
      "batch 2314  loss=136.7950  steps/s=105.73  prediction: \"ective if that's what you're referencing\" => \" ie e  eeeeeeee      tttttt  ''''   eeee\"\n",
      "batch 2315  loss=194.5029  steps/s=104.62  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"ys  .e*)))))))))))))).(((((((...........\"\n",
      "batch 2316  loss=152.2313  steps/s=105.08  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"0/b00                    tttttt/t///////\"\n",
      "batch 2317  loss=159.5918  steps/s=79.00  prediction: \"minus9 hmm still pixels on my end, weird\" => \"ate lt o            ttllt /t//       AAA\"\n",
      "batch 2319  loss=139.4505  steps/s=105.79  prediction: \"ovate too and come up w cool experiments\" => \"ri n     oooooooooooo                  e\"\n",
      "batch 2320  loss=140.1856  steps/s=103.82  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"lto  ellppppoooooooooooooooooooonnnnn   \"\n",
      "batch 2321  loss=177.3846  steps/s=101.14  prediction: \"JUST POST so i dropped a draft out there\" => \"uSy                                     \"\n",
      "batch 2323  loss=139.7315  steps/s=100.68  prediction: \"rse21 doing is a fundamental of learning\" => \"e ly: @aaa                aaaaaaaaaaaaaa\"\n",
      "batch 2324  loss=158.6898  steps/s=100.34  prediction: \"prob 2.5M tokens\n",
      "https://t.co/6FbmJG4MmF\" => \"ls:l@s2               ttttttttttttt/////\"\n",
      "batch 2325  loss=141.1239  steps/s=105.74  prediction: \"morrow, hope it goes well for you brotha\" => \"ed sor oooooooooooooooo                 \"\n",
      "batch 2326  loss=129.9115  steps/s=105.10  prediction: \"house? where is your phone charger? etc)\" => \"ere yo                                ee\"\n",
      "batch 2327  loss=127.8289  steps/s=103.99  prediction: \"you can control the models, and its free\" => \" ur c      ccc                          \"\n",
      "batch 2328  loss=139.9065  steps/s=102.67  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \"ere  ao     lllll          ttttttttt////\"\n",
      "batch 2329  loss=130.7458  steps/s=96.55  prediction: \"nis @startupmillyair pretty solid rating\" => \"dtmarkeeerrrrrssstttttrttttttttttttttttt\"\n",
      "batch 2330  loss=158.4810  steps/s=103.70  prediction: \"dnt acct for maintenance/electricity tho\" => \" dn                    nnnnnnnnecccccccc\"\n",
      "batch 2331  loss=130.9010  steps/s=106.07  prediction: \"people skills of almost everyone ive met\" => \"lrcn@s  eeeeeee     lllllllll     eeeeee\"\n",
      "batch 2333  loss=134.9839  steps/s=45.01  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \"  @  eeeeeeeee   l llss     ooeee eeeeev\"\n",
      "batch 2334  loss=150.9764  steps/s=110.37  prediction: \"you get used to it and overcome the fear\" => \":u                                   eee\"\n",
      "batch 2336  loss=139.9103  steps/s=102.94  prediction: \"uch working tomorrow, key is consistency\" => \"th  oooooooooooooooooooooooo            \"\n",
      "batch 2337  loss=147.7244  steps/s=100.21  prediction: \"ock your 1000th follower and stay at 999\" => \"u  tt                  lllll            \"\n",
      "batch 2338  loss=137.6805  steps/s=103.50  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o e         eeeeeeee                   \"\n",
      "batch 2339  loss=144.9608  steps/s=104.36  prediction: \"igABAP np bro, you should write more man\" => \"nA reedddgg       pp   o      w    eeeee\"\n",
      "batch 2340  loss=140.3552  steps/s=104.39  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"rs nas      nnnn n          tttttnn-----\"\n",
      "batch 2341  loss=127.0137  steps/s=103.38  prediction: \"you can control the models, and its free\" => \" ua oo      cc                          \"\n",
      "batch 2342  loss=190.7303  steps/s=52.57  prediction: \": example output https://t.co/jRATFli0Ik\" => \" @tn o      ooo                         \"\n",
      "batch 2343  loss=138.5050  steps/s=106.72  prediction: \"de you hate work\n",
      "https://t.co/2jmiAqT1C6\" => \"  in                  tttttttt//////////\"\n",
      "batch 2344  loss=150.7165  steps/s=97.40  prediction: \"s I love zig\n",
      "Are you doing the ziglings?\" => \" ciy                       ooooooo iiiig\"\n",
      "batch 2345  loss=119.5087  steps/s=99.10  prediction: \"y be a way to do it without grad descent\" => \":c@ o e                                 \"\n",
      "batch 2346  loss=129.1075  steps/s=103.87  prediction: \"e first img generation models rolled out\" => \" m                        eeeeeeeeeellll\"\n",
      "batch 2347  loss=136.9722  steps/s=102.98  prediction: \"what's needed to  step out of reactivitâ€¦\" => \"oe e  s ss                            tt\"\n",
      "batch 2348  loss=125.7084  steps/s=105.58  prediction: \"endeavors im going to do til ive done it\" => \" tif t                                  \"\n",
      "batch 2349  loss=142.7623  steps/s=100.43  prediction: \"l do bro, never had a french beer before\" => \"yb    ee                         eeeeeee\"\n",
      "batch 2350  loss=145.5116  steps/s=104.37  prediction: \" group or build 100x stuff and start one\" => \"to n n                                  \"\n",
      "batch 2351  loss=134.8048  steps/s=104.13  prediction: \"discovering new unseen fundamentals, too\" => \" d  e d          nnnnnnnnnnnnnnnnnnnnnnn\"\n",
      "batch 2352  loss=139.0988  steps/s=106.20  prediction: \" improve a processing unit's ability toâ€¦\" => \"ts ea aaaa                       iiiiiii\"\n",
      "batch 2353  loss=146.6443  steps/s=102.74  prediction: \"appen. i know it https://t.co/jDUR7SknBb\" => \"nl te                    tttttttttt/////\"\n",
      "batch 2354  loss=151.4367  steps/s=102.44  prediction: \" could you tell\" https://t.co/968GsOvdfW\" => \"tau                       ttttt/////////\"\n",
      "batch 2356  loss=130.5484  steps/s=104.97  prediction: \"e usually surrounded with those coloredâ€¦\" => \" care  e      uuuuuuuuuuuuuu            \"\n",
      "batch 2357  loss=133.6943  steps/s=106.27  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y m tnneeaaaaaaaaaaaaaaaattttttttt//////\"\n",
      "batch 2358  loss=138.2831  steps/s=100.08  prediction: \"ffects that are extremely hard to notice\" => \"ue irleeeeeeeeeeeeeeeeeeeeeeeeeee       \"\n",
      "batch 2359  loss=143.3315  steps/s=105.50  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"aovk a                     tttttttt/////\"\n",
      "batch 2360  loss=143.7993  steps/s=100.79  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"e e e        ooooooooooooooooooooooo o  \"\n",
      "batch 2361  loss=159.7091  steps/s=105.22  prediction: \"saas #developers https://t.co/GmrQaIKpLs\" => \" tce s#####sseeeeeeeeessssssssss////////\"\n",
      "batch 2362  loss=125.8407  steps/s=95.41  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" e o  ssssssess hhheeeeeeeeeeeeeeeeeee e\"\n",
      "batch 2363  loss=145.1047  steps/s=97.14  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"es  ts a  oooooo  ooo  oo               \"\n",
      "batch 2364  loss=133.7074  steps/s=104.03  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hl  ieiiiiiiiiiiiiittttttttttttttttttt//\"\n",
      "batch 2365  loss=135.2928  steps/s=106.37  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"am H  eeeeeeeeee         aaaaaaaaaaa    \"\n",
      "batch 2366  loss=140.8311  steps/s=104.11  prediction: \"d of just putting in more and more hours\" => \" og  on       tttttttt                  \"\n",
      "batch 2367  loss=139.9507  steps/s=101.25  prediction: \"y\n",
      "\n",
      "gotta tie everything back to the goal\" => \":t@neoeettttttttttttttteeeeettttttt     \"\n",
      "batch 2368  loss=134.8685  steps/s=105.46  prediction: \"lding w ai is gonna get left in the dust\" => \"y    i i                                \"\n",
      "batch 2370  loss=139.8467  steps/s=105.28  prediction: \" make no?\n",
      "\n",
      "maybe @yacineMTB can add this\" => \"tos   e                eeeeeeeaaaaaaaaaa\"\n",
      "batch 2371  loss=142.5059  steps/s=103.48  prediction: \" been some adventure man. God bless him.\" => \"tu e  eeeeeeeeeeeeeeeeeeeeee            \"\n",
      "batch 2372  loss=136.4973  steps/s=102.67  prediction: \" if they'll give you access to that zone\" => \"tn i \n",
      "iiii                              \"\n",
      "batch 2373  loss=131.3298  steps/s=104.28  prediction: \"chnical debt kind of effect over time. F\" => \"o pu  h                             eee \"\n",
      "batch 2374  loss=138.9322  steps/s=97.61  prediction: \"ssir\n",
      "\n",
      "ill dm you on the 25th with a link\" => \"  n t  eeee  iii                        \"\n",
      "batch 2375  loss=135.0573  steps/s=104.30  prediction: \" You can hide these with adblock i think\" => \"teeloo oo                               \"\n",
      "batch 2376  loss=140.9919  steps/s=63.97  prediction: \"@djcows but yet my 5s gifs come out 50MB\" => \"leieool                                 \"\n",
      "batch 2377  loss=118.9513  steps/s=115.01  prediction: \"y time back so i can work on what i want\" => \":i so                                   \"\n",
      "batch 2378  loss=139.9491  steps/s=101.09  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"ln: @y                            aaaaaa\"\n",
      "batch 2379  loss=133.1190  steps/s=104.57  prediction: \" only improve by improving their skills)\" => \"tfe t                         iiiiiiiiii\"\n",
      "batch 2380  loss=218.0761  steps/s=99.97  prediction: \"s: added eraser) https://t.co/TAudQKjLMg\" => \"  r  r rdddddddddddeeeeeeesssttttt//////\"\n",
      "batch 2381  loss=134.9045  steps/s=103.54  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"  e ees                         ////////\"\n",
      "batch 2382  loss=142.2015  steps/s=103.07  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"ealy: @                               xx\"\n",
      "batch 2383  loss=146.4931  steps/s=100.86  prediction: \"w site! Not gonna say much til it's done\" => \"iho    eeee                             \"\n",
      "batch 2384  loss=137.9410  steps/s=99.08  prediction: \"oodhart that too https://t.co/AKZnb9fRgL\" => \"nr  o o        tttttttttttttttttttt/////\"\n",
      "batch 2385  loss=132.3753  steps/s=21.35  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly:  o      tttttttttttttttttttt///////\"\n",
      "batch 2386  loss=154.5357  steps/s=111.40  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"tue\n",
      "Yes                            sssss\"\n",
      "batch 2389  loss=153.5959  steps/s=102.30  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nAss  ggggggggggggggh hhtttttttttt//////\"\n",
      "batch 2390  loss=139.8432  steps/s=68.59  prediction: \"xluffyb interest is a powerful thing man\" => \" itgg gyiiiiiyy ittttsstttto/////tttttii\"\n",
      "batch 2391  loss=132.8471  steps/s=105.32  prediction: \"fficulty level, progressive overload etc\" => \" o  ls        llllllllllleeeeeevvvvvveee\"\n",
      "batch 2392  loss=133.7497  steps/s=37.20  prediction: \"ly: @archived_videos am american, so idk\" => \"y  e t      llllllllll eeeeevvvvvveeeeee\"\n",
      "batch 2393  loss=146.0536  steps/s=123.39  prediction: \"e yup same did exactly this, worked well\" => \" f : @iii        dd                     \"\n",
      "batch 2394  loss=124.6415  steps/s=101.84  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"nei l          eeeeeeeeeeeeeerrrrrrrraaa\"\n",
      "batch 2395  loss=137.6782  steps/s=103.15  prediction: \"o you get more data) or hit a \"dampener\"\" => \"ns oo o                                 \"\n",
      "batch 2396  loss=131.2669  steps/s=101.46  prediction: \"d to seeing your progress on nand2tetris\" => \" un o o              rrrrrrrrrr   nnnnnn\"\n",
      "batch 2397  loss=133.1457  steps/s=104.04  prediction: \", increases both HP and MP significantly\" => \" woeeee eeeeeeeeee                     i\"\n",
      "batch 2398  loss=126.9387  steps/s=87.06  prediction: \"omeik that is super super super cool wtf\" => \"ue eeekeeeee                  s         \"\n",
      "batch 2399  loss=129.9376  steps/s=104.64  prediction: \"d\" and they do and then it stops failing\" => \" rotae\"     ddddddddddd                 \"\n",
      "batch 2400  loss=128.9930  steps/s=103.74  prediction: \"oud to yourself, or in your imagination)\" => \" th to  ooooooooooooo                  i\"\n",
      "batch 2401  loss=133.4160  steps/s=103.62  prediction: \"it can atrophy if you dont keep doing it\" => \"n  eothhhh                              \"\n",
      "batch 2402  loss=129.8714  steps/s=96.88  prediction: \"TB elon lived in leafland for a bit iirc\" => \"h   o                                   \"\n",
      "batch 2404  loss=142.0837  steps/s=101.43  prediction: \"gpt-5 powered robot of him into the wild\" => \"  Ag a                                  \"\n",
      "batch 2405  loss=129.7727  steps/s=102.21  prediction: \" like i can do so much more in python :(\" => \"titl                                    \"\n",
      "batch 2407  loss=129.0696  steps/s=102.89  prediction: \" sum bros.. pivot, its worth it trust me\" => \"tu   se       ....                tttttt\"\n",
      "batch 2408  loss=129.3302  steps/s=105.19  prediction: \"dual input vector or a set of input data\" => \" ng  d iiiiiiiiii                       \"\n",
      "batch 2409  loss=129.4610  steps/s=103.85  prediction: \"setup is going to be a bit different tho\" => \" n    o                                 \"\n",
      "batch 2410  loss=126.8240  steps/s=105.62  prediction: \"that was probably its entire purpose lol\" => \" en  ittttttttttt                       \"\n",
      "batch 2411  loss=232.0090  steps/s=103.96  prediction: \"ONE\n",
      "FREEDOOOOOM\n",
      "\n",
      "https://t.co/MAxrYM3cut\" => \"O HHGM EEEEOOOOOOOOOO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MMMMMM///\"\n",
      "batch 2413  loss=137.9776  steps/s=104.29  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \"    t                 eeeeeeeeeeeee eiii\"\n",
      "batch 2414  loss=136.6152  steps/s=105.86  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" aoo t            sssssssssss sssss     \"\n",
      "batch 2415  loss=136.7928  steps/s=101.84  prediction: \"ttin you do all that stuff, drop out etc\" => \" o   r ut                               \"\n",
      "batch 2416  loss=159.5004  steps/s=102.67  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"eply:       00000000000            ooooo\"\n",
      "batch 2417  loss=140.9358  steps/s=105.25  prediction: \"problems im overlooking, then solve them\" => \"lob  t              ooooooooooooooooo  e\"\n",
      "batch 2418  loss=127.8702  steps/s=102.01  prediction: \"what overlaps stand out to you the most?\" => \"aak  tneeeeee                           \"\n",
      "batch 2419  loss=139.3961  steps/s=105.75  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toedeedeeeeee                 CCCCnnnnnn\"\n",
      "batch 2420  loss=132.0423  steps/s=105.09  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"yne eet                      ttt////////\"\n",
      "batch 2421  loss=140.0533  steps/s=104.12  prediction: \"xample losslessâ€¦ https://t.co/1abTqawnLU\" => \"pmEtot           ssssssssssssssss///////\"\n",
      "batch 2422  loss=169.5143  steps/s=96.54  prediction: \"fsimo Lets goo!!!! Incredibly impressive\" => \"  h toaooooesssssssss!!!!!!!!!  bbbbbbbb\"\n",
      "batch 2423  loss=152.6563  steps/s=97.26  prediction: \"d 1995 type sites are such a great style\" => \" teap ooo             eee s     rr  s   \"\n",
      "batch 2425  loss=136.7856  steps/s=102.05  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tfnn                   ttttttttttt//////\"\n",
      "batch 2426  loss=122.0053  steps/s=11.02  prediction: \"reply: @daltonc its a form of rumination\" => \"e tot                 ttttttttttt///////\"\n",
      "batch 2427  loss=132.2099  steps/s=107.86  prediction: \" to recover from if it becomes a problem\" => \"thr   oooooooorrrrrr                    \"\n",
      "batch 2428  loss=188.3032  steps/s=101.48  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tn   c n            ttttttttttttt///////\"\n",
      "batch 2429  loss=133.0541  steps/s=103.09  prediction: \"just start working, and it doesnt matter\" => \"ustaa                                ttt\"\n",
      "batch 2430  loss=141.6343  steps/s=106.12  prediction: \"d virus that makes ppl cracked at scale?\" => \" m                                  aaaa\"\n",
      "batch 2431  loss=129.8724  steps/s=103.24  prediction: \"dnt mention anything related to caffeine\" => \" de p           nnnnnnnnnnnnnnnttt     e\"\n",
      "batch 2432  loss=139.7576  steps/s=100.30  prediction: \"a, good reference\n",
      "Its a tough one so far\" => \"n   a hhhh       eeeeeeeeeeee           \"\n",
      "batch 2433  loss=161.1061  steps/s=88.44  prediction: \"ruck is this you https://t.co/TaMoSJicnx\" => \"eply: @         e  e    tttttttooooooooo\"\n",
      "batch 2434  loss=139.2139  steps/s=103.33  prediction: \"6hrs on something that feels like a game\" => \"h  c 1                                  \"\n",
      "batch 2435  loss=128.3733  steps/s=105.05  prediction: \"iterate certain ppl, but those are large\" => \"ne fo l      ttttttt      tttt          \"\n",
      "batch 2436  loss=136.4176  steps/s=98.29  prediction: \"grammer unfortunately you are correct xD\" => \" a a  ammrrrrrrrrrrrrrruuuuuu     rrrrrr\"\n",
      "batch 2437  loss=148.0113  steps/s=101.08  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"h ottrarrrrrrrrr r      tttttttttttt////\"\n",
      "batch 2438  loss=128.3417  steps/s=104.95  prediction: \" just be a webpage visit, its in browser\" => \"tu  ll                         iiiiiiiii\"\n",
      "batch 2439  loss=153.4539  steps/s=102.08  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"ton ae!               nnnnnnnnnnnnn     \"\n",
      "batch 2440  loss=139.3853  steps/s=104.31  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  a    eeeeeeeeeeeeeeeeeeppttttttttt////\"\n",
      "batch 2441  loss=127.1562  steps/s=105.64  prediction: \"ht. i feel like i barely understand them\" => \"es i                           eeeee eee\"\n",
      "batch 2442  loss=130.8765  steps/s=102.20  prediction: \"ning arc, off in a remote cave somewhere\" => \" done  iiii                           ee\"\n",
      "batch 2443  loss=129.6106  steps/s=104.66  prediction: \"irl. So in irl it is probably not as bad\" => \"ne a                                    \"\n",
      "batch 2444  loss=136.6581  steps/s=105.25  prediction: \"r reward, wrecking the incentive to work\" => \"eie ee eeeeeerrrrrrrrrrr      eeeee     \"\n",
      "batch 2447  loss=141.0579  steps/s=102.09  prediction: \"very instructive zig raylib example/code\" => \"e i              iiiiiiiiiiiiiiiii     e\"\n",
      "batch 2448  loss=133.8521  steps/s=105.30  prediction: \"e and @grok both came from that, I think\" => \" omennnnnnnnnn                          \"\n",
      "batch 2449  loss=149.0027  steps/s=96.06  prediction: \"Rohit @archived_videos @discord its fake\" => \"Tnmenana@@@@@@h    a   edddd            \"\n",
      "batch 2450  loss=135.7712  steps/s=85.53  prediction: \"qc Based, a true warrior of the zig army\" => \"uestioaaaaaa aa  d ee rrirrorro         \"\n",
      "batch 2451  loss=132.8198  steps/s=105.59  prediction: \"k x's video compression is getting to it\" => \" lthit                  ssssssssssiiiiii\"\n",
      "batch 2452  loss=135.1678  steps/s=103.32  prediction: \"ire effing timeline is circle tool posts\" => \"n    e        eeeeeeeiiiiiiiiiiiiii     \"\n",
      "batch 2453  loss=154.5312  steps/s=99.61  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \"hre   ooo  i                   oo  oooss\"\n",
      "batch 2454  loss=130.7682  steps/s=103.12  prediction: \" have another tweet promoting AB testing\" => \"tee              eeeeeeetttttttttttttttt\"\n",
      "batch 2455  loss=137.9095  steps/s=21.67  prediction: \"eply: @bozo10n you can just build things\" => \" lyo            eeeeeeeetttttttttttttttt\"\n",
      "batch 2456  loss=148.1412  steps/s=109.64  prediction: \"ke half my followers came from shoutouts\" => \"e l0 llllllllllllllllll             oooo\"\n",
      "batch 2457  loss=138.9556  steps/s=105.17  prediction: \"about things that have significant value\" => \"noy ot ttttttttttttttttt           iaaaa\"\n",
      "batch 2459  loss=159.5789  steps/s=106.71  prediction: \"e77 build things people want/ need maybe\" => \" so: @ciiiii  7                 n   eeee\"\n",
      "batch 2460  loss=122.8562  steps/s=21.26  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly: @ciiiiiiii   i                 eeee\"\n",
      "batch 2461  loss=127.8532  steps/s=107.40  prediction: \"rally where the word came from, i think)\" => \"ecnii                                   \"\n",
      "batch 2462  loss=140.0709  steps/s=104.64  prediction: \"a get my future kids on this kinda stuff\" => \"npee e                                  \"\n",
      "batch 2463  loss=125.3634  steps/s=100.35  prediction: \"e or desire to practice for other things\" => \" w o t                                  \"\n",
      "batch 2464  loss=118.7029  steps/s=105.40  prediction: \"category so the rule is to tell everyone\" => \"hnct o eooooooo                       ee\"\n",
      "batch 2465  loss=140.6018  steps/s=104.47  prediction: \"ful if youre a complete beginner like me\" => \" r a  i                    eeeeeeeeeeeee\"\n",
      "batch 2466  loss=150.3583  steps/s=102.71  prediction: \"he making a dingboard clone or something\" => \"e i ggg                              ooo\"\n",
      "batch 2467  loss=127.9329  steps/s=104.97  prediction: \"seless to ppl who dont know them already\" => \"  eeesssssssssss                        \"\n",
      "batch 2468  loss=145.8350  steps/s=102.27  prediction: \"r him, thanks! Sounds useful potentially\" => \"eal :                     uuuuuuuuuuuuu \"\n",
      "batch 2469  loss=154.8527  steps/s=102.27  prediction: \"ME but you do not follow CHRIST? curious\" => \"T  @oo oo            oooooooooooo       \"\n",
      "batch 2470  loss=138.9494  steps/s=105.25  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"ys  bt                tttttttttt////////\"\n",
      "batch 2471  loss=157.3068  steps/s=65.61  prediction: \"@anish0209 gpt or claude or whatever LLM\" => \"lnbwiutiii        tt    tttt////YYYYYYoo\"\n",
      "batch 2472  loss=141.9172  steps/s=109.13  prediction: \"o church\n",
      "Starting everything immediately\" => \"na ini oo     tttctttrrttrrrrrrtteeeeeei\"\n",
      "batch 2473  loss=138.2869  steps/s=98.37  prediction: \"pmillyair lichess is like 200 elo higher\" => \"le: @stttttlliiiliiii  iiii ii ie iiee0e\"\n",
      "batch 2474  loss=129.6458  steps/s=105.23  prediction: \"nces contains homotopies (find them idk)\" => \" e sateeeeeeeeeeeeoooooooooooooooiiiiiii\"\n",
      "batch 2475  loss=130.1487  steps/s=105.08  prediction: \"eeks but you get back your skill quickly\" => \" pe  eeeeeee                          kk\"\n",
      "batch 2476  loss=132.0300  steps/s=89.65  prediction: \"ller accurate. really useful distinction\" => \"y e@oee   r      a         uulll uulilii\"\n",
      "batch 2477  loss=132.9398  steps/s=103.20  prediction: \" the atmosphere, such a great experience\" => \"theee         eeeeeeeeh          eeeeeee\"\n",
      "batch 2478  loss=125.8023  steps/s=97.18  prediction: \"s the magic of doing things from scratch\" => \" all  ttttttt             gggg          \"\n",
      "batch 2480  loss=132.2772  steps/s=100.28  prediction: \" talking drains your energy for building\" => \"thue       dddd         nnn  rrrrrrrrrr \"\n",
      "batch 2481  loss=133.2148  steps/s=105.14  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  a a                   tttt///////////\"\n",
      "batch 2482  loss=127.3758  steps/s=103.91  prediction: \"lots of stuff you learn way way way more\" => \"yk os           fffff              yyyyy\"\n",
      "batch 2484  loss=152.1829  steps/s=103.91  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"te   o                            eeeeee\"\n",
      "batch 2485  loss=156.5520  steps/s=99.48  prediction: \"u helped a ton, hugely appreciate it bro\" => \"tb _1111                            ee  \"\n",
      "batch 2486  loss=130.1875  steps/s=103.86  prediction: \"dnt mention anything related to caffeine\" => \" tt p           nnnnnnnnnnnnnnntttt    e\"\n",
      "batch 2487  loss=144.2472  steps/s=103.84  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o   re                                 \"\n",
      "batch 2488  loss=158.6972  steps/s=102.36  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \" fo au                ttttttttttttt/////\"\n",
      "batch 2489  loss=127.5987  steps/s=103.65  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"too a r  rrrr       ssssssss            \"\n",
      "batch 2490  loss=140.3579  steps/s=97.60  prediction: \"ple deep q network has achieved insanity\" => \"ly: @e eeeeeeeeeeeeee                 ea\"\n",
      "batch 2491  loss=132.0305  steps/s=103.49  prediction: \"etting up a fake verification system etc\" => \" teit,ttttttt              iiiiiiiiiii e\"\n",
      "batch 2492  loss=134.1050  steps/s=103.16  prediction: \" (by trusting in ideas) and testing them\" => \"tytte   tttttttt                        \"\n",
      "batch 2493  loss=140.6474  steps/s=96.84  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"tytse eeeeee        st  tttttttttttttttt\"\n",
      "batch 2494  loss=125.5761  steps/s=104.23  prediction: \"vision how great itll be once youre done\" => \"es te                                   \"\n",
      "batch 2495  loss=137.6755  steps/s=102.20  prediction: \"enjoyable is such a gargantuan advantage\" => \" tiuthnggnnn               aaaaaaaaaaaaa\"\n",
      "batch 2496  loss=163.1293  steps/s=99.09  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"se y a       oonnnnnnnnnntttttttttt/////\"\n",
      "batch 2498  loss=130.1016  steps/s=47.08  prediction: \"y: @melqtx every mon and thurs ma brotha\" => \"  @   n     onnnnnnnnnnntttttt////////oo\"\n",
      "batch 2499  loss=158.1159  steps/s=25.02  prediction: \"reply: @amix011 @yupiop12 You were early\" => \"ealy: @     onnnnonnnnnnttttt////////ooo\"\n",
      "batch 2500  loss=137.8066  steps/s=136.95  prediction: \"ke to continue it. Mnist is a great idea\" => \"e g o               ttt  iiiiii         \"\n",
      "batch 2501  loss=140.7387  steps/s=100.56  prediction: \"ur gzip stuff? training on gzipped data?\" => \"s  y                             n      \"\n",
      "batch 2502  loss=130.8135  steps/s=104.98  prediction: \" about it and in 1 weekend jumped up 200\" => \"t ae                            eeeee   \"\n",
      "batch 2503  loss=134.8213  steps/s=104.94  prediction: \"never I see that in mc, programming, etc\" => \"  s th eeeeeeeeeeeee                    \"\n",
      "batch 2504  loss=139.7313  steps/s=104.98  prediction: \"2 and 3 forever\n",
      "\n",
      "https://t.co/4TGEKmEHO0\" => \" d t                 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttt////////\"\n",
      "batch 2505  loss=191.2397  steps/s=20.90  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" l r               \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttt///////////\"\n",
      "batch 2506  loss=140.1434  steps/s=111.57  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th  o                    ttttttttt//////\"\n",
      "batch 2507  loss=130.3631  steps/s=105.72  prediction: \"s a natively written zig matmul function\" => \" ae                          tt     tttt\"\n",
      "batch 2508  loss=160.9534  steps/s=101.34  prediction: \" the 16 hour coding session, lets get it\" => \"thnn   77                         sssss \"\n",
      "batch 2510  loss=146.1780  steps/s=101.60  prediction: \" youre so smart why are you conquered??\"\" => \"ton                                   ee\"\n",
      "batch 2511  loss=128.2683  steps/s=105.78  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taiegitiiiiiii          lllll           \"\n",
      "batch 2512  loss=157.0042  steps/s=104.29  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"toSt tS//////////ttttttttttt///////////Y\"\n",
      "batch 2513  loss=134.7017  steps/s=104.79  prediction: \" I didnt post AT ALL til it was 98% done\" => \"t  k                                    \"\n",
      "batch 2514  loss=146.7848  steps/s=98.62  prediction: \"s waking back up https://t.co/0wXM4UadXf\" => \" aal l                            //////\"\n",
      "batch 2516  loss=134.6832  steps/s=109.66  prediction: \"ple deep q network has achieved insanity\" => \"ly: @op                        h   aaaaa\"\n",
      "batch 2517  loss=124.5479  steps/s=99.13  prediction: \"onna gm post w this video I guarantee it\" => \"ne  n nnnn                              \"\n",
      "batch 2518  loss=128.7498  steps/s=100.32  prediction: \" ways to take advantage of small nuances\" => \"tor               aaaaaaaaaaaaaaaaaaaa  \"\n",
      "batch 2519  loss=140.8331  steps/s=104.18  prediction: \"y brotha ty, nah no zig for this bad boy\" => \" t aa aaaatt                            \"\n",
      "batch 2520  loss=127.2770  steps/s=104.66  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" os    eeeeeeeeee                tttttt \"\n",
      "batch 2521  loss=139.1192  steps/s=52.87  prediction: \": @0arity @bayes_street probably yea lol\" => \" @wo seeeee          t ttttoooo  tt     \"\n",
      "batch 2522  loss=132.9120  steps/s=107.28  prediction: \"code base to get something super complex\" => \"hm t tee                                \"\n",
      "batch 2523  loss=146.4912  steps/s=54.33  prediction: \": @0x77er some likes are worth 100 likes\" => \" @0asteeeee   e    eeee                e\"\n",
      "batch 2524  loss=127.1303  steps/s=108.09  prediction: \"dition, just kpis to optimize right now)\" => \" nt iennnnnnnnn               iiiiiiiiii\"\n",
      "batch 2525  loss=139.3044  steps/s=104.43  prediction: \"sk for, then train them to ask, then act\" => \" e t                   ttt              \"\n",
      "batch 2526  loss=160.5356  steps/s=105.45  prediction: \"e77 build things people want/ need maybe\" => \"  o: @Bc       iiiiiii           eeeeeee\"\n",
      "batch 2527  loss=125.1594  steps/s=99.95  prediction: \"t. good thing we still have comonad club\" => \"h   tx                                  \"\n",
      "batch 2528  loss=145.1382  steps/s=104.17  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"eplge                               iiii\"\n",
      "batch 2529  loss=131.9706  steps/s=82.34  prediction: \"kul07 Time limits on tasks are so useful\" => \"e t enn      iiiiii            sss     s\"\n",
      "batch 2530  loss=134.7002  steps/s=104.71  prediction: \"r_fusion based\n",
      "i cant read apparently xD\" => \"e ly: @nn  iiiiiii    a   aaaaaaa aaa  e\"\n",
      "batch 2531  loss=158.1295  steps/s=103.65  prediction: \"/t.co/KAmykVYFyw https://t.co/Fg3PbzaDJZ\" => \"toctepp//////////ttttttttttt////////////\"\n",
      "batch 2532  loss=134.5466  steps/s=101.35  prediction: \" is nice. idk much about distros tho lol\" => \"at e ennnn iiii                      ooo\"\n",
      "batch 2533  loss=140.1267  steps/s=99.71  prediction: \"e @sunsettler youre in the nix dimension\" => \" a : @neeeeeee                          \"\n",
      "batch 2534  loss=119.6427  steps/s=100.65  prediction: \" said it was his last email, he meant it\" => \"ttehhehe                                \"\n",
      "batch 2535  loss=145.2185  steps/s=101.43  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" ah h      tttttttttttttttttttttttt     \"\n",
      "batch 2536  loss=144.1133  steps/s=22.35  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly:t    ttt ttttttttttt tt t tttt      \"\n",
      "batch 2537  loss=130.1554  steps/s=106.51  prediction: \"o him) and he begged to pay me to use it\" => \" al i t                                 \"\n",
      "batch 2538  loss=125.8705  steps/s=110.91  prediction: \"re you need to make a sphere version now\" => \"eply: @    e     ee  e       eeee eeeeee\"\n",
      "batch 2540  loss=135.4763  steps/s=99.90  prediction: \" @discord I made my own bot from scratch\" => \"ta h idedddddddddd                      \"\n",
      "batch 2541  loss=134.3632  steps/s=104.89  prediction: \".. would love to be proven wrong on this\" => \"  htlanww......                  ooo    \"\n",
      "batch 2542  loss=165.1483  steps/s=95.68  prediction: \"ode Solidworks\n",
      "$500/yr aint gonna cut it\" => \"  a   odloooooooooooooorr  r  nnnnnnnnnn\"\n",
      "batch 2543  loss=129.6643  steps/s=96.76  prediction: \"dness there are some juicy tactics there\" => \" vt  ooooo     eeeeeeeeeee       ccccccc\"\n",
      "batch 2544  loss=139.1804  steps/s=96.96  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \"   st  ttttttttttttttttttttttttt////////\"\n",
      "batch 2545  loss=122.8652  steps/s=106.02  prediction: \"ticated strings as defined by kolmogorov\" => \"hn o  etttttttttssssssssssss            \"\n",
      "batch 2546  loss=133.4369  steps/s=104.14  prediction: \" tons of stuff, for yrs, and that worked\" => \"thrt  t           ffffffffff            \"\n",
      "batch 2547  loss=144.8990  steps/s=99.44  prediction: \"r him, thanks! Sounds useful potentially\" => \"ean :                     uuuuuuuuuuuuuu\"\n",
      "batch 2548  loss=125.6394  steps/s=86.54  prediction: \"amebedan since ports dont allow weapons.\" => \"nsy h  eaaaee    n s  sssss    oot  lllo\"\n",
      "batch 2549  loss=124.8998  steps/s=64.20  prediction: \" @startupmillyair lichess or chessdotcom\" => \"tye   maaanne    n s   sssssso o  eooooo\"\n",
      "batch 2550  loss=142.7336  steps/s=106.91  prediction: \" up to do multiple iterations of editing\" => \"tse  t                 tttttttttttiiiiii\"\n",
      "batch 2551  loss=133.3913  steps/s=99.82  prediction: \"ne that sends the html/js/etc files over\" => \"   ete              tttttttttttttttt  ee\"\n",
      "batch 2552  loss=130.2753  steps/s=105.28  prediction: \" is better than lots of ppl not starting\" => \"ts  sssssssseeeee                     tt\"\n",
      "batch 2554  loss=134.1622  steps/s=103.84  prediction: \"nly do this technique if I involve words\" => \" e et                        iiiii      \"\n",
      "batch 2555  loss=130.0849  steps/s=95.84  prediction: \"Gotta make one and learn that skill then\" => \"ot     oo                  n            \"\n",
      "batch 2556  loss=146.0314  steps/s=102.56  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"teai       aaaaaaaaatttttttttttttt//////\"\n",
      "batch 2557  loss=145.0011  steps/s=101.35  prediction: \" is better though, I should check it out\" => \"tn aemmeeeeeeeeeeee          hhhh       \"\n",
      "batch 2558  loss=143.0874  steps/s=105.04  prediction: \"by removing a bit does not increase theâ€¦\" => \"u lpxixyyyy                             \"\n",
      "batch 2559  loss=126.6979  steps/s=102.62  prediction: \"orce you to clean to avoid embarrassment\" => \"                                   aaaaa\"\n",
      "batch 2560  loss=133.5119  steps/s=101.33  prediction: \"nkedin phase\n",
      "\n",
      "we'll teach them hopefully\" => \"  thr    hhhiiieeeeeeeeeeeeeeeeeehhhhhhh\"\n",
      "batch 2561  loss=136.5731  steps/s=95.91  prediction: \"joane College is super early in life tbh\" => \"uct o inaneeeeeeellleeee   ee       llll\"\n",
      "batch 2562  loss=130.5916  steps/s=101.21  prediction: \"like a really really interesting project\" => \"yc @eeeeee       llllllllllllleeeeeeeeee\"\n",
      "batch 2563  loss=136.7706  steps/s=105.23  prediction: \" absolutely mind blowing post all around\" => \"tb tla              lll                 \"\n",
      "batch 2564  loss=156.0090  steps/s=102.20  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"tott ttl               tttttttttttt/////\"\n",
      "batch 2565  loss=134.1870  steps/s=104.71  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"tcmo m mmmmmmmmm        eeeeeeeeeeeeeeee\"\n",
      "batch 2566  loss=126.5314  steps/s=105.33  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia  g  aaaa       nnntttttttttttttttttt\"\n",
      "batch 2567  loss=140.2508  steps/s=101.59  prediction: \" w as in why tf would you use white mode\" => \"tosaspe                                 \"\n",
      "batch 2568  loss=148.1741  steps/s=102.76  prediction: \" God for helping us both out\n",
      "it was hell\" => \"terall                                  \"\n",
      "batch 2569  loss=135.3882  steps/s=104.37  prediction: \"sonnet3.5 for pretty much everything now\" => \"  ese eeeeee                            \"\n",
      "batch 2570  loss=125.1466  steps/s=102.93  prediction: \"mething. like when youre waiting in line\" => \"etne ro o                         iiiiii\"\n",
      "batch 2571  loss=135.8152  steps/s=103.45  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn no e       eeeeeeeeeeeeeeetttt///////\"\n",
      "batch 2573  loss=134.2905  steps/s=101.75  prediction: \" thanks man! i should uh sleep more yeah\" => \"than aaaaaaaa                 sh     eee\"\n",
      "batch 2574  loss=131.6424  steps/s=103.55  prediction: \"ed hard at improving, mostly by studying\" => \"  n                                    y\"\n",
      "batch 2575  loss=138.9957  steps/s=44.60  prediction: \"y: @benfleming__ its lifechanging really\" => \"  @o d                              yyyy\"\n",
      "batch 2576  loss=129.0563  steps/s=107.11  prediction: \" in those days will have had it too easy\" => \"tns , s                                 \"\n",
      "batch 2577  loss=135.0120  steps/s=104.52  prediction: \" focus/attention to a negative direction\" => \"tort f      ttttttttttttttttttt         \"\n",
      "batch 2578  loss=143.2654  steps/s=54.80  prediction: \": @yacineMTB jak creep is a real problem\" => \" @Aoty uattttttttttt             e   iee\"\n",
      "batch 2579  loss=139.3387  steps/s=109.94  prediction: \" i found it really hard for some things.\" => \"tt  iiii                                \"\n",
      "batch 2580  loss=133.0737  steps/s=101.34  prediction: \"grammer unfortunately you are correct xD\" => \"  dmo mmmmmrrrrrrrrrrrrruuuuuu   rrrrrrr\"\n",
      "batch 2581  loss=129.8224  steps/s=104.07  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "Seat s                                 \"\n",
      "batch 2582  loss=129.7719  steps/s=105.01  prediction: \"and solving their problems/communicating\" => \"nd   o                      rrrrmmmmmmmm\"\n",
      "batch 2583  loss=138.7648  steps/s=97.64  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"g o essdnnnnneeemm    eeeee          aaa\"\n",
      "batch 2584  loss=147.6983  steps/s=102.32  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly: @a                              o oo\"\n",
      "batch 2585  loss=134.4657  steps/s=98.54  prediction: \"t your iq has to be under 70 or over 170\" => \" m ee                                   \"\n",
      "batch 2586  loss=128.9388  steps/s=104.13  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" ato   e eeeeeeeiiiiiiii                \"\n",
      "batch 2587  loss=146.9314  steps/s=103.82  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" t o        eeeeeeeeee  ffffffffff     r\"\n",
      "batch 2588  loss=134.8175  steps/s=103.87  prediction: \" is interesting play between those three\" => \"tt  e       eeeeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 2589  loss=177.3946  steps/s=103.74  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" ttK.cEcccccccLLLLeeeeeetttttttt////////\"\n",
      "batch 2590  loss=147.4497  steps/s=73.57  prediction: \"Brycicle77 its a 'being' kinda day today\" => \" yhE\n",
      "rccccc77777  tt    tttt///////ttttt\"\n",
      "batch 2591  loss=154.3953  steps/s=89.87  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ys @  cc77iiAA     pppppppppppppp     aa\"\n",
      "batch 2592  loss=132.0762  steps/s=107.13  prediction: \"et good at the ones youre not so good at\" => \"  andaea                          oooooo\"\n",
      "batch 2593  loss=136.4445  steps/s=103.37  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"t ti...ittttt                           \"\n",
      "batch 2595  loss=133.0955  steps/s=103.11  prediction: \"llows you to better descend the gradient\" => \"eis wo l                  eeeeeeeeeeeeee\"\n",
      "batch 2596  loss=133.8221  steps/s=103.12  prediction: \", how do WE figure out where things are?\" => \" to  i                                 e\"\n",
      "batch 2597  loss=132.2734  steps/s=103.84  prediction: \"learning models\n",
      "\n",
      "https://t.co/KAmykVYFyw\" => \"ymrirnrnnnnnnnnnnneeeeeeetttttt/////////\"\n",
      "batch 2598  loss=181.6791  steps/s=100.38  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"tepekemmmmmmmmmmm    tttt:::::ttt///////\"\n",
      "batch 2599  loss=142.1285  steps/s=103.09  prediction: \" from scratch, and a bit of transformers\" => \"tonp e p                                \"\n",
      "batch 2600  loss=134.5990  steps/s=38.23  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y  n e  rrrrrrrr                     rrr\"\n",
      "batch 2602  loss=135.9340  steps/s=139.55  prediction: \"eMTB How long until dingbots can do this\" => \" Tn: @ roooo                    n   oo  \"\n",
      "batch 2603  loss=145.6021  steps/s=104.93  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tud id d                        sssss   \"\n",
      "batch 2604  loss=145.3635  steps/s=96.70  prediction: \" its crack bro. be careful. i warned you\" => \"tn                              aa      \"\n",
      "batch 2605  loss=146.4046  steps/s=105.45  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"es n nnn                                \"\n",
      "batch 2606  loss=144.2667  steps/s=104.23  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplan                                   \"\n",
      "batch 2607  loss=165.0444  steps/s=103.21  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \" tus tess         oooooooooooooooooooooo\"\n",
      "batch 2608  loss=154.3299  steps/s=51.37  prediction: \": @AyNio2 see you on monday ma brotha! ðŸ«¡\" => \" @att    ooo  oo  ooooooooooooooooooooo \"\n",
      "batch 2609  loss=382.9738  steps/s=118.81  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"etly: @oooooooo                         \"\n",
      "batch 2610  loss=136.5254  steps/s=104.02  prediction: \" even the ones i disagreed with the most\" => \"tf e eeeeeeeeeee                        \"\n",
      "batch 2611  loss=148.4680  steps/s=100.06  prediction: \"houlda stuck to planting apple trees smh\" => \"iw    a                     t    t     e\"\n",
      "batch 2612  loss=134.1257  steps/s=57.96  prediction: \" @pr0timr @btwphones Will post once done\" => \"tsaz  a               n     p  ptee eeee\"\n",
      "batch 2613  loss=130.6333  steps/s=66.93  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \": @na a           ottnn   pplp p e  eeee\"\n",
      "batch 2614  loss=146.6397  steps/s=119.63  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "il  n vleeeeeeeeeeeeeeee               \"\n",
      "batch 2615  loss=126.0356  steps/s=103.19  prediction: \"works for the first time is the most fun\" => \"hn  o l                                 \"\n",
      "batch 2616  loss=123.4836  steps/s=103.46  prediction: \"uture w her, and what that would be like\" => \"t  nt                                   \"\n",
      "batch 2617  loss=158.8975  steps/s=101.13  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" iu  i                   ttttttttccccccc\"\n",
      "batch 2618  loss=131.8907  steps/s=105.70  prediction: \"just point to concepts and arent reality\" => \"ect  s                                  \"\n",
      "batch 2619  loss=139.1977  steps/s=105.59  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  h             tttttttttttttttt//////\"\n",
      "batch 2620  loss=147.4542  steps/s=104.19  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"tet  lo                          eeeeeee\"\n",
      "batch 2621  loss=126.7233  steps/s=22.00  prediction: \"eply: @Nominus9 should be out soon   : D\" => \" ly: oooo                      eee  eeee\"\n",
      "batch 2622  loss=155.3706  steps/s=107.79  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`á´˜ðŸŒ‘ðŸš€ð—¼ðŸ«¡ð—ª{`ðŸ“ˆâ€œâ€™â˜ ðŸ¤¦ð—»ðŸ˜¤{~ðŸ˜ŽðŸ˜~ðŸ“‰~~{{{{{{{{~$${{{ðŸ°$\"\n",
      "batch 2624  loss=131.7330  steps/s=104.63  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hat s   eeeeeeeeeeeeeeeeeeeeeee      nnn\"\n",
      "batch 2625  loss=131.6663  steps/s=105.15  prediction: \" two next to each other. then a 4x4. etc\" => \"the ee                     t            \"\n",
      "batch 2626  loss=126.3867  steps/s=104.85  prediction: \"egression to my past actions and results\" => \"  ine eeeeee                           s\"\n",
      "batch 2627  loss=124.1166  steps/s=104.75  prediction: \"feeling than automating hrs of work away\" => \" mr  eeeeeeee       aattaat at          \"\n",
      "batch 2628  loss=135.7056  steps/s=100.01  prediction: \"ttempt to appeal to ipad kid generation?\" => \"her  e ttttttttpppppppppppp             \"\n",
      "batch 2629  loss=168.9318  steps/s=103.86  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \"nfdi  ffff                ttttttttt/////\"\n",
      "batch 2630  loss=140.1400  steps/s=103.88  prediction: \"ions for agents\n",
      "Sounds v similar to this\" => \"nn le e           nnnnnnnnssssssss      \"\n",
      "batch 2631  loss=129.6423  steps/s=105.69  prediction: \" two next to each other. then a 4x4. etc\" => \"ahe ee                     t            \"\n",
      "batch 2632  loss=130.4464  steps/s=39.30  prediction: \"ly: @IterIntellectus its white pill week\" => \"y: . e    t tte   tt    t  hh          e\"\n",
      "batch 2634  loss=131.5608  steps/s=130.62  prediction: \"mirages keep getting crazier and crazier\" => \"eno @ t     eeeeeeeeeeee  eee         rr\"\n",
      "batch 2636  loss=130.3521  steps/s=103.54  prediction: \" can instantly runit w the runit command\" => \"to  s         n nnnnnnn                 \"\n",
      "batch 2637  loss=129.7499  steps/s=101.95  prediction: \"inds the shortest path to get everything\" => \"ng  i              ttttttttttttttttttttt\"\n",
      "batch 2638  loss=150.3009  steps/s=102.77  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e lo: @dddddddddddddddddddooaaaaiiiiiiir\"\n",
      "batch 2639  loss=140.6126  steps/s=103.91  prediction: \" you can do the second without the first\" => \"aoi                                    t\"\n",
      "batch 2640  loss=128.7993  steps/s=103.43  prediction: \"g correct (fingers crossed its this one)\" => \" a e e rrrrrrrrrrrrrrrrrrrrrrsssssssssss\"\n",
      "batch 2641  loss=139.1378  steps/s=103.01  prediction: \"p. maybe you can figure out how to do it\" => \"l : @ioii                               \"\n",
      "batch 2642  loss=137.2636  steps/s=105.20  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"h re r                     tt///////////\"\n",
      "batch 2643  loss=138.0968  steps/s=104.75  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"h e tas                        eeeeeeeee\"\n",
      "batch 2644  loss=138.9443  steps/s=103.89  prediction: \"rings out there that would just ruin ppl\" => \"e l t 0         tttttttttttt         uuu\"\n",
      "batch 2645  loss=135.2891  steps/s=103.68  prediction: \"eful/true)\n",
      "\n",
      "sometimes thisll take months\" => \" u es ssssuuuuueueeeeeeeeeeeettttttttttt\"\n",
      "batch 2646  loss=155.6717  steps/s=102.93  prediction: \"ic cases)\n",
      "dump into claude automatically\" => \"ne a  ccccccccssssssss           aaaaaaa\"\n",
      "batch 2647  loss=136.4799  steps/s=104.02  prediction: \"what's needed to  step out of reactivitâ€¦\" => \"hade sssss                             t\"\n",
      "batch 2648  loss=122.6108  steps/s=100.58  prediction: \"he going gets tough, the tough get going\" => \"e  nheeeeeee      gggggggttttttggggggggg\"\n",
      "batch 2649  loss=163.1968  steps/s=99.40  prediction: \"? nah, blocktard https://t.co/bYxFfo7Sue\" => \" N\n",
      "g ha       oaa   ttttttttttttttt/////\"\n",
      "batch 2650  loss=163.5459  steps/s=99.54  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \" nd cstrrrrrri\"\"\"\"\"\"\"ppppppppppppp\"\"\"\"\"\"\"\n",
      "batch 2651  loss=136.4008  steps/s=104.22  prediction: \"I figure if we just do it, ppl will join\" => \" illdidiiiiiiii                         \"\n",
      "batch 2652  loss=136.4176  steps/s=103.95  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"    e                ttttttttttttttt////\"\n",
      "batch 2653  loss=136.4465  steps/s=71.39  prediction: \"@btwphones thanks! its going well so far\" => \"yacomeM          ttttttttttt//////////  \"\n",
      "batch 2654  loss=132.0010  steps/s=106.93  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o                                     \"\n",
      "batch 2655  loss=143.0603  steps/s=98.18  prediction: \"yacine needs a dingboard wrap on his car\" => \" cey y yyy          eee   dd            \"\n",
      "batch 2656  loss=148.5681  steps/s=97.22  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"ene y a eee                ttttttttt////\"\n",
      "batch 2657  loss=152.8015  steps/s=100.12  prediction: \"el editor and gameplay, that sounds cool\" => \"  a a                  aaaaaaaaaaaa     \"\n",
      "batch 2658  loss=140.1905  steps/s=105.99  prediction: \" making anifusion in the first place btw\" => \"@a d              iinnnnnniiiiii        \"\n",
      "batch 2659  loss=113.0532  steps/s=63.11  prediction: \"@calbch its gonna be a good one for sure\" => \"yacinaMaa    iinnnnnnn                  \"\n",
      "batch 2662  loss=153.3481  steps/s=108.96  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"@oe  e        rurrrrrrrr   tttttttt/////\"\n",
      "batch 2663  loss=143.0542  steps/s=98.79  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" fe   k       o  ooooooooot/////////////\"\n",
      "batch 2664  loss=144.1111  steps/s=100.92  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"@iao l                          oooooooo\"\n",
      "batch 2665  loss=136.7128  steps/s=104.84  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"l tet eeeeeeeeeeeeeeeeeeeeaaaaaaaa      \"\n",
      "batch 2667  loss=146.7478  steps/s=105.35  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e le     rrrrrrrrrrrrrrrrr              \"\n",
      "batch 2668  loss=130.7260  steps/s=104.67  prediction: \"just have to connect/reconnect the wifi'\" => \"ust t '                 oonnnnnnccccceee\"\n",
      "batch 2669  loss=178.7552  steps/s=39.78  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"y: @ o             ttt oonncccccceeeeeee\"\n",
      "batch 2670  loss=177.8001  steps/s=110.68  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lss @  sssssuuu           tttttttt//////\"\n",
      "batch 2671  loss=140.2846  steps/s=101.96  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"is ss                     tttt//////////\"\n",
      "batch 2672  loss=131.3699  steps/s=103.17  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"s  t  ttttttttttttttttaaaaaaaaaahhhhhhhh\"\n",
      "batch 2673  loss=114.0470  steps/s=63.78  prediction: \"@nlevnet that's a great thought actually\" => \"yac_aeltttttttttaataaaaaaaaah hhhh h  a \"\n",
      "batch 2674  loss=132.7800  steps/s=117.93  prediction: \"r_fusion based\n",
      "i cant read apparently xD\" => \"eply: @netttta aa    aa        aaaaaalll\"\n",
      "batch 2675  loss=130.0685  steps/s=105.74  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \"htt   t         ooooooooooooo           \"\n",
      "batch 2676  loss=132.4080  steps/s=105.21  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \"  eaan     iiiiiiiiiiiitttttttttttttttt/\"\n",
      "batch 2677  loss=140.0365  steps/s=101.42  prediction: \"n pick your own time though its flexible\" => \"gl h  a                                 \"\n",
      "batch 2679  loss=153.8951  steps/s=52.75  prediction: \": @RajenJangam Thanks! Glad you liked it\" => \" @_ue a                             iiee\"\n",
      "batch 2680  loss=139.1473  steps/s=121.25  prediction: \"yon Super hyped to see what youre cookin\" => \":u naa   nnn                          ee\"\n",
      "batch 2681  loss=135.4736  steps/s=105.57  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"e \n",
      "ue          eeeeeeeeeeeeeeeeeeeeeeett\"\n",
      "batch 2682  loss=153.1916  steps/s=105.03  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"ht  nru          BBBBBBB                \"\n",
      "batch 2683  loss=146.3643  steps/s=104.39  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"  s et://///////hhhhhhtttt/////////////R\"\n",
      "batch 2684  loss=145.0033  steps/s=95.53  prediction: \"ould get my ass handed to me for suuuure\" => \"nl  i go                                \"\n",
      "batch 2685  loss=160.7045  steps/s=95.01  prediction: \"ere @jesx64 never stop having fun either\" => \" ?i: @ S     e     e                uuuu\"\n",
      "batch 2686  loss=133.9426  steps/s=104.92  prediction: \"xample\n",
      "Do this and then train them on it\" => \" mraf                                   \"\n",
      "batch 2687  loss=138.7081  steps/s=107.78  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nnitotiiiiiiittittt                     \"\n",
      "batch 2688  loss=133.8199  steps/s=103.41  prediction: \"is phrase and you will see it everywhere\" => \"n MTBreeeeeeeee                      eee\"\n",
      "batch 2689  loss=128.7698  steps/s=105.83  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"es  m                                   \"\n",
      "batch 2690  loss=131.5919  steps/s=104.03  prediction: \"rce on github to figure some of this out\" => \"ehgch                                   \"\n",
      "batch 2691  loss=127.0697  steps/s=103.82  prediction: \"ments as opposed to making the user wait\" => \"e  e it eeeeessssssss                   \"\n",
      "batch 2692  loss=239.0240  steps/s=99.69  prediction: \" ayyy thanks!!! LETS GOO FINALLY SHIPPED\" => \"t e eyyyy  yyyyy    !!!!!!              \"\n",
      "batch 2693  loss=132.9474  steps/s=103.25  prediction: \"and completely unknown to the other half\" => \"nd o   l llllllllll    nnnnnnnn         \"\n",
      "batch 2694  loss=128.8364  steps/s=96.43  prediction: \"e enlightened than me, i need to wake up\" => \" teere  eeeeeeeeeeeeeeee                \"\n",
      "batch 2695  loss=179.0737  steps/s=103.24  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"ly: @s        AAAAAA   TTT   ttttt//EEEE\"\n",
      "batch 2696  loss=139.4939  steps/s=100.45  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"eply: @  ee  eeeeeeeeeeee               \"\n",
      "batch 2697  loss=125.5320  steps/s=103.91  prediction: \"he actual serious dangers of being smart\" => \"e   o                                   \"\n",
      "batch 2698  loss=135.1282  steps/s=99.12  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" I t  taa       eeeee                  r\"\n",
      "batch 2699  loss=121.3455  steps/s=86.35  prediction: \"notmoeezm gotta love the non specificity\" => \" wxaat eeeeeee                      uuuu\"\n",
      "batch 2700  loss=128.0323  steps/s=106.18  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"too a r  rrrr       ssssssss            \"\n",
      "batch 2701  loss=134.8711  steps/s=102.38  prediction: \" which uses a superset of c. so not sure\" => \"t i cc ccccc           ss               \"\n",
      "batch 2702  loss=139.7126  steps/s=104.72  prediction: \"ver\n",
      "replace youtube embed with the video\" => \"idtat     eeeeeeeeeeeeeeeeeeeeeeeeee    \"\n",
      "batch 2703  loss=131.8042  steps/s=101.13  prediction: \"ful info have you learned from it so far\" => \" n   luu                                \"\n",
      "batch 2704  loss=129.5093  steps/s=103.59  prediction: \" deadlines dont really get done the same\" => \"toe   oo  ddddddddddd                  e\"\n",
      "batch 2705  loss=130.2053  steps/s=102.12  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"t en          e ee \"\"\"\"\"\"\"\"\"\"\"\"         \"\n",
      "batch 2706  loss=126.7070  steps/s=104.86  prediction: \" adding the context into the computation\" => \"tnr                     tttttttttttttttt\"\n",
      "batch 2708  loss=132.9330  steps/s=103.09  prediction: \" like i can do so much more in python :(\" => \"tit                                     \"\n",
      "batch 2709  loss=129.7671  steps/s=104.34  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"   ni eeeeeennnnnnnnnnnnnnnnnnnooooooooo\"\n",
      "batch 2714  loss=145.3504  steps/s=103.74  prediction: \" on it\n",
      "\n",
      "What is your version? Im curious\" => \"tnt                                     \"\n",
      "batch 2716  loss=135.2381  steps/s=70.20  prediction: \"yacineMTB nooo not a 2d grid of 2d grids\" => \":c  t  a  t     ooo                    r\"\n",
      "batch 2718  loss=137.0479  steps/s=107.53  prediction: \"nbelievably cracked\n",
      "\n",
      "still 25 years left\" => \"g oae   eeeeeeeeeeeeeeeeeeelllllllllllll\"\n",
      "batch 2719  loss=150.4720  steps/s=104.90  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`á´˜]ðŸ’ª[ðŸ«¡ð—ª$$ðŸ˜­#ðŸ§ ðŸ˜­$ð—µæˆ‘ð—¼ðŸŒ‘#ðŸ˜|á´›}ð—»ð—¿|èµ°ðŸ¤¯ðŸ¤¯ðŸ‘|ðŸ¤¯ðŸ¤¯||ðŸŽ‰ðŸ˜­ðŸ¤£#ðŸ‘\"\n",
      "batch 2720  loss=139.9123  steps/s=104.65  prediction: \"6hrs on something that feels like a game\" => \"hr6                                     \"\n",
      "batch 2721  loss=117.6464  steps/s=36.54  prediction: \"ply: @sunsettler im down another weekend\" => \"ly: @6h                        e   e  e \"\n",
      "batch 2722  loss=195.9683  steps/s=55.88  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly:                           e  eee ee\"\n",
      "batch 2723  loss=148.3523  steps/s=99.83  prediction: \"ly: @anish0209 No problem I gotchu man ðŸ«¡\" => \"y:  a  ssss h r       o       ee  eeeee \"\n",
      "batch 2724  loss=130.0046  steps/s=109.74  prediction: \" you called it. may as well draft it now\" => \"tou                                     \"\n",
      "batch 2726  loss=131.5524  steps/s=103.52  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \"ur  ii                                  \"\n",
      "batch 2727  loss=137.8813  steps/s=103.67  prediction: \"ding up the drive thru for 1000 episodes\" => \" va Be                               000\"\n",
      "batch 2728  loss=133.7716  steps/s=104.61  prediction: \"etting about them, is a v common mistake\" => \" ts  no      ttttttttt              mmmm\"\n",
      "batch 2729  loss=164.0326  steps/s=102.81  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e no                                  ??\"\n",
      "batch 2731  loss=166.5536  steps/s=97.84  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" tsu  eee             t tttttt//////////\"\n",
      "batch 2732  loss=232.2317  steps/s=20.89  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly:  eee            tttttttt//////////a\"\n",
      "batch 2733  loss=137.7299  steps/s=124.99  prediction: \"end to work, and they pretend to pay us\"\" => \"  r: @ee                                \"\n",
      "batch 2734  loss=135.1857  steps/s=105.11  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"eate                 nnnnnnnnnniiiiitttt\"\n",
      "batch 2735  loss=144.9248  steps/s=101.33  prediction: \"ey sandwich has been achieved internally\" => \"     r  ddd               eeeeeeeeeeeeee\"\n",
      "batch 2736  loss=147.9986  steps/s=105.00  prediction: \"r you choose is not technically infinite\" => \"eal s      ooooooooooooo             iii\"\n",
      "batch 2737  loss=138.1658  steps/s=10.62  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"eal :     ooooooooooo o             iiii\"\n",
      "batch 2738  loss=138.3922  steps/s=120.33  prediction: \"ems like you have. thanks for sharing it\" => \"   s seeeeeeeeeeeeee                    \"\n",
      "batch 2739  loss=143.0475  steps/s=103.20  prediction: \"st surgery, without painkillers\n",
      "\n",
      "i kneel\" => \" :s  ssssssssss             iiiiiiiiiiii\"\n",
      "batch 2740  loss=125.5149  steps/s=11.45  prediction: \"reply: @CConnorMahoney mate in two* oops\" => \"eply: @sssssss             iiiiiiiiiiiii\"\n",
      "batch 2741  loss=141.1476  steps/s=108.18  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"tn                 tttttttttttttttt/////\"\n",
      "batch 2742  loss=167.6822  steps/s=11.32  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"eptn              tttttttttttttttt//////\"\n",
      "batch 2743  loss=133.0566  steps/s=108.84  prediction: \". but idk thats just my weird take on it\" => \" ap .  tttt tttt                        \"\n",
      "batch 2744  loss=124.4383  steps/s=103.76  prediction: \"go, the name.. none of that shit matters\" => \" t    e                             tttt\"\n",
      "batch 2745  loss=134.4981  steps/s=105.42  prediction: \".. would love to be proven wrong on this\" => \"   t aawww.....                  ooo    \"\n",
      "batch 2746  loss=137.9629  steps/s=105.92  prediction: \"ney OR something extremely useful to you\" => \"d te e                eeeeeeeeeeeeeeeeee\"\n",
      "batch 2747  loss=137.5271  steps/s=104.40  prediction: \" but its worth it\n",
      "\n",
      "just make stuff thatâ€¦\" => \"tuo            ttttttttttttttttttttttttt\"\n",
      "batch 2748  loss=122.0802  steps/s=100.40  prediction: \"enisnikulin its the lichess of photoshop\" => \"  he ttt   niiiiittttt tt   sssssssss  o\"\n",
      "batch 2749  loss=130.1903  steps/s=98.57  prediction: \"pmillyair lichess is like 200 elo higher\" => \"lo: @tuuiiiiiiiiliiiiiiisssss        ooh\"\n",
      "batch 2750  loss=134.0685  steps/s=101.11  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \"d tettirrrrr   s sssssss         hh     \"\n",
      "batch 2751  loss=129.5978  steps/s=97.09  prediction: \" square gang wont let this happen &gt;:(\" => \"tuir ouy        waaa   t   ttttt     ppp\"\n",
      "batch 2752  loss=174.7925  steps/s=31.29  prediction: \"ply: @sunsettler https://t.co/2ERTWsJiwS\" => \"ly: @tiuu         a   tttttttttt     pp \"\n",
      "batch 2753  loss=131.4764  steps/s=108.19  prediction: \"uff and just pretending to do side stuff\" => \"rf i                   nnnn             \"\n",
      "batch 2755  loss=134.3414  steps/s=104.40  prediction: \"dless memory related errors (impossible)\" => \" io oo     mmmmmmeeeeeeeeerrrrrrrrrrrrss\"\n",
      "batch 2756  loss=135.5053  steps/s=104.27  prediction: \"g down other hard but unproductive paths\" => \" te                                    t\"\n",
      "batch 2757  loss=140.0555  steps/s=103.34  prediction: \"king useful things, so it didnt work out\" => \"el  elk                                 \"\n",
      "batch 2759  loss=127.7094  steps/s=63.78  prediction: \"@nlevnet that's a great thought actually\" => \"tuVSaeleee         ss                 tt\"\n",
      "batch 2761  loss=195.7345  steps/s=79.07  prediction: \" @458gdb @gizmobly @crypt0x_0 100% agree\" => \"tHkk eeeee  tt i         tttttt       tt\"\n",
      "batch 2762  loss=171.8423  steps/s=107.61  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" txepqcccccccccccc          ooooo///////\"\n",
      "batch 2763  loss=130.3354  steps/s=104.67  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tatr e                                ii\"\n",
      "batch 2764  loss=138.0649  steps/s=103.96  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "supr d     dddddaaaaaaaaaaaaaa         \"\n",
      "batch 2765  loss=128.6848  steps/s=100.69  prediction: \"ers had a username but idk his name name\" => \"  lie@eeee                              \"\n",
      "batch 2766  loss=120.7571  steps/s=83.36  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"Vhehettt                    s ss s  am t\"\n",
      "batch 2767  loss=130.7863  steps/s=104.70  prediction: \" keep doing it for more and more phrases\" => \"tew neeeeeeeeeee                       r\"\n",
      "batch 2768  loss=148.2663  steps/s=99.68  prediction: \"P get him toys, play w him, lasts longer\" => \"r@ ae gggg                            ss\"\n",
      "batch 2770  loss=153.0185  steps/s=98.69  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \" m gepi      i        hhtttttttttttt////\"\n",
      "batch 2771  loss=126.5456  steps/s=103.98  prediction: \"tion WAY more than if its someone else's\" => \"hm  r oo ooooo                         e\"\n",
      "batch 2772  loss=130.6422  steps/s=104.49  prediction: \"w up wherever decision making is present\" => \"isl g             eeeeeeeeeeeeiiiiiiiiii\"\n",
      "batch 2774  loss=131.9170  steps/s=104.41  prediction: \" ppl twist your arm behind your back lol\" => \"trtert ttttt                            \"\n",
      "batch 2775  loss=144.2473  steps/s=104.30  prediction: \"nce\n",
      "\n",
      "5 depends on not missing ANY of 1-4\" => \"  lo           n   nnnnnnnnnnnnnn       \"\n",
      "batch 2776  loss=131.3972  steps/s=102.90  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \" ecato   eeeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 2777  loss=143.8027  steps/s=100.23  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" oto rheeeeeeesssssssr0rrrrrrr  r       \"\n",
      "batch 2778  loss=134.4341  steps/s=104.59  prediction: \"y do what sounds more interesting to you\" => \" to o b                                 \"\n",
      "batch 2779  loss=130.6220  steps/s=101.41  prediction: \"han automating friction out of your work\" => \"eg tt  tttttttttttttttttiiiiii    oooooo\"\n",
      "batch 2780  loss=137.8335  steps/s=102.30  prediction: \"ly beautiful\n",
      "Love seeing stuff like this\" => \"y: @Nnaaaaaaaaaelleeeeeeeeeeeeeeeeeefffe\"\n",
      "batch 2781  loss=171.7708  steps/s=100.27  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \" vb ill              tttttttttttt///////\"\n",
      "batch 2782  loss=143.3836  steps/s=100.29  prediction: \"ct\n",
      "\n",
      "also, interesting advice in the clip\" => \"ooi   looooooooooottttttttetiiiiiiiiiiii\"\n",
      "batch 2783  loss=138.1518  steps/s=104.24  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t l e                  tttttttttttt/////\"\n",
      "batch 2784  loss=131.9479  steps/s=104.10  prediction: \"just start working, and it doesnt matter\" => \"uct                                  ttt\"\n",
      "batch 2785  loss=138.3608  steps/s=105.23  prediction: \" absolutely mind blowing post all around\" => \"tb tli               ll                 \"\n",
      "batch 2786  loss=123.5989  steps/s=31.79  prediction: \"ply: @tszzl no :( 4o is still goated tho\" => \"ly:  l  llll                            \"\n",
      "batch 2787  loss=151.9368  steps/s=117.52  prediction: \"opped this, king https://t.co/XoVrIPw6zw\" => \"uisns  ee                ttttttttttt////\"\n",
      "batch 2788  loss=132.3482  steps/s=102.62  prediction: \"ros named tuna but he swam like a salmon\" => \"em  d rrr                               \"\n",
      "batch 2789  loss=125.4989  steps/s=107.91  prediction: \" ill dm you a link to it around the 25th\" => \"tn e eeeeeeee                           \"\n",
      "batch 2790  loss=164.7080  steps/s=101.44  prediction: \"eMTB here you go https://t.co/oR4fVr3TMW\" => \" Tr n@aMMMMMyyyh               oooo/////\"\n",
      "batch 2791  loss=143.8044  steps/s=102.94  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"iul  y                     ttttt////////\"\n",
      "batch 2792  loss=135.9228  steps/s=102.35  prediction: \"broth but it tastes awful lol any advice\" => \"e    ooo       ttttttttttttt            \"\n",
      "batch 2793  loss=146.7060  steps/s=47.06  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \": @d oobbb  tttttttttttt       l        \"\n",
      "batch 2794  loss=133.6595  steps/s=106.54  prediction: \" tons of stuff, for yrs, and that worked\" => \"thlt  t             ffffffff            \"\n",
      "batch 2795  loss=132.0042  steps/s=94.65  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \"heo e   ssssnss  s            e      e  \"\n",
      "batch 2796  loss=125.4200  steps/s=99.98  prediction: \"and run it in the front end of a browser\" => \"nd   e                                  \"\n",
      "batch 2797  loss=132.8588  steps/s=105.47  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" on t      aaaaaaaaaaaannnnnnnnnnnnnnnnn\"\n",
      "batch 2798  loss=132.4680  steps/s=100.60  prediction: \"Some Tal games are real art masterpieces\" => \"p em a mmmaaa  m  aaaeaaaa aaa aaaaaaaaa\"\n",
      "batch 2799  loss=139.3004  steps/s=92.65  prediction: \"enko Could probably do this w ai now lol\" => \"  o: @ooooo          l                  \"\n",
      "batch 2800  loss=170.9741  steps/s=100.94  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @ddee   ssss         tttttttttttt///\"\n",
      "batch 2801  loss=193.0686  steps/s=97.66  prediction: \"rs: John 14:6-14 https://t.co/37ryh1InfG\" => \"eely: @sssssr   ::::::11::////////////tt\"\n",
      "batch 2802  loss=141.6581  steps/s=104.32  prediction: \" an api, if so I could make one on there\" => \"t c aasaa                               \"\n",
      "batch 2803  loss=138.7137  steps/s=100.25  prediction: \"ind groups of ppl who love what you love\" => \"ng s                                    \"\n",
      "batch 2804  loss=134.8314  steps/s=48.55  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @                                oo  \"\n",
      "batch 2806  loss=129.5715  steps/s=110.42  prediction: \"res a reason they dont but i dont see it\" => \"eply: @eeeeeeeeeee                      \"\n",
      "batch 2807  loss=127.5051  steps/s=99.87  prediction: \"her level abstraction of piece movements\" => \"es  a           eeee              eeeeee\"\n",
      "batch 2808  loss=146.4809  steps/s=100.12  prediction: \"n just do things https://t.co/909bTHzmml\" => \" eT le               ttttttttttttttttt//\"\n",
      "batch 2809  loss=131.2168  steps/s=103.45  prediction: \"ntil finally training on unzoomed images\" => \" eo s o \n",
      "      n  iiiinnnnnnnnnnnnnnnn  \"\n",
      "batch 2810  loss=150.8563  steps/s=11.11  prediction: \"reply: @5handilya See you thurs brotha ðŸ«¡\" => \"epne   \n",
      "         iiiiinnnnnnnnnnnnnnn   \"\n",
      "batch 2811  loss=134.2348  steps/s=130.52  prediction: \"ow powerful future architectures will be\" => \"u  minii             uuuuuurrrrrrrtrreee\"\n",
      "batch 2812  loss=128.7738  steps/s=104.32  prediction: \"d luck to step on worms and they stopped\" => \" i  t                                   \"\n",
      "batch 2813  loss=119.4325  steps/s=102.23  prediction: \"ark a bit so i felt like writing this up\" => \"t  o                          iiiiiiiiii\"\n",
      "batch 2814  loss=134.8069  steps/s=103.34  prediction: \" it as we speak) https://t.co/oTdseynD5s\" => \"tn t tii                   tttttttttt///\"\n",
      "batch 2815  loss=125.0768  steps/s=104.43  prediction: \"rough a floppy disk inserted in my brain\" => \"es o                                    \"\n",
      "batch 2816  loss=140.1535  steps/s=100.39  prediction: \"ight go back to ML stuff instead of this\" => \"n ta                                    \"\n",
      "batch 2817  loss=135.4726  steps/s=101.12  prediction: \"oesnt matter if its not live.. but still\" => \"   4g          tttttttttttt             \"\n",
      "batch 2818  loss=129.7854  steps/s=103.69  prediction: \"nts of time. its like skilling up almost\" => \" e    m                      iiiiiiiilll\"\n",
      "batch 2819  loss=137.3232  steps/s=105.41  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  n                         lllllllllll\"\n",
      "batch 2820  loss=138.2334  steps/s=101.41  prediction: \"worst part, as demonstrated by the graph\" => \"erd tlt  tttt            ttttttttttt    \"\n",
      "batch 2822  loss=141.0019  steps/s=104.61  prediction: \"everything is simple after you learn it\"\" => \" eo  i            i                     \"\n",
      "batch 2823  loss=132.6074  steps/s=103.36  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"s   t ttttttttt tt    pppppppppppp      \"\n",
      "batch 2824  loss=138.6597  steps/s=102.58  prediction: \"you gotta gamify reporting spam bots lol\" => \" uou   o o                              \"\n",
      "batch 2825  loss=136.6019  steps/s=98.68  prediction: \" The fundamentals contain the most alpha\" => \"thu   gA          aaaaannnnnnn          \"\n",
      "batch 2826  loss=132.1106  steps/s=103.71  prediction: \"re. it can only get 103 on snake though.\" => \"eply  eee                               \"\n",
      "batch 2827  loss=128.8730  steps/s=103.40  prediction: \" is a no go\n",
      "\n",
      "dang that sounds like a lot\" => \"tn e                                    \"\n",
      "batch 2828  loss=141.5140  steps/s=104.80  prediction: \" from scratch, and a bit of transformers\" => \"tanp a         cc                       \"\n",
      "batch 2829  loss=148.5039  steps/s=102.87  prediction: \"erous people, very sad, but also fixable\" => \"  ne i       eeeeeeeeeeee               \"\n",
      "batch 2830  loss=125.9524  steps/s=11.51  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"eply: @    e eeeeeeeeeee                \"\n",
      "batch 2832  loss=140.2820  steps/s=108.40  prediction: \"e thing, not just messing around with it\" => \" t at tttttttttt                        \"\n",
      "batch 2833  loss=145.0898  steps/s=101.40  prediction: \"ns must magnetically align their protons\" => \"   t bi i           lllllllllll         \"\n",
      "batch 2834  loss=121.4721  steps/s=104.77  prediction: \"nd of mental ownership over the codebase\" => \"g i  a                            eeeeee\"\n",
      "batch 2836  loss=196.7626  steps/s=38.16  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y                       ee   e    eeeeee\"\n",
      "batch 2838  loss=228.1986  steps/s=108.91  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"oT   IIIIIINNNNNNNMMMMM     //// ///////\"\n",
      "batch 2839  loss=162.8854  steps/s=42.69  prediction: \"ly: @shurensha Done. Great advice. Ty ty\" => \"y: @NIIEENNNNNMMMMM       / /////////ttt\"\n",
      "batch 2840  loss=154.5293  steps/s=89.73  prediction: \"y: @sebby_builds Japan sounds way better\" => \"  @C IIRRRN MMM            t    ww   ttt\"\n",
      "batch 2841  loss=132.8073  steps/s=119.93  prediction: \"p was the ultimate signal the whole time\" => \"lt: @stttt     tttttttt               ee\"\n",
      "batch 2842  loss=133.8945  steps/s=104.93  prediction: \"think bc they burn through the same fuel\" => \" et  o                   hhhhhhhhhhhh   \"\n",
      "batch 2843  loss=130.3710  steps/s=105.23  prediction: \"a decision making incongruency somewhere\" => \"ls o  sssssssss  iiiiiiiiinnnnnnnnnnnnnn\"\n",
      "batch 2844  loss=135.4221  steps/s=103.80  prediction: \" btw? or does onnx just work well enough\" => \"tateann                                 \"\n",
      "batch 2845  loss=135.8791  steps/s=104.33  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"n  al                     tttttttt//////\"\n",
      "batch 2846  loss=152.0054  steps/s=63.88  prediction: \"@anish0209 gpt or claude or whatever LLM\" => \"yxMiieMa                tttt//////ttttrr\"\n",
      "batch 2847  loss=142.4655  steps/s=107.00  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \" mrifeeeeeeeee                        rr\"\n",
      "batch 2848  loss=139.1552  steps/s=104.91  prediction: \"nts also on the nm level, but, 3d not 2d\" => \"tiou t  nnnoooo                         \"\n",
      "batch 2849  loss=142.3158  steps/s=104.58  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"  s//t:tttt///////hhhtttttt/////////////\"\n",
      "batch 2850  loss=147.2426  steps/s=99.23  prediction: \"em man, I had to share, its a crazy tool\" => \" _i                                     \"\n",
      "batch 2851  loss=128.8430  steps/s=104.92  prediction: \"rally where the word came from, i think)\" => \"ecrii                                   \"\n",
      "batch 2852  loss=133.9867  steps/s=104.97  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"teee neeeeeeeeeeeeeeetttttttttttttttttt/\"\n",
      "batch 2853  loss=139.8795  steps/s=106.05  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"thi e                                   \"\n",
      "batch 2854  loss=139.1300  steps/s=100.73  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "r n iiimmmmmeeee                       \"\n",
      "batch 2855  loss=150.0935  steps/s=105.10  prediction: \" God for helping us both out\n",
      "it was hell\" => \"tCrl                                    \"\n",
      "batch 2856  loss=135.5192  steps/s=100.64  prediction: \" more cracked by the day, love to see it\" => \"to t n                                  \"\n",
      "batch 2857  loss=183.3769  steps/s=102.98  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"L @ GGSSSSSSSNNAALLLLNALLLLLN tttttt////\"\n",
      "batch 2859  loss=143.0358  steps/s=102.77  prediction: \"ted to see how cracked you get long term\" => \" rn  o eeeeeeeeeeeeeee                  \"\n",
      "batch 2860  loss=137.6945  steps/s=101.96  prediction: \"nd beyond is such a gargantuan advantage\" => \"g  go                      aaaaaaaaaaaaa\"\n",
      "batch 2861  loss=167.6180  steps/s=102.54  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" ;nd e-;;;;;ggggggg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ooooooooooo    \"\n",
      "batch 2862  loss=135.2185  steps/s=105.63  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"ec21: @   aaaaaaaaaaarrrrrrrrrrrrrrrre  \"\n",
      "batch 2864  loss=131.9975  steps/s=105.17  prediction: \"has any non-json, ask for json in prompt\" => \"an  o           nnnnnnnnn               \"\n",
      "batch 2865  loss=134.5610  steps/s=66.01  prediction: \"@btwphones thanks! its going well so far\" => \"yulino   nnnnnnnnnnnnss   soooon        \"\n",
      "batch 2866  loss=125.7432  steps/s=109.45  prediction: \"thing you do very often, like constantly\" => \" iao  i                                 \"\n",
      "batch 2867  loss=133.1903  steps/s=104.23  prediction: \"dering doing another one of these monday\" => \"    ao         nnnnnnnnnnnnnoooo        \"\n",
      "batch 2869  loss=128.4574  steps/s=104.57  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"h nt nt  iiiiiiiiiiiiiiiioooooooooorrrrr\"\n",
      "batch 2870  loss=132.5381  steps/s=102.93  prediction: \"rol you. why would they want to do that?\" => \"ebles ttooo   o o                       \"\n",
      "batch 2872  loss=136.9357  steps/s=98.05  prediction: \"eadphones dead gonna recharge real quick\" => \" ron @hhhhhhhe  ddddd               aa a\"\n",
      "batch 2873  loss=128.9477  steps/s=103.95  prediction: \" the most important parts of improvement\" => \"to t               tttttttttttttt      m\"\n",
      "batch 2875  loss=130.2968  steps/s=66.50  prediction: \"justalexoki its tpot, all lowercase only\" => \"ssn root    oottttttttttttt      rrreree\"\n",
      "batch 2876  loss=136.6904  steps/s=108.74  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"    o  oo        p p         rrrreeeennn\"\n",
      "batch 2877  loss=129.5283  steps/s=104.17  prediction: \"izo with that soundtrack its hard not to\" => \"nie t tottiiii h    ttt tttttnnaaa      \"\n",
      "batch 2878  loss=161.5080  steps/s=105.48  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"gr teteeeeeeeeeeee dddddddddddaaaaaaaaaa\"\n",
      "batch 2879  loss=138.5801  steps/s=103.73  prediction: \"sk for, then train them to ask, then act\" => \"   t           t     t ttt              \"\n",
      "batch 2880  loss=131.6398  steps/s=105.37  prediction: \"did something similar w his site i think\" => \" n    i   iiiiiniiiiiiiiiiiiiiiiiiiiiiii\"\n",
      "batch 2881  loss=190.8129  steps/s=102.86  prediction: \"needed to dl this. meme delivery service\" => \"g                         eeeeeeeeeeeeee\"\n",
      "batch 2882  loss=162.2379  steps/s=29.37  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @                   eeeeeeeeeeeeeeee\"\n",
      "batch 2884  loss=167.6512  steps/s=107.32  prediction: \": @minamisatokun https://t.co/7cpKcX83WN\" => \" @ODn     d   t   ttteeeeeeeeeeeeeeeeeee\"\n",
      "batch 2885  loss=157.7159  steps/s=111.70  prediction: \"mk if you have any questions about usage\" => \"  e  a                              uuuu\"\n",
      "batch 2886  loss=143.7592  steps/s=104.66  prediction: \"d virus that makes ppl cracked at scale?\" => \" d  n                               aaaa\"\n",
      "batch 2888  loss=128.9927  steps/s=103.96  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \" tit hitttttttttttttttt                 \"\n",
      "batch 2889  loss=137.4086  steps/s=100.77  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lo   eerrrrrrrrrrrroi\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              \"\n",
      "batch 2890  loss=164.5388  steps/s=105.63  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..ooooooooo/////tttttttttttt///////////\"\n",
      "batch 2891  loss=140.5282  steps/s=106.04  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"h o ta                         eeeeeeeee\"\n",
      "batch 2892  loss=132.7670  steps/s=104.61  prediction: \"xample\n",
      "Do this and then train them on it\" => \" crtf                                   \"\n",
      "batch 2893  loss=128.8493  steps/s=107.52  prediction: \"ld me, no clue lool\n",
      "\n",
      "its good to be back\" => \"y  @oeee            lllllllloooooooooooo\"\n",
      "batch 2894  loss=127.0247  steps/s=38.40  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @oee        l lllllllloooooooooo oo  \"\n",
      "batch 2895  loss=119.0856  steps/s=112.62  prediction: \"yself infinite runway to build fun stuff\" => \"    eie    iiiiiiiiiinnnnn             u\"\n",
      "batch 2897  loss=130.0920  steps/s=105.48  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of  of                  tttttttttttt///\"\n",
      "batch 2898  loss=136.2148  steps/s=105.70  prediction: \"s is pretty cool https://t.co/2VR6GTbI3d\" => \" cot  t             tttttttttttttttt////\"\n",
      "batch 2899  loss=141.7285  steps/s=104.92  prediction: \"sing way more efficient/scalable methods\" => \" nu                   eeeeeeeeeeeeeeeeee\"\n",
      "batch 2900  loss=128.2013  steps/s=105.31  prediction: \" bc random twitter guy said itd be funny\" => \"te m m                                  \"\n",
      "batch 2901  loss=140.5060  steps/s=99.27  prediction: \"Koala that would be much appreciated, ty\" => \"asmaaaaaaaaaaaaattt                     \"\n",
      "batch 2902  loss=146.3923  steps/s=102.81  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \" t                       ttttttttttt////\"\n",
      "batch 2903  loss=145.5790  steps/s=95.18  prediction: \"5 custom tools speed things up a TON tbh\" => \" ge t  c     oooooo  tsettttttttpppp    \"\n",
      "batch 2904  loss=119.3283  steps/s=103.26  prediction: \"tput something as unexpected as possible\" => \" i  t tttttttttttt        eeeeeeeeeessss\"\n",
      "batch 2905  loss=127.3603  steps/s=104.33  prediction: \"dition, just kpis to optimize right now)\" => \" ni innnnnnnnn n              iiiiiiiiii\"\n",
      "batch 2906  loss=128.6477  steps/s=101.47  prediction: \"u were in vim, it should start the timer\" => \"tw o                                tttt\"\n",
      "batch 2907  loss=140.7503  steps/s=100.10  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"tse ee            ssssssssssstttttttt///\"\n",
      "batch 2908  loss=144.6325  steps/s=88.94  prediction: \"ntellectus little italy?? nah. big italy\" => \"   n steeel  lslsttttttttttttttta ?? aaa\"\n",
      "batch 2909  loss=131.6671  steps/s=106.12  prediction: \"oncept but also show you how to apply it\" => \"n e ce                       ooooooo    \"\n",
      "batch 2910  loss=125.5453  steps/s=102.79  prediction: \" was mated instead, so he resigned lmaoo\" => \"th t d                         eeeeeeeee\"\n",
      "batch 2911  loss=142.7306  steps/s=104.22  prediction: \"ying/whatever, every monday and thursday\" => \" nhCing//ggnnnninneeeeeeeeeeeeeeeey  ddd\"\n",
      "batch 2912  loss=129.3829  steps/s=102.20  prediction: \"ond\n",
      "but a fool with a sword is dangerous\" => \"nia                                     \"\n",
      "batch 2913  loss=128.6847  steps/s=106.00  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of  of fffff            ttttttttttt////\"\n",
      "batch 2914  loss=141.7278  steps/s=102.41  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" tttef                              oooo\"\n",
      "batch 2915  loss=130.2069  steps/s=97.46  prediction: \" What are your personal long term games?\" => \"thel lllhhh              o  ooo        g\"\n",
      "batch 2916  loss=133.5863  steps/s=97.66  prediction: \"iplying cells literally changed my life.\" => \"nl ut tt  llllllllllllllllllllllll      \"\n",
      "batch 2917  loss=134.4896  steps/s=102.02  prediction: \"e\n",
      "\n",
      "i need to try your coffee shop tactic\" => \" \n",
      " u   eeeeeeee                         \"\n",
      "batch 2918  loss=152.7343  steps/s=100.89  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \"ntu                          ttttttt////\"\n",
      "batch 2919  loss=134.9993  steps/s=103.68  prediction: \"never I see that in mc, programming, etc\" => \"  s    eeeeeeeeeeeee                    \"\n",
      "batch 2920  loss=125.9578  steps/s=106.25  prediction: \"rner u can actually set them to 2x speed\" => \"e tt   r                                \"\n",
      "batch 2921  loss=129.0624  steps/s=103.65  prediction: \"ts effortless to read/follow works in it\" => \"   h  e eeeeeeeteeeeeeeeeeoooooooooooooo\"\n",
      "batch 2922  loss=136.1729  steps/s=104.56  prediction: \"ng i correctly understood what you meant\" => \"  y  't                rrrrr            \"\n",
      "batch 2923  loss=167.1875  steps/s=105.25  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"to e e eeeeeeee          ttttttttttt//PP\"\n",
      "batch 2924  loss=133.8829  steps/s=97.99  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \"   e e        n   tttttttttt////////////\"\n",
      "batch 2925  loss=140.3674  steps/s=104.31  prediction: \"ther reasons why\n",
      "https://t.co/C32Ru1Tc5u\" => \" e  a t   ooooo o  hhhhhhhsstttttttttt//\"\n",
      "batch 2926  loss=134.9924  steps/s=101.84  prediction: \" btw? or does onnx just work well enough\" => \"tute  n                                 \"\n",
      "batch 2927  loss=156.8013  steps/s=99.50  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"n  o              ttttttttttttttttttt///\"\n",
      "batch 2928  loss=166.3556  steps/s=103.75  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" m K.cccccccccceLLeeeeeettttttttt///////\"\n",
      "batch 2929  loss=128.9217  steps/s=104.12  prediction: \" pays off immensely when I stick to them\" => \"tre  tttffffffffff                      \"\n",
      "batch 2931  loss=139.2925  steps/s=103.95  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tet tttaa     uuuutttttttttttttttttttttt\"\n",
      "batch 2932  loss=145.9167  steps/s=98.41  prediction: \"@sunsettler fight me (i would 100% lose)\" => \"yarmnunnnneteetettttttt            00000\"\n",
      "batch 2933  loss=166.2278  steps/s=63.29  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"yurmnulleeeeee t  t            00   !!! \"\n",
      "batch 2935  loss=148.8062  steps/s=108.38  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tude           n             ///////////\"\n",
      "batch 2936  loss=132.3149  steps/s=103.95  prediction: \" the parameters corrrect from the start?\" => \"tht  a   aaaaaaaaaarrrrrrrrrrrrrrrr    t\"\n",
      "batch 2937  loss=146.8608  steps/s=104.25  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"re in n             ttttttttttttttttttss\"\n",
      "batch 2938  loss=145.4115  steps/s=101.62  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"u  t                   ttttttttttttt////\"\n",
      "batch 2939  loss=127.9784  steps/s=104.13  prediction: \"es absolute security\n",
      "its like proving H0\" => \" se eeesssssssssssssuuuuss              \"\n",
      "batch 2940  loss=143.2018  steps/s=101.83  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" ih h      tttt ttttttttttt tttttt      \"\n",
      "batch 2941  loss=140.9893  steps/s=91.98  prediction: \"5 custom tools speed things up a TON tbh\" => \" I\n",
      "l    tttt ttttoo  o  ee              \"\n",
      "batch 2942  loss=124.4421  steps/s=77.61  prediction: \"atedro buildin something ppl want lesgoo\" => \"n  5  ttttooooo soe     gg g            \"\n",
      "batch 2944  loss=137.8790  steps/s=107.65  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"eply:         reeeeeeeeeeeeeeeeeeeeeefee\"\n",
      "batch 2945  loss=150.5357  steps/s=104.92  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u                       tttttttttt//////\"\n",
      "batch 2946  loss=144.6888  steps/s=102.73  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"eke  a        ooooooooooooooooooo       \"\n",
      "batch 2947  loss=135.1077  steps/s=105.11  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tftp s sss sssssssssssssssss         aaa\"\n",
      "batch 2948  loss=141.5393  steps/s=105.80  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" (  a               sssss               \"\n",
      "batch 2950  loss=140.5270  steps/s=103.49  prediction: \"bly helps that they have a faster ai now\" => \"uyiy  bbbllllllllhhhhhhhhhh     aaaaaaaa\"\n",
      "batch 2951  loss=133.2752  steps/s=101.80  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"th                        sssssss       \"\n",
      "batch 2952  loss=131.7940  steps/s=105.84  prediction: \"ep/useful and you become Christian again\" => \" ly  deeeeeeeeeuee                      \"\n",
      "batch 2953  loss=128.2186  steps/s=104.34  prediction: \"on mars we will make this a top priority\" => \"u    o                                  \"\n",
      "batch 2955  loss=134.0155  steps/s=105.57  prediction: \".. would love to be proven wrong on this\" => \"  hylaw ........                 ooo    \"\n",
      "batch 2956  loss=128.4356  steps/s=104.42  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \" un  o e  eeee                         e\"\n",
      "batch 2958  loss=135.1695  steps/s=104.98  prediction: \" works if you did it right, or it doesnt\" => \"thkt                                    \"\n",
      "batch 2959  loss=136.4658  steps/s=35.04  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: @m                                  \"\n",
      "batch 2960  loss=132.2079  steps/s=116.75  prediction: \"forming around AI or aroumd a fear of AI\" => \" r e n         n                        \"\n",
      "batch 2961  loss=142.9415  steps/s=104.75  prediction: \"tputs timestamps of ads =&gt; remove ads\" => \" eesee tttttttttttttttsssssss           \"\n",
      "batch 2962  loss=162.6006  steps/s=98.83  prediction: \"ettler @crypt0x_0 @EsotericCofe thanks!!\" => \" t)ttuttttttttppppp  s  0       o e     \"\n",
      "batch 2963  loss=129.1211  steps/s=105.97  prediction: \" good at developing your own techniquesâ€¦\" => \"te tereo        oo  ooooooooooo         \"\n",
      "batch 2964  loss=132.4253  steps/s=105.45  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tne eeedddddddd         rrrrrrrrrrr     \"\n",
      "batch 2966  loss=132.2680  steps/s=104.87  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"ect  ie          eeeeeee                \"\n",
      "batch 2967  loss=170.8120  steps/s=103.35  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \"NSNTH DTDAAAAAAAAAAAA             //////\"\n",
      "batch 2968  loss=189.9999  steps/s=45.86  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"     OTAAAAAAAAAA              ////////t\"\n",
      "batch 2971  loss=143.3522  steps/s=108.25  prediction: \"at fits wins, go https://t.co/vqzlbzWGd4\" => \"n  Whse tttttt t        ttttttttt///////\"\n",
      "batch 2972  loss=121.1821  steps/s=104.68  prediction: \"ot at the same time/in the same geometry\" => \"  n  t tttttt  t              eeeeeeeeee\"\n",
      "batch 2973  loss=134.8039  steps/s=104.26  prediction: \"ible w lots of work??? Sign me tf up NOW\" => \"nl  l                   ????????        \"\n",
      "batch 2974  loss=136.8139  steps/s=105.28  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er oaa                   tttttttttt/////\"\n",
      "batch 2975  loss=144.6534  steps/s=92.62  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"hes  se  eeerrrrrrrrootttoooooooooooooii\"\n",
      "batch 2976  loss=119.0409  steps/s=103.79  prediction: \"ot at the same time/in the same geometry\" => \"  a    ttttttt t              eeeeeeeeee\"\n",
      "batch 2977  loss=158.3542  steps/s=57.66  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"tIt  tttttttt         ttt  //eeeeeeeeeee\"\n",
      "batch 2978  loss=132.2003  steps/s=107.38  prediction: \"nserve the good parts against decay/loss\" => \"et o  a                         aaaaaaaa\"\n",
      "batch 2979  loss=128.5268  steps/s=91.77  prediction: \"t. have they found the piece yet or what\" => \"  i  i         h              eeeeeee   \"\n",
      "batch 2980  loss=195.9621  steps/s=29.16  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly:                         eeeeee     \"\n",
      "batch 2981  loss=129.7893  steps/s=105.95  prediction: \"conflicting values it would be a paradox\" => \"tnve t llllllllllllliiii                \"\n",
      "batch 2982  loss=164.6816  steps/s=104.44  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t.clitit/////////tttttttttt/////////////\"\n",
      "batch 2983  loss=151.1737  steps/s=99.64  prediction: \"owser gif editor\n",
      "https://t.co/CWUD0xLmZ4\" => \"ne t  o               ttttttttttt///////\"\n",
      "batch 2984  loss=151.8339  steps/s=103.47  prediction: \"ic cases)\n",
      "dump into claude automatically\" => \"ne  o ccccccccscssssss           aaaaaaa\"\n",
      "batch 2985  loss=122.0496  steps/s=102.42  prediction: \"ark a bit so i felt like writing this up\" => \"nt  et                       iiiiiiiiiii\"\n",
      "batch 2986  loss=126.3398  steps/s=104.19  prediction: \"its bad but, it has pros you can play to\" => \"n   o t                                 \"\n",
      "batch 2987  loss=138.1414  steps/s=105.62  prediction: \" lets you debug your own problems easily\" => \"tiar t t             uu                 \"\n",
      "batch 2988  loss=125.9231  steps/s=105.19  prediction: \"dition, just kpis to optimize right now)\" => \" ni iennnnnnnnnn              iiiiiiiiii\"\n",
      "batch 2990  loss=148.5498  steps/s=105.14  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" m          llllllllll      ttttttttt///\"\n",
      "batch 2991  loss=134.4387  steps/s=105.45  prediction: \" only improve by improving their skills)\" => \"tfe tsn                        iiiiiiiii\"\n",
      "batch 2993  loss=131.5255  steps/s=105.44  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"aereinnnnnnnn                      ttttt\"\n",
      "batch 2994  loss=130.2838  steps/s=105.35  prediction: \" my chess elo to give data that it works\" => \"time           n                   ttttt\"\n",
      "batch 2995  loss=136.9639  steps/s=103.78  prediction: \" Post it in the disc it helps us all out\" => \"toi  oo                                 \"\n",
      "batch 2996  loss=152.3647  steps/s=105.52  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"02 )                     tttttt/////////\"\n",
      "batch 2998  loss=134.6064  steps/s=104.02  prediction: \" (by trusting in ideas) and testing them\" => \"tytte e ttttttt                         \"\n",
      "batch 2999  loss=139.2275  steps/s=102.03  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"epg                      tttttttttt/////\"\n",
      "batch 3000  loss=128.6707  steps/s=100.80  prediction: \"ur enemy when they are making a mistake\"\" => \"s  nrrrreeeeeeeeeeeeeeeeeeee            \"\n",
      "batch 3001  loss=176.9067  steps/s=104.26  prediction: \"ackwards buttons https://t.co/JO2nBFplUJ\" => \"ne  f rrrrrrrrraaaa  ttttttttt//////////\"\n",
      "batch 3003  loss=138.9729  steps/s=104.83  prediction: \"itor as I was with 2 screens and a mouse\" => \"n   a                                   \"\n",
      "batch 3004  loss=159.3811  steps/s=103.65  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"to           !!!!!!!!!!ttttttttttttttt//\"\n",
      "batch 3005  loss=137.4328  steps/s=103.52  prediction: \"\n",
      "\n",
      "pride, however, stops error correction\" => \"\n",
      "o anmetrrrrrreeeeeeeeeeeeerrrrrrrrrrrrr\"\n",
      "batch 3006  loss=148.7707  steps/s=99.24  prediction: \" your own game engine\n",
      "challenge accepted\" => \"aou wri                eeeeeeeeeeeeeeeee\"\n",
      "batch 3007  loss=157.5592  steps/s=104.99  prediction: \"ess while retaining the same information\" => \"   s             eee eeeeeeeeeeee    iii\"\n",
      "batch 3008  loss=154.6426  steps/s=105.64  prediction: \"ood combo for stuff like this, ive found\" => \"rm o \n",
      "o oooooooooooooffff               \"\n",
      "batch 3009  loss=131.0833  steps/s=104.57  prediction: \"ntelligence\" + related learning concepts\" => \" e siooeiiiieeeeeeeeeeeeeeeeeeeeeeennnnn\"\n",
      "batch 3010  loss=124.4254  steps/s=102.80  prediction: \"rough a floppy disk inserted in my brain\" => \"esei  r                                 \"\n",
      "batch 3011  loss=149.8936  steps/s=95.81  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n  o                    tttttttttttt////\"\n",
      "batch 3012  loss=144.7007  steps/s=104.73  prediction: \" group or build 100x stuff and start one\" => \"te f nd                                 \"\n",
      "batch 3014  loss=130.1791  steps/s=95.82  prediction: \"ist either way, its all about production\" => \"n  n  attttiii t            a    at  tto\"\n",
      "batch 3015  loss=154.9713  steps/s=100.83  prediction: \"thy's highlights https://t.co/axnc6zqI4E\" => \"her  e    hhhhhhhhhhhhhhhhttttttttt/////\"\n",
      "batch 3017  loss=158.3373  steps/s=104.90  prediction: \"kers #math #saas https://t.co/99Y0IouvaF\" => \" d  iniiiii######aaaaasssssssssttttt///9\"\n",
      "batch 3018  loss=135.0553  steps/s=104.00  prediction: \"nt properties. huts dont have penthouses\" => \"  oh eeerrrrrreeeeeeeeettttt           e\"\n",
      "batch 3019  loss=190.5213  steps/s=101.44  prediction: \"ARA \"dont talk to me or my retard again\"\" => \"PA@ @AAAAAAAA                           \"\n",
      "batch 3020  loss=132.1177  steps/s=104.95  prediction: \" to recover from if it becomes a problem\" => \"tho o ooooooooo rrrr                    \"\n",
      "batch 3021  loss=128.3182  steps/s=102.38  prediction: \"assume that had a large effect back then\" => \"n                 aaaaaaaaaaa           \"\n",
      "batch 3022  loss=140.4379  steps/s=104.17  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"thi ee                                  \"\n",
      "batch 3023  loss=122.4945  steps/s=103.79  prediction: \"ait to see what you cook up with giz inc\" => \"tn ait                                  \"\n",
      "batch 3024  loss=137.1849  steps/s=103.81  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" e m gnnnnnnnnnennnneeeeeeettttttt//////\"\n",
      "batch 3025  loss=191.3171  steps/s=105.21  prediction: \" @sunsettler 100%\n",
      "\n",
      "TIME AND FREEDOM BABY\" => \"t0aninnnnnnneseeeett\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " EEEEEEEE\"\n",
      "batch 3026  loss=152.8917  steps/s=10.37  prediction: \"reply: @0xVonNeumann Love it! Cheers bro\" => \"eply: @nnnnneeeseet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " EEEEEEEEE\"\n",
      "batch 3027  loss=146.4526  steps/s=120.37  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \"rf                       ttttttt////////\"\n",
      "batch 3028  loss=121.6585  steps/s=103.83  prediction: \"yself infinite runway to build fun stuff\" => \"    e e    iiiiiiiiiiiinn               \"\n",
      "batch 3030  loss=146.9931  steps/s=95.43  prediction: \"Simple p5. Will look into matter though.\" => \" Spreie i iii    ll        l  o    ttttt\"\n",
      "batch 3031  loss=134.4405  steps/s=103.06  prediction: \"was making me sleep deprived unknowingly\" => \"ito  e               eeeeeeeeeeeeeeeeeee\"\n",
      "batch 3032  loss=140.6167  steps/s=100.17  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ng             n             ttttttt////\"\n",
      "batch 3033  loss=126.5266  steps/s=104.98  prediction: \"o make a significant impact on your life\" => \"uI a a         iiiiiiiiiiiiiiii         \"\n",
      "batch 3034  loss=135.2821  steps/s=104.58  prediction: \"eful/true)\n",
      "\n",
      "sometimes thisll take months\" => \" se   sssuuuuuueueeeeeeeeeeeettttttttttt\"\n",
      "batch 3035  loss=134.4711  steps/s=105.14  prediction: \"ll be easy to remember every single move\" => \"yye  lllllll          eeeeeeeeeeeeeeeeee\"\n",
      "batch 3036  loss=142.6058  steps/s=63.72  prediction: \"@yacineMTB so youre no longer locked in?\" => \"pazwieeee          eeeeeeeeeeeeeee  e ee\"\n",
      "batch 3037  loss=148.9375  steps/s=111.37  prediction: \"d it! Lmk how it goes man. Hope it helps\" => \" toe i                                  \"\n",
      "batch 3038  loss=131.8586  steps/s=105.09  prediction: \"an get immense alpha if you keep zooming\" => \"nd ooo         m                        \"\n",
      "batch 3039  loss=134.0935  steps/s=63.02  prediction: \"@JsonBasedman just veto their veto, easy\" => \"spcono  mmmmeeem              e e   eooo\"\n",
      "batch 3040  loss=134.5490  steps/s=110.18  prediction: \"s some cool shit https://t.co/Vo4w9BcSQZ\" => \" yon o  oooooooooo o     ttttttttttttt//\"\n",
      "batch 3041  loss=202.9105  steps/s=99.32  prediction: \"layzXD @ludwigABAP Based\n",
      "Python/zig gang\" => \"ys @p  eellllllllll       BBBBBBPPPPPPoo\"\n",
      "batch 3042  loss=156.2204  steps/s=105.65  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" atdp    ,,,,,,,,     ......    xxxxxxxx\"\n",
      "batch 3043  loss=131.4155  steps/s=103.41  prediction: \"e knows what a kernel or text editor are\" => \" pee                                    \"\n",
      "batch 3044  loss=131.1210  steps/s=105.24  prediction: \"stead of just knowing what they were, Iâ€¦\" => \"  a mveeeee                             \"\n",
      "batch 3045  loss=138.2374  steps/s=104.54  prediction: \"aster i u know its just abt authenticity\" => \"n  tott                          ttttttt\"\n",
      "batch 3046  loss=134.3274  steps/s=104.68  prediction: \"kind of just whatever I want to pivot to\" => \" nn or                                 t\"\n",
      "batch 3047  loss=140.4401  steps/s=105.04  prediction: \"on chunking showed higher level playersâ€¦\" => \"uet  s s             hhhhhhhhhhhheeeeeee\"\n",
      "batch 3048  loss=144.5075  steps/s=73.14  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"u    ononnn    n  hh        e llllllllll\"\n",
      "batch 3049  loss=125.5165  steps/s=106.45  prediction: \"se so i have no idea if this would work)\" => \"  aeeeee                                \"\n",
      "batch 3050  loss=126.1669  steps/s=104.92  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"       oooooooo                       ss\"\n",
      "batch 3051  loss=133.7553  steps/s=104.73  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \" t a          ww                        \"\n",
      "batch 3052  loss=153.9133  steps/s=103.01  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"sl                                      \"\n",
      "batch 3053  loss=147.0768  steps/s=102.63  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"saaco      aaaaaaaaatttttttttttttt//////\"\n",
      "batch 3054  loss=127.9889  steps/s=103.52  prediction: \"e are, so it has a ton of ripple effects\" => \" t f                                    \"\n",
      "batch 3055  loss=131.8502  steps/s=103.60  prediction: \"c too much attention + hasnt been solved\" => \"ar ie           ttttttttttt             \"\n",
      "batch 3056  loss=225.4828  steps/s=87.93  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" so   t               E tttttttn //ooeee\"\n",
      "batch 3057  loss=136.6202  steps/s=97.33  prediction: \"an that sounds like such a relaxing time\" => \"ndin   t   tt t         sss             \"\n",
      "batch 3058  loss=159.0818  steps/s=104.35  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tolts                          hhhhhhhht\"\n",
      "batch 3059  loss=132.9526  steps/s=104.87  prediction: \" only improve by improving their skills)\" => \"tne t                         iiiiiiiiii\"\n",
      "batch 3060  loss=133.5022  steps/s=101.41  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"a ts  onnnnnnnnnnnooooooooiiiiiiiiiiiiia\"\n",
      "batch 3061  loss=130.1998  steps/s=104.56  prediction: \" just need to learn the secret shortcuts\" => \"tud  as                    eeeeeeeeeeeet\"\n",
      "batch 3063  loss=197.4461  steps/s=21.11  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly                      eeeeeeeeeeeettt\"\n",
      "batch 3064  loss=128.4823  steps/s=109.22  prediction: \"he gamer would make for some great games\" => \"e ri                                    \"\n",
      "batch 3065  loss=130.1707  steps/s=101.83  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"e e e eeeeeeeeeteeeeeee     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     \"\n",
      "batch 3066  loss=125.4617  steps/s=103.62  prediction: \"entation, the cooler everything will get\" => \" gtt otttttttttttttoooeeeeeeeeeeeeeeeeee\"\n",
      "batch 3067  loss=213.0380  steps/s=98.78  prediction: \"H LETS GOOOOO\n",
      "truly a masterpiece lmaooo\" => \"aa  et HHHHHH OOOOOOOOOO    rr       eee\"\n",
      "batch 3068  loss=134.4415  steps/s=100.77  prediction: \"error signals, weakening backpropagation\" => \" seeeeeeeerrrrrrrr    ennnnnnnnkkaaaaaaa\"\n",
      "batch 3069  loss=161.7471  steps/s=103.23  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"t.\n",
      "oot //////////ttttttttttt////////////\"\n",
      "batch 3070  loss=134.9633  steps/s=103.26  prediction: \"complete projects than 20 half done ones\" => \"on s         eeeeeeeeett                \"\n",
      "batch 3071  loss=146.7239  steps/s=104.72  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"/..cicpttt/////////ttCCCtt//////////////\"\n",
      "batch 3072  loss=179.6415  steps/s=100.92  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"hps// r      ////////H/HHHHHH......ppppp\"\n",
      "batch 3073  loss=136.7227  steps/s=101.63  prediction: \"ust linux mints built in text editor lol\" => \"s ig           t      iiiii      ttttttt\"\n",
      "batch 3074  loss=131.7229  steps/s=104.23  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"e lyin@aattttttttttttttttttttsnnnnnnnnnn\"\n",
      "batch 3075  loss=152.0547  steps/s=104.10  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.Woo tt////tttttttttttttttttt/////////c\"\n",
      "batch 3076  loss=144.4461  steps/s=101.63  prediction: \" end of the task off worked for you too?\" => \"t dtdeeetee                 fffff    ooo\"\n",
      "batch 3077  loss=150.2111  steps/s=99.66  prediction: \"enly distributed https://t.co/NSTgQS2KiE\" => \"  it        ttt tttttttttttttttttttt////\"\n",
      "batch 3078  loss=132.8375  steps/s=104.78  prediction: \"sfully improved their lives tremendously\" => \"   te  essssssss eeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 3079  loss=134.8671  steps/s=103.68  prediction: \"reason...\"\n",
      "Had this actually happen once\" => \"epl          ..........aaaaaaaaaaaaaaaaa\"\n",
      "batch 3080  loss=201.6818  steps/s=101.81  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"tLal             LLLLLLDDEEEEEEETTTTTT  \"\n",
      "batch 3081  loss=150.5863  steps/s=102.73  prediction: \"ng an os in zig\n",
      "\n",
      "schizo giz arc when????\" => \"g  e  i iii        iiiiiizzzzzzzzz      \"\n",
      "batch 3082  loss=141.7496  steps/s=104.51  prediction: \"d first..still a bit cloudy but got theâ€¦\" => \" tha           t                        \"\n",
      "batch 3083  loss=140.0271  steps/s=100.48  prediction: \"at fits wins, go https://t.co/vqzlbzWGd4\" => \"nh  h  ttttt   t        tttttttttttttttt\"\n",
      "batch 3084  loss=135.6114  steps/s=106.43  prediction: \"ant use it for what i need to work on :(\" => \"nd  e                                   \"\n",
      "batch 3085  loss=127.0663  steps/s=98.11  prediction: \"eadphones dead gonna recharge real quick\" => \" r he eeeeeeeeeedddddnnnn    e rrrrrrrrr\"\n",
      "batch 3086  loss=158.9780  steps/s=98.77  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "trer                                   \"\n",
      "batch 3087  loss=161.5980  steps/s=104.35  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"eply           nnnnnnnnnttttttttttttt///\"\n",
      "batch 3088  loss=131.5555  steps/s=104.86  prediction: \"his, and even then you might get mislead\" => \"et pto                                  \"\n",
      "batch 3089  loss=136.0953  steps/s=103.17  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"nd  i nn    iiiiiiiiii          tttt////\"\n",
      "batch 3090  loss=143.2811  steps/s=74.97  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"n aa  iiiaaiiiii         s  ///oo/oooBBB\"\n",
      "batch 3091  loss=131.4210  steps/s=105.53  prediction: \"ty programming that in, its over, robotâ€¦\" => \"h   t  tiiiiiiiiiiiiiiiiiiii            \"\n",
      "batch 3092  loss=131.2296  steps/s=101.22  prediction: \"eaply making synthetic training data? :)\" => \" ro  @             nn     ttnnniiiiiiiii\"\n",
      "batch 3093  loss=143.5497  steps/s=102.31  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"n  r                        eeeeeeeeeeee\"\n",
      "batch 3094  loss=129.0029  steps/s=103.91  prediction: \"started begging me to let him pay for it\" => \" al          ggggggggggg                \"\n",
      "batch 3095  loss=173.6180  steps/s=74.36  prediction: \"@liljuuliet this https://t.co/MmuaB56dUP\" => \"seapne  eeggggggg t    tt               \"\n",
      "batch 3096  loss=133.8186  steps/s=117.22  prediction: \"oo much context switching to twitter idk\" => \" l  a              ttttttttttttttttttttt\"\n",
      "batch 3097  loss=127.9612  steps/s=100.34  prediction: \" it seems like a fire worth playing with\" => \"tt eteeeeeeeeeetee                      \"\n",
      "batch 3099  loss=154.4411  steps/s=94.63  prediction: \"ellessen Last time was ~6:20am cali time\" => \" y e @eeeleeesssss              aaa  iii\"\n",
      "batch 3100  loss=125.5074  steps/s=104.35  prediction: \"lots of stuff you learn way way way more\" => \"yk @do         f fff                yyyy\"\n",
      "batch 3101  loss=127.0635  steps/s=102.24  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"  e          oo  oooooooooohh      sssss\"\n",
      "batch 3102  loss=130.4707  steps/s=93.18  prediction: \"MTB theyre in the arena, fighting things\" => \"TB @      eeeeee eee  e    a a a      hh\"\n",
      "batch 3103  loss=123.5550  steps/s=28.90  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @ hereeeeeeh eee  e    a a        hi\"\n",
      "batch 3104  loss=165.7718  steps/s=83.35  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @ aeeeeeeeeee   e  a               iðŸ›‘\"\n",
      "batch 3105  loss=128.5301  steps/s=112.59  prediction: \"mals have uncanny valley detection genes\" => \"and e             aaaaaaaaaaaaaeeeeeeeee\"\n",
      "batch 3106  loss=187.0553  steps/s=104.29  prediction: \"t, learning lot.\n",
      "https://t.co/zdN159Agt6\" => \"     ii         llllllttttttttttttt/t///\"\n",
      "batch 3107  loss=126.4534  steps/s=98.78  prediction: \" of the tier lists of all time, for sure\" => \"tf                                      \"\n",
      "batch 3108  loss=130.6001  steps/s=104.09  prediction: \"nserve the good parts against decay/loss\" => \"   o ea                         aaaaaaaa\"\n",
      "batch 3109  loss=132.2327  steps/s=103.42  prediction: \"tal clarity and less of a need for sleep\" => \" ns    eeeeee  n                        \"\n",
      "batch 3110  loss=140.7809  steps/s=75.34  prediction: \"oppflightkid That could be helpful yeah!\" => \"n et ellllllla t                e   eeee\"\n",
      "batch 3111  loss=134.7886  steps/s=104.90  prediction: \"ing vidya except w only positive effects\" => \"ng  eiiiiiiiiiii                      ee\"\n",
      "batch 3113  loss=131.7262  steps/s=104.15  prediction: \" random people you dont really know well\" => \"tem k   .           oooooooo           l\"\n",
      "batch 3114  loss=148.4884  steps/s=101.09  prediction: \"he making a dingboard clone or something\" => \"e  iggg                              ooo\"\n",
      "batch 3115  loss=126.8105  steps/s=101.26  prediction: \"hem better bc you can do engine analysis\" => \"e s yt ttttttttt                     nnn\"\n",
      "batch 3116  loss=128.1642  steps/s=109.61  prediction: \"hange your brain. something to think abt\" => \"en   o        rrrrrrr                   \"\n",
      "batch 3117  loss=143.9449  steps/s=103.23  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"re in              tttttttttttttttt/////\"\n",
      "batch 3118  loss=136.5667  steps/s=103.75  prediction: \"is fine and expected, giving up is death\" => \"n  neeee          eeeeeeeeee            \"\n",
      "batch 3119  loss=135.0560  steps/s=102.11  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"ts e                     tttttttttt/////\"\n",
      "batch 3120  loss=132.0420  steps/s=103.70  prediction: \"stead of just knowing what they were, Iâ€¦\" => \" aevm eeeee                             \"\n",
      "batch 3121  loss=129.9407  steps/s=104.10  prediction: \" can instantly runit w the runit command\" => \"to  e           nnnnnnn                 \"\n",
      "batch 3122  loss=130.6244  steps/s=104.48  prediction: \" on bookmarks from people similar to you\" => \"tf  d     booooooooooooooooooo          \"\n",
      "batch 3123  loss=129.1601  steps/s=105.04  prediction: \"house? where is your phone charger? etc)\" => \"ere yo                                re\"\n",
      "batch 3124  loss=142.3384  steps/s=104.60  prediction: \"d virus that makes ppl cracked at scale?\" => \" w                                  aaaa\"\n",
      "batch 3125  loss=133.2550  steps/s=103.68  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"t    m mmmmmmmm         eeeeeeeeeeeeeeee\"\n",
      "batch 3126  loss=132.1097  steps/s=104.63  prediction: \"ite complexity? If not, what is the max?\" => \"n ini iiiiiiiiiiii                      \"\n",
      "batch 3127  loss=134.4492  steps/s=96.07  prediction: \" What are your personal long term games?\" => \"tinl illlaaaaa                          \"\n",
      "batch 3128  loss=136.9745  steps/s=100.86  prediction: \"ernet becomes, say, 100x more addictive?\" => \"  the  eeeeeeeeeeeeeeee                 \"\n",
      "batch 3129  loss=128.4391  steps/s=103.99  prediction: \"robably dont ask 'will you be my mentor'\" => \"emo                                     \"\n",
      "batch 3130  loss=155.8017  steps/s=30.29  prediction: \"ply: @pixqc @ludwigABAP i like it\n",
      "boolin\" => \"ly: @le ooo                             \"\n",
      "batch 3131  loss=134.7530  steps/s=110.61  prediction: \": @Noahpinion lack of speed/growth kills\" => \" @oawlo ooo  ood           l        o   \"\n",
      "batch 3132  loss=127.7562  steps/s=107.33  prediction: \"best ways to improve for stuff like this\" => \"u   o                           ffffffff\"\n",
      "batch 3133  loss=194.1232  steps/s=97.13  prediction: \"@___________11hz helped me out with mine\" => \"srooho_________________11111_           \"\n",
      "batch 3134  loss=177.9873  steps/s=99.35  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \" no o o                  hhhtt//t///////\"\n",
      "batch 3135  loss=130.1930  steps/s=105.42  prediction: \"usually good metrics, good feedback, etc\" => \" t t                   oooooooooooo     \"\n",
      "batch 3136  loss=125.6003  steps/s=10.68  prediction: \"reply: @opaeoh ill lyk when i open it up\" => \"e lil          ll      oooooooooooo     \"\n",
      "batch 3137  loss=137.8898  steps/s=113.98  prediction: \" strategy of perception?\n",
      "Dang thats cool\" => \"ttuu              eeeeeeeeeeeeeetttttttt\"\n",
      "batch 3138  loss=129.8657  steps/s=101.76  prediction: \"ely definitely worth messing around with\" => \" yninneiiiiiiiiiiiiiieeeeeeee           \"\n",
      "batch 3139  loss=157.8976  steps/s=59.94  prediction: \" @brianf3rnandez @crungulism Like 20mins\" => \"tyui iiiiiininneeee   eeenn            i\"\n",
      "batch 3140  loss=124.3719  steps/s=112.54  prediction: \"atedro buildin something ppl want lesgoo\" => \"r erefeeennndnn ddd   n ini  i        nn\"\n",
      "batch 3141  loss=140.9794  steps/s=106.08  prediction: \"e thing, not just messing around with it\" => \" t at ttttttttt                         \"\n",
      "batch 3142  loss=163.0926  steps/s=99.91  prediction: \"minds me of this https://t.co/bGCVZbuoNU\" => \"antt in                    tttttt///////\"\n",
      "batch 3143  loss=127.7296  steps/s=100.31  prediction: \"eed you on my side during the robot wars\" => \"     ooooonn   n                        \"\n",
      "batch 3144  loss=136.0405  steps/s=105.55  prediction: \"verything app\n",
      "may take like a decade tho\" => \"i e eeeeeeeeeeete      aaa       aaa    \"\n",
      "batch 3145  loss=126.7449  steps/s=21.26  prediction: \"eply: @BuxdahMo its not the real discord\" => \" ly:  eeeeeeeee     a   aa    a  aa     \"\n",
      "batch 3146  loss=160.1536  steps/s=127.65  prediction: \"e77 build things people want/ need maybe\" => \" _oy @eiiiii   ii                eeeeeee\"\n",
      "batch 3147  loss=142.2188  steps/s=101.19  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lc: @e m                          aaaaaa\"\n",
      "batch 3148  loss=129.1901  steps/s=100.04  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \"nbooo o               ddd               \"\n",
      "batch 3149  loss=148.2579  steps/s=102.07  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"e eo eeeeeeeeeeeeeeeeoooopttttt/////////\"\n",
      "batch 3150  loss=129.4990  steps/s=64.40  prediction: \"@IterIntellectus have you brrrytt today?\" => \"aldneeeeeeeeeeeleett   ottto/////tttttjj\"\n",
      "batch 3151  loss=234.7917  steps/s=113.79  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"o\n",
      "eeeeIIIIII           ///////////ttGGGG\"\n",
      "batch 3152  loss=147.7166  steps/s=102.73  prediction: \"employees) do half the work in a company\" => \" o   ooooo ooooo                        \"\n",
      "batch 3153  loss=128.7511  steps/s=105.75  prediction: \"this is the same as the place where theâ€¦\" => \"hi                               eeeeeee\"\n",
      "batch 3154  loss=132.5328  steps/s=30.18  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly:              s             eeeeeeeee\"\n",
      "batch 3155  loss=146.4814  steps/s=129.97  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \" mi: @   ee   e e   tttttttttttttttttt//\"\n",
      "batch 3156  loss=126.7592  steps/s=103.91  prediction: \"assume that had a large effect back then\" => \"ns o              aaaaaaaaaaa           \"\n",
      "batch 3157  loss=140.8351  steps/s=103.61  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \" riec   tttttttttttt eeeeeeeee          \"\n",
      "batch 3158  loss=137.5407  steps/s=105.80  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" .o as .......                          \"\n",
      "batch 3159  loss=133.3253  steps/s=85.47  prediction: \"kul07 Time limits on tasks are so useful\" => \"e s u .kk  u    iii  i           sss ess\"\n",
      "batch 3160  loss=128.1569  steps/s=105.21  prediction: \" try to figure out why your brain worksâ€¦\" => \"th t t         t                     rrr\"\n",
      "batch 3161  loss=127.7125  steps/s=106.15  prediction: \" linux like it hallucinated csgo or doom\" => \"ted aalllllllll lllllllllliiii          \"\n",
      "batch 3162  loss=133.0074  steps/s=104.16  prediction: \"this. or you can win by trading seats wâ€¦\" => \" e                                      \"\n",
      "batch 3163  loss=146.8128  steps/s=105.14  prediction: \"t habit of reaching for my phone is gone\" => \"hi     tttttttt                         \"\n",
      "batch 3164  loss=127.5701  steps/s=101.86  prediction: \"ely definitely worth messing around with\" => \" yninnieiiiiiiieeeeeeeeeeeeeee          \"\n",
      "batch 3165  loss=164.7576  steps/s=99.52  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"enly: @        t                r       \"\n",
      "batch 3166  loss=136.9432  steps/s=98.53  prediction: \"ollowed you on li\n",
      "my lichess is @dnbt777\" => \"n ohoooooooooooooooo                    \"\n",
      "batch 3167  loss=170.4193  steps/s=105.93  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"aCnaaiiiiiiiiiiiii@@7777777777          \"\n",
      "batch 3168  loss=143.5108  steps/s=104.67  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"@oek a                     tttttt///////\"\n",
      "batch 3169  loss=142.5574  steps/s=101.76  prediction: \"ding up the drive thru for 1000 episodes\" => \" v  e                             000000\"\n",
      "batch 3170  loss=136.2778  steps/s=102.85  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"lle @m  ppppp              eeeeeeee     \"\n",
      "batch 3171  loss=130.0348  steps/s=103.83  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "reyn s                                 \"\n",
      "batch 3172  loss=130.8052  steps/s=46.84  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \"  @ as                  tt              \"\n",
      "batch 3173  loss=127.9324  steps/s=121.07  prediction: \"im gonna read the whole library of babel\" => \"ne e  tteeee                e           \"\n",
      "batch 3174  loss=137.2558  steps/s=98.92  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"@tettin        n                        \"\n",
      "batch 3175  loss=136.9486  steps/s=103.50  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"npy  e                                  \"\n",
      "batch 3176  loss=121.8601  steps/s=100.96  prediction: \"companies spend that much cash on a logo\" => \"hmps seeeeeeeeene                       \"\n",
      "batch 3177  loss=137.8417  steps/s=104.26  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  lo     rrrrrrrrreeeeeeeeeeooooooooool\"\n",
      "batch 3178  loss=130.1149  steps/s=102.50  prediction: \"interested to hear how well it works our\" => \"n  n           eeeeeeeeeee              \"\n",
      "batch 3179  loss=126.3162  steps/s=98.64  prediction: \"ly using the word prior kinda wrong here\" => \"y:                             rrrrrrr  \"\n",
      "batch 3180  loss=133.6630  steps/s=105.01  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng\n",
      "e                                    \"\n",
      "batch 3181  loss=132.3031  steps/s=102.69  prediction: \"learn lean just so i can make lean jokes\" => \"y  i           l                        \"\n",
      "batch 3182  loss=128.5575  steps/s=102.00  prediction: \"onster company\n",
      "i believe you could do it\" => \"re g e         m      eeeeeeeeeee       \"\n",
      "batch 3183  loss=128.4385  steps/s=105.82  prediction: \"d luck to step on worms and they stopped\" => \" i             t                        \"\n",
      "batch 3184  loss=124.1010  steps/s=104.58  prediction: \"ffect has it had on you? im very curious\" => \"    e                                   \"\n",
      "batch 3185  loss=130.6799  steps/s=101.56  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"o     onnnnnnnnnnooooooooooiiiiiiiiiiiia\"\n",
      "batch 3186  loss=131.9216  steps/s=105.11  prediction: \"has any non-json, ask for json in prompt\" => \"et  o.          nnnnnnnnn               \"\n",
      "batch 3187  loss=146.5324  steps/s=104.32  prediction: \"losoft and make the circle tool yourself\" => \"yc ieooooooo                            \"\n",
      "batch 3188  loss=166.1056  steps/s=106.18  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"orddt\n",
      "urwwwwwww             tt//////////\"\n",
      "batch 3189  loss=131.6344  steps/s=45.62  prediction: \"y: @Wooltard my llm tools are faster now\" => \": @newroowww           sssss///////ttttt\"\n",
      "batch 3190  loss=144.1015  steps/s=110.45  prediction: \"ficantly off lol https://t.co/SgwnmEaXdF\" => \" n t tiiiiiiiii  f          ttttttt/////\"\n",
      "batch 3191  loss=169.0738  steps/s=97.56  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \"AP iiii                     tSSSSSEEEEEE\"\n",
      "batch 3192  loss=230.1363  steps/s=98.32  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"g iBeraaaaa          IIIII          ISSS\"\n",
      "batch 3193  loss=130.2174  steps/s=100.24  prediction: \"e or desire to practice for other things\" => \"rjto t                                  \"\n",
      "batch 3194  loss=133.1529  steps/s=106.24  prediction: \"like a really really interesting project\" => \"yc  eeeeeeee  l llllllllllllllllleeeeeee\"\n",
      "batch 3195  loss=135.0673  steps/s=103.35  prediction: \"e tbh\n",
      "My projects arent that big yet tho\" => \" ce  eeeeeeeeeeeeeeeeeeeettttttttttttttt\"\n",
      "batch 3196  loss=120.0790  steps/s=53.01  prediction: \": @yacineMTB jak creep is a real problem\" => \" @txn eeeeeeeMee   eeeeet tt  t   t  ttt\"\n",
      "batch 3197  loss=141.3383  steps/s=115.11  prediction: \"h i dont remember getting much out of it\" => \"eideed         eeeeeeeeeeeeeeeeee       \"\n",
      "batch 3198  loss=134.7048  steps/s=98.11  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"@eri ie  eeeeeeb  ettttttttttttttttt  tt\"\n",
      "batch 3199  loss=130.4184  steps/s=105.16  prediction: \"re much lower on time than your opponent\" => \"e oo                                oooo\"\n",
      "batch 3200  loss=134.4529  steps/s=11.75  prediction: \"reply: @graffioh HA thats really awesome\" => \"e oo                               ooooo\"\n",
      "batch 3201  loss=172.5110  steps/s=111.93  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \"hho T              tttttttttttttttttt///\"\n",
      "batch 3202  loss=144.4921  steps/s=74.77  prediction: \"paeoh do it man!! making games is so fun\" => \"ln  @m aa        ttttttttttt//////ssssis\"\n",
      "batch 3203  loss=156.6552  steps/s=105.86  prediction: \"kers #math #saas https://t.co/99Y0IouvaF\" => \"e   idi##########aaaaaaassssssssttttt999\"\n",
      "batch 3204  loss=180.0625  steps/s=102.24  prediction: \"luffyb Xorswap, what a username, love it\" => \"yd @ 00011     s              aaaaaa    \"\n",
      "batch 3205  loss=205.4268  steps/s=103.77  prediction: \"ST BACKPROPAGATE https://t.co/eFVShlRgdK\" => \"TMT T SUU     AAAAAAAAAAA        ///////\"\n",
      "batch 3206  loss=154.1293  steps/s=103.33  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"@ude           n             ///////////\"\n",
      "batch 3207  loss=158.7254  steps/s=101.27  prediction: \"z and ctrl+y now https://t.co/1AII6b45hG\" => \"moe zo                 tttttttttt///////\"\n",
      "batch 3208  loss=140.7917  steps/s=97.45  prediction: \"ke getting flashbanged by your teammates\" => \"e 0 rtiiiiiiiii     gg                  \"\n",
      "batch 3209  loss=136.0169  steps/s=104.39  prediction: \"ace to both physical and mental reality.\" => \"ni pos                           aaaaaaa\"\n",
      "batch 3210  loss=148.8913  steps/s=104.78  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"599)0                    ttttttttttttt//\"\n",
      "batch 3211  loss=139.8303  steps/s=105.97  prediction: \"oger @sunsettler @tunient baller name xD\" => \"ret   ooouuotttetttttttttttttttttetllell\"\n",
      "batch 3212  loss=145.9467  steps/s=105.31  prediction: \"/t.co/emubOEhMKJ https://t.co/Fxx5eUVcPp\" => \"/.dc tttttt////////ttttt///////////////x\"\n",
      "batch 3213  loss=156.4968  steps/s=57.96  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"ttdt ct///////ehhhhhttt///tt//////xxxxxx\"\n",
      "batch 3214  loss=133.0929  steps/s=109.46  prediction: \"w up wherever decision making is present\" => \"hst d             eeeeeeeeeeeiiiiiiiiiii\"\n",
      "batch 3215  loss=128.1517  steps/s=95.26  prediction: \"s Chat with your cat in the hat on a mat\" => \" on   wwwwww                            \"\n",
      "batch 3216  loss=129.9288  steps/s=104.22  prediction: \"doing stuff their mind doesnt want to do\" => \"e o            n                        \"\n",
      "batch 3217  loss=128.1046  steps/s=101.55  prediction: \"i have a few libraries in there sadly :9\" => \"npsnaa aaaaaaa                   eeeeee \"\n",
      "batch 3218  loss=131.6885  steps/s=103.69  prediction: \"ep/useful and you become Christian again\" => \" ly  eeeeeeeeeenee                      \"\n",
      "batch 3219  loss=155.0939  steps/s=101.08  prediction: \" useful stuff to save hrs of your day ig\" => \"iss  uNuuuuuuuuuffffff                  \"\n",
      "batch 3220  loss=132.4779  steps/s=102.78  prediction: \"mer.js to make it cost $0. took too long\" => \"e s m  rrrrrr  r                  oooooo\"\n",
      "batch 3221  loss=191.7085  steps/s=101.82  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \"Tmpre      IIIIIIIIINNN                 \"\n",
      "batch 3222  loss=133.6660  steps/s=104.83  prediction: \"e right things really really does matter\" => \" iite  t ttttt              llllllllllll\"\n",
      "batch 3223  loss=137.1105  steps/s=102.60  prediction: \"times and pick up new details every timâ€¦\" => \"ho k  e                           eeeeee\"\n",
      "batch 3224  loss=125.9417  steps/s=81.17  prediction: \"ryvyo no ffmpeg itd be too slow id think\" => \"e ay: @        p               ee      i\"\n",
      "batch 3225  loss=129.4309  steps/s=72.06  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tB0y           p                      ii\"\n",
      "batch 3226  loss=142.0079  steps/s=113.83  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"tori iii     teetttttttttttttttttttttt//\"\n",
      "batch 3227  loss=136.0346  steps/s=101.84  prediction: \"king one open rn just cause of this post\" => \" nf riaaaa      nnnnnnn                 \"\n",
      "batch 3228  loss=132.5984  steps/s=21.85  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @aa    n n nnnn                    \"\n",
      "batch 3229  loss=154.5357  steps/s=108.33  prediction: \"ood combo for stuff like this, ive found\" => \"um o \n",
      "o ooooooooooooo ff                \"\n",
      "batch 3230  loss=146.6429  steps/s=94.09  prediction: \"a @teodor_io teo mercy killed anime pfps\" => \"ng oa  oooooooooooo           iii   ii e\"\n",
      "batch 3232  loss=136.2197  steps/s=80.11  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  me @eiiiiiiid  ddddd dd  d       oo   \"\n",
      "batch 3234  loss=135.4040  steps/s=106.68  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "e n isuuuuuuuuutttttt                  \"\n",
      "batch 3235  loss=130.1551  steps/s=104.94  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"                        iooooooooooooooo\"\n",
      "batch 3236  loss=129.6517  steps/s=105.52  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tfingn i       n                        \"\n",
      "batch 3237  loss=129.1155  steps/s=103.30  prediction: \"ning arc, off in a remote cave somewhere\" => \"dtn   i                               ee\"\n",
      "batch 3238  loss=139.6606  steps/s=52.43  prediction: \": @yacineMTB better start skilling up ig\" => \" @drhdiiiiin                      eeeeee\"\n",
      "batch 3239  loss=126.4317  steps/s=106.91  prediction: \" ive had programming in a long long time\" => \"ts  e                            nnggggn\"\n",
      "batch 3240  loss=130.3840  steps/s=106.20  prediction: \"hing that could ruin their brand idk tho\" => \"es  a e        t                        \"\n",
      "batch 3241  loss=142.6757  steps/s=100.79  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y  es sssssssssssssssssssssttt//////////\"\n",
      "batch 3243  loss=130.6369  steps/s=103.74  prediction: \"nts of time. its like skilling up almost\" => \" h  e e                      iiiiiiillll\"\n",
      "batch 3245  loss=145.1453  steps/s=103.14  prediction: \"t lately\n",
      "\n",
      "Your RPA loop is pretty useful\" => \"hsn hil lllllll l                       \"\n",
      "batch 3246  loss=129.6178  steps/s=105.69  prediction: \"and completely unknown to the other half\" => \"nd o     lllllllllll   nnnnnnn          \"\n",
      "batch 3247  loss=120.8327  steps/s=95.96  prediction: \"metimes you gotta take one for the cause\" => \"e e alommmmoy   oottt tt ttt            \"\n",
      "batch 3250  loss=137.3116  steps/s=104.69  prediction: \"up computing 'why' for free all the time\" => \"s    a                                  \"\n",
      "batch 3251  loss=127.2712  steps/s=106.13  prediction: \"d will be free. so far, thats everything\" => \" rg i nn                                \"\n",
      "batch 3252  loss=246.2258  steps/s=100.10  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"aoie i         !!!!!!!!!!!!\n",
      "\n",
      "           \"\n",
      "batch 3253  loss=150.3900  steps/s=103.64  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"t.Kesss/////////ttttttttttttt/////////tt\"\n",
      "batch 3254  loss=127.2392  steps/s=105.51  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hie tg aaaaa        nntttttttttttttttttt\"\n",
      "batch 3255  loss=127.4953  steps/s=105.13  prediction: \" some but its not easy to put into words\" => \"tee s          n                     ttt\"\n",
      "batch 3256  loss=131.1296  steps/s=105.36  prediction: \"ing already paved paths is the only wayâ€¦\" => \"n  t                aaaaaaa             \"\n",
      "batch 3257  loss=198.2692  steps/s=39.53  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: i              aapppaa               \"\n",
      "batch 3259  loss=136.4094  steps/s=108.20  prediction: \"n run on my laptop, which I can do w ML?\" => \" tr H                                   \"\n",
      "batch 3260  loss=145.6912  steps/s=103.15  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"ld o                   ttttttttt////////\"\n",
      "batch 3261  loss=134.5156  steps/s=106.06  prediction: \" to call in the big guns (aka @gizmobly)\" => \"tha            l                        \"\n",
      "batch 3262  loss=127.5029  steps/s=102.19  prediction: \"sts w good content from this perspective\" => \"  e   s       ooooooooooooo            t\"\n",
      "batch 3263  loss=128.5656  steps/s=105.33  prediction: \"nd me tracks and ill render them for you\" => \"   o                                    \"\n",
      "batch 3264  loss=135.6342  steps/s=103.93  prediction: \"ool\n",
      "\n",
      "Maybe youll be the dude to crack it\" => \"  oh o oooooooooooo                     \"\n",
      "batch 3265  loss=136.7684  steps/s=104.82  prediction: \" lets you debug your own problems easily\" => \"toer t                                  \"\n",
      "batch 3266  loss=133.8862  steps/s=103.88  prediction: \"imative vehicle for personal development\" => \"ne ni iiiiiiiiiiiii   eeeeee   eeeeeeeee\"\n",
      "batch 3267  loss=129.9215  steps/s=103.36  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e e ot               tttttttttttttttt///\"\n",
      "batch 3268  loss=138.8234  steps/s=103.15  prediction: \"them depth wise, learning â€œon demandâ€ (â€¦\" => \" ealc e                ee          nnnnn\"\n",
      "batch 3269  loss=132.3651  steps/s=104.38  prediction: \"f scummy people getting more money/power\" => \" t h ee            eeeeeeeeeee eeeeeeeee\"\n",
      "batch 3270  loss=148.7352  steps/s=60.24  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"tSe          ee eeeee       mmmeee ooeee\"\n",
      "batch 3271  loss=130.3802  steps/s=106.57  prediction: \"his, and even then you might get mislead\" => \"ev eoo                                  \"\n",
      "batch 3272  loss=137.2807  steps/s=103.36  prediction: \"y clip of polnareff LBJing up the stairs\" => \"ot B h                                  \"\n",
      "batch 3273  loss=219.4498  steps/s=97.36  prediction: \"1 AAAAAA MY EYES https://t.co/r2a6f3Rhs7\" => \" @r atiAAAAAAAAAAA           tttt///////\"\n",
      "batch 3274  loss=131.8931  steps/s=102.51  prediction: \" a lot of chess is abt how to think less\" => \"tno  o                                  \"\n",
      "batch 3275  loss=159.5928  steps/s=103.27  prediction: \" ITTTTTTTTTTTTT\n",
      "\n",
      "https://t.co/7uhSNn1VI6\" => \"t eyT\n",
      "TTTTTTTTTTTTTTTT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/////////\"\n",
      "batch 3276  loss=161.1006  steps/s=102.82  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"toet                           hhhhhhhht\"\n",
      "batch 3277  loss=127.8201  steps/s=32.76  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @o                        hhhhh  ttt\"\n",
      "batch 3278  loss=129.1826  steps/s=104.24  prediction: \": @EsotericCofe what are you working on?\" => \" Rt eo              hh           ttt ttt\"\n",
      "batch 3279  loss=135.6016  steps/s=108.13  prediction: \"l release results soonish #buildinpublic\" => \"yft  e\n",
      "  eeeeeeeeeeeesssssssssssssssiiii\"\n",
      "batch 3280  loss=157.8613  steps/s=102.67  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"i k tmaaaaaauu n  oonooooeeeeeee\"\"\"\"\"\"\"\"\"\n",
      "batch 3281  loss=141.1945  steps/s=100.35  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" d y @aaaaaaaaawwwwlllllllllllllllllliii\"\n",
      "batch 3282  loss=136.6350  steps/s=103.96  prediction: \"tournaments, etc\n",
      "https://t.co/JA1SHygLtH\" => \"h  ny na aatttttttttttttttttttttttttttt/\"\n",
      "batch 3284  loss=133.9924  steps/s=105.91  prediction: \" the game loop in zig, rendering in cuda\" => \"th t           t                    iiii\"\n",
      "batch 3285  loss=158.1695  steps/s=86.89  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yi t  ee                    hh  ii iiddd\"\n",
      "batch 3286  loss=135.6031  steps/s=74.06  prediction: \"rrawnyy cool ass wasm cube bro\n",
      "\n",
      "followed\" => \"eily: @e   ooooooaa a   h         r\n",
      "\n",
      "\n",
      "dd\"\n",
      "batch 3287  loss=137.1845  steps/s=48.95  prediction: \"ly: @sujantkumarkv Will do man will do ðŸ’ª\" => \"y: @  a  aooooaaaaa         b    \n",
      "\n",
      "\n",
      "o\n",
      "dðŸ›‘\"\n",
      "batch 3288  loss=149.6395  steps/s=113.00  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \"h sa eeeeeeeeeeeeettttttttttttttttttt///\"\n",
      "batch 3289  loss=129.9443  steps/s=104.89  prediction: \"s large of a positive impact as possible\" => \" Ine aaaa                            sss\"\n",
      "batch 3290  loss=133.1370  steps/s=104.66  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng ia iiii       dddddddddddddd         \"\n",
      "batch 3292  loss=154.5886  steps/s=101.33  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" t a i                   ttttttttcccccFF\"\n",
      "batch 3293  loss=146.2371  steps/s=100.62  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"em st       aaaaaaaaaaaaatt/////////////\"\n",
      "batch 3294  loss=130.5417  steps/s=102.37  prediction: \"ge\n",
      "how to generate it is the question...\" => \"  e st aaaaa   neeeeeeeee               \"\n",
      "batch 3295  loss=145.4934  steps/s=104.06  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" hn                  ttttttttttttttttt//\"\n",
      "batch 3296  loss=144.7954  steps/s=85.91  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"igABdd    o       ttttttttt//////////VVV\"\n",
      "batch 3297  loss=148.9872  steps/s=105.99  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"/..cssstt/////////tttttttttt//////////tt\"\n",
      "batch 3298  loss=128.8442  steps/s=99.10  prediction: \"ne was right the rates arent high enough\" => \"gx ottiaaaaaaaa             tt  thhh  hh\"\n",
      "batch 3299  loss=136.7212  steps/s=104.10  prediction: \"enjoyable is such a gargantuan advantage\" => \" di  @hggg                 aaaaaaaaaaaaa\"\n",
      "batch 3300  loss=122.4230  steps/s=100.77  prediction: \"almost as bad as jan blocking his bishop\" => \"liyellllllllsss  aaaaaaa                \"\n",
      "batch 3301  loss=146.9688  steps/s=97.56  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"   om mi                 sttstsssstttt//\"\n",
      "batch 3302  loss=132.8860  steps/s=104.00  prediction: \" instead of main https://t.co/K187NvFlSA\" => \"@s  esssss               ttttttttttttt//\"\n",
      "batch 3303  loss=131.9009  steps/s=105.49  prediction: \"whereas, its easy to tell which is timeâ€¦\" => \"iis  \"\n",
      " ttttteeesssssss                 \"\n",
      "batch 3304  loss=182.4683  steps/s=30.53  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly:  e\n",
      "eettttesesssttss                 \"\n",
      "batch 3305  loss=132.1670  steps/s=112.32  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"    e                ttttttttttttttttttt\"\n",
      "batch 3306  loss=144.1500  steps/s=101.30  prediction: \" windows update almost bricked my laptop\" => \"th i d         d                        \"\n",
      "batch 3307  loss=135.3058  steps/s=106.84  prediction: \"robably easier/quicker ways to learn tho\" => \"esn e  rrrrreeeeeeeeeeeeeeeee           \"\n",
      "batch 3309  loss=139.0243  steps/s=101.50  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"ts a  i                   tttttttt//////\"\n",
      "batch 3310  loss=112.9624  steps/s=11.32  prediction: \"reply: @calbch its the year of the monad\" => \"eple:          l          ttttttt///////\"\n",
      "batch 3311  loss=133.0716  steps/s=107.50  prediction: \"e walking through a memory palace maybe)\" => \" d  e  l                           aaaaa\"\n",
      "batch 3312  loss=134.8816  steps/s=100.71  prediction: \"lped me too yrs ago. very inspiring dude\" => \"yl @oeeeeeeeeeee                        \"\n",
      "batch 3313  loss=135.5152  steps/s=10.90  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"eply: @eeeeeeeee                        \"\n",
      "batch 3314  loss=186.4295  steps/s=51.36  prediction: \"reply: @gizmobly https://t.co/Lz4uSVD7Gv\" => \"eply: @eeeeeeeee                        \"\n",
      "batch 3315  loss=146.4487  steps/s=113.02  prediction: \"s a crazy valuable source of improvement\" => \" ovluaaaaaaaaaaaaaaaaaa                 \"\n",
      "batch 3316  loss=132.4442  steps/s=105.66  prediction: \"k checked him out, followed, thanks mate\" => \" tg \n",
      " \n",
      "\n",
      "       k          oooooooo      \"\n",
      "batch 3317  loss=149.8407  steps/s=98.59  prediction: \" stuff! Thanks, hope yours went well man\" => \"tueto ooo                               \"\n",
      "batch 3318  loss=132.8905  steps/s=105.15  prediction: \"the behavior, forming a habit eventually\" => \"he  egeeeeeeee n                        \"\n",
      "batch 3319  loss=131.8453  steps/s=105.50  prediction: \"erscores the importance of curating andâ€¦\" => \" el eeeeeeeeeeeeeeeeeeeee               \"\n",
      "batch 3320  loss=129.8063  steps/s=104.29  prediction: \"mages looked smoother so it did that lol\" => \"ent it         t oooooooooooooo         \"\n",
      "batch 3321  loss=130.5918  steps/s=104.82  prediction: \"ting your axioms can bring immense alpha\" => \"hot ereaaaaaaaaaaaaaa                   \"\n",
      "batch 3322  loss=134.1801  steps/s=101.37  prediction: \"hts move away from the edge of the board\" => \"etee                                    \"\n",
      "batch 3324  loss=172.6377  steps/s=103.42  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"lanaaiiiiiiiii_______7777777777         \"\n",
      "batch 3325  loss=133.9096  steps/s=104.18  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \"  hean     iiiiiiiiiiiitttttttttttttt///\"\n",
      "batch 3326  loss=131.2773  steps/s=104.13  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hot     eeeeeeeteeeeeeeeeeeeeeee      nn\"\n",
      "batch 3327  loss=138.9600  steps/s=103.20  prediction: \"times and pick up new details every timâ€¦\" => \"ho e  o        n                   eeeee\"\n",
      "batch 3328  loss=129.1596  steps/s=106.06  prediction: \"ting your axioms can bring immense alpha\" => \"hot ereaaaaaaaaaaaaaa                   \"\n",
      "batch 3329  loss=192.1134  steps/s=102.27  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \" t\n",
      "t //ooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sssiiiiieeeeeeeeeeeeee\"\n",
      "batch 3330  loss=153.4558  steps/s=101.95  prediction: \"n.. animate it bros. that's 60fps almost\" => \"g rter .......           ttttttt        \"\n",
      "batch 3331  loss=129.6243  steps/s=104.85  prediction: \"s w java and python and studying for fun\" => \" artta                         nnn      \"\n",
      "batch 3332  loss=124.3060  steps/s=97.31  prediction: \"chat is this what sweat equity means????\" => \"oet   aa       t            tttt        \"\n",
      "batch 3333  loss=145.6209  steps/s=99.74  prediction: \"ers @iliekcomputers is a p strong player\" => \" saii          leeeeeiii                \"\n",
      "batch 3334  loss=129.8174  steps/s=105.40  prediction: \"s Chat with your cat in the hat on a mat\" => \" t et liiiiiii                          \"\n",
      "batch 3335  loss=131.0571  steps/s=101.72  prediction: \"ve you been unlocking yourself each time\" => \"er ooi         n     nnnnnnnnn   e     e\"\n",
      "batch 3336  loss=177.4271  steps/s=104.57  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"/..oeuh:t////////tttttttttttt/////////tt\"\n",
      "batch 3337  loss=136.7611  steps/s=104.75  prediction: \"ible w lots of work??? Sign me tf up NOW\" => \"ne  a                   ????????        \"\n",
      "batch 3338  loss=130.0883  steps/s=104.93  prediction: \"see at once that this is really so, andâ€¦\" => \" nee                                    \"\n",
      "batch 3339  loss=128.1723  steps/s=104.76  prediction: \"you really need to make your own company\" => \"ou w aaaaaaa                            \"\n",
      "batch 3340  loss=131.1626  steps/s=104.45  prediction: \"d its helped man. i shpuld sleep too lol\" => \" iha\n",
      "                                  l\"\n",
      "batch 3341  loss=132.7896  steps/s=93.03  prediction: \"cle77 arabian mate is a similar good one\" => \"oel yti  ee  aaaaaaaa                ooo\"\n",
      "batch 3342  loss=132.9442  steps/s=104.76  prediction: \"urself, if you can manage to pull it off\" => \" sele l                                 \"\n",
      "batch 3343  loss=133.2451  steps/s=104.26  prediction: \"seconds to go to jail and ruin your life\" => \" r re          t                        \"\n",
      "batch 3344  loss=130.5792  steps/s=104.64  prediction: \"he gamer would make for some great games\" => \"e  e n                                  \"\n",
      "batch 3345  loss=131.8078  steps/s=106.09  prediction: \"has any non-json, ask for json in prompt\" => \"et sn.          nnnnnnnnn               \"\n",
      "batch 3346  loss=126.1063  steps/s=104.39  prediction: \" you have a podcast on in the bg or smth\" => \"toa                                     \"\n",
      "batch 3347  loss=116.7336  steps/s=97.84  prediction: \"you should do sidetweets with the aliens\" => \":u su suu   ooouoodddddddddeettttttttttt\"\n",
      "batch 3348  loss=131.9442  steps/s=102.47  prediction: \" possible, at least quote and add a take\" => \"tree  sssssssss ll                  aaaa\"\n",
      "batch 3349  loss=126.2222  steps/s=104.49  prediction: \"s of lib arts classes they make you take\" => \" w seeeeeee        sssssssssss          \"\n",
      "batch 3350  loss=140.8954  steps/s=104.59  prediction: \"ed, its worth at least giving a shot tho\" => \"  e                                     \"\n",
      "batch 3351  loss=220.7490  steps/s=99.28  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"alh  s   TTTTTTTTTTTAAOO       tt///////\"\n",
      "batch 3352  loss=133.2517  steps/s=100.15  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n       ssssss s                        \"\n",
      "batch 3353  loss=132.7615  steps/s=104.73  prediction: \"n while still being consistent each week\" => \" thr  a                  iiiiiinnnnnneee\"\n",
      "batch 3354  loss=146.8947  steps/s=102.55  prediction: \" be cool to find some other players here\" => \"tau o oooooooooooooo                   e\"\n",
      "batch 3355  loss=142.2244  steps/s=104.01  prediction: \"rf spatial in problem solving efficiency\" => \"e oem taaaaaaaa aa                 iiiii\"\n",
      "batch 3357  loss=127.8606  steps/s=104.93  prediction: \" the time. personally i havent done this\" => \"the            t                        \"\n",
      "batch 3358  loss=196.7069  steps/s=25.98  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly:           e  ee l                  \"\n",
      "batch 3359  loss=136.6068  steps/s=110.99  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"y  edu               tttttttttttttt/////\"\n",
      "batch 3360  loss=143.8672  steps/s=104.80  prediction: \"uff like explore exploit basically daily\" => \"nfitfuffffff     eeeeeeeeeeeeeelllllllll\"\n",
      "batch 3361  loss=135.5839  steps/s=103.91  prediction: \"I figure if we just do it, ppl will join\" => \" iuddbiiiiiiiii                         \"\n",
      "batch 3363  loss=139.2834  steps/s=105.46  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"h i  as                        eeeeeeeee\"\n",
      "batch 3364  loss=159.1392  steps/s=103.67  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"g eteteeeeeeeeeeeeedddddddddddaaaaaaaaaa\"\n",
      "batch 3365  loss=150.5209  steps/s=104.57  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \"aro  sooooooooo            tt//////////t\"\n",
      "batch 3366  loss=151.7210  steps/s=99.94  prediction: \"z and ctrl+y now https://t.co/1AII6b45hG\" => \"mt oe       +++++       ttttttttt/////II\"\n",
      "batch 3367  loss=152.1972  steps/s=59.56  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"tBr   ccccccc             tt////IIIIIIII\"\n",
      "batch 3368  loss=135.9550  steps/s=116.52  prediction: \"eadphones dead gonna recharge real quick\" => \" r   @eeeeeeeeee dddd       a    na aa r\"\n",
      "batch 3371  loss=140.6205  steps/s=101.28  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" doo @             ttttttttttttttttt///V\"\n",
      "batch 3372  loss=132.3854  steps/s=101.74  prediction: \"nt get too random with high stakes stuff\" => \"   era a       t                        \"\n",
      "batch 3373  loss=140.3114  steps/s=102.56  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"at  o  ttttttoooooooooooooooossssssuuuuu\"\n",
      "batch 3374  loss=130.5052  steps/s=102.75  prediction: \"eres so little time to things in the day\" => \"   eeeeee      t tttttttttttttttt       \"\n",
      "batch 3375  loss=134.2969  steps/s=104.27  prediction: \"cept\n",
      "High levelâ€¦ https://t.co/NZUDp7sGkN\" => \"onpr ico                  ttttttttttttt/\"\n",
      "batch 3376  loss=129.7240  steps/s=102.01  prediction: \" if I decide to read em ill do a summary\" => \"tn ee                                   \"\n",
      "batch 3377  loss=137.8004  steps/s=96.23  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \"oe  oo oooooo  o    o   oooooo  oooooooo\"\n",
      "batch 3378  loss=132.3877  steps/s=102.81  prediction: \"l ideas\n",
      "\n",
      "say if youre trying to learn ML\" => \"yi eeeeeeeeeeeel         yyyyy          \"\n",
      "batch 3379  loss=161.1255  steps/s=102.86  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"to           !!!!!!!!!!tttttttttttttt///\"\n",
      "batch 3380  loss=155.1451  steps/s=104.16  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \" nt i  lllllllllllllll111100000???????? \"\n",
      "batch 3381  loss=156.6810  steps/s=70.15  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"uvt   ayyy0000p  1ii?   0  llll         \"\n",
      "batch 3382  loss=167.8676  steps/s=106.54  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"ll  @  sssssuuu          tttttttttttt///\"\n",
      "batch 3383  loss=128.1711  steps/s=104.49  prediction: \" she got into medschool after graduating\" => \"ttt                  ooooooooooooo     a\"\n",
      "batch 3384  loss=138.2718  steps/s=103.64  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"ngeele         u                        \"\n",
      "batch 3385  loss=127.6516  steps/s=102.96  prediction: \" distracting any kind of multitasking is\" => \"tooe h                             iiiii\"\n",
      "batch 3386  loss=129.3486  steps/s=98.08  prediction: \"n pick your own time though its flexible\" => \"gte e hc                                \"\n",
      "batch 3387  loss=124.9518  steps/s=79.79  prediction: \"omeik that is super super super cool wtf\" => \" eco   koo             uuu              \"\n",
      "batch 3388  loss=131.5760  steps/s=105.61  prediction: \" for most models\n",
      "https://t.co/US1Fvcybrh\" => \"tou  m  oooooooooooooottttttttttt///////\"\n",
      "batch 3389  loss=134.7478  steps/s=103.09  prediction: \"ol\n",
      "gonna crack one open rn over some ice\" => \"   h t   oooo onoooooooo  nnnnnn        \"\n",
      "batch 3390  loss=147.4178  steps/s=100.42  prediction: \"dgrammer best languages in your opinion?\" => \" e   oammmmmrmmmmrrreeaggggg            \"\n",
      "batch 3391  loss=133.5733  steps/s=101.58  prediction: \"mer.js to make it cost $0. took too long\" => \"e sem  rrrrrr  r                   ooooo\"\n",
      "batch 3392  loss=148.0541  steps/s=99.03  prediction: \"ock your 1000th follower and stay at 999\" => \"   oet         t  00000oooo             \"\n",
      "batch 3393  loss=154.8244  steps/s=101.62  prediction: \"on\n",
      "Also doesnt apple allow emulators now\" => \" m ce\n",
      "i       onoooo     lllllllllllllll\"\n",
      "batch 3394  loss=135.9827  steps/s=101.89  prediction: \"r the ceo and coo\n",
      "\n",
      "17.5hr day today lool\" => \"einf           f     ooooo o           o\"\n",
      "batch 3395  loss=131.9268  steps/s=97.74  prediction: \"ki my highschool teacher taught it to me\" => \"eng t e        ohhhhhhhhhhhhh ttat   ttt\"\n",
      "batch 3396  loss=146.1107  steps/s=105.28  prediction: \"/t.co/bGCVZbuoNU https://t.co/CPaVjqg1AU\" => \"t.cc\n",
      " tt/////////ttttttttttt//////////CV\"\n",
      "batch 3397  loss=134.1424  steps/s=105.04  prediction: \"mped billions/decades into w no solution\" => \"es\n",
      "iems        dddddddddddddd          o\"\n",
      "batch 3398  loss=133.5124  steps/s=104.38  prediction: \"learning models\n",
      "\n",
      "https://t.co/KAmykVYFyw\" => \"ymr nnennnnnnnneneeeeeeeettttt//////////\"\n",
      "batch 3399  loss=138.9306  steps/s=105.23  prediction: \"nts also on the nm level, but, 3d not 2d\" => \"tiou e nnnnnnnonn                       \"\n",
      "batch 3400  loss=157.9208  steps/s=87.43  prediction: \"dup QUICK do something that doesnt scale\" => \" e te o                    tt      t    \"\n",
      "batch 3401  loss=127.7255  steps/s=102.98  prediction: \" sensors lol thats much less complicated\" => \"ttm sssssssssssssssss      sss        cc\"\n",
      "batch 3403  loss=131.5151  steps/s=104.45  prediction: \"ard to realize. lies are really blinding\" => \"ne  oa         a          eeeeeeelllllll\"\n",
      "batch 3405  loss=130.7426  steps/s=104.57  prediction: \"hink about a post before responding lool\" => \"es  e                          ooooooooo\"\n",
      "batch 3406  loss=135.1522  steps/s=105.46  prediction: \"ot good results: https://t.co/KAmykVYFyw\" => \"uh i                    ttttttttttttttt/\"\n",
      "batch 3407  loss=147.6449  steps/s=97.75  prediction: \"en helpful!! ah nice addition, good idea\" => \"  i           ll                     ddd\"\n",
      "batch 3408  loss=139.7813  steps/s=101.10  prediction: \"c ig lisp and haskell are in the 10% lol\" => \"oant  siiiiii  i                        \"\n",
      "batch 3409  loss=135.0398  steps/s=105.45  prediction: \"y fundamentals are hidden in plain sight\" => \"om  aayymmmmmmnnaaaaaaaa                \"\n",
      "batch 3410  loss=142.0527  steps/s=103.40  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyn                                   \"\n",
      "batch 3411  loss=147.8229  steps/s=98.44  prediction: \"nch @yacineMTB let the a b testing BEGIN\" => \" iots n  yyyyyyee   eeee                \"\n",
      "batch 3413  loss=156.8553  steps/s=94.28  prediction: \"t prototype done https://t.co/9pKpWZA02k\" => \" bt, annnnnne  eeettttt   ttttttttt////t\"\n",
      "batch 3414  loss=133.8614  steps/s=103.37  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \"enbnop ooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                         \"\n",
      "batch 3415  loss=129.1627  steps/s=101.10  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"e ly  @kk               ttta   aat  mmmm\"\n",
      "batch 3416  loss=139.3858  steps/s=103.43  prediction: \"ger projects the smaller ones get faster\" => \" ts ioe rrrrrrr               eeeeeeeeee\"\n",
      "batch 3417  loss=143.1472  steps/s=103.48  prediction: \"makes a comeback they get a large reward\" => \"eres                                   e\"\n",
      "batch 3418  loss=132.5616  steps/s=101.17  prediction: \" drag down/demotivate other team members\" => \"@oe  d   ddddddddddddddooooootttttteeeee\"\n",
      "batch 3419  loss=174.7858  steps/s=101.99  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"oneMe   nnnnnnnnnaajjjjjjj  ee   OOOOOOO\"\n",
      "batch 3420  loss=163.8758  steps/s=94.64  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \" g  e  cccaannn00000   aa               \"\n",
      "batch 3421  loss=132.9757  steps/s=103.19  prediction: \"re. it can only get 103 on snake though.\" => \"eply   e                                \"\n",
      "batch 3422  loss=137.2296  steps/s=104.17  prediction: \"ern of multiplied KPIs pop up semi-often\" => \"  io         tt            ppppppppppp  \"\n",
      "batch 3423  loss=195.3281  steps/s=30.35  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly:   t   ttttt   tt    ppppppppppp     \"\n",
      "batch 3424  loss=139.0288  steps/s=109.74  prediction: \" of just doing what fundamentally worked\" => \"tnrttta                           aaaaaa\"\n",
      "batch 3425  loss=139.0459  steps/s=104.96  prediction: \"l, titan, stable diffusion, a few others\" => \"y  e r        tatttttttt iiii           \"\n",
      "batch 3426  loss=137.4999  steps/s=104.41  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" -oat;ttttttttt ttssssssssssssssssssssss\"\n",
      "batch 3427  loss=134.5847  steps/s=104.06  prediction: \"oast. silencio until youve made progress\" => \"u   tt         s  iiiiiiii              \"\n",
      "batch 3428  loss=150.3764  steps/s=102.03  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"a RiPlo    oollollll             uu    u\"\n",
      "batch 3430  loss=150.6174  steps/s=98.69  prediction: \"s if you do both\n",
      "https://t.co/EXEA72MrEm\" => \" oht                    tttttttttt//////\"\n",
      "batch 3431  loss=127.0529  steps/s=59.75  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"tIet            hhh ottttttt//////ttEEEE\"\n",
      "batch 3433  loss=155.5220  steps/s=118.51  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \" S iene eeee         tt        E EEEEAEE\"\n",
      "batch 3434  loss=148.2731  steps/s=101.37  prediction: \"s man. i try to keep it real as they say\" => \" ip   a        t                        \"\n",
      "batch 3435  loss=149.2872  steps/s=104.42  prediction: \"orking feels a bit more stale without it\" => \"ue eeeeeeeeeeeeee                       \"\n",
      "batch 3436  loss=119.6865  steps/s=44.86  prediction: \"y: @andyduboc genius concept for a piece\" => \": @aeneeeeeee                         tt\"\n",
      "batch 3437  loss=144.3511  steps/s=107.81  prediction: \"darin and english which they are meh at)\" => \" le ep      nnn nnnnnnn    hhhhhhhhhhhh \"\n",
      "batch 3438  loss=126.6600  steps/s=102.25  prediction: \"her level abstraction of piece movements\" => \"as  aa       eereeee                eeee\"\n",
      "batch 3439  loss=148.2630  steps/s=99.87  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" d   @          tttttttttttttttttttt////\"\n",
      "batch 3440  loss=149.1924  steps/s=103.45  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \" mpeererrrrrrrr r  aaaaaaaa aaaaaaa     \"\n",
      "batch 3441  loss=142.2342  steps/s=104.86  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"  s /t://///////hhhhhttttttt////////////\"\n",
      "batch 3443  loss=132.7917  steps/s=103.22  prediction: \"so i havent used anything like webgl yet\" => \"  s  ssss                             ee\"\n",
      "batch 3444  loss=129.4717  steps/s=105.43  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"t     lllllllll  a   aaaaaaa            \"\n",
      "batch 3445  loss=128.5757  steps/s=105.62  prediction: \"ar mongering gets attention (clicks etc)\" => \"tee  e eeeeeeeeeeeeeeeeeettttttttttttttt\"\n",
      "batch 3446  loss=129.0387  steps/s=102.49  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \"gal e           aaaaaaaaaaaaaahhhhhheeee\"\n",
      "batch 3447  loss=228.8173  steps/s=91.85  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"g iat aa          hhttttttttttttee    ee\"\n",
      "batch 3448  loss=144.8540  steps/s=104.88  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"tn t in7       n                        \"\n",
      "batch 3449  loss=127.8067  steps/s=104.41  prediction: \" that is not working out for some reason\" => \"th e h                        oooooooooo\"\n",
      "batch 3450  loss=167.7178  steps/s=96.88  prediction: \"eos Oh I know :) https://t.co/aV1q8nmIEk\" => \" dih @ii                    tttttt//////\"\n",
      "batch 3453  loss=128.7781  steps/s=102.25  prediction: \"y laptop and hope the bits line up right\" => \":@  aa                                  \"\n",
      "batch 3454  loss=134.3302  steps/s=105.16  prediction: \" I didnt post AT ALL til it was 98% done\" => \"t  k                                    \"\n",
      "batch 3455  loss=175.6686  steps/s=46.66  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \": @ e                                   \"\n",
      "batch 3456  loss=167.6029  steps/s=116.67  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu cll g                   7/////t//////\"\n",
      "batch 3457  loss=132.0450  steps/s=105.40  prediction: \" to recover from if it becomes a problem\" => \"thr o oooooooor rrrr                    \"\n",
      "batch 3459  loss=131.3498  steps/s=103.44  prediction: \" new meta\n",
      "dont think too hard about that\" => \"tot k           tttttttttttt           t\"\n",
      "batch 3460  loss=130.3164  steps/s=104.11  prediction: \"ces for speed and it makes the game wild\" => \"h ss i c   eeeeeeeee                    \"\n",
      "batch 3461  loss=120.8910  steps/s=44.51  prediction: \"y: @sunsettler write a will just in case\" => \"  @acscs eeeeeee  e                     \"\n",
      "batch 3462  loss=129.8550  steps/s=113.76  prediction: \"error signals, weakening backpropagation\" => \" seneeeerrrrrrr rr    nnnnnnnnnnnaaaaaaa\"\n",
      "batch 3463  loss=129.6656  steps/s=104.96  prediction: \"re much lower on time than your opponent\" => \"e oe                                 ooo\"\n",
      "batch 3464  loss=128.5653  steps/s=99.99  prediction: \"gonna code to one song and one song only\" => \" ne m             ooooooo  nnnnnnnnnnnnn\"\n",
      "batch 3465  loss=155.4151  steps/s=105.61  prediction: \"vars} complexity (O(f(n)) type stuff)\n",
      "-â€¦\" => \"eryoer  eeeeeeeeeee     (((((((((( )))))\"\n",
      "batch 3466  loss=133.2990  steps/s=101.87  prediction: \"ate? i mean i can guess, but.. nice work\" => \"t so t         c                        \"\n",
      "batch 3467  loss=121.8029  steps/s=99.91  prediction: \" of the tier lists of all time, for sure\" => \"tf e                                    \"\n",
      "batch 3468  loss=127.4297  steps/s=102.32  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e o at               hhhttttttttt///////\"\n",
      "batch 3469  loss=196.6618  steps/s=99.61  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"t  ao                ttttttttt//////////\"\n",
      "batch 3470  loss=155.1206  steps/s=91.66  prediction: \"UBalis welcome to circle tool gang, king\" => \"lTDoh             ttttttttccccttoooooool\"\n",
      "batch 3471  loss=130.9559  steps/s=104.38  prediction: \", thank God we can function at all loool\" => \" soe e                                  \"\n",
      "batch 3473  loss=138.6941  steps/s=104.19  prediction: \"2 and 3 forever\n",
      "\n",
      "https://t.co/4TGEKmEHO0\" => \"1g rr                 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttttt/////\"\n",
      "batch 3475  loss=133.1323  steps/s=103.50  prediction: \"ut you neeeeeed execution skill yourself\" => \"t  rrrrrrrreeeeeeeeeeeeeeeeeeeee        \"\n",
      "batch 3476  loss=134.7815  steps/s=104.57  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng e                                    \"\n",
      "batch 3477  loss=138.1836  steps/s=105.28  prediction: \"son but thats OK https://t.co/f85X6nDeZy\" => \"   aer              ttttttttttttttt/////\"\n",
      "batch 3479  loss=123.6448  steps/s=103.91  prediction: \"uscle and you get better as you practice\" => \"teirt                                   \"\n",
      "batch 3480  loss=135.2337  steps/s=103.89  prediction: \"ks never knows\n",
      "Or... something like that\" => \"e o o       kkkkkknnnno............     \"\n",
      "batch 3481  loss=146.1593  steps/s=90.58  prediction: \"eMTB How long until dingbots can do this\" => \" Tr   ceennnooo  o.  nnn  nni   nn      \"\n",
      "batch 3482  loss=141.9278  steps/s=101.31  prediction: \" have been goin up too. Things are movin\" => \"tao                                     \"\n",
      "batch 3483  loss=136.2717  steps/s=103.95  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  t t                      llllllllllll\"\n",
      "batch 3484  loss=134.4202  steps/s=104.94  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"eao                  nnnnnnnnnniiiiiuttt\"\n",
      "batch 3485  loss=144.1407  steps/s=95.61  prediction: \"BAP lud the goat herder back at it again\" => \" t w   ddd            t ooeee  e      tt\"\n",
      "batch 3486  loss=130.7153  steps/s=104.89  prediction: \"ust store those. skip the whole ML stuff\" => \"tt t uss          sss                   \"\n",
      "batch 3487  loss=171.7659  steps/s=98.98  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"ts              tttttttttttttttt/////   \"\n",
      "batch 3488  loss=152.0421  steps/s=104.95  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \": @nas yyyyyyyy               iiiiiiiiii\"\n",
      "batch 3489  loss=172.2601  steps/s=103.79  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lcs @  sssssuuu          tttttttttt/////\"\n",
      "batch 3490  loss=133.1037  steps/s=103.75  prediction: \"res a reason they dont but i dont see it\" => \"eply: eeeeeeeeeeee                      \"\n",
      "batch 3491  loss=128.5402  steps/s=104.71  prediction: \"en clusters into single tokens like this\" => \" t  e eeeeeeeeet                        \"\n",
      "batch 3492  loss=127.7818  steps/s=105.31  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"n e          oooooooooooohhhhhaaaaasssss\"\n",
      "batch 3493  loss=135.6544  steps/s=98.56  prediction: \", even my llm is on 3 cups of coffee bro\" => \" mhe  e                                 \"\n",
      "batch 3494  loss=153.2461  steps/s=99.44  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"nma i iiiii             ssssstsoost/////\"\n",
      "batch 3495  loss=170.1281  steps/s=99.83  prediction: \"e huge win, and yeah consistency is king\" => \" f  !!!!gguu                    nnn    n\"\n",
      "batch 3497  loss=127.8623  steps/s=97.22  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" eh g       nnnn ahaeeeeeeeeeeeeeeeee   \"\n",
      "batch 3498  loss=132.8079  steps/s=100.36  prediction: \"eaply making synthetic training data? :)\" => \" ro  @                      nnnniiiiiitt\"\n",
      "batch 3499  loss=132.5495  steps/s=103.35  prediction: \"ey once, will play otb w friends usually\" => \"                                        \"\n",
      "batch 3500  loss=126.4057  steps/s=105.18  prediction: \"e other side of the conversation is like\" => \" moo                       eeeeeee     i\"\n",
      "batch 3501  loss=145.1349  steps/s=105.09  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" r   t tttttttaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttttttt////\"\n",
      "batch 3503  loss=128.8750  steps/s=104.09  prediction: \"this the more you will see it everywhere\" => \"he  oa         t                  eeeeee\"\n",
      "batch 3504  loss=125.8539  steps/s=104.42  prediction: \"d building things with skills new to you\" => \" an  n       iiiiiiiiiiiiiiiiiii        \"\n",
      "batch 3505  loss=133.3201  steps/s=105.14  prediction: \" is interesting play between those three\" => \"tn  e       eeeteeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 3506  loss=119.7282  steps/s=102.62  prediction: \"ure the first man on mars thats so crazy\" => \"ns ee eeeeeee  t                        \"\n",
      "batch 3507  loss=137.6263  steps/s=104.19  prediction: \"tuff goes for you\n",
      "gpu stuff is super fun\" => \" te e          f       uuuuuuuuuuuuuuuuu\"\n",
      "batch 3508  loss=149.7566  steps/s=104.67  prediction: \" filter out slop https://t.co/RA1wtAYLES\" => \"toi ffffffff          tttttttttttttt////\"\n",
      "batch 3509  loss=153.6264  steps/s=101.08  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" fttt  tttttttt tt   hhhhh              \"\n",
      "batch 3510  loss=117.2961  steps/s=98.00  prediction: \"enisnikulin its the lichess of photoshop\" => \" ght @eteediiiini                      o\"\n",
      "batch 3511  loss=137.4164  steps/s=105.74  prediction: \"l, titan, stable diffusion, a few others\" => \"y  e r       aaaaaaaaat  iiii           \"\n",
      "batch 3512  loss=129.4234  steps/s=105.34  prediction: \"dibly efficient and powerful compression\" => \" tceer    iiiiiiiiiiiiii              ee\"\n",
      "batch 3513  loss=162.6522  steps/s=73.34  prediction: \"owTiedFox 16hrs every day is crazy,  wow\" => \"n c cr iiiiiei        eeee           roo\"\n",
      "batch 3514  loss=139.5194  steps/s=107.17  prediction: \"he stopped existing after the last frame\" => \"epis_d         eeee        eeeee   tt   \"\n",
      "batch 3516  loss=132.8565  steps/s=11.35  prediction: \"reply: @HSVSphere how high agency of you\" => \"epiy: @        eee         eeee    tt   \"\n",
      "batch 3517  loss=127.8582  steps/s=108.71  prediction: \"have become too big and are rotting away\" => \"esm aee eeeeeeemee                      \"\n",
      "batch 3518  loss=149.4313  steps/s=105.21  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "nt g nnnnnnnnennneee                  \"\n",
      "batch 3519  loss=138.8984  steps/s=104.48  prediction: \"n and id 100% recommend it over The Goal\" => \"gi  oodddddddd                          \"\n",
      "batch 3520  loss=140.5533  steps/s=102.60  prediction: \" making anifusion in the first place btw\" => \"ta d           n  iiiiiiiiiiiiii        \"\n",
      "batch 3521  loss=152.3208  steps/s=99.18  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"to iaia                     ttttttt/////\"\n",
      "batch 3522  loss=151.5079  steps/s=103.70  prediction: \"ic cases)\n",
      "dump into claude automatically\" => \"ne  o ecccccccscssssss           aaaaaaa\"\n",
      "batch 3524  loss=148.0520  steps/s=103.38  prediction: \"ame by making his brain care abt it more\" => \"nm o tt        m                        \"\n",
      "batch 3526  loss=139.8513  steps/s=98.60  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"@io                                 oooo\"\n",
      "batch 3527  loss=142.4444  steps/s=102.62  prediction: \" be cool to find some other players here\" => \"@eo o ooooooooooooo                   ee\"\n",
      "batch 3528  loss=152.2252  steps/s=96.77  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"@ou          ff ffffffttttttttttt///////\"\n",
      "batch 3529  loss=171.1071  steps/s=93.04  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"imloAb   eeeeee@ @aajjjjjjjoooooOOOOOOOO\"\n",
      "batch 3530  loss=188.7212  steps/s=98.98  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \" st: @@@@@SS@@@ @@@@@                   \"\n",
      "batch 3531  loss=125.6102  steps/s=11.64  prediction: \"reply: @papyruski @justalexoki elaborate\" => \"eply: @@@SSS@@@ @@@@@                   \"\n",
      "batch 3533  loss=167.3857  steps/s=110.24  prediction: \"load this prompt https://t.co/Ug4apoNeat\" => \"yu  oaoo            ttttttttttttttt/////\"\n",
      "batch 3534  loss=145.9104  steps/s=53.42  prediction: \": @pindjouf @thomasbocquet7 ayyy lets go\" => \" @t.to o   oo  ttttttttttttttt////////tt\"\n",
      "batch 3535  loss=131.7961  steps/s=107.89  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" th      eeeeeee                        \"\n",
      "batch 3536  loss=124.4194  steps/s=103.64  prediction: \"had an eye for it meant maybe its useful\" => \"et tt                                   \"\n",
      "batch 3539  loss=121.9405  steps/s=45.60  prediction: \"ly: @andrew_pynch i think about it a ton\" => \"y:  th                                  \"\n",
      "batch 3540  loss=143.9828  steps/s=110.30  prediction: \"s a crazy valuable source of improvement\" => \" i u aaaaaaaaaaaaaaaaaa                 \"\n",
      "batch 3541  loss=142.9182  steps/s=105.33  prediction: \"ks for me though. Carbs make me sluggish\" => \"  g ee                                  \"\n",
      "batch 3542  loss=131.2417  steps/s=102.91  prediction: \"my efficiency. But overall cause its fun\" => \"e e t       eeeee                       \"\n",
      "batch 3543  loss=134.6348  steps/s=103.01  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r   tttttttttt           rrrrrrrrrrrrrr\"\n",
      "batch 3544  loss=140.6398  steps/s=102.87  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"ta  aii                                 \"\n",
      "batch 3545  loss=167.9091  steps/s=29.72  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: @                                   \"\n",
      "batch 3546  loss=128.0463  steps/s=115.37  prediction: \"e unbelievably interesting and beautiful\" => \" t  n         ebbeeeeeeeeeeeeennnnnnnnnn\"\n",
      "batch 3547  loss=153.0162  steps/s=96.04  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" ee e eeeeeeeeii irrrrrrrrrrrrrrr       \"\n",
      "batch 3548  loss=127.8563  steps/s=104.05  prediction: \"d luck to step on worms and they stopped\" => \" i             t                        \"\n",
      "batch 3550  loss=132.3375  steps/s=97.68  prediction: \"lsio recursive mind exploding adventures\" => \"y e@s lllleeeeeeeeeeeeeee  i eeddddddddd\"\n",
      "batch 3551  loss=141.1969  steps/s=105.20  prediction: \"problems im overlooking, then solve them\" => \"lob  t              ooooooooooooooooo  e\"\n",
      "batch 3552  loss=138.1956  steps/s=100.61  prediction: \"gh Ive been wanting to do a wasm project\" => \"  o  l       eeeeeee nn                 \"\n",
      "batch 3554  loss=130.7227  steps/s=99.82  prediction: \"lsio recursive mind exploding adventures\" => \"y  @seeeeeeeeeeeeieeeeeeeiii  i dddddddd\"\n",
      "batch 3555  loss=130.4473  steps/s=103.50  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \":pi thtttttttttittttttt     s           \"\n",
      "batch 3556  loss=127.4979  steps/s=104.78  prediction: \"setup is going to be a bit different tho\" => \" l    o                                 \"\n",
      "batch 3558  loss=128.4844  steps/s=104.79  prediction: \" the most important parts of improvement\" => \"to t\n",
      "               tttttttttttt       m\"\n",
      "batch 3559  loss=140.9359  steps/s=101.38  prediction: \"tremely good at using ai to build things\" => \" aot  teeeeeeeet                        \"\n",
      "batch 3560  loss=164.3672  steps/s=102.82  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"t  ee          t                       e\"\n",
      "batch 3561  loss=130.4723  steps/s=104.20  prediction: \"people, i just post a weird mix of stuff\" => \"lt: @  oo                               \"\n",
      "batch 3562  loss=132.4273  steps/s=100.02  prediction: \"ate? i mean i can guess, but.. nice work\" => \"t  o s         c                        \"\n",
      "batch 3563  loss=136.6204  steps/s=100.48  prediction: \"l remember the book much better too. ime\" => \"yi  aoooommmmeemeeeeeeeee    e          \"\n",
      "batch 3564  loss=131.7520  steps/s=106.71  prediction: \"t the procedure for doing this is on mac\" => \" sts           r                        \"\n",
      "batch 3566  loss=177.2063  steps/s=104.89  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \" ac  a         t                        \"\n",
      "batch 3567  loss=129.2602  steps/s=103.46  prediction: \"or a site with a manipulatable algorithm\" => \"     o                   aaaaaaaaaaaaaaa\"\n",
      "batch 3568  loss=133.5882  steps/s=104.73  prediction: \"s\n",
      "\n",
      "probably gets more views bc of it tho\" => \" \n",
      "fa naaaaaaaaaaaaaaa                   \"\n",
      "batch 3569  loss=133.5625  steps/s=105.10  prediction: \"e Bible has treasure but you have to dig\" => \" pit  tttt     t                        \"\n",
      "batch 3570  loss=129.9150  steps/s=103.48  prediction: \"to save this for later in case I forget\"\" => \"h   to                                  \"\n",
      "batch 3571  loss=138.1320  steps/s=104.11  prediction: \"' bc thats the name of the 4min mile guy\" => \"re ieee ttttttt tttt                    \"\n",
      "batch 3572  loss=149.8292  steps/s=100.98  prediction: \"y i havent had many problems with it tbh\" => \":t sl                                   \"\n",
      "batch 3573  loss=125.4228  steps/s=50.46  prediction: \"y: @sunsettler gl w luffy tomorrow bro ðŸ«¡\" => \": @sa                                   \"\n",
      "batch 3574  loss=129.7337  steps/s=108.01  prediction: \"and completely unknown to the other half\" => \"nd o      lllllllllll  nnnnnnnn         \"\n",
      "batch 3575  loss=123.7686  steps/s=105.53  prediction: \" will get back to you when this is fixed\" => \"thee e  llll                            \"\n",
      "batch 3576  loss=150.0553  steps/s=100.32  prediction: \"el editor and gameplay, that sounds cool\" => \" la   e        l         aaaaaaaaaaa    \"\n",
      "batch 3577  loss=135.1214  steps/s=55.91  prediction: \"y: @benfleming__ its lifechanging really\" => \": @eeeee            aa  aaaaaaaa     ooo\"\n",
      "batch 3578  loss=131.9517  steps/s=107.89  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e e o                tttttttttttt///////\"\n",
      "batch 3579  loss=138.5710  steps/s=61.86  prediction: \" @0xluffyb unfunded? then do it unfunded\" => \"tmt e  ffffff   nntttttttttt////ttttnnnn\"\n",
      "batch 3580  loss=135.1516  steps/s=107.34  prediction: \" focus/attention to a negative direction\" => \"tort ff     tttttttttttttttttttt        \"\n",
      "batch 3581  loss=128.8577  steps/s=103.96  prediction: \"f a nix rollback could fix their problem\" => \" tmerin                                 \"\n",
      "batch 3582  loss=132.3114  steps/s=102.20  prediction: \"file llm editing stuff is the future imo\" => \" l   illllllllleliiiiiiiiiii            \"\n",
      "batch 3583  loss=140.5970  steps/s=102.34  prediction: \"oo, and the school wasn't even built yet\" => \" tia           t                        \"\n",
      "batch 3584  loss=162.1924  steps/s=102.13  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \" moio o                  ttttttt////////\"\n",
      "batch 3585  loss=128.8098  steps/s=104.70  prediction: \"rally where the word came from, i think)\" => \"ecniit         l                        \"\n",
      "batch 3586  loss=156.4836  steps/s=103.73  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"i r tiaaaaaaeeennnnnneeeeeeeeeeee\"\"\"\"\"\"\"\"\n",
      "batch 3587  loss=131.4344  steps/s=104.25  prediction: \"usually good metrics, good feedback, etc\" => \" t t o  uuu            oooooooooooo     \"\n",
      "batch 3588  loss=139.9021  steps/s=93.43  prediction: \"ssir\n",
      "\n",
      "ill dm you on the 25th with a link\" => \"  ael ssssl   lll                       \"\n",
      "batch 3589  loss=129.1612  steps/s=103.66  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"h ntint     iii iiiiiiiiioooooooooorrrrr\"\n",
      "batch 3590  loss=165.7139  steps/s=104.29  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"  boo k kk          tttttttttttttt//////\"\n",
      "batch 3591  loss=135.8356  steps/s=100.88  prediction: \"ne that sends the html/js/etc files over\" => \"   e eee           ttttttttttttttttt   e\"\n",
      "batch 3592  loss=187.9927  steps/s=105.22  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"   Bo/tt//\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sss//////////\"\n",
      "batch 3593  loss=154.5352  steps/s=101.52  prediction: \"ool challenge. amazing its down to 112mb\" => \" mAs  s        c   aaaaaaaaa a aa   nnn \"\n",
      "batch 3594  loss=136.3639  steps/s=100.12  prediction: \"inful to stfu but it works suuuuper well\" => \"n   t          u  u           uuuuuuuuuu\"\n",
      "batch 3595  loss=128.0478  steps/s=104.45  prediction: \"iterate certain ppl, but those are large\" => \"n\n",
      "  o l     aaatttt        tt           \"\n",
      "batch 3596  loss=126.7121  steps/s=96.48  prediction: \"imated stills have finally been defeated\" => \"ne aoeaaaaaaat ttll      llll   eeeeeeee\"\n",
      "batch 3597  loss=134.6515  steps/s=103.36  prediction: \"makes it an order of magnitude harder...\" => \"are na                               ddd\"\n",
      "batch 3598  loss=191.8297  steps/s=23.15  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly:                               ddddr\"\n",
      "batch 3599  loss=137.9322  steps/s=120.29  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r i  eee               ttttttttttttttts\"\n",
      "batch 3601  loss=129.1951  steps/s=104.07  prediction: \" the ladder on what strats are possible.\" => \"thet                                  ss\"\n",
      "batch 3602  loss=131.0399  steps/s=105.15  prediction: \"compress a lifetime into a few sentences\" => \"ome iise                             eee\"\n",
      "batch 3603  loss=129.9299  steps/s=76.47  prediction: \"ryvyo no ffmpeg itd be too slow id think\" => \"eee e          f e ii                eee\"\n",
      "batch 3604  loss=171.5079  steps/s=40.10  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: @ss          e i                    \"\n",
      "batch 3605  loss=133.3670  steps/s=107.89  prediction: \"etting about them, is a v common mistake\" => \" tat  o      tt ttttt               mmmm\"\n",
      "batch 3606  loss=136.7381  steps/s=102.47  prediction: \" end of chess, just like everyone feared\" => \"txe                sssss     eeeeeeeeeee\"\n",
      "batch 3607  loss=145.2273  steps/s=101.18  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \"  ee     eeeeee e   tttttttttttttttt////\"\n",
      "batch 3608  loss=150.6653  steps/s=98.63  prediction: \"one thing I need https://t.co/2lJdUbXtXP\" => \"  dh thhhh               ttttttttt//////\"\n",
      "batch 3609  loss=153.2410  steps/s=107.83  prediction: \" a day\n",
      "weekdays usually like 9am to 10pm\" => \"@ne  s         yyyaaaaayyyyyllalll      \"\n",
      "batch 3610  loss=125.2883  steps/s=102.20  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"le  s       a  eeeeeeeee                \"\n",
      "batch 3611  loss=121.2651  steps/s=100.45  prediction: \"an esopost to english translator service\" => \"ld r eeeeeee                 ttt  ss   s\"\n",
      "batch 3612  loss=135.9700  steps/s=103.62  prediction: \"ks never knows\n",
      "Or... something like that\" => \"e ncn      kkkkkkkknnnooo...........    \"\n",
      "batch 3613  loss=141.8076  steps/s=103.74  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nl t t         t                        \"\n",
      "batch 3614  loss=178.4759  steps/s=104.89  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"0 6tn/tt//\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sss//////////\"\n",
      "batch 3615  loss=144.2900  steps/s=103.91  prediction: \" like this too? They come in pairs often\" => \"ton o                                   \"\n",
      "batch 3616  loss=123.1376  steps/s=38.78  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @ e                 e                \"\n",
      "batch 3617  loss=138.1513  steps/s=109.61  prediction: \"ind groups of ppl who love what you love\" => \"ng  t                                   \"\n",
      "batch 3618  loss=140.3315  steps/s=104.72  prediction: \"ded something to edit gifs/clips quickly\" => \" ra0  eeeeeeeeeneeeee        t ii   iiii\"\n",
      "batch 3619  loss=129.9901  steps/s=100.88  prediction: \"ind groups of ppl who love what you love\" => \"ne  t                                  o\"\n",
      "batch 3620  loss=131.1776  steps/s=48.05  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"y: @gt                          o   oooo\"\n",
      "batch 3621  loss=143.8962  steps/s=26.51  prediction: \"reply: @ludwigABAP @0xluffyb just be you\" => \"eply  @                         o   oooo\"\n",
      "batch 3622  loss=121.5361  steps/s=48.11  prediction: \"reply: @IterIntellectus no i forgot srry\" => \"eply: @                         o   oooo\"\n",
      "batch 3623  loss=125.6634  steps/s=154.42  prediction: \"@Aryvyo use the api\n",
      "anthropic or bedrock\" => \"lx77irMyryro  ep   p    o o  o oo   oooðŸ›‘\"\n",
      "batch 3624  loss=135.2883  steps/s=107.50  prediction: \" your brain insanely bad in the long run\" => \"tou            r                        \"\n",
      "batch 3625  loss=144.9300  steps/s=96.09  prediction: \" ...but will it work, thats the question\" => \"t u   r ........                     ttt\"\n",
      "batch 3626  loss=139.0833  steps/s=100.30  prediction: \"utput or efficiency alone\n",
      "\n",
      "output^2/cost\" => \"t  u   uuuu                 oooooooooooo\"\n",
      "batch 3627  loss=150.4528  steps/s=102.78  prediction: \"enly distributed https://t.co/NSTgQS2KiE\" => \" ts         ttt ttttttttttttttttttt/////\"\n",
      "batch 3628  loss=152.6694  steps/s=106.12  prediction: \"actually protects me from getting hacked\" => \"niy            t               ttttttt  \"\n",
      "batch 3629  loss=158.8499  steps/s=99.31  prediction: \"JUST POST so i dropped a draft out there\" => \"osyy  s                                 \"\n",
      "batch 3630  loss=164.0202  steps/s=101.22  prediction: \"ein @DrBrianKeating yea he made a portal\" => \" nse @iiiiiiiiiiiiiiiinnneaaaaaaaaaaaaaa\"\n",
      "batch 3631  loss=140.9806  steps/s=99.76  prediction: \"ent in pygame and the network in pytorch\" => \" tneennnnnnnnnn nnnn                    \"\n",
      "batch 3632  loss=142.2905  steps/s=104.07  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"@s w  i                  ttttttttttttttt\"\n",
      "batch 3634  loss=137.5995  steps/s=101.65  prediction: \"he stopped existing after the last frame\" => \"a  s_lnn      eeeeeeeeeeee e            \"\n",
      "batch 3635  loss=124.4902  steps/s=102.90  prediction: \"l possible golden gate bridge existences\" => \"yf ole        l lllll      gggeeeeeeeeee\"\n",
      "batch 3636  loss=131.1641  steps/s=103.62  prediction: \" ppl twist your arm behind your back lol\" => \"trtett tttttt  t                        \"\n",
      "batch 3637  loss=140.4878  steps/s=100.20  prediction: \"its how i learned most of my tech skills\" => \"n  oo                                   \"\n",
      "batch 3638  loss=133.4530  steps/s=102.22  prediction: \", increases both HP and MP significantly\" => \" in  eeeeeeeeeeeee                     n\"\n",
      "batch 3639  loss=178.8975  steps/s=66.95  prediction: \"@startupmillyair https://t.co/c3FxqzjmK3\" => \"aoeqerbreereeee                 iciiiiii\"\n",
      "batch 3640  loss=144.5702  steps/s=106.46  prediction: \"\" and idk what that is? Time to learn it\" => \" aoos\"\"ss                               \"\n",
      "batch 3642  loss=133.3384  steps/s=103.06  prediction: \" into an age with a lot of visual beauty\" => \"tn ee                                   \"\n",
      "batch 3643  loss=131.9934  steps/s=101.43  prediction: \"nkedin phase\n",
      "\n",
      "we'll teach them hopefully\" => \"g to  h  h    eeeeeeeeeeeeeeeeeeeeeeehhh\"\n",
      "batch 3644  loss=135.9029  steps/s=99.63  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n  ii iii      u                        \"\n",
      "batch 3645  loss=137.8421  steps/s=100.51  prediction: \"oodhart that too https://t.co/AKZnb9fRgL\" => \" d  w          tttttttttttttttttttttto//\"\n",
      "batch 3646  loss=128.3496  steps/s=105.62  prediction: \"ong term advantage) you consolidate andâ€¦\" => \" g  ..         n aaaaaaaaa      oooooooo\"\n",
      "batch 3647  loss=138.5165  steps/s=103.97  prediction: \"bly helps that they have a faster ai now\" => \"ey y  bbbbbllllhhhhhhhhhhhh       aaaa  \"\n",
      "batch 3648  loss=130.1211  steps/s=103.51  prediction: \"on\n",
      "\n",
      "im guessing you do that a lot to huh\" => \"ug tat         sssss                    \"\n",
      "batch 3649  loss=138.1036  steps/s=92.30  prediction: \"here zoomer problems, cant relate /shrug\" => \"e   t \n",
      " eeeeee  ooo              ttttt h\"\n",
      "batch 3650  loss=146.0555  steps/s=104.08  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"d ao  r                                 \"\n",
      "batch 3651  loss=147.7679  steps/s=100.23  prediction: \"you so here I am https://t.co/ZHK8egA7Q1\" => \":uoaoo ooooo                  ttt///////\"\n",
      "batch 3652  loss=177.8798  steps/s=103.54  prediction: \"oing the deadline thing\n",
      "Works super well\" => \" n ttt          ddddddddiiiiiiii     eee\"\n",
      "batch 3653  loss=131.7893  steps/s=104.16  prediction: \" what to do next. i want to do my own tâ€¦\" => \"tod                                     \"\n",
      "batch 3654  loss=158.8435  steps/s=101.07  prediction: \" the 16 hour coding session, lets get it\" => \"tonn 7 77                         ssssss\"\n",
      "batch 3655  loss=128.5726  steps/s=104.21  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"tpiegitiiiiiii n       lllllll          \"\n",
      "batch 3656  loss=136.5213  steps/s=99.51  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" oo                       tttttttttt////\"\n",
      "batch 3657  loss=138.9998  steps/s=103.69  prediction: \"sk for, then train them to ask, then act\" => \" ent           t       ttt              \"\n",
      "batch 3658  loss=127.2473  steps/s=103.68  prediction: \"entation, the cooler everything will get\" => \" gt  otttttttttttttoooeeeeeeeeeeeeeeeeee\"\n",
      "batch 3659  loss=152.2873  steps/s=103.07  prediction: \" post your progress as you go through it\" => \"tluoo  ooooooooooooo                    \"\n",
      "batch 3661  loss=204.2251  steps/s=94.52  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/.cctttt/////oopoo Rs sss    ttto////gtg\"\n",
      "batch 3662  loss=123.4061  steps/s=104.44  prediction: \"ounts for new lengths of weeks/months ig\" => \"u wn                           eeeeeeees\"\n",
      "batch 3663  loss=128.0776  steps/s=104.81  prediction: \" sets? that sounds right but im not sure\" => \"tecontstttttttt tttsssss                \"\n",
      "batch 3664  loss=137.8048  steps/s=103.83  prediction: \"pi key and throw it in the settings\n",
      "done\" => \"lnt a                            ttttttt\"\n",
      "batch 3665  loss=134.7062  steps/s=101.51  prediction: \"inful to stfu but it works suuuuper well\" => \"n  i           u  u           uuuuuuuuuu\"\n",
      "batch 3666  loss=131.3488  steps/s=104.52  prediction: \"re. it can only get 103 on snake though.\" => \"eptu  eee                               \"\n",
      "batch 3667  loss=126.0961  steps/s=100.59  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \"et                                      \"\n",
      "batch 3669  loss=135.8260  steps/s=100.45  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"tat u          t          sssssss       \"\n",
      "batch 3670  loss=133.7443  steps/s=103.72  prediction: \"al of life that pays some huge dividends\" => \"nls            f                        \"\n",
      "batch 3671  loss=133.5482  steps/s=95.92  prediction: \"houlda stuck to planting apple trees smh\" => \"et    a        t             ppppppppeee\"\n",
      "batch 3672  loss=165.6738  steps/s=86.35  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"n al           t  ttttttttttttttttt////t\"\n",
      "batch 3673  loss=143.3978  steps/s=104.81  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"d ao ci                                 \"\n",
      "batch 3675  loss=194.4429  steps/s=103.83  prediction: \"needed to dl this. meme delivery service\" => \"d  o                      eeeeeeeeeeeeee\"\n",
      "batch 3676  loss=139.5418  steps/s=60.77  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tM                 eee  e eeeeeeeeeeeeee\"\n",
      "batch 3678  loss=134.1536  steps/s=108.24  prediction: \" through nevada w my dad as a little kid\" => \"thedir         n                        \"\n",
      "batch 3679  loss=153.1940  steps/s=98.61  prediction: \"CMEGroup ayy lets go more monopoly money\" => \"oui  do           y             oooooooo\"\n",
      "batch 3680  loss=128.6705  steps/s=105.09  prediction: \"tw, my b, but ill hop in on the next one\" => \"h  s i                                  \"\n",
      "batch 3681  loss=128.3944  steps/s=105.04  prediction: \" movie theater anywhere\n",
      "\n",
      "or a giant dome\" => \"te   aaaaaaaattttttteeeeeeeeeeeeeeer    \"\n",
      "batch 3682  loss=141.5890  steps/s=105.55  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lo   o      bbbbbbbbbbbbb               \"\n",
      "batch 3683  loss=137.7971  steps/s=101.15  prediction: \"ed to potential feature list, thanks bro\" => \"   u @dddddddddd       eettttttttttttttt\"\n",
      "batch 3684  loss=136.0969  steps/s=103.79  prediction: \"of the network (target, a_output, loss,â€¦\" => \"u ba                 tttttttttttttttttt,\"\n",
      "batch 3685  loss=138.1575  steps/s=104.84  prediction: \"n people imagine\n",
      "https://t.co/ZYfaaoNir7\" => \" aies          eeeeeeeeeeettttttt///////\"\n",
      "batch 3686  loss=129.9209  steps/s=104.48  prediction: \"just have to connect/reconnect the wifi'\" => \"ust th                  ooonncccccccccee\"\n",
      "batch 3687  loss=127.1858  steps/s=103.42  prediction: \"mpeg tho but not if i rely heavily on it\" => \"ore ro                                  \"\n",
      "batch 3688  loss=236.7908  steps/s=102.74  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"ING HOTSSSSSSSSGGGGGGGG       /////////3\"\n",
      "batch 3689  loss=144.3157  steps/s=100.49  prediction: \" a bool so you just become sick again :/\" => \"t           oooo                        \"\n",
      "batch 3690  loss=151.5060  steps/s=101.77  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"n   oa         n                     TTT\"\n",
      "batch 3691  loss=212.2075  steps/s=98.01  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \" G a  .EEEEEEE  RRRRRR         tt///////\"\n",
      "batch 3692  loss=145.2121  steps/s=83.16  prediction: \"edydas @tanayj make one\n",
      "good opportunity\" => \"  .   dd  RR            ttto/o/ooooopppp\"\n",
      "batch 3693  loss=122.4342  steps/s=15.08  prediction: \"reply: @djcows leveraged short positions\" => \"eply: @d  R             tttooooooooopppp\"\n",
      "batch 3694  loss=153.2688  steps/s=123.68  prediction: \"tiquing the zoomers that jump in his dms\" => \" n  oiiiiiiiiiiiii                      \"\n",
      "batch 3695  loss=147.7069  steps/s=104.00  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"/.ccssst/////////ttttttttttt/////////ttt\"\n",
      "batch 3696  loss=136.2132  steps/s=103.30  prediction: \" software used that widely is so awesome\" => \"tui a                                   \"\n",
      "batch 3697  loss=126.5569  steps/s=104.11  prediction: \"e the reward dips down below the average\" => \" ae  eeeeeeeeeeeeeeddddddd  www         \"\n",
      "batch 3698  loss=228.5237  steps/s=96.46  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"BAP t        OOOOOOOOOOOOOO tttttttttttt\"\n",
      "batch 3699  loss=128.2857  steps/s=103.30  prediction: \"got the bit order backwards or something\" => \"    ng                        rrrrrrrrrr\"\n",
      "batch 3700  loss=140.9997  steps/s=103.97  prediction: \" but vanilla obsidian seems very mid imo\" => \"tea weuuuuuuu l llllll                  \"\n",
      "batch 3701  loss=122.5572  steps/s=103.23  prediction: \"aybe I need to grow more tomatoes though\" => \"t e e                        ooooooooooo\"\n",
      "batch 3702  loss=138.0054  steps/s=101.13  prediction: \"ems like you have. thanks for sharing it\" => \" eie ieeeeeeeeeeeeee                    \"\n",
      "batch 3703  loss=134.0341  steps/s=104.63  prediction: \" so I invested my time into that instead\" => \"ttree  oo                          ttttt\"\n",
      "batch 3704  loss=168.5567  steps/s=100.09  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \" zm  no                 tttttttt////////\"\n",
      "batch 3705  loss=122.5415  steps/s=102.55  prediction: \"y noticed the last time i was there, lol\" => \":mzZi  iiiiiiitttt  tttt                \"\n",
      "batch 3706  loss=131.4473  steps/s=104.22  prediction: \"gger stuff, maybe thatll make me faster?\" => \" em tg         g                        \"\n",
      "batch 3707  loss=133.5597  steps/s=102.79  prediction: \"like there's more of a person there, idk\" => \"yteo sllleeeeeeeeeeeee                  \"\n",
      "batch 3708  loss=135.0015  steps/s=104.58  prediction: \"'ll see models get good at outputting it\" => \"so neweeeeeeeeeeeeeeeee              ttt\"\n",
      "batch 3709  loss=124.9879  steps/s=103.78  prediction: \"veryone in the past was a caveman/moron\"\" => \"e  se  eeeeeeeeeee             aaaaaaaaa\"\n",
      "batch 3710  loss=157.6599  steps/s=103.04  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"t.cc tt////////t/ttttttppptt////////////\"\n",
      "batch 3711  loss=142.4812  steps/s=104.68  prediction: \"outworking them\"\n",
      "\n",
      "i remember that often.\" => \"nl  eeeeoooooooo         eeeeeeeeeeeeeee\"\n",
      "batch 3713  loss=146.1864  steps/s=103.65  prediction: \" quality than \"loading bar\" type writing\" => \"tuee  e ttttttt tttt          \"\"\"       \"\n",
      "batch 3715  loss=196.4047  steps/s=39.30  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"  s se  ttttttt    tt  aaa\"\"\"\"\"         \"\n",
      "batch 3716  loss=131.0819  steps/s=110.59  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"eyiy:n@tatttttttttttttttttttssnnnnnnnnnn\"\n",
      "batch 3717  loss=210.6051  steps/s=95.57  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"t.cctttttt///ttnoRRR ttstttttttttntt/yta\"\n",
      "batch 3718  loss=166.4128  steps/s=104.64  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"7A@5A6AA999999111BBBBBBBA33333333333AAAA\"\n",
      "batch 3719  loss=155.4506  steps/s=104.28  prediction: \"know what it is\n",
      "\n",
      "https://t.co/wJ5n1H6JUK\" => \" 6  n              ttttttttttttttttt////\"\n",
      "batch 3720  loss=133.6501  steps/s=98.75  prediction: \"e enlightened than me, i need to wake up\" => \" tee le eeeeeeeeeeeeeeee                \"\n",
      "batch 3721  loss=154.6718  steps/s=66.70  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tBre elleeeeeeeee eee                   \"\n",
      "batch 3722  loss=129.4011  steps/s=107.50  prediction: \"uters. i dont like those tbh. weird shit\" => \"s   a          t                        \"\n",
      "batch 3723  loss=159.2538  steps/s=105.26  prediction: \"/t.co/gufhF6ZVD6 https://t.co/0ldvn5Oi6t\" => \"/..c t ////////////ttttttttt///////////t\"\n",
      "batch 3724  loss=135.0975  steps/s=101.23  prediction: \"elete post but it works on anyone's post\" => \" sletttteeeettet ttttttttt      ooooooon\"\n",
      "batch 3725  loss=134.5173  steps/s=103.86  prediction: \"nd then vcs give u money for some reason\" => \"g  o a         n                        \"\n",
      "batch 3727  loss=131.5910  steps/s=100.46  prediction: \"hess isnt hard just make the right moves\" => \"ere :nssssssssssss                      \"\n",
      "batch 3728  loss=145.9180  steps/s=94.09  prediction: \"ts like how prisoners get JACKED in jail\" => \"   o s i                  e  ee         \"\n",
      "batch 3729  loss=159.8970  steps/s=101.86  prediction: \"cost) is probably a better way to put it\" => \"hml  eeeeetttttibbbbbbbbbbbbb           \"\n",
      "batch 3730  loss=133.5926  steps/s=101.85  prediction: \" figuring it out. it just clicked for me\" => \"@ot fffffff              t   t          \"\n",
      "batch 3731  loss=137.1662  steps/s=105.45  prediction: \"y with any industry/niche and ill run it\" => \":andneyiyyyyyyyyyyyyyyynnnnnnnnnnn      \"\n",
      "batch 3732  loss=127.0384  steps/s=105.45  prediction: \" adding the context into the computation\" => \"inr t\n",
      "                  tttttttttttttttt\"\n",
      "batch 3733  loss=140.7643  steps/s=100.49  prediction: \"in a year, and this was his main opening\" => \"nk  0 00                             iii\"\n",
      "batch 3734  loss=123.2706  steps/s=95.72  prediction: \"re you need to make a sphere version now\" => \"eply: @ e eeee e                  eeeeen\"\n",
      "batch 3735  loss=156.9631  steps/s=106.30  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"to.oe\n",
      "tttttt///////ttttt////////////////\"\n",
      "batch 3736  loss=152.0693  steps/s=60.11  prediction: \" @Yosef_Frost vision: pro\n",
      "execution: slo\" => \"iSe  \n",
      "t///////tthttttpp//:pp////tttttOOO\"\n",
      "batch 3737  loss=136.8940  steps/s=106.72  prediction: \"ible w lots of work??? Sign me tf up NOW\" => \"ns                      ????????        \"\n",
      "batch 3738  loss=138.5718  steps/s=65.57  prediction: \"@nlevnet that's a great thought actually\" => \"lixqaelll      t    ?????               \"\n",
      "batch 3739  loss=139.5823  steps/s=106.88  prediction: \"xample losslessâ€¦ https://t.co/1abTqawnLU\" => \"qpttot o       e sssssssssssssssssstttt/\"\n",
      "batch 3740  loss=122.1997  steps/s=59.78  prediction: \" @startupmillyair lichess or chessdotcom\" => \"tPatot oo  lllllllssssssssssssttt/sssstt\"\n",
      "batch 3741  loss=141.0750  steps/s=123.07  prediction: \"Koala that would be much appreciated, ty\" => \"aE saaaaaaaaaaaaaaa            ccccecccc\"\n",
      "batch 3742  loss=143.1791  steps/s=94.99  prediction: \"Simple p5. Will look into matter though.\" => \"pnEaoaoop     ll ll  ll  l       ttttttt\"\n",
      "batch 3743  loss=137.4909  steps/s=104.06  prediction: \" an extremely powerful idea when applied\" => \"tre  h         t  eeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 3744  loss=123.9396  steps/s=52.74  prediction: \": @teodor_io funny number go up type shi\" => \" @itd s         eeeee  eeeee  e   p pepe\"\n",
      "batch 3745  loss=146.6114  steps/s=116.53  prediction: \"a little weirder https://t.co/dcbD9IdKyf\" => \"nbros i....         t eetttttttttttt////\"\n",
      "batch 3746  loss=162.7998  steps/s=103.34  prediction: \"fects the rest of the day. Cheers brotha\" => \" nhn  t  ffeeeetetttt                   \"\n",
      "batch 3747  loss=150.7259  steps/s=98.99  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"tte te            sssssstttttttttttttt//\"\n",
      "batch 3748  loss=133.6340  steps/s=103.62  prediction: \" never rule things out as impossible tbh\" => \"te esset                          ssssss\"\n",
      "batch 3749  loss=133.4359  steps/s=103.83  prediction: \" instead of main https://t.co/K187NvFlSA\" => \"ts   sssss               ttttttttttttt//\"\n",
      "batch 3750  loss=147.2478  steps/s=74.00  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"u s easa    aa n         ttt//ooo/oooooo\"\n",
      "batch 3751  loss=138.5434  steps/s=28.06  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @an    aai          t   oooooooooll\"\n",
      "batch 3752  loss=122.4006  steps/s=79.99  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly: @ on aaaaaii             oooooooolll\"\n",
      "batch 3753  loss=133.5154  steps/s=135.22  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n BA  iAAA     s                h       \"\n",
      "batch 3754  loss=138.9401  steps/s=101.57  prediction: \"k x's video compression is getting to it\" => \"esw ut                  sssssssssiiiiiii\"\n",
      "batch 3755  loss=150.3163  steps/s=100.77  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"epl : @         aaaaaaaasssstttttttt////\"\n",
      "batch 3756  loss=141.8576  steps/s=104.85  prediction: \"k in college it worked for me super well\" => \"es0 b          l                      ee\"\n",
      "batch 3757  loss=139.0833  steps/s=101.50  prediction: \"worst part, as demonstrated by the graph\" => \" rhB  t ttttt            tttttttttt     \"\n",
      "batch 3758  loss=132.5579  steps/s=103.54  prediction: \" fundamentals.  Take the time to invest.\" => \"to          tt n aaaaaa                 \"\n",
      "batch 3759  loss=141.5510  steps/s=98.86  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tnp  n                   ttttttttttttttt\"\n",
      "batch 3760  loss=138.3325  steps/s=104.63  prediction: \"what's needed to  step out of reactivitâ€¦\" => \"iate sssss     s                       t\"\n",
      "batch 3761  loss=140.6691  steps/s=101.83  prediction: \" making anifusion in the first place btw\" => \"@e t           naiiiiiinnniiiiiiii      \"\n",
      "batch 3762  loss=142.2834  steps/s=104.48  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"te do gggggggggniiiiiiiieeeeeeeeeeeeeeee\"\n",
      "batch 3763  loss=175.4557  steps/s=98.85  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"nm  ler          TTT       TEEEELLLLLLLL\"\n",
      "batch 3764  loss=136.5437  steps/s=104.11  prediction: \" eat. 500cal ea =&gt; 1500 extra cal/day\" => \"tnea                      00000000      \"\n",
      "batch 3765  loss=147.3641  steps/s=58.42  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"t2ea     aa  a    a     000          aaa\"\n",
      "batch 3766  loss=132.4938  steps/s=59.06  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @    ccc  a              e        aaa\"\n",
      "batch 3768  loss=151.5568  steps/s=130.15  prediction: \"dwigABAP Big win, love it, great job man\" => \" i.a  ccciii               ee          ðŸ›‘\"\n",
      "batch 3770  loss=148.6496  steps/s=106.52  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne e  llllllll            ttttttttt/////\"\n",
      "batch 3771  loss=132.3410  steps/s=104.20  prediction: \"mple py script manages building/updating\" => \"aae    ooo pppp ppppppp        iiiiiiiii\"\n",
      "batch 3772  loss=153.9923  steps/s=98.01  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \" lo eple  iii          ttttttt//////////\"\n",
      "batch 3773  loss=132.4898  steps/s=105.02  prediction: \"ill you get better at as you practice it\" => \"nl b                  t                 \"\n",
      "batch 3774  loss=129.9062  steps/s=104.38  prediction: \"d from 15 relevant studies in 10 seconds\" => \" boum m        r        e               \"\n",
      "batch 3775  loss=175.2055  steps/s=99.08  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \"2@a1  uuuuuuuuuuuuuuuu e                \"\n",
      "batch 3776  loss=139.5747  steps/s=104.73  prediction: \" approximate it better outcompete others\" => \"tbl a u        t   tttttttttttttttttttte\"\n",
      "batch 3777  loss=126.4539  steps/s=103.40  prediction: \"or a site with a manipulatable algorithm\" => \"     o                   aaaaaaaaaaaaaaa\"\n",
      "batch 3778  loss=142.0872  steps/s=102.18  prediction: \"very instructive zig raylib example/code\" => \"e t            t iiiiiiiiiiiiiiiii     e\"\n",
      "batch 3779  loss=134.0951  steps/s=88.67  prediction: \"ucoder Any cracked accts you wanna list?\" => \"re,vre  rrrrrcr     ccccccc          aaa\"\n",
      "batch 3780  loss=130.5742  steps/s=104.98  prediction: \"we need shape rotator models already smh\" => \"a n e    eeeeeeneeeeeeeeeeeeoooo  e     \"\n",
      "batch 3781  loss=133.3135  steps/s=104.37  prediction: \" is interesting play between those three\" => \"tt  e       eeeteeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 3782  loss=143.2036  steps/s=100.00  prediction: \"azy like that. Cheers my English brother\" => \"ns T e                                  \"\n",
      "batch 3783  loss=131.5062  steps/s=105.67  prediction: \"avorite password what would it be?? haha\" => \"ne o o                  wwwwwwww        \"\n",
      "batch 3785  loss=134.3716  steps/s=104.70  prediction: \" it as we speak) https://t.co/oTdseynD5s\" => \"tn t tii                   ttttttt//////\"\n",
      "batch 3786  loss=123.7382  steps/s=29.80  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @i                   stttttt///////s\"\n",
      "batch 3787  loss=137.2325  steps/s=121.02  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \"or y  e ee               tttttt/////////\"\n",
      "batch 3788  loss=146.5717  steps/s=86.04  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"eply: @        nhhh t   t   /       sssl\"\n",
      "batch 3789  loss=137.4763  steps/s=105.95  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"@e eee eeeeeeeele                       \"\n",
      "batch 3790  loss=169.5505  steps/s=104.28  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"nssn                  ttttttttttttttt///\"\n",
      "batch 3791  loss=141.0770  steps/s=60.20  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tE   ,      o ooo ttttttttttt/////////oo\"\n",
      "batch 3792  loss=134.7645  steps/s=106.34  prediction: \" exercise days, and just work a bit less\" => \"txo e  e    ee n                        \"\n",
      "batch 3793  loss=208.2214  steps/s=55.17  prediction: \"y: @BenjaminDEKR https://t.co/XKzK1sR0d2\" => \"  @ne  eeeeeee       ss s               \"\n",
      "batch 3794  loss=137.1970  steps/s=120.68  prediction: \"Tex prob huge dollars in anti drone bots\" => \"Bx eT exxxxeeeer e                      \"\n",
      "batch 3795  loss=135.3616  steps/s=45.08  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \": @eeeeeeeeeee    rrr                  n\"\n",
      "batch 3797  loss=143.2086  steps/s=111.83  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"ta   e            ............../hhhh///\"\n",
      "batch 3798  loss=140.5530  steps/s=62.21  prediction: \"@yacineMTB You want us to find our moms?\" => \"HaVSeebeee   ......     t tt////////ooJJ\"\n",
      "batch 3799  loss=134.8455  steps/s=113.41  prediction: \"n pick your own time though its flexible\" => \" a B ca        c                        \"\n",
      "batch 3800  loss=120.8722  steps/s=69.69  prediction: \"yotzol its not a meme, its a way of life\" => \":u ca  yo      n                        \"\n",
      "batch 3801  loss=117.6597  steps/s=108.98  prediction: \"o the door the instant she hears it open\" => \" p nop t    tt t     tt        hh       \"\n",
      "batch 3802  loss=148.6980  steps/s=104.83  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \" @ n)nnn       n                   _____\"\n",
      "batch 3803  loss=132.7031  steps/s=98.64  prediction: \"ably do this for all future projects tbh\" => \"tl n                                    \"\n",
      "batch 3805  loss=136.6009  steps/s=106.29  prediction: \"_opener oops i misread your comment my b\" => \"px aeoooooooooooooooo                   \"\n",
      "batch 3806  loss=121.1626  steps/s=52.28  prediction: \": @0arity @bayes_street probably yea lol\" => \" @ktrl oooooo o   ese  ee          mmm  \"\n",
      "batch 3807  loss=135.5496  steps/s=105.24  prediction: \"yMazza my favorite systems administrator\" => \":e :aaaay   y  msssseeeee  s mmmmm mm   \"\n",
      "batch 3808  loss=156.5658  steps/s=85.28  prediction: \"rchived_videos @LimkarRohit @discord LOL\" => \"eily: @a  a    _iisssseesssaammiiiiiiirr\"\n",
      "batch 3809  loss=135.6420  steps/s=106.51  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \"hof  i  iiiiiiiiiii                     \"\n",
      "batch 3810  loss=127.9247  steps/s=104.58  prediction: \"started begging me to let him pay for it\" => \" af  t       ggggggggggg                \"\n",
      "batch 3811  loss=194.0512  steps/s=35.60  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly: @      gggggggggg ee                \"\n",
      "batch 3812  loss=127.5115  steps/s=121.21  prediction: \"ht them the openscad to make the pulleys\" => \"e g        hhhhhhh                      \"\n",
      "batch 3813  loss=153.4128  steps/s=103.54  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "i    eeee     r         tttttttttt/////\"\n",
      "batch 3814  loss=134.4710  steps/s=104.88  prediction: \"hitectures. it only finds different MLPs\" => \"es veeneeeeeeeettttt                    \"\n",
      "batch 3815  loss=131.5508  steps/s=103.96  prediction: \"t the procedure for doing this is on mac\" => \" rt  a         r                        \"\n",
      "batch 3816  loss=142.6401  steps/s=29.92  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @n       eeree                      \"\n",
      "batch 3817  loss=146.5060  steps/s=130.76  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ust  ereeeeeeee urod  rooo           oo \"\n",
      "batch 3818  loss=127.8528  steps/s=106.27  prediction: \"s are your own, and i need to prove that\" => \" tet t                                  \"\n",
      "batch 3819  loss=130.0262  steps/s=103.36  prediction: \"d segments of the godfather and seinfeld\" => \" stte eeeeeeeeeee                       \"\n",
      "batch 3821  loss=132.8745  steps/s=104.85  prediction: \"the behavior, forming a habit eventually\" => \"hef igeeeeeeee n                        \"\n",
      "batch 3822  loss=136.8684  steps/s=98.97  prediction: \"ple deep q network has achieved insanity\" => \"ly: @he ee     neeee           ee  aaaai\"\n",
      "batch 3823  loss=141.4229  steps/s=104.80  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \"    g g        n                gggggggg\"\n",
      "batch 3824  loss=170.5922  steps/s=59.74  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tjst  gn  g         tt         gg   glll\"\n",
      "batch 3825  loss=135.9740  steps/s=107.42  prediction: \"the highest quality music we have so far\" => \";e   a    hhhhh hh     t                \"\n",
      "batch 3826  loss=144.8023  steps/s=100.09  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"esuoao  oooooooo    tttttttttttttt//////\"\n",
      "batch 3827  loss=139.7700  steps/s=104.57  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"tue eedeeeeee                 CCCCnnnnnn\"\n",
      "batch 3828  loss=131.2030  steps/s=105.46  prediction: \"verything that happens to everyone else'\" => \"erytee ee   ttt ttttttttttt     eeeeeeee\"\n",
      "batch 3829  loss=194.5405  steps/s=52.94  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @lut ee ttttttthhhhttttp   eeeeeeeeeeee\"\n",
      "batch 3830  loss=219.9964  steps/s=118.49  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"theeeaee         OOOOOOO    ////////////\"\n",
      "batch 3831  loss=141.6397  steps/s=104.84  prediction: \"mpactful on actual success for me though\" => \"elhu ve        t        ccccccccc       \"\n",
      "batch 3832  loss=181.8396  steps/s=100.69  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"he e         ///////////HHHHH......ppppp\"\n",
      "batch 3833  loss=138.7184  steps/s=106.64  prediction: \"credibly cool to see this project evolve\" => \"h   t7tittcccccccoooooooo  oo   t  eeett\"\n",
      "batch 3834  loss=130.2621  steps/s=102.65  prediction: \"dnt mention anything related to caffeine\" => \" d  d           nnnnnnnnnnnnnnnttttt   e\"\n",
      "batch 3835  loss=181.8322  steps/s=104.27  prediction: \"s depth? currently doing a similar thing\" => \" oee r         r                        \"\n",
      "batch 3836  loss=128.2004  steps/s=98.03  prediction: \"gpu accelerated cnn from scratch?\n",
      "\n",
      "based\" => \"   ae a ccccceececccccc           ccccra\"\n",
      "batch 3837  loss=133.5561  steps/s=104.17  prediction: \"y its been a useful learning experience?\" => \" is ao                        eeeeeeeeee\"\n",
      "batch 3838  loss=127.3000  steps/s=104.93  prediction: \" games because we trusted each other lol\" => \"tre   memmmmeeeeeeeeeeeeeeeeeeeeeeee    \"\n",
      "batch 3839  loss=125.4120  steps/s=102.91  prediction: \"he actual serious dangers of being smart\" => \"e   d                                   \"\n",
      "batch 3840  loss=127.6640  steps/s=104.46  prediction: \"d to seeing your progress on nand2tetris\" => \" ane  o              rrrrrrrrrr    nnnnn\"\n",
      "batch 3841  loss=130.3093  steps/s=30.64  prediction: \"ply: @yacineMTB sent from my xerox phone\" => \"ly: @i         r    rrrrrrr     nnnnnnnn\"\n",
      "batch 3842  loss=142.1931  steps/s=142.43  prediction: \"anks maaan. i want it to load SUPER fast\" => \"nd  e  aannnaaanaan   aa                \"\n",
      "batch 3843  loss=128.2017  steps/s=101.19  prediction: \" android OS inside of a virtual machine?\" => \"tnn an         n                        \"\n",
      "batch 3844  loss=161.5848  steps/s=105.23  prediction: \"/t.co/T03I8pk4ER\n",
      "https://t.co/XSr1ijr0iv\" => \"tozpe:t/////////tttttttttttttt//////////\"\n",
      "batch 3845  loss=133.3304  steps/s=105.34  prediction: \"\n",
      "\n",
      "\"fly over xyz tourist location for $5\"\" => \"\n",
      "y  o eeeeeeeeere             oooooooooo\"\n",
      "batch 3846  loss=142.4057  steps/s=102.78  prediction: \"d some stuff!!!!\n",
      "https://t.co/160qafZKAk\" => \" ts    sssssssss!!!!!!!!!!ttttttttttt///\"\n",
      "batch 3847  loss=135.5199  steps/s=104.34  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n  i                           iiiiiiiii\"\n",
      "batch 3848  loss=125.8510  steps/s=102.48  prediction: \"have you seen the walmart aura points ad\" => \"engi d   v     eee eeee eee e  aaaaaaaaa\"\n",
      "batch 3850  loss=135.4527  steps/s=104.71  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yC  aa      lllllllllllllllssssstttt////\"\n",
      "batch 3851  loss=134.7629  steps/s=100.30  prediction: \"gonna code to one song and one song only\" => \" na   i       o     ooooo   nnnnn   nnnn\"\n",
      "batch 3853  loss=169.3369  steps/s=37.75  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: @e e            ooo nn  nnn  nn nnnnn\"\n",
      "batch 3854  loss=142.7690  steps/s=138.23  prediction: \" its a sign you should make react in zig\" => \"ts n   AA                               \"\n",
      "batch 3856  loss=147.5397  steps/s=105.53  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" mi          ll lllllll    tttttttt/////\"\n",
      "batch 3857  loss=135.8443  steps/s=96.92  prediction: \"tler good knight https://t.co/lACUcp7zMH\" => \"he   plll ll      ttttttttt////////AAAAA\"\n",
      "batch 3858  loss=143.5829  steps/s=100.32  prediction: \"ogan?? was he on sidetweets or something\" => \"n  owe o                           eeeee\"\n",
      "batch 3859  loss=138.9735  steps/s=93.56  prediction: \"daily Whats your roadmap for learning ml\" => \"  no  lla hh               or  oo       \"\n",
      "batch 3860  loss=157.1659  steps/s=21.29  prediction: \"eply: @kayzee_ow https://t.co/y0ck4lbyrK\" => \" ly: @laaahh          a    or  oo      n\"\n",
      "batch 3861  loss=135.6391  steps/s=112.18  prediction: \". seems like a fancy type of hard coding\" => \" ihe  eeeeeeeeeeeeee                    \"\n",
      "batch 3862  loss=136.8330  steps/s=105.00  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" -&gt;ttttttttt ttssssssssssssssssssssss\"\n",
      "batch 3863  loss=136.2691  steps/s=97.24  prediction: \" takes a lot of work and years of it tho\" => \"thate e        t                        \"\n",
      "batch 3864  loss=151.1338  steps/s=101.62  prediction: \"dgrammer best languages in your opinion?\" => \"    mammmmmmmmmmmrraaaaaaaaaa           \"\n",
      "batch 3866  loss=122.4435  steps/s=29.51  prediction: \"ply: @yacineMTB Just ask it to go faster\" => \"ly: @Sammmmrrmrmrraaaaaaa            nnn\"\n",
      "batch 3867  loss=135.0663  steps/s=107.83  prediction: \"ate, but I think about this all the time\" => \"ti e       tttt t      ttttt            \"\n",
      "batch 3869  loss=126.9659  steps/s=102.67  prediction: \" already doing, faster. you are the user\" => \"t  e e eeeeeeeed                        \"\n",
      "batch 3871  loss=132.3280  steps/s=104.63  prediction: \"r 100x more productive, get good with it\" => \"ette                                    \"\n",
      "batch 3872  loss=132.5700  steps/s=101.68  prediction: \" pried the shift key off w a screwdriver\" => \"ia ereaa                                \"\n",
      "batch 3873  loss=145.2226  steps/s=103.78  prediction: \"he phone seems to make a huge difference\" => \"i   t          e                     eee\"\n",
      "batch 3874  loss=135.9953  steps/s=93.19  prediction: \"ller accurate. really useful distinction\" => \"yy @eeeooeeeeeee eeeeee    e    fffeefii\"\n",
      "batch 3875  loss=140.8345  steps/s=103.97  prediction: \" from scratch, and a bit of transformers\" => \"tonp e         c                        \"\n",
      "batch 3876  loss=141.1121  steps/s=100.69  prediction: \" is actually happening behind the scenes\" => \"tn ee            aaaaaaaaaannnnnnnh   ne\"\n",
      "batch 3877  loss=132.7298  steps/s=103.58  prediction: \"a good way to beat addictions in general\" => \"nf i w i                                \"\n",
      "batch 3878  loss=139.8208  steps/s=102.99  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"lte  ellppppooooooooooooooooooooonnn    \"\n",
      "batch 3879  loss=134.0291  steps/s=98.76  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  p: i iiiiiiii    ddd  d               \"\n",
      "batch 3880  loss=134.0926  steps/s=104.31  prediction: \"hitectures. it only finds different MLPs\" => \"in  nvneeeeeeeettttt                    \"\n",
      "batch 3881  loss=137.4771  steps/s=103.89  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" el leleeeeeeeeeeeeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttt/////////\"\n",
      "batch 3882  loss=144.9052  steps/s=99.84  prediction: \" your own game engine\n",
      "challenge accepted\" => \"tou wAw                  ee eeeeeeeeeeee\"\n",
      "batch 3883  loss=224.5726  steps/s=100.14  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"n  t e                    ttttttt///////\"\n",
      "batch 3884  loss=138.8436  steps/s=101.51  prediction: \" come to your house, and move mario back\" => \"taveeeeeee     m                        \"\n",
      "batch 3885  loss=131.0481  steps/s=101.68  prediction: \"nd requires a phone app to connect to it\" => \"d 9d   a eeeeeee            p           \"\n",
      "batch 3886  loss=156.3347  steps/s=99.22  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"e   aesees                              \"\n",
      "batch 3887  loss=123.7240  steps/s=98.89  prediction: \"ood and helps you not waste future years\" => \"nlho           n                        \"\n",
      "batch 3888  loss=135.4104  steps/s=102.79  prediction: \"ore descriptive titles for the rest lool\" => \" k n         eeneeeeeeeeeeeeeeeeeett    \"\n",
      "batch 3889  loss=132.9592  steps/s=99.38  prediction: \" long long time\n",
      "\n",
      "https://t.co/svmrGr008p\" => \"tot              gg     ttttttttttttt///\"\n",
      "batch 3890  loss=135.4362  steps/s=105.23  prediction: \"ed for simple stuff but couldn't handleâ€¦\" => \"   t                          uuuuu     \"\n",
      "batch 3891  loss=136.0102  steps/s=104.16  prediction: \"uq?\n",
      "\n",
      "this freaked me out, didnt know ifâ€¦\" => \"t ma               eeeeeeee             \"\n",
      "batch 3892  loss=128.8604  steps/s=101.90  prediction: \"\n",
      "\n",
      "good potential source of cool projects\" => \"\n",
      " osd  ooooooooooooooooooooooooooooooooo\"\n",
      "batch 3893  loss=142.4291  steps/s=105.27  prediction: \"er/common, insurance will drive adoption\" => \" sS    eeeeeeeeemmmnnnnnnnnnnn        ii\"\n",
      "batch 3894  loss=142.1342  steps/s=100.94  prediction: \"\n",
      "\n",
      "and give it slightly higher privileges\" => \"\n",
      "reri iiiiiiiiiiiiiii              iiiii\"\n",
      "batch 3895  loss=136.7278  steps/s=105.17  prediction: \"e and remember as much as possible after\" => \" sla           meeeeemmm        ssssssss\"\n",
      "batch 3896  loss=162.4530  steps/s=106.57  prediction: \" possible the true x for elon is 42,069x\" => \"trm  ssssssssss                         \"\n",
      "batch 3897  loss=136.4674  steps/s=104.59  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"th   i                        aaaaaaaaaa\"\n",
      "batch 3898  loss=138.3141  steps/s=104.51  prediction: \"building logic gates and RAM and whatnot\" => \"et l  lbbb                              \"\n",
      "batch 3899  loss=133.5157  steps/s=104.46  prediction: \"etter, all in your head\n",
      "Can explain more\" => \" t             l                   aaaaa\"\n",
      "batch 3900  loss=126.8900  steps/s=102.32  prediction: \" android OS inside of a virtual machine?\" => \"and and        n                        \"\n",
      "batch 3901  loss=133.2153  steps/s=101.96  prediction: \"utomatically imagine letters as colored?\" => \"r  n o  ooooaaaaaaaaaaaaaaatttttt       \"\n",
      "batch 3902  loss=126.6859  steps/s=20.90  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly: oooooaaaaaaaaaaaaaaaitttt        ee\"\n",
      "batch 3903  loss=126.3578  steps/s=132.28  prediction: \"ng sedenions for something in your game?\" => \"g r   y          nn  ssoo ss   n        \"\n",
      "batch 3904  loss=134.8971  steps/s=101.99  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" a  o t         aaaaa \n",
      "\n",
      "\n",
      "\n",
      "rrrrraaaaraaag\"\n",
      "batch 3905  loss=144.3295  steps/s=102.25  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \" ih  e ..    eee            tttt////////\"\n",
      "batch 3906  loss=126.3123  steps/s=104.53  prediction: \"ht. i feel like i barely understand them\" => \"es io                          eeeee eee\"\n",
      "batch 3908  loss=131.0199  steps/s=105.06  prediction: \" sessions with you and everyone else man\" => \"the teeesssssss sss               eeeeee\"\n",
      "batch 3909  loss=126.6814  steps/s=100.58  prediction: \"o make a comeback. would be great to see\" => \"ut oo e                                 \"\n",
      "batch 3910  loss=125.1413  steps/s=37.90  prediction: \"ly: @IterIntellectus its white pill week\" => \"y: @j e      eeke                     ee\"\n",
      "batch 3911  loss=154.8672  steps/s=106.71  prediction: \"ess while retaining the same information\" => \"                     eeeeeeeeeeee    iii\"\n",
      "batch 3912  loss=204.9281  steps/s=100.86  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"P N  GNGNNNNNNNALLLLLNALLLI  tttt///////\"\n",
      "batch 3913  loss=143.5565  steps/s=100.86  prediction: \"g i can make some insanely helpful stuff\" => \" a  ei                          eeee    \"\n",
      "batch 3914  loss=128.2763  steps/s=104.15  prediction: \"thing I need to pay attention to, thanks\" => \"hi  i\n",
      "                     ttttttttttttt\"\n",
      "batch 3915  loss=148.0179  steps/s=94.49  prediction: \" stuff! Thanks, hope yours went well man\" => \"te s  ooo      s              o         \"\n",
      "batch 3916  loss=167.7965  steps/s=103.57  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"ne ra #aaaaaaan nnnnnnnnn tttttt////////\"\n",
      "batch 3917  loss=135.0436  steps/s=103.93  prediction: \" is structured to add llms pretty easily\" => \"tndi n                 dddd             \"\n",
      "batch 3919  loss=135.2063  steps/s=103.71  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"y c  u               tttttttttttttttt///\"\n",
      "batch 3921  loss=145.4232  steps/s=93.03  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"ya @susttttttteehhtthhtttt/////////////o\"\n",
      "batch 3922  loss=134.7890  steps/s=102.81  prediction: \"unches, then good luck ever finding them\" => \"l eee          n                        \"\n",
      "batch 3923  loss=129.8921  steps/s=103.45  prediction: \"g the cursor with your hands using video\" => \" t s llllll                             \"\n",
      "batch 3924  loss=138.4756  steps/s=102.25  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" t o                    tttttttttttttt//\"\n",
      "batch 3925  loss=127.6545  steps/s=103.76  prediction: \"then add audio and make it a vid editor.\" => \" ee dus      ddddddddddda               \"\n",
      "batch 3926  loss=136.2301  steps/s=100.57  prediction: \"that there were pink cubes at some point\" => \" im            t                        \"\n",
      "batch 3927  loss=136.5289  steps/s=104.90  prediction: \"y with any industry/niche and ill run it\" => \" ti nniyyyyyyyyy yyyyynnnnnnnnnnnn      \"\n",
      "batch 3928  loss=139.8962  steps/s=103.95  prediction: \"aster i u know its just abt authenticity\" => \"nt tottt       t                 ttttttt\"\n",
      "batch 3929  loss=121.0344  steps/s=103.11  prediction: \"veryone in the past was a caveman/moron\"\" => \"e es  eeeeeeeeeeee             aaaaaaaaa\"\n",
      "batch 3931  loss=160.0050  steps/s=99.94  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" teddi-;;;;;gggggggt\n",
      "\n",
      "\n",
      "\n",
      "ooooooooooooo   \"\n",
      "batch 3932  loss=137.5459  steps/s=105.36  prediction: \" right now its just learning on the side\" => \"ae  r                            nn     \"\n",
      "batch 3933  loss=133.2801  steps/s=105.40  prediction: \" function w gpt3.5 instead of uppercaseâ€¦\" => \"ti l  e        t                        \"\n",
      "batch 3934  loss=139.2750  steps/s=104.03  prediction: \"n people imagine\n",
      "https://t.co/ZYfaaoNir7\" => \" a ete         eeeeeeeeeeeettttttttt////\"\n",
      "batch 3935  loss=133.7009  steps/s=104.13  prediction: \" fundamentals.  Take the time to invest.\" => \"to          tttn aaaaaa                 \"\n",
      "batch 3936  loss=128.3472  steps/s=103.77  prediction: \"ppl who got rich playing 0 sum games tho\" => \"let  i                                  \"\n",
      "batch 3937  loss=124.8769  steps/s=104.11  prediction: \"r this, practice it to get skilled at it\" => \"esup  u        r                        \"\n",
      "batch 3938  loss=141.1985  steps/s=106.35  prediction: \"l modeling is a great one to add to this\" => \"yfr@ttmmmmmmm  m                        \"\n",
      "batch 3939  loss=129.7061  steps/s=105.32  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i                        ttteetttttt\"\n",
      "batch 3941  loss=123.1883  steps/s=72.52  prediction: \"yotzol its not a meme, its a way of life\" => \" uili    t     t  ttt   eeee  tt        \"\n",
      "batch 3942  loss=133.1486  steps/s=107.09  prediction: \"ite complexity? If not, what is the max?\" => \"n in  iiiiiiiiiiiii                     \"\n",
      "batch 3944  loss=151.3015  steps/s=97.32  prediction: \"B GPT isnt wrong, just ahead of its time\" => \" y ia i                                 \"\n",
      "batch 3945  loss=123.5100  steps/s=97.99  prediction: \" literally can\n",
      "not good for computer tho\" => \"ti   Ty       l lllll   oooooooooooooooo\"\n",
      "batch 3946  loss=131.2408  steps/s=105.13  prediction: \" about it and in 1 weekend jumped up 200\" => \"t a a                           eeeee   \"\n",
      "batch 3947  loss=139.5594  steps/s=102.21  prediction: \"racticing self control leads to strength\" => \"etl : 00tttt ii    cc       lll         \"\n",
      "batch 3949  loss=145.8276  steps/s=97.93  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"e Aai igggg    loooooooo                \"\n",
      "batch 3950  loss=135.5533  steps/s=105.33  prediction: \"m scratch in numpy like i did w backprop\" => \"ete et                                  \"\n",
      "batch 3951  loss=127.0629  steps/s=102.49  prediction: \"my ability to make things I want to make\" => \"e e rt         i                        \"\n",
      "batch 3952  loss=179.2319  steps/s=97.53  prediction: \"eos Oh I know :) https://t.co/aV1q8nmIEk\" => \" r a @iii                   ttttt///////\"\n",
      "batch 3953  loss=131.5367  steps/s=104.97  prediction: \", thank God we can function at all loool\" => \" ire i                                  \"\n",
      "batch 3954  loss=129.8404  steps/s=101.23  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"eeiyi @aattttttttttttttttttsssnnnnnnnnnn\"\n",
      "batch 3955  loss=122.2435  steps/s=35.33  prediction: \"st: caffeine is steroids but for posting\" => \"  eeantaattttttttttttttssstttnnnnnnnnnnn\"\n",
      "batch 3956  loss=154.4214  steps/s=139.22  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \" ucccrc7777             tttttttt////////\"\n",
      "batch 3957  loss=126.3829  steps/s=105.33  prediction: \"tion WAY more than if its someone else's\" => \" c  r oo oooooo                        e\"\n",
      "batch 3958  loss=133.8570  steps/s=30.06  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"ly  t oo ooo   t                     eee\"\n",
      "batch 3959  loss=126.7877  steps/s=108.67  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia    aaaaa        nntttttttttttttttttt\"\n",
      "batch 3962  loss=159.8469  steps/s=91.83  prediction: \"072 im super glad man! love to hear that\" => \"x B xi ff      n   gu t ng    t         \"\n",
      "batch 3963  loss=138.6104  steps/s=105.60  prediction: \" done in 1s, lol https://t.co/d2QCy0zBel\" => \"ton innnnnnn                ttttttt/////\"\n",
      "batch 3964  loss=127.8601  steps/s=103.87  prediction: \"nse and you can't efficiently work withâ€¦\" => \"ge t t                                  \"\n",
      "batch 3966  loss=123.0446  steps/s=103.53  prediction: \"ticated strings as defined by kolmogorov\" => \"hn o  etttttttttssssssssssss            \"\n",
      "batch 3967  loss=144.2259  steps/s=100.48  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"e t e_eeeeeee  e   eeeett               \"\n",
      "batch 3968  loss=138.6494  steps/s=100.40  prediction: \"o church\n",
      "Starting everything immediately\" => \" h ioe o     ttttttttttttttttrrriiiiiiii\"\n",
      "batch 3969  loss=132.4816  steps/s=104.21  prediction: \"file editing program, will show vid soon\" => \" l ii    iiiiiiiiiiiiiiiiiii l          \"\n",
      "batch 3970  loss=136.8248  steps/s=97.58  prediction: \"ylde lowkey cant believe zompy said that\" => \":e jaeiiiillllle        l               \"\n",
      "batch 3972  loss=150.0637  steps/s=104.45  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"tircrcct/////////ttttttttttt///////////t\"\n",
      "batch 3973  loss=156.9423  steps/s=96.68  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" aia/tttuuuueeeeeeettttttttt/////////ZZZ\"\n",
      "batch 3974  loss=134.0279  steps/s=103.79  prediction: \" can see something 1000000x better to do\" => \"tat eanaa      n         00000000000    \"\n",
      "batch 3976  loss=130.5193  steps/s=105.08  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  o i        n                        \"\n",
      "batch 3977  loss=133.2584  steps/s=102.57  prediction: \" new meta\n",
      "dont think too hard about that\" => \"tot h           tttttttttttt           t\"\n",
      "batch 3978  loss=136.9804  steps/s=103.16  prediction: \"itor as I was with 2 screens and a mouse\" => \"n   a                                   \"\n",
      "batch 3979  loss=174.3103  steps/s=89.52  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"ap t a                   tsstts       e2\"\n",
      "batch 3980  loss=130.5744  steps/s=103.66  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hat s   eeeeeeeeeeeeeeeeeeeeeeee      nn\"\n",
      "batch 3981  loss=128.7116  steps/s=104.15  prediction: \"ar mongering gets attention (clicks etc)\" => \"nee  eeeeeeeeeeeeeeeeeeeeetttttttttttttt\"\n",
      "batch 3982  loss=161.6173  steps/s=78.28  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"ectbebeeenn    n  attttttnnnt tn     cct\"\n",
      "batch 3983  loss=127.3325  steps/s=106.28  prediction: \"rd it means theyre giving you a discount\" => \"ee2y:                eeeeeee            \"\n",
      "batch 3984  loss=137.8947  steps/s=65.51  prediction: \"@ludwigABAP ever thought of moving here?\" => \"yubin_e       eeeeeee  hh gg            \"\n",
      "batch 3985  loss=148.2872  steps/s=108.14  prediction: \"18/hr\n",
      "\n",
      "cons\n",
      "- none\n",
      "- i only know scratch\" => \" 0   \n",
      "     \n",
      "\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nnnnnnnnnnnnn   \"\n",
      "batch 3986  loss=142.6298  steps/s=87.52  prediction: \"igABAP Born to consoom, forced to signal\" => \"n     \n",
      "A\n",
      "AAAAAoonnoonooooooooooo        \"\n",
      "batch 3987  loss=126.3706  steps/s=64.42  prediction: \" @startupmillyair lichess or chessdotcom\" => \"t1ua  BABBBBB onooooooooooooo  o   sss o\"\n",
      "batch 3988  loss=127.0542  steps/s=102.32  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \"twia  ABAAAAAA    nn   s         sssssoðŸ›‘\"\n",
      "batch 3989  loss=148.8254  steps/s=108.27  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"@h   e         ............... /////////\"\n",
      "batch 3990  loss=164.8331  steps/s=104.93  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"neere #aaaaaaan nnnnnnnnn  ttttttttt////\"\n",
      "batch 3991  loss=148.8543  steps/s=61.34  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"tS a#aaaaaaaan n   t    tttt/////tcctttt\"\n",
      "batch 3992  loss=136.0921  steps/s=110.10  prediction: \"unctional adults that they interact with\" => \"td  f         d       tttttttttttttttttt\"\n",
      "batch 3993  loss=135.1112  steps/s=104.71  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \"  se w                         stt//////\"\n",
      "batch 3994  loss=137.2411  steps/s=106.73  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \"gteaeen                ttttt///////////x\"\n",
      "batch 3995  loss=136.2498  steps/s=100.00  prediction: \" new meta\n",
      "dont think too hard about that\" => \"iok i           tttttttttttt            \"\n",
      "batch 3996  loss=110.9373  steps/s=11.33  prediction: \"reply: @calbch its the year of the monad\" => \"eply: @        ttttttttttttt           t\"\n",
      "batch 3997  loss=133.1725  steps/s=136.75  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @yactnt    t ttt tht n    o   o   o att\"\n",
      "batch 3998  loss=152.1756  steps/s=116.96  prediction: \"ynch Its official im naming my kid movie\" => \":c nunwwnn     n         iiiiiiiiimmmmmm\"\n",
      "batch 3999  loss=134.6681  steps/s=105.71  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \"0 s  = tttttr                     oooooo\"\n",
      "batch 4000  loss=130.5957  steps/s=105.60  prediction: \" could approximate non linear functionsâ€¦\" => \"ton tt         t    oo          nnnnnnnn\"\n",
      "batch 4001  loss=135.9273  steps/s=75.86  prediction: \"ludwigABAP its all slop tier, always was\" => \"ys @ t         t      lll n    nnnnannnn\"\n",
      "batch 4002  loss=127.4552  steps/s=107.04  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"e eoa                                   \"\n",
      "batch 4003  loss=128.4476  steps/s=105.25  prediction: \" to put in effort to unwire it (nbd tho)\" => \"thde                                    \"\n",
      "batch 4004  loss=135.9017  steps/s=103.75  prediction: \"think you can do cdn type stuff w em btw\" => \"hi             n                        \"\n",
      "batch 4005  loss=136.0462  steps/s=102.49  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"tne             aa a ssssssssttttttttt//\"\n",
      "batch 4006  loss=130.3166  steps/s=104.30  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly eno               eeeeeeeeeeeeeeennuu\"\n",
      "batch 4008  loss=139.6254  steps/s=75.68  prediction: \"eCachet Consistency is a deadly strategy\" => \" pho          t etiiitteni  eeeeeeeuuuun\"\n",
      "batch 4009  loss=134.6647  steps/s=108.95  prediction: \"ntellectus little italy?? nah. big italy\" => \"gs aaeeeeeeetttlttttttttt   aaaa??      \"\n",
      "batch 4010  loss=128.7635  steps/s=101.74  prediction: \"her level abstraction of piece movements\" => \"e e i a        re ee              eeeeee\"\n",
      "batch 4011  loss=155.8220  steps/s=102.53  prediction: \"cost) is probably a better way to put it\" => \"huss eneeiiitttibbbbbbbbbbbb            \"\n",
      "batch 4012  loss=139.1966  steps/s=104.33  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltee ellpppooooooooooooooooooooonnnnn   \"\n",
      "batch 4013  loss=135.2420  steps/s=101.88  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" a e  e              gggeeeeeeeeeeee    \"\n",
      "batch 4014  loss=141.6183  steps/s=105.13  prediction: \" up to do multiple iterations of editing\" => \"tst  t                 ttttttttttttiiiii\"\n",
      "batch 4015  loss=129.3528  steps/s=105.19  prediction: \"s w java and python and studying for fun\" => \" artt                                   \"\n",
      "batch 4016  loss=128.4566  steps/s=102.59  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \" seeo o                                 \"\n",
      "batch 4017  loss=181.0624  steps/s=97.90  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"an n e      @a@@@@jjjjjjj       OOOOOOOO\"\n",
      "batch 4018  loss=154.3554  steps/s=84.19  prediction: \"tard Interesting can you elaborate more?\" => \"hln s  ooaaannnenneen           o   OOOðŸ›‘\"\n",
      "batch 4019  loss=135.6250  steps/s=106.72  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"rn eo e       eeeeeeeeeeeeeeetttttt/////\"\n",
      "batch 4020  loss=137.1343  steps/s=101.10  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \"eho   e        n        fffffffffffff   \"\n",
      "batch 4021  loss=138.3289  steps/s=97.40  prediction: \"vinwylde the r in rgb stood for retarded\" => \"en oSrieeeeee  n                        \"\n",
      "batch 4023  loss=144.7790  steps/s=102.90  prediction: \"l. but really, I have absolutely no clue\" => \"y  n u                        llllllllll\"\n",
      "batch 4024  loss=128.4219  steps/s=103.59  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tl   llllllllll laa aaaaaaaa            \"\n",
      "batch 4026  loss=129.3911  steps/s=103.52  prediction: \" us safe from undetectable Dyson spheres\" => \"tpaenn                 eeeeeeeeeeeeeeeee\"\n",
      "batch 4027  loss=128.8864  steps/s=103.98  prediction: \"d size to whatever you want which helps.\" => \" ai i                              hhhhh\"\n",
      "batch 4028  loss=147.0695  steps/s=104.41  prediction: \"ks.. 90% correct https://t.co/t9unPUcvje\" => \"eyoo            rrrrrrrrrttttttt///////t\"\n",
      "batch 4029  loss=148.8428  steps/s=94.38  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"s          rrrrr ttttttttt/////////ccccc\"\n",
      "batch 4030  loss=132.5343  steps/s=61.63  prediction: \"@calbch its gonna be a good one for sure\" => \"saiwzgi       t hhttttt/tttotoocccocoooo\"\n",
      "batch 4031  loss=134.2546  steps/s=107.99  prediction: \" what to do next. i want to do my own tâ€¦\" => \"toa                                     \"\n",
      "batch 4032  loss=131.5884  steps/s=103.35  prediction: \"s\n",
      "\n",
      "so super frictionless, it sounds like\" => \" \n",
      "  t       sss ssssrsssssssssssssssssss\"\n",
      "batch 4033  loss=124.5633  steps/s=100.66  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @eeeeeeeeeeeerrrrrr               \"\n",
      "batch 4034  loss=150.5270  steps/s=94.86  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"han sreeeeeee t t   tt t  t     o       \"\n",
      "batch 4035  loss=157.6391  steps/s=97.41  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \" tng ntt nn             ttttttttttt/////\"\n",
      "batch 4036  loss=149.1895  steps/s=103.49  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"t.coneet////////tttttttttttt////////////\"\n",
      "batch 4037  loss=148.7128  steps/s=103.98  prediction: \"of visualization goes away with practice\" => \"u i  \n",
      "        iiiiiiiiioaaaaaaaaaaaaaaaa\"\n",
      "batch 4038  loss=143.2266  steps/s=21.02  prediction: \"eply: @ludwigsonneck Did you learn/grow?\" => \" ly: \n",
      "      iiiiiiiiiiiaaaaaaaaa aaaaaaa\"\n",
      "batch 4039  loss=136.9843  steps/s=107.84  prediction: \"to the planning phase with more momentum\" => \"h   ea         n nnnnnnnn             mm\"\n",
      "batch 4040  loss=129.2042  steps/s=97.35  prediction: \"but openai is cringe so obviously sonnet\" => \"ecto                 iiii      ooooooooo\"\n",
      "batch 4041  loss=135.9754  steps/s=103.99  prediction: \" know. But this will help you immensely.\" => \"to             n                      ll\"\n",
      "batch 4042  loss=123.7236  steps/s=104.82  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "then aaaaaaaaa         a               \"\n",
      "batch 4043  loss=148.0637  steps/s=100.65  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" ae o'o             o ooooo             \"\n",
      "batch 4044  loss=139.0995  steps/s=101.22  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" a   @wwww            tttttttttttttttt//\"\n",
      "batch 4045  loss=115.5161  steps/s=39.63  prediction: \"ly: @0xbingllm we gettin it we gettin it\" => \"y: @ oww            ttttttttttttttttt///\"\n",
      "batch 4046  loss=133.1571  steps/s=107.63  prediction: \"minds me of that old gpt engineer script\" => \"enetide                                 \"\n",
      "batch 4047  loss=134.9754  steps/s=103.54  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \" tnt ttceeeeeeeeeeeeeeeeeettttttt///////\"\n",
      "batch 4048  loss=158.0587  steps/s=105.17  prediction: \"m tools for speedy development (et al):â€¦\" => \"aht/cotooooooooooooo      eeeeeeeeeeeeee\"\n",
      "batch 4049  loss=130.8472  steps/s=105.11  prediction: \"is God for sure. but ive grown confident\" => \"n  e                                    \"\n",
      "batch 4051  loss=131.8020  steps/s=105.73  prediction: \"at can be beaten if you look hard enough\" => \"n  sseseeeeeeeeeee                      \"\n",
      "batch 4052  loss=138.6447  steps/s=106.32  prediction: \"enjoyable is such a gargantuan advantage\" => \" tit hhgnnnn               aaaaaaaaaaaaa\"\n",
      "batch 4054  loss=134.9122  steps/s=105.23  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \" i             n                        \"\n",
      "batch 4055  loss=140.6219  steps/s=104.25  prediction: \"so much better than ppl who dont anyways\" => \"  o  o                                  \"\n",
      "batch 4056  loss=150.4156  steps/s=63.97  prediction: \"@gizmobly @XEng lol why did he block you\" => \"sibio__        t                       y\"\n",
      "batch 4057  loss=132.7567  steps/s=119.01  prediction: \"ould build the thing then maybe post it!\" => \"  iuoh uuuuuuu                          \"\n",
      "batch 4058  loss=131.7984  steps/s=104.87  prediction: \" to recover from if it becomes a problem\" => \"tor o oooooooor rrrr                    \"\n",
      "batch 4059  loss=137.6902  steps/s=105.07  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  ti  t                    llllllllllll\"\n",
      "batch 4060  loss=159.4769  steps/s=105.38  prediction: \"his ~10yrs ago w py\n",
      "Learn by doing WORKS\" => \"en  se ttttts                           \"\n",
      "batch 4061  loss=163.9016  steps/s=90.27  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yg @   ts            a             ddddd\"\n",
      "batch 4062  loss=137.7570  steps/s=104.58  prediction: \"ave been trying to compress these lately\" => \"ne             n                eeeeeeee\"\n",
      "batch 4063  loss=143.5871  steps/s=104.30  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \"hath            ooooooooooonnnnnnnnn    \"\n",
      "batch 4064  loss=129.8650  steps/s=103.89  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \"hss  ha        t  aaaaaaa    nn         \"\n",
      "batch 4065  loss=138.9527  steps/s=67.28  prediction: \"seatedro c-&gt;wasm and js, all frontend\" => \" tt    t        aaaaaaaas  n           f\"\n",
      "batch 4066  loss=135.8235  steps/s=107.17  prediction: \"ked bc i could make cool fun stuff in it\" => \"  f  h                                  \"\n",
      "batch 4067  loss=131.9259  steps/s=21.72  prediction: \"eply: @yacineMTB dependency independency\" => \" ly:                                    \"\n",
      "batch 4068  loss=158.4203  steps/s=159.49  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" Bnt o      Abbbbbbbbbb  uu uuuuuuu     \"\n",
      "batch 4070  loss=143.1092  steps/s=105.03  prediction: \"nfidence\n",
      "\n",
      "\"idk\" is often the best belief\" => \"tidltoieeeeeeeedeiiiiiiii\"\"eeeeeeeeeeeee\"\n",
      "batch 4071  loss=134.8184  steps/s=105.16  prediction: \"g real and distracted from the adventure\" => \" at t                 dddddd          ee\"\n",
      "batch 4072  loss=128.1612  steps/s=104.63  prediction: \" component that approximates transformsâ€¦\" => \"ton o  oooooooon  tttttttttttttttttttttt\"\n",
      "batch 4073  loss=135.3407  steps/s=104.79  prediction: \"de it one of the best ive had in a while\" => \" rhv iiii                               \"\n",
      "batch 4074  loss=125.7100  steps/s=104.35  prediction: \"atterns so we should do (description ofâ€¦\" => \"t ahat            s               d  ooo\"\n",
      "batch 4075  loss=128.2079  steps/s=101.54  prediction: \"rappers around statistical distributions\" => \"ente  @  rrrrrr rrrrsssssssaastttiiiiiii\"\n",
      "batch 4076  loss=141.2096  steps/s=102.31  prediction: \"ficantly off lol https://t.co/SgwnmEaXdF\" => \" net tiiiiiiiiii            ttt/////////\"\n",
      "batch 4077  loss=144.1970  steps/s=98.30  prediction: \"its how i learned most of my tech skills\" => \"nst e                                   \"\n",
      "batch 4078  loss=136.5221  steps/s=102.37  prediction: \"ovate too and come up w cool experiments\" => \"ue n     oooooonooooo                  e\"\n",
      "batch 4079  loss=117.1486  steps/s=65.26  prediction: \" miss the good old completion model days\" => \"tann   o     ooooooo      oo   e ooeeeee\"\n",
      "batch 4080  loss=128.7855  steps/s=103.44  prediction: \"entation, the cooler everything will get\" => \"   o otttttttttttttoooeeeeeeeeeeeeeeeeee\"\n",
      "batch 4081  loss=136.0152  steps/s=101.45  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e ly: @   eeeees                        \"\n",
      "batch 4082  loss=143.3490  steps/s=104.12  prediction: \"ying/whatever, every monday and thursday\" => \":n  o/ggggggnnnnnneeeeeeeeeeeeeeyyyyyddd\"\n",
      "batch 4084  loss=127.3367  steps/s=99.21  prediction: \" it seems like a fire worth playing with\" => \"ts eiiieeeeeee t                        \"\n",
      "batch 4085  loss=127.3835  steps/s=104.03  prediction: \" way you perceive the world and yourself\" => \"thet                   eeeeeee          \"\n",
      "batch 4086  loss=140.6312  steps/s=100.77  prediction: \"oger @sunsettler @tunient baller name xD\" => \"u  t  luuuuueeeeetette@@ttttttttttlllel \"\n",
      "batch 4087  loss=129.8242  steps/s=103.08  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eee  t  eeeeeeeseeeeeeeeeeeeeeeiiiiiiiii\"\n",
      "batch 4088  loss=135.7617  steps/s=105.24  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" enese,eeeeeeeedeeeeeeeeeeetttt/////////\"\n",
      "batch 4089  loss=152.4239  steps/s=103.20  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"iul  y                     ttttt////////\"\n",
      "batch 4090  loss=127.8152  steps/s=102.75  prediction: \"seful instances of delayed gratification\" => \" dfoe          n               eeeee   a\"\n",
      "batch 4091  loss=133.0299  steps/s=104.38  prediction: \" and the professor thought it was a typo\" => \"t d  iiii                               \"\n",
      "batch 4092  loss=166.5537  steps/s=86.46  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn\"            d       hhhhh  tt        \"\n",
      "batch 4093  loss=178.5338  steps/s=36.07  prediction: \"ply: @2wlearning https://t.co/8ri7u6xMxw\" => \"ly: @id               hhhhth  tt      e \"\n",
      "batch 4095  loss=136.8657  steps/s=115.99  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"tam g i                                 \"\n",
      "batch 4096  loss=126.8120  steps/s=103.95  prediction: \"ding up to that over which skill matters\" => \" ng  e         t                        \"\n",
      "batch 4097  loss=133.2581  steps/s=107.37  prediction: \" off with a basic template and modify it\" => \"tuar   tttt    t                 aaaa   \"\n",
      "batch 4099  loss=124.8968  steps/s=95.86  prediction: \"resy you can already talk to one of them\" => \"eply: @            aaaaaaaaaa           \"\n",
      "batch 4100  loss=137.5452  steps/s=104.28  prediction: \"r, ill dm you the link when that happens\" => \"e ey, ee                             hhh\"\n",
      "batch 4101  loss=133.0299  steps/s=105.74  prediction: \"the most useful? https://t.co/w0tVqarS34\" => \"hes  r                tttttttttttttttt//\"\n",
      "batch 4102  loss=139.9721  steps/s=102.55  prediction: \"n=1)\n",
      "2 their goals are their vidya (n=2)\" => \" rh r e        n                        \"\n",
      "batch 4103  loss=140.1273  steps/s=101.28  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tn     .......eee                       \"\n",
      "batch 4104  loss=133.6587  steps/s=102.58  prediction: \"arpertony lichess? and what time control\" => \"td errrrrrrrrrrerrr                     \"\n",
      "batch 4105  loss=155.3102  steps/s=104.71  prediction: \"ng up every word you hear more than once\" => \"   wo                                   \"\n",
      "batch 4106  loss=129.4742  steps/s=105.36  prediction: \"ful for learning https://t.co/B7rPa9oFnr\" => \" n  t      llll rrrr            t///////\"\n",
      "batch 4107  loss=134.4039  steps/s=104.69  prediction: \" is structured to add llms pretty easily\" => \"tnd                     d               \"\n",
      "batch 4108  loss=122.9014  steps/s=102.26  prediction: \"bank account evaporate like a black hole\" => \"et d o         u     aaaaaaaaaaaaaaaaaa \"\n",
      "batch 4109  loss=131.6257  steps/s=101.48  prediction: \" ig i still dont understand comonads yet\" => \"ts  ih                         nnnnnnnnn\"\n",
      "batch 4110  loss=134.7469  steps/s=104.18  prediction: \"er useful building block to get good at.\" => \"  o       uuuuuuuuuuuu                  \"\n",
      "batch 4111  loss=138.8344  steps/s=99.75  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"um   yyyylllllllll                      \"\n",
      "batch 4113  loss=159.1880  steps/s=95.16  prediction: \"2 and a monkey pfp too.. this is bananas\" => \"0@n7oo777                               \"\n",
      "batch 4114  loss=137.1383  steps/s=105.09  prediction: \"ouraging way, not stressful for the kid)\" => \"ul   inggggggggnnnnnnnn                 \"\n",
      "batch 4115  loss=142.3046  steps/s=101.27  prediction: \" be cool to find some other players here\" => \"tuotc ooooooooooooo                   ee\"\n",
      "batch 4116  loss=145.2623  steps/s=104.54  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"eman:                                   \"\n",
      "batch 4117  loss=136.2954  steps/s=104.37  prediction: \"rings out there that would just ruin ppl\" => \"enlyt 0        ttttttttttttt            \"\n",
      "batch 4118  loss=127.0828  steps/s=104.72  prediction: \"ink not tho, I believe in synthetic data\" => \"ng o      ttt                           \"\n",
      "batch 4119  loss=145.1075  steps/s=101.01  prediction: \"ers @iliekcomputers is a p strong player\" => \" soee         i ieeiiii                 \"\n",
      "batch 4120  loss=190.0056  steps/s=107.55  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \"PAP C ERR sssssssssssssssssssss         \"\n",
      "batch 4121  loss=141.6819  steps/s=95.58  prediction: \"Simple p5. Will look into matter though.\" => \"oBeOp Spps    ii      ooooooo oo t ttttt\"\n",
      "batch 4122  loss=137.4684  steps/s=100.89  prediction: \"! wanted to do something a bit different\" => \" Io @e            oooooo                \"\n",
      "batch 4123  loss=151.8763  steps/s=103.36  prediction: \"actually protects me from getting hacked\" => \"liy                            tttttttt \"\n",
      "batch 4124  loss=137.8040  steps/s=102.89  prediction: \"ift camera to dogs perspective = dataset\" => \"n otg ;        t                   eeeee\"\n",
      "batch 4125  loss=133.7948  steps/s=103.55  prediction: \"hitectures. it only finds different MLPs\" => \"an  neneeeeeeeettttt                    \"\n",
      "batch 4126  loss=123.5079  steps/s=100.38  prediction: \" it seems like a fire worth playing with\" => \"ts eieeeee  eeete                       \"\n",
      "batch 4128  loss=125.8898  steps/s=102.72  prediction: \"ind. also so my brain doesnt deteriorate\" => \"ng g           n                        \"\n",
      "batch 4129  loss=147.7261  steps/s=103.26  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"ta i       aaaaaaaaatttttttttttttt//////\"\n",
      "batch 4130  loss=143.9883  steps/s=91.47  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \" lt  ouaaaaaaxx :o:    ot  n/n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oo\n",
      "\n",
      "o\"\n",
      "batch 4131  loss=160.4259  steps/s=104.91  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"ton          !!!!!!!!!!ttttttttttt//////\"\n",
      "batch 4132  loss=159.1191  steps/s=66.03  prediction: \" more to 400! Been a crazy two weeks lol\" => \"tot  t  !!!!!!!!!       tttt/////// FFGG\"\n",
      "batch 4133  loss=151.4403  steps/s=112.50  prediction: \"cicle77 welcome aboard the zig train bro\" => \"onan           t        a               \"\n",
      "batch 4134  loss=127.8677  steps/s=104.95  prediction: \"e the reward dips down below the average\" => \" ae   eeeeeeeeeeeeeedddddd   ww         \"\n",
      "batch 4136  loss=132.2137  steps/s=59.32  prediction: \" @justalexoki You have alerted the horde\" => \"tte heeeeeeeee r   d          e       ee\"\n",
      "batch 4137  loss=129.4422  steps/s=105.43  prediction: \" in those days will have had it too easy\" => \"tn  o s                                 \"\n",
      "batch 4138  loss=131.2010  steps/s=102.21  prediction: \"ol\n",
      "gonna crack one open rn over some ice\" => \"ne o     oooooonoooooooo   nnnnn        \"\n",
      "batch 4139  loss=125.9018  steps/s=101.32  prediction: \"ne was right the rates arent high enough\" => \"   ha iaaaaaa                           \"\n",
      "batch 4140  loss=121.2975  steps/s=102.68  prediction: \"op over and over is the opposite of slop\" => \"n co                             o     o\"\n",
      "batch 4141  loss=127.6378  steps/s=104.28  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"aa  a r  rrrr  r    ssssssss            \"\n",
      "batch 4142  loss=141.2851  steps/s=104.93  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \" o fg n        n                gggggggg\"\n",
      "batch 4143  loss=145.3975  steps/s=72.31  prediction: \"@squirtle_says yacine what have you done\" => \"tuwinon  tt       y  t  tt  ttg       ll\"\n",
      "batch 4144  loss=133.5450  steps/s=55.74  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"y: @o g  tttt   syy     tt   a        ll\"\n",
      "batch 4145  loss=161.4390  steps/s=133.84  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":ucBe cy ee             ttttttttt///////\"\n",
      "batch 4146  loss=136.8987  steps/s=105.15  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"n  s  c        eiiiiittttttttttttt//////\"\n",
      "batch 4147  loss=158.5311  steps/s=104.87  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" minost                     ttttt///////\"\n",
      "batch 4148  loss=130.8129  steps/s=105.61  prediction: \"nts of time. its like skilling up almost\" => \"eo    m                     iiiiiiiiilll\"\n",
      "batch 4149  loss=137.2148  steps/s=106.43  prediction: \"a recent nvim noob Tutor is super useful\" => \" m             n                      uu\"\n",
      "batch 4150  loss=186.6472  steps/s=102.77  prediction: \"s: added eraser) https://t.co/TAudQKjLMg\" => \" /e  rrrdddddddeddeeeeeeeeseetttttttt///\"\n",
      "batch 4151  loss=129.8498  steps/s=100.98  prediction: \" do. pays dividends for a long long time\" => \"to             dddddddddddd             \"\n",
      "batch 4152  loss=131.8252  steps/s=104.93  prediction: \" is a wild computational rabbithole man.\" => \"t  r s         c          aaaaaaaaaaaaaa\"\n",
      "batch 4153  loss=133.6009  steps/s=104.74  prediction: \"indirections/abstractions/contexts oh ok\" => \"ngesl  iiiiiiiiiiiiiiiiisssssssctttttttt\"\n",
      "batch 4154  loss=161.4357  steps/s=104.43  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"thuststtt//////tttttttttttttt///////////\"\n",
      "batch 4155  loss=137.3843  steps/s=105.16  prediction: \"t am article to help ppl understand theâ€¦\" => \"hmeeet         t                        \"\n",
      "batch 4157  loss=140.6986  steps/s=105.41  prediction: \"yo grand children at 85. gps kids r busy\" => \" u  n5e                                 \"\n",
      "batch 4158  loss=137.0288  steps/s=104.76  prediction: \"amount of time, or did you just enjoy it\" => \"re ia          m                        \"\n",
      "batch 4159  loss=154.5088  steps/s=102.82  prediction: \"zzl\n",
      "\n",
      "Or maybe he got it from someone idk\" => \"eob wr                                  \"\n",
      "batch 4160  loss=137.2955  steps/s=103.41  prediction: \"d all the aliases for commands to bashrc\" => \" oh    aaaa aaaaa                       \"\n",
      "batch 4161  loss=177.9256  steps/s=101.42  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"  eas//////BstttBBBBBooo oooo           \"\n",
      "batch 4162  loss=148.6205  steps/s=102.96  prediction: \"ynch Its official im naming my kid movie\" => \":  nadwnn      n               mmimmmmmm\"\n",
      "batch 4163  loss=145.6348  steps/s=98.41  prediction: \"B GPT isnt wrong, just ahead of its time\" => \"AP danTTTTTTT                           \"\n",
      "batch 4164  loss=135.8305  steps/s=101.83  prediction: \"lex code across multiple (simple!) Files\" => \"ym  l o        cc            lllllllllll\"\n",
      "batch 4165  loss=123.9789  steps/s=102.71  prediction: \"y time back so i can work on what i want\" => \":t nawm        m                        \"\n",
      "batch 4166  loss=138.3353  steps/s=99.28  prediction: \"a Meet the new boss\n",
      "Same as the old boss\" => \"ni mo tattttt        eee                \"\n",
      "batch 4167  loss=141.2950  steps/s=99.93  prediction: \"en helpful!! ah nice addition, good idea\" => \" to  @e eeeee  n                    dddd\"\n",
      "batch 4168  loss=130.5382  steps/s=101.87  prediction: \"eaply making synthetic training data? :)\" => \" lo  h             nn      iiiiiiiinntta\"\n",
      "batch 4169  loss=136.6470  steps/s=100.84  prediction: \"appen. i know it https://t.co/jDUR7SknBb\" => \"ne ea                    tttttttttttt///\"\n",
      "batch 4170  loss=137.1581  steps/s=103.26  prediction: \"tent and youll get stronger and stronger\" => \"  ot   t                              nn\"\n",
      "batch 4171  loss=222.5606  steps/s=99.82  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OO OOOOOOOOOOOOOOOOOOOOOOOOOGGGttttttttt\"\n",
      "batch 4172  loss=150.7005  steps/s=100.67  prediction: \"to it so you can share with your friends\" => \"  t    t                                \"\n",
      "batch 4173  loss=133.8238  steps/s=106.97  prediction: \"ki i have an idea but it will cost $1600\" => \"en  tas            aa                   \"\n",
      "batch 4174  loss=130.6400  steps/s=104.01  prediction: \"ve you been unlocking yourself each time\" => \"e ty i         n     nnnnnnnnnn  eee  ee\"\n",
      "batch 4175  loss=147.8600  steps/s=101.66  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \":t yauuuuuu            tt ttttttttttt///\"\n",
      "batch 4176  loss=146.2718  steps/s=99.92  prediction: \"r him, thanks! Sounds useful potentially\" => \"ealy: @                    uuuuuuuuuuuu \"\n",
      "batch 4177  loss=119.7840  steps/s=63.94  prediction: \"@btwphones thanks! its going well so far\" => \"y_eine_   hh     nnn  sssuss u  n   llll\"\n",
      "batch 4178  loss=136.4226  steps/s=105.26  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er hna                   ttttttttttttt//\"\n",
      "batch 4179  loss=135.8863  steps/s=105.11  prediction: \" to ask \"show me every block below y=16\"\" => \"ah                                      \"\n",
      "batch 4180  loss=139.5660  steps/s=105.02  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"aututtta      u uutttttttttttttttttttttt\"\n",
      "batch 4181  loss=136.8058  steps/s=101.96  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et     ttttttooooooooooooooosssssssuuuuu\"\n",
      "batch 4182  loss=136.1344  steps/s=64.32  prediction: \"@yacineMTB so youre no longer locked in?\" => \"yazinllooo o ooooooooooo  ossssu  uuuu  \"\n",
      "batch 4183  loss=136.7062  steps/s=106.12  prediction: \"mul, transitions from one derivative toâ€¦\" => \"en em a iiiiiiiiiiiiiiiinn              \"\n",
      "batch 4184  loss=150.5717  steps/s=99.78  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" a                      tttttttttttttt//\"\n",
      "batch 4185  loss=128.8945  steps/s=101.15  prediction: \"ot a lot of sleep last night, feels good\" => \"u   eo                                  \"\n",
      "batch 4186  loss=135.8147  steps/s=106.83  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \"hlbe  aaaaa              ttt teell  e   \"\n",
      "batch 4187  loss=139.6439  steps/s=98.77  prediction: \"durr. the kings gambit. crazy mf opening\" => \" netet rrrrr   r                        \"\n",
      "batch 4188  loss=135.2598  steps/s=104.67  prediction: \"m scratch in numpy like i did w backprop\" => \"ett  t                                  \"\n",
      "batch 4189  loss=131.1742  steps/s=105.85  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" torinillllllll llllllllll,,,,,,,,,,tt  \"\n",
      "batch 4190  loss=134.5402  steps/s=104.14  prediction: \" instead of main https://t.co/K187NvFlSA\" => \"ts   sssss               tttttttt///////\"\n",
      "batch 4191  loss=132.0181  steps/s=104.61  prediction: \"d now your follower base is more aligned\" => \" ft            n   ooooooo              \"\n",
      "batch 4192  loss=120.0936  steps/s=103.30  prediction: \"ellite imagery onto the photos they took\" => \" sis seeeeeeeeeteeee          ttttttttto\"\n",
      "batch 4193  loss=122.5650  steps/s=92.86  prediction: \"hag_ its good to be on the outside again\" => \"et saataaa     t oooooo    o    tt t ooo\"\n",
      "batch 4194  loss=130.0884  steps/s=105.04  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly ees               eeeeeeeeennnneenuuu\"\n",
      "batch 4195  loss=165.2766  steps/s=101.94  prediction: \"expected him to be maybe 55 or something\" => \" p o                                    \"\n",
      "batch 4196  loss=139.4086  steps/s=102.52  prediction: \"t just means youre on par with a supergm\" => \"has  e sssssss s                        \"\n",
      "batch 4197  loss=139.2778  steps/s=104.92  prediction: \"' bc thats the name of the 4min mile guy\" => \"sa   e' tttttttttttt                    \"\n",
      "batch 4198  loss=132.1175  steps/s=67.33  prediction: \"@btwphones thanks! its going well so far\" => \"lresiettttttttt tt                      \"\n",
      "batch 4199  loss=138.1944  steps/s=110.39  prediction: \"it too\n",
      "its probably a good place idk tho\" => \"n  a   tttttt  t           oooo         \"\n",
      "batch 4200  loss=176.3647  steps/s=83.12  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"hsl t tiii      bb      t  ttoo  /    o \"\n",
      "batch 4201  loss=142.4094  steps/s=104.80  prediction: \"movie)\n",
      "\n",
      "Wifi mode when its high (gaming)\" => \"ets i     iiiiiiiiiiiiiiiiiiii          \"\n",
      "batch 4202  loss=149.3957  steps/s=106.57  prediction: \"e 10000x crazier than anything out there\" => \" iie aa  000000000            nnnnnn    \"\n",
      "batch 4203  loss=137.1630  steps/s=103.52  prediction: \"lad its helpful man, which did you read?\" => \"yn nicclllllllllllllll                  \"\n",
      "batch 4204  loss=127.9818  steps/s=102.14  prediction: \" people who find their work fun win more\" => \"@ron                                    \"\n",
      "batch 4205  loss=128.1061  steps/s=104.50  prediction: \"cially long term stuff,  makes it harder\" => \"hnte e                                  \"\n",
      "batch 4206  loss=133.8977  steps/s=106.13  prediction: \"er useful building block to get good at.\" => \"         uuuuuuuuuuuu                   \"\n",
      "batch 4207  loss=140.7835  steps/s=100.58  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \"hnn raennneeeeeneeeeeeeeeeeeeeettttttttt\"\n",
      "batch 4208  loss=231.4735  steps/s=103.73  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"  E UAAU            FFF           //////\"\n",
      "batch 4209  loss=145.0676  steps/s=103.49  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"epla: @eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 4210  loss=139.2953  steps/s=104.45  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"ea ate                           dd?????\"\n",
      "batch 4211  loss=128.9669  steps/s=105.38  prediction: \"tw, my b, but ill hop in on the next one\" => \" p s i                                  \"\n",
      "batch 4212  loss=174.8123  steps/s=97.30  prediction: \" 4am programming https://t.co/5THAY3txKR\" => \"t6rt m        m mmmmm m  tttttttttt/////\"\n",
      "batch 4213  loss=166.8418  steps/s=29.19  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"lyt s      mmmm mmmmmpp tttttt/t///////x\"\n",
      "batch 4214  loss=148.2631  steps/s=109.67  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"toe    a         ssssssssssssssttt//////\"\n",
      "batch 4215  loss=177.8401  steps/s=102.97  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"m b d iiiiiiiieeegggggg&&&&;;;;;;;gggggt\"\n",
      "batch 4216  loss=146.0060  steps/s=105.59  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" t o        eeeeeeeeee  ffffffffff     r\"\n",
      "batch 4217  loss=133.1402  steps/s=100.61  prediction: \"monstration purposes, i am not a heathen\" => \"eut ,ao       ooooooooosss              \"\n",
      "batch 4218  loss=126.9772  steps/s=106.05  prediction: \"you should do it, youd learn a ton i bet\" => \":u  s                                   \"\n",
      "batch 4219  loss=128.8449  steps/s=105.98  prediction: \"irl. So in irl it is probably not as bad\" => \"ne a           r       i                \"\n",
      "batch 4220  loss=168.8126  steps/s=103.29  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edeti @mmmmmmmm                  aaaaaaa\"\n",
      "batch 4222  loss=125.0223  steps/s=100.74  prediction: \"tony no but id be down rn for some games\" => \"  n aaerrrr                             \"\n",
      "batch 4223  loss=122.8819  steps/s=104.66  prediction: \"int as fast as possible on loop, idk tho\" => \"ngta             sssssssssssss  ooooo oo\"\n",
      "batch 4224  loss=144.2593  steps/s=100.54  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ng a           n           tttttttt/////\"\n",
      "batch 4225  loss=140.6323  steps/s=103.30  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyn @                                 \"\n",
      "batch 4226  loss=124.7095  steps/s=100.46  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"ttene eeeeeee  n                        \"\n",
      "batch 4227  loss=131.5238  steps/s=102.99  prediction: \"and completely unknown to the other half\" => \"td o     lllllllllll   nnnnnnn          \"\n",
      "batch 4228  loss=171.7470  steps/s=104.14  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \" ac ia         t                        \"\n",
      "batch 4229  loss=132.3038  steps/s=104.12  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o            m                        \"\n",
      "batch 4230  loss=134.9815  steps/s=105.16  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng  o          n                 uuuuuuu\"\n",
      "batch 4231  loss=135.4073  steps/s=102.13  prediction: \"g\n",
      "Especially the more complex things get\" => \"   o onooooooiilllllll     eeeeeee      \"\n",
      "batch 4232  loss=171.4476  steps/s=102.22  prediction: \"er did failed\n",
      "\n",
      "ðŸ“ˆ My hit rate is only abâ€¦\" => \"  r                                     \"\n",
      "batch 4233  loss=149.0576  steps/s=20.93  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly                                     \"\n",
      "batch 4234  loss=148.3923  steps/s=123.10  prediction: \"nally get monads\n",
      "https://t.co/lYN3cpV8JV\" => \"grTB e                tttttttttttt//////\"\n",
      "batch 4235  loss=124.3650  steps/s=104.15  prediction: \"veryone in the past was a caveman/moron\"\" => \"ery   eeeeeeeeeeee            aaaaaaaaaa\"\n",
      "batch 4236  loss=139.5686  steps/s=100.48  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \"    wl oooo    t                  oooooo\"\n",
      "batch 4237  loss=133.5737  steps/s=100.93  prediction: \" knowing linux is a massive weakness imo\" => \"tin onnnnnnnnnnnnnii               s sss\"\n",
      "batch 4238  loss=204.7071  steps/s=21.07  prediction: \"eply: @yacineMTB https://t.co/H0UMjZbPTA\" => \" ly: nnnnnnnnnniiii               ssssss\"\n",
      "batch 4239  loss=133.8129  steps/s=109.43  prediction: \"f scummy people getting more money/power\" => \" t inee        m   eeeeeeeeeee eeeeeeeee\"\n",
      "batch 4240  loss=132.9049  steps/s=105.77  prediction: \" on life event stuff\n",
      "- made progress onâ€¦\" => \"tf pr e    eeeeeeeeee                   \"\n",
      "batch 4241  loss=127.6699  steps/s=78.74  prediction: \"zmobly has selo made the circle tool yet\" => \"o b ee         ssss e    e      e r oooo\"\n",
      "batch 4242  loss=118.0339  steps/s=46.86  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @l e     l            e      e l oooo\"\n",
      "batch 4243  loss=128.1809  steps/s=108.21  prediction: \"iterate certain ppl, but those are large\" => \"neoao       tttttttt      tttt          \"\n",
      "batch 4244  loss=130.8084  steps/s=104.51  prediction: \"hink about a post before responding lool\" => \"es ie                           ooo oooo\"\n",
      "batch 4245  loss=131.2992  steps/s=104.06  prediction: \"x len output, custom system prompts, etc\" => \" mt  ee       uuuuuuuuuuuttttttmmmmmmmtt\"\n",
      "batch 4246  loss=140.3537  steps/s=99.68  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \" ly  yyyllllloolooo                     \"\n",
      "batch 4247  loss=127.7058  steps/s=103.81  prediction: \"dates/incentives to fund ai safety stuff\" => \"  l  aaaaaaaaeeeeeeeeeeennnn            \"\n",
      "batch 4248  loss=125.5073  steps/s=103.99  prediction: \"works for the first time is the most fun\" => \"hre   l        r                        \"\n",
      "batch 4249  loss=132.7564  steps/s=64.59  prediction: \"@Aryvyo use the api\n",
      "anthropic or bedrock\" => \"jux_er_rr      r      t i  tt           \"\n",
      "batch 4250  loss=140.9231  steps/s=108.45  prediction: \"ying/whatever, every monday and thursday\" => \":n oi/ggggggnnnnnneeeeeeeeeeeeeeeey  ddd\"\n",
      "batch 4251  loss=163.5632  steps/s=99.78  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \" ete i. t   e  eeee   nnnn   t/t////////\"\n",
      "batch 4252  loss=141.1142  steps/s=105.66  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"np (  rsss     t  ttttttttttttttttttttt/\"\n",
      "batch 4253  loss=140.5847  steps/s=105.42  prediction: \" kache who made dingboard w llms (afaik)\" => \"aii  is                                 \"\n",
      "batch 4254  loss=178.5507  steps/s=81.98  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"pne ll                 d           aaaaa\"\n",
      "batch 4255  loss=137.1027  steps/s=105.89  prediction: \" is actually happening behind the scenes\" => \"an ee           aaaaaaaaa      n        \"\n",
      "batch 4256  loss=126.7701  steps/s=103.96  prediction: \" linux like it hallucinated csgo or doom\" => \"ael allllllllll illlllliiiiiii          \"\n",
      "batch 4257  loss=133.4088  steps/s=105.02  prediction: \"ill you get better at as you practice it\" => \"nl bt                 tt                \"\n",
      "batch 4258  loss=137.5300  steps/s=103.57  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \"are  a        l            ttttttttt////\"\n",
      "batch 4259  loss=164.5511  steps/s=97.03  prediction: \"d @gizmobly @covix2772 store files in it\" => \" bu  olllllrooo @ooooo  tttoott227s  s  \"\n",
      "batch 4260  loss=128.9219  steps/s=98.61  prediction: \" it seems like a fire worth playing with\" => \"@s eieeeeeeeeeeleeee                    \"\n",
      "batch 4261  loss=129.9731  steps/s=103.82  prediction: \"n just build cool fun stuff all the time\" => \" t tet         u        uuuuuuu         \"\n",
      "batch 4262  loss=154.4447  steps/s=101.46  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" n   s                   sstttttccccccc/\"\n",
      "batch 4263  loss=140.1706  steps/s=98.81  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \" I @wMBB    eeeeeeeeeeeeeessssssssss  ss\"\n",
      "batch 4264  loss=118.1067  steps/s=59.44  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"@yu   Teeeeeeeeeeeeeeeesessssee       ss\"\n",
      "batch 4265  loss=133.5845  steps/s=119.37  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"e ly: @tttttt      eeee ee              \"\n",
      "batch 4266  loss=138.8376  steps/s=100.61  prediction: \"ts just showing you their main accts now\" => \"  ne t         tss                      \"\n",
      "batch 4267  loss=104.8978  steps/s=11.01  prediction: \"reply: @opaeoh ill lyk when i open it up\" => \"eply: @        ts                       \"\n",
      "batch 4268  loss=152.8534  steps/s=119.27  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n  ititttttmmmmiiiiiiiiizzzziiiiziii    \"\n",
      "batch 4269  loss=141.1153  steps/s=102.89  prediction: \"ding up the drive thru for 1000 episodes\" => \" nn B                             000000\"\n",
      "batch 4270  loss=260.3466  steps/s=96.48  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"whh o  t///////vhhhhhhhhhhhttttttt/oo//o\"\n",
      "batch 4272  loss=150.8096  steps/s=103.11  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"0kbu                     ttttttttttt////\"\n",
      "batch 4273  loss=132.6087  steps/s=105.19  prediction: \"did it again w feedback itd be the paper\" => \" fn  i dddd                             \"\n",
      "batch 4274  loss=136.7363  steps/s=103.73  prediction: \"g\n",
      "Especially the more complex things get\" => \"e; o inoooooooilllllll     eeeee        \"\n",
      "batch 4275  loss=139.1665  steps/s=103.19  prediction: \"well\n",
      "\n",
      "maxing it out is worth considering\" => \"hrk TPn        n                       i\"\n",
      "batch 4276  loss=137.9816  steps/s=105.85  prediction: \"2 and 3 forever\n",
      "\n",
      "https://t.co/4TGEKmEHO0\" => \" g r                  ee\n",
      "\n",
      "tttttttt//////\"\n",
      "batch 4277  loss=142.9344  steps/s=105.18  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \"  n     \n",
      "\n",
      "ss                            \"\n",
      "batch 4278  loss=140.9360  steps/s=101.26  prediction: \"pounds over time vs disappears instantly\" => \"lst @teeeee                     ss sssss\"\n",
      "batch 4279  loss=139.3209  steps/s=105.04  prediction: \"s it and im unaware (would love to know)\" => \" a os                                   \"\n",
      "batch 4280  loss=125.1578  steps/s=102.02  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"eryil ii                         iiiiiii\"\n",
      "batch 4281  loss=140.0104  steps/s=102.38  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \".i   le.   eeeee            ttttttt/////\"\n",
      "batch 4282  loss=176.7848  steps/s=80.60  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"     ee                 ttttt////PPPPooo\"\n",
      "batch 4283  loss=135.4310  steps/s=106.50  prediction: \"g/take a break from dopamine-exhaustingâ€¦\" => \" t so e     aaa aaaa   aaaaaaa aaaaaaaaa\"\n",
      "batch 4284  loss=141.0449  steps/s=98.09  prediction: \"n pulls models too, but only from github\" => \" a ee n             ooooooooooooooo     \"\n",
      "batch 4285  loss=137.1069  steps/s=102.13  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"e@ly:          eeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 4286  loss=130.7119  steps/s=98.09  prediction: \"ld me, no clue lool\n",
      "\n",
      "its good to be back\" => \"y  @r eeee             llloloooooooooooo\"\n",
      "batch 4287  loss=136.5608  steps/s=103.79  prediction: \"y cool implications, seems like it would\" => \":I toe         c iiiiiiiiiiiisssiii     \"\n",
      "batch 4288  loss=140.9215  steps/s=102.38  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"toog  g        e                        \"\n",
      "batch 4289  loss=151.7486  steps/s=104.36  prediction: \"for whatever they click on,play it w VLC\" => \" r taleoooeeeeeteeeeeeeee               \"\n",
      "batch 4290  loss=147.5569  steps/s=99.37  prediction: \"n @grapplingdev HA i love it, lets do it\" => \"gbe eeeaeaaaaaanaaa                     \"\n",
      "batch 4291  loss=180.5283  steps/s=47.36  prediction: \"y: @arithmoquine https://t.co/Aj4WZoykKU\" => \": @nbeaaaaaaaaann                       \"\n",
      "batch 4292  loss=159.0375  steps/s=135.52  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \" s @a aaaieee                      AAAAE\"\n",
      "batch 4293  loss=127.9311  steps/s=102.72  prediction: \"entation, the cooler everything will get\" => \" et   tttttttttttttoooeeeeeeeeeeeeeeeeee\"\n",
      "batch 4294  loss=127.9676  steps/s=105.57  prediction: \"st powerful learning techniques there is\" => \"  s t                  eeeennnnnneeeeeee\"\n",
      "batch 4295  loss=257.7819  steps/s=97.20  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \" GOe s.EEEEEE   AAA RRR tttttttttttt////\"\n",
      "batch 4297  loss=143.3363  steps/s=94.97  prediction: \"oull just be on his midbie goats list dw\" => \" g.                           i  ii  ii \"\n",
      "batch 4298  loss=133.3221  steps/s=104.67  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"to  t                        ttttt//////\"\n",
      "batch 4299  loss=156.4783  steps/s=102.00  prediction: \"??\n",
      "\n",
      "oh wow it is https://t.co/dShiVDjfFr\" => \"\n",
      " vo  w??????wwowww          tttt///////\"\n",
      "batch 4300  loss=130.3907  steps/s=103.89  prediction: \"and then pivot to doing a project in zig\" => \"n   i d                                 \"\n",
      "batch 4301  loss=129.3399  steps/s=103.95  prediction: \" resulting in a cool, weird type of game\" => \"tetae reeeeeee n                        \"\n",
      "batch 4302  loss=135.6452  steps/s=103.63  prediction: \" end of chess, just like everyone feared\" => \"tas                sssss     eeeeeeeeeee\"\n",
      "batch 4303  loss=183.9668  steps/s=10.94  prediction: \"reply: @calbach_ https://t.co/Gyx4pLqxKX\" => \"e ly             ssssss     eeeeeeeeeeee\"\n",
      "batch 4304  loss=142.6180  steps/s=110.14  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nk oe\n",
      " eeeeeee e                        \"\n",
      "batch 4305  loss=137.7936  steps/s=104.30  prediction: \"acked spends their time on fb linked etc\" => \"nk  ao oooo   dddd                      \"\n",
      "batch 4306  loss=151.1628  steps/s=98.25  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"teu                      t tttttt///////\"\n",
      "batch 4307  loss=158.3946  steps/s=104.99  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"trc ot ////////ttttttttttttt////////////\"\n",
      "batch 4308  loss=128.2780  steps/s=105.49  prediction: \"you can get a stronger 'muscle' for this\" => \" u  hoh                                 \"\n",
      "batch 4309  loss=135.9811  steps/s=105.58  prediction: \"to the planning phase with more momentum\" => \"hri ea         n nnnnnnnn             mm\"\n",
      "batch 4310  loss=130.1669  steps/s=105.29  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"aoee                                    \"\n",
      "batch 4311  loss=128.2373  steps/s=105.22  prediction: \"s w java and python and studying for fun\" => \" a tts                                  \"\n",
      "batch 4313  loss=128.3726  steps/s=103.80  prediction: \"it seems like using a spoon vs a scalpel\" => \"n   a          e                        \"\n",
      "batch 4314  loss=134.7300  steps/s=105.12  prediction: \"to rename all my .txt files to md though\" => \"  t e                                   \"\n",
      "batch 4315  loss=140.3428  steps/s=52.45  prediction: \": @moh1xabc i cooked so hard i burned it\" => \" @a ne m       m                        \"\n",
      "batch 4316  loss=137.1079  steps/s=106.43  prediction: \"r reward, wrecking the incentive to work\" => \"eiec e eeeerrrrrrrrrrrr       eeeeee    \"\n",
      "batch 4317  loss=155.1884  steps/s=69.51  prediction: \"helscom a new $500k logo should fix this\" => \"eyeweerrr rrr  ww             e         \"\n",
      "batch 4319  loss=130.7207  steps/s=113.07  prediction: \"almost as bad as jan blocking his bishop\" => \"n  rl llll           aa              iii\"\n",
      "batch 4320  loss=179.7998  steps/s=30.73  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @llllssa aa  aaaaaa              iii\"\n",
      "batch 4322  loss=130.7007  steps/s=107.76  prediction: \"it got like 2x fps rendering ocean waves\" => \"n   w                         eeeeeeeeee\"\n",
      "batch 4324  loss=145.1602  steps/s=38.47  prediction: \"ly: @ludwigABAP Its a good hivemind, sir\" => \"y                       eee  eeeeenn eee\"\n",
      "batch 4325  loss=134.6113  steps/s=112.01  prediction: \" I gotta make the disc announcement oops\" => \"t ot th                              nnn\"\n",
      "batch 4326  loss=149.0271  steps/s=100.67  prediction: \"an!\n",
      "Gpt 4o came in clutch for the images\" => \"n  ooo         m            cc          \"\n",
      "batch 4327  loss=108.2844  steps/s=21.39  prediction: \"eply: @visakanv The attack of the clowns\" => \" ly: @a        m        c               \"\n",
      "batch 4328  loss=202.5482  steps/s=136.28  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"oee s  GGGGG!!!!!!!!!!!!OO              \"\n",
      "batch 4329  loss=159.8776  steps/s=95.26  prediction: \"builds 2012 but yet blunders mate in one\" => \"et_I Nbbbb   0 2222 2                   \"\n",
      "batch 4330  loss=137.6048  steps/s=100.01  prediction: \"Building scratch from scratch in scratch\" => \" y iuliiii                crrcccc       \"\n",
      "batch 4331  loss=127.9453  steps/s=105.10  prediction: \" good at developing your own techniquesâ€¦\" => \"testere        o o  ooooooooooo         \"\n",
      "batch 4332  loss=141.1025  steps/s=103.86  prediction: \" been some adventure man. God bless him.\" => \"tuee  eeeeeeeeeeeeeeeeeeeeee            \"\n",
      "batch 4333  loss=137.6578  steps/s=104.52  prediction: \"t 200hrs in around the same time you did\" => \" oeo           t                        \"\n",
      "batch 4334  loss=142.8020  steps/s=103.02  prediction: \"pression contest\n",
      "https://t.co/bLEHGWjFSr\" => \"lo  @    oooooooossstttttttttttttt//////\"\n",
      "batch 4335  loss=142.5693  steps/s=103.72  prediction: \"leneck is my lack of knowledge of opengl\" => \"ys uteetteeee  t                    oooo\"\n",
      "batch 4336  loss=139.5085  steps/s=102.74  prediction: \"ike a combinatoric sized pain in the ass\" => \"ne  o               iiiiiiiiiiiiiiiii   \"\n",
      "batch 4337  loss=131.5553  steps/s=104.46  prediction: \"erscores the importance of curating andâ€¦\" => \" -n e eeeeeeeee eeeeeeeee               \"\n",
      "batch 4338  loss=121.4632  steps/s=97.95  prediction: \"hnote uuuh i have a license for thse sir\" => \"es e etstttuuuuhuh                      \"\n",
      "batch 4339  loss=144.5454  steps/s=102.54  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"neai       aaaaaaaaatttttttttttttt//////\"\n",
      "batch 4341  loss=135.5851  steps/s=103.88  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t    a         r                        \"\n",
      "batch 4342  loss=142.1104  steps/s=103.21  prediction: \"coordinates are busted\n",
      "just buy new ones\" => \"enta  aaaaaaaaaraaaaaaeeeeeeesss        \"\n",
      "batch 4343  loss=136.2880  steps/s=97.66  prediction: \"he stopped existing after the last frame\" => \"e  go nnn      eeeee             tttt   \"\n",
      "batch 4344  loss=130.5129  steps/s=105.13  prediction: \"ed hard at improving, mostly by studying\" => \"  y            r                      yy\"\n",
      "batch 4345  loss=150.9870  steps/s=101.39  prediction: \"he making a dingboard clone or something\" => \"e   ogg                              ooo\"\n",
      "batch 4346  loss=128.7872  steps/s=104.62  prediction: \"good idea but whatever, i wanna have fun\" => \" o fni                           aaaaaaa\"\n",
      "batch 4347  loss=151.1550  steps/s=104.23  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"oodty      UU      ttttttttttttttt//////\"\n",
      "batch 4348  loss=133.3841  steps/s=103.41  prediction: \"ably do this for all future projects tbh\" => \"te  o  ll                               \"\n",
      "batch 4349  loss=131.2630  steps/s=102.23  prediction: \"ce for an american traveling there soon?\" => \"o a it          aaaaaaaaaaaaaaaaneeeeeee\"\n",
      "batch 4350  loss=131.7424  steps/s=104.98  prediction: \"resent them in (i.e. \"jimmy shot a ballâ€¦\" => \"eplewt  eeeeeeet                        \"\n",
      "batch 4351  loss=178.5427  steps/s=66.44  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"anzsileeeeeeee   ee     mm ....         \"\n",
      "batch 4352  loss=132.3184  steps/s=107.00  prediction: \"ideo of you doing some crazy stuff. damn\" => \"n  i o            oooooooo              \"\n",
      "batch 4353  loss=143.6015  steps/s=104.44  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"to.cssst/////////ttttttttttt/////////PPP\"\n",
      "batch 4354  loss=132.6852  steps/s=105.03  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"er   i           eeeeeee                \"\n",
      "batch 4355  loss=132.3082  steps/s=104.96  prediction: \"il of the recall/visualization over time\" => \"nl ne                llllllllllliiiiiiii\"\n",
      "batch 4356  loss=131.4998  steps/s=105.23  prediction: \"ting your axioms can bring immense alpha\" => \"hn  e eaaaaaaaaaaaaaa                   \"\n",
      "batch 4357  loss=131.7963  steps/s=104.18  prediction: \" fast eventually. i know this from chess\" => \"aud s  sss  eeeeee                      \"\n",
      "batch 4358  loss=130.6970  steps/s=104.32  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"a   o             tttttttttttttttt//////\"\n",
      "batch 4359  loss=126.6437  steps/s=105.27  prediction: \" to ignore such gaps in order to make aâ€¦\" => \"to bs          n                        \"\n",
      "batch 4360  loss=198.8513  steps/s=10.80  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"e laa                                   \"\n",
      "batch 4361  loss=141.5971  steps/s=110.22  prediction: \"is here, line 7: https://t.co/72Mt9DfH09\" => \"n \n",
      "  p                       :::ttt/////\"\n",
      "batch 4362  loss=146.8791  steps/s=103.97  prediction: \" pre session lift make a difference btw?\" => \"tr e     ssssss sss               eeeeee\"\n",
      "batch 4363  loss=156.6879  steps/s=101.34  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \" pa eaeeeeeolllollllllooooooooott///////\"\n",
      "batch 4364  loss=137.0168  steps/s=99.56  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"epg                      ttttttt////////\"\n",
      "batch 4365  loss=152.5015  steps/s=103.65  prediction: \"o make rlly complex interactive web apps\" => \"ua  s                        eeeeeeeeeee\"\n",
      "batch 4366  loss=141.3704  steps/s=106.65  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "y  i t        n                        \"\n",
      "batch 4367  loss=163.9740  steps/s=101.15  prediction: \"TB cant even ðŸ˜­ because no fluid dynamics\" => \"h s   aaa              e                \"\n",
      "batch 4368  loss=133.9178  steps/s=103.54  prediction: \"ploring become really clear to your mind\" => \"ly: @ ae       eeeeeeeeeeellllllll      \"\n",
      "batch 4369  loss=132.8096  steps/s=104.24  prediction: \"lped me too yrs ago. very inspiring dude\" => \"yy @oeeeeeeeeees                      ii\"\n",
      "batch 4370  loss=143.0647  steps/s=100.35  prediction: \" lol positive feedback loops are awesome\" => \"tee ea  ooooooo    eeeeeeeeee         ee\"\n",
      "batch 4373  loss=184.7262  steps/s=23.71  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly:   oooooo    eeeeeeeeee o        eee\"\n",
      "batch 4374  loss=127.1495  steps/s=124.56  prediction: \"what overlaps stand out to you the most?\" => \"had  anetttt       aa                   \"\n",
      "batch 4375  loss=139.4306  steps/s=103.89  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"ndnt teaaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 4376  loss=130.2109  steps/s=104.11  prediction: \"no responses or just \"cool!\" Or whatever\" => \" wiee t        n  ssssssssoooooo        \"\n",
      "batch 4377  loss=160.6622  steps/s=104.75  prediction: \" possible the true x for elon is 42,069x\" => \"tom   sssssssss                         \"\n",
      "batch 4378  loss=130.9163  steps/s=103.29  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \" e  rot   eeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 4379  loss=134.6725  steps/s=102.73  prediction: \"nt and then generate a new one each time\" => \"  s r e       nnnnnneeeeeeeeeeeeeeeee e \"\n",
      "batch 4380  loss=136.2712  steps/s=59.20  prediction: \" @llamapuckey never visit sf without jug\" => \"tLrm   aaa neneneneeeeeee               \"\n",
      "batch 4381  loss=148.5321  steps/s=106.06  prediction: \"high quality patches they send to FFmpeg\" => \"es  o  hhhhhh                           \"\n",
      "batch 4382  loss=187.4372  steps/s=36.42  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly::@l  hhh      hhtthht  t             \"\n",
      "batch 4383  loss=132.2384  steps/s=107.37  prediction: \"t them as axioms, and it screws you over\" => \" tt   t t                               \"\n",
      "batch 4384  loss=133.4064  steps/s=100.33  prediction: \"or always posting these, they're great ðŸ‘\" => \"u eaaasaaa    ss     ssss      eeeeeeeee\"\n",
      "batch 4385  loss=155.5200  steps/s=102.77  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"/.SottSt/////////ttttttttttt///////////Y\"\n",
      "batch 4386  loss=134.2589  steps/s=104.55  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hrs ibiiiiiiiiiiiiitttttttttttttttttt///\"\n",
      "batch 4387  loss=144.3244  steps/s=105.45  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \"nb                         tttt/////////\"\n",
      "batch 4388  loss=137.0942  steps/s=103.47  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" t to t         aaaaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaaaaagggg\"\n",
      "batch 4389  loss=154.0887  steps/s=100.11  prediction: \"sonnet 3.5v2 its amazing for programming\" => \" rn o                   aaaaiii   rrrrrr\"\n",
      "batch 4390  loss=149.9915  steps/s=103.40  prediction: \" I'm super down for another one thursday\" => \"t   !  !!      s                        \"\n",
      "batch 4391  loss=129.7250  steps/s=100.91  prediction: \"ably do this for all future projects tbh\" => \"nlI!  l                                 \"\n",
      "batch 4392  loss=144.7681  steps/s=105.70  prediction: \"ard players used to get through the race\" => \"net    aaaaaaaaeee                      \"\n",
      "batch 4393  loss=126.7419  steps/s=104.89  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"n       ooooooo                       ss\"\n",
      "batch 4394  loss=136.1504  steps/s=103.46  prediction: \"e go all the blindfold web dev positions\" => \" w am          l   lllllllll           i\"\n",
      "batch 4395  loss=128.1799  steps/s=105.12  prediction: \"have become too big and are rotting away\" => \"et   ne eeeeeee ee                      \"\n",
      "batch 4396  loss=136.5112  steps/s=106.03  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" ellleleeeeeeeeeeeeeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttt////////\"\n",
      "batch 4397  loss=130.3112  steps/s=106.72  prediction: \"orthless. you find the gold when you dig\" => \" ed  eessssssssssss                     \"\n",
      "batch 4398  loss=132.1507  steps/s=106.08  prediction: \"ng and figure out which freqs i care abt\" => \"  ato                                   \"\n",
      "batch 4399  loss=135.8422  steps/s=20.95  prediction: \"eply: @mynamebedan head completely empty\" => \" ly: a                                  \"\n",
      "batch 4400  loss=143.1315  steps/s=123.05  prediction: \"d you man. Yea whenever you can do join!\" => \" is                    eeeeeeeee        \"\n",
      "batch 4401  loss=135.6207  steps/s=105.47  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" aoe           s   ssssssssss ssssss    \"\n",
      "batch 4402  loss=149.9321  steps/s=104.69  prediction: \"\n",
      "\"runit\"\n",
      "\n",
      "almost never have to modify it\" => \"\n",
      "\"s   o\"\"\"\"\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttt           \"\n",
      "batch 4403  loss=133.3549  steps/s=104.56  prediction: \"tll program all my ML experiments for me\" => \"hee            t  lll                   \"\n",
      "batch 4404  loss=141.1105  steps/s=100.59  prediction: \"ded something to edit gifs/clips quickly\" => \" ra      e eee m   e       iiiiii iiiiii\"\n",
      "batch 4405  loss=163.3113  steps/s=89.95  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"oop n         o    t tt ttttt///////cccF\"\n",
      "batch 4406  loss=135.7153  steps/s=102.61  prediction: \" literally can\n",
      "not good for computer tho\" => \"tia o                l   ooooooooooooooo\"\n",
      "batch 4407  loss=134.6914  steps/s=105.07  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"nl yoe                                  \"\n",
      "batch 4408  loss=132.0329  steps/s=105.55  prediction: \", how do WE figure out where things are?\" => \" too i                                  \"\n",
      "batch 4409  loss=131.6498  steps/s=99.31  prediction: \"new following you was the right decision\" => \" ro           ww wwwww                  \"\n",
      "batch 4410  loss=192.9791  steps/s=28.82  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: @     wwwww  www                    \"\n",
      "batch 4411  loss=163.4165  steps/s=113.44  prediction: \" 4min miles, need to know whats possible\" => \"t8t ih                                  \"\n",
      "batch 4412  loss=154.7497  steps/s=12.51  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"eply: @                                s\"\n",
      "batch 4413  loss=119.6573  steps/s=112.20  prediction: \"g us to blow our fears out of proportion\" => \" tw et                          oooooooo\"\n",
      "batch 4414  loss=143.4589  steps/s=104.90  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"em n                                    \"\n",
      "batch 4415  loss=124.2372  steps/s=46.30  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \": @La                 n nn              \"\n",
      "batch 4416  loss=204.9709  steps/s=118.07  prediction: \"RAFT clone?????? https://t.co/LpT9VeD8p0\" => \"T @aaa        ?????????????tttttt/t/////\"\n",
      "batch 4417  loss=147.9959  steps/s=99.79  prediction: \"minds me of this https://t.co/Qoy9ykJ35M\" => \"enex  cooo              tttttt/////////9\"\n",
      "batch 4418  loss=141.5219  steps/s=101.55  prediction: \"ight go back to ML stuff instead of this\" => \"nheai          t                        \"\n",
      "batch 4419  loss=131.5549  steps/s=102.01  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: e ssssseeeelnll lllnnllllllllllllllle\"\n",
      "batch 4420  loss=138.3564  steps/s=104.06  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"  i  aaaa      t               eeeeeeeee\"\n",
      "batch 4421  loss=164.1238  steps/s=81.76  prediction: \"x140201 @teodor_io start with the Gospel\" => \"pr ptg           ttoo       ttttt ttt  e\"\n",
      "batch 4423  loss=126.3067  steps/s=105.75  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"te          aa eeeeeeeee                \"\n",
      "batch 4424  loss=119.7641  steps/s=103.08  prediction: \"ink thats gonna be a massive rabbit hole\" => \"ng n   ttttttttt               aaaabbbbb\"\n",
      "batch 4425  loss=138.3151  steps/s=105.22  prediction: \"n X and see people dropping crazy things\" => \" hir               eeeeppppppppppp      \"\n",
      "batch 4426  loss=137.1764  steps/s=104.76  prediction: \"soned wine games https://t.co/9edvpSK4pr\" => \"    t          e              tttt//////\"\n",
      "batch 4427  loss=132.4106  steps/s=100.02  prediction: \"ndustries\n",
      "Currently building semi public\" => \"  ro d niiiiiiirrrrrrrrrrrrriiiiiiiiiiii\"\n",
      "batch 4428  loss=138.1958  steps/s=104.90  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"n  n           aaaaaaaaaaa              \"\n",
      "batch 4430  loss=139.4964  steps/s=95.50  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"enly: @ oo           ttttttttttttt//////\"\n",
      "batch 4431  loss=152.3058  steps/s=103.80  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"e  p  o             ss???????tttt///////\"\n",
      "batch 4432  loss=142.8388  steps/s=102.76  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"enly:e        eeeeeeeeeeeeeeettttt//////\"\n",
      "batch 4433  loss=143.9546  steps/s=98.83  prediction: \" job adding the australian language pack\" => \"tu n t                 aaaaaaaaaaaaaaaaa\"\n",
      "batch 4434  loss=133.4384  steps/s=103.59  prediction: \"urself, if you can manage to pull it off\" => \"n  ee l                                 \"\n",
      "batch 4437  loss=144.3531  steps/s=101.50  prediction: \"meone should make a zig finetune dataset\" => \"e e y yoooooooooooo                   ee\"\n",
      "batch 4438  loss=129.9413  steps/s=21.60  prediction: \"eply: @Nominus9 a unicorn would fix tpot\" => \" ly: @ooooooooom                     eee\"\n",
      "batch 4439  loss=140.6965  steps/s=134.69  prediction: \"h @tsoding Musializer looked pretty cool\" => \"etesa sssssssssn ssiiiiiiiiiil  eeeeeett\"\n",
      "batch 4440  loss=127.0484  steps/s=104.39  prediction: \"be distracted for longer periods of time\" => \"l            dddddd        rrrrrrrrrr   \"\n",
      "batch 4441  loss=137.2542  steps/s=102.38  prediction: \"king useful things, so it didnt work out\" => \"ena                                     \"\n",
      "batch 4442  loss=132.2387  steps/s=99.27  prediction: \"ded something to edit gifs/clips quickly\" => \" rli ieeeeeeeeeneeeee     iiiiiii iiiiii\"\n",
      "batch 4443  loss=134.4660  steps/s=79.61  prediction: \"minus9 This is my new favorite edm track\" => \"eni e eeeiin                iiiiiiiii   \"\n",
      "batch 4444  loss=195.9007  steps/s=109.19  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"tanesnnn       OOOOO!!!!!!!!            \"\n",
      "batch 4445  loss=140.6332  steps/s=99.40  prediction: \"hdaily how does it compare to 100m leads\" => \"e Es  lllllllllloooooo                  \"\n",
      "batch 4446  loss=129.6674  steps/s=105.93  prediction: \"s called it tho, dont practice deception\" => \" t  t                       tttt   ccccc\"\n",
      "batch 4447  loss=132.7193  steps/s=104.24  prediction: \"t info, hence why I expanded past papers\" => \" st rah                                 \"\n",
      "batch 4448  loss=129.5906  steps/s=106.07  prediction: \"d size to whatever you want which helps.\" => \" ti o                               hhhh\"\n",
      "batch 4449  loss=140.4208  steps/s=101.56  prediction: \"h i dont remember getting much out of it\" => \"eCedee i     eedeeeeeeeeeeeeeeee        \"\n",
      "batch 4450  loss=132.7376  steps/s=65.50  prediction: \"@codyaims 113 bots liked this one so far\" => \"aac1402d      11  e eeee eee            \"\n",
      "batch 4451  loss=129.3369  steps/s=105.06  prediction: \"new super super early on she was the one\" => \" M rti         r  eeeeee                \"\n",
      "batch 4452  loss=137.8277  steps/s=105.09  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"4o od  i       p     oo                 \"\n",
      "batch 4453  loss=128.2850  steps/s=104.12  prediction: \"cond while avoiding exhausting the first\" => \"hsli           e     iiiiiiiiiiiiiiiiiii\"\n",
      "batch 4454  loss=143.6150  steps/s=104.52  prediction: \"thought I would\n",
      "\n",
      "Now, I shall take tomoâ€¦\" => \"ha  e                  IIII             \"\n",
      "batch 4455  loss=131.2705  steps/s=102.80  prediction: \"n to achieve an awesome long term vision\" => \" to a aaaaa    aaaaaaae   e eee eeeee   \"\n",
      "batch 4456  loss=133.4114  steps/s=104.90  prediction: \"divide the softmax by sqrt(dk) type beat\" => \" nsto iiiiiiiiiei                       \"\n",
      "batch 4457  loss=141.5310  steps/s=105.43  prediction: \"future wife, dayum\n",
      "\n",
      "happy for you brotha\" => \" nn dwu u                     yyyyyyy   \"\n",
      "batch 4458  loss=123.6556  steps/s=54.47  prediction: \": @archived_videos definitely the latter\" => \" @lidwu ueeeeed e de   yyfyyyyyyy     aa\"\n",
      "batch 4459  loss=153.6381  steps/s=108.84  prediction: \"ning curve so I can make cool stuff w it\" => \" t te          n                        \"\n",
      "batch 4460  loss=125.9625  steps/s=100.75  prediction: \"ood at noticing things, would be so kino\" => \" k  ttgtttttttttttttttiiiiiii           \"\n",
      "batch 4461  loss=133.3228  steps/s=107.60  prediction: \"re you need to make a sphere version now\" => \"eply: @     e                          e\"\n",
      "batch 4462  loss=131.6490  steps/s=105.42  prediction: \"ered into something super super powerful\" => \" esre t        e                   eeeee\"\n",
      "batch 4463  loss=129.4778  steps/s=104.34  prediction: \" from that channel/vid to that x account\" => \"tr   al        a  aaa        ttttt      \"\n",
      "batch 4464  loss=137.2499  steps/s=105.04  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nnaa   nnnnnmmm mmmmmmmmmmm             \"\n",
      "batch 4465  loss=130.1487  steps/s=104.21  prediction: \" the ladder on what strats are possible.\" => \"thet                                  ss\"\n",
      "batch 4466  loss=134.8451  steps/s=102.52  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"eow         oootoo                    tt\"\n",
      "batch 4468  loss=136.0289  steps/s=105.03  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "oon ws uuuuuuutttttt                   \"\n",
      "batch 4469  loss=124.9951  steps/s=105.65  prediction: \"rself or others interested in something?\" => \"eot oy     oooor   rrrreeeeeeeeeeeeeeeee\"\n",
      "batch 4470  loss=137.2606  steps/s=94.79  prediction: \"mannak Duh they used the hydraulic press\" => \"eneo ro o      n    eeeeeee       hh  ii\"\n",
      "batch 4472  loss=134.9535  steps/s=97.96  prediction: \"vinwylde the r in rgb stood for retarded\" => \"e  nSaaee eeee n                    rrrr\"\n",
      "batch 4473  loss=150.9135  steps/s=29.92  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @HSeeeeeee                     rrrrr\"\n",
      "batch 4475  loss=149.3816  steps/s=108.88  prediction: \"ke half my followers came from shoutouts\" => \"e    llllllllllllllllll             oooo\"\n",
      "batch 4477  loss=134.8893  steps/s=104.49  prediction: \"nomic than discord id switch immediately\" => \"tthe e         n             iiiiiiiiiii\"\n",
      "batch 4478  loss=147.4865  steps/s=104.57  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"  s /t:t////////hhhhhtttttttt/////////tt\"\n",
      "batch 4479  loss=147.6094  steps/s=104.83  prediction: \"you have ffmpeg installed on your system\" => \" u teett       t                        \"\n",
      "batch 4480  loss=123.2822  steps/s=48.29  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \"  @te t                a            yyy \"\n",
      "batch 4481  loss=133.1559  steps/s=108.75  prediction: \"ut from having 1/3rd the progress per hr\" => \"s                              rrrrrrrrr\"\n",
      "batch 4482  loss=130.6811  steps/s=104.70  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" \"  o                   eeeeeeeeeeeeeeee\"\n",
      "batch 4483  loss=133.8946  steps/s=101.66  prediction: \" bricked my laptop\n",
      "patronizing bloatware\" => \"te   ee              pppppppppppppaaaaaa\"\n",
      "batch 4484  loss=169.4039  steps/s=103.57  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e   iii#########aaaaaaaaaasssssss///////\"\n",
      "batch 4485  loss=135.6124  steps/s=100.25  prediction: \"eed\n",
      "\n",
      "Trust is our most valuable resource\" => \" dn:eddddddeeees                        \"\n",
      "batch 4486  loss=128.5016  steps/s=100.49  prediction: \" tool yet tho. selo has circle supremacy\" => \"toe                                    c\"\n",
      "batch 4487  loss=128.8638  steps/s=106.15  prediction: \"t your iq has to be under 70 or over 170\" => \" sute t        t                        \"\n",
      "batch 4488  loss=128.9530  steps/s=97.12  prediction: \"uters. i dont like those tbh. weird shit\" => \"t i            t                        \"\n",
      "batch 4489  loss=136.2135  steps/s=101.99  prediction: \"ve feedback loop\n",
      "https://t.co/SvrkOEyyVo\" => \"en o itiieeeeeeeeeeeeeppppttttttttt/////\"\n",
      "batch 4490  loss=224.5688  steps/s=78.46  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"lxneneeeeeeee   ootppppptttt/OOOOOOOOOOO\"\n",
      "batch 4491  loss=140.7751  steps/s=106.18  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" to  gnannnnnnn nnnneeeeeeettttttt//////\"\n",
      "batch 4492  loss=138.3136  steps/s=105.87  prediction: \"e transformer architecture works so well\" => \" ann            rrrrrrrrrrrrrrrrrrrrrrr \"\n",
      "batch 4493  loss=209.0602  steps/s=95.81  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/.co hhtt////rrrrRRRttttttttttttts///oto\"\n",
      "batch 4494  loss=137.3167  steps/s=101.73  prediction: \"to fall back on. build stuff on the side\" => \" no//t                                  \"\n",
      "batch 4495  loss=152.3038  steps/s=104.38  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"agd oru@      AAAABBBBBB                \"\n",
      "batch 4496  loss=139.3504  steps/s=104.69  prediction: \"e a dog\n",
      "\n",
      "thats how i feel abt it anyways\" => \" a l                                    \"\n",
      "batch 4497  loss=119.2069  steps/s=72.15  prediction: \"sunsettler hes locked in to the outdoors\" => \" a d        t                      t   t\"\n",
      "batch 4499  loss=146.7697  steps/s=111.57  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \" l : @leeeeeeeee  e   tttttttttttttttt//\"\n",
      "batch 4500  loss=125.8714  steps/s=102.96  prediction: \"d hire my friends to do research with me\" => \" oo o                                   \"\n",
      "batch 4501  loss=136.1873  steps/s=104.63  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"n  s          ieiiiiittttttttttttttttt//\"\n",
      "batch 4502  loss=124.4613  steps/s=99.76  prediction: \"er this applies outside of chess as well\" => \" s :s steetttiiniitpsssstsssssosdssdssss\"\n",
      "batch 4503  loss=131.8166  steps/s=105.25  prediction: \"o get those kinds of sessions more often\" => \" l                       sssssssssssssss\"\n",
      "batch 4505  loss=138.0003  steps/s=104.69  prediction: \"o you get more data) or hit a \"dampener\"\" => \" g o  oo                                \"\n",
      "batch 4506  loss=152.5586  steps/s=100.31  prediction: \"a little weirder https://t.co/dcbD9IdKyf\" => \"ns tt.....iiii    ttttttttttttttttttt///\"\n",
      "batch 4507  loss=144.6724  steps/s=102.24  prediction: \"allenge\n",
      "however: https://t.co/TzbAuUlGIG\" => \"n  ouu          eeeeeeeee:::::://///////\"\n",
      "batch 4508  loss=146.9879  steps/s=102.76  prediction: \"y i havent had many problems with it tbh\" => \":t  le                                  \"\n",
      "batch 4509  loss=134.3915  steps/s=106.22  prediction: \"cool ML/studying/building posts are gone\" => \"ompee           oooooouiiiiiiiiiiiiiiggg\"\n",
      "batch 4510  loss=128.5847  steps/s=103.90  prediction: \"t progress/mistakes made/lessons learned\" => \" wt e    rrrrsssssssssssssssssssssssssee\"\n",
      "batch 4511  loss=135.3271  steps/s=96.77  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n  AP AAssssss s                        \"\n",
      "batch 4512  loss=135.0839  steps/s=103.23  prediction: \"ay simpler, but also much more effective\" => \"l   t          n                        \"\n",
      "batch 4514  loss=133.4009  steps/s=102.20  prediction: \"h\n",
      "Also good to know abt the muting thing\" => \"ev io     oooooooooooooooo            tt\"\n",
      "batch 4515  loss=137.4521  steps/s=99.10  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"@ok       nnnnnonnnooooooooooo          \"\n",
      "batch 4516  loss=142.6501  steps/s=104.63  prediction: \"st surgery, without painkillers\n",
      "\n",
      "i kneel\" => \"  so s sssssss             iiiiiiiiiiiii\"\n",
      "batch 4517  loss=127.1465  steps/s=103.51  prediction: \"e are, so it has a ton of ripple effects\" => \" t u aa                                f\"\n",
      "batch 4518  loss=189.7802  steps/s=98.75  prediction: \"rs: John 14:6-14 https://t.co/37ryh1InfG\" => \"e  yte@sssss        111:444tttttttttttt/\"\n",
      "batch 4519  loss=179.6563  steps/s=10.65  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"ep yte@ssss        1111:44ttttttttttttt/\"\n",
      "batch 4520  loss=133.4993  steps/s=107.99  prediction: \"learn and have fun building baller stuff\" => \"yve   r                             llll\"\n",
      "batch 4521  loss=123.5339  steps/s=105.00  prediction: \"ming world models, and also trusting you\" => \"ene vo                  dd              \"\n",
      "batch 4522  loss=137.1032  steps/s=100.60  prediction: \"e. I can teach you a bit too if you want\" => \"   :a                                   \"\n",
      "batch 4523  loss=162.8908  steps/s=79.04  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"en  o     aaaaa   a       o     oo o  oo\"\n",
      "batch 4524  loss=138.6325  steps/s=66.96  prediction: \" @pr0timr @btwphones Will post once done\" => \"tla aa    aaa     a       o    oooooonoðŸ›‘\"\n",
      "batch 4525  loss=145.6770  steps/s=111.52  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" a                                   ooo\"\n",
      "batch 4526  loss=130.6572  steps/s=49.80  prediction: \"y: @Nominus9 So no chess players, got it\" => \": @  eh        t                   ooooo\"\n",
      "batch 4527  loss=139.0323  steps/s=110.17  prediction: \"them depth wise, learning â€œon demandâ€ (â€¦\" => \"healc e               eeee        nnnnnn\"\n",
      "batch 4528  loss=170.0131  steps/s=103.20  prediction: \" To Learn (LHTL)\n",
      "https://t.co/zMGdAcfDpd\" => \"th  oo     LLLLLLLLLTTTT      tttt//////\"\n",
      "batch 4529  loss=131.6620  steps/s=102.48  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @eeeeeeeeeeeerrrrrrr tt           \"\n",
      "batch 4530  loss=213.0785  steps/s=97.84  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"o\n",
      " toraEEEEEEEOOOOOOOOOOOOOt            \"\n",
      "batch 4531  loss=135.3112  steps/s=101.58  prediction: \"elf even if it overlaps with signoooling\" => \" lyl lleeee    l                iiiiiiii\"\n",
      "batch 4532  loss=165.5131  steps/s=88.85  prediction: \"ettler @crypt0x_0 @EsotericCofe thanks!!\" => \" ty:s@eeeeee   r             iiioooooooo\"\n",
      "batch 4533  loss=140.9629  steps/s=102.77  prediction: \"at's definitely part of the current meta\" => \"n dadl     teetteetttt  t               \"\n",
      "batch 4534  loss=140.3075  steps/s=51.95  prediction: \": @0xluffyb graphics programming be like\" => \" @toaea   teee  eet                  ee \"\n",
      "batch 4535  loss=142.5428  steps/s=111.53  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \"hle  u      aaaaaaattttttttttttttttt////\"\n",
      "batch 4536  loss=131.2417  steps/s=103.89  prediction: \" two next to each other. then a 4x4. etc\" => \"@he ee                     t            \"\n",
      "batch 4537  loss=118.3976  steps/s=45.94  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \": @see t tt ttt         tttt h          \"\n",
      "batch 4538  loss=133.0305  steps/s=108.30  prediction: \" life during hard times\n",
      "Thank God for it\" => \"ti   i                                  \"\n",
      "batch 4539  loss=116.0758  steps/s=55.08  prediction: \": @archived_videos definitely the latter\" => \" @aic    ii    d       diiii            \"\n",
      "batch 4540  loss=133.0746  steps/s=107.14  prediction: \"urself, if you can manage to pull it off\" => \"ne le l                                 \"\n",
      "batch 4541  loss=141.1752  steps/s=101.76  prediction: \"losoft and make the circle tool yourself\" => \"ynkoooooooooo  s                        \"\n",
      "batch 4543  loss=142.1133  steps/s=100.15  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"es s                   a attttttt///////\"\n",
      "batch 4544  loss=130.6294  steps/s=103.39  prediction: \"nd mental storage/organization efficient\" => \"g, eef,e      t ttttttttaaaaaaaaaaaaaiii\"\n",
      "batch 4545  loss=132.3704  steps/s=102.42  prediction: \"e rotators\n",
      "\n",
      "we color c, e, f, g the same\" => \" toe      ooooooooooooooooo             \"\n",
      "batch 4546  loss=182.4937  steps/s=45.83  prediction: \"y: @01beigecamry https://t.co/qAESPOcfdy\" => \"  @se oooottarrerooooooo   ,,,,         \"\n",
      "batch 4547  loss=165.7486  steps/s=74.73  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: @ roaarrraaarrotttt  // ,,,          \"\n",
      "batch 4548  loss=136.6944  steps/s=106.94  prediction: \"e exposure therapy and learn more abt it\" => \" a  oooooooooooteeeeeeeeeeeee           \"\n",
      "batch 4549  loss=139.0405  steps/s=102.90  prediction: \" have to reprompt it like 1/3rd the time\" => \"tad                                     \"\n",
      "batch 4550  loss=136.7533  steps/s=102.64  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n  n  iiiii                 ttt/////////\"\n",
      "batch 4551  loss=142.4586  steps/s=99.86  prediction: \"ircle tool gang) https://t.co/eWviZR2Y3N\" => \"ni    cc     oo         ttttttt/////////\"\n",
      "batch 4552  loss=137.0680  steps/s=98.18  prediction: \"surely you will not regret this decision\" => \" c a ratt      l                       e\"\n",
      "batch 4553  loss=137.7535  steps/s=78.87  prediction: \"wphones Love the plan, sounds meaningful\" => \"iht e  tt                           iiii\"\n",
      "batch 4554  loss=179.4501  steps/s=106.27  prediction: \"7AHwatHv6Y was really really really good\" => \"  .@ t////tttttHHHHHaaaaaaaaalllllllllll\"\n",
      "batch 4555  loss=141.9126  steps/s=102.83  prediction: \" wonder what else you could fast-preview\" => \"thea                                    \"\n",
      "batch 4556  loss=136.5482  steps/s=102.11  prediction: \"anything else would kneecap learning no?\" => \"td tii         n             eeeeeeeennn\"\n",
      "batch 4558  loss=131.0579  steps/s=105.37  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \"  oee              ...........tttttttt//\"\n",
      "batch 4559  loss=136.1829  steps/s=102.95  prediction: \"olve for the entire past week was a typo\" => \"  e e                     eeeeeeee      \"\n",
      "batch 4560  loss=134.4547  steps/s=104.28  prediction: \"etter, all in your head\n",
      "Can explain more\" => \"    e          l                   aaaaa\"\n",
      "batch 4561  loss=129.4600  steps/s=103.36  prediction: \"an explanation that made sense to me lol\" => \"nd  o           nnnnnaaaaaaaaaaa        \"\n",
      "batch 4563  loss=136.0179  steps/s=80.03  prediction: \"minus9 This is my new favorite edm track\" => \"onf me  nnnnn              ae  eeeeeee  \"\n",
      "batch 4564  loss=128.5602  steps/s=106.43  prediction: \"learn lean just so i can make lean jokes\" => \"ym i  l        l                        \"\n",
      "batch 4565  loss=127.5740  steps/s=103.89  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"thet t      tt t                        \"\n",
      "batch 4566  loss=145.8657  steps/s=103.58  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" 0u ed         d          sssssssss     \"\n",
      "batch 4567  loss=143.0073  steps/s=103.09  prediction: \"d you man. Yea whenever you can do join!\" => \" i s i                eeeeeeeeee        \"\n",
      "batch 4568  loss=143.6266  steps/s=61.92  prediction: \" @Yosef_Frost vision: pro\n",
      "execution: slo\" => \"tIas               eeeeeee eeeee     oon\"\n",
      "batch 4569  loss=135.3679  steps/s=105.82  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "'oteisuuuuuuuuttttttt                  \"\n",
      "batch 4570  loss=168.9279  steps/s=103.35  prediction: \"rackpad &gt;&gt; 3 monitors + pc + mouse\" => \"ecly: @ppppp       &&&;;;;;             \"\n",
      "batch 4571  loss=133.8035  steps/s=104.54  prediction: \"e right things really really does matter\" => \" mite  t ttttt               lllllllllll\"\n",
      "batch 4572  loss=134.3836  steps/s=104.94  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"tee            eeeeeeeeeeeeeee          \"\n",
      "batch 4573  loss=147.9072  steps/s=99.24  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y     sssssssssssssssssssssstttttt//////\"\n",
      "batch 4574  loss=120.8250  steps/s=99.99  prediction: \" just do what i tell them the first time\" => \"tua s                  t   ttttt   ttttt\"\n",
      "batch 4575  loss=144.2663  steps/s=101.75  prediction: \"allenge\n",
      "however: https://t.co/TzbAuUlGIG\" => \"n   u           eeeeeeeee:::::://///////\"\n",
      "batch 4576  loss=130.4770  steps/s=104.07  prediction: \"miliar with a place and the things in jt\" => \"enio ri iiiiiiiiii aaaaaaa              \"\n",
      "batch 4577  loss=139.2956  steps/s=100.61  prediction: \"and down\n",
      "Long term trend is what matters\" => \"tt ou          n                       t\"\n",
      "batch 4578  loss=142.1628  steps/s=106.11  prediction: \"te correctly lol\n",
      "https://t.co/0eYn1IVGOH\" => \" re tte         oootttttttttt///////////\"\n",
      "batch 4579  loss=145.7449  steps/s=104.73  prediction: \"r die, and when they swim they find food\" => \"esis           w                        \"\n",
      "batch 4580  loss=134.3897  steps/s=104.94  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \"ga e  t                                 \"\n",
      "batch 4581  loss=132.5230  steps/s=78.12  prediction: \"minus9 This is my new favorite edm track\" => \"entit n o                       ooo  mmm\"\n",
      "batch 4582  loss=129.0485  steps/s=94.18  prediction: \"kaysh No I have to run the code manually\" => \"elm    oo                       e       \"\n",
      "batch 4583  loss=138.6346  steps/s=104.42  prediction: \"yo grand children at 85. gps kids r busy\" => \"    7ee                                 \"\n",
      "batch 4584  loss=140.3093  steps/s=101.62  prediction: \"e, and i know i need to get back into it\" => \"  asee                                  \"\n",
      "batch 4585  loss=136.3920  steps/s=101.65  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"rd tj          n                        \"\n",
      "batch 4586  loss=135.8065  steps/s=103.93  prediction: \"soned wine games https://t.co/9edvpSK4pr\" => \"    t          e              ttttt/////\"\n",
      "batch 4587  loss=130.4029  steps/s=104.42  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \"ht  y t        nooooooooooooo           \"\n",
      "batch 4589  loss=130.7017  steps/s=104.99  prediction: \"every useful thing I do the cooler it is\" => \" e memeeeeeeeeereee                     \"\n",
      "batch 4590  loss=191.1058  steps/s=78.85  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \"   Ieereeee    n         ttt ooooooooo  \"\n",
      "batch 4591  loss=154.9196  steps/s=107.21  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tude           n            ///////////t\"\n",
      "batch 4592  loss=137.6691  steps/s=71.36  prediction: \"rrawnyy cool ass wasm cube bro\n",
      "\n",
      "followed\" => \"eely: @             ss //// ////ooooooso\"\n",
      "batch 4593  loss=137.2593  steps/s=55.61  prediction: \"ly: @gizmobly probably\n",
      "especially if bjj\" => \"y: @                sss s s ccoooooooooo\"\n",
      "batch 4594  loss=136.1572  steps/s=111.37  prediction: \"ore descriptive titles for the rest lool\" => \"rk i         eedeeeeeeeeeeeeeeteeeeee   \"\n",
      "batch 4595  loss=119.2221  steps/s=65.00  prediction: \"@skooookum i forget but its at least 100\" => \"saawoooooooiie eiiteeettt ttt tt  tt    \"\n",
      "batch 4596  loss=137.3303  steps/s=118.88  prediction: \" What are your personal long term games?\" => \"th d  llo           rr                  \"\n",
      "batch 4597  loss=142.2314  steps/s=102.84  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" er  rsssssss             tttttttttt////\"\n",
      "batch 4598  loss=132.3820  steps/s=103.57  prediction: \" yrs. ur brain will figure it out, trust\" => \"toui             r        iiiiiii       \"\n",
      "batch 4601  loss=130.5574  steps/s=103.87  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yies r   llleeeleeeeeeeeeeeeeelllll\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "batch 4602  loss=131.1910  steps/s=102.44  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"t ll           ne \"\"\"\"\"\"\"\"\"\"\"\"          \"\n",
      "batch 4603  loss=136.0852  steps/s=105.24  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" aoa t         s   ssssssssss sssssss   \"\n",
      "batch 4605  loss=126.8773  steps/s=104.17  prediction: \"eeks but you get back your skill quickly\" => \"     eeeeeee   e                      kk\"\n",
      "batch 4606  loss=136.1881  steps/s=104.82  prediction: \"oud walk away w a much stronger skillset\" => \"rn\n",
      "            w                        \"\n",
      "batch 4607  loss=135.2160  steps/s=104.98  prediction: \"s. im betting on that. but i am not sure\" => \" uo thy                 ttt             \"\n",
      "batch 4608  loss=138.2204  steps/s=104.84  prediction: \" but back in the day thats how I learned\" => \"tuc  cccccc                             \"\n",
      "batch 4609  loss=143.1745  steps/s=103.87  prediction: \" it was all tactice, but this is the way\" => \"tn nn                 ttttttttttttt     \"\n",
      "batch 4610  loss=142.5494  steps/s=99.68  prediction: \"rse21 help poor sama out, he needs ideas\" => \"eeky: @ooo     l                       e\"\n",
      "batch 4611  loss=129.6201  steps/s=104.08  prediction: \"cuda skills, so its a fun way to do both\" => \"oniin          s                        \"\n",
      "batch 4612  loss=131.3511  steps/s=106.07  prediction: \"gh times when it all looks bleak/failing\" => \"    ghh                      lllllllllll\"\n",
      "batch 4613  loss=135.6738  steps/s=105.29  prediction: \"ey once, will play otb w friends usually\" => \"                                        \"\n",
      "batch 4615  loss=127.6866  steps/s=104.18  prediction: \"on mars we will make this a top priority\" => \"u              w                        \"\n",
      "batch 4616  loss=123.1852  steps/s=105.00  prediction: \" will get back to you when this is fixed\" => \"thee   llllll                           \"\n",
      "batch 4618  loss=242.5043  steps/s=44.97  prediction: \"y: @BenjaminDEKR https://t.co/XKzK1sR0d2\" => \": @leelll                               \"\n",
      "batch 4620  loss=131.4384  steps/s=108.22  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" to ee   eeeeeee                        \"\n",
      "batch 4621  loss=128.9203  steps/s=104.81  prediction: \"d\" and they do and then it stops failing\" => \" r te d    dddddddddddd                 \"\n",
      "batch 4622  loss=132.5833  steps/s=103.94  prediction: \"der the hood the better you can innovate\" => \" rnden n       t        eee             \"\n",
      "batch 4623  loss=131.5002  steps/s=97.75  prediction: \"us im in, gonna do this rn, on the rocks\" => \"nted           n                  nn    \"\n",
      "batch 4625  loss=134.2606  steps/s=104.06  prediction: \" which uses a superset of c. so not sure\" => \"thi cncccccc   c       ss               \"\n",
      "batch 4626  loss=153.7008  steps/s=96.72  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"LM nic         p pp   oo                \"\n",
      "batch 4627  loss=129.3148  steps/s=101.09  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"tai  t            pppppppp              \"\n",
      "batch 4628  loss=140.1095  steps/s=104.40  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" oo                     ttttttttt///////\"\n",
      "batch 4629  loss=133.2333  steps/s=105.53  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"nh r  l  hhhaaataaaaa                   \"\n",
      "batch 4630  loss=150.0209  steps/s=100.40  prediction: \"s if you do both\n",
      "https://t.co/EXEA72MrEm\" => \" wnha                   tttttttttt//////\"\n",
      "batch 4631  loss=128.1396  steps/s=75.75  prediction: \"ryvyo no ffmpeg itd be too slow id think\" => \"  ly: @        f fttttttttto/ooooooooEEE\"\n",
      "batch 4633  loss=130.3986  steps/s=107.62  prediction: \"to fall back on. build stuff on the side\" => \"h nrha                                  \"\n",
      "batch 4634  loss=143.0129  steps/s=104.57  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"lte  eppppppooooooooooooooooooooonnnn   \"\n",
      "batch 4635  loss=132.7759  steps/s=105.94  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"  e  eta       t              eeeeeeeeee\"\n",
      "batch 4636  loss=158.0698  steps/s=97.51  prediction: \"builds 2012 but yet blunders mate in one\" => \"etti  bbbb     s         ee  eeeeeee    \"\n",
      "batch 4637  loss=143.2725  steps/s=103.90  prediction: \"ying/whatever, every monday and thursday\" => \":nggiiggggggnnnnnneeeeeeeeeeeeeeeee  ddd\"\n",
      "batch 4638  loss=130.5602  steps/s=104.47  prediction: \"ions you choose, like oregon or whatever\" => \"nn  ooooooooooooooooooooooooooooo      e\"\n",
      "batch 4639  loss=134.3990  steps/s=105.12  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t a  a         r                        \"\n",
      "batch 4640  loss=164.5088  steps/s=101.59  prediction: \"on every monday and thursday of the week\" => \"   o           n                        \"\n",
      "batch 4641  loss=144.7825  steps/s=103.59  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \" c /z  a                                \"\n",
      "batch 4642  loss=120.2672  steps/s=100.13  prediction: \"y be a way to do it without grad descent\" => \":thne                                   \"\n",
      "batch 4643  loss=127.8209  steps/s=104.21  prediction: \"more efficient parameters in the network\" => \"enei        eee eeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 4644  loss=129.4876  steps/s=70.84  prediction: \"justalexoki the t has always meant taoki\" => \"est t  eeeeeeeit   eee e aa  ae  ee tttt\"\n",
      "batch 4645  loss=180.2423  steps/s=112.20  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"ts t  eiiiii    ttttttttttttttt//////aao\"\n",
      "batch 4646  loss=133.0972  steps/s=104.72  prediction: \"c, just separated by some amount of time\" => \"h n s a,       t  t                     \"\n",
      "batch 4648  loss=129.1854  steps/s=103.96  prediction: \"dates/incentives to fund ai safety stuff\" => \"  o oa aaaaaaeeeeeeeeeennnnn            \"\n",
      "batch 4649  loss=125.8836  steps/s=103.05  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"go tt              ooooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaaa\"\n",
      "batch 4650  loss=158.9894  steps/s=99.10  prediction: \"? nah, blocktard https://t.co/bYxFfo7Sue\" => \"\n",
      "oro   a    aaaaaa tttttttttttttt///////\"\n",
      "batch 4651  loss=159.4048  steps/s=28.98  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @ aa    aaaaa ttttttttttttt///////oo\"\n",
      "batch 4652  loss=139.5526  steps/s=109.59  prediction: \"ions for agents\n",
      "Sounds v similar to this\" => \"nneie e           nnnnnnnnnsssssss      \"\n",
      "batch 4653  loss=237.1743  steps/s=101.84  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"er t O SSSSSSSS GGGGGG     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tt/////3\"\n",
      "batch 4654  loss=140.0846  steps/s=104.18  prediction: \"ms' meaning more straightforward success\" => \"e bleme''''mmmmmmmmmmm    rrrrrrrrrrrrrr\"\n",
      "batch 4655  loss=148.7206  steps/s=99.76  prediction: \"s a crazy valuable source of improvement\" => \" taluaaaaaaaaaaaaaaaaaaa                \"\n",
      "batch 4656  loss=143.0319  steps/s=103.60  prediction: \"d LLMs to get boilerplate and stuff done\" => \" m toeAnn      t                        \"\n",
      "batch 4657  loss=128.2999  steps/s=103.10  prediction: \"a single man who can bench more than 400\" => \"nd n           n                        \"\n",
      "batch 4658  loss=134.5805  steps/s=97.34  prediction: \"P get him toys, play w him, lasts longer\" => \" Toe  gAg                               \"\n",
      "batch 4659  loss=137.3780  steps/s=104.68  prediction: \"that can run for under $1000 of compute?\" => \"heas m                            000000\"\n",
      "batch 4660  loss=151.0166  steps/s=100.31  prediction: \"ME but you do not follow CHRIST? curious\" => \"T  ooo o       u   oooooooooooooo       \"\n",
      "batch 4661  loss=154.5258  steps/s=21.20  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \" t:llo            oo ooooooooooo        \"\n",
      "batch 4662  loss=147.9786  steps/s=126.29  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \"dtea ea      tt t                       \"\n",
      "batch 4663  loss=123.4874  steps/s=102.23  prediction: \" a cross section now that you mention it\" => \"t  k                                    \"\n",
      "batch 4664  loss=155.1318  steps/s=104.06  prediction: \"Pragmatist @kuberdenis dan dan and danny\" => \" a@P agggggggaagaaaaaaaaaddddddddddddddn\"\n",
      "batch 4665  loss=122.7321  steps/s=76.28  prediction: \"0nnnpppppppppp hilarious bait, i love it\" => \"x 9 tpppppppppppppppiiiii ddi a         \"\n",
      "batch 4667  loss=137.6652  steps/s=106.23  prediction: \"n X and see people dropping crazy things\" => \" ai               eeeeeppppppppppp      \"\n",
      "batch 4669  loss=128.8656  steps/s=103.50  prediction: \"entation, the cooler everything will get\" => \"  te otttttttttttttoooeeeeeeeeeeeeeeeeee\"\n",
      "batch 4670  loss=136.0556  steps/s=100.02  prediction: \"ding stuff for fun also helped immensely\" => \" mtut iiiii  ff fffffffff               \"\n",
      "batch 4671  loss=126.9500  steps/s=105.72  prediction: \"ment it with all the details that pop up\" => \"e e pe e          t    ttttttttttttttt  \"\n",
      "batch 4672  loss=129.9705  steps/s=101.03  prediction: \"ng so you can automate ruining your life\" => \"g aa                          nnnnuuuuuu\"\n",
      "batch 4673  loss=131.0169  steps/s=105.97  prediction: \"es success, but there is a causal factor\" => \"  r t aaaesssssssssssssee               \"\n",
      "batch 4674  loss=152.4127  steps/s=105.66  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"                        tttttt//////////\"\n",
      "batch 4676  loss=136.4318  steps/s=100.93  prediction: \" can be taken much much much further tbh\" => \"totci          t                 hhhhhhh\"\n",
      "batch 4677  loss=133.2578  steps/s=105.43  prediction: \"g real and distracted from the adventure\" => \" atdt                 ddddddd         ee\"\n",
      "batch 4678  loss=189.7250  steps/s=11.07  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"e  s                 ddddddd          ee\"\n",
      "batch 4679  loss=126.2910  steps/s=129.37  prediction: \"sing llms to their full potential rn tbh\" => \" n                             lllll    \"\n",
      "batch 4680  loss=132.8333  steps/s=104.12  prediction: \"cy and then work up to really short ones\" => \"h  itt nnnnnnnn nn                      \"\n",
      "batch 4681  loss=123.4777  steps/s=103.69  prediction: \"rning gpu acceleration is super valuable\" => \"e  in nnnnn       aaaaaa                \"\n",
      "batch 4682  loss=157.4742  steps/s=100.28  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \" t aw                         ttttt/////\"\n",
      "batch 4683  loss=128.2560  steps/s=104.00  prediction: \"doing stuff their mind doesnt want to do\" => \"  n            n                        \"\n",
      "batch 4684  loss=113.1606  steps/s=30.48  prediction: \"ply: @calbch do it\n",
      "i double dog dare you\" => \"ly: @          t      d    d d   nn     \"\n",
      "batch 4685  loss=123.0431  steps/s=137.57  prediction: \"hnote uuuh i have a license for thse sir\" => \"ec s  ttttuuuuu uuu                     \"\n",
      "batch 4686  loss=134.0766  steps/s=104.66  prediction: \"ys a bad thing just good to keep in mind\" => \": hl\n",
      "aaaaaaaaaaa                        \"\n",
      "batch 4687  loss=128.7386  steps/s=101.16  prediction: \"inlet like me to test experiments out on\" => \"ne ee r                  eeeeeeeeeeeeett\"\n",
      "batch 4688  loss=121.2819  steps/s=28.03  prediction: \"eply: @djcows you need attention, is all\" => \" ly:                    eeeeeeeeeeeetttt\"\n",
      "batch 4689  loss=127.0017  steps/s=128.76  prediction: \" a bool so you just become sick again :/\" => \"t  tt t  ooooooooooo                    \"\n",
      "batch 4690  loss=138.7280  steps/s=104.93  prediction: \"nts also on the nm level, but, 3d not 2d\" => \" iou o nnnnoooonn                       \"\n",
      "batch 4691  loss=146.7039  steps/s=104.34  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "ee           d           sssssss      \"\n",
      "batch 4692  loss=131.1317  steps/s=64.84  prediction: \"@btwphones thanks! its going well so far\" => \"lDnpnle    e  a aaaa  s ssss            \"\n",
      "batch 4693  loss=130.7519  steps/s=113.63  prediction: \" off with a basic template and modify it\" => \"tn p  tttttt   t                  a     \"\n",
      "batch 4694  loss=123.9445  steps/s=45.37  prediction: \"y: @_diginova i served my time in x jail\" => \": @ttdttti     a            a           \"\n",
      "batch 4695  loss=135.3546  steps/s=110.86  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r   tttttttttt           rrrrrrrrrrrrrr\"\n",
      "batch 4696  loss=192.6522  steps/s=98.34  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \"0i  y          ruuuuuurr                \"\n",
      "batch 4697  loss=144.8674  steps/s=39.18  prediction: \"ly: @ludwigABAP Its a good hivemind, sir\" => \"y: @   uuuuuuuuuuuuuuur                 \"\n",
      "batch 4698  loss=131.7561  steps/s=139.72  prediction: \"ller accurate. really useful distinction\" => \"y  @1u1rrrruerr  ccr  a      ll   i  iii\"\n",
      "batch 4699  loss=128.5324  steps/s=104.78  prediction: \"y laptop and hope the bits line up right\" => \":cajaa                                  \"\n",
      "batch 4700  loss=126.9959  steps/s=103.88  prediction: \"g, or write something else in zig, later\" => \"  iazi                                  \"\n",
      "batch 4701  loss=133.5408  steps/s=101.76  prediction: \"e. I can teach you a bit too if you want\" => \"                                        \"\n",
      "batch 4702  loss=141.0592  steps/s=96.15  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "o     mmmmmmmmee                ff     \"\n",
      "batch 4703  loss=134.7460  steps/s=104.13  prediction: \"more friction than they need to function\" => \"ereie h                                 \"\n",
      "batch 4704  loss=145.7659  steps/s=101.34  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"tnvm  oooooooooollll                    \"\n",
      "batch 4705  loss=142.9228  steps/s=104.18  prediction: \"ameboy emulator) https://t.co/og8bnpdUHw\" => \"ne sea        a             tttt////////\"\n",
      "batch 4706  loss=185.9109  steps/s=29.52  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: @ a    aaaa         tttt///////////o\"\n",
      "batch 4707  loss=137.5152  steps/s=110.77  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nsaaaaannnnnmmm mmmmmmmmmmm             \"\n",
      "batch 4708  loss=127.4638  steps/s=104.97  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"euly     rrreeerettttttttttteeeetttteeee\"\n",
      "batch 4709  loss=123.8154  steps/s=104.71  prediction: \"s and had strong knowledge of the course\" => \" oh       ddddd                         \"\n",
      "batch 4710  loss=131.2737  steps/s=103.54  prediction: \"stion, why do they cluster where they do\" => \"  rr                              eeeeee\"\n",
      "batch 4711  loss=135.4808  steps/s=103.19  prediction: \"ich is a suuuuper good thing to practice\" => \"ns oo          u uuuuuuuuuu             \"\n",
      "batch 4712  loss=134.7263  steps/s=103.34  prediction: \"e session, just wake up without an alarm\" => \" t      eee    nssssss                  \"\n",
      "batch 4713  loss=126.7327  steps/s=46.37  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \"  @n eeee   sssssssss       w          a\"\n",
      "batch 4714  loss=129.1089  steps/s=114.00  prediction: \"i have a few libraries in there sadly :9\" => \"nh  a  aaaaa                     eee    \"\n",
      "batch 4715  loss=136.1084  steps/s=99.96  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"ta s i   eeeeeec eeeeee    ee           \"\n",
      "batch 4716  loss=139.7294  steps/s=104.34  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"eply: @        e       tttttttttt///////\"\n",
      "batch 4717  loss=140.0211  steps/s=103.89  prediction: \"ful if youre a complete beginner like me\" => \" n i ii                    eeeeeeeeeeeee\"\n",
      "batch 4718  loss=137.9738  steps/s=105.53  prediction: \"tial art and he generalizes between them\" => \"ho   omaaaaaaaaaaa          eeeeeeeeeeee\"\n",
      "batch 4719  loss=127.6333  steps/s=104.52  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taie itiiiiiii n         llll           \"\n",
      "batch 4720  loss=134.4763  steps/s=72.66  prediction: \"dejavucoder roon was gpt5 the whole time\" => \" rt git    ooooooo oo       et       xxx\"\n",
      "batch 4721  loss=131.7289  steps/s=106.31  prediction: \"ies and more insights. Then will release\" => \"nl sd               iissssss           e\"\n",
      "batch 4722  loss=136.4240  steps/s=102.93  prediction: \"libraries or backend compute or anything\" => \"yke@5eeeeeeerrr rrrrrrr                 \"\n",
      "batch 4723  loss=127.7368  steps/s=103.47  prediction: \" my weird posts but im happy nonetheless\" => \"tote eeeeee    t                        \"\n",
      "batch 4724  loss=126.2961  steps/s=102.77  prediction: \"was intentional but it sounds super cool\" => \" tt A          nnnttttttttttttt         \"\n",
      "batch 4725  loss=132.1487  steps/s=105.40  prediction: \"eet you can do some crazy things in life\" => \" d e                                    \"\n",
      "batch 4726  loss=137.8252  steps/s=101.93  prediction: \"f children will build my programs for me\" => \" toe           m         llll           \"\n",
      "batch 4727  loss=128.5804  steps/s=105.91  prediction: \" in those days will have had it too easy\" => \"at  mns                                 \"\n",
      "batch 4728  loss=139.2953  steps/s=104.83  prediction: \"itor as I was with 2 screens and a mouse\" => \"n   a          w                        \"\n",
      "batch 4729  loss=132.8791  steps/s=103.07  prediction: \"mer.js to make it cost $0. took too long\" => \"e sen rrrrrrrr r                  oooooo\"\n",
      "batch 4730  loss=127.7610  steps/s=104.44  prediction: \"it seems like using a spoon vs a scalpel\" => \"n  oo          e                        \"\n",
      "batch 4731  loss=137.5931  steps/s=103.70  prediction: \"anything else would kneecap learning no?\" => \"nd  i          n             eeeeeeeeenn\"\n",
      "batch 4732  loss=134.4886  steps/s=104.49  prediction: \"ting up prints, never had a problem w it\" => \" o a           n                        \"\n",
      "batch 4733  loss=127.1694  steps/s=103.79  prediction: \"f a nix rollback could fix their problem\" => \"ot erin                                 \"\n",
      "batch 4734  loss=133.5795  steps/s=103.60  prediction: \"lay this game\n",
      "\n",
      "happy wheels was gold too\" => \"ys  e t               pppppppp          \"\n",
      "batch 4735  loss=157.5155  steps/s=103.93  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"  e  h                                oo\"\n",
      "batch 4736  loss=130.6026  steps/s=102.38  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @eeeeeeeeeeerrrrrrrrr             \"\n",
      "batch 4737  loss=131.9285  steps/s=103.61  prediction: \"ck inside my brain. not sure what though\" => \"oeeeotc        c                        \"\n",
      "batch 4738  loss=125.5624  steps/s=100.72  prediction: \"rd it means theyre giving you a discount\" => \"ee y                eeeeee              \"\n",
      "batch 4739  loss=139.7525  steps/s=105.39  prediction: \"nts also on the nm level, but, 3d not 2d\" => \" oou o nnnnnooonn                       \"\n",
      "batch 4740  loss=134.5271  steps/s=103.97  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"  eile         n                 ///////\"\n",
      "batch 4741  loss=135.1257  steps/s=102.20  prediction: \"mcignore feature https://t.co/oLseuf2uxS\" => \"eetltn              tttttttttt//////////\"\n",
      "batch 4742  loss=148.6042  steps/s=103.70  prediction: \"mentals can be really really hard to see\" => \"e taiesnnnnnnnn nn a   aaaalllllllllll  \"\n",
      "batch 4743  loss=140.3954  steps/s=100.91  prediction: \"om gpt10 how strong could you make gpt2?\" => \" e: tat                    ooooooo      \"\n",
      "batch 4744  loss=149.6366  steps/s=98.07  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "oa l          l                        \"\n",
      "batch 4745  loss=128.8194  steps/s=103.79  prediction: \"d take a bite of a giant company's lunch\" => \" t  x                           a       \"\n",
      "batch 4746  loss=135.4267  steps/s=103.64  prediction: \"ould keep going) https://t.co/zZj3emr1oN\" => \"ute                         tttttt//////\"\n",
      "batch 4748  loss=133.1317  steps/s=104.00  prediction: \"d my sleep waaay better\n",
      "\n",
      "would recommend\" => \" ae r a        e  aaaaeeeeeeeeeeeeeeeeee\"\n",
      "batch 4750  loss=129.3238  steps/s=98.66  prediction: \"surely you will not regret this decision\" => \" mda raas     yl                       e\"\n",
      "batch 4751  loss=127.3399  steps/s=99.27  prediction: \"often to be random chance\n",
      "\n",
      "i love it tbh\" => \"u oet o  oo                             \"\n",
      "batch 4752  loss=145.4329  steps/s=58.65  prediction: \" @Yosef_Frost vision: pro\n",
      "execution: slo\" => \"tloe  ooo      t     nnnn \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "eee      \"\n",
      "batch 4753  loss=155.1418  steps/s=111.65  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"tate t          fffffff    ee ttttt/////\"\n",
      "batch 4754  loss=133.7345  steps/s=103.77  prediction: \" is interesting play between those three\" => \"tn  e       eeeteeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 4755  loss=135.0112  steps/s=104.23  prediction: \"self tho prob cause that sounds more fun\" => \"  mm m         m                        \"\n",
      "batch 4756  loss=132.9057  steps/s=102.15  prediction: \" and can be much more useful to increase\" => \"tnan   nnnn                             \"\n",
      "batch 4757  loss=163.2059  steps/s=103.36  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"anldt\n",
      "uwwwwwwww             stt/////////\"\n",
      "batch 4758  loss=127.6828  steps/s=102.50  prediction: \" front end. i want minimal backend stuff\" => \"@ou            n      nnnnnnnn nnn      \"\n",
      "batch 4759  loss=135.7538  steps/s=99.36  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"ntu to         n                        \"\n",
      "batch 4761  loss=143.6256  steps/s=103.96  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"ath the     hhhhhhhhhhhhtttttttttttttt//\"\n",
      "batch 4762  loss=128.7030  steps/s=104.96  prediction: \" use commonly are invisible fundamentals\" => \"tpr pep                             nnnn\"\n",
      "batch 4763  loss=137.6908  steps/s=104.72  prediction: \"n X and see people dropping crazy things\" => \" bir               eeeepppppppppppp     \"\n",
      "batch 4764  loss=135.1731  steps/s=104.12  prediction: \" know. But this will help you immensely.\" => \"te o           n                       l\"\n",
      "batch 4765  loss=156.0548  steps/s=84.52  prediction: \"mobly @amix011 May do this in the future\" => \"ene om o                        iii  eee\"\n",
      "batch 4766  loss=131.5057  steps/s=105.84  prediction: \"e increased space the model has to think\" => \" tott   eeeeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 4767  loss=153.6783  steps/s=46.69  prediction: \"y: @astroButter @karpathy @MagnusCarlsen\" => \"  @se e eeeeeeece  eeee ee              \"\n",
      "batch 4769  loss=135.8715  steps/s=108.30  prediction: \" long long time\n",
      "\n",
      "https://t.co/svmrGr008p\" => \"tet              ggggg  tttttttttttt////\"\n",
      "batch 4770  loss=133.3965  steps/s=104.76  prediction: \"hat easy guys, you learn like way faster\" => \"at e ltttt      yyyyyyyy                \"\n",
      "batch 4771  loss=151.1039  steps/s=105.43  prediction: \" filter out slop https://t.co/RA1wtAYLES\" => \"tosdffffffff           ttttttttttttttt//\"\n",
      "batch 4772  loss=133.4223  steps/s=102.40  prediction: \"i have a few libraries in there sadly :9\" => \"np aa aaaaaaa                           \"\n",
      "batch 4773  loss=137.5114  steps/s=104.98  prediction: \", how much info could you get from that?\" => \" io  i         m                        \"\n",
      "batch 4774  loss=128.4592  steps/s=105.14  prediction: \"\n",
      "shit like this: https://t.co/Z4JE4KMgHs\" => \"\n",
      "o s  sssssssss siihhtttttttttttttttttt/\"\n",
      "batch 4775  loss=141.0789  steps/s=103.55  prediction: \"owing that your food supply doesnt scale\" => \"u  i n ttttttttt               ooo      \"\n",
      "batch 4776  loss=143.7254  steps/s=93.36  prediction: \"pmillyair lichess is like 200 elo higher\" => \"l   @itttaiiiiii       sss              \"\n",
      "batch 4777  loss=134.5198  steps/s=99.37  prediction: \"nsettler 1min in, its pretty good so far\" => \"    taissssssess  iiiiii                \"\n",
      "batch 4778  loss=143.4432  steps/s=104.59  prediction: \" 10% is figuring out a fix + applying it\" => \"t0eree          iii                     \"\n",
      "batch 4779  loss=140.6916  steps/s=101.95  prediction: \" is actually happening behind the scenes\" => \"tt ee               aaaaaaannnnnnnnnnnnn\"\n",
      "batch 4780  loss=140.8916  steps/s=100.18  prediction: \"0x_0 how is crypto this good at replying\" => \"%lufistt000000                          \"\n",
      "batch 4781  loss=124.0929  steps/s=98.32  prediction: \"ticed this too, its what got me thinking\" => \"hc_            tttttttt   t tt        tt\"\n",
      "batch 4782  loss=126.9877  steps/s=75.48  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"hee   uttttttt t o   o    oooo  oo  iiii\"\n",
      "batch 4783  loss=144.1808  steps/s=105.73  prediction: \"ve not! Will look tho sounds interesting\" => \"e  o eeee      l       ooooooooo        \"\n",
      "batch 4784  loss=134.3783  steps/s=101.79  prediction: \" software used that widely is so awesome\" => \"@oe                                     \"\n",
      "batch 4785  loss=179.7050  steps/s=101.72  prediction: \"7AHwatHv6Y was really really really good\" => \"   a.c/////ttttHHHHHaaaaaaaallllllllllll\"\n",
      "batch 4786  loss=138.2268  steps/s=101.17  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"@t r l l                                \"\n",
      "batch 4787  loss=140.0465  steps/s=103.26  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"ue       .............                  \"\n",
      "batch 4788  loss=136.9802  steps/s=105.25  prediction: \"dont know much about it other than that.\" => \"  g t          t                tttttttt\"\n",
      "batch 4789  loss=136.7887  steps/s=100.98  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"@ou            aaaaaaaaaaa              \"\n",
      "batch 4790  loss=180.5348  steps/s=65.36  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" eh o         aaaaaa                  ll\"\n",
      "batch 4791  loss=129.7884  steps/s=106.55  prediction: \"ol shit way more than alcohol and gaming\" => \"r   ni                            aaaaaa\"\n",
      "batch 4792  loss=132.6728  steps/s=100.02  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"@out  oo                         ggggggg\"\n",
      "batch 4793  loss=140.6561  steps/s=93.20  prediction: \" who build cool stuff get followers here\" => \"@hue d ee      d                o o     \"\n",
      "batch 4794  loss=135.8388  steps/s=98.92  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" eodesesssssss                          \"\n",
      "batch 4795  loss=130.9785  steps/s=103.30  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" toe   e eeeeeee                        \"\n",
      "batch 4796  loss=159.0728  steps/s=102.74  prediction: \"n `AI(short prompt)-&gt;output` programs\" => \"gatttar               rootttttttttttpptt\"\n",
      "batch 4797  loss=140.7944  steps/s=104.33  prediction: \" improve a processing unit's ability toâ€¦\" => \"ts eacaaaa                      iiiiiiii\"\n",
      "batch 4798  loss=145.6659  steps/s=58.93  prediction: \" @AI_Solzhenitsyn it's an acquired taste\" => \"tgnei a         siss   i  s    iiiiii tt\"\n",
      "batch 4799  loss=130.4163  steps/s=106.45  prediction: \"d its helped man. i shpuld sleep too lol\" => \" a nn                                  l\"\n",
      "batch 4801  loss=118.8851  steps/s=94.42  prediction: \"ler i wish it tasted as good as it looks\" => \"yd @ a llll      i         sss       ooo\"\n",
      "batch 4802  loss=180.7871  steps/s=38.95  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @ o ll           ts       s      oooo\"\n",
      "batch 4803  loss=175.2697  steps/s=59.52  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @tii          tttssstt   s      oooo\"\n",
      "batch 4804  loss=140.3450  steps/s=128.03  prediction: \"gh Ive been wanting to do a wasm project\" => \" on alo      eee eee                    \"\n",
      "batch 4805  loss=132.6651  steps/s=102.73  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" Lnteeeeeeeeeeeeeeeeeeeeeee             \"\n",
      "batch 4806  loss=193.3533  steps/s=99.91  prediction: \"________11hz togglesite is super helpful\" => \"i___@_______________ 11      sssssssseee\"\n",
      "batch 4807  loss=137.5863  steps/s=103.46  prediction: \"AM much more energy and thoughts flowing\" => \"B                                       \"\n",
      "batch 4808  loss=131.6870  steps/s=100.80  prediction: \"u come up with. Forgetfulness is a bitch\" => \"nc o           u                        \"\n",
      "batch 4809  loss=132.2230  steps/s=102.66  prediction: \"ught it was a cool idea so i speedran it\" => \"n io ttttttttt t                        \"\n",
      "batch 4810  loss=135.1127  steps/s=104.30  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \" tncntteeeeeeeeeeeeeeeeeeetttt/////////t\"\n",
      "batch 4811  loss=134.7218  steps/s=104.39  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tnstiiiiiiiiiiiiiiiiiiiiiiiiii          \"\n",
      "batch 4812  loss=142.3372  steps/s=65.21  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tyntiiiiniinniiiiCiiiii        d i  i   \"\n",
      "batch 4813  loss=157.8391  steps/s=107.84  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"taclot///////ttttttttttttttttttt///////t\"\n",
      "batch 4814  loss=131.6710  steps/s=104.48  prediction: \"ions you choose, like oregon or whatever\" => \"tf rooooooooooooooooooooooooooooo      e\"\n",
      "batch 4815  loss=130.7309  steps/s=99.79  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" d   sssssssseee          nnnnn         \"\n",
      "batch 4817  loss=152.1741  steps/s=104.57  prediction: \"ich in this case, is their lack of speed\" => \"tkesee                                  \"\n",
      "batch 4818  loss=135.1738  steps/s=103.84  prediction: \"erfect timing actually if thats the case\" => \" e h ntttttttttitttttttt                \"\n",
      "batch 4819  loss=135.0862  steps/s=104.95  prediction: \" exercise days, and just work a bit less\" => \"txe e       ee s                        \"\n",
      "batch 4820  loss=132.2621  steps/s=106.97  prediction: \"il of the recall/visualization over time\" => \"nlean                llllllllllliiiiiiii\"\n",
      "batch 4822  loss=126.6683  steps/s=104.28  prediction: \"ding up to that over which skill matters\" => \" na re         t                        \"\n",
      "batch 4823  loss=128.3507  steps/s=103.18  prediction: \"MTB a dollar flowing through the economy\" => \"T\n",
      " r a         l        h hhhhhhhhhhhhh \"\n",
      "batch 4824  loss=131.3599  steps/s=39.22  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"y:a@ a           llll     hhhhhhh hhoeee\"\n",
      "batch 4825  loss=128.1416  steps/s=106.89  prediction: \"rally where the word came from, i think)\" => \"ecnis          l                        \"\n",
      "batch 4826  loss=128.6929  steps/s=105.92  prediction: \"setup is going to be a bit different tho\" => \" l    o                                 \"\n",
      "batch 4827  loss=195.6504  steps/s=12.51  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"epai                                    \"\n",
      "batch 4828  loss=131.7821  steps/s=108.08  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"esa m          e           )))          \"\n",
      "batch 4829  loss=164.7212  steps/s=76.79  prediction: \"wlearning \"Pricing it in\" now 15% faster\" => \"hil  y e   nnn n  n               oollll\"\n",
      "batch 4830  loss=134.8818  steps/s=106.64  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"em Ha eeeeeeeeee         aa aaaaaaaa    \"\n",
      "batch 4831  loss=129.6095  steps/s=104.32  prediction: \"seless to ppl who dont know them already\" => \"  eeessssssssss                         \"\n",
      "batch 4832  loss=155.8489  steps/s=104.92  prediction: \"ge w git commits\n",
      "https://t.co/aMMtiAGLQh\" => \" zm   l            ttttttttttttttt//////\"\n",
      "batch 4833  loss=136.1947  steps/s=102.41  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" tie               ppppppp//////////////\"\n",
      "batch 4834  loss=132.8167  steps/s=103.24  prediction: \"tand on the shoulders of retarded giants\" => \" rs  pe        t               eeeeeeerd\"\n",
      "batch 4835  loss=122.5966  steps/s=22.40  prediction: \"eply: @btwphones Thanks! more on the way\" => \" ly: @                        ee eeeeedd\"\n",
      "batch 4836  loss=130.9073  steps/s=113.64  prediction: \"on + analysis, considering posting on gh\" => \"n sa a aaaaaaaa aaannsiiiiiiiiiiiiiiinnn\"\n",
      "batch 4837  loss=125.7535  steps/s=21.27  prediction: \"eply: @bozo10n you can just build things\" => \" ly: naaaaaaaaa a  sssiiiiiiiiiiiiiinngg\"\n",
      "batch 4838  loss=126.0690  steps/s=108.50  prediction: \"atterns so we should do (description ofâ€¦\" => \"t  h t            s                  ooo\"\n",
      "batch 4839  loss=134.9844  steps/s=100.68  prediction: \", welcome to circle gang @ineedtolocking\" => \" iod o ooooooooeo      c     eeeeeeeeeee\"\n",
      "batch 4840  loss=129.0149  steps/s=103.06  prediction: \" eu would lose half its talent overnight\" => \"tvee  ee       e                        \"\n",
      "batch 4841  loss=135.1029  steps/s=98.63  prediction: \" Post it in the disc it helps us all out\" => \"to    o                                 \"\n",
      "batch 4842  loss=127.8768  steps/s=103.88  prediction: \"rally where the word came from, i think)\" => \"ec,ii          l                        \"\n",
      "batch 4843  loss=130.4564  steps/s=70.13  prediction: \"@squirtle_says yacine what have you done\" => \"sulqiillrrrrleee       e                \"\n",
      "batch 4845  loss=138.8336  steps/s=119.35  prediction: \" @yotzol prelude in c major from scratch\" => \"asteq aecc yy yy                    ooor\"\n",
      "batch 4846  loss=132.0224  steps/s=102.28  prediction: \"nsettler 1min in, its pretty good so far\" => \"   arereeseseees  nn                    \"\n",
      "batch 4847  loss=148.4029  steps/s=103.70  prediction: \"know what it is\n",
      "\n",
      "https://t.co/wJ5n1H6JUK\" => \"eato               tttttttttttttttt/////\"\n",
      "batch 4848  loss=124.8799  steps/s=98.35  prediction: \"lms\n",
      "and lots and lots of trial and error\" => \"ya @donnnllll                           \"\n",
      "batch 4849  loss=131.9532  steps/s=104.88  prediction: \"mindset that kills the call to adventure\" => \"atdi  ittttttttttttttttt                \"\n",
      "batch 4850  loss=172.1457  steps/s=101.45  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"m_ u0 iiiiiiiggeggggg&&&&&;;;;;;;gggtttt\"\n",
      "batch 4851  loss=133.1567  steps/s=103.80  prediction: \" us safe from undetectable Dyson spheres\" => \"ap  n                  eeeeeeeeeeeeeeeee\"\n",
      "batch 4852  loss=131.3474  steps/s=104.04  prediction: \"x len output, custom system prompts, etc\" => \"_ma  ee       uuuuuuuuuuuttttttttmmmmmtt\"\n",
      "batch 4853  loss=178.5672  steps/s=90.65  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \"  n    eppttt     s ssssssssttttts///tcc\"\n",
      "batch 4854  loss=115.7989  steps/s=31.93  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @  noott  sssssssssssssttttt/////tcc\"\n",
      "batch 4855  loss=128.9145  steps/s=106.90  prediction: \" already doing, faster. you are the user\" => \"a te e eeeeeeeed                        \"\n",
      "batch 4856  loss=180.5323  steps/s=36.52  prediction: \"ply: @sunsettler https://t.co/2ERTWsJiwS\" => \"ly: @ eeeeeeeeee                        \"\n",
      "batch 4857  loss=130.7911  steps/s=109.63  prediction: \" if you come across any useful stuff tho\" => \"at  o                            ssuuuuu\"\n",
      "batch 4858  loss=145.4543  steps/s=102.26  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"aoe  n                      tttttttt////\"\n",
      "batch 4859  loss=130.6443  steps/s=100.35  prediction: \"im how fun the funny computer things are\" => \"ne  o                              n    \"\n",
      "batch 4861  loss=129.4919  steps/s=103.49  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" t   ooooooo                         eee\"\n",
      "batch 4862  loss=125.1885  steps/s=38.98  prediction: \"t: dingboard is the lichess of photoshop\" => \"     oooooo       t               eeeeee\"\n",
      "batch 4863  loss=133.9790  steps/s=108.94  prediction: \" is structured to add llms pretty easily\" => \"ind                     dd              \"\n",
      "batch 4864  loss=117.6293  steps/s=31.76  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @en    c   t   d dd                 \"\n",
      "batch 4866  loss=128.4786  steps/s=107.61  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tl   llllllllll laa aaaaaaaa            \"\n",
      "batch 4867  loss=131.7643  steps/s=89.63  prediction: \"verflow they shoulda forked this instead\" => \"eraolllao ooo  too         fo     k     \"\n",
      "batch 4868  loss=124.8129  steps/s=103.21  prediction: \"ler its always an :x day here on twitter\" => \"ya @suetttttt  t  a   a               et\"\n",
      "batch 4870  loss=134.7009  steps/s=104.55  prediction: \" company dgaf and you can contact those?\" => \"iore            aaaa             ccccccc\"\n",
      "batch 4872  loss=125.4472  steps/s=101.47  prediction: \"and run it in the front end of a browser\" => \"td c e                                  \"\n",
      "batch 4873  loss=162.3140  steps/s=102.24  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" @p4 tnn     ooooooooooooooooooooo//////\"\n",
      "batch 4874  loss=156.9481  steps/s=20.85  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: s      oooooooooooooooooooo////////\"\n",
      "batch 4876  loss=158.6078  steps/s=107.90  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" tot st                     ttttt///////\"\n",
      "batch 4878  loss=131.7464  steps/s=105.47  prediction: \"resent them in (i.e. \"jimmy shot a ballâ€¦\" => \"epl   e eeeeeeet                        \"\n",
      "batch 4879  loss=270.3591  steps/s=99.31  prediction: \": CHECK\n",
      "DELTA TIME: CHECK\n",
      "GRAVITY: CHECK\" => \" @aeP CCCCEEEEEETTTEEEEECCCEEECCCCCCCCCC\"\n",
      "batch 4880  loss=166.2602  steps/s=10.92  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"eply: SCCEEEEEETTTEEEEEECCCEECCCCACCCCCC\"\n",
      "batch 4881  loss=149.7372  steps/s=126.35  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"ebey: @  ooooooc    ttttttttttttttttt///\"\n",
      "batch 4882  loss=152.0350  steps/s=84.94  prediction: \"cicle77 welcome aboard the zig train bro\" => \"o p nt cccccceeceeeettt/tttttttttttzzzaa\"\n",
      "batch 4884  loss=149.2570  steps/s=106.11  prediction: \"insanely OP\n",
      "One idea is to build usefulâ€¦\" => \"n sse slllllnnnnnnnnnnn                 \"\n",
      "batch 4885  loss=176.4257  steps/s=104.58  prediction: \"nly read a bit so far but its super good\" => \" yy is\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                           \"\n",
      "batch 4886  loss=148.5121  steps/s=105.26  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"toclott////////ttttttttStttttt///////ttt\"\n",
      "batch 4887  loss=144.7516  steps/s=103.05  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"edi i      eeeeleeeeee                  \"\n",
      "batch 4888  loss=134.1272  steps/s=104.60  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \"day   t                                 \"\n",
      "batch 4890  loss=132.8826  steps/s=99.81  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" ta e          l                ssssssss\"\n",
      "batch 4891  loss=128.3692  steps/s=99.37  prediction: \"ood at noticing things, would be so kino\" => \"ul   tgggtttttttttttttiiigii            \"\n",
      "batch 4892  loss=135.3394  steps/s=105.15  prediction: \"the highest quality music we have so far\" => \" eo  a   hhhhhhhhh                      \"\n",
      "batch 4893  loss=139.9844  steps/s=104.80  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"ew it                            ???????\"\n",
      "batch 4894  loss=142.5654  steps/s=98.03  prediction: \" lol positive feedback loops are awesome\" => \"toe ea  oooooooo   eeeeeeeee          ee\"\n",
      "batch 4895  loss=139.1282  steps/s=108.40  prediction: \"n pick your own time though its flexible\" => \" ao  do                                 \"\n",
      "batch 4896  loss=119.3237  steps/s=101.54  prediction: \"s and sugar and i dont get tired anymore\" => \" an          aaa                        \"\n",
      "batch 4897  loss=133.3377  steps/s=105.63  prediction: \" the zero quine: https://t.co/qt0qAp9ZYk\" => \"thetttttt                 ttt:tt//qqqqqq\"\n",
      "batch 4898  loss=135.2395  steps/s=102.66  prediction: \"g the cursor with your hands using video\" => \" th   lllll                             \"\n",
      "batch 4899  loss=128.0186  steps/s=104.01  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" ato     eeeeeeeiiiiiiii                \"\n",
      "batch 4900  loss=138.4988  steps/s=100.42  prediction: \"nism oooh possibly, thats a good thought\" => \" nitamesssooooooooooooos  s            t\"\n",
      "batch 4901  loss=140.8363  steps/s=97.79  prediction: \"nks!! feels good to be doing these again\" => \"  m amoo    sss s           oo      gggg\"\n",
      "batch 4903  loss=136.7119  steps/s=104.75  prediction: \"de it one of the best ive had in a while\" => \" chi iii                                \"\n",
      "batch 4904  loss=129.5053  steps/s=99.86  prediction: \"custom extension to watch yt on 4x speed\" => \"oneMc          tttt tttttttttt          \"\n",
      "batch 4905  loss=130.4662  steps/s=105.16  prediction: \"s a natively written zig matmul function\" => \" ar            v             t      tttt\"\n",
      "batch 4906  loss=133.9213  steps/s=38.01  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y    v         v      t    ttt      ttnn\"\n",
      "batch 4907  loss=129.8309  steps/s=107.62  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i                        ttttetttttt\"\n",
      "batch 4908  loss=133.3517  steps/s=102.68  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"hy  cB                                  \"\n",
      "batch 4909  loss=144.3337  steps/s=104.42  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"  n/et:t/////////hhhhhtttttt///////////R\"\n",
      "batch 4910  loss=144.7990  steps/s=99.28  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"nsish                                   \"\n",
      "batch 4911  loss=138.1656  steps/s=100.27  prediction: \"r full potential https://t.co/jR1cEbfQlo\" => \"etn l  l llllll llltttttttttttttttt/////\"\n",
      "batch 4912  loss=135.4768  steps/s=101.95  prediction: \"was making me sleep deprived unknowingly\" => \"hy                     eeeeeeeeeeeeeeeee\"\n",
      "batch 4913  loss=126.7764  steps/s=98.90  prediction: \"ood at noticing things, would be so kino\" => \" k u tttttttttttttttttttgiii            \"\n",
      "batch 4914  loss=129.7061  steps/s=104.78  prediction: \"d\" and they do and then it stops failing\" => \" r tt d    dddddddddddd                 \"\n",
      "batch 4915  loss=135.3809  steps/s=101.53  prediction: \"r tweet was epictetus's two handles idea\" => \"ecoy           eeeeeeeeeetttttttttttssss\"\n",
      "batch 4916  loss=132.0446  steps/s=98.76  prediction: \"is lol. alright alright, target acquired\" => \"n  I     ll   lllll  lllll  attttttttttt\"\n",
      "batch 4917  loss=161.8046  steps/s=99.05  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"t  o   ss    oooooonnnotttttttttttttt///\"\n",
      "batch 4919  loss=163.8158  steps/s=100.46  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" tidei-;;;;;ggggggggttttfffooooooooooo  \"\n",
      "batch 4920  loss=135.6698  steps/s=105.29  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"e c                 uuuuu  tttttttt/////\"\n",
      "batch 4921  loss=137.0012  steps/s=103.43  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"ngy ll         u                        \"\n",
      "batch 4923  loss=133.0716  steps/s=105.46  prediction: \"DLR but could just be forward/left/right\" => \"P\n",
      "iluni        u                     rrr\"\n",
      "batch 4924  loss=131.3304  steps/s=103.77  prediction: \"to a prompt, auto copied to my clipboard\" => \"  i  t                    oooo          \"\n",
      "batch 4925  loss=136.9621  steps/s=105.41  prediction: \"n X and see people dropping crazy things\" => \" i w              eeeeepppppppppppp     \"\n",
      "batch 4926  loss=140.7892  steps/s=102.46  prediction: \"blue, someone is working harder than you\" => \"aile eee  eeeeeeeee                     \"\n",
      "batch 4927  loss=126.5421  steps/s=105.25  prediction: \" some but its not easy to put into words\" => \"tee e          s                   ttttt\"\n",
      "batch 4928  loss=119.8756  steps/s=104.55  prediction: \"g us to blow our fears out of proportion\" => \" t  et s                        oooooooo\"\n",
      "batch 4929  loss=145.5214  steps/s=102.47  prediction: \" be cool to find some other players here\" => \"teu c ooooooooooooo                   ee\"\n",
      "batch 4930  loss=173.9803  steps/s=101.26  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tf  o                  t ttttttttttt////\"\n",
      "batch 4931  loss=139.2815  steps/s=84.34  prediction: \" version control https://t.co/syhjjWL8M6\" => \"te  ee            ttttttt////////////sss\"\n",
      "batch 4932  loss=152.0143  steps/s=106.39  prediction: \"7 make money so you can make video games\" => \"7wrecee ceeeeeon   ooo       oo     aa  \"\n",
      "batch 4933  loss=129.1626  steps/s=104.33  prediction: \"ol shit way more than alcohol and gaming\" => \" l:l i                            aaaaaa\"\n",
      "batch 4934  loss=139.2745  steps/s=103.49  prediction: \" windows update almost bricked my laptop\" => \"th i g         d                        \"\n",
      "batch 4936  loss=136.7294  steps/s=101.16  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \" z n e        nnnnnnnnnnnnnnneeeeeeeeeee\"\n",
      "batch 4937  loss=136.2832  steps/s=105.36  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"n  s  c        enniiitttttttttttttt/////\"\n",
      "batch 4938  loss=177.2249  steps/s=103.99  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e p9biiiiiiiiaaaaaaaaaaaasssssssttt/////\"\n",
      "batch 4939  loss=141.9154  steps/s=104.08  prediction: \"sing way more efficient/scalable methods\" => \" n                    fffeeeeeeeeeeeeeee\"\n",
      "batch 4940  loss=141.2086  steps/s=100.69  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"ti   ia                    tt///////////\"\n",
      "batch 4942  loss=133.9192  steps/s=100.78  prediction: \"efforts\n",
      "\n",
      "mcafee still remained installed\" => \" fteeetee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffffeeeeeeeeeeeeeeeell\"\n",
      "batch 4943  loss=151.7983  steps/s=102.84  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"tYeYYea                            sssss\"\n",
      "batch 4944  loss=134.4011  steps/s=105.48  prediction: \"us things that make your life easier ig?\" => \"st uu iiiiiiiit tttttt                  \"\n",
      "batch 4945  loss=134.2280  steps/s=103.30  prediction: \"ave been trying to compress these lately\" => \"nes loo        n                eeeeeeee\"\n",
      "batch 4946  loss=133.1161  steps/s=103.01  prediction: \"ng and converged to guessing really well\" => \"   eode                   gggggggggg eee\"\n",
      "batch 4947  loss=131.4660  steps/s=105.71  prediction: \"stead of just knowing what they were, Iâ€¦\" => \"    m eeeee    s                        \"\n",
      "batch 4948  loss=148.3106  steps/s=104.59  prediction: \"sidering going down a very similar route\" => \" cohohosssssiiiiggggggnnnn              \"\n",
      "batch 4949  loss=150.5927  steps/s=76.37  prediction: \"eativeBuilds @yacineMTB bro lets connect\" => \" roo @iiiiiiiiiniinn  n           r     \"\n",
      "batch 4950  loss=129.9630  steps/s=104.68  prediction: \"experience but i work w someone who does\" => \" at   eeeeeeeeeneeeee                 oo\"\n",
      "batch 4951  loss=135.2674  steps/s=104.55  prediction: \"pl to influence what they think (cringe)\" => \"ly:t rp        n                        \"\n",
      "batch 4952  loss=129.6831  steps/s=104.87  prediction: \"ink in part bc you have more to remember\" => \"ng ine  ii                              \"\n",
      "batch 4953  loss=129.4805  steps/s=103.98  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \"nbooo o               ddddd             \"\n",
      "batch 4954  loss=142.1725  steps/s=104.38  prediction: \"se and 'magically' econ makes more sense\" => \" t l            aaaaaaa               ee\"\n",
      "batch 4955  loss=129.7171  steps/s=105.01  prediction: \"compress a lifetime into a few sentences\" => \"omp iise                             eee\"\n",
      "batch 4956  loss=179.4445  steps/s=102.50  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"nn an\n",
      "                       7777       \"\n",
      "batch 4957  loss=187.9484  steps/s=38.67  prediction: \"ly: @pepegawitch https://t.co/SATxjQ6nk5\" => \"i  ii                    7777           \"\n",
      "batch 4958  loss=135.2266  steps/s=116.57  prediction: \"yacineMTB Its addicting stuff be careful\" => \" ciin pee        7t7ddsssstt         eeðŸ›‘\"\n",
      "batch 4959  loss=114.9080  steps/s=30.08  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: @pee      t dtdddsssstt         eeðŸ›‘\"\n",
      "batch 4960  loss=136.5690  steps/s=87.39  prediction: \"ly: @shurensha Done. Great advice. Ty ty\" => \"y: @  peeeeI   dddtttdsssttt         eeðŸ›‘\"\n",
      "batch 4961  loss=131.8371  steps/s=110.35  prediction: \"ds (i think, music is not my strongsuit)\" => \" \n",
      "s tr                                  \"\n",
      "batch 4962  loss=134.9331  steps/s=103.45  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "o  eusuuuuuuuuttttttt                  \"\n",
      "batch 4963  loss=143.9870  steps/s=102.88  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"ne tootaaa rrrr sssssssssssssssstt//////\"\n",
      "batch 4964  loss=134.3316  steps/s=105.34  prediction: \"n is a great way to beat some addictions\" => \"gtwoe ssss                              \"\n",
      "batch 4965  loss=131.0925  steps/s=106.49  prediction: \"probably because we were ballin too hard\" => \"lo: @ n  abbbbbbbbbaeeeeeeeeeeeeeee     \"\n",
      "batch 4966  loss=128.0444  steps/s=101.84  prediction: \" im excited to see how you pull this off\" => \"t alll                                  \"\n",
      "batch 4967  loss=147.7282  steps/s=98.91  prediction: \"ed\n",
      "Hes just gonna keep goin up from here\" => \"  ly @ eeeeeee se                       \"\n",
      "batch 4968  loss=130.2220  steps/s=100.72  prediction: \"pany uses it often for researching stuff\" => \"lrp @yoommmm                            \"\n",
      "batch 4969  loss=129.8236  steps/s=105.67  prediction: \"that there were pink cubes at some point\" => \" ei n          t                        \"\n",
      "batch 4970  loss=131.7255  steps/s=103.91  prediction: \"l here is better than funny number go up\" => \"yi e oo                       nnnnnnnnnn\"\n",
      "batch 4971  loss=128.6690  steps/s=104.20  prediction: \"rger abstractions which eventually haveâ€¦\" => \"ee  e    aaaaaaraaarrrrr              ee\"\n",
      "batch 4972  loss=170.5059  steps/s=99.94  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \" l   srrtttriiiii\"\"\"\"\"\"\"ppppppppppp\"\"\"\"\"\"\n",
      "batch 4973  loss=135.7708  steps/s=104.15  prediction: \", or if claude is in an india region tho\" => \" io i iiii                        iiii  \"\n",
      "batch 4974  loss=129.3306  steps/s=105.35  prediction: \". some, years later, have paid off a ton\" => \" i  snmsseeeeeeseeeeeeeeeeeeaaaaa       \"\n",
      "batch 4975  loss=128.4224  steps/s=106.14  prediction: \" bc random twitter guy said itd be funny\" => \"te a m                                  \"\n",
      "batch 4976  loss=142.3306  steps/s=104.82  prediction: \"s\n",
      "\n",
      "been doing this over half my life now\" => \" \n",
      "e  eeeeeeeeeee                        \"\n",
      "batch 4977  loss=138.4905  steps/s=102.77  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"ep c           e    nnnttttttttt////////\"\n",
      "batch 4978  loss=142.2569  steps/s=102.95  prediction: \"uch working tomorrow, key is consistency\" => \"th  ouoooooooootoooooooooooo            \"\n",
      "batch 4979  loss=145.6749  steps/s=95.83  prediction: \"ure Beautiful, and great choice of music\" => \"t   o o    ttuuur                 cccccc\"\n",
      "batch 4980  loss=152.1827  steps/s=97.00  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"ent                    ttttttttttt//////\"\n",
      "batch 4981  loss=128.6927  steps/s=103.66  prediction: \"experience but i work w someone who does\" => \" a\n",
      "   e eeeeeeeneeeee                 oo\"\n",
      "batch 4982  loss=132.1808  steps/s=107.16  prediction: \"n pick your own time though its flexible\" => \" tm pe                                  \"\n",
      "batch 4983  loss=134.4458  steps/s=97.24  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"ne c itaaaaaaaaaaaaaaaaaaaaaaaaaa       \"\n",
      "batch 4984  loss=131.8316  steps/s=103.72  prediction: \"see this everywhere when you look for it\" => \"tpa        eeeeeeeeeeeeeeeeeeeee        \"\n",
      "batch 4985  loss=143.0690  steps/s=103.38  prediction: \" been some adventure man. God bless him.\" => \"te e  eeeeeeeeeeeeeeeeeeeeee            \"\n",
      "batch 4986  loss=132.4616  steps/s=80.75  prediction: \"eigecamry @sunsettler shredded that shit\" => \" n e  eeeeeeeeeneeeeeeeeee   dddddddd   \"\n",
      "batch 4987  loss=133.4072  steps/s=105.65  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"ni eeeh hhhhhaataaaaa                   \"\n",
      "batch 4988  loss=158.9435  steps/s=96.91  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u te  7                  tttttttt//////\"\n",
      "batch 4989  loss=142.2501  steps/s=99.91  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"e ee@Ao    ooooooooooooooooooooooooo    \"\n",
      "batch 4990  loss=142.6829  steps/s=104.31  prediction: \"nce\n",
      "\n",
      "5 depends on not missing ANY of 1-4\" => \" eoo           n   nnnnnnnnnnnnnn       \"\n",
      "batch 4991  loss=126.3298  steps/s=99.71  prediction: \"u can build in a week is actually insane\" => \"ttaoom uuuuu                            \"\n",
      "batch 4992  loss=134.7300  steps/s=103.48  prediction: \"ing vidya except w only positive effects\" => \"ng  ei iiiiiiii                       ee\"\n",
      "batch 4993  loss=153.2889  steps/s=103.21  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"u    m         t                      oo\"\n",
      "batch 4994  loss=128.3047  steps/s=103.51  prediction: \"ink not tho, I believe in synthetic data\" => \"ng        ttt                           \"\n",
      "batch 4995  loss=150.7096  steps/s=99.11  prediction: \"0x_0 how is crypto this good at replying\" => \"  ur@ t                                 \"\n",
      "batch 4996  loss=135.8850  steps/s=103.13  prediction: \"o you get more data) or hit a \"dampener\"\" => \"ut s  oo                                \"\n",
      "batch 4997  loss=125.0567  steps/s=100.51  prediction: \"ood and helps you not waste future years\" => \"udo            d                        \"\n",
      "batch 4998  loss=127.7188  steps/s=102.94  prediction: \"have primitives if you look close enough\" => \"emp i iviiiiiiiviiiiiiiiii            oo\"\n",
      "batch 4999  loss=138.9322  steps/s=99.50  prediction: \"ideally yes. mostly medium sized updates\" => \"nesie illllllllellllyyyyy mmmmmmmm      \"\n",
      "batch 5000  loss=132.4585  steps/s=104.68  prediction: \"t the procedure for doing this is on mac\" => \" ots           r                        \"\n",
      "batch 5001  loss=129.5790  steps/s=100.55  prediction: \"ust linux mints built in text editor lol\" => \"ttioe          t   iiiiiiiii tt tttttttt\"\n",
      "batch 5002  loss=129.9668  steps/s=103.58  prediction: \"file editing program, will show vid soon\" => \" n it    iiiiiiniiiiiiiiiiii ll         \"\n",
      "batch 5003  loss=135.1870  steps/s=100.40  prediction: \" windows update almost bricked my laptop\" => \"th i i         d                        \"\n",
      "batch 5004  loss=131.5893  steps/s=102.76  prediction: \"and completely unknown to the other half\" => \"nd o  ll llllllllll    nnnnnnn          \"\n",
      "batch 5006  loss=117.8156  steps/s=80.24  prediction: \"arcyan now you can make pokemon real too\" => \"nd o   aaa          nnnn     ooooooee   \"\n",
      "batch 5007  loss=135.5662  steps/s=105.29  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \" ie w   lllllll l ooooooo oooooo      e!\"\n",
      "batch 5008  loss=146.8222  steps/s=105.46  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \" o n) n        n                     ___\"\n",
      "batch 5009  loss=132.3738  steps/s=77.64  prediction: \"unsettler Ive made a few, its fun indeed\" => \"s  n nn        n                      nn\"\n",
      "batch 5010  loss=136.2946  steps/s=106.11  prediction: \"e, i would also have liked to be yacine\"\" => \"                                        \"\n",
      "batch 5011  loss=135.7968  steps/s=99.82  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"tet                              ooooooo\"\n",
      "batch 5012  loss=130.7912  steps/s=99.76  prediction: \" new meta\n",
      "dont think too hard about that\" => \"tot k           tttttttttttt            \"\n",
      "batch 5013  loss=134.4157  steps/s=103.28  prediction: \"ck inside my brain. not sure what though\" => \"a ee th        c                        \"\n",
      "batch 5014  loss=133.1525  steps/s=104.25  prediction: \"ant use it for what i need to work on :(\" => \"tdy  r                                  \"\n",
      "batch 5016  loss=134.4302  steps/s=52.11  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @ttae                                  \"\n",
      "batch 5017  loss=119.7693  steps/s=125.48  prediction: \"whoa thats wild, old twitter could never\" => \" e   setttttt    tt       t   tttttt  tt\"\n",
      "batch 5018  loss=130.7755  steps/s=105.11  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"t                 tttttttttttttt////////\"\n",
      "batch 5019  loss=145.7718  steps/s=100.86  prediction: \"employees) do half the work in a company\" => \"               s                        \"\n",
      "batch 5020  loss=134.0449  steps/s=105.34  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \"     a  aaaaaaan                 ///////\"\n",
      "batch 5021  loss=156.0105  steps/s=105.59  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "a h t etteeeeeteeeeee          cccccccc\"\n",
      "batch 5022  loss=151.5937  steps/s=100.33  prediction: \"ock's claude api may not have this issue\" => \"nie ee cccccc  c                        \"\n",
      "batch 5024  loss=193.0084  steps/s=12.17  prediction: \"reply: @gizmobly https://t.co/Lz4uSVD7Gv\" => \"eplc  @cccccc                           \"\n",
      "batch 5025  loss=138.8385  steps/s=121.60  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" ree  ee       e      tteeeeeeeeeeee    \"\n",
      "batch 5026  loss=149.8811  steps/s=45.70  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @se e       gt t    ggeeeeeeee        \"\n",
      "batch 5028  loss=132.6402  steps/s=108.93  prediction: \" if you come across any useful stuff tho\" => \"tn  o                            uuuuuuu\"\n",
      "batch 5029  loss=128.1830  steps/s=57.07  prediction: \": @sunsettler SAP is gonna go hella hard\" => \" @Ba so                        suuffffff\"\n",
      "batch 5030  loss=165.7975  steps/s=106.20  prediction: \"; O(TREE3) btw)\n",
      "These all probably exist\" => \"&@ty)gt&;;;;ttt)t))T)TT))         bbbbbb\"\n",
      "batch 5031  loss=147.1387  steps/s=104.91  prediction: \"velsio im hyped to see what youre cookin\" => \"e  vlllllllll  v                        \"\n",
      "batch 5033  loss=153.0763  steps/s=104.84  prediction: \"o\n",
      "Learn by doing, get compounding skills\" => \" \n",
      "crss                         ooooggnnn\"\n",
      "batch 5034  loss=142.8160  steps/s=97.64  prediction: \"verflow they shoulda forked this instead\" => \"e yor raa  oo  n        oooooddd   iiiii\"\n",
      "batch 5036  loss=183.1289  steps/s=79.28  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" oarr  oo        hhhhhhhh ttt o / ooisss\"\n",
      "batch 5037  loss=161.8955  steps/s=106.96  prediction: \"oing the deadline thing\n",
      "Works super well\" => \"nn aat           ddddddiiiiiiiii e   eee\"\n",
      "batch 5039  loss=140.2637  steps/s=105.10  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"y   ataaaaaaaaa a   tttttttttttttt//////\"\n",
      "batch 5040  loss=150.9505  steps/s=105.00  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u                      ttttttttt////////\"\n",
      "batch 5041  loss=126.2040  steps/s=104.10  prediction: \"ticated strings as defined by kolmogorov\" => \" n o  etttttttttssssssssssss            \"\n",
      "batch 5043  loss=131.5685  steps/s=102.32  prediction: \" new meta\n",
      "dont think too hard about that\" => \"tot i           ttttttttttttt         tt\"\n",
      "batch 5044  loss=172.8079  steps/s=31.95  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: @t      t t tttttttttttt     o   ttt\"\n",
      "batch 5045  loss=125.4746  steps/s=131.33  prediction: \"im gonna read the whole library of babel\" => \"ne e  eeennnn                         bb\"\n",
      "batch 5047  loss=165.6655  steps/s=104.92  prediction: \"ful to me, like use every day type stuff\" => \" l )           l      eeeeeeeeeee       \"\n",
      "batch 5048  loss=135.0304  steps/s=104.70  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"eag   tg            ttttttttttttttttttt/\"\n",
      "batch 5049  loss=144.5674  steps/s=104.59  prediction: \"know what it is\n",
      "\n",
      "https://t.co/wJ5n1H6JUK\" => \"i  an              tttttttttttttttt/////\"\n",
      "batch 5050  loss=151.1472  steps/s=104.42  prediction: \"obably been undervaluing its utility tbh\" => \"nl  t t  eeeeeebeeeeeeeeeeuuuuuuuuuiiiii\"\n",
      "batch 5051  loss=131.5901  steps/s=102.90  prediction: \"t channel you found that effing exploded\" => \" on  k         n                        \"\n",
      "batch 5052  loss=152.4659  steps/s=104.24  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"ttrot/t/////tttttttttttttttttt////////cc\"\n",
      "batch 5053  loss=139.2988  steps/s=104.25  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd t  aaaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5054  loss=123.7871  steps/s=21.16  prediction: \"eply: @mynamebedan head completely empty\" => \" lyn aaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee  \"\n",
      "batch 5055  loss=133.0526  steps/s=107.43  prediction: \"learn and have fun building baller stuff\" => \" ve   r                             llll\"\n",
      "batch 5056  loss=161.7754  steps/s=104.85  prediction: \"ful to me, like use every day type stuff\" => \" n )           l      eeeeeeeeeee       \"\n",
      "batch 5057  loss=131.6356  steps/s=104.59  prediction: \"eel free to run ideas by me whenever btw\" => \" n i  eeeeeeee                    eeeeee\"\n",
      "batch 5058  loss=144.5294  steps/s=104.61  prediction: \"ooks like from someone elses perspective\" => \"ulha              ooooooooeeeeeeeeeeeeee\"\n",
      "batch 5059  loss=135.6482  steps/s=103.13  prediction: \"ould keep going) https://t.co/zZj3emr1oN\" => \"ut                          tttttttt////\"\n",
      "batch 5060  loss=127.3218  steps/s=99.69  prediction: \"see more details as you unblur an image.\" => \"  uu  ee eeeeeeeeeeee       s       uuuu\"\n",
      "batch 5061  loss=130.6465  steps/s=105.46  prediction: \"verything that happens to everyone else'\" => \"erytee ee   ttt ttttttttttt     eeeeeeee\"\n",
      "batch 5062  loss=193.1500  steps/s=88.45  prediction: \"gABAP @yacineMTB https://t.co/NDBKphrBEW\" => \" Bt   e   iit     aaa tttttttttteee/eeee\"\n",
      "batch 5063  loss=129.7366  steps/s=105.50  prediction: \" bc random twitter guy said itd be funny\" => \"tema m                                  \"\n",
      "batch 5064  loss=162.0452  steps/s=99.83  prediction: \"2 and a monkey pfp too.. this is bananas\" => \".p                                      \"\n",
      "batch 5065  loss=133.7017  steps/s=105.04  prediction: \"ly when you try to build the thing again\" => \"y   o c        n                        \"\n",
      "batch 5066  loss=168.2732  steps/s=97.03  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"au e nnnnnnn yy y     ..ttt.t.tttttt////\"\n",
      "batch 5067  loss=128.2932  steps/s=105.51  prediction: \"st powerful learning techniques there is\" => \"    so                 eeeeeeeeeeeeeeeee\"\n",
      "batch 5068  loss=131.1825  steps/s=101.68  prediction: \"ne that sends the html/js/etc files over\" => \"   eree            tttttttttttttttt   ee\"\n",
      "batch 5069  loss=146.0811  steps/s=104.45  prediction: \"ting the entire GOL industry as we speak\" => \" nhe m         t                        \"\n",
      "batch 5070  loss=125.8777  steps/s=104.83  prediction: \"w if you know they answered w/o thinking\" => \"ht   b                      wwwwwwwww   \"\n",
      "batch 5071  loss=137.5358  steps/s=100.47  prediction: \"ed me understand https://t.co/LHjT6ITtSs\" => \"  b:       eeeeeeeeeedddttttt/////////tt\"\n",
      "batch 5072  loss=127.1464  steps/s=104.82  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" o    eeeeeeeeete                tttttt \"\n",
      "batch 5073  loss=135.2037  steps/s=103.68  prediction: \"e tbh\n",
      "My projects arent that big yet tho\" => \" pe  eeeeeeeeeeeeeeeeeeee ettttttttttttt\"\n",
      "batch 5074  loss=154.0745  steps/s=89.53  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eely: @  rrr  rt00000   ttttttt  ee     \"\n",
      "batch 5075  loss=128.2912  steps/s=105.91  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \" wit  t                          uu     \"\n",
      "batch 5077  loss=131.0001  steps/s=105.17  prediction: \"10mins on a puzzle just try ur best gues\" => \"0 e g  nnnnnn                           \"\n",
      "batch 5078  loss=158.5675  steps/s=70.48  prediction: \"HSVSphere just barely hit max call depth\" => \"am  h  n                                \"\n",
      "batch 5079  loss=131.8756  steps/s=106.41  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" tingneeeeeeeeeneeeeeeeeeeeetttttttooooo\"\n",
      "batch 5080  loss=136.4890  steps/s=100.16  prediction: \"an that sounds like such a relaxing time\" => \"nd g tttttttttt         s               \"\n",
      "batch 5081  loss=143.6176  steps/s=101.30  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" an           t ttttttttttttttttttt     \"\n",
      "batch 5082  loss=129.7330  steps/s=98.67  prediction: \"oo much context switching to twitter idk\" => \"uk  t          c    tttttttttttttttttttt\"\n",
      "batch 5083  loss=135.6794  steps/s=102.80  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"taeoo       mmm mmmmmm   ttttttttttppppp\"\n",
      "batch 5084  loss=125.0661  steps/s=103.73  prediction: \" of twitter it usually means engineering\" => \"tf t        ttttttttt              eeeee\"\n",
      "batch 5086  loss=131.1924  steps/s=105.66  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o  m         m                        \"\n",
      "batch 5087  loss=195.7040  steps/s=95.64  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \" tim    yyyyyy    ttttttttttttttt////tto\"\n",
      "batch 5088  loss=125.1009  steps/s=102.73  prediction: \"rner u can actually set them to 2x speed\" => \"e t            n                        \"\n",
      "batch 5089  loss=136.9045  steps/s=105.73  prediction: \" extreme levels of being acoustic though\" => \"ts t ssss    eeseeeeeeeeeeeeee          \"\n",
      "batch 5091  loss=146.2655  steps/s=103.37  prediction: \"ou get faster and faster at solving them\" => \"ug y                                    \"\n",
      "batch 5092  loss=131.1336  steps/s=104.96  prediction: \"ty programming that in, its over, robotâ€¦\" => \"h   t  tiiiiiiiiiiiiiiiiiiii            \"\n",
      "batch 5093  loss=151.3046  steps/s=104.18  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"toDD D               eeettt///////////zt\"\n",
      "batch 5094  loss=128.3605  steps/s=104.29  prediction: \" will get back to you when this is fixed\" => \"thee h llllll                           \"\n",
      "batch 5096  loss=166.0907  steps/s=100.70  prediction: \"ng jai??? Instantly 10x more interesting\" => \" 8 n l      ?????????                   \"\n",
      "batch 5097  loss=132.8022  steps/s=103.00  prediction: \"ns the returns are high on more of it :)\" => \"   i  h        s                        \"\n",
      "batch 5098  loss=173.4736  steps/s=96.87  prediction: \"d @gizmobly @covix2772 store files in it\" => \" ph       rr               oo           \"\n",
      "batch 5099  loss=130.5068  steps/s=102.87  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \"uri ii                                  \"\n",
      "batch 5100  loss=131.5261  steps/s=99.96  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" s e eeeeee e  e      ggeeeeeeeeeeeee   \"\n",
      "batch 5101  loss=126.0751  steps/s=97.12  prediction: \"mirages keep getting crazier and crazier\" => \"and a g      egeeeeeeeeeeeeee         rr\"\n",
      "batch 5102  loss=129.5200  steps/s=104.83  prediction: \". some, years later, have paid off a ton\" => \" s  s msseeeeeeseeeeeeeeeeeeaaaaa       \"\n",
      "batch 5104  loss=130.2291  steps/s=98.70  prediction: \"c high entropy stuff that fits the curve\" => \"oup  taaaaaa               ttttttttttttt\"\n",
      "batch 5105  loss=139.4494  steps/s=102.85  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyd                                   \"\n",
      "batch 5106  loss=130.7036  steps/s=103.16  prediction: \" is interesting play between those three\" => \"tn  e       eeeteeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5107  loss=171.0659  steps/s=99.60  prediction: \"locking @ludwigABAP circleboard!?!?!?!?!\" => \"ys @eoeeeoollliilllgggiiiicAAAAAccccrrr!\"\n",
      "batch 5108  loss=150.7140  steps/s=70.45  prediction: \"2wlearning Great stuff man, keep pushing\" => \"    eoelllnnngggg A A ccccc     e !!!???\"\n",
      "batch 5109  loss=146.3558  steps/s=107.24  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \"hln  i       aaaaaatttttttttttttttt/////\"\n",
      "batch 5110  loss=151.9263  steps/s=100.39  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"nh t@       ttt  ttttttttttttt//////////\"\n",
      "batch 5111  loss=163.5551  steps/s=98.00  prediction: \"eople be bookmarking anything these days\" => \" psd_@_Mpppp   e    kkkkkkk             \"\n",
      "batch 5112  loss=146.5075  steps/s=104.75  prediction: \"tem\n",
      "- SPHERE GUN https://t.co/tqM3ZpJCkN\" => \"hxn  dd                   ttt//////////t\"\n",
      "batch 5113  loss=148.0228  steps/s=100.66  prediction: \" joining man, looking forward to thurs!!\" => \"@ues\n",
      "eeooonnnnnnnnnnnnnoooooooooo       \"\n",
      "batch 5114  loss=177.3419  steps/s=105.32  prediction: \"/t.co/lBwBETlxDd cats are insane animals\" => \"t.cost/////////tBBBBBBBttttt     aaaaaaa\"\n",
      "batch 5115  loss=135.3290  steps/s=104.88  prediction: \"memory of doing a hard thing in the past\" => \"e hiea                                  \"\n",
      "batch 5117  loss=157.6808  steps/s=103.96  prediction: \"orks but is mvp\n",
      "\n",
      "https://t.co/0jdbSxKeVi\" => \"uk amm                    \n",
      "\n",
      "ttttt///////\"\n",
      "batch 5118  loss=153.1760  steps/s=102.72  prediction: \"dgrammer it was a really fun time though\" => \"  a1 mrrrrrrrrrrrrrr                    \"\n",
      "batch 5119  loss=134.6490  steps/s=102.37  prediction: \" of all time itd be sebby and his 9 alts\" => \"@f     oollllll l                       \"\n",
      "batch 5121  loss=126.8009  steps/s=99.09  prediction: \"ood direction to get more good direction\" => \"uk a eeee eeeeedooooooooooooo oooooooooo\"\n",
      "batch 5122  loss=131.1141  steps/s=87.79  prediction: \"ochenko curious, can you elaborate more?\" => \"uo a eeeeoooooooo o  oo    ooooooeeeoooo\"\n",
      "batch 5123  loss=131.1212  steps/s=103.19  prediction: \"tle robots\n",
      "\n",
      "they remove so much friction\" => \"hec od l     ttetttttteeeeeeeeee        \"\n",
      "batch 5124  loss=132.5924  steps/s=104.60  prediction: \"dit on my phone)\n",
      "https://t.co/iWZ4An9PaZ\" => \" t                    tttttttttttt/ttt//\"\n",
      "batch 5125  loss=137.3260  steps/s=105.00  prediction: \"r reward, wrecking the incentive to work\" => \"ecec ieeeeeerrrrrrrrrrrr      eeeeee    \"\n",
      "batch 5126  loss=127.7603  steps/s=102.29  prediction: \"reevaluating concepts you often overlook\" => \"e ly   aaaaaaaaaaaannnnnn        ooooooo\"\n",
      "batch 5127  loss=131.7594  steps/s=107.56  prediction: \"t (for example working when youre tired)\" => \"hmoush ooooooooooooor                   \"\n",
      "batch 5128  loss=138.1297  steps/s=106.03  prediction: \"ool looking games, and get more interest\" => \"rrse   oooooooooooooo                 ee\"\n",
      "batch 5129  loss=136.2519  steps/s=104.20  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"tn l le        e                        \"\n",
      "batch 5130  loss=133.3249  steps/s=86.05  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"eli   e        n d                      \"\n",
      "batch 5131  loss=167.4254  steps/s=68.20  prediction: \" @thetechbrother https://t.co/nOiteSF1jC\" => \"tll   e     c    e     ttstttttnnnnn   ðŸ›‘\"\n",
      "batch 5132  loss=133.8250  steps/s=107.45  prediction: \" long long time\n",
      "\n",
      "https://t.co/svmrGr008p\" => \"aot a            gg     tttttttt///ttt//\"\n",
      "batch 5133  loss=129.7640  steps/s=104.51  prediction: \"u decide to start building it initially?\" => \"rc                            iiiiiiiiii\"\n",
      "batch 5135  loss=131.2622  steps/s=101.26  prediction: \" knowing linux is a massive weakness imo\" => \"@in onnnnnnnnnnnnnnn              ssssss\"\n",
      "batch 5136  loss=137.7909  steps/s=103.36  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n  t                     ttttttt////////\"\n",
      "batch 5137  loss=153.3799  steps/s=105.00  prediction: \"esponses\n",
      "4 repeat step 3 til you have 1â€¦\" => \" s  t   ssssssssesseeeeeeeeee           \"\n",
      "batch 5138  loss=137.9784  steps/s=105.33  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yo    b               ttttttttttttt/////\"\n",
      "batch 5139  loss=140.6713  steps/s=103.90  prediction: \"re advanced in the art of shape rotating\" => \"eply:                                   \"\n",
      "batch 5140  loss=144.5358  steps/s=21.25  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" ly                                     \"\n",
      "batch 5141  loss=136.8576  steps/s=119.18  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"trs eee            sssssssssssttttt/////\"\n",
      "batch 5142  loss=129.4975  steps/s=105.63  prediction: \" the ladder on what strats are possible.\" => \"thet                                    \"\n",
      "batch 5143  loss=153.7276  steps/s=98.88  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"tbth    ee          ttttttttttttttt///88\"\n",
      "batch 5144  loss=110.8712  steps/s=21.20  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @  ee        tttttttttttttttt/88888\"\n",
      "batch 5145  loss=128.4759  steps/s=108.67  prediction: \"reevaluating concepts you often overlook\" => \"e ly  aaaaaaaaaaaaannnnnn         oooooo\"\n",
      "batch 5146  loss=139.2237  steps/s=104.80  prediction: \"aw of undulation https://t.co/VdFFnrRkLH\" => \"n  ne                ttttttttttttttttt//\"\n",
      "batch 5147  loss=129.4898  steps/s=104.50  prediction: \"that leads nowhere + info that clustersâ€¦\" => \"heoeie                                  \"\n",
      "batch 5148  loss=141.0359  steps/s=97.37  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" dio              tttttttttttttttttt////\"\n",
      "batch 5149  loss=131.5128  steps/s=97.07  prediction: \"TB strategy is an abstraction of tactics\" => \"h  sieteeetttttt tt       ss at ttttccco\"\n",
      "batch 5150  loss=138.7082  steps/s=103.54  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"ndn oteaaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5151  loss=138.5757  steps/s=98.57  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" d   @           ttttttttttttttttttt////\"\n",
      "batch 5152  loss=139.2548  steps/s=96.21  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n o    ii      s                h       \"\n",
      "batch 5153  loss=139.9528  steps/s=103.43  prediction: \"rflowsucks and never went on there again\" => \"e oy  aooossssssssssseeeeeee    eeeeeeee\"\n",
      "batch 5154  loss=132.1314  steps/s=101.63  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \"gid e          aaaaaaaaaaaaaaahhhhhh  ee\"\n",
      "batch 5155  loss=130.0019  steps/s=105.19  prediction: \" can instantly runit w the runit command\" => \"to  s           nnnnnnn                 \"\n",
      "batch 5156  loss=133.5184  steps/s=105.04  prediction: \"the behavior, forming a habit eventually\" => \"he  igeeeeeeee n                        \"\n",
      "batch 5157  loss=146.1509  steps/s=103.28  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omcec  cccc               tttttttttttt//\"\n",
      "batch 5158  loss=153.2273  steps/s=87.91  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \"hle  h  eeeeeeo            t///aooooo\n",
      "oo\"\n",
      "batch 5159  loss=131.3337  steps/s=103.84  prediction: \"unny for your runway\n",
      "\n",
      "Idk just a thought\" => \"sd rene        r rrrrrrrrruuuuuu        \"\n",
      "batch 5160  loss=131.6443  steps/s=103.65  prediction: \" yrs. ur brain will figure it out, trust\" => \"toai            rrr       iiiiiii       \"\n",
      "batch 5161  loss=125.0787  steps/s=104.07  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"li d tttttttttttt               eeeeeeee\"\n",
      "batch 5162  loss=127.6892  steps/s=102.77  prediction: \"ing and shipping is gonna grow immensely\" => \"ng oh  n  npppp pppppiiinnnnggggg       \"\n",
      "batch 5163  loss=149.8787  steps/s=97.35  prediction: \"s message is NOT approved by square gang\" => \" in i  ssssssssssss                     \"\n",
      "batch 5164  loss=130.6269  steps/s=103.97  prediction: \"we need shape rotator models already smh\" => \"arn      eeeeeeneeeeeeeeeeeeoooo  e  aaa\"\n",
      "batch 5165  loss=143.9128  steps/s=104.12  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e eiigRttttttt t                        \"\n",
      "batch 5166  loss=190.7004  steps/s=22.40  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly: @Rtttt                             \"\n",
      "batch 5167  loss=129.5722  steps/s=130.97  prediction: \"oo much context switching to twitter idk\" => \"nla            m  tt  ttttcctttttttttttt\"\n",
      "batch 5168  loss=134.0956  steps/s=104.73  prediction: \" so I invested my time into that instead\" => \"torterooo                          ttttt\"\n",
      "batch 5169  loss=139.5750  steps/s=103.87  prediction: \"' bc thats the name of the 4min mile guy\" => \" o   e'ttttttttttttt                    \"\n",
      "batch 5170  loss=136.9081  steps/s=104.97  prediction: \", how much info could you get from that?\" => \" ao  i         m                        \"\n",
      "batch 5171  loss=125.9256  steps/s=104.27  prediction: \"ht. i feel like i barely understand them\" => \"eh i                           eeeee eee\"\n",
      "batch 5172  loss=132.0089  steps/s=105.74  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"  ie                   eeeeeeeeeehhhhhh \"\n",
      "batch 5173  loss=123.9303  steps/s=99.26  prediction: \"feeling than automating hrs of work away\" => \" lm  eeeeeeee  eeaaaaaaaaattttt         \"\n",
      "batch 5175  loss=180.8893  steps/s=29.58  prediction: \"ply: @sunsettler https://t.co/2ERTWsJiwS\" => \"lyn: eeeeeeee  eaaattaatattttt          \"\n",
      "batch 5176  loss=149.3683  steps/s=127.99  prediction: \"he second one Unison (Knife Party Remix)\" => \"ey e  A      e    nnnnnnnnnnnnnnnnn     \"\n",
      "batch 5177  loss=127.2816  steps/s=101.39  prediction: \"resting, what kinds of tools has he made\" => \"eply: @nnnnne  n i                      \"\n",
      "batch 5178  loss=132.4006  steps/s=103.83  prediction: \"ces to back him up\n",
      "\n",
      "stand user type shit\" => \"ese            c                        \"\n",
      "batch 5179  loss=132.4731  steps/s=64.40  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"jizm6be  k                      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  t\"\n",
      "batch 5180  loss=125.3029  steps/s=106.47  prediction: \"anifold, like on the surface of a sphere\" => \"nt on ooo                               \"\n",
      "batch 5181  loss=133.3320  steps/s=102.90  prediction: \"re. it can only get 103 on snake though.\" => \"e le  eee                               \"\n",
      "batch 5182  loss=128.5562  steps/s=102.73  prediction: \"r, it felt a little linkediny over there\" => \"e iy: @tttttttt tttttttttllllllli    eee\"\n",
      "batch 5183  loss=139.7578  steps/s=102.37  prediction: \"6x speed version https://t.co/yCogzpgz92\" => \"2  m                      sssst/////////\"\n",
      "batch 5184  loss=144.3564  steps/s=60.25  prediction: \" @sunsettler all my homies HATE openings\" => \"tJao     eeeeeee         sss//////pppppz\"\n",
      "batch 5186  loss=245.8848  steps/s=96.60  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"jsianaeeeeeeee          ss  OOOOOOOOOOOO\"\n",
      "batch 5187  loss=229.0322  steps/s=112.83  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"PAP      LEEOOOOOOOOOOOOGG  tttt////////\"\n",
      "batch 5188  loss=147.9054  steps/s=103.11  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e  t     rrrrrrrrrrrrrrrrrr             \"\n",
      "batch 5189  loss=155.7179  steps/s=21.03  prediction: \"eply: @tszzl &gt; the present will\n",
      "how??\" => \" ly:   rrrrrrrrrrrrrrrrrr               \"\n",
      "batch 5190  loss=132.0127  steps/s=117.13  prediction: \"u come up with. Forgetfulness is a bitch\" => \"rc                          e e         \"\n",
      "batch 5191  loss=183.8860  steps/s=101.89  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"tipek/yyymmmmmmmmm ::t:::ttt:///tt//////\"\n",
      "batch 5192  loss=155.0406  steps/s=103.24  prediction: \"hackers #buildinpublic #developers #SaaS\" => \"et steeeeeeeeeiiiiiiiiiiiiiiiiiieeeeeeee\"\n",
      "batch 5193  loss=133.7173  steps/s=105.40  prediction: \"than \"heres a tool to solve problem xyz\"\" => \"han  ihhhhhhh  r                oooooooo\"\n",
      "batch 5194  loss=129.9404  steps/s=104.16  prediction: \"d size to whatever you want which helps.\" => \" ao s                               hhhh\"\n",
      "batch 5195  loss=131.8417  steps/s=102.17  prediction: \"r tweet was epictetus's two handles idea\" => \"ettt  @        eeeeeeeeeettttttttttt sss\"\n",
      "batch 5196  loss=145.2797  steps/s=104.01  prediction: \"as the guide on how to beat mind viruses\" => \"t ing                                   \"\n",
      "batch 5197  loss=131.8934  steps/s=89.29  prediction: \"ly @plasmarob you could have a miz mobly\" => \"y: @gu         s o oooooo               \"\n",
      "batch 5198  loss=130.6661  steps/s=104.65  prediction: \"his, and even then you might get mislead\" => \"en eoo                                  \"\n",
      "batch 5199  loss=135.6212  steps/s=100.90  prediction: \"or always posting these, they're great ðŸ‘\" => \"u e eesaaaaaaaassssssssssssstttteeeeeeee\"\n",
      "batch 5200  loss=136.4986  steps/s=103.63  prediction: \"ould keep going) https://t.co/zZj3emr1oN\" => \"ur                          tttttt//////\"\n",
      "batch 5201  loss=134.8883  steps/s=101.82  prediction: \"marter you get the more the traps change\" => \"etl  a                                  \"\n",
      "batch 5202  loss=134.2118  steps/s=103.59  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \"   pa                 eeeeeeeeeeeee iiii\"\n",
      "batch 5203  loss=146.7874  steps/s=36.03  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: ill              eeeeeeeeeee iiiiiii\"\n",
      "batch 5204  loss=153.8963  steps/s=144.45  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \"hcn  looo    A                        tt\"\n",
      "batch 5205  loss=134.7868  steps/s=104.25  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng oo          n                  uuuu  \"\n",
      "batch 5206  loss=132.3339  steps/s=102.97  prediction: \"ang out in tunisia every once in a while\" => \"nd ee t                                 \"\n",
      "batch 5207  loss=150.4777  steps/s=103.59  prediction: \"st tab\n",
      "\n",
      "other than that, not much so far\" => \"  to t tttttttt tttttttttttttttttt      \"\n",
      "batch 5208  loss=151.5092  steps/s=90.27  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \" lo o e tttoooooo     a nnnnnnnn  ooo   \"\n",
      "batch 5209  loss=153.0266  steps/s=98.92  prediction: \"ily @ineedtolocking @kuberdenis detected\" => \"ni tellllloooooooooooonoooooo       eeee\"\n",
      "batch 5210  loss=128.9640  steps/s=102.41  prediction: \" regarded so take that w a grain of salt\" => \"tenl  ii                                \"\n",
      "batch 5211  loss=135.1518  steps/s=101.93  prediction: \"g the cursor with your hands using video\" => \" to  ll lll                             \"\n",
      "batch 5212  loss=147.4154  steps/s=104.39  prediction: \"/t.co/bGCVZbuoNU https://t.co/CPaVjqg1AU\" => \"p.dc  tt//////////tttttttttt//////////VV\"\n",
      "batch 5213  loss=127.0697  steps/s=103.69  prediction: \"mething. like when youre waiting in line\" => \"ashe oo o                         iiiiii\"\n",
      "batch 5214  loss=132.0732  steps/s=105.08  prediction: \"aking a day off caffeine helped fix this\" => \"ne n ltaaaaaaaaaaaaaaafffffffffffff     \"\n",
      "batch 5215  loss=131.3412  steps/s=103.36  prediction: \"te how much some debuffs will damage yoâ€¦\" => \"  n  ee ttt    t                        \"\n",
      "batch 5216  loss=132.6834  steps/s=100.14  prediction: \"pany uses it often for researching stuff\" => \"lsx @yommmm                             \"\n",
      "batch 5217  loss=129.9026  steps/s=105.45  prediction: \"o halt with a general halting function?\"\" => \"ust t                                nnn\"\n",
      "batch 5218  loss=153.6955  steps/s=86.97  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"epl m @ttt     n        aa          nn  \"\n",
      "batch 5219  loss=133.1816  steps/s=104.67  prediction: \" in terms of your thoughts in each \"era\"\" => \"tt e e         m                        \"\n",
      "batch 5220  loss=128.7374  steps/s=99.89  prediction: \" glitches\n",
      "your game is looking great btw\" => \"teme        ee e eeee                   \"\n",
      "batch 5221  loss=137.9501  steps/s=104.18  prediction: \"\n",
      "\n",
      "the command runit runs the last output\" => \"\n",
      "tt n          t                        \"\n",
      "batch 5222  loss=132.4377  steps/s=104.20  prediction: \"e, i would also have liked to be yacine\"\" => \"    a                                   \"\n",
      "batch 5223  loss=136.1062  steps/s=105.51  prediction: \"epts end up just being 'oh its just xyz'\" => \" lyco                                   \"\n",
      "batch 5224  loss=173.4456  steps/s=104.19  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e ie                                  ??\"\n",
      "batch 5225  loss=133.3400  steps/s=104.23  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"  s ididdddddddddddtttttttttttttttcccccc\"\n",
      "batch 5226  loss=130.6227  steps/s=105.31  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"                        iooooooooooooooo\"\n",
      "batch 5227  loss=144.0175  steps/s=103.60  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf                                      \"\n",
      "batch 5228  loss=128.9947  steps/s=105.62  prediction: \"s large of a positive impact as possible\" => \" Iiea aaa                             ss\"\n",
      "batch 5229  loss=136.9579  steps/s=101.87  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" of eaaaaaaaa           tttttttttt//////\"\n",
      "batch 5230  loss=138.1980  steps/s=91.14  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"il aaaaaa      c        tttt/tttttn22n2 \"\n",
      "batch 5233  loss=128.2233  steps/s=106.43  prediction: \"onna think in terms of utility and price\" => \"ue      nnnnnnnnnnnn                    \"\n",
      "batch 5234  loss=132.9583  steps/s=105.60  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" on t      aaaaaaaaaaaannnnnnnnnnnnnnnnn\"\n",
      "batch 5235  loss=126.7594  steps/s=101.37  prediction: \"e or desire to practice for other things\" => \" doott                                  \"\n",
      "batch 5236  loss=154.4703  steps/s=105.91  prediction: \"keep that in mind\n",
      "idk what brypto is btw\" => \" ll rl                                  \"\n",
      "batch 5238  loss=146.6553  steps/s=104.81  prediction: \"d LLMs to get boilerplate and stuff done\" => \" sttAnnnn      t                        \"\n",
      "batch 5239  loss=143.5175  steps/s=104.62  prediction: \"nce\n",
      "\n",
      "5 depends on not missing ANY of 1-4\" => \"deoo  a        n   nnnnnnnnnnnnnn       \"\n",
      "batch 5240  loss=136.8580  steps/s=104.04  prediction: \"e WAY more effective\n",
      "\n",
      "global optima gang\" => \" li ie         eeeeeeeeeeeeeeeeeee      \"\n",
      "batch 5241  loss=130.5244  steps/s=98.50  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" te            l                mm    \n",
      "\n",
      "\"\n",
      "batch 5242  loss=136.4776  steps/s=92.16  prediction: \"iplying cells literally changed my life.\" => \"nh  u  lllllllllllllllllllllllllll    ll\"\n",
      "batch 5243  loss=141.7249  steps/s=96.63  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \" keneiih  oo      ggggggeesggggge llll  \"\n",
      "batch 5244  loss=132.8234  steps/s=105.06  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"f  o  s        s              aaaaaaa   \"\n",
      "batch 5245  loss=127.8786  steps/s=96.37  prediction: \"yb is this founder mode or manager mode?\" => \": i0 f                  oo              \"\n",
      "batch 5246  loss=258.9196  steps/s=98.06  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"B tor  OOOOOOOOEEOMTM      ttttt////////\"\n",
      "batch 5247  loss=135.3068  steps/s=99.38  prediction: \"t gotta watch out for the poison lizards\" => \" an      ttttttttttttttttt     ooooooooo\"\n",
      "batch 5248  loss=132.7845  steps/s=105.34  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o            m                        \"\n",
      "batch 5250  loss=137.6398  steps/s=100.53  prediction: \"ffects that are extremely hard to notice\" => \" e   leeeeeeeeeteeeeeeeeeeeeeeeee       \"\n",
      "batch 5251  loss=131.8624  steps/s=104.20  prediction: \"llows you to better descend the gradient\" => \"yis  ool                   eeeeeeeeeeeee\"\n",
      "batch 5252  loss=141.2185  steps/s=98.01  prediction: \" bet, im down, whats a good time for you\" => \"ie m                                    \"\n",
      "batch 5253  loss=150.2474  steps/s=104.49  prediction: \"f us have jobs)\n",
      "\n",
      "https://t.co/qTcrhcfjBM\" => \" y  oo                 tttttttt/////////\"\n",
      "batch 5254  loss=192.0563  steps/s=97.30  prediction: \"w many GFLOPS? Are these legal in CA????\" => \"otk y                      eeeeeeeeeee e\"\n",
      "batch 5255  loss=133.7780  steps/s=104.20  prediction: \"ve to somewhere else\n",
      "\n",
      "idk just a thought\" => \"e    ee    eeeemeeeeeeeeeeeeeee         \"\n",
      "batch 5256  loss=127.2474  steps/s=103.80  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" o s o  oooo                         eee\"\n",
      "batch 5257  loss=134.2263  steps/s=105.00  prediction: \" your brain insanely bad in the long run\" => \"tou            r                        \"\n",
      "batch 5258  loss=123.0559  steps/s=28.99  prediction: \"st: caffeine is steroids but for posting\" => \"  ei           r     aa               nn\"\n",
      "batch 5259  loss=146.4515  steps/s=110.07  prediction: \" it can be! Nice https://t.co/7gl6yX5jXL\" => \"tf   e....                tttttttttt////\"\n",
      "batch 5260  loss=155.2117  steps/s=103.97  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t    0                                nn\"\n",
      "batch 5261  loss=165.4341  steps/s=106.45  prediction: \"expected him to be maybe 55 or something\" => \" s  s I  eeeee                          \"\n",
      "batch 5262  loss=138.7171  steps/s=103.90  prediction: \"e in milan venice florence.. sorrento rn\" => \" t   oo      nnnnnnnn nnneeeeeeeeeeeeeee\"\n",
      "batch 5263  loss=131.1943  steps/s=71.03  prediction: \"ryvyo no ffmpeg itd be too slow id think\" => \"e  y  @ n   nnn  f   e  eee eeoooo o r  \"\n",
      "batch 5264  loss=164.6132  steps/s=84.05  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"yudinrA                     ooooo  !!!!!\"\n",
      "batch 5265  loss=149.4838  steps/s=113.12  prediction: \"owser gif editor\n",
      "https://t.co/CWUD0xLmZ4\" => \" e i  o             ttttttttttttttttt///\"\n",
      "batch 5266  loss=133.5245  steps/s=103.85  prediction: \"is such a great productivity improvement\" => \"n  cs                          ttiiiiiii\"\n",
      "batch 5267  loss=133.7874  steps/s=29.62  prediction: \"ply: @ludwigABAP Oh based it keeps going\" => \"ly:  i                     tt iiiiiiiiit\"\n",
      "batch 5268  loss=168.5655  steps/s=110.62  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \" to s  mm           tttttttttttttttt////\"\n",
      "batch 5269  loss=147.4730  steps/s=79.11  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"ys a            tttttttttt//////////TTTT\"\n",
      "batch 5270  loss=146.4008  steps/s=110.16  prediction: \"coder trust me bro im high iq, see above\" => \"ous   aeeeeeeee                         \"\n",
      "batch 5271  loss=127.5758  steps/s=104.22  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"e i   ii                         iiiiiii\"\n",
      "batch 5272  loss=206.1114  steps/s=102.25  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"B YFUTA              FF             ////\"\n",
      "batch 5273  loss=137.2574  steps/s=105.52  prediction: \"ut from having 1/3rd the progress per hr\" => \"t ent                         rrrrrrrrrr\"\n",
      "batch 5274  loss=127.9906  steps/s=60.46  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"i n                         rrrr   r  rr\"\n",
      "batch 5275  loss=133.3060  steps/s=87.22  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"i n   r    nn yn    o    rrrrrrr        \"\n",
      "batch 5276  loss=133.7631  steps/s=107.95  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng in iiii    d ddddddddddddddd         \"\n",
      "batch 5277  loss=125.9238  steps/s=100.25  prediction: \"ould get my ass handed to me for suuuure\" => \"u     w        l                        \"\n",
      "batch 5278  loss=158.1770  steps/s=104.99  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "oh  t eteeeeeeteeeeee           ccccccc\"\n",
      "batch 5279  loss=136.6510  steps/s=104.16  prediction: \" You can hide these with adblock i think\" => \"iow o  oo                               \"\n",
      "batch 5280  loss=133.4325  steps/s=101.38  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \" r etieeeeeeeeeneeeeeelllll sssssssssss \"\n",
      "batch 5281  loss=131.6406  steps/s=104.07  prediction: \" apart and send each one off to an agent\" => \"ine t          a                        \"\n",
      "batch 5282  loss=134.8655  steps/s=102.41  prediction: \"inful to stfu but it works suuuuper well\" => \"ne ua          t       t      uuuuuuuuuu\"\n",
      "batch 5283  loss=118.9149  steps/s=32.88  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @oo       uuu t          uuuuuuuuuuu\"\n",
      "batch 5285  loss=136.9511  steps/s=117.96  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"u enooooooooooonoo           e  eeeeeeee\"\n",
      "batch 5286  loss=131.8155  steps/s=104.86  prediction: \"t immensely and give you new information\" => \" ing  e        n                        \"\n",
      "batch 5287  loss=156.0104  steps/s=96.89  prediction: \"minds me of this https://t.co/Qoy9ykJ35M\" => \"onhae eemm                 ttttt////////\"\n",
      "batch 5288  loss=132.0001  steps/s=105.13  prediction: \" so that the context switch is seamless.\" => \"toa                 tttttttttttttt sssss\"\n",
      "batch 5289  loss=127.5807  steps/s=105.45  prediction: \"ything rewarding that follows from that)\" => \" irgaiigieeerrrerrrrrrrr                \"\n",
      "batch 5290  loss=138.9912  steps/s=97.45  prediction: \"o went too high. Looped back around to 0\" => \"umew eweeeee          ooooooo  oo    o  \"\n",
      "batch 5291  loss=146.4258  steps/s=102.69  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame                                    \"\n",
      "batch 5292  loss=128.4715  steps/s=104.14  prediction: \"en clusters into single tokens like this\" => \" t  e eeeeeeeeet                        \"\n",
      "batch 5293  loss=132.5265  steps/s=13.82  prediction: \"reply: @justalexoki He is the goat fr fr\" => \"eplfe  eeeeeee t       s                \"\n",
      "batch 5294  loss=144.3752  steps/s=160.51  prediction: \"ublic Refining my problem finder program\" => \"te te iiuiiiini iiinn i          eee  r \"\n",
      "batch 5295  loss=120.2926  steps/s=42.21  prediction: \"y: @sunsettler gl w luffy tomorrow bro ðŸ«¡\" => \"  @nuuiuuiiiiii               o  rr   rr\"\n",
      "batch 5296  loss=129.9593  steps/s=119.01  prediction: \"ust linux mints built in text editor lol\" => \"tlioe          t        iiiittt tttttttt\"\n",
      "batch 5297  loss=134.6597  steps/s=103.93  prediction: \".. would love to be proven wrong on this\" => \"  htla w.......w                 ooo    \"\n",
      "batch 5298  loss=140.9118  steps/s=103.43  prediction: \"rings out there that would just ruin ppl\" => \"entit          ttttttttttttt       uuuuu\"\n",
      "batch 5300  loss=136.1870  steps/s=100.36  prediction: \"s some cool shit https://t.co/Vo4w9BcSQZ\" => \" aor o oooooooooo        tttttttttt/////\"\n",
      "batch 5301  loss=131.4533  steps/s=105.00  prediction: \"m parts of your brain will want to do it\" => \"o@e    trrrrtrrrrrrrrr                  \"\n",
      "batch 5302  loss=132.0527  steps/s=101.11  prediction: \"g the cursor with your hands using video\" => \" s ,  lllll                             \"\n",
      "batch 5303  loss=132.3514  steps/s=100.17  prediction: \"just happen to have sicilian parents lol\" => \"ust e                             aaaa  \"\n",
      "batch 5304  loss=148.4010  steps/s=104.19  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  ae ceeeeeeeeege         tttttttttt////\"\n",
      "batch 5305  loss=171.8740  steps/s=97.12  prediction: \"locking @ludwigABAP circleboard!?!?!?!?!\" => \"yn @ieeeoonn@@@@@gggggggcccccccccccccr!!\"\n",
      "batch 5306  loss=119.6906  steps/s=21.56  prediction: \"eply: @mynamebedan head completely empty\" => \" ly: @eoo@@@@@@eggggggcccccccccccccr!!!!\"\n",
      "batch 5307  loss=131.1855  steps/s=106.84  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \"  osee e           ..........tttttt/////\"\n",
      "batch 5308  loss=158.2453  steps/s=99.39  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"iot   oo ooooo n                  ooooee\"\n",
      "batch 5309  loss=134.2733  steps/s=103.20  prediction: \"nbelievably cracked\n",
      "\n",
      "still 25 years left\" => \" o re   eeeeeee eeeeeeeeeeelllllllllllll\"\n",
      "batch 5310  loss=136.4747  steps/s=104.37  prediction: \"mul, transitions from one derivative toâ€¦\" => \"ene i aiaaaiiiiiiiiiiiinnnnnn           \"\n",
      "batch 5311  loss=135.0254  steps/s=104.87  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"nize egiiiiiiiiii       tttttttttttt////\"\n",
      "batch 5312  loss=130.3052  steps/s=95.64  prediction: \"resy you can already talk to one of them\" => \"eply   eeee e        aaaaaaatttt        \"\n",
      "batch 5313  loss=136.8718  steps/s=103.58  prediction: \"hristians believe this is the case w God\" => \"e   iliiiiisiiiiiiiiieiiiiiii           \"\n",
      "batch 5314  loss=141.4892  steps/s=71.22  prediction: \"am_Kantor actually something came up rip\" => \"ne ii\n",
      "isss  itteeeeee  s   e            \"\n",
      "batch 5315  loss=141.7254  steps/s=114.58  prediction: \" giz tarantinos alt?????? this shit fire\" => \"te ii ii     aataaaaaatt???????????    i\"\n",
      "batch 5317  loss=128.2448  steps/s=105.53  prediction: \" good at developing your own techniquesâ€¦\" => \"testere        o o   oooooooooo         \"\n",
      "batch 5318  loss=128.9885  steps/s=105.09  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"  ntintt iiiiiiiiiiiiiiiiooooooooooorrrr\"\n",
      "batch 5319  loss=154.8744  steps/s=102.61  prediction: \"utput brothers karamazov, word for word\"\" => \"s iAu Auu         rrrrrrrrrr aaaaaoooooo\"\n",
      "batch 5320  loss=131.4986  steps/s=104.62  prediction: \"tups are hidden in the fog 2 moves ahead\" => \" rnf f ttt     s                        \"\n",
      "batch 5322  loss=185.8916  steps/s=52.66  prediction: \": example output https://t.co/jRATFli0Ik\" => \" @jurs                                  \"\n",
      "batch 5323  loss=140.7354  steps/s=108.58  prediction: \"ful if youre a complete beginner like me\" => \" st   i                    eeeeeeeeeeeee\"\n",
      "batch 5324  loss=137.4392  steps/s=106.04  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  lo o   rrrrrrrreeeeeeeeeeeoooooooooll\"\n",
      "batch 5325  loss=124.9396  steps/s=101.35  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \" teoo o                dd               \"\n",
      "batch 5326  loss=135.1357  steps/s=104.52  prediction: \"is fine and expected, giving up is death\" => \"n  ee e           eeeeeeeeee            \"\n",
      "batch 5327  loss=136.1635  steps/s=100.25  prediction: \" process does feel good when err go down\" => \"trnenneeeeeeeeeseeeeeeee ee  ee         \"\n",
      "batch 5328  loss=128.1087  steps/s=105.04  prediction: \" just be a webpage visit, its in browser\" => \"tu  ll         l                 iiiiiii\"\n",
      "batch 5329  loss=135.3762  steps/s=104.68  prediction: \"ng, dunno why this flew over my head lol\" => \"  o si ennnnnnn nnn                     \"\n",
      "batch 5330  loss=135.9163  steps/s=105.40  prediction: \", how much info could you get from that?\" => \" and i         m                        \"\n",
      "batch 5331  loss=226.9084  steps/s=52.42  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \"  @  i    i        o  o           oo    \"\n",
      "batch 5332  loss=128.0343  steps/s=107.17  prediction: \" use commonly are invisible fundamentals\" => \"tsr pee                             nnnn\"\n",
      "batch 5333  loss=128.1812  steps/s=37.57  prediction: \"ly: @0xbingllm we gettin it we gettin it\" => \"y:   e    lllll                  eennnnn\"\n",
      "batch 5334  loss=146.2702  steps/s=118.58  prediction: \" surprised at how clean of a read it was\" => \"tea  s         s                        \"\n",
      "batch 5335  loss=118.9108  steps/s=90.83  prediction: \"enisnikulin its the lichess of photoshop\" => \" tle @sssiiiiiin                       o\"\n",
      "batch 5336  loss=129.8736  steps/s=104.69  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" \"o a                   eeeeeeeeeeeeeeee\"\n",
      "batch 5337  loss=132.5695  steps/s=103.24  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"n \n",
      "\n",
      "n nnnnnnnnnntttttttttttttttt////////\"\n",
      "batch 5338  loss=129.8176  steps/s=104.40  prediction: \"e did not seem like the type to work out\" => \" ln                  eeeeeeeeeee        \"\n",
      "batch 5339  loss=145.6702  steps/s=99.51  prediction: \"s waking back up https://t.co/0wXM4UadXf\" => \" ar  l                          ////////\"\n",
      "batch 5340  loss=162.7338  steps/s=106.72  prediction: \"CMEGroup ayy lets go more monopoly money\" => \"orb  o                      oooooooooooo\"\n",
      "batch 5341  loss=121.1477  steps/s=58.16  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"ts w  o                    ooooooooooooo\"\n",
      "batch 5342  loss=139.6667  steps/s=62.20  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @  o  oo                ooooooooooooðŸ›‘\"\n",
      "batch 5343  loss=135.5236  steps/s=106.19  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng oo          n                 uuuuu  \"\n",
      "batch 5344  loss=137.9623  steps/s=103.21  prediction: \"s is pretty cool https://t.co/2VR6GTbI3d\" => \" tote t            tttttttttttttttt/////\"\n",
      "batch 5345  loss=163.4780  steps/s=102.32  prediction: \"up man youre gonna go far over the years\" => \" lei                                    \"\n",
      "batch 5346  loss=136.9777  steps/s=103.54  prediction: \"about things that have significant value\" => \"nou\"\n",
      "ttttttttttttttttttt          iiiiii\"\n",
      "batch 5347  loss=127.6183  steps/s=106.02  prediction: \" adventure over the comfort of certainty\" => \"tbet teeeeeeeeeteeeeeeeeeeeee           \"\n",
      "batch 5348  loss=135.9976  steps/s=104.15  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \"hoo  i  iiiiiiiniii                     \"\n",
      "batch 5349  loss=133.9541  steps/s=103.39  prediction: \"nbelievably cracked\n",
      "\n",
      "still 25 years left\" => \"ge re   eeeeeee eeeeeeeeecllllllllllllll\"\n",
      "batch 5350  loss=204.9208  steps/s=97.19  prediction: \" @sunsettler 100%\n",
      "\n",
      "TIME AND FREEDOM BABY\" => \"tnre ennnnnnnnnneee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   EEEEEEEE\"\n",
      "batch 5351  loss=132.8120  steps/s=102.55  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"g  aro   eeeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 5352  loss=143.9239  steps/s=60.34  prediction: \" @0xluffyb Deserved\n",
      "You build cool stuff\" => \"tpuhe reeeeeeeeeeeeeeeese      i    ssss\"\n",
      "batch 5353  loss=168.1867  steps/s=37.11  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @reeeeeeeeeeeeeeee e o    i    ssss\"\n",
      "batch 5354  loss=152.6505  steps/s=108.13  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne s   MMssssssss     GGGGrrrrrrrrrrrrrr\"\n",
      "batch 5355  loss=137.7496  steps/s=100.93  prediction: \"x reddit is the strange people attractor\" => \" 0ieeeTeeeeeeeet ee         e eee  eteet\"\n",
      "batch 5356  loss=128.5220  steps/s=30.06  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: @ixeeeeeeee  tt     eeeeeeeeepeetttt\"\n",
      "batch 5357  loss=144.4599  steps/s=129.01  prediction: \"izmobly you have 3 days or youre blocked\" => \"neMTB edii   A          ee    ee  eeeoee\"\n",
      "batch 5358  loss=146.5815  steps/s=101.09  prediction: \"le77 Good stuff brotha\n",
      "\n",
      "looks productive\" => \"yxe@B Byyo     7           ooooooooooooo\"\n",
      "batch 5359  loss=139.7104  steps/s=105.34  prediction: \"on chunking showed higher level playersâ€¦\" => \"  t ts               hhhhhhhhhhhheeeeeee\"\n",
      "batch 5360  loss=135.4074  steps/s=104.50  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" tid eheeeeeeeeteeeet ttttttttttttttttt \"\n",
      "batch 5361  loss=170.2685  steps/s=106.22  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"ng dv  iiieeee             tttttt///////\"\n",
      "batch 5362  loss=153.8982  steps/s=98.44  prediction: \"y childhood was nuketown 2025 and python\" => \":toae yyyy         h ooooo   ooo oo     \"\n",
      "batch 5363  loss=151.1324  steps/s=71.56  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"yi @l lllh          ttt ttt/////       ðŸ›‘\"\n",
      "batch 5364  loss=129.9322  steps/s=106.88  prediction: \"rger abstractions which eventually haveâ€¦\" => \"ees t     aaaaaraaarrrrr              ee\"\n",
      "batch 5365  loss=129.6245  steps/s=104.51  prediction: \"ed around the data that flows through it\" => \"  eteae   dd dddddd              ttttttt\"\n",
      "batch 5366  loss=120.0420  steps/s=100.44  prediction: \"all of the theories that we could invent\" => \"rse  t                                  \"\n",
      "batch 5367  loss=130.8819  steps/s=105.44  prediction: \"ty programming that in, its over, robotâ€¦\" => \"h  tt  tiiiiiiiiiiiiiiiiiiii        ,   \"\n",
      "batch 5368  loss=130.7580  steps/s=96.26  prediction: \"oulda made stock cert flags instead, rip\" => \" ltar raaaaaa   aa                      \"\n",
      "batch 5369  loss=146.8452  steps/s=93.53  prediction: \"ere @jaivinwylde prime rgb lore revealed\" => \"   y @aaS                     rr ee rree\"\n",
      "batch 5370  loss=129.8319  steps/s=104.08  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"eie    s                                \"\n",
      "batch 5371  loss=131.7176  steps/s=104.51  prediction: \" fundamentals.  Take the time to invest.\" => \"too         tt n aaaaa                  \"\n",
      "batch 5372  loss=168.8733  steps/s=39.42  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y   ut  tttttt n  a        ee          t\"\n",
      "batch 5373  loss=128.5149  steps/s=116.65  prediction: \" have another tweet promoting AB testing\" => \"taete          e e    tttttttttttttttttt\"\n",
      "batch 5374  loss=162.1727  steps/s=90.00  prediction: \"ettler @crypt0x_0 @EsotericCofe thanks!!\" => \"  eo @e tteettttettttttoooooooooteettttt\"\n",
      "batch 5375  loss=131.8918  steps/s=105.04  prediction: \"o an actual bot\n",
      "\n",
      "https://t.co/thSLgC2Cbo\" => \" mt in              ttttttttttttttt/////\"\n",
      "batch 5376  loss=131.3045  steps/s=99.87  prediction: \"im gonna read the whole library of babel\" => \"net a ettn                           bbb\"\n",
      "batch 5377  loss=154.2488  steps/s=100.26  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tnt r                                   \"\n",
      "batch 5378  loss=133.3240  steps/s=105.86  prediction: \"he pot of gold at the end of the rainbow\" => \"e     t        t                        \"\n",
      "batch 5379  loss=132.4610  steps/s=99.67  prediction: \"ssir\n",
      "\n",
      "ill dm you on the 25th with a link\" => \"  pet oo       l                 hh hh  \"\n",
      "batch 5380  loss=134.9081  steps/s=104.60  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn  o e       eeeeeeeeeeeeeeetttt///////\"\n",
      "batch 5381  loss=162.6107  steps/s=99.61  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"ep          00000000000                 \"\n",
      "batch 5382  loss=149.6511  steps/s=105.95  prediction: \"mentals can be really really hard to see\" => \"e taiesnnnnnnnn nn      aallllllllllll  \"\n",
      "batch 5383  loss=134.2226  steps/s=103.58  prediction: \" so I invested my time into that instead\" => \"ttreerooo                          ttttt\"\n",
      "batch 5384  loss=132.0467  steps/s=103.51  prediction: \"t (for example working when youre tired)\" => \" coush ooooooooooooo                    \"\n",
      "batch 5385  loss=143.2411  steps/s=105.42  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"te.ce/t///////ttttttttttttttttt/////////\"\n",
      "batch 5386  loss=137.3827  steps/s=102.71  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"rbsat         l llllllllllllllllllllllll\"\n",
      "batch 5387  loss=128.1464  steps/s=96.47  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \" n a  iiiii    n e ee eeeeeee\n",
      "\n",
      "\n",
      "yyyyyyss\"\n",
      "batch 5388  loss=129.6927  steps/s=98.31  prediction: \"sing llms to their full potential rn tbh\" => \" no a                            ll t   \"\n",
      "batch 5389  loss=137.9792  steps/s=100.45  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lo  e errrrrrrrorrrr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             \"\n",
      "batch 5390  loss=138.6657  steps/s=106.16  prediction: \"nd super useful: https://t.co/i2lqZZ1GQR\" => \"g  s     uuuuuuuuuuuuuuusssstttt////////\"\n",
      "batch 5391  loss=132.1394  steps/s=103.79  prediction: \"he pot of gold at the end of the rainbow\" => \"e k   t        t                        \"\n",
      "batch 5392  loss=136.7246  steps/s=101.50  prediction: \" rivals\n",
      "\n",
      "but idk, i dont know the theory\" => \"ter i oooooooii iiiiiid                 \"\n",
      "batch 5393  loss=230.7223  steps/s=95.95  prediction: \" ayyy thanks!!! LETS GOO FINALLY SHIPPED\" => \"tny iyyyyyyyyyyy     !!!!!            LL\"\n",
      "batch 5394  loss=138.2444  steps/s=104.63  prediction: \" different on your OS. you can google em\" => \"tor te         f                        \"\n",
      "batch 5395  loss=183.0643  steps/s=101.96  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \"nN   HHHHHHssssssssssssssssssssss       \"\n",
      "batch 5397  loss=142.9820  steps/s=103.72  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyn                                   \"\n",
      "batch 5398  loss=167.2399  steps/s=100.90  prediction: \"eos Oh I know :) https://t.co/aV1q8nmIEk\" => \" ria dddd                        ///////\"\n",
      "batch 5399  loss=158.0579  steps/s=104.92  prediction: \"ou get like 5 seconds to shoot your shot\" => \"rr R R                         ooooooooo\"\n",
      "batch 5400  loss=140.9759  steps/s=105.01  prediction: \"ed in joining, repeat these instructions\" => \"  e  eeeeeeeiiieiiiiiinn eeeeeeeeeeetttt\"\n",
      "batch 5401  loss=143.9303  steps/s=100.96  prediction: \" your own game engine\n",
      "challenge accepted\" => \"tou wAt        r       eeeeeeeeeeeeeeeee\"\n",
      "batch 5402  loss=165.9033  steps/s=100.34  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"egty: @nnnnnnnenenyyyyhhhhhhnn          \"\n",
      "batch 5404  loss=126.6000  steps/s=102.40  prediction: \"l possible golden gate bridge existences\" => \"yt ol         lllllll      eeeeeeeeeeeee\"\n",
      "batch 5405  loss=178.5700  steps/s=99.60  prediction: \"sleep + zoom calls?\n",
      "WE OVERCOME THAT SHT\" => \" aaea bse      e                 EEEEEEE\"\n",
      "batch 5406  loss=130.8501  steps/s=104.09  prediction: \" just need to learn the secret shortcuts\" => \"tui tas                    eeeeeeeeeeeet\"\n",
      "batch 5407  loss=126.1253  steps/s=97.71  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \" an a           ttteeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5408  loss=143.2427  steps/s=107.21  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ns             n           tttttttttt///\"\n",
      "batch 5409  loss=130.6175  steps/s=99.59  prediction: \" people who find their work fun win more\" => \"tro    e                                \"\n",
      "batch 5410  loss=130.6722  steps/s=105.84  prediction: \" get to master idk depends on your goals\" => \"te eeee        t          dddddd        \"\n",
      "batch 5411  loss=138.5700  steps/s=105.78  prediction: \"ew_pynch join often, good guys to follow\" => \" _s anannnnnnnn nnnnnnnnn oooo o  oooooo\"\n",
      "batch 5412  loss=129.8461  steps/s=104.53  prediction: \"video w that id, it starts at that frame\" => \"edeseee                 tttttttttttttttt\"\n",
      "batch 5413  loss=127.4709  steps/s=103.50  prediction: \"go, the name.. none of that shit matters\" => \" o e he                             tttt\"\n",
      "batch 5414  loss=128.1090  steps/s=104.97  prediction: \"an the last 5 bc of the skills he gained\" => \"nd   ee                                 \"\n",
      "batch 5415  loss=136.6746  steps/s=105.23  prediction: \"randomly via ssh https://t.co/3MxqH9R1Ya\" => \"ene t  eeee                ssssttt//////\"\n",
      "batch 5416  loss=127.8445  steps/s=101.90  prediction: \"o my head\n",
      "\n",
      "empirical blog posts are king\" => \"rl  e        eeeeeeeeiiiii              \"\n",
      "batch 5417  loss=127.7380  steps/s=104.66  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" arnaaa      aa aaaaaaaa   ssttt////////\"\n",
      "batch 5418  loss=140.1668  steps/s=100.70  prediction: \"dering what was on that list, thanks man\" => \"  ae           w                 tttt   \"\n",
      "batch 5419  loss=132.5620  steps/s=105.94  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"nh reet  hhhhaataaaaa                   \"\n",
      "batch 5420  loss=125.0134  steps/s=103.30  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e  thoeeeeetttttt                   dddd\"\n",
      "batch 5421  loss=139.2474  steps/s=92.17  prediction: \"builds mcdonalds just wants to grill man\" => \"ett\n",
      " ebbbb      dd            tttt nnn  \"\n",
      "batch 5423  loss=131.3105  steps/s=101.53  prediction: \"tus Even more bc this doesnt have alaska\" => \"hrI ereteeleeee                       aa\"\n",
      "batch 5424  loss=144.6610  steps/s=102.04  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" t                  t                ooo\"\n",
      "batch 5425  loss=168.8972  steps/s=90.39  prediction: \"ez5341 Will do brother. Much appreciated\" => \" Ihu @ ee             oooo          occr\"\n",
      "batch 5426  loss=133.0980  steps/s=100.26  prediction: \"yacine needs a dingboard wrap on his car\" => \":c jeecy00         eee  d     arrrraa   \"\n",
      "batch 5427  loss=155.6015  steps/s=104.86  prediction: \"copy ... etc\n",
      "\n",
      "my bottleneck is LLM speed\" => \"op it        .......                    \"\n",
      "batch 5428  loss=127.3586  steps/s=103.56  prediction: \" long time. Play a game or two a day idk\" => \"tea                                     \"\n",
      "batch 5429  loss=126.5874  steps/s=39.15  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y                  aa                   \"\n",
      "batch 5430  loss=144.7578  steps/s=117.04  prediction: \"r easy setup btw\n",
      "https://t.co/dWiO4erSb1\" => \"eply:  ssssssssesssstttttttttttttttt////\"\n",
      "batch 5431  loss=128.5375  steps/s=105.00  prediction: \" way you perceive the world and yourself\" => \"tae                   eeeeeeee          \"\n",
      "batch 5432  loss=126.4135  steps/s=105.04  prediction: \" long run in weird ways you dont realize\" => \"ton            n                        \"\n",
      "batch 5433  loss=168.2009  steps/s=101.76  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" loag                                   \"\n",
      "batch 5434  loss=130.6032  steps/s=101.84  prediction: \"nd mental storage/organization efficient\" => \"g  eef,      tt tttttt  aaaaaaaaaaaaaiii\"\n",
      "batch 5435  loss=127.6894  steps/s=103.32  prediction: \"hem better bc you can do engine analysis\" => \"e s yt ttttttttt                     nnn\"\n",
      "batch 5436  loss=145.8944  steps/s=102.65  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"eih  n      00000000                  oo\"\n",
      "batch 5437  loss=149.6730  steps/s=104.05  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \"rparr\n",
      "\n",
      "aaaaaaalallllllllllll tt/////////\"\n",
      "batch 5438  loss=132.1043  steps/s=105.16  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"     aaaaaaaaaabaaaaaa                  \"\n",
      "batch 5439  loss=153.3961  steps/s=100.95  prediction: \"ombies, lethal company, misc other stuff\" => \"resolooooo                              \"\n",
      "batch 5440  loss=131.9229  steps/s=104.92  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"  itn                  eeeeeegeeeehhhhh \"\n",
      "batch 5441  loss=132.2877  steps/s=105.58  prediction: \" fast eventually. i know this from chess\" => \"tuo s  ss   eeeeee                      \"\n",
      "batch 5442  loss=142.4030  steps/s=104.00  prediction: \"Logit transform: https://t.co/MtjBY3y5n5\" => \"oaoo              ttttttttttttttttt/////\"\n",
      "batch 5443  loss=136.6583  steps/s=104.52  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" midh heeeeeeeeteeeet ttttttttttttttttt \"\n",
      "batch 5444  loss=134.1584  steps/s=108.98  prediction: \"pynch we must accelerate snake\n",
      "snake/acc\" => \"l   @deeeeeeu          tteeeeeeeeesasssa\"\n",
      "batch 5445  loss=150.6036  steps/s=104.66  prediction: \"ame by making his brain care abt it more\" => \"ne r           m                        \"\n",
      "batch 5446  loss=132.4471  steps/s=103.76  prediction: \"learning models\n",
      "\n",
      "https://t.co/KAmykVYFyw\" => \"ys i nrnnnnnnnnenneeeeeeettttt//////////\"\n",
      "batch 5447  loss=140.5748  steps/s=104.84  prediction: \"ike a combinatoric sized pain in the ass\" => \"ne                  iiiiiiiiiiiiiiiii   \"\n",
      "batch 5449  loss=180.9064  steps/s=10.73  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"eply: @            iiiiiiiiiiiiiiiii    \"\n",
      "batch 5450  loss=139.2010  steps/s=155.52  prediction: \"0nnnpppppppppp hilarious bait, i love it\" => \"x   nonnnnppppppppppiiiiiiiiiiii        \"\n",
      "batch 5451  loss=130.2315  steps/s=106.07  prediction: \"d meant i could do whatever i wanted lol\" => \" ae i eaaaaaa  a                        \"\n",
      "batch 5453  loss=144.2954  steps/s=102.39  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"theeen                    tttttttttttt//\"\n",
      "batch 5454  loss=128.9937  steps/s=101.12  prediction: \"o my head\n",
      "\n",
      "empirical blog posts are king\" => \"rme e       eeeeeeeeeeiii               \"\n",
      "batch 5455  loss=135.6899  steps/s=104.80  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"  o            eeeeeeeeeeeeeeeeeeeeeeett\"\n",
      "batch 5456  loss=145.2439  steps/s=59.31  prediction: \" @anish0209 And now hes making it run js\" => \"tlye        eeec eeeeeeeeeeeeeetttt  t t\"\n",
      "batch 5457  loss=131.4272  steps/s=121.74  prediction: \"n og returns\n",
      "truly a legendary 5-9 today\" => \"gth  s       n nrrrrrr r    a           \"\n",
      "batch 5458  loss=139.1763  steps/s=105.23  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toe eedeeeeee                 CCCCnnnnnn\"\n",
      "batch 5459  loss=136.6544  steps/s=104.44  prediction: \"ol\n",
      "gonna crack one open rn over some ice\" => \"r      ooooooooloooooooo  nnnnn         \"\n",
      "batch 5460  loss=138.0930  steps/s=104.27  prediction: \"al, one of the most cracked players ever\" => \"nk eo                                eee\"\n",
      "batch 5461  loss=160.3132  steps/s=105.61  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"t.ccesot///////t/ttttttttttt///////////p\"\n",
      "batch 5463  loss=144.0233  steps/s=61.18  prediction: \"is would make a really cool pfp actually\" => \"n  eoetoooooou t  ttt t/tttt/oppppppppqq\"\n",
      "batch 5465  loss=145.4504  steps/s=109.71  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"e y upeeeeeeeeeeeeeeeeoooottttttt///////\"\n",
      "batch 5466  loss=121.6449  steps/s=20.40  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: e eeeeeeeeeeeoooooottttttt/////////\"\n",
      "batch 5467  loss=124.5820  steps/s=112.66  prediction: \" to get tons of llms to output good code\" => \"theet tttttttttt                oooooooo\"\n",
      "batch 5468  loss=144.9483  steps/s=103.38  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"/.cc/sstt/////////tttttttttt//////////tt\"\n",
      "batch 5470  loss=182.1917  steps/s=99.28  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"ene  oo@@@@@@oooooo    2222ttttt77777///\"\n",
      "batch 5471  loss=139.9544  steps/s=102.80  prediction: \"my database is a text file called main.c\" => \"e e  H         b   aaa            t   ll\"\n",
      "batch 5472  loss=129.2174  steps/s=104.11  prediction: \"en get way too absorbed into one of them\" => \"   o           t     ooooooooooooooooooo\"\n",
      "batch 5473  loss=142.7449  steps/s=103.30  prediction: \" it was all tactice, but this is the way\" => \"tn  n                 tttttttttttt      \"\n",
      "batch 5474  loss=150.0467  steps/s=99.62  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"beyph__kaaaaaaaaaat               eeeeee\"\n",
      "batch 5475  loss=140.8403  steps/s=103.43  prediction: \"ou get faster and faster at solving them\" => \"ugt                                     \"\n",
      "batch 5477  loss=144.6221  steps/s=99.32  prediction: \"ideally yes. mostly medium sized updates\" => \"ne be  eeeeeeelellll yy               dd\"\n",
      "batch 5478  loss=133.9906  steps/s=104.80  prediction: \" tons of stuff, for yrs, and that worked\" => \"th t  t        t     fffffff            \"\n",
      "batch 5479  loss=136.9710  steps/s=104.16  prediction: \"l release results soonish #buildinpublic\" => \"ya   \n",
      "\n",
      "  eeeeeeeeeeeesssssssssssssssiiii\"\n",
      "batch 5480  loss=138.9404  steps/s=103.94  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \" t  e e        f            ttt/////////\"\n",
      "batch 5481  loss=154.6636  steps/s=104.37  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"u  oo  kkkkk         tttttttttttttt/////\"\n",
      "batch 5482  loss=154.2468  steps/s=100.38  prediction: \"ynch Its official im naming my kid movie\" => \" a eadd        n         iiiiiiiiiiimmmm\"\n",
      "batch 5483  loss=135.0533  steps/s=103.87  prediction: \"oud walk away w a much stronger skillset\" => \"u  \n",
      "           w                        \"\n",
      "batch 5484  loss=127.5816  steps/s=57.63  prediction: \" @startupmillyair lichess or chessdotcom\" => \"t6 d         w w   a              ssssss\"\n",
      "batch 5487  loss=131.7165  steps/s=93.10  prediction: \"gizmobly @juweeism duude this is awesome\" => \" z o n  aallllyw       s       sssssssso\"\n",
      "batch 5488  loss=161.5203  steps/s=110.04  prediction: \"row)\n",
      "\n",
      "deletes 10 lines backwards in nvim\" => \"eply: @oodddeeeeeeeeeeeeeeeeeee         \"\n",
      "batch 5489  loss=131.3786  steps/s=101.91  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"s  it ttttttttt t      pppppppppppp     \"\n",
      "batch 5490  loss=130.6764  steps/s=103.29  prediction: \"es your data instead of storing the data\" => \" saa att tt     aaaaaaaa                \"\n",
      "batch 5491  loss=125.7048  steps/s=103.27  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"toa a   rrrrrr r    ssssssss            \"\n",
      "batch 5492  loss=189.7559  steps/s=77.67  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \":a  arrrr      ssss sssssss   mm   eeeee\"\n",
      "batch 5493  loss=125.3920  steps/s=48.88  prediction: \"ly: @andrew_pynch i think about it a ton\" => \"y: @ r   ss    \n",
      " st tstsss             g\"\n",
      "batch 5494  loss=130.9797  steps/s=108.77  prediction: \"@djcows but yet my 5s gifs come out 50MB\" => \"bewpo00 jss   tt  ttt t     /oo        ðŸ›‘\"\n",
      "batch 5495  loss=132.0086  steps/s=115.02  prediction: \" to make it better before (if) I release\" => \"tor   d ee         eee     eeeee e  eeee\"\n",
      "batch 5496  loss=134.3754  steps/s=99.70  prediction: \" inference than gpus\n",
      "\n",
      "but what do i know\" => \"@md   nnnnnnnnnnnnnnnnnn                \"\n",
      "batch 5497  loss=144.0143  steps/s=105.50  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" anoai          oooooooooooonnnnnnnn    \"\n",
      "batch 5499  loss=128.4008  steps/s=104.96  prediction: \"good idea but whatever, i wanna have fun\" => \" o fnn                           aaaaaaa\"\n",
      "batch 5500  loss=129.5308  steps/s=104.86  prediction: \"so they get into an unending doom spiral\" => \" ni titttttttttttt        nnnnnnnnnnnnn \"\n",
      "batch 5501  loss=133.2164  steps/s=103.74  prediction: \"n getting rid of the phone really is key\" => \"ga l a                                  \"\n",
      "batch 5502  loss=144.0267  steps/s=99.74  prediction: \"ogan?? was he on sidetweets or something\" => \"u ho e                   eeeeeeeeeeeeeee\"\n",
      "batch 5504  loss=136.9548  steps/s=103.84  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tadbiatiiiiiiii iiiiii                  \"\n",
      "batch 5505  loss=131.0796  steps/s=96.71  prediction: \"ke to continue it. Mnist is a great idea\" => \"eyw            n           iii          \"\n",
      "batch 5506  loss=132.3077  steps/s=105.17  prediction: \" the time and not spread important info?\" => \"toel l                              tttt\"\n",
      "batch 5507  loss=134.8516  steps/s=102.03  prediction: \"here for the funny symbols and recursion\" => \"er   er        r                        \"\n",
      "batch 5508  loss=121.9660  steps/s=98.96  prediction: \"is i need to make golden gate tetris bot\" => \"n    ew                 e      eeeeeeeee\"\n",
      "batch 5509  loss=132.9461  steps/s=102.48  prediction: \"al hypotheses to search through and test\" => \"nl     oooootttttttteeeetthhhhhhhhhhhhhh\"\n",
      "batch 5510  loss=150.9972  steps/s=105.05  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"bo  mn nnnn(((()))                     f\"\n",
      "batch 5511  loss=123.7582  steps/s=104.81  prediction: \"int as fast as possible on loop, idk tho\" => \"ngt              sssssssssssss    o    o\"\n",
      "batch 5512  loss=140.3698  steps/s=99.53  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \" dt ogyyyylll osooo l                   \"\n",
      "batch 5513  loss=158.5784  steps/s=104.75  prediction: \"our gpt api key\n",
      "\n",
      "https://t.co/qBtIejDpHA\" => \"usd in                 pppppttttt///////\"\n",
      "batch 5514  loss=136.5782  steps/s=103.09  prediction: \"ked bc i could make cool fun stuff in it\" => \" \n",
      "w  h                                  \"\n",
      "batch 5516  loss=154.4767  steps/s=104.96  prediction: \"ood combo for stuff like this, ive found\" => \" m 4o\n",
      "o oooooooooooo  ff                \"\n",
      "batch 5517  loss=147.8952  steps/s=103.52  prediction: \" quality than \"loading bar\" type writing\" => \"tueet eettttttt tttt                    \"\n",
      "batch 5518  loss=136.0146  steps/s=101.96  prediction: \"dering what was on that list, thanks man\" => \" aaW  a      wwwwwww              ttttt \"\n",
      "batch 5520  loss=177.0738  steps/s=76.90  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \":aaji w        w   tttttttttttttttt     \"\n",
      "batch 5521  loss=149.4295  steps/s=106.66  prediction: \"boards to learn the keys other ppl used)\" => \"eok  aaaaa     r            eeeee       \"\n",
      "batch 5522  loss=147.6353  steps/s=104.24  prediction: \"insanely OP\n",
      "One idea is to build usefulâ€¦\" => \"ngss  lsllllnnnnnnnnnnn                 \"\n",
      "batch 5523  loss=139.9089  steps/s=103.01  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" r edo            rrrrrrrrrrrrrrrrhhhhhh\"\n",
      "batch 5524  loss=141.5276  steps/s=102.15  prediction: \" so this helped\n",
      "\n",
      "Are you gonna continue?\" => \"@t  s                             ooonnn\"\n",
      "batch 5525  loss=130.1496  steps/s=100.59  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n  s   sssssss s                        \"\n",
      "batch 5526  loss=127.4539  steps/s=105.87  prediction: \"eeks but you get back your skill quickly\" => \"     eeeeeee   e                      kk\"\n",
      "batch 5527  loss=135.0652  steps/s=62.93  prediction: \"@codyaims 113 bots liked this one so far\" => \"aagwaee                    k            \"\n",
      "batch 5528  loss=148.2658  steps/s=106.37  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" nr  isss???????????????ss              \"\n",
      "batch 5529  loss=146.4540  steps/s=101.85  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" ta           d dd                      \"\n",
      "batch 5530  loss=129.9464  steps/s=103.83  prediction: \"ions you choose, like oregon or whatever\" => \"nn roooooooooooooooooooooooooooooo     e\"\n",
      "batch 5531  loss=137.9576  steps/s=51.36  prediction: \": @pindjouf @thomasbocquet7 ayyy lets go\" => \" @loc oooooooooooooo ooooeeee        eee\"\n",
      "batch 5533  loss=186.6589  steps/s=20.56  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"epty ooooooooooooooo oooeeeee        eee\"\n",
      "batch 5534  loss=127.1141  steps/s=159.76  prediction: \"TB strategy is an abstraction of tactics\" => \"B io  i nn ttt t taas      aaa    tttttt\"\n",
      "batch 5535  loss=168.2823  steps/s=104.26  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"en piniiiiiiiaaaaaaaaaaaaaassssstt//////\"\n",
      "batch 5536  loss=122.2350  steps/s=46.51  prediction: \"y: @sunsettler write a will just in case\" => \": @pieiieeeeaaaaaaaaaaaaasstt///////////\"\n",
      "batch 5537  loss=146.1000  steps/s=108.87  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame                                    \"\n",
      "batch 5540  loss=140.0134  steps/s=103.59  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toede deeeeee                IIICCnnnnnn\"\n",
      "batch 5541  loss=131.7503  steps/s=103.57  prediction: \"has any non-json, ask for json in prompt\" => \"ets o.          nnnnnnnnn               \"\n",
      "batch 5542  loss=132.4493  steps/s=103.36  prediction: \"esting example of goodharting the reward\" => \" tbtttttteeeeeeneeeeeeee  oooooo        \"\n",
      "batch 5543  loss=138.8972  steps/s=99.21  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"n ere e                                 \"\n",
      "batch 5544  loss=149.1627  steps/s=103.70  prediction: \" God for helping us both out\n",
      "it was hell\" => \"tCol                                    \"\n",
      "batch 5545  loss=136.2868  steps/s=103.43  prediction: \"lf of that was way off. all good tho nbd\" => \"y0                      fffff           \"\n",
      "batch 5546  loss=133.8644  steps/s=104.27  prediction: \" strategy is short term low integrity BS\" => \"too  e        sssssss              ttttt\"\n",
      "batch 5547  loss=127.0740  steps/s=105.38  prediction: \"en get way too absorbed into one of them\" => \"    I          t     oooo oooooooooooooo\"\n",
      "batch 5548  loss=157.4556  steps/s=99.16  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"t ty      r uuueuuttttttttttttttttt/////\"\n",
      "batch 5549  loss=130.5681  steps/s=99.15  prediction: \"n to achieve an awesome long term vision\" => \"gh  _  aaa            e eeee eeee       \"\n",
      "batch 5550  loss=133.1903  steps/s=38.83  prediction: \"ly: @morew4rd Gettin there, yup\n",
      "Soooooon\" => \"y: @maaaa e      e   e eeeee  ee     ooo\"\n",
      "batch 5551  loss=136.8787  steps/s=116.37  prediction: \"@yacineMTB You want us to find our moms?\" => \"madqalaaeeee     e      ee       ooooooo\"\n",
      "batch 5552  loss=139.6543  steps/s=112.59  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"nk y  yyylllloolooo                     \"\n",
      "batch 5553  loss=128.1368  steps/s=102.89  prediction: \"e are, so it has a ton of ripple effects\" => \" t                                      \"\n",
      "batch 5554  loss=128.0724  steps/s=101.49  prediction: \"custom extension to watch yt on 4x speed\" => \"h tM          ttttttttttttttttt         \"\n",
      "batch 5555  loss=126.5838  steps/s=98.92  prediction: \"king spheres are infinitely many circles\" => \"elo toieeeeeeeeseeeeeeeeee   nnnn nn    \"\n",
      "batch 5556  loss=137.2474  steps/s=105.23  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"tyr  e       ,,,,,          stttt///////\"\n",
      "batch 5557  loss=147.1874  steps/s=103.96  prediction: \"as the guide on how to beat mind viruses\" => \"nting p                                 \"\n",
      "batch 5558  loss=141.1080  steps/s=100.59  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e ly:                   sttttttttt//////\"\n",
      "batch 5559  loss=130.6123  steps/s=104.11  prediction: \"s changing how I think abt models a lot.\" => \" wra\n",
      "ta                                 \"\n",
      "batch 5560  loss=137.6497  steps/s=102.91  prediction: \"sy and they put bugs in the concrete lol\" => \"  ra  aaa      n                        \"\n",
      "batch 5561  loss=124.7822  steps/s=105.49  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"ge ta              ooooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaaa\"\n",
      "batch 5562  loss=137.8660  steps/s=103.65  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"ne                       tttttt/////////\"\n",
      "batch 5563  loss=127.3992  steps/s=104.12  prediction: \"s of lib arts classes they make you take\" => \" wosseeeeee        sssssssssss          \"\n",
      "batch 5564  loss=121.7767  steps/s=100.34  prediction: \" learn if youre not an opening memorizer\" => \"teae                           nnnnnnnnn\"\n",
      "batch 5565  loss=120.8901  steps/s=52.04  prediction: \": @EsotericCofe what are you working on?\" => \" @yacs       o  o          nnnnnnnnnnnno\"\n",
      "batch 5566  loss=161.2949  steps/s=132.37  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"se y  iiiiiir  r htthttttttttttttt/////o\"\n",
      "batch 5567  loss=127.6407  steps/s=104.08  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" f    eeeeeeeeete                tttttt \"\n",
      "batch 5568  loss=135.0587  steps/s=101.15  prediction: \"inful to stfu but it works suuuuper well\" => \"n  es          t  u           uuuuuuuuuu\"\n",
      "batch 5569  loss=174.7663  steps/s=101.53  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"s al ooo   000000000ttttttttttttttttt///\"\n",
      "batch 5570  loss=153.1451  steps/s=104.74  prediction: \" tackling client projects, ThreeJS courâ€¦\" => \"the             lllllllccccc   eeeeeeeee\"\n",
      "batch 5571  loss=137.5773  steps/s=105.39  prediction: \"anything else would kneecap learning no?\" => \"nd th t        n             eeeeeeeennn\"\n",
      "batch 5572  loss=130.4391  steps/s=104.54  prediction: \"miliar with a place and the things in jt\" => \"entoiriiiiiiiiiiii aaaaaaa              \"\n",
      "batch 5573  loss=132.1386  steps/s=101.28  prediction: \"ur gzip stuff? training on gzipped data?\" => \"se i                         innnnnnn   \"\n",
      "batch 5575  loss=166.3123  steps/s=93.77  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"yx @su sttttttt rtttnnttttttttpttpp///tt\"\n",
      "batch 5577  loss=141.9751  steps/s=103.10  prediction: \"is new wave of RL stuff im seeing lately\" => \"n the                                   \"\n",
      "batch 5578  loss=124.2056  steps/s=93.23  prediction: \"bly same, llms are so much faster though\" => \"eyts           m                    eeee\"\n",
      "batch 5579  loss=126.7787  steps/s=96.98  prediction: \"cking it was kobe posting the whole time\" => \"oaln eiieel                       httthh\"\n",
      "batch 5580  loss=110.0224  steps/s=11.16  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @ie l                      thttthh\"\n",
      "batch 5581  loss=140.0347  steps/s=128.54  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"@t .  .......eeetee t nnn               \"\n",
      "batch 5582  loss=134.3974  steps/s=104.02  prediction: \"s. im betting on that. but i am not sure\" => \"  y t yy                ttt             \"\n",
      "batch 5583  loss=126.2399  steps/s=102.87  prediction: \" commonly use amd it works insanely well\" => \"tatt                                    \"\n",
      "batch 5584  loss=139.2670  steps/s=103.99  prediction: \" is \"given the context, how relevant isâ€¦\" => \"ts   \" \"\"                     eeeeeeeeee\"\n",
      "batch 5585  loss=166.5374  steps/s=99.91  prediction: \"ellectus @gfodor https://t.co/Emux6iPInC\" => \" st   eeeeeeeeee  ttttttttttttttt/////tt\"\n",
      "batch 5586  loss=140.1961  steps/s=99.41  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"tok       nnnnnonnooooooooooo           \"\n",
      "batch 5587  loss=128.6706  steps/s=103.38  prediction: \" in bend you should post, sounds awesome\" => \"tn aaiinnnnnn  n             ooooo sssss\"\n",
      "batch 5588  loss=131.0319  steps/s=105.71  prediction: \"nt do that\n",
      "now it doesnt do that\n",
      "\n",
      "repeat\" => \"  d        ttttttttttttttttttttttttttttt\"\n",
      "batch 5589  loss=140.3013  steps/s=104.26  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" ito tttt      t    tttttttttttttttt////\"\n",
      "batch 5590  loss=142.0219  steps/s=102.81  prediction: \" making anifusion in the first place btw\" => \"tyyt           n   nnnnnnniiiii         \"\n",
      "batch 5591  loss=143.4989  steps/s=100.17  prediction: \"e IRL, its fundamentals all the way down\" => \" @ya @aaaa  ss n            t  laall    \"\n",
      "batch 5592  loss=134.5956  steps/s=101.86  prediction: \"ire effing timeline is circle tool posts\" => \"neoe y       eeeeeeeeiiiiiiiiiiiiiii    \"\n",
      "batch 5593  loss=132.7541  steps/s=102.97  prediction: \"y started pushing the boulder 5x as much\" => \":i aeaaaaa  eeet  ttttt                 \"\n",
      "batch 5594  loss=122.8651  steps/s=63.60  prediction: \"@skooookum i forget but its at least 100\" => \"yucmneeoooo        t tttt t             \"\n",
      "batch 5595  loss=141.0156  steps/s=106.53  prediction: \"erminal sub window alongside your files?\" => \"   :a                                   \"\n",
      "batch 5596  loss=207.5966  steps/s=87.42  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" Mo  a  a           EEE     toooooiiiiii\"\n",
      "batch 5597  loss=142.9800  steps/s=100.77  prediction: \"ad to give some direction/motivation tho\" => \"n_             t          eooiiiiiiiiiii\"\n",
      "batch 5598  loss=160.9163  steps/s=91.68  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"    tro t  7777         eeooiiiiiiiioooo\"\n",
      "batch 5599  loss=153.5948  steps/s=96.26  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"n  a  77          eeeee tiitiiiii      o\"\n",
      "batch 5600  loss=203.7425  steps/s=102.43  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"o    IIIIIINNNNNNNMMMMM         ////////\"\n",
      "batch 5602  loss=131.7628  steps/s=105.52  prediction: \"m, are also used in calculating/thinking\" => \"e te ae                         llllllli\"\n",
      "batch 5603  loss=165.9723  steps/s=98.38  prediction: \" 4am programming https://t.co/5THAY3txKR\" => \"@Ert e          mmmmm mmmatttt/t////////\"\n",
      "batch 5604  loss=131.7747  steps/s=101.94  prediction: \" android OS inside of a virtual machine?\" => \"@nd an         n                        \"\n",
      "batch 5605  loss=133.4447  steps/s=104.88  prediction: \"r time your focus muscle will strengthen\" => \"eotreeeeeeeeee r                        \"\n",
      "batch 5606  loss=134.6478  steps/s=105.88  prediction: \"r the years for business/building things\" => \"e(e )    eeeee r       sssssssssssssiiii\"\n",
      "batch 5607  loss=144.2568  steps/s=70.29  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ust  eeeeeeeer  rr  essssssssiii   iiiii\"\n",
      "batch 5608  loss=129.5602  steps/s=108.29  prediction: \"igh quality outputs with infinite tokens\" => \"nh             uuuuuuuuutttttiiiiiiiiiii\"\n",
      "batch 5609  loss=135.4418  steps/s=105.44  prediction: \", its everywhere https://t.co/hHirNEgYqf\" => \" ao ,          r   eeeeeeeeetttttttt////\"\n",
      "batch 5610  loss=134.8773  steps/s=101.92  prediction: \"ant believe I havent been napping before\" => \"nd, d     ee      eeeeeeeeeeeeeeeneennee\"\n",
      "batch 5611  loss=145.0197  steps/s=103.94  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" r   ehtttttttaaaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttttt/////\"\n",
      "batch 5612  loss=158.6506  steps/s=105.73  prediction: \"caml my caml, our fearful thread is done\" => \"asase    mmmmmmmmm                      \"\n",
      "batch 5613  loss=133.2769  steps/s=103.17  prediction: \"inful to stfu but it works suuuuper well\" => \"nk sl          t       t      uuuuuuuuuu\"\n",
      "batch 5614  loss=141.6674  steps/s=42.27  prediction: \"ly: @sujantkumarkv Will do man will do ðŸ’ª\" => \"y: tt     tttuu   t          uuuuuuuuuu \"\n",
      "batch 5615  loss=126.2985  steps/s=112.36  prediction: \"e knows what a kernel or text editor are\" => \" p o                                    \"\n",
      "batch 5616  loss=162.0305  steps/s=105.30  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"epny  @         nnnnnnnnttttttttttttt///\"\n",
      "batch 5617  loss=124.4335  steps/s=104.79  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "the  taaaaaaaa         a               \"\n",
      "batch 5618  loss=130.1782  steps/s=105.63  prediction: \"a decision making incongruency somewhere\" => \"ns o  ssssssssss iiiiiiiinnnnnnnnnnnnnnn\"\n",
      "batch 5619  loss=128.3025  steps/s=104.28  prediction: \"then add audio and make it a vid editor.\" => \" ea ais     dddddddddddd                \"\n",
      "batch 5620  loss=188.4884  steps/s=52.56  prediction: \": @minamisatokun https://t.co/7cpKcX83WN\" => \" @juamo  adddda dd   a                 i\"\n",
      "batch 5621  loss=146.4554  steps/s=109.62  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" hn                  tttttttttttt/tt////\"\n",
      "batch 5623  loss=154.2557  steps/s=69.96  prediction: \"Brycicle77 its a 'being' kinda day today\" => \"AP lt tt       n  tt  tttttt///////// oa\"\n",
      "batch 5624  loss=132.2623  steps/s=106.38  prediction: \"sfully improved their lives tremendously\" => \"  fues sssssssss eeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5625  loss=133.8890  steps/s=89.72  prediction: \"eMTB very, very inefficiently, thats how\" => \" TBuecyyeeeeee v eer  iiiiiiieeeeeetttt \"\n",
      "batch 5627  loss=137.5750  steps/s=103.36  prediction: \"ind groups of ppl who love what you love\" => \"ne                                      \"\n",
      "batch 5629  loss=133.0011  steps/s=106.46  prediction: \" software used that widely is so awesome\" => \"tue                                     \"\n",
      "batch 5631  loss=127.0682  steps/s=102.94  prediction: \" new meta\n",
      "dont think too hard about that\" => \"tok             t ttttttttttt          t\"\n",
      "batch 5632  loss=121.1643  steps/s=101.22  prediction: \"elete post but it works on anyone's post\" => \"  te  eeeeeeeeettttttt               oon\"\n",
      "batch 5634  loss=127.5606  steps/s=105.35  prediction: \"best ways to improve for stuff like this\" => \"u   o                            fffffff\"\n",
      "batch 5635  loss=133.4809  steps/s=103.89  prediction: \"the highest quality music we have so far\" => \"hen   h  hhhhhhhhh     t                \"\n",
      "batch 5636  loss=153.4039  steps/s=98.90  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"asie tieee                ttttttttt/////\"\n",
      "batch 5637  loss=135.0190  steps/s=21.66  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly:  eeee              tttttttttt//////\"\n",
      "batch 5638  loss=125.4882  steps/s=111.08  prediction: \"lots of stuff you learn way way way more\" => \"yt @ou         f                    yyyy\"\n",
      "batch 5640  loss=166.2327  steps/s=103.26  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"tn ee          t                        \"\n",
      "batch 5642  loss=128.1178  steps/s=104.98  prediction: \" are no forests where 2+2 truly equals 5\" => \"tr             r  eeeeeeeeeeee          \"\n",
      "batch 5643  loss=139.7509  steps/s=103.47  prediction: \"6hrs on something that feels like a game\" => \"hrs1                                    \"\n",
      "batch 5644  loss=132.3547  steps/s=104.81  prediction: \"r these very cool words. well said, dang\" => \"et ee          r           o            \"\n",
      "batch 5645  loss=138.2868  steps/s=101.93  prediction: \"worst part, as demonstrated by the graph\" => \"ir    e  tttt           ttttttttttttt   \"\n",
      "batch 5646  loss=132.5277  steps/s=99.87  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"ne e            ddd      e              \"\n",
      "batch 5647  loss=144.5328  steps/s=104.55  prediction: \"darin and english which they are meh at)\" => \" ao axe    nnnn nnnnnnn       hhhhhhhhh \"\n",
      "batch 5649  loss=136.1996  steps/s=99.24  prediction: \"vinwylde the r in rgb stood for retarded\" => \"er eSren eeeee n                     rrr\"\n",
      "batch 5650  loss=146.0726  steps/s=102.79  prediction: \"d LLMs to get boilerplate and stuff done\" => \" mtt ennn      t                        \"\n",
      "batch 5651  loss=139.3131  steps/s=101.26  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" t e                    tttttttttt//////\"\n",
      "batch 5652  loss=130.7052  steps/s=103.74  prediction: \"e forever with a simple 5min interaction\" => \" sin oeeeeeeeeefee              iiiiiiii\"\n",
      "batch 5653  loss=134.5003  steps/s=102.50  prediction: \"ut you neeeeeed execution skill yourself\" => \"   w rrrrr eeeeeeeeeeeeeeeeeeeee        \"\n",
      "batch 5654  loss=141.1734  steps/s=100.23  prediction: \"ffects that are extremely hard to notice\" => \" ee  leeeeee eeteeeeeeeeeeeeeeeeee      \"\n",
      "batch 5655  loss=139.6930  steps/s=105.45  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"e e s y        ooooooooooooooooooo      \"\n",
      "batch 5657  loss=136.1231  steps/s=101.87  prediction: \"ill consider leaning into it more though\" => \"nl             l    iiinnniiiiiiii      \"\n",
      "batch 5658  loss=135.9627  steps/s=103.96  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"epc,                uuuu   tttttt///////\"\n",
      "batch 5659  loss=128.7055  steps/s=104.34  prediction: \"have become too big and are rotting away\" => \"as  aee eeeeeeemee                      \"\n",
      "batch 5660  loss=128.0512  steps/s=103.61  prediction: \"dates/incentives to fund ai safety stuff\" => \" vo oaaaaaaaaeeeeeeeeeeennnn            \"\n",
      "batch 5661  loss=238.2679  steps/s=95.29  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"nCe  a      OOOOOOOOOOOOOOO  ///////////\"\n",
      "batch 5662  loss=138.9034  steps/s=100.28  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" ts cs     mmmmmmmmmmmmmmmmeeee ee   ooo\"\n",
      "batch 5663  loss=126.7923  steps/s=105.77  prediction: \"nse and you can't efficiently work withâ€¦\" => \"ge t                       n            \"\n",
      "batch 5664  loss=136.0084  steps/s=103.70  prediction: \"re use at my job instead of adobes stuff\" => \"eplo:                                   \"\n",
      "batch 5665  loss=127.6652  steps/s=104.28  prediction: \"more efficient parameters in the network\" => \"eveie       eee eeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5667  loss=140.7723  steps/s=104.12  prediction: \"how it is in c++. Trace them rays brotha\" => \"el  ol                                  \"\n",
      "batch 5668  loss=133.8528  steps/s=104.74  prediction: \"e info produced by exploring new options\" => \" iiani nn      n                        \"\n",
      "batch 5669  loss=135.1259  steps/s=104.79  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \" tse                           /////////\"\n",
      "batch 5670  loss=133.1675  steps/s=105.81  prediction: \"elf even if it overlaps with signoooling\" => \" ysl llleee                          iii\"\n",
      "batch 5671  loss=126.0096  steps/s=101.81  prediction: \"his wtf\n",
      "\n",
      "ill dm u a link around the 25th\" => \"esi t t  ttttt t                        \"\n",
      "batch 5672  loss=126.9240  steps/s=103.20  prediction: \"in there for sure\n",
      "Those guys are awesome\" => \"ng   eeeeeee   e      eee             ee\"\n",
      "batch 5674  loss=127.2230  steps/s=104.27  prediction: \" a lot will impact the rest of your life\" => \"t  ti          l                        \"\n",
      "batch 5675  loss=143.8811  steps/s=105.30  prediction: \"sing way more efficient/scalable methods\" => \" n l                   eeeeeeeeeeeeeeeee\"\n",
      "batch 5676  loss=118.1587  steps/s=30.14  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"ly: @          f     eeeeeeeffeeeeeeeeee\"\n",
      "batch 5677  loss=125.3561  steps/s=117.07  prediction: \" @llamapuckey never visit sf without jug\" => \"ttil  laa  e   f y eeeeeeeifffieeetttoee\"\n",
      "batch 5678  loss=133.7757  steps/s=106.77  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"   s  s        s              aaaaaaa   \"\n",
      "batch 5679  loss=145.3144  steps/s=96.24  prediction: \"looking fractals https://t.co/PNG9vTa8x5\" => \"ys oroooooooooo laaaaaaatttttttttt//////\"\n",
      "batch 5680  loss=141.9585  steps/s=106.35  prediction: \"yacine needs a dingboard wrap on his car\" => \":copro c    aa                a o  aa   \"\n",
      "batch 5681  loss=140.9433  steps/s=98.38  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"g eo  m                   tttttt////////\"\n",
      "batch 5683  loss=181.4324  steps/s=99.01  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tf  icii            ttttttttttt/////////\"\n",
      "batch 5684  loss=127.4994  steps/s=29.98  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly: @ic        n  tttttttttt///////////t\"\n",
      "batch 5685  loss=130.3542  steps/s=119.58  prediction: \"u can build in a week is actually insane\" => \"sc of   uuuu   n                        \"\n",
      "batch 5686  loss=132.1424  steps/s=38.68  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @at uuuuuu                  a     aa \"\n",
      "batch 5687  loss=125.9970  steps/s=29.31  prediction: \"reply: @justalexoki He is the goat fr fr\" => \"eply: @uuuuuu                 aa     aaa\"\n",
      "batch 5688  loss=120.1748  steps/s=145.75  prediction: \"he race to steal the eu tech bros begins\" => \"e  o  ccc          eeee  eeeeeeee    eee\"\n",
      "batch 5689  loss=131.3298  steps/s=103.17  prediction: \"ining data. The loss went down over time\" => \"ngto ennnaaaaaanaaaa                    \"\n",
      "batch 5690  loss=136.0178  steps/s=104.48  prediction: \"self tho prob cause that sounds more fun\" => \"  mm mm        m                        \"\n",
      "batch 5691  loss=127.1291  steps/s=103.37  prediction: \"ind. also so my brain doesnt deteriorate\" => \"ng  o          n                       r\"\n",
      "batch 5692  loss=136.4312  steps/s=105.75  prediction: \"per curious to see what youre working on\" => \"lrt  sa                                 \"\n",
      "batch 5693  loss=130.1958  steps/s=105.16  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in l          n               nn       \"\n",
      "batch 5694  loss=124.4100  steps/s=38.29  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"e:  y            nnnnn        nnnn      \"\n",
      "batch 5697  loss=127.7274  steps/s=110.93  prediction: \" and realized idk what it actually means\" => \"tb fhf f        ddddddd             aaaa\"\n",
      "batch 5698  loss=173.5010  steps/s=103.09  prediction: \"n `AI(short prompt)-&gt;output` programs\" => \" tdo a                 oottttttttttttttt\"\n",
      "batch 5699  loss=152.1121  steps/s=103.58  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"p..oknet////////tttttttttttt///////////t\"\n",
      "batch 5700  loss=143.4774  steps/s=101.90  prediction: \"y is that the levels of learning theory?\" => \":iiceee        t                   eeeee\"\n",
      "batch 5701  loss=227.0400  steps/s=97.45  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \" GOT G EEEEE      RRRR       tttt///////\"\n",
      "batch 5702  loss=148.0263  steps/s=89.86  prediction: \"ller accurate. really useful distinction\" => \"y  @To            tttt   . l/ll   sstttt\"\n",
      "batch 5703  loss=141.4652  steps/s=100.53  prediction: \"p chats and 4chan are two i can think of\" => \"llt @          c                        \"\n",
      "batch 5705  loss=156.3672  steps/s=98.45  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"eu    oonnnnaaa      ..........tttt/////\"\n",
      "batch 5706  loss=129.6872  steps/s=105.06  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf nin i       n                        \"\n",
      "batch 5707  loss=206.6136  steps/s=103.19  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"h n///////////tttttttttttttttt//////FFFF\"\n",
      "batch 5708  loss=134.8568  steps/s=103.06  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"enl :                                   \"\n",
      "batch 5709  loss=136.7478  steps/s=103.70  prediction: \"de you hate work\n",
      "https://t.co/2jmiAqT1C6\" => \" ci i                 tttttttttttt//////\"\n",
      "batch 5710  loss=133.8165  steps/s=102.68  prediction: \"y its been a useful learning experience?\" => \" c  uo                        eeeeeeeeee\"\n",
      "batch 5711  loss=133.3370  steps/s=104.31  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \"ue    000       0000000000              \"\n",
      "batch 5712  loss=143.8171  steps/s=102.88  prediction: \"hackers #saas #developers #buildinpublic\" => \"esgs niiiiissssessssseeeee######eeeeeeee\"\n",
      "batch 5713  loss=129.5367  steps/s=104.86  prediction: \"en clusters into single tokens like this\" => \" t  e eeeeeeee t                        \"\n",
      "batch 5714  loss=126.2876  steps/s=106.89  prediction: \"ood and helps you not waste future years\" => \"ud                                      \"\n",
      "batch 5715  loss=135.0986  steps/s=99.10  prediction: \" personally wasted many years bc of this\" => \"ta inaeeeeeeellelllaaaaaaaaaaayyy       \"\n",
      "batch 5716  loss=138.0349  steps/s=104.75  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"tyr  e      ,,,,,,          tttttttt////\"\n",
      "batch 5718  loss=141.6028  steps/s=103.08  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"   e  c    nnnnonnnntttttttttttt////////\"\n",
      "batch 5720  loss=157.3488  steps/s=101.46  prediction: \"encoded url that leads to discord invite\" => \" t : @2cceee   e                  ddd   \"\n",
      "batch 5721  loss=168.4261  steps/s=38.81  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"y  @7  eeee         t          ddd      \"\n",
      "batch 5722  loss=120.6443  steps/s=138.86  prediction: \"resy you can already talk to one of them\" => \"eply: @eeee        aaaaaaaaa  o         \"\n",
      "batch 5723  loss=133.0500  steps/s=103.60  prediction: \"uff and just pretending to do side stuff\" => \"rf f           n        nnnn            \"\n",
      "batch 5724  loss=158.7214  steps/s=37.27  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"y: n o             ttnnntttt   dd       \"\n",
      "batch 5725  loss=145.1565  steps/s=144.25  prediction: \"d 1995 type sites are such a great style\" => \" too   o       ttttttssse               \"\n",
      "batch 5726  loss=125.0643  steps/s=105.42  prediction: \"rself or others interested in something?\" => \"eos of     oooor   rrrreeeeeeeeeeeeeeeee\"\n",
      "batch 5727  loss=139.6543  steps/s=104.83  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"y   uec aaaaaaa a   ttttttttttttttttt///\"\n",
      "batch 5728  loss=137.6742  steps/s=104.14  prediction: \"ions for agents\n",
      "Sounds v similar to this\" => \"nn Le e           nnnnnnnnnsssssss      \"\n",
      "batch 5729  loss=135.8467  steps/s=20.89  prediction: \"eply: @ludwigsonneck Did you learn/grow?\" => \" lyv  r       nnnonnnnnn sssssss        \"\n",
      "batch 5730  loss=138.1731  steps/s=110.45  prediction: \" from scratch, and a bit of transformers\" => \"tonp a         c                        \"\n",
      "batch 5732  loss=128.6640  steps/s=98.73  prediction: \"dness there are some juicy tactics there\" => \" ie  mooooo    s                     ctc\"\n",
      "batch 5733  loss=148.2150  steps/s=96.65  prediction: \"ieved internally https://t.co/tbnU75n8eA\" => \"nn  h eeeeeeeeeeeeeee tttttttttttttttt//\"\n",
      "batch 5734  loss=126.5992  steps/s=103.27  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"  e e    oooooo                        s\"\n",
      "batch 5735  loss=129.6446  steps/s=104.32  prediction: \"people, i just post a weird mix of stuff\" => \"lr     o                                \"\n",
      "batch 5736  loss=136.5763  steps/s=104.54  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"l   aey  aaaaaaa    tttttttttttttttt////\"\n",
      "batch 5737  loss=142.4101  steps/s=105.00  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"eko the     hhhhhhhhhhhhtttttttttt//////\"\n",
      "batch 5738  loss=148.1133  steps/s=100.66  prediction: \"ve you ever worked for a fast food chain\" => \"el olil        eeeeee                   \"\n",
      "batch 5739  loss=133.5484  steps/s=101.89  prediction: \"n theres ppl who dont code like this????\" => \" t \n",
      " oeeeeeeee r                        \"\n",
      "batch 5740  loss=161.2140  steps/s=100.00  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"ng ne               tttttttttttttttttt//\"\n",
      "batch 5741  loss=144.8049  steps/s=101.62  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"eysi          eeeeeeeeeee ????ttt////888\"\n",
      "batch 5742  loss=148.6114  steps/s=104.78  prediction: \"ort (effort is proportional to time butâ€¦\" => \"ne tett      ff fff  roooooooooooooooott\"\n",
      "batch 5743  loss=125.8561  steps/s=102.96  prediction: \"aybe I need to grow more tomatoes though\" => \"n ene          e             ooooooooooo\"\n",
      "batch 5744  loss=129.0071  steps/s=99.96  prediction: \"r than age sounds like a skill issue tbh\" => \"etly: @ aa                       sssssss\"\n",
      "batch 5745  loss=141.3352  steps/s=96.68  prediction: \"ublic Refining my problem finder program\" => \"rlet  iiii  inn   i               e     \"\n",
      "batch 5746  loss=169.7715  steps/s=102.60  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \"ot ettccccccccccc           ooooo///////\"\n",
      "batch 5747  loss=135.9055  steps/s=93.69  prediction: \"thy I wonder how attention relates to IQ\" => \"hee/Ckaaa         oo   ttttttttttttttttt\"\n",
      "batch 5749  loss=123.9574  steps/s=104.19  prediction: \"ming world models, and also trusting you\" => \"ene vo         r      ddddd             \"\n",
      "batch 5750  loss=137.9125  steps/s=102.72  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"etny:         eeeeaeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5751  loss=130.6888  steps/s=104.63  prediction: \"of those bc there are uncountably many c\" => \"n   bnn                                 \"\n",
      "batch 5753  loss=135.5737  steps/s=103.60  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tftp s ssssssssssssssssssss          aaa\"\n",
      "batch 5754  loss=129.5073  steps/s=105.22  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y  eite  lll   l                      aa\"\n",
      "batch 5755  loss=125.9057  steps/s=103.58  prediction: \"he result, its equivalent to convolution\" => \"e e rerrrr     t         tttttttttttttto\"\n",
      "batch 5756  loss=237.9019  steps/s=94.17  prediction: \"/t.co/NlzdO0Z2DA https://t.co/qGWUkC7cdS\" => \"t..ootstt///tt t    ttttttttttttoooooooo\"\n",
      "batch 5757  loss=130.3012  steps/s=105.77  prediction: \"rger abstractions which eventually haveâ€¦\" => \"ees e     aaaaaraaaarrrr              ee\"\n",
      "batch 5758  loss=131.8373  steps/s=102.73  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \"uri ii                                  \"\n",
      "batch 5759  loss=131.8656  steps/s=102.39  prediction: \" pried the shift key off w a screwdriver\" => \"tareaaa                                 \"\n",
      "batch 5760  loss=151.2844  steps/s=100.98  prediction: \"of work every monday and thursday brotha\" => \"u in r         r                  dddd  \"\n",
      "batch 5761  loss=136.1266  steps/s=102.25  prediction: \"y\n",
      "\n",
      "gotta tie everything back to the goal\" => \":\n",
      "  eseeettttttttetttttttttttttttt      \"\n",
      "batch 5762  loss=143.7578  steps/s=102.14  prediction: \" have been goin up too. Things are movin\" => \"taa                                     \"\n",
      "batch 5763  loss=126.4967  steps/s=99.32  prediction: \"on said we cant use that word any more!!\" => \"u  b           n                        \"\n",
      "batch 5764  loss=178.9349  steps/s=103.85  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OOOO\n",
      "\n",
      "                      tttttt//////\"\n",
      "batch 5765  loss=123.5255  steps/s=96.34  prediction: \"he race to steal the eu tech bros begins\" => \"e do      e eeeeeettee eteetteeeee   eee\"\n",
      "batch 5766  loss=130.2776  steps/s=102.76  prediction: \"better generalizer than the classic MLP?\" => \"u           eeeeeeeeeeeeeeeeeeeee       \"\n",
      "batch 5767  loss=133.0109  steps/s=105.05  prediction: \"se? seems like death spiral potential no\" => \"  eo eeeeeeeeeeeeeeeeeee                \"\n",
      "batch 5768  loss=134.7635  steps/s=104.59  prediction: \"discovering new unseen fundamentals, too\" => \" ne t d        n  nnnnnnnnnnnnnnnnnnnnnn\"\n",
      "batch 5769  loss=171.2379  steps/s=106.60  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"lanaaiiiiiiiii_______777777777i         \"\n",
      "batch 5770  loss=146.7582  steps/s=105.76  prediction: \"he HTML/CSS to render (show) the webpage\" => \"e d e   e                             ee\"\n",
      "batch 5771  loss=140.7028  steps/s=97.23  prediction: \"my database is a text file called main.c\" => \"e tetee        t                 eee  ee\"\n",
      "batch 5773  loss=134.9500  steps/s=72.50  prediction: \"oppflightkid That could be helpful yeah!\" => \"nle e  ppp     t             leeelllllll\"\n",
      "batch 5774  loss=148.1049  steps/s=107.23  prediction: \"sted this first)\n",
      "https://t.co/7AHwatHv6Y\" => \" ooo o              tttttttttttt///////t\"\n",
      "batch 5775  loss=148.2472  steps/s=99.23  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" too @eee         ttttttttt/////////////\"\n",
      "batch 5776  loss=138.2225  steps/s=105.69  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  lo     rrrrrrrrreeeeeeeeeeoooooooooll\"\n",
      "batch 5777  loss=143.6948  steps/s=98.61  prediction: \"t just means youre on par with a supergm\" => \"hin ti  sssss  s                        \"\n",
      "batch 5779  loss=131.9579  steps/s=104.04  prediction: \"d my sleep waaay better\n",
      "\n",
      "would recommend\" => \" as   a        e  aaaaeeeeeeeeeeeeeeeeee\"\n",
      "batch 5780  loss=148.3620  steps/s=51.63  prediction: \": @yacineMTB Action produces information\" => \" @brly eeeeeeaa  aaaeeeeeeeeeeeeeermmmme\"\n",
      "batch 5781  loss=140.8149  steps/s=107.15  prediction: \" up to do multiple iterations of editing\" => \"tst  t                 ttttttttttttiiiii\"\n",
      "batch 5782  loss=131.9547  steps/s=104.90  prediction: \"ite complexity? If not, what is the max?\" => \"n ini iiiiiiiiiniii                     \"\n",
      "batch 5783  loss=132.2443  steps/s=104.65  prediction: \"l? I guess maybe low level memory stuff?\" => \"y  @a                   llllllleeeeeeeee\"\n",
      "batch 5784  loss=138.7197  steps/s=99.77  prediction: \"yacine needs a dingboard wrap on his car\" => \" c ca         eeeee  ee e               \"\n",
      "batch 5785  loss=121.2784  steps/s=104.62  prediction: \" and the quote tweet is the reply itself\" => \"t pt t ttttttttetttteeeeeeeeeeeeee      \"\n",
      "batch 5786  loss=158.2541  steps/s=105.09  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"t..ootttt/////////tttttttt/////////////p\"\n",
      "batch 5787  loss=155.2950  steps/s=30.27  prediction: \"ply: @sunsettler https://t.co/VV0NoHhCJz\" => \"ly: @ t////////ottttttt///t/////////YYYY\"\n",
      "batch 5788  loss=130.9843  steps/s=110.26  prediction: \"g correct (fingers crossed its this one)\" => \" a e e errrrrrrrrrrrrrrrrrrrrsssssssssss\"\n",
      "batch 5789  loss=139.1617  steps/s=101.15  prediction: \"ly got above len=2 for the longest time.\" => \"y:b@ zt                                e\"\n",
      "batch 5790  loss=139.3042  steps/s=106.11  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tut ttta      u uuttttttttttttttttttttt/\"\n",
      "batch 5791  loss=131.6861  steps/s=103.65  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t a                hhhtttttttttttttt////\"\n",
      "batch 5792  loss=137.1580  steps/s=52.57  prediction: \": @ns123abc meet only one of her parents\" => \" @tai i         httttttttttttto//////ooj\"\n",
      "batch 5793  loss=135.3604  steps/s=106.01  prediction: \"n clarity from practicing visualizationâ€¦\" => \" t e e n       r rrrrrrrriiiiiiiiiiiiiii\"\n",
      "batch 5794  loss=150.7316  steps/s=102.35  prediction: \"r you call this) https://t.co/l6jyM49oCP\" => \"etea L                   ttttttttttttt//\"\n",
      "batch 5795  loss=139.8038  steps/s=105.60  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th  o                   tttttttttt//////\"\n",
      "batch 5796  loss=129.7447  steps/s=105.14  prediction: \"d it tho, was a change of weather for me\" => \" th t eeeeee   t                        \"\n",
      "batch 5797  loss=148.3439  steps/s=101.69  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"er i eeeeeeeeeeeeeeeeooppppptttttooo////\"\n",
      "batch 5798  loss=131.6789  steps/s=72.99  prediction: \"xluffyb interest is a powerful thing man\" => \"_eti fffffffeeeeeetetss  tto///o//tljjjj\"\n",
      "batch 5799  loss=125.3802  steps/s=108.04  prediction: \"te well is a powerful powerful advantage\" => \"hv e ye                               aa\"\n",
      "batch 5800  loss=126.7881  steps/s=102.64  prediction: \"have primitives if you look close enough\" => \"ete ie viiiiiiiviiiiiiiiii            oo\"\n",
      "batch 5801  loss=139.7523  steps/s=98.92  prediction: \" just signed up as a beta tester hehhehe\" => \"tuv            s                 eeeeeee\"\n",
      "batch 5802  loss=122.4778  steps/s=70.58  prediction: \"0nnnpppppppppp hilarious bait, i love it\" => \"x uo p ppppppppppppp   a aa      e  ehee\"\n",
      "batch 5803  loss=125.4755  steps/s=105.59  prediction: \"e latent space of \"make things ppl want\"\" => \" att  t     tttt                        \"\n",
      "batch 5804  loss=147.7533  steps/s=103.24  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" yee h       hht             nnnnnnnnnnn\"\n",
      "batch 5805  loss=141.1972  steps/s=99.86  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"@n e oooooooo iiiiiiiiiiiiiiii          \"\n",
      "batch 5806  loss=132.1251  steps/s=103.59  prediction: \" personally make you a funny monkey meme\" => \"@ld      llllllllll                     \"\n",
      "batch 5807  loss=128.4006  steps/s=103.85  prediction: \"and i think that helped me a ton in life\" => \"nd o t                                  \"\n",
      "batch 5808  loss=137.6757  steps/s=107.66  prediction: \"efitted from tracking sleep and whatnot?\" => \" fe    eeeeeeeete                       \"\n",
      "batch 5809  loss=130.7852  steps/s=104.37  prediction: \"at can be beaten if you look hard enough\" => \"nss seseeeeeeeeeeee                     \"\n",
      "batch 5810  loss=126.1549  steps/s=105.70  prediction: \"ood and helps you not waste future years\" => \" d             n                    uuuu\"\n",
      "batch 5811  loss=143.8842  steps/s=103.61  prediction: \"/t.co/zlto3SBYwd https://t.co/joIt9EpsFP\" => \"/..kottt////////tttttttttttt/////////ttt\"\n",
      "batch 5812  loss=148.2355  steps/s=86.43  prediction: \"gizmobly @juweeism duude this is awesome\" => \" zuttl//tttttltwwtttttt/tttt/ttttttsssso\"\n",
      "batch 5813  loss=132.3248  steps/s=105.54  prediction: \"plate btw if u wanna make ur own version\" => \"ly: @s eeeee                            \"\n",
      "batch 5814  loss=137.2179  steps/s=104.56  prediction: \"ool looking games, and get more interest\" => \" d   o oooooooolooooo                  e\"\n",
      "batch 5815  loss=133.5880  steps/s=100.23  prediction: \"or always posting these, they're great ðŸ‘\" => \" s lees  a  aaassss ssssssss eeeeeeeeeee\"\n",
      "batch 5816  loss=132.4164  steps/s=104.59  prediction: \"onder if he stuck w onnx or went w tf.js\" => \"    le                                  \"\n",
      "batch 5817  loss=132.0057  steps/s=81.95  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eply: @                                t\"\n",
      "batch 5818  loss=133.2988  steps/s=107.87  prediction: \"velsio's\n",
      "\n",
      "just gotta keep building, bros\" => \"er eslsssssssss sssssss      tt  t      \"\n",
      "batch 5819  loss=131.4128  steps/s=100.49  prediction: \"great great thurs\n",
      "key was blocking x lol\" => \" e eee gggggttt tttttttt                \"\n",
      "batch 5820  loss=157.0971  steps/s=104.47  prediction: \"??\n",
      "\n",
      "oh wow it is https://t.co/dShiVDjfFr\" => \" ?o n  ??????wwoww            ttt///////\"\n",
      "batch 5821  loss=139.1229  steps/s=92.87  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \"nn  ? ooooo    s    e ee e eeeeh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  s\"\n",
      "batch 5822  loss=133.4427  steps/s=102.19  prediction: \"ful info have you learned from it so far\" => \" n   sl        u                        \"\n",
      "batch 5823  loss=126.6069  steps/s=105.54  prediction: \"his is the same w similar things in life\" => \"ene  iiiiiii   s                    iiii\"\n",
      "batch 5824  loss=136.2597  steps/s=101.53  prediction: \"inful to stfu but it works suuuuper well\" => \"ng ts          t  u           uuuuuuuuuu\"\n",
      "batch 5825  loss=130.7060  steps/s=105.53  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in            n               nnn      \"\n",
      "batch 5826  loss=134.5231  steps/s=104.71  prediction: \" to ask \"show me every block below y=16\"\" => \"th                                      \"\n",
      "batch 5827  loss=128.9259  steps/s=101.50  prediction: \"inlet like me to test experiments out on\" => \"nglee r        t         eeeeeeeeeeeeett\"\n",
      "batch 5828  loss=126.8581  steps/s=103.57  prediction: \"s of industry water cooler conversations\" => \" fnt   ssssssssns             oorrrrrroo\"\n",
      "batch 5829  loss=177.2269  steps/s=106.25  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"t..ool:t///////ttttttttttttt//////////tt\"\n",
      "batch 5830  loss=142.1358  steps/s=104.60  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" poo tttt      t    ttttttttttttttt/////\"\n",
      "batch 5831  loss=134.1717  steps/s=104.13  prediction: \"ed, excited to see how it goes for you ðŸ«¡\" => \"  e deeeeeeeeeeeeeeeeeee                \"\n",
      "batch 5833  loss=130.7690  steps/s=102.01  prediction: \"umps ig\n",
      "\n",
      "all good, just gotta never stop\" => \"te  aaa        g                        \"\n",
      "batch 5834  loss=135.2332  steps/s=101.37  prediction: \"thats a good one, comparing with experts\" => \"he e te                ooooo            \"\n",
      "batch 5835  loss=132.7060  steps/s=103.93  prediction: \"imize model performance (we are talkingâ€¦\" => \"net o i        eeemmmeeeeeeeeeeeeeeeeeee\"\n",
      "batch 5836  loss=139.6339  steps/s=102.66  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" minnnnnnnooooo          tttttttttttt///\"\n",
      "batch 5837  loss=148.7636  steps/s=68.64  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ectc n oo  o      tttttttttttt//////ffff\"\n",
      "batch 5838  loss=150.9828  steps/s=107.82  prediction: \" God for helping us both out\n",
      "it was hell\" => \"tOr  l                                  \"\n",
      "batch 5839  loss=152.8784  steps/s=97.70  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"tedw o o             t  ttttttttttt///88\"\n",
      "batch 5840  loss=137.8655  steps/s=103.54  prediction: \"n and id 100% recommend it over The Goal\" => \" a fooddddddd  d                        \"\n",
      "batch 5841  loss=156.3998  steps/s=104.69  prediction: \"ndow its just :q when inside that window\" => \"  \n",
      "o o    o o                       i   \"\n",
      "batch 5842  loss=145.1093  steps/s=104.07  prediction: \"t habit of reaching for my phone is gone\" => \"hf    ttttttttt                         \"\n",
      "batch 5843  loss=139.0881  steps/s=96.06  prediction: \"ts just showing you their main accts now\" => \"h o  t         t                        \"\n",
      "batch 5844  loss=130.8894  steps/s=99.24  prediction: \"ntiers out there we dont even know about\" => \"  TB           t          eeeeeeeee     \"\n",
      "batch 5845  loss=131.3920  steps/s=104.67  prediction: \" the time and not spread important info?\" => \"toe  l                              tttt\"\n",
      "batch 5846  loss=141.2819  steps/s=101.02  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to ai             ssssss               \"\n",
      "batch 5847  loss=126.9294  steps/s=102.58  prediction: \"lgorithms\n",
      "Get better learning algorithms\" => \"y rn             tttttttteeeeeeeeeerrrrr\"\n",
      "batch 5848  loss=134.1172  steps/s=100.15  prediction: \"xes this (whether you want it to or not)\" => \" s  s ssssssssss                        \"\n",
      "batch 5849  loss=129.7907  steps/s=105.07  prediction: \"m, are also used in calculating/thinking\" => \"a ae aee                        aallllii\"\n",
      "batch 5850  loss=143.8797  steps/s=103.43  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"theeee                    tttt/////////t\"\n",
      "batch 5851  loss=138.7321  steps/s=104.29  prediction: \"rs a question i've been unable to crackâ€¦\" => \"e he l   sssssss         eeeeeeeee      \"\n",
      "batch 5852  loss=138.3962  steps/s=98.17  prediction: \"mann is the goat I love that guy so much\" => \"alt lyn  n nnn                          \"\n",
      "batch 5853  loss=132.3274  steps/s=103.70  prediction: \"e firework chair https://t.co/J6w6odDBx3\" => \" a n nn        e      rrrrrrrttttt//////\"\n",
      "batch 5854  loss=135.9732  steps/s=102.72  prediction: \"ns you get the yellow letters on lichess\" => \" eea t                    eeeeeeeeeeeeee\"\n",
      "batch 5855  loss=127.8526  steps/s=104.00  prediction: \"n sheeps clothing is probably enough tbh\" => \" saloes                                 \"\n",
      "batch 5856  loss=124.6178  steps/s=45.58  prediction: \"y: @gizmobly nooooooooo my plans, foiled\" => \": @ eee        nooooooooo            bbb\"\n",
      "batch 5857  loss=139.6333  steps/s=129.06  prediction: \"yon Super hyped to see what youre cookin\" => \":u g ee   o   onoooooooo          o oooo\"\n",
      "batch 5858  loss=129.7238  steps/s=106.00  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"e  eeeeeeeeeeeeteeeeeee     \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     \"\n",
      "batch 5859  loss=131.7704  steps/s=104.59  prediction: \"it got like 2x fps rendering ocean waves\" => \"ns w                          eeeeeeeeee\"\n",
      "batch 5861  loss=143.4245  steps/s=100.16  prediction: \" can so can you. But maybe im projecting\" => \"toe                                     \"\n",
      "batch 5862  loss=151.0081  steps/s=105.51  prediction: \"verfit test btw) https://t.co/qErYnoBOJi\" => \"er b ( tttttttttttttttttttttttttt///////\"\n",
      "batch 5863  loss=148.8484  steps/s=94.27  prediction: \"eMTB How long until dingbots can do this\" => \" TB i tttt        t       ttt     oooo  \"\n",
      "batch 5864  loss=133.4056  steps/s=104.53  prediction: \" dingboard. Several others ive seen irl.\" => \"tome                        eeeeeeeeeeee\"\n",
      "batch 5865  loss=138.9546  steps/s=105.13  prediction: \" approximate it better outcompete others\" => \"tbl l          t   tttttttttttttttttttte\"\n",
      "batch 5866  loss=131.4680  steps/s=103.46  prediction: \" of indirection? Is that why that works?\" => \"tf a        iiiiiiiiiii           tttttt\"\n",
      "batch 5867  loss=139.1758  steps/s=104.11  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et   t tttttttoooooooooooooosssssssuusuu\"\n",
      "batch 5868  loss=135.6821  steps/s=100.28  prediction: \"important piece of advice here by a mile\" => \"np   aan       n             eeeeee     \"\n",
      "batch 5869  loss=127.2391  steps/s=104.54  prediction: \"you can control the models, and its free\" => \":u  oc    cccc c                        \"\n",
      "batch 5870  loss=143.0417  steps/s=104.62  prediction: \" drains your energy by paying attentionâ€¦\" => \"toat i         n      yyyyyyyyyyy     nn\"\n",
      "batch 5871  loss=137.0301  steps/s=107.00  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" mn nnnnnnnooo           ttttttttt//////\"\n",
      "batch 5872  loss=155.1109  steps/s=100.38  prediction: \"uff\n",
      "\n",
      "1. frogbrot https://t.co/JfifQf9WWd\" => \"tf of  fffffffffffffttttttttttt///////ff\"\n",
      "batch 5873  loss=131.3483  steps/s=99.03  prediction: \"if you say wala a lot are you a walawala\" => \"nu                   aaaaa             a\"\n",
      "batch 5874  loss=136.9751  steps/s=98.95  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"  o i sssssasaa                         \"\n",
      "batch 5875  loss=139.3416  steps/s=100.49  prediction: \" but also, probably, very poorly sampled\" => \"tus  l         l    bbbbbbb   ooyyyyyyyy\"\n",
      "batch 5876  loss=132.9116  steps/s=30.21  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: @ o          bbbbbbb    ,oyyyyyyyppl\"\n",
      "batch 5877  loss=152.3506  steps/s=145.28  prediction: \"mobly @amix011 May do this in the future\" => \"ern o olo    A    1 111              lee\"\n",
      "batch 5878  loss=151.4738  steps/s=104.79  prediction: \"e 10000x crazier than anything out there\" => \" tie aaa  000000              nnnnnn    \"\n",
      "batch 5879  loss=150.8110  steps/s=100.36  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \":u  ao                tttttttttttttt////\"\n",
      "batch 5880  loss=138.0389  steps/s=96.36  prediction: \"i wonder what the 3rd+ order effects are\" => \"n(Ba  iiii                     rrrrrrrer\"\n",
      "batch 5881  loss=128.9560  steps/s=90.93  prediction: \"Some Tal games are real art masterpieces\" => \"Spm  eo        m       aaerree   ee  aee\"\n",
      "batch 5882  loss=142.1811  steps/s=97.64  prediction: \"ight go back to ML stuff instead of this\" => \"nhs i          t                        \"\n",
      "batch 5883  loss=127.0875  steps/s=97.35  prediction: \"mirages keep getting crazier and crazier\" => \"ene               eeeeee  ettt         z\"\n",
      "batch 5884  loss=133.2276  steps/s=99.12  prediction: \" harmony until the clown nation attacked\" => \"@ar di                         nnnnnnnnt\"\n",
      "batch 5885  loss=159.2166  steps/s=103.39  prediction: \"/t.co/T03I8pk4ER\n",
      "https://t.co/XSr1ijr0iv\" => \"/.coo////////////tttttttttttt///////////\"\n",
      "batch 5886  loss=170.2200  steps/s=86.53  prediction: \"dup QUICK do something that doesnt scale\" => \" auoet/eepppppIoIottttttttttttttttttttss\"\n",
      "batch 5887  loss=139.3441  steps/s=104.40  prediction: \"e transformer architecture works so well\" => \" oo:       n    rrrrrrrrrrrrrrrrrrrrrrr \"\n",
      "batch 5888  loss=125.8111  steps/s=95.74  prediction: \"ki my highschool teacher taught it to me\" => \" d h       h hhhhhhhhhhhhheeeet tt      \"\n",
      "batch 5889  loss=135.6663  steps/s=102.86  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"ttth  e eeeeeeee   aaaaattttttttttttttt/\"\n",
      "batch 5890  loss=147.3212  steps/s=94.25  prediction: \" giz tarantinos alt?????? this shit fire\" => \"@oe  eg     aaanaatttttt???????????tt   \"\n",
      "batch 5891  loss=153.9299  steps/s=100.13  prediction: \"o make rlly complex interactive web apps\" => \"rs  t                     llleeeeeeeeeee\"\n",
      "batch 5892  loss=141.6694  steps/s=105.00  prediction: \"king progress. Now i see it eeeverywhere\" => \"  a at                          eeeeeeee\"\n",
      "batch 5893  loss=127.7921  steps/s=38.86  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y edai               s       eeeeeeeeeee\"\n",
      "batch 5894  loss=140.8223  steps/s=119.24  prediction: \"@djcows but yet my 5s gifs come out 50MB\" => \"audeeblooooss  r             eeeeeeeeree\"\n",
      "batch 5896  loss=131.3572  steps/s=58.38  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @ ioooooss         e     eeeeee   rrðŸ›‘\"\n",
      "batch 5897  loss=137.8378  steps/s=120.83  prediction: \"uth is the global maxima strat long term\" => \"t lie tttttttttttt            aaaa    a \"\n",
      "batch 5898  loss=130.1520  steps/s=102.92  prediction: \"mance feedback you hear abt friendly ppl\" => \"ake  o  eeeeeeeeeeeeeeeeee              \"\n",
      "batch 5899  loss=134.1375  steps/s=103.74  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" trit                                   \"\n",
      "batch 5900  loss=154.7922  steps/s=104.23  prediction: \"/t.co/T03I8pk4ER\n",
      "https://t.co/XSr1ijr0iv\" => \"t.coo/t://////////ttttttttttt///////////\"\n",
      "batch 5901  loss=137.0788  steps/s=102.52  prediction: \" the parameters corrrect from the start?\" => \"tha        aaaaaaaaarrrrrrrrrrrrrrrrr tt\"\n",
      "batch 5902  loss=198.1689  steps/s=100.67  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"o U eIIIIINNNNNNNMMMMMM             ////\"\n",
      "batch 5903  loss=136.8495  steps/s=102.93  prediction: \"and run it in the front end of a browser\" => \"nd t                                    \"\n",
      "batch 5904  loss=135.5594  steps/s=92.11  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @ o  i iiiiiniinnnnaaat  a a         \"\n",
      "batch 5905  loss=127.6463  steps/s=98.91  prediction: \"e drew your whole country as the soyjack\" => \" a                                      \"\n",
      "batch 5906  loss=156.5753  steps/s=101.61  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" ole ''nnnnnn  nggg\n",
      "\n",
      "                   \"\n",
      "batch 5907  loss=192.4822  steps/s=46.16  prediction: \"y: @BenjaminDEKR https://t.co/XKzK1sR0d2\" => \": @co' nnnaa gg oo                      \"\n",
      "batch 5908  loss=152.0214  steps/s=116.83  prediction: \"ock your 1000th follower and stay at 999\" => \"ue   ee        t 00000000oo             \"\n",
      "batch 5909  loss=130.3873  steps/s=104.70  prediction: \"useful analogies that show up everywhere\" => \"tt hsss                               ee\"\n",
      "batch 5910  loss=144.6625  steps/s=103.28  prediction: \"uper hard but I think it could be doable\" => \"te glarrrrrrrrrr                        \"\n",
      "batch 5911  loss=137.3879  steps/s=103.45  prediction: \"itor as I was with 2 screens and a mouse\" => \"n a a a        w                        \"\n",
      "batch 5912  loss=123.5354  steps/s=105.33  prediction: \"ginal returns idea seems to pop up a lot\" => \" no  o                eeeeeeee          \"\n",
      "batch 5913  loss=128.0329  steps/s=102.01  prediction: \"o feel cool writing in an alien language\" => \"nw o ee                           nnnnnn\"\n",
      "batch 5914  loss=134.0652  steps/s=102.07  prediction: \"error signals, weakening backpropagation\" => \"  eeeeeeeeerrrr rrr   e nnnnnnnaaaaaaaaa\"\n",
      "batch 5915  loss=139.7357  steps/s=104.66  prediction: \"ther reasons why\n",
      "https://t.co/C32Ru1Tc5u\" => \" e  e     ooooo o  hhhhhhhhttttttttt////\"\n",
      "batch 5916  loss=141.1752  steps/s=103.01  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nniootiiiiiiitt tt                      \"\n",
      "batch 5917  loss=131.4433  steps/s=104.04  prediction: \"e first img generation models rolled out\" => \" to            g          eeeeeeeeeellll\"\n",
      "batch 5918  loss=150.6306  steps/s=105.08  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`@LI8ÊœðŸ˜­`$$$$$$$$$$$$$$$$$$$$$$$$$}}}}}}}\"\n",
      "batch 5919  loss=134.8917  steps/s=100.28  prediction: \"you really need to make your own company\" => \":u gtaaa a                              \"\n",
      "batch 5920  loss=125.9284  steps/s=101.73  prediction: \" stream but i do my actual job and stuff\" => \"toet           t                        \"\n",
      "batch 5921  loss=134.2609  steps/s=103.75  prediction: \" You can hide these with adblock i think\" => \"toe s  oo                               \"\n",
      "batch 5923  loss=164.0617  steps/s=96.37  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"emly: @nnnnnnnnneeeeehhhhhh             \"\n",
      "batch 5924  loss=149.1950  steps/s=103.41  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tm iiiiiissssssissssstttttttttt/////////\"\n",
      "batch 5925  loss=159.6276  steps/s=100.62  prediction: \" cool\n",
      "\n",
      "ez follow\n",
      "https://t.co/F6AUVWpskt\" => \"@odi i           \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ooooooo////////\"\n",
      "batch 5926  loss=144.2334  steps/s=101.97  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"@it  t      fff ffff    ttttt///////////\"\n",
      "batch 5927  loss=128.9643  steps/s=104.84  prediction: \"oser and closer until you can putt it in\" => \"nt             l                        \"\n",
      "batch 5928  loss=134.5145  steps/s=100.68  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"tt   ll        e                        \"\n",
      "batch 5929  loss=133.9498  steps/s=70.82  prediction: \"ludwigABAP its all slop tier, always was\" => \"yd @ eee   i   n                        \"\n",
      "batch 5930  loss=134.9614  steps/s=105.63  prediction: \"I figure if we just do it, ppl will join\" => \" muddiiiiiiiiii                         \"\n",
      "batch 5931  loss=143.1904  steps/s=73.11  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"yaciigMiiiii                     lllllll\"\n",
      "batch 5932  loss=154.0018  steps/s=106.68  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"t.ccannt/////////ttttttttt//////////////\"\n",
      "batch 5933  loss=131.3238  steps/s=100.55  prediction: \"lves and destroy it all for local optima\" => \"ye @yaee eeeeeeee                 llllll\"\n",
      "batch 5934  loss=128.4286  steps/s=103.49  prediction: \"tle robots\n",
      "\n",
      "they remove so much friction\" => \" ai t ll     tt ttttttteeooooee         \"\n",
      "batch 5935  loss=132.9109  steps/s=74.33  prediction: \"paeoh Can't wait to see what ppl do w it\" => \"ls: to ooootttt ttttteeeeeeeee          \"\n",
      "batch 5936  loss=140.2216  steps/s=105.07  prediction: \"000000000000000000000001% of the new one\" => \" 1@ tl 00000000000000000000000000000    \"\n",
      "batch 5937  loss=199.1788  steps/s=100.00  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"  n  assssssss                  nn      \"\n",
      "batch 5938  loss=140.2278  steps/s=103.61  prediction: \"e (although Josh only mentioned it once)\" => \" fai iaaaaaaatth hoohoooo ooooooo     nn\"\n",
      "batch 5939  loss=160.4600  steps/s=104.56  prediction: \"/t.co/gufhF6ZVD6 https://t.co/0ldvn5Oi6t\" => \"/..c///:///////////ttttttttt///////////t\"\n",
      "batch 5940  loss=133.0901  steps/s=105.13  prediction: \"e walking through a memory palace maybe)\" => \" d  l  lll                         aaaaa\"\n",
      "batch 5941  loss=143.6753  steps/s=102.26  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"ld   o                 tttttttttttttt///\"\n",
      "batch 5942  loss=153.6404  steps/s=65.04  prediction: \" @AI_Solzhenitsyn it's an acquired taste\" => \"tyo        y  y yytttttttttttt//////bbbb\"\n",
      "batch 5943  loss=158.1328  steps/s=109.07  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \"nffi  ff                   tttttttttt///\"\n",
      "batch 5944  loss=134.8232  steps/s=80.52  prediction: \"odor_io worst metric youve heard so far?\" => \"neff oooooooooo   tttttttttt//oo/oooooor\"\n",
      "batch 5945  loss=137.8590  steps/s=84.29  prediction: \"calbach_ thanks! hope its useful for you\" => \"once\n",
      "tooo_o     tttt    t     e  e  f rr\"\n",
      "batch 5946  loss=147.1982  steps/s=105.12  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"taw    a        sssssssssssssssttttttt//\"\n",
      "batch 5947  loss=146.7099  steps/s=102.70  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e  aa          t             ,,,,,,,,,,,\"\n",
      "batch 5948  loss=132.2130  steps/s=100.77  prediction: \"the beta (should be around the 25th)\n",
      ": D\" => \"he             e                        \"\n",
      "batch 5949  loss=131.2732  steps/s=105.22  prediction: \"zations seem like they could be improved\" => \"en o?itiiiiiiiiiiiieeeeeeeeeee          \"\n",
      "batch 5950  loss=125.0181  steps/s=100.50  prediction: \"what overlaps stand out to you the most?\" => \"hie  itteee                             \"\n",
      "batch 5951  loss=137.3581  steps/s=99.09  prediction: \"ur gzip stuff? training on gzipped data?\" => \"teag                                    \"\n",
      "batch 5952  loss=155.4325  steps/s=11.75  prediction: \"reply: @ludwigABAP @0xluffyb just be you\" => \"eply: @                                 \"\n",
      "batch 5953  loss=133.6572  steps/s=114.91  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y: @           t    ii f    gg i    g  ðŸ›‘\"\n",
      "batch 5954  loss=136.9935  steps/s=109.34  prediction: \"rally will not trample on your free will\" => \"enly:           lllllllllll             \"\n",
      "batch 5955  loss=122.2128  steps/s=101.95  prediction: \"ng sedenions for something in your game?\" => \"   re     n  nn nnnsssooooooo           \"\n",
      "batch 5956  loss=204.4724  steps/s=89.69  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"t.cou/s/////oooooooooo  t tt ttt////   o\"\n",
      "batch 5957  loss=138.3571  steps/s=105.58  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" - gt;ttttttttt ttssssssssssssssssssssss\"\n",
      "batch 5958  loss=129.9187  steps/s=105.00  prediction: \" the ladder on what strats are possible.\" => \"thet                                  ss\"\n",
      "batch 5959  loss=150.8328  steps/s=105.07  prediction: \"e 10000x crazier than anything out there\" => \" iie aaa    00000000          nnnnnnn   \"\n",
      "batch 5960  loss=125.3504  steps/s=105.38  prediction: \"hat \"group photo\" means several entities\" => \"et  tt         t                eeeeeeee\"\n",
      "batch 5961  loss=144.9514  steps/s=104.23  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e  iat         t             ,,,,,,,,,,,\"\n",
      "batch 5962  loss=147.9160  steps/s=100.87  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"n a            n          ttttttttttt///\"\n",
      "batch 5963  loss=136.3425  steps/s=100.29  prediction: \"i know bedrock api has a chat window too\" => \"nkaab          b                        \"\n",
      "batch 5964  loss=149.9806  steps/s=102.87  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e ly: @ddddddddnddddddddddooaaaaiiiiiiir\"\n",
      "batch 5965  loss=137.0712  steps/s=104.66  prediction: \"ead to insanity\n",
      "\n",
      "https://t.co/FLccrhEiEd\" => \" rxolso             \n",
      "\n",
      "\n",
      "\n",
      "tttttttttttt////\"\n",
      "batch 5966  loss=138.0817  steps/s=95.35  prediction: \"ded something to edit gifs/clips quickly\" => \" dtd    eeeeeeeneeeeetttttttiiiii iiiiii\"\n",
      "batch 5967  loss=132.3972  steps/s=101.07  prediction: \" android OS inside of a virtual machine?\" => \"and an         n                        \"\n",
      "batch 5968  loss=143.4788  steps/s=103.04  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \":  saasaaaaasss ssss                    \"\n",
      "batch 5969  loss=138.9479  steps/s=100.83  prediction: \"l do bro, never had a french beer before\" => \"ya @jjd        b                 eeeeeee\"\n",
      "batch 5970  loss=146.6726  steps/s=105.12  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" m(         lll llllll     ttttttttt////\"\n",
      "batch 5971  loss=176.3202  steps/s=101.09  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"lt  @p        AAAAAA   TTT    //////EEEE\"\n",
      "batch 5972  loss=137.5351  steps/s=99.63  prediction: \"imated stills have finally been defeated\" => \"ns AP aaaaaaaa n  ttt   llllll  eeeeeeee\"\n",
      "batch 5974  loss=128.0097  steps/s=20.91  prediction: \"eply: @btwphones Thanks! more on the way\" => \" ly: @aaaaaaa     t    lllllll  eeeeeeee\"\n",
      "batch 5975  loss=137.8527  steps/s=133.43  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"  n  s tt     anaaaaaaaaaaaaaaaaaaaaaall\"\n",
      "batch 5976  loss=141.5066  steps/s=106.13  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"t..ce/t//////tttttttttttttttt///////////\"\n",
      "batch 5977  loss=130.6065  steps/s=102.39  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \"    tt tttttttttooooooooooo             \"\n",
      "batch 5978  loss=114.1715  steps/s=76.20  prediction: \"0nnnpppppppppp hilarious bait, i love it\" => \"077 uptppppppppppppppiiiilsss           \"\n",
      "batch 5979  loss=135.0367  steps/s=105.77  prediction: \"ang out in tunisia every once in a while\" => \"nd ee                                   \"\n",
      "batch 5980  loss=127.5619  steps/s=103.93  prediction: \" games because we trusted each other lol\" => \"aee   memmmmeeeeeeeeeeeeeeeeeeeeeeee    \"\n",
      "batch 5981  loss=131.7145  steps/s=104.53  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"  e  at        t              eeeeeeeeee\"\n",
      "batch 5982  loss=152.6026  steps/s=102.78  prediction: \"r him, thanks! Sounds useful potentially\" => \"ealy:                     uuuuuuuuuuuuu \"\n",
      "batch 5983  loss=128.1272  steps/s=95.47  prediction: \"nes @micsolana same for my history class\" => \" Myr  t hhhho    aasssaaa            lll\"\n",
      "batch 5984  loss=125.2999  steps/s=103.75  prediction: \" front end. i want minimal backend stuff\" => \"to  i          n       nnnnnn   nn      \"\n",
      "batch 5985  loss=130.5551  steps/s=104.05  prediction: \"t immensely and give you new information\" => \"hing  e        n                        \"\n",
      "batch 5986  loss=146.0947  steps/s=91.16  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \"g ce  ieee     l ll       e  aaneeeeeete\"\n",
      "batch 5987  loss=189.4999  steps/s=83.12  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \":eichtci l     s      aaaattaeettttteeww\"\n",
      "batch 5988  loss=154.1199  steps/s=79.38  prediction: \"@startupmillyair https://t.co/c3FxqzjmK3\" => \"lrcpn0Mttlt   l  tttttt///////////t/ewwðŸ›‘\"\n",
      "batch 5989  loss=141.5047  steps/s=113.83  prediction: \"vinwylde the r in rgb stood for retarded\" => \"en nStejiiiieiiw                    rrrr\"\n",
      "batch 5990  loss=136.2110  steps/s=105.26  prediction: \"per curious to see what youre working on\" => \"lrn tsa                                 \"\n",
      "batch 5991  loss=176.1389  steps/s=72.76  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \"hsos r          o   oo ttttt  oooooooonn\"\n",
      "batch 5992  loss=149.2173  steps/s=108.03  prediction: \"? i actually dont know anything abt groq\" => \"\n",
      "?? it????ii                   nnnnnn   \"\n",
      "batch 5993  loss=168.6287  steps/s=99.17  prediction: \"eos Oh I know :) https://t.co/aV1q8nmIEk\" => \" pi: @i                   ::::tt////////\"\n",
      "batch 5994  loss=134.7966  steps/s=101.50  prediction: \"ice didnt know they made it that low, ty\" => \"ne sv c     nnn nn                      \"\n",
      "batch 5995  loss=148.4081  steps/s=104.19  prediction: \"f us have jobs)\n",
      "\n",
      "https://t.co/qTcrhcfjBM\" => \" t  ymo                stttttttttt//////\"\n",
      "batch 5996  loss=135.9290  steps/s=98.09  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  o: ieeeeiiiiee dddddddd  ooooooooooooo\"\n",
      "batch 5997  loss=148.0081  steps/s=100.07  prediction: \"tic strategy\n",
      "Positional chess type stuff\" => \"hoe ioccttttttttttttttttttttssssssssssss\"\n",
      "batch 5998  loss=130.8510  steps/s=104.96  prediction: \" about it and in 1 weekend jumped up 200\" => \"t aea                          eeeeeee  \"\n",
      "batch 5999  loss=141.2842  steps/s=105.14  prediction: \"rong tho, my confidence is only like 70%\" => \"evrt o o  o     o    o  o          n  n \"\n",
      "batch 6001  loss=130.8097  steps/s=105.11  prediction: \"dual input vector or a set of input data\" => \" ag  idiiiiii iiii                      \"\n",
      "batch 6002  loss=144.4338  steps/s=101.67  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"iheel               ttttttttttttttttt///\"\n",
      "batch 6003  loss=174.4738  steps/s=101.68  prediction: \"ng jai??? Instantly 10x more interesting\" => \"   nl8 i       n???????                 \"\n",
      "batch 6004  loss=140.1439  steps/s=104.47  prediction: \"sed\n",
      "\n",
      "Try it asap\n",
      "https://t.co/ZK8YpKEtoP\" => \" lf   o     \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "sttttttttt/////\"\n",
      "batch 6005  loss=161.5764  steps/s=96.14  prediction: \"er CERN/physics bros you know what to do\" => \"  ot  rrrt  tt s sssssssssssooooooo  ooo\"\n",
      "batch 6006  loss=127.6404  steps/s=105.18  prediction: \"hem better bc you can do engine analysis\" => \"a s ct  tttttttt                     nnn\"\n",
      "batch 6007  loss=212.6307  steps/s=91.03  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" s et teeee                 tt  nn/nnnna\"\n",
      "batch 6008  loss=119.7218  steps/s=104.04  prediction: \"he race to steal the eu tech bros begins\" => \"e   a ca          tt   ttte teeeee   eee\"\n",
      "batch 6009  loss=130.4403  steps/s=104.37  prediction: \" regarded so take that w a grain of salt\" => \"te em i                                 \"\n",
      "batch 6010  loss=137.8235  steps/s=104.16  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"tentae   pppppaaaaaaaaaattttttttttt/////\"\n",
      "batch 6012  loss=136.6628  steps/s=100.25  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"one  al                   tttt//////////\"\n",
      "batch 6013  loss=139.9816  steps/s=105.49  prediction: \"mentals can be really really hard to see\" => \"e tamesunnnnnnn nn      aalllllllllll   \"\n",
      "batch 6015  loss=132.2734  steps/s=105.42  prediction: \"can help guide them towards better stuff\" => \"hnthe                            ttttttt\"\n",
      "batch 6016  loss=148.3152  steps/s=97.69  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n a                 ttttttttttttttttt///\"\n",
      "batch 6017  loss=134.4059  steps/s=104.42  prediction: \"ly harder than the last. repeat forever.\" => \" : oL     hhhhhhhhhhhhh            eeeee\"\n",
      "batch 6018  loss=139.2852  steps/s=102.35  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \" ib  t tttttttttoooooooo o  t tt        \"\n",
      "batch 6019  loss=147.2963  steps/s=104.03  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"nc g mmmmmm   ' ''''''''                \"\n",
      "batch 6020  loss=130.3255  steps/s=105.34  prediction: \"10mins on a puzzle just try ur best gues\" => \"  i    nnnnnn                           \"\n",
      "batch 6021  loss=130.2899  steps/s=100.25  prediction: \"engagement-bait generating llm finetunes\" => \"  ae  e eeeeeeemeeeeeeeeeeeeeeegnnnnnnnn\"\n",
      "batch 6022  loss=210.4610  steps/s=11.18  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"e ty: @eeeeeeeeeeeeeeeeeeeeeeegnnnnnnnnn\"\n",
      "batch 6024  loss=131.0792  steps/s=108.27  prediction: \"evelopment speed\n",
      "https://t.co/YNvpK7QsyT\" => \" e t          eeeeeeeeeeeeettttttttt////\"\n",
      "batch 6025  loss=135.2681  steps/s=105.19  prediction: \".. would love to be proven wrong on this\" => \" .h  awww......w                 ooo    \"\n",
      "batch 6026  loss=131.0233  steps/s=101.59  prediction: \"rappers around statistical distributions\" => \"ect : @  rrrrrr rrrrsssssssssssttttttiii\"\n",
      "batch 6027  loss=133.8537  steps/s=103.74  prediction: \"rce on github to figure some of this out\" => \"ehgr           g                        \"\n",
      "batch 6028  loss=137.9962  steps/s=103.52  prediction: \"dless memory related errors (impossible)\" => \" yo oo     m    meee eeererreererrrrrrrr\"\n",
      "batch 6029  loss=131.3861  steps/s=89.34  prediction: \"y_builds i wouldrather shootmyself loool\" => \" \n",
      "iseessbbyy    l e  rrrrrrrr  oossoooll\"\n",
      "batch 6030  loss=132.1405  steps/s=103.73  prediction: \"activation energy as much as possible ig\" => \"noudo r       t tt                  ssss\"\n",
      "batch 6031  loss=128.7798  steps/s=102.93  prediction: \"umps ig\n",
      "\n",
      "all good, just gotta never stop\" => \"roe n          g                        \"\n",
      "batch 6032  loss=143.4598  steps/s=104.29  prediction: \"\" and idk what that is? Time to learn it\" => \" ooo \"\"ss                               \"\n",
      "batch 6033  loss=131.9711  steps/s=104.51  prediction: \"s a natively written zig matmul function\" => \" aa        v  vv      i i    tt  t  t  t\"\n",
      "batch 6034  loss=174.7996  steps/s=99.75  prediction: \"ng jai??? Instantly 10x more interesting\" => \" 8   8 i      ???????                   \"\n",
      "batch 6035  loss=145.8598  steps/s=98.01  prediction: \"Simple p5. Will look into matter though.\" => \" ppi ii        nlllllllllll   tttttttttt\"\n",
      "batch 6036  loss=128.4905  steps/s=105.06  prediction: \"ong term advantage) you consolidate andâ€¦\" => \"    .e         a aaaaaaaaa      oooooooo\"\n",
      "batch 6037  loss=130.1384  steps/s=100.28  prediction: \"term, informative/useful is more memetic\" => \"hr e an            iieeeeeeeeeeeeeemmmmm\"\n",
      "batch 6038  loss=146.6021  steps/s=102.56  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"tae  e           ............/////////ht\"\n",
      "batch 6039  loss=145.2671  steps/s=103.89  prediction: \", or just Jesus? https://t.co/GsoAQ2Ip2z\" => \" ye e               ssssssssssss////////\"\n",
      "batch 6040  loss=138.7528  steps/s=103.62  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" tit                ttttttttttttttt/////\"\n",
      "batch 6042  loss=145.4419  steps/s=66.87  prediction: \"@levelsio @yacineMTB dang stole my reply\" => \"nudin t aaaaiia aaatttttttttt//////jjjjj\"\n",
      "batch 6043  loss=130.7367  steps/s=108.12  prediction: \"ommittal move like going on a sabbatical\" => \"ue e e mmmmmmmmmmm                     a\"\n",
      "batch 6044  loss=129.9337  steps/s=105.07  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"  ag  ttttttttttttttttaaaaaaaahhhhhhhhhh\"\n",
      "batch 6045  loss=139.1390  steps/s=99.35  prediction: \" more cracked by the day, love to see it\" => \"ta t ittttee   ee                       \"\n",
      "batch 6046  loss=133.8570  steps/s=104.89  prediction: \"lay this game\n",
      "\n",
      "happy wheels was gold too\" => \"ys  ln                ppppppppe         \"\n",
      "batch 6047  loss=132.4787  steps/s=105.36  prediction: \"f if time (need to do a lot b4 the 25th)\" => \" w  it  fff    f                        \"\n",
      "batch 6048  loss=136.1427  steps/s=90.20  prediction: \"TB strategy is an abstraction of tactics\" => \"h   i  e   eee t              tttttttttt\"\n",
      "batch 6049  loss=129.3589  steps/s=105.09  prediction: \"w the entire thing works when you use it\" => \"il  en         n                        \"\n",
      "batch 6050  loss=125.2871  steps/s=103.32  prediction: \"rning gpu acceleration is super valuable\" => \"e  in  nnnn    n  aaaaaa                \"\n",
      "batch 6052  loss=137.5344  steps/s=105.27  prediction: \" but vanilla obsidian seems very mid imo\" => \"ter peeuuuuuu l llllll                  \"\n",
      "batch 6053  loss=135.1574  steps/s=103.23  prediction: \"rney to be gigacracked and save your dog\" => \"ey y  o                     aaaaaaaaa   \"\n",
      "batch 6054  loss=152.5890  steps/s=99.12  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tn  n                       ttttttttttt/\"\n",
      "batch 6055  loss=136.2666  steps/s=105.86  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei      iiiiiiiii iiii               aa\"\n",
      "batch 6056  loss=125.8785  steps/s=98.20  prediction: \"eadphones dead gonna recharge real quick\" => \"  i   hhheeeeeeeeeednnnnn aaarrrrrraaree\"\n",
      "batch 6057  loss=132.4440  steps/s=103.17  prediction: \" never rule things out as impossible tbh\" => \"te eteet                          ssssss\"\n",
      "batch 6058  loss=133.8346  steps/s=103.68  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"ne toetgggaaggnannnnnnaaaaaaaaaaa       \"\n",
      "batch 6059  loss=133.6529  steps/s=104.40  prediction: \"o model_interface.send_to_ai(prompt)\n",
      "\n",
      "ez\" => \"ut a            eeeeeeeeeeeee________ooo\"\n",
      "batch 6061  loss=169.0897  steps/s=93.74  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \"  id @eeeeeeeeeeeeeettttttttttttttt/////\"\n",
      "batch 6062  loss=129.9722  steps/s=104.99  prediction: \"et good at the ones youre not so good at\" => \" tuntae        t                 ooooooo\"\n",
      "batch 6064  loss=136.8776  steps/s=101.45  prediction: \"i know bedrock api has a chat window too\" => \"nka            b                        \"\n",
      "batch 6065  loss=135.3888  steps/s=101.75  prediction: \" job adding the australian language pack\" => \"tuk            d      aaaaaaaaaaaaaaaaaa\"\n",
      "batch 6066  loss=124.1566  steps/s=103.67  prediction: \" i was wondering abt yesterday re ceasar\" => \"tt s is                           eeeeee\"\n",
      "batch 6067  loss=147.3941  steps/s=102.62  prediction: \"as irl but the ppl here are way higher x\" => \"n i oo                                  \"\n",
      "batch 6068  loss=140.7509  steps/s=105.56  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" t               ttttttttttttttttttt////\"\n",
      "batch 6069  loss=159.2028  steps/s=101.33  prediction: \"el editor and gameplay, that sounds cool\" => \"  al  l                  aaaaaaaaaaa    \"\n",
      "batch 6071  loss=129.0214  steps/s=105.68  prediction: \"\n",
      "shit like this: https://t.co/Z4JE4KMgHs\" => \"\n",
      "o s  sssssssss ssihhhtttttttttttttt////\"\n",
      "batch 6072  loss=169.1210  steps/s=48.73  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \"  @ce  ss   iiishhttttttttttttt//////444\"\n",
      "batch 6073  loss=141.8621  steps/s=108.86  prediction: \" v. move forward/backward is layer stuff\" => \"tea   ,                rrrrrrrraaaaaaraa\"\n",
      "batch 6074  loss=180.5410  steps/s=106.64  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"nh T ,               tttttttttttt///////\"\n",
      "batch 6075  loss=127.6444  steps/s=104.57  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"euly    rrrreeerettttttttttteeeetttteeee\"\n",
      "batch 6076  loss=133.7938  steps/s=102.88  prediction: \"olve for the entire past week was a typo\" => \"n e e                     eeeeeeee      \"\n",
      "batch 6077  loss=126.5708  steps/s=102.90  prediction: \"assume that had a large effect back then\" => \"ns c           s   aaaaaaaaaa           \"\n",
      "batch 6078  loss=141.2944  steps/s=99.86  prediction: \" this long lost treasure of a song, damn\" => \"tor f          n                        \"\n",
      "batch 6079  loss=129.9062  steps/s=104.40  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"  n aaaaaaaaaaabaaaaaa                  \"\n",
      "batch 6080  loss=125.8431  steps/s=95.53  prediction: \"air they do have the best premove system\" => \"nn atayyyyyy                   eeee eeee\"\n",
      "batch 6082  loss=138.4195  steps/s=103.74  prediction: \"tbh, i like having control over my tools\" => \" aa e t        t                    oooo\"\n",
      "batch 6083  loss=133.7509  steps/s=100.03  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"              eeeeeeeeeeee              \"\n",
      "batch 6085  loss=152.1094  steps/s=102.23  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lo  t eeee  ee                        nn\"\n",
      "batch 6086  loss=128.1113  steps/s=104.78  prediction: \"your post, your app has been declined :(\" => \":urnan         r                        \"\n",
      "batch 6088  loss=130.9107  steps/s=101.62  prediction: \"han automating friction out of your work\" => \"et e   tttttttt tttttttttttttittoooooooo\"\n",
      "batch 6089  loss=133.7463  steps/s=103.53  prediction: \"he pot of gold at the end of the rainbow\" => \"ey  t t        t                        \"\n",
      "batch 6090  loss=139.1720  steps/s=46.55  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \": @ t t                                 \"\n",
      "batch 6091  loss=131.8470  steps/s=106.29  prediction: \"llows you to better descend the gradient\" => \"y s  o l                  eeeeeeeeeeeeee\"\n",
      "batch 6092  loss=138.5592  steps/s=102.40  prediction: \"plex projects in it but it was super fun\" => \"ly: @r   eeeeee                         \"\n",
      "batch 6093  loss=131.6204  steps/s=103.59  prediction: \"plex projects in it but it was super fun\" => \"ly: @r e eeeeee                         \"\n",
      "batch 6094  loss=149.4701  steps/s=100.35  prediction: \"o make rlly complex interactive web apps\" => \" ad a                        eeeeeeeeeee\"\n",
      "batch 6096  loss=130.3777  steps/s=105.08  prediction: \"ntelligence\" + related learning concepts\" => \"de sisoeiiiiiieeeeeeeeeeeeeeeeeeeeennnnn\"\n",
      "batch 6097  loss=126.6625  steps/s=102.73  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"u  b tb ttttttttt               eeeeeeee\"\n",
      "batch 6098  loss=142.6233  steps/s=102.67  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" ie h        tt tttttttttttttttttttt    \"\n",
      "batch 6099  loss=130.8064  steps/s=104.57  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  iei        n                        \"\n",
      "batch 6100  loss=135.5317  steps/s=104.41  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei      iiiiiiiiiiiiiii              aa\"\n",
      "batch 6101  loss=127.4843  steps/s=104.94  prediction: \"g correct (fingers crossed its this one)\" => \" a e eerrrrrrrrrrrrrrrrrrrrrrsssssssssss\"\n",
      "batch 6102  loss=128.8533  steps/s=101.52  prediction: \"s of industry water cooler conversations\" => \" aht  ssssssssss              oooorrrroo\"\n",
      "batch 6103  loss=136.7439  steps/s=105.50  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tadbiatiiitiiii iiiiii                  \"\n",
      "batch 6104  loss=131.2587  steps/s=100.04  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" w  i          l                 sssssss\"\n",
      "batch 6106  loss=154.9816  steps/s=99.15  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"teo  z iiiiiiiiiiiiiiiiissttttt/////////\"\n",
      "batch 6107  loss=141.4405  steps/s=100.03  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"rht  oooooooooonooo               eeeeee\"\n",
      "batch 6108  loss=136.7205  steps/s=103.49  prediction: \" his story you wont regret it, its crazy\" => \"tas sassssssss                          \"\n",
      "batch 6109  loss=130.6265  steps/s=104.82  prediction: \"unny for your runway\n",
      "\n",
      "Idk just a thought\" => \"pd renn        n  rrrrrrrr  uuu         \"\n",
      "batch 6110  loss=235.9490  steps/s=101.22  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"vS  st   EEEEEEEE !!!!!!!!!!!     tttttt\"\n",
      "batch 6111  loss=128.2055  steps/s=103.44  prediction: \"mpeg tho but not if i rely heavily on it\" => \"ele uo                                  \"\n",
      "batch 6112  loss=147.1138  steps/s=104.69  prediction: \"/t.co/zlto3SBYwd https://t.co/joIt9EpsFP\" => \"ta.kltttttttt////ttttttttttt//////////tt\"\n",
      "batch 6113  loss=141.7227  steps/s=104.65  prediction: \"e thing, not just messing around with it\" => \" tiat ttttttttt                         \"\n",
      "batch 6114  loss=132.7964  steps/s=104.00  prediction: \"st flows through. dunno but good thought\" => \" an n         t         uuuuuuuooooooooo\"\n",
      "batch 6115  loss=134.2894  steps/s=103.39  prediction: \"r taxes and splitting with other winners\" => \"eii (          n        tttttttttttttttt\"\n",
      "batch 6116  loss=152.1802  steps/s=104.27  prediction: \"verfit test btw) https://t.co/qErYnoBOJi\" => \"er t  ttttttttttttttttttttttttttt///////\"\n",
      "batch 6117  loss=130.2354  steps/s=103.87  prediction: \" different distribution of training data\" => \"tov  eeeeeeeeeeeeeeetttiiiiiiiiiiiiiiiii\"\n",
      "batch 6119  loss=135.0623  steps/s=103.48  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tsstiiiiiiiiiiiiiiiiiiiiiiiiii          \"\n",
      "batch 6120  loss=132.0481  steps/s=104.12  prediction: \" fundamentals.  Take the time to invest.\" => \"to   t      tt naaaaaaa                 \"\n",
      "batch 6121  loss=152.5476  steps/s=11.22  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"e tns      ttt taaaaaa                  \"\n",
      "batch 6122  loss=191.7576  steps/s=109.82  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y       ataaaaana a at    Tt        e tt\"\n",
      "batch 6124  loss=155.0610  steps/s=80.16  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y     daaaaaaaan  tttt  tttt        essðŸ›‘\"\n",
      "batch 6125  loss=156.8979  steps/s=105.83  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nes ou\n",
      "                NN  tt:://///////\"\n",
      "batch 6126  loss=153.2806  steps/s=86.85  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"en uln  n         tttt  tttt/tto   opppp\"\n",
      "batch 6127  loss=155.7786  steps/s=105.98  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"igd oeu@      AAAABBBBBB                \"\n",
      "batch 6128  loss=127.0890  steps/s=104.67  prediction: \"will exhaust this reward bc its not real\" => \"il    i        t                        \"\n",
      "batch 6129  loss=144.6596  steps/s=102.43  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"iul  t                     tttttttt/////\"\n",
      "batch 6130  loss=128.0221  steps/s=98.02  prediction: \"e ive been thinking the exact same thing\" => \" b ol eeeeeeeeeeee e e tttttttttt    tee\"\n",
      "batch 6131  loss=198.4575  steps/s=99.71  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"tr.ielet/////////ttttttttttt////////////\"\n",
      "batch 6134  loss=140.6713  steps/s=101.97  prediction: \"ems like you have. thanks for sharing it\" => \"   i ie  eeeee eee                      \"\n",
      "batch 6135  loss=150.8127  steps/s=98.95  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl         0000000000             ooooo\"\n",
      "batch 6136  loss=123.1398  steps/s=104.12  prediction: \"you into thinking hes an anime character\" => \" u cti                    nnnnnnn       \"\n",
      "batch 6137  loss=128.7493  steps/s=95.28  prediction: \"tler where would you say you are on this\" => \" yi isotttttt                     aa    \"\n",
      "batch 6138  loss=124.4023  steps/s=101.77  prediction: \"bank account evaporate like a black hole\" => \"en o           t     aaaaaaaaaaaaaaaaaa \"\n",
      "batch 6139  loss=144.6982  steps/s=100.67  prediction: \"dgrammer best languages in your opinion?\" => \" re tyrmmmmmmmmmrrrree ggggg            \"\n",
      "batch 6140  loss=141.3454  steps/s=104.15  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n  y   iiii                 ttttttttt///\"\n",
      "batch 6141  loss=148.0478  steps/s=92.53  prediction: \"tler \"wait.. could nixos fix that, too?\"\" => \" ym is eeeaaaaar          co    tttttttt\"\n",
      "batch 6142  loss=140.7837  steps/s=105.06  prediction: \"on chunking showed higher level playersâ€¦\" => \"uet  s               hhhhhhhhhhhheeeeeee\"\n",
      "batch 6143  loss=141.6759  steps/s=71.49  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ust  osinn      oohhhhhhhheheeeellllllll\"\n",
      "batch 6144  loss=186.6619  steps/s=114.11  prediction: \"____11hz @Collab_Land_ the fuck is this?\" => \"_________________11    enll             \"\n",
      "batch 6145  loss=137.7869  steps/s=104.33  prediction: \" different on your OS. you can google em\" => \"tor tf         f                        \"\n",
      "batch 6146  loss=128.7112  steps/s=101.27  prediction: \"u were in vim, it should start the timer\" => \"tg t           n                    tttt\"\n",
      "batch 6147  loss=122.4104  steps/s=42.37  prediction: \"y: @gizmobly nooooooooo my plans, foiled\" => \": @ie          i   oooo        tt tttttt\"\n",
      "batch 6148  loss=192.4421  steps/s=113.65  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"ts r           oooooooooo     ttt tt eee\"\n",
      "batch 6149  loss=131.8333  steps/s=108.97  prediction: \" like 1hr ago lol\n",
      "\n",
      "also is that your dog\" => \"tei  ii              lllllllll          \"\n",
      "batch 6150  loss=135.6698  steps/s=104.85  prediction: \"efitted from tracking sleep and whatnot?\" => \" ,ey   eeeeeeeete                       \"\n",
      "batch 6152  loss=131.0689  steps/s=105.56  prediction: \"mindset that kills the call to adventure\" => \"eddi  ittttttttttttttttt                \"\n",
      "batch 6153  loss=136.5768  steps/s=105.05  prediction: \")\n",
      "RAG would be very useful for requestsâ€¦\" => \" \n",
      "attcrrr                            eee\"\n",
      "batch 6154  loss=139.9979  steps/s=100.24  prediction: \"nvestor\n",
      "\n",
      "Simpleagreementforfuture Equity\" => \" a ianinnn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "\n",
      "eeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 6156  loss=146.8767  steps/s=98.95  prediction: \"e IRL, its fundamentals all the way down\" => \" tia @aaaassssas  eeennnnaaataalaaaalll \"\n",
      "batch 6158  loss=139.0985  steps/s=103.78  prediction: \"for code writing https://t.co/Vlv7kxKPyM\" => \"ormin                 tttttttttttt//////\"\n",
      "batch 6159  loss=146.5856  steps/s=103.35  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"td m mmmmmm   ' '''''''''               \"\n",
      "batch 6160  loss=167.7855  steps/s=96.61  prediction: \"ode Solidworks\n",
      "$500/yr aint gonna cut it\" => \" e'm eiddddddddodd\n",
      "\n",
      "\n",
      "sssss       nnnnnnn\"\n",
      "batch 6161  loss=133.3181  steps/s=104.90  prediction: \"ite complexity? If not, what is the max?\" => \"n in  iiiiiiiiiniii                     \"\n",
      "batch 6163  loss=128.7164  steps/s=105.21  prediction: \"r the picture\" for any industry or niche\" => \"eito                                r   \"\n",
      "batch 6164  loss=155.8491  steps/s=101.66  prediction: \"igABAP has selo made the circle tool yet\" => \"nh ol giiiii AAlA                       \"\n",
      "batch 6165  loss=132.0970  steps/s=105.65  prediction: \" breadth, right now the latter is bigger\" => \"tere n         r            ttttttt     \"\n",
      "batch 6166  loss=130.3920  steps/s=73.75  prediction: \"justalexoki its tpot, all lowercase only\" => \"ust  ureeeeee  t   ttt t tt             \"\n",
      "batch 6168  loss=133.5772  steps/s=111.88  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"ne aadttgaaagaaaaaaaaaaaaa    a         \"\n",
      "batch 6169  loss=135.1901  steps/s=101.36  prediction: \" for yourself they pay dividends forever\" => \"tooooooooooooo                     ddddd\"\n",
      "batch 6170  loss=130.2164  steps/s=104.67  prediction: \"ncing is just how things go in business.\" => \" he   neeeeiiiin                       s\"\n",
      "batch 6171  loss=127.2435  steps/s=104.55  prediction: \" adding the context into the computation\" => \"tnr t                   tttttttttttttttt\"\n",
      "batch 6172  loss=136.2412  steps/s=104.89  prediction: \"uq?\n",
      "\n",
      "this freaked me out, didnt know ifâ€¦\" => \"r  a   m       aff eeeeeee              \"\n",
      "batch 6173  loss=135.4294  steps/s=84.10  prediction: \"qc Based, a true warrior of the zig army\" => \"uexkmaiqqq  aaae      rr   rrr          \"\n",
      "batch 6175  loss=141.3839  steps/s=23.53  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly:  qq    aaee      rr   r r          \"\n",
      "batch 6176  loss=129.3913  steps/s=110.36  prediction: \"cks things into place, great feeling lol\" => \"oini          itiiii                   l\"\n",
      "batch 6177  loss=134.4290  steps/s=102.93  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"  e ididdddddddddddtttttttttttttttcccccc\"\n",
      "batch 6178  loss=137.8038  steps/s=103.74  prediction: \" super awesome, wait why multiple chats?\" => \"toa ta         s        wwwwww          \"\n",
      "batch 6179  loss=128.4007  steps/s=105.08  prediction: \"the world more, become more dysfnctional\" => \"hin   n        t        eeeeeeeeeeeeeeeo\"\n",
      "batch 6181  loss=164.0228  steps/s=100.14  prediction: \"2 and a monkey pfp too.. this is bananas\" => \"0g   o                                  \"\n",
      "batch 6182  loss=121.2175  steps/s=99.89  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"ter                           sssss s  a\"\n",
      "batch 6183  loss=131.0164  steps/s=96.98  prediction: \"ki my highschool teacher taught it to me\" => \"en o           ohhhhhhhooh  a aa a      \"\n",
      "batch 6184  loss=245.4386  steps/s=89.05  prediction: \"/t.co/NlzdO0Z2DA https://t.co/qGWUkC7cdS\" => \"t..ooht//////ooco  hhhhhttttttttt///tt  \"\n",
      "batch 6185  loss=137.4043  steps/s=105.19  prediction: \"e waves stopped\n",
      "\n",
      "https://t.co/FO1wQxoZRU\" => \" cshee  e    eeeepppppppppppttt/////////\"\n",
      "batch 6186  loss=129.6166  steps/s=99.35  prediction: \"t in a position to help you at all loool\" => \"hm             n           oo           \"\n",
      "batch 6187  loss=129.1868  steps/s=102.42  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yn                       uuuuuuuuuuuuuuu\"\n",
      "batch 6188  loss=162.8702  steps/s=103.50  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"tr.oohot///////ttttttttttttt///////////t\"\n",
      "batch 6189  loss=132.3487  steps/s=103.87  prediction: \"just have to connect/reconnect the wifi'\" => \"ust t                   ooonnnnnnnnneeee\"\n",
      "batch 6190  loss=130.6341  steps/s=104.60  prediction: \"your life (which is what happened to me)\" => \"our r y                       hhhhh     \"\n",
      "batch 6191  loss=139.8807  steps/s=105.16  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"np (  rsss        ttttttttttttttttttttt/\"\n",
      "batch 6192  loss=141.1664  steps/s=99.69  prediction: \" cs maps btw? would love to see pictures\" => \"to             w                        \"\n",
      "batch 6193  loss=197.0456  steps/s=104.20  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \"uGyr    OOOOOOI IIIINNNN     e eeeeeeess\"\n",
      "batch 6194  loss=157.0345  steps/s=100.77  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \"tla e               hhhhhttttttttttt////\"\n",
      "batch 6195  loss=131.9441  steps/s=98.99  prediction: \"n just do things https://t.co/909bTHzmml\" => \" l o e              ttttttttt/////////99\"\n",
      "batch 6196  loss=141.9308  steps/s=103.25  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"eyof         eeeeeeeee???????ttttt//////\"\n",
      "batch 6197  loss=138.2461  steps/s=96.41  prediction: \"y based. how do you compile zig to wasm?\" => \":gr ro   e              o  oo oopppp    \"\n",
      "batch 6198  loss=126.5937  steps/s=99.68  prediction: \"ki my highschool teacher taught it to me\" => \"ena js         hhhhhohhoooo     tt    tt\"\n",
      "batch 6199  loss=135.6322  steps/s=97.79  prediction: \"ath dependence can be used strategically\" => \"n xo h     h  c eeeeeeeeeeee       ttttt\"\n",
      "batch 6200  loss=126.2288  steps/s=104.14  prediction: \"you can get a stronger 'muscle' for this\" => \":u hooh                                 \"\n",
      "batch 6201  loss=131.3338  steps/s=97.24  prediction: \"s9 and of course, its subscription based\" => \" int                    ssssssssss srrs \"\n",
      "batch 6202  loss=130.9505  steps/s=105.82  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \":i  o                                   \"\n",
      "batch 6203  loss=195.6864  steps/s=79.22  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" ee t  uu   g        tttttttt      mmmmm\"\n",
      "batch 6204  loss=145.2100  steps/s=109.69  prediction: \"@arthur_d3nt cool shit\n",
      "cuda interop too?\" => \"yndiolAa@@arrrttttttttttt  oooott oo   t\"\n",
      "batch 6205  loss=130.5956  steps/s=59.34  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tma  aaaartttttt   h                 ooo\"\n",
      "batch 6206  loss=171.0866  steps/s=62.07  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"h  e raaartttthl                      oðŸ›‘\"\n",
      "batch 6207  loss=136.9885  steps/s=109.65  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"nty le                                  \"\n",
      "batch 6209  loss=161.5082  steps/s=96.56  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"se y   i       b   to   atttthtttt/////c\"\n",
      "batch 6210  loss=158.2530  steps/s=105.80  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"t.\n",
      "oo//////////ttttttttttttt////////////\"\n",
      "batch 6211  loss=149.1472  steps/s=98.21  prediction: \" bet, im down, whats a good time for you\" => \"tees tttttttt     www  w  wo     oo   oo\"\n",
      "batch 6212  loss=147.8680  steps/s=105.40  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"d as  i                                 \"\n",
      "batch 6213  loss=145.6570  steps/s=104.09  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" es  e         n      ttttttttttttttttt/\"\n",
      "batch 6214  loss=139.7381  steps/s=103.94  prediction: \" to animate a NN https://t.co/JdnKMowlAa\" => \"toetettttttttttaa          tttttttt/////\"\n",
      "batch 6216  loss=143.6555  steps/s=99.79  prediction: \" process does feel good when err go down\" => \"tanenneeeeeeeeese eeeee  ee  ee    e    \"\n",
      "batch 6217  loss=133.5589  steps/s=106.39  prediction: \"tle robots\n",
      "\n",
      "they remove so much friction\" => \" ep te           ttt toeeeeeee          \"\n",
      "batch 6218  loss=148.2776  steps/s=104.08  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"te eee eeeeeeeele                       \"\n",
      "batch 6220  loss=168.5253  steps/s=86.42  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"hie  pe       o             ccc ccc  ooo\"\n",
      "batch 6221  loss=148.9183  steps/s=105.29  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \"hneri lllllllll lllll1111100000?????????\"\n",
      "batch 6222  loss=130.2751  steps/s=99.92  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"@n  liiiii                    eeeeeeeeee\"\n",
      "batch 6223  loss=153.9915  steps/s=105.29  prediction: \" filter out slop https://t.co/RA1wtAYLES\" => \"too ffffffff          tttttttttttttttttt\"\n",
      "batch 6224  loss=136.2012  steps/s=101.40  prediction: \"i know bedrock api has a chat window too\" => \"nl a           b                        \"\n",
      "batch 6225  loss=153.1642  steps/s=103.06  prediction: \"output less verbose/convoluted solutions\" => \"n siistttu ttt    ees eeeoooeeoooeeoesoo\"\n",
      "batch 6226  loss=136.4701  steps/s=105.14  prediction: \"e increased space the model has to think\" => \" ao t   eeeeeeeeeeeeeeeeeeeeee          \"\n",
      "batch 6227  loss=130.5107  steps/s=100.19  prediction: \" quarter is another kinda similar banger\" => \"tue ee                          iiiiiiii\"\n",
      "batch 6228  loss=125.0334  steps/s=97.44  prediction: \"air they do have the best premove system\" => \"nn  oerriii                    eeee eeee\"\n",
      "batch 6229  loss=136.4454  steps/s=103.84  prediction: \"t am article to help ppl understand theâ€¦\" => \" meuet         t                        \"\n",
      "batch 6231  loss=147.9788  steps/s=104.05  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"  e  ep    3                            \"\n",
      "batch 6232  loss=139.0543  steps/s=102.13  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"ya @roiiiiiirrrr                        \"\n",
      "batch 6233  loss=138.3743  steps/s=103.31  prediction: \"e, i would also have liked to be yacine\"\" => \"  t                                     \"\n",
      "batch 6234  loss=139.3403  steps/s=100.92  prediction: \"free could help too if thats the problem\" => \" iecoPuuuuuu   l                        \"\n",
      "batch 6235  loss=125.1202  steps/s=64.36  prediction: \"@Aryvyo use the api\n",
      "anthropic or bedrock\" => \"lcsbnoe        l          tttht        e\"\n",
      "batch 6236  loss=132.9100  steps/s=106.10  prediction: \"e, i would also have liked to be yacine\"\" => \"  y                                     \"\n",
      "batch 6237  loss=140.2574  steps/s=100.84  prediction: \"tbh, about 1/3rd of the way through them\" => \" s er ttttttttt                      h h\"\n",
      "batch 6238  loss=139.0065  steps/s=99.25  prediction: \"od simclusters chosen principle engineer\" => \"n he              ssssssssssssssceeeeeee\"\n",
      "batch 6239  loss=145.4907  steps/s=11.59  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eply: @          ssssssssssssssseeeeeeee\"\n",
      "batch 6240  loss=131.8996  steps/s=118.33  prediction: \"ns\n",
      "you me and andrew, that was super fun\" => \" t  sessssssso                          \"\n",
      "batch 6241  loss=132.1300  steps/s=101.02  prediction: \" got chicken bone broth from walmart lol\" => \"@oo                          oo         \"\n",
      "batch 6242  loss=135.6413  steps/s=104.89  prediction: \"our phone constantly. i had this problem\" => \"nle          oonoonnnnn  n              \"\n",
      "batch 6244  loss=125.4664  steps/s=97.03  prediction: \"eadphones dead gonna recharge real quick\" => \" k h  heeeeeeeeeeeennn  n   aaa  rrrrrrr\"\n",
      "batch 6246  loss=126.2415  steps/s=101.18  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"n o          oo  oooooooooooh      sssss\"\n",
      "batch 6247  loss=142.8218  steps/s=103.03  prediction: \"would be insanely useful to do this with\" => \" rone  u  oo   eee leeee    ul          \"\n",
      "batch 6248  loss=140.4501  steps/s=102.09  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"hneo   aaa   aac ae      oo    uuuu oooo\"\n",
      "batch 6249  loss=142.4744  steps/s=103.63  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" tso          t  tttttttttttttttttt/////\"\n",
      "batch 6250  loss=147.9171  steps/s=102.30  prediction: \"igure out how to improve your work ethic\" => \"nA  s          t    o  oooooooo oooo oo \"\n",
      "batch 6251  loss=164.7908  steps/s=58.31  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"tH us _________     oo o ooo  oo        \"\n",
      "batch 6252  loss=130.4623  steps/s=108.98  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" t ereeeeeeeeeenm nnnnnnn        ttttttt\"\n",
      "batch 6253  loss=147.6725  steps/s=104.21  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"@ae i m                      o  o     o \"\n",
      "batch 6254  loss=124.8440  steps/s=104.73  prediction: \"vision how great itll be once youre done\" => \"e   e                                   \"\n",
      "batch 6255  loss=130.4202  steps/s=104.36  prediction: \" to use. code is linked in another reply\" => \"toe  se     se ee   ee    e ii     ee ee\"\n",
      "batch 6256  loss=138.0529  steps/s=104.24  prediction: \"t learning from the things theyre doing.\" => \"hteenee        n                        \"\n",
      "batch 6257  loss=140.6164  steps/s=104.74  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n ,                      ttttt//////////\"\n",
      "batch 6258  loss=137.0598  steps/s=87.49  prediction: \"upmillyair microsoft is a faulty company\" => \"se t  ttta  iiil  tttoootttotttt    aooo\"\n",
      "batch 6259  loss=128.7178  steps/s=104.19  prediction: \"ppl who got rich playing 0 sum games tho\" => \"les  i                                  \"\n",
      "batch 6260  loss=144.8106  steps/s=98.17  prediction: \"h mines a $10 quintillion metal asteroid\" => \"e@ tttttt             iiiiiiiiiiiilllllt\"\n",
      "batch 6261  loss=129.1680  steps/s=104.30  prediction: \" sum bros.. pivot, its worth it trust me\" => \"teus  e       .r..                tttttt\"\n",
      "batch 6262  loss=172.1933  steps/s=102.88  prediction: \"on every monday and thursday of the week\" => \"u  o sn      n n   nnnn    ddddd        \"\n",
      "batch 6263  loss=142.9624  steps/s=69.71  prediction: \"yacineMTB Its addicting stuff be careful\" => \":c ceen   nn     dddddddddd          eee\"\n",
      "batch 6264  loss=126.4876  steps/s=106.69  prediction: \"d hire my friends to do research with me\" => \" o  o                                   \"\n",
      "batch 6265  loss=136.5639  steps/s=104.79  prediction: \"r 100x more productive, get good with it\" => \"esou    000000                          \"\n",
      "batch 6266  loss=150.7898  steps/s=100.33  prediction: \" thought they became ugly when they fell\" => \"the  dddd   hhh h                   eeee\"\n",
      "batch 6267  loss=133.9500  steps/s=105.04  prediction: \" you have a podcast on in the bg or smth\" => \"tous                                    \"\n",
      "batch 6268  loss=137.0031  steps/s=104.53  prediction: \"\n",
      "Learning is the precursor to succeeding\" => \"\n",
      "oeurheVO6O22OO(OOOOOOOOO4OOOTNNL?2?NN?0\"\n",
      "batch 6269  loss=149.3490  steps/s=98.44  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \" e  rieii  ssssssssttttttttttttttt//////\"\n",
      "batch 6270  loss=132.4489  steps/s=104.28  prediction: \"he gamer would make for some great games\" => \"e  e d                                  \"\n",
      "batch 6271  loss=145.6831  steps/s=104.48  prediction: \"tputs timestamps of ads =&gt; remove ads\" => \"hseseeettttttttttttttssss ts            \"\n",
      "batch 6272  loss=133.0691  steps/s=104.82  prediction: \"cially long term stuff,  makes it harder\" => \"hnoe e                                  \"\n",
      "batch 6273  loss=136.6049  steps/s=105.53  prediction: \"the model well except for precisely howâ€¦\" => \"he  tar      eedeeeeeeeeeeeeeeeeeeeeeee \"\n",
      "batch 6274  loss=143.3056  steps/s=102.75  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \" r e   ttttttttttttt    eeeeee          \"\n",
      "batch 6275  loss=146.3447  steps/s=103.95  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"teaeee eeeeeeeele                       \"\n",
      "batch 6276  loss=173.4389  steps/s=104.35  prediction: \"ful to me, like use every day type stuff\" => \" c )  l        l      eeeee  eeee yyyyyy\"\n",
      "batch 6277  loss=133.1611  steps/s=103.27  prediction: \"he thing, no? All you need is prediction\" => \"e     t                                 \"\n",
      "batch 6278  loss=145.7346  steps/s=104.69  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u aoio                        0000     \"\n",
      "batch 6279  loss=139.8375  steps/s=95.90  prediction: \"s I love zig\n",
      "Are you doing the ziglings?\" => \" mo  no                              iig\"\n",
      "batch 6280  loss=131.4243  steps/s=85.18  prediction: \" thanks man! i should uh sleep more yeah\" => \"th   aaaaaaaa                        eee\"\n",
      "batch 6281  loss=131.8135  steps/s=105.43  prediction: \"ling down on stuff I initially dismissed\" => \"yt i  m    o oon               iiiiiiiii\"\n",
      "batch 6282  loss=135.0645  steps/s=103.97  prediction: \"ite complexity? If not, what is the max?\" => \"n in  iiiiiiiiinii                      \"\n",
      "batch 6283  loss=125.0814  steps/s=98.71  prediction: \"elete post but it works on anyone's post\" => \" fte  teeeeeeeett tttt               oo \"\n",
      "batch 6284  loss=123.4584  steps/s=101.36  prediction: \"y noticed the last time i was there, lol\" => \":azzaiiiiiiiiieneetttttttt              \"\n",
      "batch 6285  loss=138.0997  steps/s=103.52  prediction: \"amount of time, or did you just enjoy it\" => \"np r           n                        \"\n",
      "batch 6286  loss=133.3539  steps/s=104.70  prediction: \"fficulty level, progressive overload etc\" => \" i  ls         lllllllllleeeeevvvvvvveee\"\n",
      "batch 6287  loss=126.5471  steps/s=45.22  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  @s uf t  elll lell  eeseeeveeveeeeeeee\"\n",
      "batch 6288  loss=137.6040  steps/s=113.68  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"sd nis         n          ee     nn-----\"\n",
      "batch 6289  loss=158.2844  steps/s=105.20  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"re x   x                \n",
      "\n",
      "\n",
      "\n",
      "//////////11\"\n",
      "batch 6290  loss=153.5417  steps/s=103.66  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"ge d onnnnnnn((e)                       \"\n",
      "batch 6291  loss=136.5185  steps/s=106.33  prediction: \"ession youll do something until its done\" => \"   et eeeeeeee sooooooooooooo           \"\n",
      "batch 6292  loss=174.3065  steps/s=86.17  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \" i er eoooo  oos   ohhhhhhtttttittttt   \"\n",
      "batch 6293  loss=133.3459  steps/s=66.83  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"tloe  eoooo      oottttttttttt/////   eðŸ›‘\"\n",
      "batch 6294  loss=132.7767  steps/s=108.94  prediction: \"r tweet was epictetus's two handles idea\" => \"ealy: @        eeeeeeeeeetttttttttttssss\"\n",
      "batch 6295  loss=144.7683  steps/s=105.53  prediction: \"h's run are: samplesize=64, epochs=100,â€¦\" => \"e g h                   seeeeeeeeeeee===\"\n",
      "batch 6296  loss=136.5700  steps/s=105.54  prediction: \"r these very cool words. well said, dang\" => \"ea ee t  ee  eer   oe   oo   oo     o   \"\n",
      "batch 6297  loss=148.5160  steps/s=100.13  prediction: \"eglide theyre patronizing.\n",
      "trash company\" => \" \n",
      " r @ eeeeeeeereeeeeeeeeeerrrrriiiiannn\"\n",
      "batch 6298  loss=138.6764  steps/s=102.29  prediction: \"een enough to find mentorable candidates\" => \" d e           n                nnnnnnan\"\n",
      "batch 6299  loss=143.6855  steps/s=102.61  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" ia  a         d      tttttttttttttt////\"\n",
      "batch 6300  loss=137.3036  steps/s=105.34  prediction: \" movie theater anywhere\n",
      "\n",
      "or a giant dome\" => \"tor  aaaaaaaa  tatt aaeeeeeeeeeeeee     \"\n",
      "batch 6301  loss=148.5344  steps/s=85.65  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" o t aauuueeeeeaee   eeee   oo\n",
      "\n",
      "\n",
      "\n",
      "  oooo\"\n",
      "batch 6302  loss=146.4545  steps/s=106.48  prediction: \"erous people, very sad, but also fixable\" => \"  ie s        e eeeeeeee                \"\n",
      "batch 6303  loss=137.5124  steps/s=21.13  prediction: \"eply: @ludwigsonneck Did you learn/grow?\" => \" ly: s     e  eeeeeeeee                 \"\n",
      "batch 6304  loss=139.8568  steps/s=109.78  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"ndae edaaaaaaaaaaaaaaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 6305  loss=144.6176  steps/s=103.24  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nsaaa annnaammm mmmmmmmmmmm m           \"\n",
      "batch 6306  loss=154.3255  steps/s=94.23  prediction: \"MTB be less dim =&gt; be less dim\n",
      "Genius\" => \"TB canimi      m e                    ee\"\n",
      "batch 6307  loss=175.2987  steps/s=104.84  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" t K8cccccccccLLLLLe teeeeetttte///tt///\"\n",
      "batch 6309  loss=149.8551  steps/s=99.70  prediction: \"mobile works now https://t.co/vI0ds7feVt\" => \"avt  o or  ooooooo    o     t/t/////////\"\n",
      "batch 6310  loss=139.8375  steps/s=99.02  prediction: \"bootloader fast and frictionless is king\" => \"eutooooooooooooboott    t       tsssssss\"\n",
      "batch 6311  loss=165.2249  steps/s=30.64  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"  s / ooooooooob  tt            ssssssii\"\n",
      "batch 6312  loss=129.3093  steps/s=132.64  prediction: \" they secretly exercise and dont tell us\" => \"toeblb ee   seeteeeeeeeeeeeeee          \"\n",
      "batch 6314  loss=157.4636  steps/s=77.09  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"ys @l lleeeeeeeeeeeeeeeeeet      tee  Y \"\n",
      "batch 6315  loss=127.2463  steps/s=106.46  prediction: \"nse and you can't efficiently work withâ€¦\" => \" e             n           nn           \"\n",
      "batch 6316  loss=133.7397  steps/s=98.38  prediction: \"od simclusters chosen principle engineer\" => \"uie              ssssssssssssssseeeeeeee\"\n",
      "batch 6317  loss=130.2510  steps/s=103.87  prediction: \"he thing, no? All you need is prediction\" => \"e g t t                                 \"\n",
      "batch 6318  loss=140.2430  steps/s=100.32  prediction: \"to play chess sometime, my li is dnbt777\" => \"h t  i                s     s         i \"\n",
      "batch 6319  loss=223.8661  steps/s=75.25  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"lxpwhe           s   ee      OOOOOOOOOOO\"\n",
      "batch 6320  loss=134.7800  steps/s=106.28  prediction: \"mands it outputs\n",
      "https://t.co/dWiO4erSb1\" => \"andt            tttttttttttttttttttttttt\"\n",
      "batch 6321  loss=144.1302  steps/s=99.25  prediction: \" them for yourself initially? im curious\" => \"th m                           iiiiiiiii\"\n",
      "batch 6322  loss=143.8996  steps/s=102.51  prediction: \"my camera by accident so maybe thats why\" => \"a e   i   ee        aa      a a        a\"\n",
      "batch 6323  loss=131.2202  steps/s=83.93  prediction: \"hniacus specialized chips are the future\" => \"et   mee    aacccccccii                 \"\n",
      "batch 6324  loss=129.2190  steps/s=104.17  prediction: \"dual input vector or a set of input data\" => \" mi  i iiiiiiiini                       \"\n",
      "batch 6325  loss=130.6379  steps/s=103.91  prediction: \" way you perceive the world and yourself\" => \"taet t                 eeeeeee          \"\n",
      "batch 6326  loss=147.7721  steps/s=101.89  prediction: \"file llm editing stuff is the future imo\" => \" l tto lllleellilllliiiiiiiit if  ft    \"\n",
      "batch 6327  loss=141.6335  steps/s=97.18  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"irt e                         o       oo\"\n",
      "batch 6330  loss=131.5916  steps/s=99.57  prediction: \"the beta (should be around the 25th)\n",
      ": D\" => \"he le          e                        \"\n",
      "batch 6331  loss=128.6237  steps/s=103.91  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" r aaa        a aaaaaaaaa ssssstttttt///\"\n",
      "batch 6332  loss=143.3148  steps/s=103.00  prediction: \" learning how things work under the hood\" => \"tore aar  rn       nn  nn     nn   nn   \"\n",
      "batch 6333  loss=132.0455  steps/s=103.89  prediction: \"ust store those. skip the whole ML stuff\" => \"ttut  ss          ss                    \"\n",
      "batch 6334  loss=142.5926  steps/s=93.77  prediction: \"ex Only if you get a lobotomy afterwards\" => \" a t  te                   oooooooo tt f\"\n",
      "batch 6335  loss=150.0218  steps/s=99.42  prediction: \"ere @jesx64 never stop having fun either\" => \"   n @Seeeeeee  eee      ooo          f \"\n",
      "batch 6338  loss=159.0879  steps/s=104.61  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" ane u                                  \"\n",
      "batch 6340  loss=140.3989  steps/s=104.53  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"ecti ag             tttttttttttttt//////\"\n",
      "batch 6341  loss=133.2773  steps/s=103.27  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot i                        tttttt/////\"\n",
      "batch 6342  loss=147.1325  steps/s=103.07  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"e   i    e eeeeleeeeee                  \"\n",
      "batch 6343  loss=153.9923  steps/s=59.96  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tle   llueeeeeeeeeee                   l\"\n",
      "batch 6344  loss=128.5800  steps/s=119.69  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \"  id @eeeeeeeeeseeerrrrrnnnnn      ttttt\"\n",
      "batch 6345  loss=148.7604  steps/s=102.30  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame                                    \"\n",
      "batch 6347  loss=146.6551  steps/s=103.38  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"nd e                   tttttttttttt/////\"\n",
      "batch 6348  loss=126.9548  steps/s=25.79  prediction: \"eply: @BuxdahMo its not the real discord\" => \" ly:           y     tttttttttttt///////\"\n",
      "batch 6349  loss=129.9829  steps/s=106.74  prediction: \"ecurity bots monitoring my whole network\" => \" iao              ooooooooooooooo       \"\n",
      "batch 6350  loss=147.7592  steps/s=102.76  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"aoo oolooolllllelll                    h\"\n",
      "batch 6351  loss=140.9433  steps/s=103.28  prediction: \"now unless i need to paste in huge files\" => \" t oo   ss  ss s  s                   ee\"\n",
      "batch 6352  loss=166.6663  steps/s=103.48  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t..oottt////t//99999tttttp///ttt////t///\"\n",
      "batch 6353  loss=153.4878  steps/s=65.21  prediction: \"@levelsio @yacineMTB dang stole my reply\" => \"lewinett/ttt9t9ppttpttt/t//t//tt/tttttts\"\n",
      "batch 6354  loss=143.2191  steps/s=115.13  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"d    iii      c          ttttt//tt//////\"\n",
      "batch 6355  loss=137.9683  steps/s=102.62  prediction: \"ide stuff on top of normal operations ig\" => \"ne u d                o  ooooooooooooooo\"\n",
      "batch 6357  loss=185.3440  steps/s=96.41  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"tLd          OOOOOO!!!!!!        an     \"\n",
      "batch 6358  loss=162.7666  steps/s=101.27  prediction: \" To Learn (LHTL)\n",
      "https://t.co/zMGdAcfDpd\" => \"aha no       LLLLLLLLLLTTT     tttt/////\"\n",
      "batch 6360  loss=135.0693  steps/s=96.75  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n  o              tttttttttt///////////p\"\n",
      "batch 6361  loss=165.6411  steps/s=98.24  prediction: \"er CERN/physics bros you know what to do\" => \"  tr @rttttttttthhssssssssssoooooooooooo\"\n",
      "batch 6362  loss=140.4828  steps/s=104.96  prediction: \"ts one of the fundamentals of everything\" => \"  it n                          eeeeeeee\"\n",
      "batch 6363  loss=144.9546  steps/s=105.54  prediction: \"re advanced in the art of shape rotating\" => \"eply: @                                 \"\n",
      "batch 6364  loss=133.4861  steps/s=105.54  prediction: \"n an addiction\n",
      "Really curious what it is\" => \" ma  e aaaaaaaa annnnnnnniiiiiiii       \"\n",
      "batch 6365  loss=157.9631  steps/s=106.00  prediction: \"t to follow btw\n",
      "\n",
      "https://t.co/HtQ8VvN4bY\" => \"hso o  tt   ooooooottttttttttttttttttttt\"\n",
      "batch 6366  loss=147.9251  steps/s=102.15  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \" t r ceeeeeeeeeeeee         ttt/////////\"\n",
      "batch 6367  loss=161.1882  steps/s=101.55  prediction: \" the 16 hour coding session, lets get it\" => \"@hint  7                         ssssss \"\n",
      "batch 6368  loss=127.2537  steps/s=105.06  prediction: \"nse and you can't efficiently work withâ€¦\" => \" t             n           nn           \"\n",
      "batch 6369  loss=137.1338  steps/s=46.53  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \"  @ae                   neen            \"\n",
      "batch 6370  loss=159.7408  steps/s=123.53  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" B   t lPPuu   ssssssseeetee  ooo       \"\n",
      "batch 6371  loss=138.3556  steps/s=104.43  prediction: \"layer type stuff, but going even further\" => \"yr  moxe  re    ee                    ef\"\n",
      "batch 6372  loss=138.6470  steps/s=104.02  prediction: \"ich is a suuuuper good thing to practice\" => \"n  oo          s uuuuuuuuuu             \"\n",
      "batch 6373  loss=130.7197  steps/s=105.09  prediction: \"ume instead of a flat surface of a wafer\" => \"t   o                      aaaffffffffff\"\n",
      "batch 6374  loss=145.6256  steps/s=100.52  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"etny: @o           ttstttttttttttttttttt\"\n",
      "batch 6375  loss=134.0073  steps/s=105.92  prediction: \"code base to get something super complex\" => \"on q te        e                        \"\n",
      "batch 6376  loss=138.1104  steps/s=104.52  prediction: \"e, and i know i need to get back into it\" => \"    e                                   \"\n",
      "batch 6377  loss=161.7311  steps/s=103.49  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"tene                          ttttt/////\"\n",
      "batch 6378  loss=136.3884  steps/s=101.34  prediction: \"f time and space that can reach in here?\" => \" t  io         t         aaaaaaaaa      \"\n",
      "batch 6379  loss=140.9740  steps/s=103.05  prediction: \" end of the task off worked for you too?\" => \"txdtieeetee                  ffff    ooo\"\n",
      "batch 6380  loss=150.6289  steps/s=100.83  prediction: \"r easy setup btw\n",
      "https://t.co/dWiO4erSb1\" => \"eply: @s ssesssessstttpptttttttttt//////\"\n",
      "batch 6381  loss=186.2222  steps/s=104.13  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"  64ohtt//\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ss\n",
      "\n",
      "sts/////////t\"\n",
      "batch 6382  loss=158.4019  steps/s=68.77  prediction: \"rrawnyy cool ass wasm cube bro\n",
      "\n",
      "followed\" => \"eily: @\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ooo\n",
      "osssssssssst/////oo/o\n",
      "oo\"\n",
      "batch 6383  loss=141.1807  steps/s=105.50  prediction: \" ppl twist your arm behind your back lol\" => \"trtet  tttttt  t                        \"\n",
      "batch 6384  loss=139.0913  steps/s=105.34  prediction: \"dless memory related errors (impossible)\" => \" io to     mmmm eeeeeeeeeerrrrrrrrrrrrrs\"\n",
      "batch 6385  loss=146.2609  steps/s=73.21  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yn @lrssssssseeleeeeeeeerrrrrr          \"\n",
      "batch 6386  loss=149.4948  steps/s=107.72  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" C/            d           sssssss      \"\n",
      "batch 6387  loss=140.9407  steps/s=65.35  prediction: \"@yacineMTB You want us to find our moms?\" => \"Harlny\n",
      "aaiie     a      ssss            \"\n",
      "batch 6388  loss=156.7021  steps/s=113.23  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \" r    _ettttt  n                        \"\n",
      "batch 6389  loss=138.5981  steps/s=104.82  prediction: \" cliff in one go. like, good luck w that\" => \"to             f                        \"\n",
      "batch 6390  loss=131.1086  steps/s=104.67  prediction: \"his is the same w similar things in life\" => \"ene  t iiiiii  ssss       ss     i  ii  \"\n",
      "batch 6391  loss=159.0643  steps/s=102.98  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yk   1                 eeeeeeeeeeee ooee\"\n",
      "batch 6392  loss=132.2317  steps/s=104.38  prediction: \"ntelligence\" + related learning concepts\" => \" e si oeiiieeeeeeeeeeeeeeeeeeeeeeeennnnn\"\n",
      "batch 6393  loss=129.5866  steps/s=52.95  prediction: \": @sunsettler SAP is gonna go hella hard\" => \" @srmsosneeeeeeeeeeee eeeeenne   nnnnnnn\"\n",
      "batch 6394  loss=131.4348  steps/s=119.07  prediction: \"the man stretches his mind and his limbs\" => \"he   snx  n    n                        \"\n",
      "batch 6395  loss=133.7497  steps/s=104.76  prediction: \"than \"heres a tool to solve problem xyz\"\" => \"hon  ihhhhhhh  r                 ooooooo\"\n",
      "batch 6397  loss=130.9870  steps/s=29.64  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly: tihhhh                    oooo ooolo\"\n",
      "batch 6398  loss=112.4948  steps/s=114.80  prediction: \" --. .. ...- . / -.-- --- ..- / ..- .--.\" => \"t-t..  ............--------------    ...\"\n",
      "batch 6399  loss=137.9978  steps/s=105.05  prediction: \", thank God we can function at all loool\" => \" ieeee                                  \"\n",
      "batch 6400  loss=136.8452  steps/s=104.78  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eoa          neeeee   eeeeeeee        \"\n",
      "batch 6401  loss=131.1971  steps/s=104.38  prediction: \"oud to yourself, or in your imagination)\" => \"  t to oooooooooooooo                  i\"\n",
      "batch 6402  loss=138.6771  steps/s=105.19  prediction: \"er? What does that corner look like? Etc\" => \"  ot in                                 \"\n",
      "batch 6403  loss=136.6034  steps/s=105.43  prediction: \"but for now ill run whatever ppl ask for\" => \"et   u         n                        \"\n",
      "batch 6404  loss=133.7316  steps/s=101.52  prediction: \"eaply making synthetic training data? :)\" => \" t   @         n    n      tnnnnniiiiiia\"\n",
      "batch 6405  loss=139.3397  steps/s=100.47  prediction: \"uper loudly but yea. it helps w thinking\" => \"  lnp p        u                        \"\n",
      "batch 6406  loss=125.9386  steps/s=97.56  prediction: \" was truly L tier. not L tier but L tier\" => \"th  r0  r                               \"\n",
      "batch 6407  loss=128.9329  steps/s=97.22  prediction: \"dness there are some juicy tactics there\" => \"  o s   o      reeeeeeeee ee        tttt\"\n",
      "batch 6408  loss=126.3179  steps/s=97.68  prediction: \"oulda made stock cert flags instead, rip\" => \" nos   aaa aaa               ct    sss  \"\n",
      "batch 6409  loss=125.5945  steps/s=98.55  prediction: \"an wrong something something bla bla bla\" => \"n  in m        m         mgggggggg     b\"\n",
      "batch 6410  loss=144.7215  steps/s=87.14  prediction: \"wigABAP a friendly virus. one that talks\" => \"hgh  wr             nnnnn n           aa\"\n",
      "batch 6411  loss=139.8161  steps/s=105.93  prediction: \"k in college it worked for me super well\" => \" itu           l                      ee\"\n",
      "batch 6412  loss=153.4398  steps/s=100.56  prediction: \"e77 build things people want/ need maybe\" => \" 8o c@ciiiiiiiiiiiiii           eeeeeeee\"\n",
      "batch 6413  loss=145.4770  steps/s=105.24  prediction: \"ive and do the bare minimum you may getâ€¦\" => \"ne o  a ss       e  ee ee   e   m  mm   \"\n",
      "batch 6414  loss=219.7359  steps/s=98.23  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"B    O   MMM MM     P          / /////  \"\n",
      "batch 6415  loss=145.1906  steps/s=105.99  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" i gt;ttttttttt tssssssssss ssssssssssss\"\n",
      "batch 6416  loss=141.3838  steps/s=105.27  prediction: \"rong tho, my confidence is only like 70%\" => \"edithooo                                \"\n",
      "batch 6418  loss=149.8657  steps/s=102.25  prediction: \"he phone seems to make a huge difference\" => \"a 1 t       eeeeee e   e           e eee\"\n",
      "batch 6419  loss=137.6116  steps/s=105.40  prediction: \"a good way to beat addictions in general\" => \"nf i wsi    oo oooo   aa  aa aa   ii    \"\n",
      "batch 6420  loss=137.9057  steps/s=102.14  prediction: \" this era where breaches happen so often\" => \"toe  e ii ie iin  er eeee  hheehhee  ee \"\n",
      "batch 6421  loss=180.9948  steps/s=73.40  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"lentteli  ie e    er eeee   ee      !!!!\"\n",
      "batch 6422  loss=144.2085  steps/s=107.25  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t l                    ttttttttttt/////1\"\n",
      "batch 6423  loss=140.2130  steps/s=65.88  prediction: \"@JsonBasedman just veto their veto, easy\" => \"ladwt          t  tttttttttt//////tt1118\"\n",
      "batch 6424  loss=147.9327  steps/s=112.43  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ne  o   dd                  tt//////////\"\n",
      "batch 6426  loss=140.1556  steps/s=102.59  prediction: \"rings out there that would just ruin ppl\" => \"enelt 0        ttt  ttttttttt      uu  u\"\n",
      "batch 6427  loss=143.3400  steps/s=99.98  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \"tae                                     \"\n",
      "batch 6428  loss=137.9643  steps/s=99.19  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tn .  b......eettnnnnnn                 \"\n",
      "batch 6430  loss=166.3320  steps/s=100.41  prediction: \"/t.co/hjQfCWaZxw\n",
      "https://t.co/VFbc29W7Ct\" => \"t.coohtt////t////tttttttt//t//tt////t///\"\n",
      "batch 6431  loss=161.4808  steps/s=105.26  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"g et teeeeeeeeeee eeee ddddddaaaaaaaaaaa\"\n",
      "batch 6432  loss=129.2291  steps/s=104.58  prediction: \"more efficient parameters in the network\" => \"enei)       eee eeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 6433  loss=134.8972  steps/s=103.99  prediction: \"just start working, and it doesnt matter\" => \"ust            t                     ttt\"\n",
      "batch 6434  loss=146.9768  steps/s=104.63  prediction: \"r months or yrs\n",
      "\n",
      "https://t.co/7N4QDEMGnO\" => \"ete eo           rrrrrrrrssssttttttttt//\"\n",
      "batch 6435  loss=136.6222  steps/s=104.21  prediction: \" muscle for mentally doing them will get\" => \"tott eerrrrrr  e                     lll\"\n",
      "batch 6436  loss=151.2928  steps/s=73.82  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"n tr e uu         l    lllllll   ee     \"\n",
      "batch 6437  loss=129.6028  steps/s=75.31  prediction: \" @sunsettler @namingbe_ damn thats crazy\" => \"tsuruusuu      n  n   l      e    m     \"\n",
      "batch 6438  loss=128.7881  steps/s=105.87  prediction: \"ive sum game players\n",
      "tautologically true\" => \"ne oy          m          aaaaaaaallllll\"\n",
      "batch 6439  loss=142.9250  steps/s=105.57  prediction: \"ng cd /;sudo rm -rf * and pressing enter\" => \"g  d tt        d                        \"\n",
      "batch 6440  loss=153.2079  steps/s=100.64  prediction: \"o make rlly complex interactive web apps\" => \"nf  f                        eeeeeee eee\"\n",
      "batch 6441  loss=135.7245  steps/s=105.84  prediction: \"file editing program, will show vid soon\" => \"on it   iiiiiiiiiiiiiiiiii   lll        \"\n",
      "batch 6442  loss=119.5417  steps/s=60.03  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tyw weieiiieiiiiiiiiiii llll          oo\"\n",
      "batch 6443  loss=142.0777  steps/s=108.07  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"tu   a                                  \"\n",
      "batch 6444  loss=133.0545  steps/s=99.09  prediction: \" What are your personal long term games?\" => \"tood aahaaaa         rr  rr  oo         \"\n",
      "batch 6445  loss=120.8879  steps/s=97.59  prediction: \"metimes you gotta take one for the cause\" => \"e e   o mmmo   eoooot                  e\"\n",
      "batch 6446  loss=129.2981  steps/s=100.40  prediction: \"ke getting flashbanged by your teammates\" => \"  t tiiiiiiiiii    ggggggg             a\"\n",
      "batch 6447  loss=149.9527  steps/s=104.50  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " tnt oOv-å§]/ð˜â€z::DOON00!P@@@Ê€SWE@G~UULL\"\n",
      "batch 6448  loss=134.1719  steps/s=102.70  prediction: \"ob/business but.. its fun to think about\" => \" l              bbbsssssssss            \"\n",
      "batch 6449  loss=144.5414  steps/s=104.10  prediction: \"w, weve been going for a few weeks or so\" => \"o td  o          eeee                   \"\n",
      "batch 6450  loss=224.5434  steps/s=99.84  prediction: \" ayyy thanks!!! LETS GOO FINALLY SHIPPED\" => \"t              nn     !!                \"\n",
      "batch 6451  loss=137.9500  steps/s=105.27  prediction: \"useful analogies that show up everywhere\" => \"n9 hsssss            a                ee\"\n",
      "batch 6452  loss=143.1180  steps/s=103.30  prediction: \"f children will build my programs for me\" => \" t a           n    lllllllll     r    r\"\n",
      "batch 6453  loss=130.9934  steps/s=100.02  prediction: \"what overlaps stand out to you the most?\" => \"heh  anteeeeee                          \"\n",
      "batch 6454  loss=120.1607  steps/s=64.67  prediction: \"@yacineMTB You want us to find our moms?\" => \"laranaaeeeee     a   t tt            o  \"\n",
      "batch 6455  loss=121.4044  steps/s=107.80  prediction: \"arcyan now you can make pokemon real too\" => \"nnney enaa                    o o  ommo \"\n",
      "batch 6456  loss=139.5831  steps/s=98.95  prediction: \"_opener oops i misread your comment my b\" => \"_1_c@ ooooooooooooooo                 mm\"\n",
      "batch 6457  loss=149.8897  steps/s=105.25  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"eply  \n",
      "e  eeee                   ii  i  \"\n",
      "batch 6458  loss=139.2860  steps/s=103.48  prediction: \"ng to caffeine+building/studying for fun\" => \"g ai e niiiiinni++++iiiiiiiiiiiiiiiiiinn\"\n",
      "batch 6459  loss=134.1668  steps/s=11.18  prediction: \"reply: @djcows leveraged short positions\" => \"e   r niigiinnni+++iiiiiiiiiiiiiiiiiinnf\"\n",
      "batch 6460  loss=159.2889  steps/s=126.19  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"ns no        nnonnnnnnnnttttt//////////t\"\n",
      "batch 6461  loss=128.3968  steps/s=105.21  prediction: \"ort of like a spike strip but for boats)\" => \"u   o                                   \"\n",
      "batch 6462  loss=138.3011  steps/s=101.84  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" tntt t     a   aaaa    rrrrrrarrarrgggg\"\n",
      "batch 6463  loss=129.5141  steps/s=100.14  prediction: \"to it so you can share with your friends\" => \"h t    t                                \"\n",
      "batch 6464  loss=131.4252  steps/s=104.47  prediction: \"and solving their problems/communicating\" => \"nd   o         n            rrrrommmmmmm\"\n",
      "batch 6465  loss=141.1171  steps/s=103.20  prediction: \"e some exciting long term vision then no\" => \" f o  oeeee  eete  e              i    n\"\n",
      "batch 6466  loss=148.7358  steps/s=105.26  prediction: \"/t.co/zlto3SBYwd https://t.co/Izzdx8c2HJ\" => \"s.ccd //t///////ttttttttttttt//////zzzzz\"\n",
      "batch 6467  loss=141.2199  steps/s=101.12  prediction: \"ly got above len=2 for the longest time.\" => \"y: @0iz                                e\"\n",
      "batch 6468  loss=129.6410  steps/s=107.20  prediction: \"am not fixing it https://t.co/dsgcKVp5Ha\" => \"ne                      tttttttttttt////\"\n",
      "batch 6470  loss=121.2426  steps/s=30.12  prediction: \"ply: @sunsettler im down another weekend\" => \"ly: @s            i   ttttttttttt///////\"\n",
      "batch 6471  loss=150.3429  steps/s=112.10  prediction: \"he building -&gt; increase skillset loop\" => \"e  as     i iii iiii ii i i     i   l ll\"\n",
      "batch 6472  loss=131.7901  steps/s=104.11  prediction: \"ining data. The loss went down over time\" => \"ngt  ennnnaaaaanaaaa                    \"\n",
      "batch 6473  loss=131.4131  steps/s=104.38  prediction: \" with a small group of people around you\" => \"tosto                      oo    oppooo \"\n",
      "batch 6474  loss=147.8132  steps/s=98.05  prediction: \"ey sandwich has been achieved internally\" => \"   h     a a   s          heeeeeeeeeeeee\"\n",
      "batch 6475  loss=139.3343  steps/s=102.07  prediction: \"t some point ill probably make it public\" => \" it   t                  l lllll        \"\n",
      "batch 6476  loss=133.8094  steps/s=92.14  prediction: \"enko Could probably do this w ai now lol\" => \" t b   ooooo ollolobbbbbbbl             \"\n",
      "batch 6477  loss=125.9432  steps/s=101.92  prediction: \"go, the name.. none of that shit matters\" => \" o   he                             tttt\"\n",
      "batch 6478  loss=125.5658  steps/s=100.95  prediction: \"tony learns domain expansion in season 5\" => \"h t   o  nnnnnnnn n    nnnnnnnnnnnnnnnnn\"\n",
      "batch 6479  loss=131.4543  steps/s=104.21  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \"  o    e             ........tttttttt///\"\n",
      "batch 6480  loss=132.3272  steps/s=102.48  prediction: \"ate? i mean i can guess, but.. nice work\" => \"n  t           c                        \"\n",
      "batch 6482  loss=135.6056  steps/s=104.01  prediction: \"t (for example working when youre tired)\" => \" soush oooooooooooooo                   \"\n",
      "batch 6483  loss=136.2894  steps/s=103.55  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \"ne a ee        t    httttttttttttttt////\"\n",
      "batch 6484  loss=129.2109  steps/s=98.52  prediction: \"re you need to make a sphere version now\" => \"e l   @Seeeeee                 eehheeeee\"\n",
      "batch 6485  loss=149.0787  steps/s=100.01  prediction: \"ns must magnetically align their protons\" => \"   i ei i       iiillllllllllllll       \"\n",
      "batch 6487  loss=147.6325  steps/s=95.87  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \" cne limmmnnttt0t00 aaaaaaaaa a         \"\n",
      "batch 6488  loss=130.5966  steps/s=100.56  prediction: \"rappers around statistical distributions\" => \"eney      rrrrr rrrssssssssssssstttiiiii\"\n",
      "batch 6489  loss=152.0527  steps/s=105.18  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"  h                    tttttttt/t///////\"\n",
      "batch 6490  loss=132.8029  steps/s=104.99  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"e e m          e                        \"\n",
      "batch 6491  loss=147.4058  steps/s=100.10  prediction: \"u helped a ton, hugely appreciate it bro\" => \"rh  e_11                     pp   a p   \"\n",
      "batch 6492  loss=131.6775  steps/s=104.25  prediction: \" hold onto the ones not worth finishing.\" => \"tot o  ooooooootooooooo oooo          nn\"\n",
      "batch 6493  loss=136.6195  steps/s=105.08  prediction: \"ll be easy to remember every single move\" => \"y e alllllll          eeeeeeeeeeeeeeeeee\"\n",
      "batch 6494  loss=142.4596  steps/s=104.63  prediction: \"xample\n",
      "Do this and then train them on it\" => \" crdo          t                        \"\n",
      "batch 6495  loss=138.5124  steps/s=104.91  prediction: \" but also, probably, very poorly sampled\" => \"tel llll       l                  oooooo\"\n",
      "batch 6496  loss=138.4566  steps/s=58.77  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tyl  lloo      bllbbbbbbb loooooooo rrpp\"\n",
      "batch 6497  loss=126.1924  steps/s=20.10  prediction: \"reply: @justalexoki He is the goat fr fr\" => \"eply: @oo      bllbbbbbbb llooooooo rppp\"\n",
      "batch 6498  loss=148.4652  steps/s=107.87  prediction: \"leneck is my lack of knowledge of opengl\" => \"yx iteeeetttttee ee       k k         oe\"\n",
      "batch 6499  loss=135.2728  steps/s=104.60  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" th e   eeeeeeee                        \"\n",
      "batch 6500  loss=133.7276  steps/s=104.70  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \"gormeri                        sssssssll\"\n",
      "batch 6501  loss=135.3731  steps/s=103.63  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"yne esj                     tttt////////\"\n",
      "batch 6502  loss=152.5020  steps/s=103.09  prediction: \"rop from scratch https://t.co/1UU2vBEGsS\" => \"em e  L       r rrcccccccccctttt////////\"\n",
      "batch 6504  loss=139.6386  steps/s=104.06  prediction: \"no work on my part? ok lol thanks @sama\"\" => \"gtroe          n                        \"\n",
      "batch 6505  loss=180.0669  steps/s=22.31  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: n                                  \"\n",
      "batch 6506  loss=144.4362  steps/s=107.76  prediction: \"e a dog\n",
      "\n",
      "thats how i feel abt it anyways\" => \" a l                                    \"\n",
      "batch 6507  loss=126.7741  steps/s=72.34  prediction: \"justalexoki its tpot, all lowercase only\" => \"ust  ok   aa   k             ll    waaaa\"\n",
      "batch 6508  loss=146.3233  steps/s=106.45  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e le  X   rrrrrrrrrrrrrrrrr             \"\n",
      "batch 6509  loss=133.2139  steps/s=103.89  prediction: \"ich is a great way to find opportunities\" => \"ni  f iiiii                            t\"\n",
      "batch 6510  loss=127.3822  steps/s=99.79  prediction: \"ice awareness and reading ppl/situations\" => \"nh ifaaaaaaaaaaaaaaaaaaaaaaeee  nnnaaaii\"\n",
      "batch 6511  loss=136.2427  steps/s=11.70  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"eply: @aaaaaaaaaaaaaaaaaaaee    nn aaiii\"\n",
      "batch 6512  loss=132.0282  steps/s=110.09  prediction: \"oud to yourself, or in your imagination)\" => \" te to  ooooooooooooo                  i\"\n",
      "batch 6513  loss=138.7583  steps/s=99.65  prediction: \"own to play more. was a pleasure as well\" => \"   e           m                aaaaaa  \"\n",
      "batch 6514  loss=132.3250  steps/s=104.03  prediction: \"oser and closer until you can putt it in\" => \"ut             l                        \"\n",
      "batch 6515  loss=134.3861  steps/s=101.01  prediction: \"st went from rome to naples two days ago\" => \" ahti                                   \"\n",
      "batch 6516  loss=153.2034  steps/s=104.59  prediction: \"vars} complexity (O(f(n)) type stuff)\n",
      "-â€¦\" => \"isyoe  eeee eeeee  e   (((((((((()))))))\"\n",
      "batch 6518  loss=135.3677  steps/s=103.54  prediction: \" is interesting play between those three\" => \"tn  e      eee t eeeeeee e eeeeeeeeeeeee\"\n",
      "batch 6520  loss=130.4630  steps/s=100.40  prediction: \"rappers around statistical distributions\" => \"enty:    rrrrrr rrrssssssssststttttttiii\"\n",
      "batch 6522  loss=184.1424  steps/s=99.45  prediction: \"________11hz togglesite is super helpful\" => \"____________________t11ttttiisssssss    \"\n",
      "batch 6523  loss=150.6648  steps/s=84.97  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \"gert roooooooooooooooo                  \"\n",
      "batch 6524  loss=138.6375  steps/s=80.35  prediction: \"minus9 This is my new favorite edm track\" => \"ene  roooooo                            \"\n",
      "batch 6525  loss=140.8630  steps/s=105.04  prediction: \"sk for, then train them to ask, then act\" => \" e t           t     t ttt t            \"\n",
      "batch 6526  loss=137.1818  steps/s=104.76  prediction: \"urself, if you can manage to pull it off\" => \"ne eeyl                                 \"\n",
      "batch 6528  loss=153.9243  steps/s=97.93  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"   o ii                  tttttt/////////\"\n",
      "batch 6529  loss=139.0768  steps/s=102.78  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \" gse                           /////////\"\n",
      "batch 6530  loss=142.4902  steps/s=104.40  prediction: \"ead to insanity\n",
      "\n",
      "https://t.co/FLccrhEiEd\" => \" rxoiso     aaa  aa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tt\n",
      "\n",
      "ttt///ttttc\"\n",
      "batch 6531  loss=136.9334  steps/s=104.45  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"  ng is                                 \"\n",
      "batch 6532  loss=141.9297  steps/s=105.21  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" t  e            ttttttttttttttttttttttt\"\n",
      "batch 6533  loss=136.0305  steps/s=104.54  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \" e r e         t     ttttttttttttttthh/h\"\n",
      "batch 6534  loss=159.3889  steps/s=64.32  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tdu e    ee tttthhtttttttt/////////hhhhh\"\n",
      "batch 6535  loss=136.8346  steps/s=113.15  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"nga            n          ttttttt///////\"\n",
      "batch 6537  loss=139.5601  steps/s=99.34  prediction: \"ely the case for chess and debugging imo\" => \"  o  @ eeeeeeeeeee                      \"\n",
      "batch 6538  loss=155.7150  steps/s=76.15  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yw @ao  eeeee      ee . s ssss/// g gggg\"\n",
      "batch 6539  loss=129.5063  steps/s=106.70  prediction: \"in but u see it everywhere after a while\" => \"net e t               eeeeeeeeeeeeeeeeee\"\n",
      "batch 6540  loss=141.6592  steps/s=105.23  prediction: \"n doing on a method of learning faster)â€¦\" => \" e a  eeeee    e                        \"\n",
      "batch 6541  loss=225.8451  steps/s=101.21  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OTVIWGWOTNOOTNNNOON  N            ttttt/\"\n",
      "batch 6542  loss=180.5231  steps/s=88.56  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" d GOO T  T      EEEEE tt ////tt////tIII\"\n",
      "batch 6543  loss=133.8389  steps/s=105.85  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" t ts sssssssssssseeeeeeeeee            \"\n",
      "batch 6544  loss=155.1517  steps/s=105.57  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \"ot  in                  dddddddddddddddn\"\n",
      "batch 6545  loss=132.5812  steps/s=100.16  prediction: \"o actually understand the program better\" => \"nis  s             aaaaa              rr\"\n",
      "batch 6546  loss=144.8310  steps/s=106.24  prediction: \"s it and im unaware (would love to know)\" => \" so s                                   \"\n",
      "batch 6548  loss=150.6608  steps/s=105.49  prediction: \"\n",
      "\"runit\"\n",
      "\n",
      "almost never have to modify it\" => \"\n",
      "a e rf/Gð˜€ð—µá´›ð—²ðŸŒ‘Hz#[ðŸ˜¤ðŸ˜Ž[UU$xx##44ðŸ¤¦[$##á´â€ðŸ§ L_\"\n",
      "batch 6549  loss=137.7305  steps/s=104.08  prediction: \"ly when you try to build the thing again\" => \"y o en         c                        \"\n",
      "batch 6550  loss=141.9277  steps/s=105.39  prediction: \"ould help large numbers of ppl if solved\" => \"utderero    lllllll    le               \"\n",
      "batch 6552  loss=134.9669  steps/s=105.42  prediction: \"his, and even then you might get mislead\" => \"ev oto                                  \"\n",
      "batch 6553  loss=126.6703  steps/s=98.50  prediction: \"see more details as you unblur an image.\" => \" loet     eeeeeeeeee                   u\"\n",
      "batch 6554  loss=144.0648  steps/s=104.15  prediction: \"l. but really, I have absolutely no clue\" => \"y  sgAg                        lllllllll\"\n",
      "batch 6555  loss=146.5411  steps/s=105.12  prediction: \" kache who made dingboard w llms (afaik)\" => \"tii  i is            a   da        aaaa \"\n",
      "batch 6556  loss=135.6853  steps/s=98.71  prediction: \"eed\n",
      "\n",
      "Trust is our most valuable resource\" => \" dseddddddddeeedee                      \"\n",
      "batch 6557  loss=136.0654  steps/s=101.72  prediction: \" Post it in the disc it helps us all out\" => \"too l                                   \"\n",
      "batch 6559  loss=115.2698  steps/s=99.18  prediction: \"o the door the instant she hears it open\" => \"uo noi t       t              hhh       \"\n",
      "batch 6560  loss=134.7484  steps/s=96.86  prediction: \"my database is a text file called main.c\" => \"e e t       e       a                  e\"\n",
      "batch 6561  loss=190.3870  steps/s=31.18  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly: @       e     aaa                  l\"\n",
      "batch 6562  loss=141.0780  steps/s=107.27  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \" l lw   l lllll llooo o o o ooo  oo   !!\"\n",
      "batch 6563  loss=137.4132  steps/s=103.71  prediction: \"pl to influence what they think (cringe)\" => \"lyrin p        n                        \"\n",
      "batch 6564  loss=121.1428  steps/s=99.85  prediction: \" feel to be a tier above elon @teodor_io\" => \"toa ee                           eeeeeee\"\n",
      "batch 6565  loss=153.0010  steps/s=99.95  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \"hrne  _otttttttt eeeeeee                \"\n",
      "batch 6566  loss=144.3452  steps/s=96.76  prediction: \"072 im super glad man! love to hear that\" => \"x 7  iis  00     e                     t\"\n",
      "batch 6567  loss=150.4553  steps/s=104.52  prediction: \"you get used to it and overcome the fear\" => \":u             t                      e \"\n",
      "batch 6568  loss=136.8835  steps/s=80.35  prediction: \"dwigABAP Big win, love it, great job man\" => \" i     uu g                ooe  te  eee \"\n",
      "batch 6569  loss=128.6907  steps/s=105.51  prediction: \"ort of like a spike strip but for boats)\" => \"u t o                                   \"\n",
      "batch 6570  loss=149.3774  steps/s=102.87  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"tn l  m ooooooooo ll                    \"\n",
      "batch 6571  loss=173.7804  steps/s=94.44  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \"  to Boooollllll          m     mmmooooo\"\n",
      "batch 6572  loss=167.5335  steps/s=104.14  prediction: \"ou get like 5 seconds to shoot your shot\" => \"u  R                          oooooooooo\"\n",
      "batch 6573  loss=132.5475  steps/s=99.73  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \"gi o  e        n      fffffffffffffff   \"\n",
      "batch 6574  loss=126.5635  steps/s=102.57  prediction: \"works for the first time is the most fun\" => \" r  o e        r                        \"\n",
      "batch 6575  loss=128.3451  steps/s=103.97  prediction: \"ng signals from constant individual lies\" => \"g re ei iiisssss    ssss  nnnnnnnnniiiii\"\n",
      "batch 6576  loss=133.1420  steps/s=104.51  prediction: \"just point to concepts and arent reality\" => \"ust            t                        \"\n",
      "batch 6577  loss=155.1707  steps/s=102.28  prediction: \"ombies, lethal company, misc other stuff\" => \"n s sooooo                              \"\n",
      "batch 6578  loss=128.9464  steps/s=103.60  prediction: \" of twitter it usually means engineering\" => \"tf t  t     t tttt tt             ee eee\"\n",
      "batch 6579  loss=134.3140  steps/s=53.12  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @lixh tttt tt                eeaneeeenn\"\n",
      "batch 6580  loss=144.7429  steps/s=109.39  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"  o te ettttttttttttteeeeeeeeeee        \"\n",
      "batch 6581  loss=120.2347  steps/s=106.38  prediction: \" is it some kind of info storage system?\" => \"tt ts                                  s\"\n",
      "batch 6582  loss=145.6105  steps/s=104.32  prediction: \"morrow, hope it goes well for you brotha\" => \"edise  ooor oo r  o  ooo   oo oo   oo   \"\n",
      "batch 6583  loss=150.2823  steps/s=103.23  prediction: \" God for helping us both out\n",
      "it was hell\" => \"tCrl         l               o      t   \"\n",
      "batch 6585  loss=142.7569  steps/s=104.03  prediction: \" to me except this feels 100x better fug\" => \"thets ttt   te e  ee ee    e   ee eeee  \"\n",
      "batch 6586  loss=143.5119  steps/s=104.33  prediction: \"is fine and expected, giving up is death\" => \"n  \n",
      "e aaeeee   neeeei e  e   ee     ii i\"\n",
      "batch 6587  loss=150.5647  steps/s=11.14  prediction: \"reply: @HSVSphere how high agency of you\" => \"eprae  ieeee   ieeee  e  e   ei     ii i\"\n",
      "batch 6588  loss=139.3125  steps/s=111.70  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" i\" l  ll  aaaa aabbbbb    aaaaaaaaaaaaa\"\n",
      "batch 6589  loss=145.3143  steps/s=101.05  prediction: \"employees) do half the work in a company\" => \" os   o    oo  so                       \"\n",
      "batch 6590  loss=147.7643  steps/s=106.01  prediction: \" so this helped\n",
      "\n",
      "Are you gonna continue?\" => \"@to s                              oonnn\"\n",
      "batch 6591  loss=129.1200  steps/s=99.16  prediction: \"ideos Its good to be back on the streets\" => \"ne    siiisseddoooo                     \"\n",
      "batch 6592  loss=156.8582  steps/s=101.39  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"etey            aaaaaaaaaaatttt/////////\"\n",
      "batch 6594  loss=135.2707  steps/s=103.95  prediction: \"s changing how I think abt models a lot.\" => \" an   ats       nn  hhhh                \"\n",
      "batch 6595  loss=138.5335  steps/s=105.89  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"\n",
      "Iot  o.][á´„á´›[ð—ªÊœ$#44ÊœÊŸ$`Z|Z#3Qð—µ#ðŸ°á´€##Ê€â€æˆ‘â€¦#\"\n",
      "batch 6596  loss=141.2894  steps/s=105.10  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  h          t  ttttttttttttttt///////\"\n",
      "batch 6597  loss=132.9682  steps/s=100.78  prediction: \"ho. i like it much much better than rome\" => \"e. iar                           ttttttt\"\n",
      "batch 6598  loss=160.7893  steps/s=105.15  prediction: \"a fckton of time https://t.co/HOKGcS3zKn\" => \"ng i \n",
      "ttt     tt t    tt   tttt /tttt///\"\n",
      "batch 6599  loss=133.3066  steps/s=102.76  prediction: \"rol you. why would they want to do that?\" => \"eble  tooooo oowoo                      \"\n",
      "batch 6600  loss=135.0042  steps/s=103.27  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"enlye                                   \"\n",
      "batch 6601  loss=114.7259  steps/s=20.90  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly:           i    i                   \"\n",
      "batch 6602  loss=122.1518  steps/s=66.84  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly:           ii  ii                   \"\n",
      "batch 6603  loss=125.1487  steps/s=120.11  prediction: \"d work that into my current program haha\" => \" io i                          rrrrrrrrr\"\n",
      "batch 6605  loss=140.6879  steps/s=50.72  prediction: \": @0xluffyb graphics programming be like\" => \" @HDsl                   rr rrrrrrrr r  \"\n",
      "batch 6606  loss=179.5194  steps/s=111.98  prediction: \" make https://t.co/s6ZBWGye2X executable\" => \"ias a kak t t  tt  tt/  ///tt/t//eeeteee\"\n",
      "batch 6607  loss=150.4996  steps/s=105.02  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omlec  cc c ce eee         tttttttt/////\"\n",
      "batch 6608  loss=140.8723  steps/s=104.13  prediction: \"up computing 'why' for free all the time\" => \"se                                      \"\n",
      "batch 6609  loss=160.3824  steps/s=20.44  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"   ae          u                        \"\n",
      "batch 6611  loss=147.2071  steps/s=111.91  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"eai         00000000                  oo\"\n",
      "batch 6612  loss=138.3027  steps/s=104.23  prediction: \"al of life that pays some huge dividends\" => \"nls            f                        \"\n",
      "batch 6613  loss=145.0064  steps/s=105.18  prediction: \"he just checkmated because he got lucky\"\" => \"e bi\"\"\"\"\"\"\"\"hhhhhhhee  eeecceeeeeeeeeee \"\n",
      "batch 6614  loss=129.6013  steps/s=105.37  prediction: \"ng things work out rather than 'tactics'\" => \"   ea   nn gg  n                 ttttttt\"\n",
      "batch 6615  loss=140.1610  steps/s=104.41  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \" lolw  llllllll loooo o o o ooo  oo   !!\"\n",
      "batch 6616  loss=134.1741  steps/s=104.43  prediction: \" arent tired when you dont have caffeine\" => \"i e   e        t                        \"\n",
      "batch 6617  loss=153.7373  steps/s=101.95  prediction: \"ly easy actually https://t.co/H2M3XYMGwC\" => \"y: o    aa  aaaaaaal aalllttttt  t//////\"\n",
      "batch 6619  loss=138.8940  steps/s=100.69  prediction: \"you really need to make your own company\" => \":u aeaaa           e  e    e        o   \"\n",
      "batch 6620  loss=132.1678  steps/s=104.30  prediction: \"s of thought, and your ability to thinkâ€¦\" => \" eee e                                tt\"\n",
      "batch 6621  loss=163.9264  steps/s=100.86  prediction: \"prob 2.5M tokens\n",
      "https://t.co/6FbmJG4MmF\" => \"lo: @a2                tttttttttttt/////\"\n",
      "batch 6625  loss=138.1120  steps/s=106.75  prediction: \"re you need to make a sphere version now\" => \"eply: @S                  t     e ssseee\"\n",
      "batch 6626  loss=216.4532  steps/s=103.43  prediction: \"ST BACKPROPAGATE https://t.co/eFVShlRgdK\" => \" \n",
      "er  SUBBBBBOA  AAAAA     TT    /   ///\"\n",
      "batch 6627  loss=158.4605  steps/s=99.53  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"eet rC            tttttttttt        ss  \"\n",
      "batch 6628  loss=152.8280  steps/s=103.00  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"io d o (nn((()))))                    ff\"\n",
      "batch 6629  loss=139.7002  steps/s=43.36  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y:de nn(())))))n                     fff\"\n",
      "batch 6630  loss=146.3969  steps/s=115.55  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"emuy:no oooo ooc   ttttttttttttttttttt//\"\n",
      "batch 6631  loss=144.0807  steps/s=102.14  prediction: \"rf spatial in problem solving efficiency\" => \"eioth aaaaaaaaaaa  a               iiiii\"\n",
      "batch 6632  loss=159.9918  steps/s=104.05  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "aci pizj???zz?@?K`RR8?GG???L??????UU?-?\"\n",
      "batch 6634  loss=138.4573  steps/s=101.47  prediction: \"retty great as well, hes also on youtube\" => \"eplto i    tt te     ee    el ll        \"\n",
      "batch 6635  loss=136.3432  steps/s=104.70  prediction: \"so they get into an unending doom spiral\" => \" li t tttt  tt ttt tt    n  nnnnnnnnnnn \"\n",
      "batch 6636  loss=154.0160  steps/s=97.81  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" oihe heeh eee sss               sp     \"\n",
      "batch 6637  loss=128.1910  steps/s=49.19  prediction: \": @archived_videos definitely the latter\" => \" @HeVehheiiie  sssserr  e               \"\n",
      "batch 6638  loss=132.1661  steps/s=109.04  prediction: \"th `sudo service NetworkManager restart`\" => \" e  en         r     eeeeeeeeeeeeeerrrrr\"\n",
      "batch 6640  loss=156.1400  steps/s=103.48  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"   so  ssssss 0000000000tttt////////////\"\n",
      "batch 6641  loss=120.6302  steps/s=78.17  prediction: \"sunsettler hes locked in to the outdoors\" => \" r so ssseeee0ee  kkkkk//ttttttttttteRRR\"\n",
      "batch 6642  loss=135.3624  steps/s=106.43  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"ece ee                      tttttttt////\"\n",
      "batch 6643  loss=131.8709  steps/s=105.43  prediction: \"e did not seem like the type to work out\" => \" mn                  eeeeeeeeeee        \"\n",
      "batch 6644  loss=162.5750  steps/s=60.67  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"t0ad   e    e  e e   eetteeettt         \"\n",
      "batch 6645  loss=140.0200  steps/s=119.65  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"      en              t tt/////////tWWWW\"\n",
      "batch 6646  loss=140.3712  steps/s=106.18  prediction: \"it anymore. Now she can go get groceries\" => \"n  a                                   g\"\n",
      "batch 6648  loss=138.6078  steps/s=104.52  prediction: \" since llms are not great with zig (ime)\" => \"tts            l                        \"\n",
      "batch 6649  loss=119.8524  steps/s=45.77  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  @ca    l                              \"\n",
      "batch 6650  loss=125.7164  steps/s=107.55  prediction: \"he result, its equivalent to convolution\" => \"e  arrrrrr     t          ttttttttttttto\"\n",
      "batch 6651  loss=139.1344  steps/s=105.32  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"h re r                      tt//////////\"\n",
      "batch 6652  loss=134.6847  steps/s=103.67  prediction: \"he case for some regions outside the US.\" => \"e e tt         s           oooooooooeee \"\n",
      "batch 6653  loss=145.9186  steps/s=104.91  prediction: \"s a man wanna build his own.. everything\" => \" is aassa  aa  a naaaa nn  nn           \"\n",
      "batch 6654  loss=145.1906  steps/s=101.67  prediction: \" more cracked by the day, love to see it\" => \"tar  ng                                 \"\n",
      "batch 6655  loss=136.3935  steps/s=98.33  prediction: \"the man just liked big words and spirals\" => \"he  @a aaaaa                            \"\n",
      "batch 6657  loss=142.6341  steps/s=105.23  prediction: \"freedom fighters. ppl who wanted freedom\" => \" on           eeeeee                    \"\n",
      "batch 6658  loss=137.4942  steps/s=105.12  prediction: \"eel free to run ideas by me whenever btw\" => \" d n  eeeeeeeee                   eeeeee\"\n",
      "batch 6659  loss=137.9369  steps/s=104.25  prediction: \"just have to connect/reconnect the wifi'\" => \"ust t                   ooocccccccccccnt\"\n",
      "batch 6660  loss=141.1458  steps/s=72.75  prediction: \"yacineMTB nooo not a 2d grid of 2d grids\" => \" ci  o       oooooooo co nnccntte      e\"\n",
      "batch 6661  loss=132.9422  steps/s=112.55  prediction: \"surely you will not regret this decision\" => \" rus  aaaa     t                       i\"\n",
      "batch 6663  loss=140.7853  steps/s=103.03  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \" f   l  .      e             tt/////////\"\n",
      "batch 6664  loss=127.8738  steps/s=102.10  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \"   stt tttttttttoooooooooo              \"\n",
      "batch 6665  loss=141.2830  steps/s=104.77  prediction: \"freedom fighters. ppl who wanted freedom\" => \" on  r       eeeeeee                    \"\n",
      "batch 6666  loss=138.1858  steps/s=102.33  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" 2onnnnnnnooooo          ttttttttttt////\"\n",
      "batch 6667  loss=150.1438  steps/s=104.07  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"aile   e  eeee    e \n",
      "e\n",
      "\n",
      "eee::::ttt:///tt\"\n",
      "batch 6668  loss=137.0378  steps/s=104.33  prediction: \"d size to whatever you want which helps.\" => \" ti                e    e       w   hhhh\"\n",
      "batch 6669  loss=151.1667  steps/s=103.40  prediction: \" mon), celebrating someones bday on both\" => \"to             r        oeeeeeeeeeo oooo\"\n",
      "batch 6670  loss=138.1253  steps/s=99.97  prediction: \"hdaily how does it compare to 100m leads\" => \"e  ri llllllloolo  ooooo                \"\n",
      "batch 6671  loss=140.5124  steps/s=47.31  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \"  @0ollll  ooo         oo               \"\n",
      "batch 6672  loss=137.1063  steps/s=111.42  prediction: \"ter and more efficient than studying imo\" => \"hrt  tstttttt   t eeee  eeeeeeet  ttttii\"\n",
      "batch 6673  loss=141.2227  steps/s=103.99  prediction: \" relationship where you never lie to her\" => \"tere   aartaaa  a      ee    reeeee    e\"\n",
      "batch 6675  loss=135.8756  steps/s=93.74  prediction: \"ntellectus To beat paranoia, accept risk\" => \"gi  eeteeetttt l e      e aaaaaaaee     \"\n",
      "batch 6676  loss=159.4282  steps/s=103.73  prediction: \" possible the true x for elon is 42,069x\" => \"trm   s sssssss                         \"\n",
      "batch 6677  loss=147.8194  steps/s=102.95  prediction: \"ou get faster and faster at solving them\" => \"ugt                                     \"\n",
      "batch 6679  loss=145.0564  steps/s=77.80  prediction: \"minus9 hmm still pixels on my end, weird\" => \"ene  e              tt                 e\"\n",
      "batch 6680  loss=135.0427  steps/s=108.38  prediction: \"here zoomer problems, cant relate /shrug\" => \"e   u  Smmee e     elel             eeee\"\n",
      "batch 6681  loss=157.9330  steps/s=101.60  prediction: \"tler good knight https://t.co/lACUcp7zMH\" => \"heo  eeeeeeerooooooo    ttttttttt///////\"\n",
      "batch 6682  loss=137.5883  steps/s=99.27  prediction: \"lsio recursive mind exploding adventures\" => \"y  @stseeeeeeeeeeieeeeeiiiiie eedddddddd\"\n",
      "batch 6683  loss=135.7569  steps/s=104.13  prediction: \"usually good metrics, good feedback, etc\" => \"rt t                   oooooooooooo     \"\n",
      "batch 6684  loss=176.8835  steps/s=103.38  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"B IudO TTOOOOOOOOOOOOOOOO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tt///\"\n",
      "batch 6685  loss=162.1130  steps/s=98.57  prediction: \" more cracked by the day, love to see it\" => \"tade \n",
      "                                  \"\n",
      "batch 6686  loss=156.9016  steps/s=101.21  prediction: \"expected him to be maybe 55 or something\" => \" s  e                                   \"\n",
      "batch 6687  loss=129.1862  steps/s=103.60  prediction: \" can see something 1000000x better to do\" => \"tat eaaaa      n        000000000000    \"\n",
      "batch 6688  loss=128.2176  steps/s=100.38  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"ne aaeeeee     s                        \"\n",
      "batch 6689  loss=140.2354  steps/s=100.79  prediction: \" easy to use too\n",
      "https://t.co/EjkhiWdtX3\" => \"tanen n        t   tttttttttttt////////t\"\n",
      "batch 6690  loss=157.0505  steps/s=101.49  prediction: \"dgrammer it was a really fun time though\" => \"  me mmrrrrrrrrrrrrrr                   \"\n",
      "batch 6691  loss=125.0453  steps/s=101.94  prediction: \" is it some kind of info storage system?\" => \"@t  s                                  s\"\n",
      "batch 6692  loss=130.4967  steps/s=102.22  prediction: \"r tweet was epictetus's two handles idea\" => \"e@ly: @        eeeeeeeeeettttttttttt    \"\n",
      "batch 6694  loss=142.7294  steps/s=67.66  prediction: \"Brycicle77 its a 'being' kinda day today\" => \" y @ t wee eeeet ttteee''t       a   dda\"\n",
      "batch 6695  loss=135.2748  steps/s=107.70  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \"hr  tieeeeeeeeeneeeeeelllll  sssssssss  \"\n",
      "batch 6696  loss=151.4228  steps/s=70.01  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"ust nieneneeeeeeeee   s    ss           \"\n",
      "batch 6698  loss=143.9926  steps/s=107.52  prediction: \"he goated advice https://t.co/gZx1K1OtSg\" => \"e gh                  tttttttttttttttt//\"\n",
      "batch 6700  loss=161.3556  steps/s=102.04  prediction: \"he making a dingboard clone or something\" => \"e g m g g   iiii         d       oo  ooo\"\n",
      "batch 6701  loss=149.8664  steps/s=102.01  prediction: \"though who knows\n",
      "https://t.co/YpddagC5uf\" => \"he  il aa    hhhhhhhhhhhhhhhtttttt//////\"\n",
      "batch 6702  loss=130.2401  steps/s=104.34  prediction: \"et good at the ones youre not so good at\" => \" tantaa        t                 ooooooo\"\n",
      "batch 6703  loss=130.3056  steps/s=102.90  prediction: \"d useful stuff better with the new tools\" => \" us uuu uu uuuu ufuffff tttttt  ttttt tt\"\n",
      "batch 6704  loss=147.4043  steps/s=104.41  prediction: \"nally get monads\n",
      "https://t.co/lYN3cpV8JV\" => \"gtTB e e               ttttttttttttt////\"\n",
      "batch 6705  loss=144.0277  steps/s=104.13  prediction: \"bly helps that they have a faster ai now\" => \"ey p  bbbpbbbllhlhhhh hhh h  h a  aaaaa \"\n",
      "batch 6706  loss=136.6156  steps/s=104.96  prediction: \"h yes it is? I would literally sit on aâ€¦\" => \"ei \"no uu                      llllll  l\"\n",
      "batch 6707  loss=142.8447  steps/s=99.29  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"ls  @ nm                          aaaaaa\"\n",
      "batch 6708  loss=132.9763  steps/s=100.58  prediction: \" in this article\n",
      "https://t.co/8gCd6cnXXP\" => \"t  tiiiiiiiiiiiiiiitttttttttttttttttttcc\"\n",
      "batch 6709  loss=156.6439  steps/s=104.31  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"tan innt////t///ttttttttt//t//tt////t///\"\n",
      "batch 6710  loss=148.1061  steps/s=103.51  prediction: \"morrow, hope it goes well for you brotha\" => \"ed sororoor oo r  o  ooo   oo oo   oo   \"\n",
      "batch 6711  loss=134.4073  steps/s=104.08  prediction: \"f time and space that can reach in here?\" => \" wieo,         t           aaaaaaa      \"\n",
      "batch 6712  loss=176.4955  steps/s=103.42  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \" a\n",
      "ti          t                        \"\n",
      "batch 6713  loss=144.1100  steps/s=64.40  prediction: \"@yacineMTB so youre no longer locked in?\" => \"saclyll        t                        \"\n",
      "batch 6714  loss=143.1148  steps/s=105.85  prediction: \" lets you debug your own problems easily\" => \"toar s   tt    t       uu       oo    oo\"\n",
      "batch 6715  loss=128.5021  steps/s=101.57  prediction: \"engagement-bait generating llm finetunes\" => \" tB   eeeeeeeeegeeeeeeeeeeeeennnnnnnnnnn\"\n",
      "batch 6718  loss=139.5885  steps/s=104.23  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"the  i                       aaaaaaaaaaa\"\n",
      "batch 6719  loss=135.5526  steps/s=105.16  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hos ibiiiiiiiiiiiiitttttttttttttttttttt/\"\n",
      "batch 6720  loss=135.8053  steps/s=104.59  prediction: \"house? where is your phone charger? etc)\" => \"eweioo                                ee\"\n",
      "batch 6721  loss=129.1756  steps/s=89.94  prediction: \"bly same, llms are so much faster though\" => \"ey ouo    e    s                       e\"\n",
      "batch 6722  loss=130.1588  steps/s=101.90  prediction: \"u come up with. Forgetfulness is a bitch\" => \"rc                                      \"\n",
      "batch 6723  loss=143.6425  steps/s=103.79  prediction: \"l, titan, stable diffusion, a few others\" => \"y   iros   s  tsttttt t  iii      f     \"\n",
      "batch 6724  loss=130.6349  steps/s=97.05  prediction: \"surely you will not regret this decision\" => \" ros aattttt   l                     eee\"\n",
      "batch 6725  loss=154.5014  steps/s=104.62  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \" tr bs                  dddddddddddddddn\"\n",
      "batch 6726  loss=137.1084  steps/s=86.03  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"ee  : @            eee  e    nntnnnnnnn \"\n",
      "batch 6727  loss=159.0210  steps/s=104.58  prediction: \"arning, josh waitzkin\n",
      "\n",
      "Gigacracked books\" => \"ne tt  e  ee   t    ii iiiiinaiiaaaaikkk\"\n",
      "batch 6728  loss=160.1611  steps/s=87.82  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" rtt @eeeeh    LLLLO\n",
      "\n",
      " \n",
      "eaa  aaaa arra  \"\n",
      "batch 6729  loss=152.8257  steps/s=78.18  prediction: \"asedBeffJezos log(followers)/account age\" => \"r  niiBeOOOOOO wzez e   ee r  aaarccccTT\"\n",
      "batch 6730  loss=183.4857  steps/s=114.31  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"o   eeEEEEEEEOOOOOOOOOOOOOOOwwww        \"\n",
      "batch 6731  loss=145.4754  steps/s=100.83  prediction: \"blue, someone is working harder than you\" => \"le   ee  eeeeeeeeee                     \"\n",
      "batch 6732  loss=135.3120  steps/s=102.99  prediction: \"people, i just post a weird mix of stuff\" => \"lrt    oo                               \"\n",
      "batch 6733  loss=137.5301  steps/s=103.61  prediction: \"anding pages or whatever feels gross idk\" => \"td at o o      n           eeeeeeeeee  e\"\n",
      "batch 6734  loss=187.8833  steps/s=62.35  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" stct                    eeeeeeeeessss  \"\n",
      "batch 6735  loss=139.5571  steps/s=105.70  prediction: \" even the ones i disagreed with the most\" => \"tv e eee  eeeeen          e e           \"\n",
      "batch 6736  loss=144.5507  steps/s=103.32  prediction: \"he goated advice https://t.co/gZx1K1OtSg\" => \"a gh           t      tttttttttt////////\"\n",
      "batch 6737  loss=140.5849  steps/s=99.90  prediction: \"nism oooh possibly, thats a good thought\" => \"gs go  oooooooooooooooosossssssss   tttt\"\n",
      "batch 6738  loss=137.0660  steps/s=98.93  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"ns  n d                                 \"\n",
      "batch 6739  loss=132.5970  steps/s=104.57  prediction: \"d into using dishonest middlewit tactics\" => \" we ie e           sssssssssssiiiiiiiiii\"\n",
      "batch 6740  loss=131.1388  steps/s=101.43  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"o saninnnnnnnnnnnooooooooooiiiiiiiiiiiia\"\n",
      "batch 6741  loss=138.0634  steps/s=80.21  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"ni r anaahhahhh\n",
      "o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " iiii s      aaaa\"\n",
      "batch 6742  loss=135.5309  steps/s=85.76  prediction: \"gizmobly @juweeism duude this is awesome\" => \" rn nhahahhhhh\n",
      "w\n",
      "\n",
      "\n",
      "\n",
      "s     d         aaaa\"\n",
      "batch 6743  loss=165.3028  steps/s=111.85  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" tar @hA@@@@@eeeeeees________         ee\"\n",
      "batch 6744  loss=143.2613  steps/s=102.03  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t a                    tttttttttttt/////\"\n",
      "batch 6745  loss=146.7743  steps/s=102.33  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"hu   t                     ttttt////////\"\n",
      "batch 6747  loss=135.7881  steps/s=101.92  prediction: \"worst part, as demonstrated by the graph\" => \"iu   t e tttt                   t       \"\n",
      "batch 6748  loss=131.4929  steps/s=104.74  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf nin         n                        \"\n",
      "batch 6749  loss=137.9269  steps/s=105.57  prediction: \" get to master idk depends on your goals\" => \"te eeee        t           ddddd        \"\n",
      "batch 6750  loss=135.0136  steps/s=95.93  prediction: \"unches, then good luck ever finding them\" => \"rd             l                        \"\n",
      "batch 6751  loss=129.5132  steps/s=105.98  prediction: \" life you have to put in work to do this\" => \"tou to   ie  eee                        \"\n",
      "batch 6752  loss=126.7078  steps/s=103.67  prediction: \"or a site with a manipulatable algorithm\" => \"     o                   aaaaaaaaaaaaaaa\"\n",
      "batch 6753  loss=137.8026  steps/s=104.25  prediction: \"ros named tuna but he swam like a salmon\" => \"em  d   r rd    d                       \"\n",
      "batch 6754  loss=130.3939  steps/s=105.28  prediction: \"can help guide them towards better stuff\" => \"on oe          e                 ttttttt\"\n",
      "batch 6755  loss=151.2562  steps/s=98.29  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \" p  olaaaaannnnnnnnnnnneeeeeeeee\"\"\"\"\"\"\"\"\"\n",
      "batch 6756  loss=124.8015  steps/s=102.66  prediction: \"d hire my friends to do research with me\" => \" to                                     \"\n",
      "batch 6757  loss=131.6906  steps/s=105.22  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"ewl y          e                        \"\n",
      "batch 6758  loss=132.1559  steps/s=104.16  prediction: \"that was probably its entire purpose lol\" => \"he i ittttttttt tt                      \"\n",
      "batch 6759  loss=139.8354  steps/s=103.87  prediction: \"e a gifboard btw https://t.co/hFlPyNTvRm\" => \" ooo                     ttttttttt//////\"\n",
      "batch 6760  loss=130.3613  steps/s=105.61  prediction: \" just be a webpage visit, its in browser\" => \"tu  ll ll                       iiiii   \"\n",
      "batch 6761  loss=174.9080  steps/s=65.14  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"ludlnol o              ttiistiiiii is  e\"\n",
      "batch 6762  loss=145.2543  steps/s=101.96  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"yn @llokko  bbb e  tt tt/////////to UjUe\"\n",
      "batch 6763  loss=152.7693  steps/s=112.40  prediction: \"an!\n",
      "Gpt 4o came in clutch for the images\" => \"n   tokaa      n          cc            \"\n",
      "batch 6764  loss=133.1641  steps/s=102.39  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot i                        tttt///////\"\n",
      "batch 6765  loss=123.8650  steps/s=71.51  prediction: \"sunsettler hes locked in to the outdoors\" => \" bn   nnnn              ttttttttttttKKoo\"\n",
      "batch 6766  loss=132.1632  steps/s=110.49  prediction: \"but i followed just in case you do pivot\" => \"et                                      \"\n",
      "batch 6767  loss=136.2633  steps/s=104.00  prediction: \" get to master idk depends on your goals\" => \"te eeee        t         ddddddd        \"\n",
      "batch 6768  loss=144.0135  steps/s=104.57  prediction: \"er/common, insurance will drive adoption\" => \" sS    ee eeeeeeemennnnnnnnnnn       i i\"\n",
      "batch 6769  loss=152.2873  steps/s=103.72  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" asoai           ooo  oo  oonnnn  nn    \"\n",
      "batch 6770  loss=128.9134  steps/s=99.05  prediction: \"ers had a username but idk his name name\" => \"  o eteeee     r  e                     \"\n",
      "batch 6771  loss=142.7005  steps/s=100.51  prediction: \"ent in pygame and the network in pytorch\" => \" to e nnnnnn nnnn n   n  n      e       \"\n",
      "batch 6772  loss=149.1113  steps/s=105.41  prediction: \"usly gives API access, can also finetune\" => \"      ssssseessssss essssssss   ss  ss  \"\n",
      "batch 6773  loss=180.7860  steps/s=38.10  prediction: \"ly: @pepegawitch https://t.co/SATxjQ6nk5\" => \"y: e  iesseii ie    esssss  sc  ss  sn n\"\n",
      "batch 6774  loss=171.0310  steps/s=110.49  prediction: \"fects the rest of the day. Cheers brotha\" => \" nm   ttf  ttettetttt      e    e   ee e\"\n",
      "batch 6775  loss=126.1517  steps/s=28.94  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: @ tte ttee t t tt       ee  e      h\"\n",
      "batch 6776  loss=131.7465  steps/s=114.35  prediction: \"if you have enough courage to go for it.\" => \"n  oo                             oooooo\"\n",
      "batch 6777  loss=202.4396  steps/s=104.21  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \"0qoWzVTTTll00MMMMMMMMLMLL0LLL0000ttttttt\"\n",
      "batch 6778  loss=172.4584  steps/s=101.97  prediction: \"at's definitely part of the current meta\" => \"n aarr etedt ttte t ttet  t    t te   re\"\n",
      "batch 6779  loss=162.7683  steps/s=75.63  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \" w t   ddeie   e nt  ee   e  f r t    t \"\n",
      "batch 6780  loss=154.4030  steps/s=107.85  prediction: \"mirages keep getting crazier and crazier\" => \"azt @lu  i  eeeeeeeeeee eee  tr nna  aaa\"\n",
      "batch 6781  loss=161.1707  steps/s=103.89  prediction: \" goes over the massive 4096 token window\" => \"@rn ssssooo oooe   e   ee      e    e   \"\n",
      "batch 6782  loss=154.1957  steps/s=103.87  prediction: \"actually protects me from getting hacked\" => \"niya              t t         tt tt tt  \"\n",
      "batch 6783  loss=146.4499  steps/s=105.43  prediction: \"ney OR something extremely useful to you\" => \"dMto t                eeeeeeeeeeeeeeeeee\"\n",
      "batch 6785  loss=147.4759  steps/s=100.33  prediction: \" and realized idk what it actually means\" => \"tbtfif fff       dddddd      a   a  aaaa\"\n",
      "batch 6786  loss=227.6251  steps/s=22.14  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly: f f      dd dddddd      aa  a aaaaa\"\n",
      "batch 6787  loss=159.4683  steps/s=147.49  prediction: \"izmobly you have 3 days or youre blocked\" => \"n    f a       d   aa i         l  lllll\"\n",
      "batch 6788  loss=171.2439  steps/s=106.20  prediction: \"ped\n",
      "mean = 84.75 https://t.co/B3Ji1JkdXr\" => \"lre sl  e eeea  a e a  eep     tt////ttt\"\n",
      "batch 6789  loss=151.4841  steps/s=103.65  prediction: \"ses to use them, only uses open src ones\" => \"  bss ssseseseeese e ee e    e    e   s \"\n",
      "batch 6790  loss=147.4911  steps/s=104.74  prediction: \"iration theres some awesome ppl in there\" => \"n  w    ii iiiiii r r  e eeeseee eeeee e\"\n",
      "batch 6791  loss=138.1734  steps/s=104.21  prediction: \"and completely unknown to the other half\" => \"nd of    l lllllllll   nnnnnnn          \"\n",
      "batch 6793  loss=158.3105  steps/s=100.27  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "lh   eI|Mjá´„z_4@-v!!!__5@j#4\"\".@-.@M4\n",
      "?5\"\n",
      "batch 6794  loss=148.9675  steps/s=104.82  prediction: \"e context, like words, strengthen ideas?\" => \" c    o   o    t    e        e tetee eee\"\n",
      "batch 6795  loss=146.0742  steps/s=105.52  prediction: \"ion, which allows better problem solving\" => \"nn  teeeooooo  o oooo  o  o   t   e  ell\"\n",
      "batch 6796  loss=151.0643  steps/s=104.16  prediction: \"eting ppl on here\n",
      "\n",
      "the next half WE BALL\" => \" t  eeeeeeee   e  e    eeee ee e e    h \"\n",
      "batch 6797  loss=146.7149  steps/s=106.08  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \" ae aat         t    t ee    e    e  o  \"\n",
      "batch 6798  loss=152.8634  steps/s=103.03  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"nl   s  aa aa lllllllllllllltttt////////\"\n",
      "batch 6799  loss=178.2304  steps/s=44.77  prediction: \"y: @_diginova i served my time in x jail\" => \"  @sasaalllllllllllllll tt t////////5555\"\n",
      "batch 6800  loss=224.0185  steps/s=44.43  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: aaallllllllllllll  tt t//////555555\"\n",
      "batch 6801  loss=132.5249  steps/s=126.10  prediction: \"u can build in a week is actually insane\" => \" t ou   uuuu   n                        \"\n",
      "batch 6802  loss=153.6114  steps/s=105.72  prediction: \"usly gives API access, can also finetune\" => \"      esssseesssses essssesss a ss  css \"\n",
      "batch 6803  loss=149.2515  steps/s=100.64  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @51xðŸ“‰`BkðŸ’ªð—²JvzðŸ‘€`APPIbbAPI%,,x$Éª$,1)\"\n",
      "batch 6804  loss=305.0529  steps/s=10.93  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"eply: @51xá´˜QBk9fJvz.QAPPIbbAPIX,,xXXX,1)\"\n",
      "batch 6805  loss=141.3666  steps/s=136.52  prediction: \"nds like a super cool premise for a game\" => \"     re  s      u             o  o      \"\n",
      "batch 6806  loss=150.0345  steps/s=104.80  prediction: \"n run on my laptop, which I can do w ML?\" => \" tr HS?                                 \"\n",
      "batch 6807  loss=144.8594  steps/s=100.71  prediction: \"be setting a deadline might help as well\" => \"e k i          t    e           e       \"\n",
      "batch 6808  loss=157.2858  steps/s=99.66  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"     oetttrrtrrr rrr  ttttt   tt/tt////2\"\n",
      "batch 6809  loss=129.0131  steps/s=105.22  prediction: \"nd of mental ownership over the codebase\" => \"d i  a                           ee eeee\"\n",
      "batch 6811  loss=154.1884  steps/s=105.05  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"d as cr   e    e    e             r   r \"\n",
      "batch 6812  loss=156.5454  steps/s=105.80  prediction: \"would be insanely useful to do this with\" => \"hrdm  ieoooe    ee ie e uu uue      e   \"\n",
      "batch 6814  loss=158.7466  steps/s=102.98  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"    o   ............ o       o          \"\n",
      "batch 6815  loss=156.7247  steps/s=102.07  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @ a eeee     e         o  o         \"\n",
      "batch 6816  loss=144.7430  steps/s=101.75  prediction: \"be setting a deadline might help as well\" => \"e   i          t          i     e       \"\n",
      "batch 6817  loss=148.1932  steps/s=97.03  prediction: \"ts just showing you their main accts now\" => \"h nk a00t      s   i    i               \"\n",
      "batch 6818  loss=152.2117  steps/s=104.09  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"ey  d       eeeleeeeeee    e            \"\n",
      "batch 6819  loss=149.7049  steps/s=104.30  prediction: \"mething to run from (getting called out)\" => \"e es ve)eeetee  e   oo        g gg g g t\"\n",
      "batch 6820  loss=145.7420  steps/s=104.37  prediction: \"he thing, no? All you need is prediction\" => \"e g t     t                             \"\n",
      "batch 6821  loss=148.6058  steps/s=99.45  prediction: \"unday is a great sunday to write haskell\" => \" d                                 t    \"\n",
      "batch 6822  loss=147.9920  steps/s=104.27  prediction: \"c, just separated by some amount of time\" => \"h nkota,  ,t   s ta  teee  e        t   \"\n",
      "batch 6823  loss=184.7524  steps/s=44.22  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \"  @ae ,    ttatseta  aaee  e     o  t  o\"\n",
      "batch 6824  loss=149.9336  steps/s=103.19  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"tt  uuu   e    eeeee eeeeeeeeee eeeeeen \"\n",
      "batch 6825  loss=143.1170  steps/s=106.63  prediction: \"d luck to step on worms and they stopped\" => \" i   t         t                     t  \"\n",
      "batch 6826  loss=143.6971  steps/s=101.62  prediction: \"ly know how many angels fit on a pinhead\" => \"y: @I llll w    w    nn n    n          \"\n",
      "batch 6827  loss=156.2561  steps/s=101.70  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "pme  c,71jI,_4@zf,IOW7W7j*xI==O,C==C\n",
      "CC\"\n",
      "batch 6828  loss=150.8618  steps/s=104.08  prediction: \"ing vidya except w only positive effects\" => \"ng l ii  iiiiii                    e ee \"\n",
      "batch 6829  loss=167.2962  steps/s=103.38  prediction: \"is not true loss https://t.co/VvtOa0Aau2\" => \"n  \n",
      "  o ooss s esossssssstttts////t //tt\"\n",
      "batch 6830  loss=152.5228  steps/s=104.09  prediction: \"ou get faster and faster at solving them\" => \"             t      t   a    a a  a     \"\n",
      "batch 6831  loss=145.1795  steps/s=102.81  prediction: \"engthen the habit over reps\n",
      "Cool thought\" => \"  ioe tt teteehthhh t hehe e  eeee  o oo\"\n",
      "batch 6832  loss=150.3128  steps/s=102.22  prediction: \"on the manager/grifter/sociopath problem\" => \"ue e  ooo  o   ee eeer ererrrrerrrrrtrrr\"\n",
      "batch 6833  loss=176.3944  steps/s=103.89  prediction: \"ful to me, like use every day type stuff\" => \" c   o    e  u l e    eee e   eeeee yy  \"\n",
      "batch 6834  loss=150.0063  steps/s=102.17  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"   s ha e eeeeieeieeeiiieeeee  eee e eee\"\n",
      "batch 6835  loss=142.4157  steps/s=83.77  prediction: \"nes @micsolana same for my history class\" => \"   eeos sssnsssaaaaaaa ae  e         y  \"\n",
      "batch 6836  loss=140.8336  steps/s=105.94  prediction: \"ressures me to say things I dont believe\" => \"epl l @fá´›wy]~â€æˆ‘1á´˜@xÊœ$ZZZá´›Iá´èµ°já´‡$|wj`3$á´€,x\"\n",
      "batch 6837  loss=225.7696  steps/s=21.11  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly:   t  e  e   s       ss             \"\n",
      "batch 6838  loss=174.4236  steps/s=103.49  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y  @bart  e ee s s    s sss            e\"\n",
      "batch 6839  loss=158.5536  steps/s=114.17  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"@romooooollloole  ll  o o             o \"\n",
      "batch 6841  loss=143.7483  steps/s=99.64  prediction: \"n to achieve an awesome long term vision\" => \" t ovm  aaaaa  aaaaaa  e e eee eeee e   \"\n",
      "batch 6842  loss=160.2888  steps/s=102.68  prediction: \"meone should make a zig finetune dataset\" => \"eae  l o oo oooooo                   ee \"\n",
      "batch 6843  loss=147.8547  steps/s=100.82  prediction: \" to make it better before (if) I release\" => \"@he neeeee   e  e  e e  ee ee eee  ee ee\"\n",
      "batch 6844  loss=144.9790  steps/s=102.61  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to be              sssss               \"\n",
      "batch 6845  loss=149.1048  steps/s=104.10  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"the\n",
      "t tt t  i  t  t tthhttttttt////ttoot\"\n",
      "batch 6846  loss=134.1351  steps/s=104.13  prediction: \"en get way too absorbed into one of them\" => \"   o           t      ooo oooooooooooooo\"\n",
      "batch 6847  loss=134.5511  steps/s=96.40  prediction: \"if you say wala a lot are you a walawala\" => \"n               aaaaaaaaa aa          a \"\n",
      "batch 6848  loss=150.2833  steps/s=105.65  prediction: \"ng game becomes abt strategizing aroundâ€¦\" => \"g   o og g    gg  e    e  ettttttaaaaaa \"\n",
      "batch 6849  loss=180.9100  steps/s=100.91  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:      p         0 000   ttttt/t//t///\"\n",
      "batch 6850  loss=146.7281  steps/s=104.88  prediction: \"now unless i need to paste in huge files\" => \"gw fmm  ss  ssss  s          e        ee\"\n",
      "batch 6851  loss=150.8057  steps/s=94.99  prediction: \"builds It is factually what plants crave\" => \"etls  sbb s              t              \"\n",
      "batch 6852  loss=155.8863  steps/s=105.55  prediction: \" right now its just learning on the side\" => \"ter r                   t   t    nn     \"\n",
      "batch 6853  loss=162.2169  steps/s=104.19  prediction: \"ks.. 90% correct https://t.co/t9unPUcvje\" => \"  o         or  rrr c r rot ctt/tt/c//tc\"\n",
      "batch 6854  loss=163.0870  steps/s=102.58  prediction: \"i it does look super nice, was gonna say\" => \"nm   @a a    i    o     o               \"\n",
      "batch 6855  loss=173.2092  steps/s=103.96  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"rn rneaaaaa##aaena  nnnnn tnnnsttttt///t\"\n",
      "batch 6856  loss=148.9455  steps/s=99.85  prediction: \" said it was his last email, he meant it\" => \"@teehe  h e  i      ss   s   s    a a   \"\n",
      "batch 6857  loss=150.7216  steps/s=103.58  prediction: \" wasnt paying attention during that part\" => \"taat          a  a a tt ntt nttnnnnnttt \"\n",
      "batch 6859  loss=148.8698  steps/s=104.65  prediction: \"ng them as irrational, then assigning 0â€¦\" => \"   raoigggg  i   ii iiiiia  aaaiaaaninin\"\n",
      "batch 6860  loss=148.2233  steps/s=103.81  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t  k a   r r   r     p   o   o  o    t  \"\n",
      "batch 6861  loss=150.8975  steps/s=110.57  prediction: \"mcignore feature https://t.co/oLseuf2uxS\" => \"aats    o o         e tt ttttteettttt///\"\n",
      "batch 6862  loss=142.3432  steps/s=105.16  prediction: \"people, i just post a weird mix of stuff\" => \"lrb    oo                               \"\n",
      "batch 6863  loss=152.4446  steps/s=100.33  prediction: \"reat book, glad youre enjoying it so far\" => \"ep y: @fv{{.=07(I==w@=1===T0==T0Ib:TbIv}\"\n",
      "batch 6864  loss=146.9094  steps/s=105.29  prediction: \"y areas of corporate world it seems like\" => \" a ann  a   aa aa  arroororr rr e       \"\n",
      "batch 6865  loss=144.4412  steps/s=105.15  prediction: \" tons of stuff, for yrs, and that worked\" => \"thit     t     s    ffff fff            \"\n",
      "batch 6866  loss=148.2007  steps/s=103.48  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"eing  hm{w}}?}L@jI}}{=&}IIj}^{}{}=&}};v{\"\n",
      "batch 6867  loss=149.1321  steps/s=103.38  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"r  p et  e         e eeeeeeeeeeeeeeeeeee\"\n",
      "batch 6868  loss=165.6834  steps/s=103.56  prediction: \"ve feedback loop\n",
      "https://t.co/MlojgQGjx4\" => \"e uo eeeeee eeo e eeoopppoptpp///tp////o\"\n",
      "batch 6869  loss=141.3054  steps/s=102.55  prediction: \" put you so far ahead its not even funny\" => \"to lwol   o    l                        \"\n",
      "batch 6870  loss=150.7354  steps/s=103.29  prediction: \" monday\n",
      "\n",
      "5am (your timezone) is best imo\" => \"tyn s  a      ayyyyyy y yo oo  m   o  o \"\n",
      "batch 6871  loss=130.0528  steps/s=101.78  prediction: \"lms\n",
      "and lots and lots of trial and error\" => \"y  @ non llln     n      l              \"\n",
      "batch 6872  loss=152.1339  steps/s=102.11  prediction: \" btw? or does onnx just work well enough\" => \"tateannt    t  n    o    o    o         \"\n",
      "batch 6873  loss=302.8655  steps/s=11.17  prediction: \"reply: @esiarpze its good to be back man\" => \"epl   hBk5=x=(TB5@@1(#vz##j)#?zk:I)-.;:v\"\n",
      "batch 6874  loss=144.9949  steps/s=107.73  prediction: \" about it and in 1 weekend jumped up 200\" => \"t aean   a  a                e     eee e\"\n",
      "batch 6875  loss=144.8920  steps/s=103.57  prediction: \"aking a day off caffeine helped fix this\" => \"re n ltllaa aa aaa  aafaaff fffffe ffe  \"\n",
      "batch 6876  loss=141.1933  steps/s=103.89  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in i          n n    n  n     nnn      \"\n",
      "batch 6877  loss=146.2595  steps/s=100.26  prediction: \" The fundamentals contain the most alpha\" => \"thn    AAA      nnnnnnnnaannn nn        \"\n",
      "batch 6878  loss=220.1617  steps/s=20.66  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly: @ A        nnnnnaanannnn           \"\n",
      "batch 6879  loss=191.7732  steps/s=56.96  prediction: \"ply: @Wooltard @eigenrobot Poor things ðŸ˜¢\" => \"ly: @laP       nnnnnnaanannnn           \"\n",
      "batch 6880  loss=130.7232  steps/s=130.85  prediction: \" of the tier lists of all time, for sure\" => \"tf    oo  eee  e  e   t                 \"\n",
      "batch 6881  loss=151.9891  steps/s=103.14  prediction: \"your .env and fill it out\n",
      "\n",
      "then it works\" => \":u ao n   n   nn   n             t    tt\"\n",
      "batch 6882  loss=163.8387  steps/s=66.83  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ust -eee                   tt     t   oo\"\n",
      "batch 6883  loss=153.1243  steps/s=105.89  prediction: \" drains your energy by paying attentionâ€¦\" => \"teat ta   i    r      yyyyyyyy yy y   nn\"\n",
      "batch 6884  loss=133.7948  steps/s=102.49  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"thi               ppppppp               \"\n",
      "batch 6885  loss=146.4326  steps/s=104.32  prediction: \" what to do next. i want to do my own tâ€¦\" => \"tou d     o    o  o        t t       o  \"\n",
      "batch 6886  loss=164.6557  steps/s=97.73  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n                     attttttttttt//////\"\n",
      "batch 6887  loss=143.5422  steps/s=104.95  prediction: \"pick any domain/topic there are usuallyâ€¦\" => \"lxt do         n     i  iio i i   e   a \"\n",
      "batch 6888  loss=159.0706  steps/s=105.64  prediction: \" 10% is figuring out a fix + applying it\" => \"t0eeee    e  i  ii       ii  i       i  \"\n",
      "batch 6889  loss=213.6057  steps/s=89.49  prediction: \"icCapital COMMENCE OPERATION BRAIN DRAIN\" => \"necThe riiiCiii i   OEE E EE ORR NNINN R\"\n",
      "batch 6890  loss=148.8444  steps/s=104.97  prediction: \"has any non-json, ask for json in prompt\" => \"et  oi          nnn nnn                 \"\n",
      "batch 6891  loss=142.4814  steps/s=104.20  prediction: \" regarded so take that w a grain of salt\" => \"teee  ii    ie       ee aa   aa   aaa  a\"\n",
      "batch 6892  loss=157.2044  steps/s=103.28  prediction: \"100x bigger than the others\n",
      "\n",
      "I dunno lol\" => \"  h nae0 0      0    g      hh   h   e  \"\n",
      "batch 6893  loss=154.7440  steps/s=102.15  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"eploy  f3jMTB_UE21UWx!b)!qTB!@E(kxZyZ1Zk\"\n",
      "batch 6894  loss=150.4057  steps/s=104.05  prediction: \"on chunking showed higher level playersâ€¦\" => \"n e  s       n      hhhhhh hhhhh eeeee e\"\n",
      "batch 6895  loss=151.7950  steps/s=104.43  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lo  @e     bbbbbbbb bbbb                \"\n",
      "batch 6896  loss=153.6957  steps/s=103.23  prediction: \"my camera by accident so maybe thats why\" => \"e tai i e me     aa aa      a a  a     a\"\n",
      "batch 6897  loss=145.8771  steps/s=104.74  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"  eit          a               /////////\"\n",
      "batch 6898  loss=187.8459  steps/s=103.64  prediction: \"luffyb Xorswap, what a username, love it\" => \"yd @s7x11110ffff f    w    a  aaa aaa   \"\n",
      "batch 6899  loss=145.3620  steps/s=101.10  prediction: \"hnote uuuh i have a license for thse sir\" => \"ea e_ s      u  hu           e    eeeeee\"\n",
      "batch 6900  loss=139.7962  steps/s=104.45  prediction: \"miliar with a place and the things in jt\" => \"enioa iiiiii iiiii aaa aaaa  a          \"\n",
      "batch 6901  loss=219.9611  steps/s=101.76  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"E fGisONEEEEETTTATETT O     tttt ////tt/\"\n",
      "batch 6902  loss=157.5412  steps/s=103.25  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \":tito it titttiiiittt  ts  sa s s  aa   \"\n",
      "batch 6904  loss=145.8000  steps/s=103.50  prediction: \"e right things really really does matter\" => \" mstee tt  tttt   t      r ll  llll   ll\"\n",
      "batch 6905  loss=135.4506  steps/s=102.45  prediction: \"he audiobook content is better than both\" => \"e   t  ttuuooooooooooooooottttttttttt tt\"\n",
      "batch 6906  loss=142.3426  steps/s=102.87  prediction: \"conflicting values it would be a paradox\" => \"tnveo illllllllllllliii  i              \"\n",
      "batch 6908  loss=148.0761  steps/s=104.05  prediction: \"nts also on the nm level, but, 3d not 2d\" => \"tio  p  nnonnn nn                       \"\n",
      "batch 6910  loss=151.8430  steps/s=103.15  prediction: \"many roadblocks trying to automate stuff\" => \"en sie        or  oooooo    oo oott tttt\"\n",
      "batch 6911  loss=146.2759  steps/s=104.78  prediction: \"ng i correctly understood what you meant\" => \"t bo 't isss   n    ir         oooo oo  \"\n",
      "batch 6912  loss=205.7620  steps/s=99.16  prediction: \"1 AAAAAA MY EYES https://t.co/r2a6f3Rhs7\" => \" @    eAeAAAAAAAAAA YYYYY E  ttttttt////\"\n",
      "batch 6913  loss=186.8370  steps/s=80.40  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \" eii @ArA     E     t t   t /tt/t tRRRRðŸ›‘\"\n",
      "batch 6914  loss=146.2317  steps/s=104.51  prediction: \" in the post, only read the abstract tho\" => \"tn                                    tt\"\n",
      "batch 6915  loss=148.3077  steps/s=104.45  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efe t  gCN(Ov85@7AYAxxw\"/C\"\n",
      "OOvY.EYESzz!\"\n",
      "batch 6916  loss=168.7351  steps/s=103.34  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"ebo i  fMð˜Sá´›É´0Éª217ðŸ¤”9]$6CM*SRR65217ðŸ‘9ð—»á´‡VC\"\n",
      "batch 6917  loss=158.7596  steps/s=58.90  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"@Mas mmmmmm   oo          a ooa a  a aaa\"\n",
      "batch 6918  loss=146.9827  steps/s=105.46  prediction: \"just point to concepts and arent reality\" => \"ust     s      t   o     t  tnn    nnn t\"\n",
      "batch 6919  loss=160.8349  steps/s=101.91  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tude           n         /////t//////tts\"\n",
      "batch 6920  loss=146.9130  steps/s=103.12  prediction: \"rap out of them\n",
      "\n",
      "dont worship complexity\" => \"eciy  @g%XXXXXX/G1UzXXXX?v2X'k?GPU?F0%?J\"\n",
      "batch 6921  loss=137.4120  steps/s=102.17  prediction: \"often to be random chance\n",
      "\n",
      "i love it tbh\" => \"n h t oo  o o   o         n  n          \"\n",
      "batch 6923  loss=172.5133  steps/s=83.70  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"eply: @g%vFFF_FjG1UzWWW5Wv2F'kbMuU5x0%ðŸ˜¢ðŸ˜¢\"\n",
      "batch 6924  loss=159.1556  steps/s=103.84  prediction: \"izer\n",
      "\n",
      "his uses a NN this uses Q learning\" => \"n  hu       ss sssss ss N s sssss   ss  \"\n",
      "batch 6925  loss=147.3495  steps/s=100.97  prediction: \"y areas of corporate world it seems like\" => \":aonnn  a   aa aa  rrroororr rr e       \"\n",
      "batch 6926  loss=150.2844  steps/s=103.65  prediction: \"xperience that will make me live longer)\" => \" li     eeeeeeeeeeeee e             llll\"\n",
      "batch 6927  loss=186.6562  steps/s=99.55  prediction: \"________11hz togglesite is super helpful\" => \"_i__________________11111      e  eeee e\"\n",
      "batch 6928  loss=149.3617  steps/s=98.58  prediction: \"ot of politics is reinforcement learning\" => \"nteo ooooo  oo  o oiii iiii ieiee ereeen\"\n",
      "batch 6930  loss=155.4471  steps/s=104.37  prediction: \"r time your focus muscle will strengthen\" => \"eotrg th_w__O__@O____k____Of(@@/km/(y1Ov\"\n",
      "batch 6931  loss=143.6317  steps/s=104.79  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i s                     t  tteeetdtttt\"\n",
      "batch 6932  loss=138.0241  steps/s=105.52  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \"se te t  t    t  t  t t          u   u  \"\n",
      "batch 6933  loss=138.3491  steps/s=102.54  prediction: \" have another tweet promoting AB testing\" => \"text             e  eeeeeettttettttttttt\"\n",
      "batch 6934  loss=155.0213  steps/s=100.14  prediction: \"em man, I had to share, its a crazy tool\" => \"  oc    o          a      a   a       a \"\n",
      "batch 6935  loss=145.9480  steps/s=105.58  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r t id       ii siiississssstst////////\"\n",
      "batch 6936  loss=178.2328  steps/s=101.48  prediction: \".03$ a day you can help a webdev in need\" => \" ho        0                           e\"\n",
      "batch 6937  loss=162.6019  steps/s=98.89  prediction: \"ode Solidworks\n",
      "$500/yr aint gonna cut it\" => \"r  t   dd ddddoo    o0000000000  nnnnnnn\"\n",
      "batch 6939  loss=140.4130  steps/s=103.94  prediction: \"people, i just post a weird mix of stuff\" => \"lr:  s  o                               \"\n",
      "batch 6940  loss=136.4917  steps/s=99.04  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" ait  taaaa    eeeee                    \"\n",
      "batch 6941  loss=151.7373  steps/s=103.96  prediction: \"igABAP Born to consoom, forced to signal\" => \"tA th e           o   oo oo oo  rrrruuuu\"\n",
      "batch 6942  loss=148.8818  steps/s=105.04  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "ee  aaw+*[]Ê€ðŸ‘`@g^Ê€á´€*Z|_][QðŸš€QZðŸ˜***[*`-'*\"\n",
      "batch 6943  loss=142.5814  steps/s=104.62  prediction: \"oud to yourself, or in your imagination)\" => \"  e oo o oooo oo o ooo  o  o  o    r i  \"\n",
      "batch 6944  loss=156.8941  steps/s=103.08  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"totltt  lll  e e      tt ttttttt////////\"\n",
      "batch 6945  loss=172.3701  steps/s=86.14  prediction: \"dup QUICK do something that doesnt scale\" => \" tta tee e          tttttttt/ttththtt ll\"\n",
      "batch 6946  loss=147.3493  steps/s=106.47  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"ll:  mp   pppe    e       e  eeeeeee a  \"\n",
      "batch 6947  loss=155.1031  steps/s=101.38  prediction: \" could you tell\" https://t.co/968GsOvdfW\" => \"tae                           tt////////\"\n",
      "batch 6948  loss=169.6065  steps/s=97.21  prediction: \" was truly L tier. not L tier but L tier\" => \"thu    o   o   l   ttt t LLLLLLt  ttLLLL\"\n",
      "batch 6949  loss=151.3319  steps/s=94.14  prediction: \"MTB theyre in the arena, fighting things\" => \"iB w o t   e   er      t      t    ti tt\"\n",
      "batch 6950  loss=140.7918  steps/s=102.33  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tr  hn                      tttttt//////\"\n",
      "batch 6952  loss=145.5176  steps/s=105.38  prediction: \"d its helped man. i shpuld sleep too lol\" => \" i n    aa       d              lplp    \"\n",
      "batch 6953  loss=150.6788  steps/s=101.42  prediction: \"output less verbose/convoluted solutions\" => \"   s  ttte ttt    ess eeeooeeeoooeeoseoo\"\n",
      "batch 6954  loss=164.8062  steps/s=103.67  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"/h.c tt///////ttttQtttptttttt///////////\"\n",
      "batch 6955  loss=154.0428  steps/s=101.72  prediction: \"nds like a super cool premise for a game\" => \"   ettssssssss         p    p oorro oo  \"\n",
      "batch 6956  loss=135.5871  steps/s=102.38  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" is  s     mmmmmmmmmmemmmeeeee    e  ooo\"\n",
      "batch 6957  loss=137.6874  steps/s=104.69  prediction: \"dit on my phone)\n",
      "https://t.co/iWZ4An9PaZ\" => \" t  o                 ttttttttttttttt///\"\n",
      "batch 6958  loss=142.0431  steps/s=97.94  prediction: \"er this applies outside of chess as well\" => \"   e  tttttt   n t ppppptttoooosss   sss\"\n",
      "batch 6959  loss=145.6508  steps/s=104.31  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd t ddaaaaaanaaaanaaeeeeee ee eeeee eee\"\n",
      "batch 6960  loss=133.8541  steps/s=103.01  prediction: \"en get way too absorbed into one of them\" => \"               t      ooo oooooooooooooo\"\n",
      "batch 6961  loss=149.0257  steps/s=102.95  prediction: \"ld almost suspect God is on their side..\" => \"y g dudo   os s sssssss   s             \"\n",
      "batch 6962  loss=157.0223  steps/s=91.70  prediction: \"gABAP why?? cause its fun and i like fun\" => \"eBo   ud         ???   s             ii \"\n",
      "batch 6963  loss=145.3634  steps/s=102.83  prediction: \"tournaments, etc\n",
      "https://t.co/JA1SHygLtH\" => \"  tny n   aaat ettetttttttttttttttttt/tt\"\n",
      "batch 6964  loss=147.0535  steps/s=104.55  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \"oi            en  e     e      e       a\"\n",
      "batch 6965  loss=146.5244  steps/s=105.68  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"yce \n",
      "sn t      e     n    t   ttttt////G\"\n",
      "batch 6966  loss=149.5570  steps/s=102.96  prediction: \"s some cool shit https://t.co/Vo4w9BcSQZ\" => \" a roo o ooooo   oo   o  t tt /tt/tt////\"\n",
      "batch 6967  loss=142.2821  steps/s=103.01  prediction: \"hinks he might pick up in future decades\" => \"en  i ii h hhhhhh    i                  \"\n",
      "batch 6968  loss=141.3530  steps/s=104.21  prediction: \"ntelligence\" + related learning concepts\" => \" \n",
      " si oeiieieie ee eeleelee eeeleeennnen\"\n",
      "batch 6970  loss=160.0754  steps/s=102.13  prediction: \"bly helps that they have a faster ai now\" => \"ee o  bbbblblllh hhl  h h hh h h  aaa   \"\n",
      "batch 6971  loss=152.4985  steps/s=103.84  prediction: \"n=1)\n",
      "2 their goals are their vidya (n=2)\" => \"  h i 111  1e  r e er    r     r   r    \"\n",
      "batch 6972  loss=154.1850  steps/s=74.43  prediction: \"eCachet Consistency is a deadly strategy\" => \" ueen  ehee e  n s ae    a    ade   a  a\"\n",
      "batch 6973  loss=153.7144  steps/s=105.67  prediction: \"k the same amount but on their own stuff\" => \"eyp r  e   ee   e    e      t   t  o   t\"\n",
      "batch 6975  loss=129.5259  steps/s=104.13  prediction: \" local optima solution they got stuck in\" => \"titt tt        t   oooooooooooooottttttt\"\n",
      "batch 6976  loss=334.0114  steps/s=10.93  prediction: \"reply: @0xVonNeumann Love it! Cheers bro\" => \"eply  tr9Vð—°]*ðŸ˜É´Jâ€œ[Ê€Ê€|]**â€*[!*]É´***â€™â€Êœâ™‚|$\"\n",
      "batch 6977  loss=151.3423  steps/s=106.70  prediction: \" strategy is short term low integrity BS\" => \"too  es   s    ssss ss        t  t t trt\"\n",
      "batch 6978  loss=140.4893  steps/s=105.43  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" thee    eeee ee    e                   \"\n",
      "batch 6979  loss=141.6754  steps/s=104.17  prediction: \"en hook it up to a domain and everything\" => \" to    eee   eo    o  o o          a a  \"\n",
      "batch 6980  loss=168.6692  steps/s=107.24  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"leypn__@akakaaa aataa a    i  e ee eeeee\"\n",
      "batch 6981  loss=149.1474  steps/s=105.34  prediction: \"l amazing, do what you like least, first\" => \"ywenda \n",
      "e  e  a aa  a    a       l      \"\n",
      "batch 6982  loss=160.6106  steps/s=71.23  prediction: \"koslib Also just saw the Eu/acc, respect\" => \" r\n",
      "a aaal       a   a        e  ,,a,,  e\"\n",
      "batch 6983  loss=138.9481  steps/s=107.45  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \" le       eeeeen    e     e     e  e   e\"\n",
      "batch 6984  loss=139.4921  steps/s=105.69  prediction: \"your life (which is what happened to me)\" => \" ur e    ly  l         ii       hhh   h \"\n",
      "batch 6985  loss=144.1123  steps/s=105.18  prediction: \"to the planning phase with more momentum\" => \"h a ea         nn nnnnnn              mm\"\n",
      "batch 6986  loss=336.2571  steps/s=11.70  prediction: \"reply: @kubeden Id be down in the future\" => \"e oe  @wWÉªIÊŸ[ðŸ˜`@vj*m|k^]x/]*É´*æˆ‘ðŸ¤”1*x/ðŸ˜¤[*ÊŸ\"\n",
      "batch 6987  loss=143.0067  steps/s=112.35  prediction: \"ce for an american traveling there soon?\" => \"a s it       aa aaaa aaaaaaaaaa neeeeeee\"\n",
      "batch 6988  loss=164.5535  steps/s=106.55  prediction: \"ded techniques too, lmk if you know more\" => \" reee  ee  eeeeeddeeeeeee      o  o    o\"\n",
      "batch 6989  loss=144.9776  steps/s=105.01  prediction: \"eet you can do some crazy things in life\" => \" p e                 o                  \"\n",
      "batch 6990  loss=161.1751  steps/s=105.74  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`W0 ce  []]]]1]1    ,                 e \"\n",
      "batch 6991  loss=148.1556  steps/s=103.37  prediction: \"e walking through a memory palace maybe)\" => \" d  l      l               o m     aaa a\"\n",
      "batch 6992  loss=140.5147  steps/s=100.48  prediction: \"ive sum game players\n",
      "tautologically true\" => \"ne  b i  i     t           eeaaaalllllal\"\n",
      "batch 6993  loss=152.2987  steps/s=65.29  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tyte ii   e      ee eeaattutteaalllllatl\"\n",
      "batch 6994  loss=147.9883  steps/s=116.90  prediction: \"tloader ah another tool builder, love it\" => \"hy  neoottoo ooooooooootootooo   oo o l \"\n",
      "batch 6995  loss=271.7275  steps/s=11.19  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eply: @WIz:]3=3)Aj@:_)/,3v%325?)?/]]x)--\"\n",
      "batch 6996  loss=175.9287  steps/s=174.90  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \"hp  nsttteaa  aaaa ttttt tttto  ///ooooo\"\n",
      "batch 6997  loss=144.8075  steps/s=104.22  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"nldnt htttttt  t tttttttstttttttt///////\"\n",
      "batch 6998  loss=174.8244  steps/s=53.46  prediction: \": @0x77er some likes are worth 100 likes\" => \" @Buxl      ts  elttssststtt/////////llt\"\n",
      "batch 6999  loss=146.3246  steps/s=107.41  prediction: \"uch  there would be to take into account\" => \"nh nn  h    hh                      t   \"\n",
      "batch 7000  loss=144.7341  steps/s=106.13  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \" es     00      000000000               \"\n",
      "batch 7001  loss=145.2778  steps/s=98.79  prediction: \" What are your personal long term games?\" => \"tovd  haaaaaaaa    rrrrrrroooo   o      \"\n",
      "batch 7002  loss=164.5663  steps/s=102.55  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"s.cc tt/////////ttQtttpttttt////////////\"\n",
      "batch 7003  loss=182.7231  steps/s=98.44  prediction: \"ost valuable RESOURCE\n",
      "\n",
      "damn i need sleep\" => \"ut orto   t uu o   R RRRREREEE E C  nn n\"\n",
      "batch 7004  loss=163.1611  steps/s=47.92  prediction: \"y: @melqtx every mon and thurs ma brotha\" => \": @lr o   t  uuo RRREEREEE a   a m  ne n\"\n",
      "batch 7005  loss=149.9045  steps/s=112.66  prediction: \"nt and then generate a new one each time\" => \" ett  e   e  n nnneneee neeeneeee e ee e\"\n",
      "batch 7006  loss=150.4812  steps/s=100.96  prediction: \" people who find their work fun win more\" => \"tree r e e h   ho     h  h o     w  w w \"\n",
      "batch 7007  loss=135.4263  steps/s=102.71  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"ne            ee  eeeee      e e   e    \"\n",
      "batch 7008  loss=145.2491  steps/s=103.52  prediction: \"our sword and over time makes you deadly\" => \"u in              r    r              e \"\n",
      "batch 7010  loss=132.9146  steps/s=99.39  prediction: \"ood at noticing things, would be so kino\" => \"ul  t tt ttt  tttttttiiiigii            \"\n",
      "batch 7011  loss=134.1807  steps/s=105.90  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"the  t       t t                        \"\n",
      "batch 7012  loss=152.8346  steps/s=102.78  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"ou d t                     ttttttt///t//\"\n",
      "batch 7014  loss=160.7455  steps/s=105.09  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \"uedrr\n",
      "\n",
      "a\n",
      "\n",
      "a\n",
      "ioa aalallllllllllct/ct/t///\"\n",
      "batch 7015  loss=154.0208  steps/s=103.74  prediction: \"nce I did one in django I perma switched\" => \"ge\n",
      "\n",
      "r    e                 n      n     \"\n",
      "batch 7016  loss=139.7020  steps/s=97.93  prediction: \"yb is this founder mode or manager mode?\" => \" eo  c             nnn oo           aaae\"\n",
      "batch 7017  loss=212.4783  steps/s=21.35  prediction: \"eply: @BuxdahMo its not the real discord\" => \" ly: @         n   ndd oo      m    meae\"\n",
      "batch 7018  loss=175.5433  steps/s=106.78  prediction: \"ful to me, like use every day type stuff\" => \" l h  l   e  l l e    eee e   eeeey yy  \"\n",
      "batch 7019  loss=144.0182  steps/s=101.20  prediction: \"ns\n",
      "you me and andrew, that was super fun\" => \"   eeesosoossoos   o      d            a\"\n",
      "batch 7020  loss=176.6258  steps/s=98.88  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" rdedi-;ggg;ggtgtg\n",
      " r\n",
      "\n",
      "\n",
      "rfffoooooo   o  \"\n",
      "batch 7021  loss=146.8706  steps/s=105.37  prediction: \" can instantly runit w the runit command\" => \"to  s   n   n n nnnn n t t   t          \"\n",
      "batch 7023  loss=156.9532  steps/s=100.83  prediction: \"a, thats super coool!!!!! how did it go?\" => \"n  e   hhhts ss s s     !!!!!!!!!!o oo  \"\n",
      "batch 7024  loss=250.2772  steps/s=11.20  prediction: \"reply: @0xluffyb https://t.co/Qs8R6GnjEa\" => \"eply:  fxqq+$x$!@GGWG44,IbG~III8GWG;j,~G\"\n",
      "batch 7025  loss=141.2746  steps/s=110.95  prediction: \"eal interview round, not as a standalone\" => \" liias    e eeeneeeeee  n             aa\"\n",
      "batch 7026  loss=153.6911  steps/s=102.79  prediction: \"ugh or is it just whatever comes to mind\" => \"se  o oorrr o  o  i     t tt   t t  t   \"\n",
      "batch 7027  loss=151.9410  steps/s=104.43  prediction: \" an api, if so I could make one on there\" => \"t chaas      aa                         \"\n",
      "batch 7028  loss=157.0468  steps/s=104.25  prediction: \"ways but in many cases it holds you back\" => \"oste    l   a      a   a  a             \"\n",
      "batch 7029  loss=153.6710  steps/s=104.10  prediction: \"cipe for less funny + fake feeling posts\" => \"hnloseseeeeeee s    e          fffffee  \"\n",
      "batch 7031  loss=155.3286  steps/s=104.08  prediction: \"ks for me though. Carbs make me sluggish\" => \"i g eee    e              r          e  \"\n",
      "batch 7032  loss=156.2051  steps/s=104.10  prediction: \"ay simpler, but also much more effective\" => \"n  o  n        p                       e\"\n",
      "batch 7033  loss=166.2835  steps/s=99.71  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \"op ri l    \"\"\"\"e   tttttttttttt/////////\"\n",
      "batch 7034  loss=165.2495  steps/s=98.93  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"moblA aamme eeen  onoooeeeeeeee\"\"\"\"\"e\"e\"\"\n",
      "batch 7035  loss=154.3958  steps/s=89.02  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @ azioinnnnnnnnneee eeeeeee       o o\"\n",
      "batch 7036  loss=150.4763  steps/s=104.78  prediction: \"er useful building block to get good at.\" => \"       u   uuuuu uuu ul ll              \"\n",
      "batch 7037  loss=139.4913  steps/s=72.02  prediction: \"sunsettler hes locked in to the outdoors\" => \" p   uuu  eull     lll         t  oooooo\"\n",
      "batch 7038  loss=136.2689  steps/s=105.72  prediction: \"s using techniques right under our noses\" => \" oo  o     o   s n      iiiuu  uu u     \"\n",
      "batch 7039  loss=207.2092  steps/s=36.52  prediction: \"ly: @I_Like_Buttes @opaeoh CANT TOUCH ME\" => \"y: s o o   n nuesss iii u   u  u uu     \"\n",
      "batch 7040  loss=145.2092  steps/s=111.23  prediction: \" i found it really hard for some things.\" => \"@n  iiiiii                              \"\n",
      "batch 7041  loss=155.8755  steps/s=102.87  prediction: \"stone cpus in it https://t.co/UsFG7LjU6T\" => \"  n    e ennn  en  e      t t t tttt////\"\n",
      "batch 7042  loss=145.4155  steps/s=103.41  prediction: \"e tbh\n",
      "My projects arent that big yet tho\" => \" ce ceeeeeeeee ee ee ee te t ttttttttt  \"\n",
      "batch 7043  loss=180.3381  steps/s=97.25  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" teu ueenrrnneee   ett  htttht//ttt/////\"\n",
      "batch 7044  loss=155.5286  steps/s=103.75  prediction: \" an extremely powerful idea when applied\" => \"tn  re is ts set   eee e   e eee  e    e\"\n",
      "batch 7045  loss=170.8928  steps/s=75.02  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"n  oe  as  s   t  teee  lt e eee  pppiie\"\n",
      "batch 7047  loss=155.8561  steps/s=107.47  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"@heer     t   e    h tttttttttt/o////oo/\"\n",
      "batch 7048  loss=139.4017  steps/s=102.06  prediction: \"e latent space of \"make things ppl want\"\" => \" aft  tt  tt t t  t     e        e     p\"\n",
      "batch 7049  loss=149.7854  steps/s=104.90  prediction: \"ift camera to dogs perspective = dataset\" => \"n ont tt    t  t            e    ee  e  \"\n",
      "batch 7050  loss=184.1706  steps/s=31.98  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly: @e&     t               eeee ee  e t\"\n",
      "batch 7051  loss=142.5473  steps/s=107.45  prediction: \"it got like 2x fps rendering ocean waves\" => \"n  w                       e  e e  eeeee\"\n",
      "batch 7052  loss=149.0398  steps/s=103.31  prediction: \"l significantly shoot ahead towards them\" => \"yt iaeoi  ii iili ii i i     aaaaaaa aa \"\n",
      "batch 7053  loss=153.2953  steps/s=105.37  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u c                    tttttttttt///////\"\n",
      "batch 7054  loss=134.7634  steps/s=104.68  prediction: \"vision how great itll be once youre done\" => \"edthe                                  e\"\n",
      "batch 7055  loss=148.2802  steps/s=104.57  prediction: \"/t.co/emubOEhMKJ https://t.co/Fxx5eUVcPp\" => \"tonc ctt////t////ttttttt//////tt////t///\"\n",
      "batch 7056  loss=148.9108  steps/s=104.86  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng io i  i id n  dd dddd ddd d d        \"\n",
      "batch 7057  loss=158.2609  steps/s=100.57  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  o rooeeeeeedeeeoeeett tttt tttt       \"\n",
      "batch 7058  loss=134.2251  steps/s=104.91  prediction: \"y laptop and hope the bits line up right\" => \" b j a                                  \"\n",
      "batch 7059  loss=146.8470  steps/s=104.26  prediction: \"w. Might do one every mon and every tues\" => \"i de  oo oo oooroo  o  o   o        eee \"\n",
      "batch 7060  loss=154.1861  steps/s=103.15  prediction: \"se and 'magically' econ makes more sense\" => \" t x    e     aaaaaaaaa  a   aaa      ee\"\n",
      "batch 7061  loss=152.4806  steps/s=105.44  prediction: \"no work on my part? ok lol thanks @sama\"\" => \"gtro t  r r  o r        oo  o   ok     a\"\n",
      "batch 7062  loss=155.1810  steps/s=95.48  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @  zoo    i ri  a  a l  alaaa     aaa\"\n",
      "batch 7063  loss=166.7793  steps/s=53.36  prediction: \": @RajenJangam Thanks! Glad you liked it\" => \" @aoz i nininn ai aaa aala aaaaa   t aat\"\n",
      "batch 7064  loss=151.2158  steps/s=107.27  prediction: \"r die, and when they swim they find food\" => \"eyis  n bz\n",
      "SJB,bx=,N0v8I?!M.v,x#GHb1)B6D\"\n",
      "batch 7065  loss=156.5551  steps/s=99.36  prediction: \" your own game engine\n",
      "challenge accepted\" => \"toudw r r      n   e e  een eeneeneeeeee\"\n",
      "batch 7066  loss=212.2351  steps/s=21.34  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @w     w  n   eee  eenneeneeneeeeee\"\n",
      "batch 7067  loss=162.2530  steps/s=119.79  prediction: \"lda is better than 3D Zelda\n",
      "\n",
      "its vanilla\" => \"y  @Rut;     e e t  t     t             \"\n",
      "batch 7068  loss=142.5523  steps/s=99.05  prediction: \"ust linux mints built in text editor lol\" => \"tti t      i   t   iii iiii     tttt  tt\"\n",
      "batch 7069  loss=153.6803  steps/s=73.61  prediction: \"eCachet Consistency is a deadly strategy\" => \"  a   i    its sssiitin    i    ttt t tt\"\n",
      "batch 7070  loss=150.5997  steps/s=106.43  prediction: \"tings, and speeding up my workflow, you?\" => \"hn   teee eeeneeee ee                   \"\n",
      "batch 7072  loss=159.3427  steps/s=98.41  prediction: \" joining man, looking forward to thurs!!\" => \"@ueeaeeon nonn n  nonoononnnooooo      o\"\n",
      "batch 7073  loss=153.9115  steps/s=104.07  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"iuh  y                     ttttt////////\"\n",
      "batch 7074  loss=145.7769  steps/s=97.08  prediction: \"ould build the thing then maybe post it!\" => \"u uh   uuu uuu      h   tt ttt   h   t  \"\n",
      "batch 7075  loss=155.4936  steps/s=78.29  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e ly: @_f6?j,M09CY@vM@,,zUUT21S&6â€¦;2â€¦â€¦â€¦â€¦\"\n",
      "batch 7076  loss=145.1717  steps/s=107.69  prediction: \"ranoid to install an extension like that\" => \"etly: @tp7?AjM09CY@QMvRâ€¦â€¦QQQA1SI][;xâ€¦]\n",
      "T\"\n",
      "batch 7077  loss=159.6370  steps/s=98.04  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"@m tcii t      t  t        e     p      \"\n",
      "batch 7078  loss=150.1421  steps/s=103.51  prediction: \"ver\n",
      "replace youtube embed with the video\" => \"id ae e  e ee ee eereee eeeeeeeeeeee e  \"\n",
      "batch 7079  loss=162.0292  steps/s=46.25  prediction: \"y: @andyduboc genius concept for a piece\" => \": @aere ee eeeeree eueeueeee eeee e  e e\"\n",
      "batch 7080  loss=153.0193  steps/s=114.31  prediction: \"r full potential https://t.co/jR1cEbfQlo\" => \"eto r @n.z{Amx0$@ðŸ“ˆ@ðŸ¤”X`É´-\"`kc\"1R1|Ex\",(^-\"\n",
      "batch 7081  loss=163.4636  steps/s=97.54  prediction: \"yacine needs a dingboard wrap on his car\" => \":c sll p  eee een   n ne    ao ooao  a  \"\n",
      "batch 7082  loss=152.4536  steps/s=98.00  prediction: \"n just do things https://t.co/909bTHzmml\" => \"gx t tu n              t s tt tt////9/9/\"\n",
      "batch 7083  loss=141.6214  steps/s=104.63  prediction: \"e first img generation models rolled out\" => \" g g                      eeeee eeeellll\"\n",
      "batch 7084  loss=148.8891  steps/s=105.38  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"k re s      '   e    e  e t  ///ttt////t\"\n",
      "batch 7086  loss=145.4615  steps/s=104.26  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sah e                  ttt tttttttt////\"\n",
      "batch 7087  loss=148.5375  steps/s=103.72  prediction: \" what to do next. i want to do my own tâ€¦\" => \"tou       o    o  o        t t       o  \"\n",
      "batch 7088  loss=149.5788  steps/s=94.52  prediction: \"builds mcdonalds just wants to grill man\" => \"ut     b    ddd d    d  t  ttttt  t     \"\n",
      "batch 7089  loss=149.2240  steps/s=88.02  prediction: \"AP wow\n",
      "\n",
      "i need to pivot from using print\" => \"N PbiAwwwwAAAww  w      tt  ooo o     n \"\n",
      "batch 7090  loss=150.4556  steps/s=105.37  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"te   o         1                    eeee\"\n",
      "batch 7091  loss=162.3648  steps/s=105.04  prediction: \"esponses\n",
      "4 repeat step 3 til you have 1â€¦\" => \" s  t   sssssssssseesseeeee ee e        \"\n",
      "batch 7092  loss=154.2576  steps/s=104.55  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" r nna       f   f  ttttt ttt\n",
      "ittttt////\"\n",
      "batch 7093  loss=159.0936  steps/s=103.40  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \"  isaanaaaaasss sss                     \"\n",
      "batch 7094  loss=155.5806  steps/s=66.28  prediction: \"@skooookum i forget but its at least 100\" => \"tuninas\n",
      "os      s y                 e   \"\n",
      "batch 7095  loss=152.2722  steps/s=118.16  prediction: \"ncredibly mesmerizing to watch. dang bro\" => \" l iieoiiiiii   eeeeeeii i  it    t     \"\n",
      "batch 7096  loss=153.7809  steps/s=105.32  prediction: \"usly gives API access, can also finetune\" => \"r      sssseesssses essssesss a ss  css \"\n",
      "batch 7097  loss=148.4998  steps/s=103.91  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"nei e                        ttt tt/////\"\n",
      "batch 7098  loss=141.7898  steps/s=104.04  prediction: \"it got like 2x fps rendering ocean waves\" => \"n  w                       e  e e  eeeee\"\n",
      "batch 7099  loss=144.6665  steps/s=101.04  prediction: \"new super super early on she was the one\" => \" m et   e      re   eee   er    ee e   s\"\n",
      "batch 7100  loss=150.1887  steps/s=104.88  prediction: \"ern of multiplied KPIs pop up semi-often\" => \"  iottt tte   t    i  ii p pppp  pp  p  \"\n",
      "batch 7101  loss=154.0919  steps/s=103.57  prediction: \" right now its just learning on the side\" => \"ter r                   t   t    nn     \"\n",
      "batch 7102  loss=153.4244  steps/s=103.56  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"e sc n sRLkF!?5kk1R\"F:x4k\"N,xj?\"6IxCMZ:,\"\n",
      "batch 7104  loss=151.8742  steps/s=97.23  prediction: \"eadme updates :( https://t.co/FAmcprLRrm\" => \" ror @    e  eeee      :::::tt//////////\"\n",
      "batch 7105  loss=146.2150  steps/s=105.12  prediction: \"mind responds to and processes phenomena\" => \"entsrt      o  n o   oo        s sssssss\"\n",
      "batch 7106  loss=144.5670  steps/s=102.78  prediction: \"ace to both physical and mental reality.\" => \"nt tosn   t  t                   a aaaaa\"\n",
      "batch 7107  loss=192.5218  steps/s=30.40  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @ s  tt    t                aaaaaaaa\"\n",
      "batch 7108  loss=215.3223  steps/s=54.81  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @   t       t      a    a  aaaaaala\"\n",
      "batch 7109  loss=140.5659  steps/s=111.65  prediction: \"mind responds to and processes phenomena\" => \"anisrt      o  n o    o        s sssssss\"\n",
      "batch 7110  loss=157.9061  steps/s=102.93  prediction: \"python or c??? ðŸ¤” https://t.co/XQktKXHLU2\" => \"l tt  s ro oo  o ???   ?   ? tt  t/tXXt/\"\n",
      "batch 7111  loss=173.1837  steps/s=94.00  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" Bsm wo     A  b b bb  ttt  /tthhththttt\"\n",
      "batch 7112  loss=140.3199  steps/s=103.93  prediction: \" the time. personally i havent done this\" => \"thes     t   t t   e     l    l l      e\"\n",
      "batch 7113  loss=141.3770  steps/s=103.58  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \" rh aeeeeeeeeeeneeeeeeeeeea  ssssssssss \"\n",
      "batch 7114  loss=167.2234  steps/s=101.15  prediction: \"ng jai??? Instantly 10x more interesting\" => \"g8 n 8        ????????                  \"\n",
      "batch 7115  loss=180.6861  steps/s=103.10  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns      ,          o  tttt  tttttt/t//t/\"\n",
      "batch 7116  loss=167.8291  steps/s=71.77  prediction: \"ZyMazza what do they call this opening??\" => \"yM,n ,  a     ot t t tt tttt/tttth////p/\"\n",
      "batch 7117  loss=148.5964  steps/s=103.60  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \" t  t  ttttttttettetttttttttttttt///////\"\n",
      "batch 7118  loss=163.5648  steps/s=103.78  prediction: \"t to follow btw\n",
      "\n",
      "https://t.co/HtQ8VvN4bY\" => \"hsc      o  ot  oootttttttttt ttttt//ttt\"\n",
      "batch 7119  loss=149.1093  steps/s=101.51  prediction: \"rogress\n",
      "Is the side proj the ml project?\" => \"euoyy @ FTá´‡vA_MSSTMkxfvXðŸ˜‰mLkbFvIf{3b$w:I\"\n",
      "batch 7120  loss=133.4249  steps/s=105.06  prediction: \"an is usually to attack so imma do that\"\" => \"nd t           s          a  a          \"\n",
      "batch 7121  loss=159.3973  steps/s=77.99  prediction: \"koslib Also just saw the Eu/acc, respect\" => \" r se        s    tatt a   t   a       t\"\n",
      "batch 7123  loss=136.3317  steps/s=105.54  prediction: \" think it applies to others that do this\" => \"th m          ii ii         tttttttttt t\"\n",
      "batch 7124  loss=146.2392  steps/s=99.88  prediction: \"enko Could probably do this w ai now lol\" => \" d  i i        p p     ooo              \"\n",
      "batch 7125  loss=131.8345  steps/s=103.56  prediction: \"endeavors im going to do til ive done it\" => \" ti  t                                  \"\n",
      "batch 7126  loss=178.3301  steps/s=52.92  prediction: \": @sahir2k on the 25th check ur dms  : D\" => \" @aaou a      o       o   o             \"\n",
      "batch 7127  loss=144.2943  steps/s=106.55  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"te            ee eee  oeeeeeeee   o  o  \"\n",
      "batch 7128  loss=144.3415  steps/s=102.73  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \"uri ii                                  \"\n",
      "batch 7129  loss=154.5652  steps/s=94.72  prediction: \"builds 2012 but yet blunders mate in one\" => \"eti iibbb     222  2        d   d       \"\n",
      "batch 7130  loss=163.4573  steps/s=103.10  prediction: \"p in the readme\n",
      "\n",
      "https://t.co/dWiO4erSb1\" => \"lit @ e t\n",
      "  te \n",
      "ee\n",
      "tet\n",
      "e\n",
      "tett\n",
      "\n",
      "ttttt////\"\n",
      "batch 7131  loss=151.0951  steps/s=105.22  prediction: \"ate, but I think about this all the time\" => \"t bet t   t  tt t     t   ttt  t        \"\n",
      "batch 7132  loss=156.1879  steps/s=103.93  prediction: \"owing that your food supply doesnt scale\" => \"u  i nitt  tt  tt      oo      ooo  oo  \"\n",
      "batch 7133  loss=149.9879  steps/s=103.20  prediction: \"outworking them\"\n",
      "\n",
      "i remember that often.\" => \"ul  eeeeeo     o  o   e  eeeememeemeeeee\"\n",
      "batch 7135  loss=137.8545  steps/s=105.06  prediction: \"or a site with a manipulatable algorithm\" => \"u    o  o             a  aaaaa a aaaaaaa\"\n",
      "batch 7136  loss=186.8063  steps/s=29.04  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"ly: @ a o           a aa aaaaaaaaaaaataa\"\n",
      "batch 7137  loss=156.7043  steps/s=110.16  prediction: \"r you choose is not technically infinite\" => \"eai  i  /._Xá´¡xzBj@^217,:X$jX$â™‚â€™xWv$~zâ€œ17\"\n",
      "batch 7138  loss=191.9530  steps/s=105.09  prediction: \"YYYYYYYYYYYYYYY\n",
      "\n",
      "https://t.co/xt0RP3tmNR\" => \"oBYYYYYYYYYYYYYYYYYYY\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " AtY/\n",
      "\n",
      "/ttt\"\n",
      "batch 7139  loss=201.8845  steps/s=96.21  prediction: \"f you can read graphs youre already ngmi\" => \" m     B       \n",
      "\n",
      "   a   t  t htt    ttt \"\n",
      "batch 7140  loss=143.6213  steps/s=102.20  prediction: \" can be taken much much much further tbh\" => \"@oack          n          ccccccuuuuuuhh\"\n",
      "batch 7141  loss=148.9028  steps/s=103.88  prediction: \"the highest quality music we have so far\" => \"hen  a      hhhhhhh                     \"\n",
      "batch 7142  loss=152.4591  steps/s=104.36  prediction: \"ficantly off lol https://t.co/SgwnmEaXdF\" => \" n t diiiiiiiii    f f  l  t ttttt////tt\"\n",
      "batch 7143  loss=157.4599  steps/s=99.79  prediction: \"n confirm this is a very goated strategy\" => \" Ai esa na aa  f         i  i    s a  ta\"\n",
      "batch 7144  loss=165.1809  steps/s=106.06  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.rio tt///ttt/ottttttttttttt/tt////t///\"\n",
      "batch 7145  loss=143.1123  steps/s=106.08  prediction: \"evelopment speed\n",
      "https://t.co/YNvpK7QsyT\" => \" ei          eeeeeeeeeepeeetttttttttttt/\"\n",
      "batch 7146  loss=150.4252  steps/s=103.76  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \"  se                          s t///////\"\n",
      "batch 7147  loss=148.6586  steps/s=105.68  prediction: \"/t.co/dWiO4erSb1 https://t.co/VaQuvIKJWu\" => \"p.coosstot//t//oo//ttt/t//t///tt////t//V\"\n",
      "batch 7148  loss=176.6913  steps/s=92.58  prediction: \"athy @paulg @ylecun Been blocked by lex?\" => \"ne od ra@@@r@p@@@@aa@@@@ e  cee ceeebee \"\n",
      "batch 7149  loss=148.7606  steps/s=104.13  prediction: \" from scratch, and a bit of transformers\" => \"tonp a p       crc  a a                 \"\n",
      "batch 7150  loss=145.1239  steps/s=101.25  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"ne rn ee  eeee n     e       a       t  \"\n",
      "batch 7151  loss=157.6891  steps/s=104.73  prediction: \"nfidence\n",
      "\n",
      "\"idk\" is often the best belief\" => \" idltr eeeeeeeidei\"\"e\"\"\"i\"eei ee eeee ee\"\n",
      "batch 7152  loss=151.8061  steps/s=108.72  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"nl   ooyylll\n",
      "\n",
      "oloo  o                   \"\n",
      "batch 7153  loss=159.4987  steps/s=98.42  prediction: \"nus9 Thats super useful to know actually\" => \" mdl7c  TTTT ss sssss  s   uuu          \"\n",
      "batch 7154  loss=149.7715  steps/s=59.57  prediction: \"@skooookum i forget but its at least 100\" => \"luolIl0oo ss s  u ss uuuuuu  s   t  laal\"\n",
      "batch 7155  loss=184.5682  steps/s=112.58  prediction: \"luffyb Xorswap, what a username, love it\" => \"ys @sAB0111    f f    w    aaaaaa a a   \"\n",
      "batch 7156  loss=150.7070  steps/s=105.30  prediction: \"strategies like this. Gets way more data\" => \"    et ttstst sss ts teeee ss    s    e \"\n",
      "batch 7157  loss=137.1272  steps/s=104.25  prediction: \"but for now ill run whatever ppl ask for\" => \"et             n                        \"\n",
      "batch 7158  loss=152.3552  steps/s=104.36  prediction: \"r the years for business/building things\" => \"e(e i onx*jj!!ðŸ¤”b(\"j)!!!((!ðŸ¤”vKðŸ¤”\"!/!)(ðŸ¤”ðŸ¤”ðŸ¤”j\"\n",
      "batch 7159  loss=145.9918  steps/s=103.36  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" o  falll   aa \n",
      "aaaaaba    aa  a aaaaaaa\"\n",
      "batch 7160  loss=140.5114  steps/s=103.38  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \" ere e eeee e e eee    l l      t  rttrt\"\n",
      "batch 7161  loss=174.2014  steps/s=100.78  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" rr4 t  in   ooooooolloootltotttto//////\"\n",
      "batch 7162  loss=172.2641  steps/s=68.40  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"ltlrofnooo   ooooooottttt/////t////oqqqq\"\n",
      "batch 7163  loss=163.6523  steps/s=110.55  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \" i ayoo      a       tLLLttttt/t////////\"\n",
      "batch 7165  loss=145.9807  steps/s=105.43  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r o  d      iii siiississssttsttttt////\"\n",
      "batch 7166  loss=136.5428  steps/s=103.79  prediction: \"w up wherever decision making is present\" => \"ost d             eeeeeeeeeeeeiiiiiiiiii\"\n",
      "batch 7167  loss=143.2520  steps/s=104.31  prediction: \"usually good metrics, good feedback, etc\" => \"nt n             o o    o ooooooooo     \"\n",
      "batch 7168  loss=143.8497  steps/s=94.94  prediction: \"daily Whats your roadmap for learning ml\" => \" iul ulllol        o  ooooo   daa     e \"\n",
      "batch 7169  loss=172.3595  steps/s=100.15  prediction: \"eople be bookmarking anything these days\" => \"  ia_@_M i      ooooo   o      anannnn n\"\n",
      "batch 7170  loss=140.1328  steps/s=103.95  prediction: \" different distribution of training data\" => \"tov eeeeeee e eeeeeeettttittttiiiiiinini\"\n",
      "batch 7171  loss=149.9671  steps/s=104.59  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"n              ennnititittttttttttttt///\"\n",
      "batch 7172  loss=146.7503  steps/s=103.12  prediction: \"s\n",
      "\n",
      "so super frictionless, it sounds like\" => \" \n",
      "r t t   s ss  ssss  ss ss ss  sssss ss\"\n",
      "batch 7173  loss=142.2430  steps/s=99.34  prediction: \" im pretty screwed when we play sap then\" => \"tt sss  e  t      eeee e eeee ee  e    e\"\n",
      "batch 7174  loss=137.1447  steps/s=100.10  prediction: \"hnote uuuh i have a license for thse sir\" => \"eak trtttt tuuueu            e         e\"\n",
      "batch 7175  loss=149.2822  steps/s=103.80  prediction: \"t the procedure for doing this is on mac\" => \"hre      tt  e r  trr eer  o o   o   o  \"\n",
      "batch 7176  loss=145.0996  steps/s=104.64  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"n  yo    e  ee                          \"\n",
      "batch 7177  loss=148.5257  steps/s=102.13  prediction: \"rney to be gigacracked and save your dog\" => \"e, yy al.jj$ÊœQBAP.á´‡ðŸ˜â˜ $.$QQY/Vâ€x^,á´|$`á´€[%\"\n",
      "batch 7178  loss=175.1387  steps/s=113.61  prediction: \"OOYAH\n",
      "gl brotha\n",
      "Gonna join you in 6hrs ðŸ«¡\" => \"M  outttOOOOOO   aaa r aaanonnnnnn n    \"\n",
      "batch 7179  loss=164.6193  steps/s=105.13  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t    0                         \n",
      "      nn\"\n",
      "batch 7180  loss=169.4654  steps/s=97.02  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"ti                             o  oooo o\"\n",
      "batch 7182  loss=147.2688  steps/s=104.45  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" d                   nnnntttttttt///////\"\n",
      "batch 7183  loss=147.4025  steps/s=102.49  prediction: \"d to seeing your progress on nand2tetris\" => \" ineooooo     eer  r  rr rrrr or    nnnn\"\n",
      "batch 7184  loss=204.3513  steps/s=21.00  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @ooo  e  eer  rr rr rrrr or n nnnnn\"\n",
      "batch 7185  loss=157.7287  steps/s=117.08  prediction: \"of learning is learning from the past ig\" => \"n a eaaeenaennnen n n nan nnn n    r    \"\n",
      "batch 7186  loss=142.9012  steps/s=105.91  prediction: \"o have positive interactions its to grow\" => \"us e      o  o t  i ii itiiitiiiiiiitttt\"\n",
      "batch 7187  loss=145.4952  steps/s=105.53  prediction: \"nomic than discord id switch immediately\" => \"gtto e     oo  mo   o   d  d id iii diii\"\n",
      "batch 7188  loss=148.3745  steps/s=104.01  prediction: \"o nothing for now but funny number go up\" => \"not eeeeeee   onnn no  ooo nnn   n  nn  \"\n",
      "batch 7189  loss=159.7621  steps/s=102.66  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \":do oou  u   u        tt tt ttttttt////Q\"\n",
      "batch 7190  loss=170.9822  steps/s=105.03  prediction: \" ITTTTTTTTTTTTT\n",
      "\n",
      "https://t.co/7uhSNn1VI6\" => \"t e T TTTTTTTTTTTTT\n",
      "\n",
      "\n",
      "\n",
      "EEEt\n",
      "T\n",
      "\n",
      "t\n",
      "\n",
      "\n",
      "///tt\"\n",
      "batch 7191  loss=250.1923  steps/s=10.94  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"e p     A.IImxW,O:612.:k_xWCS0G1C/TTTLT7\"\n",
      "batch 7192  loss=185.8444  steps/s=121.89  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \" 1at./otoo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ssssssteeeeeeeeeeeeeeee\"\n",
      "batch 7194  loss=145.8710  steps/s=104.29  prediction: \"ational ones it might actually be useful\" => \"n s  o oooiooonnoooi  i     ttta  tt ll \"\n",
      "batch 7195  loss=159.3428  steps/s=97.88  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"e lfo  aTTvvTTx,TITTTTTTTTTTTTTTkTTTTTTT\"\n",
      "batch 7196  loss=144.8028  steps/s=103.97  prediction: \"ommittal move like going on a sabbatical\" => \"u  e e  mmmmammt      e    o          aa\"\n",
      "batch 7198  loss=154.2688  steps/s=102.08  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  cee e ee ee eeee g   e   ttttt ttttctt\"\n",
      "batch 7199  loss=150.0143  steps/s=100.99  prediction: \" or so more to go. Lookin forward t o it\" => \"@n    ooooooo  ooooooooooooooooo   o    \"\n",
      "batch 7200  loss=144.5257  steps/s=106.18  prediction: \"t theres probably better stuff out there\" => \" Ing e e     e ebbb bbbbbbbtettttttt  tt\"\n",
      "batch 7201  loss=192.1593  steps/s=30.60  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly:p@e e     b bbbb bbbbbttttttttttt  tt\"\n",
      "batch 7203  loss=153.5759  steps/s=122.20  prediction: \"Tex prob huge dollars in anti drone bots\" => \"  @ Te eeeexxeexe e e                   \"\n",
      "batch 7204  loss=157.5486  steps/s=99.35  prediction: \"ynch Its official im naming my kid movie\" => \":c eadr w      n     i iiii  iiiiiii  m \"\n",
      "batch 7205  loss=175.5910  steps/s=97.25  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"t a n i i    i n  hh a ttttthttt  ////cc\"\n",
      "batch 7206  loss=146.2720  steps/s=101.83  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"los @m      ee    eee   e    eeeeeee    \"\n",
      "batch 7207  loss=195.0164  steps/s=102.56  prediction: \" audio too\n",
      "\n",
      "I really felt that beat drop\" => \"@ p O p            o   o  o l  l l  t tt\"\n",
      "batch 7208  loss=134.7571  steps/s=104.06  prediction: \"future features\n",
      "\n",
      "thanks for the idea bro\" => \" ne elttttttttteeetteeeeeeeetee t  e    \"\n",
      "batch 7209  loss=155.8012  steps/s=76.14  prediction: \"yMazza my favorite systems administrator\" => \":aisutf  affffffeeateessssstse    a   rr\"\n",
      "batch 7211  loss=146.4028  steps/s=106.71  prediction: \"e code a bit in /ai-tools/multicoder lol\" => \" it to                     iiiiiiiiioooo\"\n",
      "batch 7213  loss=142.8725  steps/s=98.30  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"  o  edaaaad   e     ooooonnn nn  n     \"\n",
      "batch 7214  loss=154.5253  steps/s=100.91  prediction: \"inlet like me to test experiments out on\" => \"ng ru rr  rr  ire    ee  eee  e etettett\"\n",
      "batch 7215  loss=151.8949  steps/s=105.16  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \" don  l    e  eet  tt ttttttttttt///////\"\n",
      "batch 7216  loss=143.5544  steps/s=102.60  prediction: \"it playable on lichess and post the link\" => \"n  t   llllllll l llll  l  a       s   s\"\n",
      "batch 7217  loss=144.8712  steps/s=103.38  prediction: \"oud walk away w a much stronger skillset\" => \"n  \n",
      "  od    w  ww    w                  \"\n",
      "batch 7218  loss=166.5901  steps/s=83.20  prediction: \"ubed making gpt2 from scratch in c(obol)\" => \"se t  k    a   aa          a    s       \"\n",
      "batch 7219  loss=148.1181  steps/s=104.17  prediction: \"e irl. i dare u. https://t.co/NEk2CLBwti\" => \" i t @                     .......tt////\"\n",
      "batch 7220  loss=151.0146  steps/s=100.09  prediction: \"ffects that are extremely hard to notice\" => \"     l  e ee eete eeetette te  er  e t  \"\n",
      "batch 7221  loss=149.6533  steps/s=104.91  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplye   ;Oð—¯U%MTBðŸ˜Q@KQ|É´Jx^^x]7[O]â˜ ~zð—±`%á´›\"\n",
      "batch 7222  loss=137.3161  steps/s=102.94  prediction: \"lots of stuff you learn way way way more\" => \"yn @o  o       sff ff             yyyy y\"\n",
      "batch 7225  loss=145.9379  steps/s=102.89  prediction: \"rning gpu acceleration is super valuable\" => \"e  ig  uxO1vv.Y@PH.KDDBUx_2xT7jOjj]O%W.[\"\n",
      "batch 7226  loss=171.2049  steps/s=103.49  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"/..c itt//// //999998t8ttpp//ttt////t///\"\n",
      "batch 7227  loss=156.1674  steps/s=103.85  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \" eai    a  aaaaaaaaattttttt:tttttttt////\"\n",
      "batch 7228  loss=153.7515  steps/s=97.11  prediction: \"reading the code, most are from zig init\" => \"eply: @skx&zðŸ’ª&Y@ðŸ’ª64_ðŸ’ªðŸ’ªðŸ’ª.vðŸ’ª#{%Zq%Exq8SS9â€œ\"\n",
      "batch 7229  loss=138.4931  steps/s=104.60  prediction: \" so that the context switch is seamless.\" => \"toa              t  tttt tt t tttt sssss\"\n",
      "batch 7230  loss=159.6555  steps/s=108.47  prediction: \"nis @startupmillyair pretty solid rating\" => \" ni  d   tt ttttttttttiiiii tt    sesss \"\n",
      "batch 7231  loss=145.4388  steps/s=103.71  prediction: \"best ways to improve for stuff like this\" => \"e  oo                          fffffffff\"\n",
      "batch 7232  loss=143.1076  steps/s=103.13  prediction: \"t the truth/reality?\n",
      "\n",
      "sounds paradoxical\" => \" is po    t ttt tttttttttttttttt\n",
      "\n",
      "\n",
      "\n",
      "aaaa\"\n",
      "batch 7233  loss=162.8087  steps/s=101.92  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "o mee ee  eeeeee ee ee ees sss s  s  s\"\n",
      "batch 7234  loss=144.5989  steps/s=104.28  prediction: \"learn and have fun building baller stuff\" => \"yveo a wrrr r    n   n       n  nn  llll\"\n",
      "batch 7235  loss=166.5928  steps/s=53.94  prediction: \": @iliekcomputers Just steal it back bro\" => \" @s.co lr   a    n   u    n  ll l  llll \"\n",
      "batch 7236  loss=148.2417  steps/s=107.32  prediction: \"ed, its worth at least giving a shot tho\" => \"  e   s   s s     t      t   t        t \"\n",
      "batch 7237  loss=136.1530  steps/s=104.01  prediction: \"but for now ill run whatever ppl ask for\" => \"ut             n                        \"\n",
      "batch 7238  loss=145.2595  steps/s=103.69  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd to saaaaaanaaaanaaeeeeee eeeeeeee eee\"\n",
      "batch 7239  loss=143.8441  steps/s=105.00  prediction: \"sions of significantly stronger models,â€¦\" => \" oe teoooooo oisiisiiiiiiiisiinnnnnnnn  \"\n",
      "batch 7240  loss=157.7888  steps/s=91.44  prediction: \"ller accurate. really useful distinction\" => \"yy ioooosro i i aciaa l   ll l s sslslss\"\n",
      "batch 7241  loss=157.6369  steps/s=100.13  prediction: \"enly distributed https://t.co/NSTgQS2KiE\" => \" tis         tttttttttttttttttttttt/////\"\n",
      "batch 7242  loss=143.8569  steps/s=106.15  prediction: \"st powerful learning techniques there is\" => \"  s t   o  o   o    e    e eeeeneneeeeee\"\n",
      "batch 7243  loss=125.9388  steps/s=100.96  prediction: \" learn if youre not an opening memorizer\" => \"toto                          nnnnnnnnnn\"\n",
      "batch 7244  loss=175.9532  steps/s=46.55  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \"  @ o                      nnnnnn n n ee\"\n",
      "batch 7245  loss=145.4172  steps/s=108.44  prediction: \"cy and then work up to really short ones\" => \"o si t  nnnn nn n                       \"\n",
      "batch 7246  loss=157.5714  steps/s=71.64  prediction: \"2wlearning Great stuff man, keep pushing\" => \"  Ascnnnnnnnn n                        o\"\n",
      "batch 7247  loss=147.0137  steps/s=108.46  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  aos   e eeeeeeeeeeeeeepetpttttptt/////\"\n",
      "batch 7248  loss=171.1012  steps/s=84.31  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yn @aonseseeeaepeeeeeeetttttt/tt/ttatt a\"\n",
      "batch 7249  loss=140.2719  steps/s=106.57  prediction: \"thing you do very often, like constantly\" => \"he e  o                                 \"\n",
      "batch 7250  loss=139.6872  steps/s=105.53  prediction: \"setup is going to be a bit different tho\" => \"      o     o                           \"\n",
      "batch 7251  loss=175.1815  steps/s=100.27  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"s     o   00000000000  tttttttttttt/////\"\n",
      "batch 7252  loss=147.2611  steps/s=105.63  prediction: \"t am article to help ppl understand theâ€¦\" => \" meue          t                 p      \"\n",
      "batch 7253  loss=154.2506  steps/s=101.74  prediction: \"l remember the book much better too. ime\" => \"yb @ iBmoooemmeeebbeemeeee  ee     ee   \"\n",
      "batch 7254  loss=187.4530  steps/s=34.27  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"ly: @ omoooemmebebbeemeeb e ee  e  ee   \"\n",
      "batch 7255  loss=162.5117  steps/s=124.85  prediction: \"the man just liked big words and spirals\" => \" er ea amaa      uu   e              dd \"\n",
      "batch 7256  loss=146.1390  steps/s=101.28  prediction: \"ems like you have. thanks for sharing it\" => \" eae seeeeee e eeeee                    \"\n",
      "batch 7257  loss=169.9678  steps/s=104.56  prediction: \"/t.co/vfpikXycuH https://t.co/HIjM4H1lEy\" => \"/.cco tt////t///tttttttp////ttHH///HH/HH\"\n",
      "batch 7258  loss=194.5107  steps/s=104.08  prediction: \" audio too\n",
      "\n",
      "I really felt that beat drop\" => \"@rpOO p            \n",
      "   o  o    t t  t tt\"\n",
      "batch 7259  loss=160.1965  steps/s=90.32  prediction: \"yan I have fun. does that make me a CEO?\" => \":c Du r  o I   ro      e  tat  taa  eaa \"\n",
      "batch 7260  loss=148.2658  steps/s=103.90  prediction: \"on the manager/grifter/sociopath problem\" => \"n  oe o e  e   e  eeeraererrrrerrrrrtrrr\"\n",
      "batch 7261  loss=149.3536  steps/s=99.84  prediction: \"r switching if mint doesnt serve me well\" => \"etl  d  ?ðŸš€|É´ÊŸð˜á´¡_/'Q#%.á´¡Wð—¼[`#|%#}.+W^%%wâ€\"\n",
      "batch 7262  loss=172.8973  steps/s=104.64  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lr     sssss s s            ttttttt/////\"\n",
      "batch 7263  loss=168.4245  steps/s=105.09  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" ss f.    l             s   tttttstttc//\"\n",
      "batch 7264  loss=150.2221  steps/s=106.34  prediction: \"seconds to go to jail and ruin your life\" => \" d rer         t  o  o  o    a   ao   o \"\n",
      "batch 7265  loss=218.9195  steps/s=102.47  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"INe  OTSSSSS SS GGGGGGGG N      tt///333\"\n",
      "batch 7266  loss=147.7919  steps/s=104.29  prediction: \"d it tho, was a change of weather for me\" => \" th titeeeeee  tt           a  aa      e\"\n",
      "batch 7267  loss=147.2843  steps/s=104.24  prediction: \"e context, like words, strengthen ideas?\" => \" s o  o   o    t    e        e  etee eee\"\n",
      "batch 7269  loss=150.0263  steps/s=99.60  prediction: \" process does feel good when err go down\" => \"tenenneeen eee sese eee eee   o e  oe  o\"\n",
      "batch 7270  loss=150.4363  steps/s=96.40  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \" e erneeen nn  se   o eo eoo oo r  oo  o\"\n",
      "batch 7271  loss=162.1280  steps/s=103.10  prediction: \"grammer extra respectfully:\n",
      "\n",
      "skill issue\" => \" eAPte grrrrrrrrrrrrrereeeeereellsslllll\"\n",
      "batch 7272  loss=149.2091  steps/s=104.30  prediction: \"aise), and we'd end up in the same place\" => \"rn nc aeaaaaaaaa e ee e                 \"\n",
      "batch 7274  loss=215.2241  steps/s=99.84  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"oNc Tae      !!!!!!!!!!!!G              \"\n",
      "batch 7275  loss=151.2896  steps/s=104.01  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"the   tt t  a  t  t tthhtttthttht//ttoot\"\n",
      "batch 7276  loss=141.5586  steps/s=104.39  prediction: \"cks things into place, great feeling lol\" => \"oini         iitiii                  e  \"\n",
      "batch 7277  loss=147.9672  steps/s=103.41  prediction: \" pre session lift make a difference btw?\" => \"trks      sssss ssss               eefee\"\n",
      "batch 7278  loss=164.6013  steps/s=52.11  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @tnluessssss  s            e e feeeee e\"\n",
      "batch 7281  loss=214.4389  steps/s=38.33  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @ ssss    e          ifeee feeeee e\"\n",
      "batch 7282  loss=174.7900  steps/s=122.97  prediction: \"ost valuable RESOURCE\n",
      "\n",
      "damn i need sleep\" => \"ut s  s   t   uo   l RRRREREEEEE E  n  n\"\n",
      "batch 7283  loss=142.2411  steps/s=104.06  prediction: \" are no forests where 2+2 truly equals 5\" => \"t   w          re   ereeeeee e e2222    \"\n",
      "batch 7284  loss=137.4658  steps/s=103.73  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"euly   cxH)zXMTBEIvUzCFI+FFSOU.CWFqFSO(V\"\n",
      "batch 7285  loss=146.1864  steps/s=103.97  prediction: \"s, have back and forth conversations etc\" => \"  ptp h s  s    a   a                 oo\"\n",
      "batch 7286  loss=150.5388  steps/s=104.68  prediction: \"just think your program into existence?\"\" => \"ust     t   t  t    u    r     r    o   \"\n",
      "batch 7287  loss=146.1889  steps/s=95.73  prediction: \"builds mcdonalds just wants to grill man\" => \"et n  bbb   u      oo        t  t tttt  \"\n",
      "batch 7288  loss=138.8283  steps/s=102.74  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"eply: @sAá´€Qá´›_ðŸ˜|%Q#{ðŸ°â€œÊŸ|å§#ð—±ðŸ˜Q#~ð—±ð—²^4-#â€ðŸ§ 5#\"\n",
      "batch 7289  loss=161.1876  steps/s=103.70  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "fe      \n",
      "  \n",
      "\n",
      "d         s ssssss s     \"\n",
      "batch 7290  loss=163.7625  steps/s=103.25  prediction: \"p. i am too slow https://t.co/aqrBNijWpk\" => \"l   @a e                tt o ttto////t /\"\n",
      "batch 7291  loss=167.5152  steps/s=103.86  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"t.hcottt:///tt///tttttttt///t/tt:///tt//\"\n",
      "batch 7292  loss=208.3418  steps/s=105.97  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \"EEtE  T T   WAA A      Rtt ttt/t//////00\"\n",
      "batch 7293  loss=166.7651  steps/s=98.17  prediction: \"reat book, glad youre enjoying it so far\" => \"eply: @i.G{â™‚â€¦07@QCSMYY(%WO1KING!#bvå€‘#,z#\"\n",
      "batch 7294  loss=147.3580  steps/s=99.09  prediction: \"s I love zig\n",
      "Are you doing the ziglings?\" => \" se      o        o e    oo  o     i gg \"\n",
      "batch 7295  loss=185.0834  steps/s=30.34  prediction: \"ply: @sunsettler https://t.co/8FPo1elzOu\" => \"ly: @b   o       oo e  o o      g  iggg \"\n",
      "batch 7296  loss=161.6732  steps/s=110.12  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th  o  o             t  ttttttttttttt///\"\n",
      "batch 7298  loss=149.0862  steps/s=70.95  prediction: \"justalexoki its tpot, all lowercase only\" => \"uctr t            tt tt tt  //t////cc/ll\"\n",
      "batch 7300  loss=172.2576  steps/s=101.42  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eply: @j.wmzz0x;+j@S+.@mc0j,IFb!jP11kvvO\"\n",
      "batch 7301  loss=158.8389  steps/s=105.73  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nA    gggggg ggygygyy tssstttt//////////\"\n",
      "batch 7302  loss=141.2453  steps/s=102.49  prediction: \"better generalizer than the classic MLP?\" => \"ux         eeeeeeeeeeeeeeeeee          a\"\n",
      "batch 7303  loss=156.0519  steps/s=88.34  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lot  P eeeeee eie   ii   e eee      l   \"\n",
      "batch 7304  loss=137.2254  steps/s=105.51  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"euly   c.V)zzLTBFIvFF.H+\"0+,H++MLP11z5(K\"\n",
      "batch 7305  loss=170.0382  steps/s=81.08  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eply   coV)z4LTBGIvSD.Hq\"0jj,q'MLP11z5(ðŸ›‘\"\n",
      "batch 7306  loss=140.5772  steps/s=105.50  prediction: \"ed around the data that flows through it\" => \"   t ae d     ed dd  d  aa  a t  t tt tt\"\n",
      "batch 7307  loss=135.9897  steps/s=104.00  prediction: \"the angle of ur screens after she leaves\" => \"he  ra                      e e eeeeeeee\"\n",
      "batch 7308  loss=154.8278  steps/s=101.56  prediction: \"pounds over time vs disappears instantly\" => \"lst   unooeoooosoo oo s      sss sssasss\"\n",
      "batch 7309  loss=156.3703  steps/s=101.08  prediction: \"r model architecture not based on tokens\" => \"e@ly:   rBSPz/A,?@,Sy.HA\n",
      "C2x,\"GMLP1/zb(w\"\n",
      "batch 7310  loss=147.5756  steps/s=94.76  prediction: \"us im in, gonna do this rn, on the rocks\" => \"tttoA        i n i t no         n     n \"\n",
      "batch 7311  loss=139.7609  steps/s=103.59  prediction: \"e first img generation models rolled out\" => \" g n           g          eeeee eeeellll\"\n",
      "batch 7312  loss=141.6118  steps/s=103.63  prediction: \"snt even intentionally trying to do that\" => \" t wt t t    nnnnnnnnnnnnnnnnnnntt     t\"\n",
      "batch 7313  loss=151.5466  steps/s=100.89  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" t                                      \"\n",
      "batch 7314  loss=147.1026  steps/s=103.92  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"h  g is                                 \"\n",
      "batch 7315  loss=183.3225  steps/s=80.68  prediction: \"h1xabc king shit https://t.co/UJrAexS6FM\" => \"esp t                    p     ttrrrrnnn\"\n",
      "batch 7316  loss=158.3766  steps/s=69.70  prediction: \" @llamapuckey never visit sf without jug\" => \"tmus           i    t    tt ////trrrrrrr\"\n",
      "batch 7317  loss=149.5563  steps/s=107.61  prediction: \"ould keep going) https://t.co/zZj3emr1oN\" => \" r            ee          t tt t/t////t/\"\n",
      "batch 7318  loss=144.2503  steps/s=102.94  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"e e s see eeeeeteeee eeh   \n",
      " o\n",
      "\n",
      "\n",
      "j     j\"\n",
      "batch 7319  loss=158.6344  steps/s=59.53  prediction: \" @sunsettler all my homies HATE openings\" => \"tye seseettteee ee     oo\n",
      "\n",
      "\n",
      " j j      ss\"\n",
      "batch 7320  loss=144.2220  steps/s=106.58  prediction: \"ational ones it might actually be useful\" => \"ree  oroooiooonnoooi  i     t ta  tt al \"\n",
      "batch 7322  loss=140.7001  steps/s=104.11  prediction: \"to work on things that make sense to you\" => \"h  ya o             o         t     t  t\"\n",
      "batch 7323  loss=156.9308  steps/s=102.15  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \"oi a i                  ssssstttttccccc/\"\n",
      "batch 7324  loss=153.0958  steps/s=102.69  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"tatn ttll l  e e      t tttttt//////////\"\n",
      "batch 7325  loss=162.7898  steps/s=64.25  prediction: \"@JsonBasedman just veto their veto, easy\" => \"lsbiilllaaaaee t   tttt ttt//////tttttpp\"\n",
      "batch 7326  loss=181.7966  steps/s=62.49  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"y: @Jareeeaaee    ttttt//tt.///t tOtttpðŸ›‘\"\n",
      "batch 7327  loss=152.5294  steps/s=105.93  prediction: \" drains your energy by paying attentionâ€¦\" => \"tu t ia   i    r  n   yyyyyyyy yy y   nn\"\n",
      "batch 7328  loss=138.1940  steps/s=103.41  prediction: \"cool ML/studying/building posts are gone\" => \"onbeth        ooooootouuiiiiiiiiiiiiiigg\"\n",
      "batch 7329  loss=159.1164  steps/s=56.15  prediction: \" @thetechbrother high p doom\n",
      "low p value\" => \"t0t     ttooooootuuiiiigiiiiooisss   g g\"\n",
      "batch 7330  loss=162.6773  steps/s=107.95  prediction: \" post your progress as you go through it\" => \"tlw o  oooooo  oo  o oo   ss            \"\n",
      "batch 7331  loss=168.7877  steps/s=91.21  prediction: \"fsimo Lets goo!!!! Incredibly impressive\" => \"     cooo oo oooos!!!!!!!!!     r       \"\n",
      "batch 7332  loss=140.1276  steps/s=103.05  prediction: \"th itself but couldnt figure out how lol\" => \" e t  ettt ttt tt    t t t t   uu uu  u \"\n",
      "batch 7333  loss=141.7453  steps/s=104.39  prediction: \" from that channel/vid to that x account\" => \"to       o     a  a a      t tttt    tt \"\n",
      "batch 7334  loss=174.4394  steps/s=37.90  prediction: \"ly: @horseracedpast Hows it goin so far?\" => \"y: o aoo    a aaaa   a    tt tt      tt \"\n",
      "batch 7335  loss=148.6078  steps/s=107.90  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"ec y:r@lIzJJ0JJJJkJJ:J[xbJ+J+J+++)+-&++;\"\n",
      "batch 7336  loss=135.0340  steps/s=102.23  prediction: \"uture w her, and what that would be like\" => \"t   e   t      e             w          \"\n",
      "batch 7337  loss=155.5291  steps/s=74.51  prediction: \"izmobly you have 3 days or youre blocked\" => \"nm n e  e e    r   h    a a  t        e \"\n",
      "batch 7339  loss=151.8616  steps/s=111.43  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"g m utmooooemme m  e e                  \"\n",
      "batch 7340  loss=132.3972  steps/s=98.97  prediction: \"d work that into my current program haha\" => \" on                            rrrrrrrrr\"\n",
      "batch 7341  loss=171.8153  steps/s=102.45  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"/..l itt/t// ///99998t/ttpp//ttt////t/t/\"\n",
      "batch 7343  loss=157.6916  steps/s=103.80  prediction: \"t habit of reaching for my phone is gone\" => \"hf    ttt t tt h     h  h               \"\n",
      "batch 7344  loss=145.5968  steps/s=103.28  prediction: \" been some adventure man. God bless him.\" => \"tuve  eeeeeeeeeeeeeeeeeeeeee            \"\n",
      "batch 7345  loss=143.5458  steps/s=98.08  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"tee                   r  o      s ss  s \"\n",
      "batch 7346  loss=144.2943  steps/s=104.52  prediction: \" to recover from if it becomes a problem\" => \"thr o o  ooorro rorrr r               e \"\n",
      "batch 7347  loss=176.2380  steps/s=98.83  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tn                   t t ttttttttttt////\"\n",
      "batch 7348  loss=155.8334  steps/s=102.59  prediction: \"stone cpus in it https://t.co/UsFG7LjU6T\" => \"  e    e  nnn  en  e      t t t tttt////\"\n",
      "batch 7349  loss=150.8585  steps/s=104.91  prediction: \"d at that too\n",
      "\n",
      "Get skilled w both id say\" => \" ta  g      ttttttttttttttt             \"\n",
      "batch 7350  loss=147.8033  steps/s=104.99  prediction: \"at DAN had. 'get in character' type beat\" => \"n  te\"  ht  htt  t     h  a    ' '' ae  \"\n",
      "batch 7352  loss=159.0271  steps/s=103.67  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf        i    i  i  i                  \"\n",
      "batch 7353  loss=152.0793  steps/s=104.53  prediction: \" can so can you. But maybe im projecting\" => \"taid i                                e \"\n",
      "batch 7354  loss=155.8782  steps/s=96.26  prediction: \"builds 2012 but yet blunders mate in one\" => \"ut d          2222 2    u        eeee   \"\n",
      "batch 7355  loss=151.5206  steps/s=104.82  prediction: \" focus/attention to a negative direction\" => \"tort f s   t ttuottoottt tttttttt  t t  \"\n",
      "batch 7356  loss=132.4536  steps/s=104.81  prediction: \"had an eye for it meant maybe its useful\" => \"et  t                                   \"\n",
      "batch 7357  loss=139.1054  steps/s=105.26  prediction: \" which uses a superset of c. so not sure\" => \"thi ch cccc    c    sss s s s           \"\n",
      "batch 7358  loss=133.9462  steps/s=102.89  prediction: \"tput something as unexpected as possible\" => \"hh  t ttttttttttt  t      eeee eeeeessss\"\n",
      "batch 7359  loss=145.6369  steps/s=82.08  prediction: \"kul07 Time limits on tasks are so useful\" => \"et tutouo     ii    ii   s e ssss s ssss\"\n",
      "batch 7360  loss=142.2075  steps/s=105.29  prediction: \"ing this with terms masters commonly use\" => \"ng o  i        t            s  smmmsmmmm\"\n",
      "batch 7362  loss=144.2526  steps/s=104.46  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hon reliiiiiiiiiiiitttittttttttttt//////\"\n",
      "batch 7363  loss=159.4282  steps/s=106.07  prediction: \"wigABAP thats why they call him zigmobly\" => \" sd  ell   ttAAAAtttttthhhhhh h  hh llll\"\n",
      "batch 7365  loss=147.2714  steps/s=101.44  prediction: \" like i can do so much more in python :(\" => \"tial l l                                \"\n",
      "batch 7366  loss=148.1145  steps/s=104.08  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"ts   o         1                   eeeee\"\n",
      "batch 7367  loss=163.5841  steps/s=101.58  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"@ude           n           ///t//////tt/\"\n",
      "batch 7368  loss=133.1185  steps/s=105.30  prediction: \"ments as opposed to making the user wait\" => \"e oe inee eeeesesssss   s  o            \"\n",
      "batch 7369  loss=154.3380  steps/s=97.96  prediction: \"pynch we must accelerate snake\n",
      "snake/acc\" => \"l t  an e pp s  s     aae  aeee eaeeeaaa\"\n",
      "batch 7370  loss=154.1856  steps/s=101.16  prediction: \" wtf, hes goated https://t.co/o1FdLtmzSj\" => \"thne                tttt tttt  ttttt//tt\"\n",
      "batch 7371  loss=138.4583  steps/s=103.87  prediction: \", usually because you border more things\" => \" sn  ne  e   e  e ee e u uuuuu  e  e err\"\n",
      "batch 7373  loss=149.0746  steps/s=103.44  prediction: \" even the ones i disagreed with the most\" => \"tv e eee  eeeeen          e ee          \"\n",
      "batch 7374  loss=137.4025  steps/s=88.22  prediction: \"enisnikulin its the lichess of photoshop\" => \" tst eneennninni  i   iee eee i hh    oh\"\n",
      "batch 7375  loss=140.1397  steps/s=104.04  prediction: \"see at once that this is really so, andâ€¦\" => \" le      ee   e      t    t    t    s  a\"\n",
      "batch 7376  loss=145.7141  steps/s=105.84  prediction: \"t immensely and give you new information\" => \"hing  e   e    n e  e     e   e   n    n\"\n",
      "batch 7377  loss=147.4148  steps/s=103.45  prediction: \"surely you will not regret this decision\" => \" pnt iaaaa     l   l               t tti\"\n",
      "batch 7378  loss=159.7975  steps/s=98.57  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"mobld iiiiiii ieg&&&&&&;;;;;;;gtggggttii\"\n",
      "batch 7379  loss=226.0711  steps/s=97.87  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"i\n",
      "v   rrEEEEEEOOOOOOOOOOttttttt         \"\n",
      "batch 7381  loss=147.9998  steps/s=103.11  prediction: \" far dang the format looks so much nicer\" => \"to             f   a   o  ooo oo  ooo  o\"\n",
      "batch 7382  loss=145.9439  steps/s=100.27  prediction: \", even my llm is on 3 cups of coffee bro\" => \" aa   nn                               f\"\n",
      "batch 7383  loss=148.2665  steps/s=103.91  prediction: \"y with any industry/niche and ill run it\" => \":iicnni iyyy iy yyyyynnyyynnnnn  n n n  \"\n",
      "batch 7384  loss=149.1959  steps/s=104.01  prediction: \"mething to run from (getting called out)\" => \"etes veeeeetee  e   oo        g g  g g t\"\n",
      "batch 7385  loss=154.0311  steps/s=97.06  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"LMs  re ee  o  too   oo  nn   n n       \"\n",
      "batch 7386  loss=193.4178  steps/s=21.07  prediction: \"eply: @yacineMTB dependency independency\" => \" ly: @g  e  o   oo  ooo  nn   n         \"\n",
      "batch 7387  loss=147.9569  steps/s=136.42  prediction: \"t really is a long term + hard work game\" => \"hto tee ei     s    n           r    r  \"\n",
      "batch 7388  loss=145.3944  steps/s=96.75  prediction: \"mann is the goat I love that guy so much\" => \"eth lyn n                               \"\n",
      "batch 7389  loss=141.7956  steps/s=102.96  prediction: \"a wave of weird suspensions going around\" => \"nme  eee  e    s    e  sssssss s so  oso\"\n",
      "batch 7390  loss=131.4663  steps/s=106.72  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" o s oo oo o                          e \"\n",
      "batch 7391  loss=169.0009  steps/s=100.44  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"egly: @HSVSYYMBAP-&99;)999fc?jL+-&@@;@M.\"\n",
      "batch 7392  loss=146.7541  steps/s=101.59  prediction: \"ressure either turns to dust or to a gem\" => \"eply: @t.;S:BMBAJOz\n",
      "á´;)}kjfc?jA+-&@@;@A.\"\n",
      "batch 7393  loss=144.8127  steps/s=104.54  prediction: \"uch  there would be to take into account\" => \"scian  h    hh                      t   \"\n",
      "batch 7394  loss=177.8574  steps/s=104.52  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OO\n",
      "\n",
      "                   d   ttttt////////\"\n",
      "batch 7395  loss=178.3117  steps/s=73.85  prediction: \"ruck is this you https://t.co/TaMoSJicnx\" => \"esoy  @eIIIIIIIIPEGJOHNJOONNOOOOOMOm;OOO\"\n",
      "batch 7396  loss=141.5159  steps/s=106.43  prediction: \"erscores the importance of curating andâ€¦\" => \" en e eeeeeeeee ee e eeee               \"\n",
      "batch 7397  loss=159.2725  steps/s=93.23  prediction: \"rdenis grats btw. site looks amazing too\" => \"e ly: ik\n",
      "UUUUUO)PII'O;NOOTOOOOOMOSJSJk.O\"\n",
      "batch 7399  loss=153.4543  steps/s=85.12  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \" rndeeessers   tttt  i  t   t   aaaaa mm\"\n",
      "batch 7401  loss=185.8247  steps/s=104.21  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \":i euses e o   ti t itt tttttt  lammmmmm\"\n",
      "batch 7402  loss=137.2249  steps/s=106.32  prediction: \" than ever to be get skilled at building\" => \"thoe t tt tt   t e e e   ee      e  e   \"\n",
      "batch 7403  loss=157.4518  steps/s=52.57  prediction: \": @teodor_io funny number go up type shi\" => \" @tuicee ee     eee  ee  ee      e  i   \"\n",
      "batch 7404  loss=140.4011  steps/s=116.78  prediction: \"s and sugar and i dont get tired anymore\" => \" anu       aa ana a  a                  \"\n",
      "batch 7405  loss=145.8851  steps/s=104.51  prediction: \"g us calculate costs some weird jank way\" => \" t a           aa a   sssss sss         \"\n",
      "batch 7406  loss=149.6010  steps/s=101.00  prediction: \"pany uses it often for researching stuff\" => \"lrx @yomommm   oo o    o     e  r   r   \"\n",
      "batch 7407  loss=198.3563  steps/s=44.56  prediction: \"ly: @I_Like_Buttes @opaeoh CANT TOUCH ME\" => \"y: @yenm  my   oo n    oeoe ee  rr  r ff\"\n",
      "batch 7408  loss=139.3147  steps/s=107.94  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o  m         m                        \"\n",
      "batch 7409  loss=143.4461  steps/s=104.34  prediction: \"re much lower on time than your opponent\" => \"e lo  n bzUUUk@qUU1-q,2@OOqqU44N68TOx4HD\"\n",
      "batch 7410  loss=139.7048  steps/s=104.30  prediction: \"e first img generation models rolled out\" => \" gi            g           eeee eeeellll\"\n",
      "batch 7411  loss=146.7121  steps/s=105.04  prediction: \"e walking through a memory palace maybe)\" => \" d  l      l               o o     aaa a\"\n",
      "batch 7412  loss=150.3458  steps/s=103.52  prediction: \"forward, forever\n",
      "https://t.co/zlto3SBYwd\" => \" rmr  n       rorrrrrrrrrrrrrrtt///////t\"\n",
      "batch 7413  loss=165.3067  steps/s=90.21  prediction: \"ntellectus To beat paranoia, accept risk\" => \"   rearrerleeerr   e  t/ttattaoaoooocccc\"\n",
      "batch 7414  loss=144.5119  steps/s=105.90  prediction: \"d its helped man. i shpuld sleep too lol\" => \" toh    aa                      pppp    \"\n",
      "batch 7415  loss=149.5178  steps/s=104.37  prediction: \" what? never heard of it lol skill issue\" => \"tate   aeee e  neeae  e re  a  e    lil \"\n",
      "batch 7416  loss=148.4809  steps/s=100.06  prediction: \"is the platonic form of a platonic form?\" => \"n  r    e e    t     i    o  f oo       \"\n",
      "batch 7417  loss=152.8880  steps/s=102.48  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"taa ae       a    l l        o  o     o \"\n",
      "batch 7418  loss=140.7746  steps/s=75.27  prediction: \"is would make a really cool pfp actually\" => \"n BhPl    l  l la   l  ll l  op   pp  ea\"\n",
      "batch 7419  loss=143.7704  steps/s=107.74  prediction: \"an get immense alpha if you keep zooming\" => \"nd oem         m m                      \"\n",
      "batch 7420  loss=146.0877  steps/s=104.29  prediction: \"s\n",
      "\n",
      "probably gets more views bc of it tho\" => \" \n",
      " n naaaaaaaaaaaaayyy                  \"\n",
      "batch 7421  loss=150.7174  steps/s=103.50  prediction: \"sed to sound like the opposite of curses\" => \" d l e  e                 o        o  o \"\n",
      "batch 7422  loss=149.6435  steps/s=83.33  prediction: \"phones Thanks man! its going well so far\" => \"lo e   s s   ssn          i i o o     ss\"\n",
      "batch 7423  loss=140.5017  steps/s=104.32  prediction: \"started begging me to let him pay for it\" => \" uf          ggggggggg gg               \"\n",
      "batch 7424  loss=161.1520  steps/s=104.59  prediction: \"nus9 Thats super useful to know actually\" => \"gs ne  TTTTT ss    s   e     u          \"\n",
      "batch 7425  loss=152.8484  steps/s=103.44  prediction: \"n\n",
      "Took me from c to a student in college\" => \" \n",
      " ti ootootoooo oo    o oo o  t    t t \"\n",
      "batch 7426  loss=188.6997  steps/s=105.04  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"h a//////tt/tttttcottttttt///t/tt/FF/FFF\"\n",
      "batch 7427  loss=158.3336  steps/s=100.39  prediction: \"ly pretending to give unsolicited advice\" => \"y  @ee pe eeee t  e e      e e eii iiiie\"\n",
      "batch 7428  loss=150.9305  steps/s=104.83  prediction: \"lity, not others, for what is true/false\" => \"yfs   et   t    t ot  tt   ot  r  r rt r\"\n",
      "batch 7429  loss=189.3611  steps/s=103.37  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"  V4\n",
      "ctt//\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ss\n",
      "\n",
      "ttt//////s//t\"\n",
      "batch 7430  loss=158.0701  steps/s=102.71  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"   oo o  o         d   n     ee reeeeeee\"\n",
      "batch 7431  loss=147.7124  steps/s=104.44  prediction: \"mul, transitions from one derivative toâ€¦\" => \"enc t aiiaaaiititiiiiin n  n      io   i\"\n",
      "batch 7433  loss=146.7490  steps/s=104.22  prediction: \"king useful things, so it didnt work out\" => \" n                                      \"\n",
      "batch 7434  loss=143.9307  steps/s=104.48  prediction: \"good idea but whatever, i wanna have fun\" => \" od  n  io  o      t        aa   aaaa aa\"\n",
      "batch 7435  loss=145.5434  steps/s=98.64  prediction: \" I got a creality one, works well so far\" => \"t  b                 e     e            \"\n",
      "batch 7436  loss=138.0930  steps/s=104.84  prediction: \"his is the same w similar things in life\" => \"engs t iiiiih  ssss       s    i i  ii  \"\n",
      "batch 7437  loss=175.5827  steps/s=91.64  prediction: \"ed_videos Thanks!! Yea I took like 0.3mg\" => \"  io itihisseh  sss   s   s      i  ii  \"\n",
      "batch 7438  loss=148.0874  steps/s=100.93  prediction: \"oger @sunsettler @tunient baller name xD\" => \"n da eoo@ o@@tteteeee@@@tttttetttl ee ee\"\n",
      "batch 7439  loss=147.2763  steps/s=104.53  prediction: \"ss I need to do keyboard input from it..\" => \"       l      e e    e  e  o        o   \"\n",
      "batch 7440  loss=142.3932  steps/s=105.51  prediction: \"ing and shipping is gonna grow immensely\" => \"ng  e nnnnnpppp n ppp nninggggngg  g    \"\n",
      "batch 7441  loss=148.2906  steps/s=101.23  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"n   e         i  i  t tt ittttttttt/t//t\"\n",
      "batch 7442  loss=164.9624  steps/s=102.58  prediction: \"y i havent had many problems with it tbh\" => \":t0 a  elel     a  aa    a        m    t\"\n",
      "batch 7444  loss=154.5358  steps/s=106.01  prediction: \"hts move away from the edge of the board\" => \"e 'e l       a a         e  e e   e   oe\"\n",
      "batch 7445  loss=153.7562  steps/s=102.32  prediction: \" way I implemented it might be different\" => \"them   ae  aeeee e    em em me    ei iee\"\n",
      "batch 7446  loss=150.5719  steps/s=98.85  prediction: \"yacine needs a dingboard wrap on his car\" => \":c xa  y0 e eneen eee di  d     i    rr \"\n",
      "batch 7447  loss=149.3235  steps/s=103.85  prediction: \"6x speed version https://t.co/yCogzpgz92\" => \"hr a            e e e  eesssststt///////\"\n",
      "batch 7448  loss=144.6949  steps/s=101.86  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \" rn aieeeeeeeeeneeeeeeellll  ssssssssss \"\n",
      "batch 7449  loss=160.6205  steps/s=72.52  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"yds@cn eeeeeee nnnnnnpppppppps    s     \"\n",
      "batch 7450  loss=204.3984  steps/s=54.62  prediction: \"ly: @I_Like_Buttes @opaeoh CANT TOUCH ME\" => \"y: @gn AeeeeAe ennpnpppppppppp          \"\n",
      "batch 7451  loss=148.7027  steps/s=108.82  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"yc ttinyeaaaaaaaaaaaaaaatttttttttttt////\"\n",
      "batch 7452  loss=144.2582  steps/s=103.06  prediction: \"l possible golden gate bridge existences\" => \"yf eaelp     lllol  l      e ee ee eeeee\"\n",
      "batch 7455  loss=171.8943  steps/s=94.43  prediction: \"nDEKR he confused plurality for majority\" => \"gl e           n   ee eeee e   i    ii  \"\n",
      "batch 7457  loss=152.7302  steps/s=77.55  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \" sa: nsnn nnn en      e  u     r  ooort \"\n",
      "batch 7458  loss=138.2847  steps/s=108.05  prediction: \"ings will continue until morale improves\" => \"ng AP eeee       innnnnnnnn   l         \"\n",
      "batch 7459  loss=143.8995  steps/s=104.04  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hn  ieiiiiiiiiiiiiitttittttttttttttt////\"\n",
      "batch 7460  loss=151.6696  steps/s=107.64  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"hen ib.t   tnnnhnn tnntnt//////////FFFFF\"\n",
      "batch 7461  loss=151.4472  steps/s=100.20  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \"gnr rti        nn nn nnnnnnnneneeeenenee\"\n",
      "batch 7463  loss=148.1751  steps/s=105.60  prediction: \"o you get more data) or hit a \"dampener\"\" => \"ns s  o      o                          \"\n",
      "batch 7464  loss=149.6320  steps/s=100.37  prediction: \"in a year, and this was his main opening\" => \"nk 00 0                  a   a    a   ii\"\n",
      "batch 7465  loss=160.0789  steps/s=103.25  prediction: \"y i havent had many problems with it tbh\" => \":t ri    el   a a  aa    a        h    t\"\n",
      "batch 7466  loss=157.7380  steps/s=103.20  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"oystu onnnoonnononn ooon oi i  iriii aia\"\n",
      "batch 7467  loss=155.1802  steps/s=105.48  prediction: \" kache who made dingboard w llms (afaik)\" => \"tin ei is        e   a   da        aada \"\n",
      "batch 7468  loss=166.5981  steps/s=60.40  prediction: \" @AI_Solzhenitsyn it's an acquired taste\" => \"tcu e   e  a    dd   a   aa   a    aaaaa\"\n",
      "batch 7469  loss=144.6415  steps/s=107.48  prediction: \"s, but eventually this catches up to you\" => \"  n  n        elelllllll ttt ttt        \"\n",
      "batch 7470  loss=172.8324  steps/s=104.39  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/..co:/: ///////TT/OOOOOOtO/t//t////////\"\n",
      "batch 7471  loss=159.5152  steps/s=103.55  prediction: \"ot of politics is reinforcement learning\" => \"n  o ooooo  oo to t  s  iiisiccce e eeen\"\n",
      "batch 7472  loss=147.9351  steps/s=93.98  prediction: \"have you seen the walmart aura points ad\" => \"etps:l            e ee eee ee   aaaaaaaa\"\n",
      "batch 7473  loss=298.8347  steps/s=11.27  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @jaðŸ¤”kkðŸ¤¦_Y,)A@@zvx:yyQ#ÊŸYq7U8bFGP(U\"\n",
      "batch 7474  loss=165.5383  steps/s=139.45  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"@n _ay  h  n   h    h h t   t ttt/tt/ //\"\n",
      "batch 7475  loss=141.4566  steps/s=102.21  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"ne all l l l   leeee etee ereeerrarrraaa\"\n",
      "batch 7476  loss=140.2327  steps/s=104.39  prediction: \"ed around the data that flows through it\" => \"   teae d dd  dd dd  d  aa  a t  t tt tt\"\n",
      "batch 7477  loss=139.7850  steps/s=104.25  prediction: \" pays off immensely when I stick to them\" => \"tit  ttt ffffff ff   m         e        \"\n",
      "batch 7478  loss=151.6589  steps/s=101.72  prediction: \"well\n",
      "\n",
      "maxing it out is worth considering\" => \"irk rin  e    nn                   o   i\"\n",
      "batch 7479  loss=147.1599  steps/s=98.00  prediction: \"ould build the thing then maybe post it!\" => \"nr   h          u        thhh    h   t  \"\n",
      "batch 7480  loss=139.4090  steps/s=102.05  prediction: \" been the difference, in your experience\" => \"tue hh         eeeeeeeeeeeeeeee eeeeeeee\"\n",
      "batch 7481  loss=196.1238  steps/s=99.86  prediction: \"@___________11hz helped me out with mine\" => \"linwen_e_______________1111_ e  e   e   \"\n",
      "batch 7482  loss=152.7236  steps/s=98.76  prediction: \"ly pretending to give unsolicited advice\" => \"y  @ee  e eeee t  t          n  ii iiii \"\n",
      "batch 7483  loss=164.8384  steps/s=63.82  prediction: \"@jamstack_guru Speed of launches as well\" => \"l_z___eteteee tt  tee  n  o inieii d iie\"\n",
      "batch 7484  loss=143.8906  steps/s=107.90  prediction: \"e money now bc you can get 10x more done\" => \" a   m eeeeee ee                        \"\n",
      "batch 7485  loss=147.6202  steps/s=104.15  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er b a  h  e     e   he   t tttoottott//\"\n",
      "batch 7486  loss=146.5297  steps/s=103.45  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"  ft pi  ii                tttttt//////t\"\n",
      "batch 7487  loss=171.7654  steps/s=37.05  prediction: \"ly: @shurensha Done. Great advice. Ty ty\" => \"y:  v  t rn       n   w tttt////t//////t\"\n",
      "batch 7488  loss=145.8963  steps/s=136.25  prediction: \" square gang wont let this happen &gt;:(\" => \"tti     rr     gg gg  gtttttttt t   hp p\"\n",
      "batch 7489  loss=137.4759  steps/s=101.75  prediction: \"you into thinking hes an anime character\" => \" ug ti t  o tot  i   iin n  n  nn nn  n \"\n",
      "batch 7490  loss=148.1997  steps/s=105.99  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"omted ttrtrtttretttt.t......t......tt///\"\n",
      "batch 7491  loss=159.9856  steps/s=101.92  prediction: \" useful stuff to save hrs of your day ig\" => \"tsi   uuuuuuuuufufffff                  \"\n",
      "batch 7493  loss=145.2894  steps/s=104.67  prediction: \"r minds after realizing thats not rly it\" => \"eos l  gk)â€7ï¸fÉ´@|}z7v*#_:))#*C%*##x$â€™qxj\"\n",
      "batch 7494  loss=154.0981  steps/s=104.69  prediction: \"se and 'magically' econ makes more sense\" => \"   a    e     aaaaaaaaa  a   aaa      ee\"\n",
      "batch 7495  loss=164.3611  steps/s=106.07  prediction: \"sonnet 3.5v2 its amazing for programming\" => \" m t          n n         a         rrrr\"\n",
      "batch 7496  loss=146.1912  steps/s=104.96  prediction: \"cy and then work up to really short ones\" => \"o  i t nnnnnnnn n                       \"\n",
      "batch 7498  loss=147.8417  steps/s=104.44  prediction: \"ing responses seems like a better metric\" => \"nts\n",
      "oeeeieeeensnnesssessseseeeeee  eeeee\"\n",
      "batch 7500  loss=159.0093  steps/s=86.78  prediction: \"rdenis grats btw. site looks amazing too\" => \"e  g: @ u/.5B2&,@V,7N0zTy)).,CTv,,,,,,BA\"\n",
      "batch 7501  loss=156.6877  steps/s=103.73  prediction: \"izer\n",
      "\n",
      "his uses a NN this uses Q learning\" => \"nesr    i iississsss s    s sssss s ss  \"\n",
      "batch 7502  loss=144.4783  steps/s=104.38  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"      aaayaayaaaa aaaa  a       ,       \"\n",
      "batch 7503  loss=168.8340  steps/s=102.56  prediction: \"G SUB 30 BABYYYY https://t.co/E87r3E6tgg\" => \"ISdieP FLLL   BBBBYYYYYYYYY  // //////EE\"\n",
      "batch 7504  loss=155.5752  steps/s=105.73  prediction: \" is a wild computational rabbithole man.\" => \"tntypsea    aa a c    aa aaa i aaai aab \"\n",
      "batch 7505  loss=167.7464  steps/s=38.61  prediction: \"ly: @0xbingllm we gettin it we gettin it\" => \"y  h\n",
      "heh    a   cc   aaa aaa i aaatiaa i\"\n",
      "batch 7506  loss=160.8651  steps/s=134.97  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"tLpw wpi    e   tt tttttt tt tttttt/8888\"\n",
      "batch 7507  loss=150.2521  steps/s=100.51  prediction: \" that outputs its own weights and biases\" => \"toa t      t tt ttt tt  t   t   t       \"\n",
      "batch 7508  loss=150.5533  steps/s=97.03  prediction: \"ng so you can automate ruining your life\" => \"   a           n             uunuunuuu u\"\n",
      "batch 7509  loss=147.6497  steps/s=106.51  prediction: \", how much info could you get from that?\" => \" ao  i  i  i   m  o    oo  oo   o    o  \"\n",
      "batch 7511  loss=164.1204  steps/s=104.76  prediction: \"ood combo for stuff like this, ive found\" => \"nm o \n",
      "o ooooooooo   offf  f             \"\n",
      "batch 7512  loss=153.8490  steps/s=104.98  prediction: \"makes a comeback they get a large reward\" => \"pkes          a   a                    e\"\n",
      "batch 7513  loss=137.3383  steps/s=103.13  prediction: \"mages looked smoother so it did that lol\" => \"pke  tt        t  ooooooooooooo         \"\n",
      "batch 7514  loss=170.1530  steps/s=74.58  prediction: \"owTiedFox 16hrs every day is crazy,  wow\" => \"   it eo eee  osooeeeeee     d          \"\n",
      "batch 7515  loss=138.4260  steps/s=105.65  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf ntnn n     nn  i   g      g   o      \"\n",
      "batch 7516  loss=145.0995  steps/s=104.09  prediction: \"thing I need to pay attention to, thanks\" => \"h r i\n",
      "e    i  e           tttttt ttttttt\"\n",
      "batch 7518  loss=142.1228  steps/s=104.82  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  in         n                        \"\n",
      "batch 7519  loss=141.7880  steps/s=104.02  prediction: \"ing this with terms masters commonly use\" => \"nd o  f        t            s  smmmsmmmm\"\n",
      "batch 7520  loss=198.6531  steps/s=94.11  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \" to  uuu   uuuuu uuue  er    o  oo   OOO\"\n",
      "batch 7521  loss=146.9562  steps/s=100.29  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"n e e            i  t tt itttt/t///////t\"\n",
      "batch 7522  loss=179.7634  steps/s=41.66  prediction: \"ly: @Purring_Lynx Good addition for sure\" => \"y:     o i     i  ttt tttttt//////////tt\"\n",
      "batch 7523  loss=144.7055  steps/s=107.49  prediction: \"uch  there would be to take into account\" => \"thihn  h    hh                      t   \"\n",
      "batch 7524  loss=155.0741  steps/s=101.38  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \"hr  s  u    a a    aa ooo o  o   o    o \"\n",
      "batch 7525  loss=156.7879  steps/s=69.17  prediction: \"yacineMTB Its addicting stuff be careful\" => \":c     a      a daddddtt te  ee  f  e ie\"\n",
      "batch 7526  loss=161.9591  steps/s=108.36  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"tei       s  o oinnnnnonttnntt/tt/t//t//\"\n",
      "batch 7527  loss=150.6159  steps/s=102.65  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \"  se                            ////////\"\n",
      "batch 7528  loss=169.1083  steps/s=103.61  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"epl   i gKA?MC!;x!vk!!.!!!k!5xá´„!^!VMR$D!\"\n",
      "batch 7529  loss=171.3336  steps/s=96.06  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"h L oa rrncnn000000ttttssttt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ykyy\"\n",
      "batch 7530  loss=146.9815  steps/s=103.93  prediction: \"de it one of the best ive had in a while\" => \" r    i   i    t  t      e   e          \"\n",
      "batch 7531  loss=145.2407  steps/s=97.89  prediction: \"n pulls models too, but only from github\" => \" i  et             e     oo     o       \"\n",
      "batch 7532  loss=145.4327  steps/s=104.65  prediction: \"If are not one, you stand out like crazy\" => \"    e  e ee    ne             o         \"\n",
      "batch 7533  loss=143.6836  steps/s=100.25  prediction: \"ond\n",
      "but a fool with a sword is dangerous\" => \" ea sa                                  \"\n",
      "batch 7534  loss=158.2424  steps/s=103.47  prediction: \"Koala that would be much appreciated, ty\" => \"assaaaKaaaaaaaa a a              a aaa a\"\n",
      "batch 7535  loss=144.9705  steps/s=102.81  prediction: \"ool looking games, and get more interest\" => \" d e  looolooooooooo                  ee\"\n",
      "batch 7536  loss=194.3195  steps/s=64.38  prediction: \"@IterIntellectus https://t.co/7QXmzFoC4o\" => \"bacinlMooolllll                    eeeee\"\n",
      "batch 7537  loss=156.8290  steps/s=106.55  prediction: \"ways but in many cases it holds you back\" => \"irl r l l   a      a   a  a             \"\n",
      "batch 7538  loss=147.7732  steps/s=95.11  prediction: \"kaysh No I have to run the code manually\" => \"  w   a          a a                  a \"\n",
      "batch 7539  loss=181.0089  steps/s=57.25  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @aa a            a                 aaa\"\n",
      "batch 7540  loss=148.9329  steps/s=116.68  prediction: \"od simclusters chosen principle engineer\" => \"   e      o       sssessss ssssccenneenn\"\n",
      "batch 7541  loss=138.3177  steps/s=104.49  prediction: \"d take a bite of a giant company's lunch\" => \" ti a                           a       \"\n",
      "batch 7542  loss=136.3313  steps/s=103.92  prediction: \"et good at the ones youre not so good at\" => \" tandat        t                  oooooo\"\n",
      "batch 7543  loss=154.6086  steps/s=105.32  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  ae ci   e    e    e             r   r \"\n",
      "batch 7544  loss=140.7506  steps/s=103.37  prediction: \"entation, the cooler everything will get\" => \"  te ottt tttttttttooooeeeeeeeee eeeee e\"\n",
      "batch 7545  loss=150.3148  steps/s=74.13  prediction: \"minus9 This is my new favorite edm track\" => \"ane etomiit    o      eeeeee eeeiie  e e\"\n",
      "batch 7547  loss=170.4761  steps/s=106.40  prediction: \"ived did. Its pribably more fun that way\" => \"ne a   i   i   ii  i    ii       r      \"\n",
      "batch 7550  loss=208.8395  steps/s=98.18  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"eit    saj._ILÊŸÊŸá´á´¡Ê€Ê€á´€á´€E_Aqá´˜á´˜á´ÉªÉªIá´›á´›Êœá´‡É´É´á´¡á´¡\"\n",
      "batch 7551  loss=147.3259  steps/s=103.96  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" t          mm mmmmmmemmmeeeoeeooee  ooo\"\n",
      "batch 7552  loss=145.2752  steps/s=103.69  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"h ntontt ii iiii iiiioiiiioooorooorrrror\"\n",
      "batch 7554  loss=137.8840  steps/s=103.72  prediction: \"r this, practice it to get skilled at it\" => \"esup al az.;+;F_,á´€@:&&,Êœá´‡&vjá´¡.ÊŸIMá´‡/á´„á´€.M&\"\n",
      "batch 7555  loss=158.7584  steps/s=105.39  prediction: \"utput in readme\n",
      "\n",
      "https://t.co/hKCmvzerIc\" => \"s     p              ttttttttt/t//t/////\"\n",
      "batch 7556  loss=154.2120  steps/s=103.31  prediction: \"h, that explanation/example makes sense'\" => \"e   oa h h hh hhaaaaaaaaaaxaaaaaaaeeeeee\"\n",
      "batch 7558  loss=167.3995  steps/s=102.40  prediction: \"oing the deadline thing\n",
      "Works super well\" => \" n tat   t   t    dd dddieiiiniiiee ee e\"\n",
      "batch 7559  loss=148.8969  steps/s=97.24  prediction: \"s I love zig\n",
      "Are you doing the ziglings?\" => \" tnt,    e   e  e eee iii      o   g ggg\"\n",
      "batch 7561  loss=165.5615  steps/s=101.20  prediction: \"rop from scratch https://t.co/1UU2vBEGsS\" => \"eml y @PgF!!!!!!!!!!!!!!!!!!!!!MLP!!!!!!\"\n",
      "batch 7562  loss=147.3384  steps/s=104.67  prediction: \"h yes it is? I would literally sit on aâ€¦\" => \"ei  oo uu                       lllll  l\"\n",
      "batch 7563  loss=143.6460  steps/s=104.07  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eoo  n       neeeee  e e eeeee        \"\n",
      "batch 7564  loss=139.6744  steps/s=103.99  prediction: \"ed around the data that flows through it\" => \"  eteee d     ed dd  d  aa  a t  t tt tt\"\n",
      "batch 7565  loss=133.3422  steps/s=103.71  prediction: \" with a small group of people around you\" => \"to to                      oo    oppooo \"\n",
      "batch 7566  loss=150.6286  steps/s=99.27  prediction: \"iplying cells literally changed my life.\" => \"n tot  iiilllllllllllllllllllllllal     \"\n",
      "batch 7567  loss=151.5629  steps/s=104.72  prediction: \"king progress. Now i see it eeeverywhere\" => \" na    a                        eeeeeeee\"\n",
      "batch 7569  loss=144.7551  steps/s=100.78  prediction: \"be setting a deadline might help as well\" => \"e   i          n          e             \"\n",
      "batch 7570  loss=150.9959  steps/s=102.97  prediction: \"ey once, will play otb w friends usually\" => \"    a                   l               \"\n",
      "batch 7571  loss=143.9230  steps/s=104.17  prediction: \"r coding lol. And some chess. Great move\" => \"el z   eh0w;&A&z7;0K(UGkGUUzGG7v(T..AA8T\"\n",
      "batch 7572  loss=165.6365  steps/s=52.28  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @Buaiooooooo   o   o                  e\"\n",
      "batch 7573  loss=147.0404  steps/s=107.05  prediction: \" cliff in one go. like, good luck w that\" => \"to             f                        \"\n",
      "batch 7574  loss=153.6337  steps/s=82.56  prediction: \"xluffyb interest is a powerful thing man\" => \" 0pfhffffff    e         o o oo         \"\n",
      "batch 7575  loss=138.9447  steps/s=109.03  prediction: \"chat is this what sweat equity means????\" => \"ee   ht  ttttt t t         w  t    ttat \"\n",
      "batch 7576  loss=151.8750  steps/s=104.17  prediction: \"efitted from tracking sleep and whatnot?\" => \" f y e eeeeeeeete  te         ee   e    \"\n",
      "batch 7579  loss=133.8382  steps/s=97.12  prediction: \"have you seen the walmart aura points ad\" => \"ete oivev e e  ee ee   eee aaaaaaaaaaa a\"\n",
      "batch 7580  loss=145.1584  steps/s=105.16  prediction: \" dingboard. Several others ive seen irl.\" => \"tome  i                    eeeeeeee eeee\"\n",
      "batch 7582  loss=163.0488  steps/s=58.64  prediction: \" @llamapuckey never visit sf without jug\" => \"tlne  iaad    ee eeev   e   e eeeeeeeee \"\n",
      "batch 7583  loss=215.7509  steps/s=36.81  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly: @ aad    eeeeevv   e     eeeeeee   \"\n",
      "batch 7584  loss=237.8445  steps/s=41.14  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eply: @ Lzv6666kL6KKKK://KKTT/YxFjHx2RY6\"\n",
      "batch 7585  loss=148.8103  steps/s=110.20  prediction: \"ight any pros youd get in the short term\" => \"nh oe t  y    oy                 t    t \"\n",
      "batch 7586  loss=147.7967  steps/s=101.49  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"tuue e      a  aaaaa aa a        a  a   \"\n",
      "batch 7587  loss=149.0037  steps/s=104.40  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" re  tntttttttaaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttt/////////\"\n",
      "batch 7588  loss=160.8417  steps/s=103.97  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"ta   ee    ee    . .  ...  ....  /hh////\"\n",
      "batch 7589  loss=157.1330  steps/s=99.70  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"tacbc ceee777e b at ttttt ttttottt ttt t\"\n",
      "batch 7590  loss=149.9727  steps/s=105.70  prediction: \" on life event stuff\n",
      "- made progress onâ€¦\" => \"tn er e    e  ee ee ee e ef fff  e   e s\"\n",
      "batch 7591  loss=155.7941  steps/s=103.10  prediction: \"izer\n",
      "\n",
      "his uses a NN this uses Q learning\" => \"ne o      i ssssssss ssNNNNNsssss   ss  \"\n",
      "batch 7592  loss=160.8708  steps/s=75.29  prediction: \"oppflightkid That could be helpful yeah!\" => \"  slisi\n",
      "piiissss N   s    ss            \"\n",
      "batch 7593  loss=149.7052  steps/s=106.40  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"tn             t   ttt  ttttttttttt/////\"\n",
      "batch 7594  loss=173.9718  steps/s=80.10  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \" wa      p o   t t ttt pttttt////tZZZsZt\"\n",
      "batch 7595  loss=140.3773  steps/s=105.93  prediction: \"ot even remotely the same as a beginners\" => \"u e es  e eeeeeeeeeeeeeeeeee            \"\n",
      "batch 7596  loss=141.7710  steps/s=102.69  prediction: \"ool looking games, and get more interest\" => \"un e   ooolooooloooo                  ee\"\n",
      "batch 7597  loss=144.4200  steps/s=104.27  prediction: \"n while still being consistent each week\" => \" aho  s           l     i i iiiininnn ne\"\n",
      "batch 7598  loss=145.7817  steps/s=102.41  prediction: \" easy to use too\n",
      "https://t.co/EjkhiWdtX3\" => \"tanen nt       s     ttttttttt/////////t\"\n",
      "batch 7599  loss=149.6092  steps/s=92.11  prediction: \"eMTB i wonder which anime pfp is his alt\" => \" TBo  a         o otthhhhhh    ppppp p h\"\n",
      "batch 7600  loss=137.9207  steps/s=104.76  prediction: \" play instead of making random moves lol\" => \"to t t              aaa  aaaaa  a       \"\n",
      "batch 7601  loss=141.3884  steps/s=104.43  prediction: \"pired link broadcast out to the most ppl\" => \"lsta w                          t tttttt\"\n",
      "batch 7602  loss=150.4541  steps/s=105.18  prediction: \" carry/drop 100s per run\n",
      "\n",
      "auto lifeguard\" => \"ta  e  a  r  r   rr00000r rrrrr  r   u  \"\n",
      "batch 7603  loss=139.1010  steps/s=104.66  prediction: \"cool ML/studying/building posts are gone\" => \"hn eth        o oooo///i/iiiiiiiiiiiiggg\"\n",
      "batch 7604  loss=149.4886  steps/s=100.50  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"g i thaeeieeeeieeieieeeeeeeee  eee e eee\"\n",
      "batch 7605  loss=133.9461  steps/s=104.93  prediction: \"e\n",
      "graphics programming is so awesome man\" => \" Ye       p p   r rrrrrrmrrgggg   is mm \"\n",
      "batch 7606  loss=144.1365  steps/s=103.49  prediction: \"es absolute security\n",
      "its like proving H0\" => \"  eressesseeesesssususuuuuss es   riiii \"\n",
      "batch 7607  loss=142.9898  steps/s=103.93  prediction: \"epts end up just being 'oh its just xyz'\" => \" lyao                                   \"\n",
      "batch 7608  loss=146.8402  steps/s=102.76  prediction: \"f time and space that can reach in here?\" => \" wie o   i       e       a   aaa a      \"\n",
      "batch 7610  loss=140.9465  steps/s=101.34  prediction: \" ig i still dont understand comonads yet\" => \"ts hih   i   i  i       t    t dnnndnndn\"\n",
      "batch 7611  loss=155.1625  steps/s=102.96  prediction: \"r you choose is not technically infinite\" => \"ean     i,[ÉªðŸ¤”xz(`@â€™*17^:Zâ€|$b|,xWvðŸ˜­$â€ð˜€17\"\n",
      "batch 7612  loss=142.0606  steps/s=103.78  prediction: \"ool looking games, and get more interest\" => \"ul   o ooolooooloooo                  ee\"\n",
      "batch 7613  loss=144.7744  steps/s=101.63  prediction: \" pried the shift key off w a screwdriver\" => \"taneeaa  a e     e   e     f   f     f  \"\n",
      "batch 7614  loss=133.5693  steps/s=99.14  prediction: \"t gotta watch out for the poison lizards\" => \"hte y  tttttttttttttttt t         o o   \"\n",
      "batch 7615  loss=148.6467  steps/s=88.69  prediction: \"builds mcdonalds just wants to grill man\" => \"ei ue tbb          o         tt   t     \"\n",
      "batch 7616  loss=158.8562  steps/s=105.94  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \"p ffg n nn    nn   o    t    ttgggg gg g\"\n",
      "batch 7617  loss=141.9867  steps/s=102.83  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot i                        ttttt//////\"\n",
      "batch 7619  loss=151.0171  steps/s=105.11  prediction: \"snt, now i think and focus waaaay better\" => \" teptt       i            n     aaa aaa \"\n",
      "batch 7620  loss=151.2000  steps/s=103.31  prediction: \"well\n",
      "\n",
      "maxing it out is worth considering\" => \"ant  Pn  e    nn   i               o   i\"\n",
      "batch 7621  loss=145.7608  steps/s=101.65  prediction: \"g i can make some insanely helpful stuff\" => \" h  eie  i in  e         n    e eene    \"\n",
      "batch 7622  loss=155.1984  steps/s=103.84  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"  e  epp 3333 o         o      o       s\"\n",
      "batch 7623  loss=139.5227  steps/s=105.29  prediction: \"ot even remotely the same as a beginners\" => \"n ece      eeeeeeeeeeeeeeeee            \"\n",
      "batch 7624  loss=183.7335  steps/s=64.50  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"yudqaeM eeeeeee  tt e eeeee       !!! e \"\n",
      "batch 7625  loss=155.4462  steps/s=106.09  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"    sentetttttetttteteeeeeeneeeeein  i  \"\n",
      "batch 7626  loss=151.4921  steps/s=104.90  prediction: \"ld love to hear if you dont mind sharing\" => \"y  @lap o   o  l       o  o             \"\n",
      "batch 7627  loss=146.6552  steps/s=105.30  prediction: \"e info produced by exploring new options\" => \" iiaii nn  n   nn        d  e         oo\"\n",
      "batch 7628  loss=168.7202  steps/s=101.31  prediction: \"eople be bookmarking anything these days\" => \" pi i@_M p pe   bobbo  oo     nononn n n\"\n",
      "batch 7629  loss=145.4565  steps/s=104.48  prediction: \" loss (erroneously a vector) as a scalar\" => \"tot eh h       eoooooo   e              \"\n",
      "batch 7630  loss=217.1180  steps/s=101.16  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OTOIWYWOTNOOTNNNOON  N           ///  //\"\n",
      "batch 7631  loss=171.6706  steps/s=104.41  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"n       ,     o    o  tttt  tttttt////t/\"\n",
      "batch 7632  loss=136.5113  steps/s=101.25  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \" :e a         e\n",
      " eeteeeeeeeeeeee eeeeeee\"\n",
      "batch 7633  loss=157.6220  steps/s=105.94  prediction: \"ort (effort is proportional to time butâ€¦\" => \"ne te t ft ttff fff oroooooooo otooo to \"\n",
      "batch 7634  loss=152.1850  steps/s=105.40  prediction: \"just think your program into existence?\"\" => \"usto    t   t  t    u    r     r    o   \"\n",
      "batch 7636  loss=146.3750  steps/s=104.38  prediction: \"he result, its equivalent to convolution\" => \"e  e i r  re ret e teeesstt te tt  ovt  \"\n",
      "batch 7637  loss=173.4278  steps/s=104.60  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"n,  rs  ,     o    o  tttt  tttttt////t/\"\n",
      "batch 7638  loss=165.0153  steps/s=44.81  prediction: \"y: @melqtx every mon and thurs ma brotha\" => \"  @n n  o     o    t ttttttt////tt////tt\"\n",
      "batch 7639  loss=172.9000  steps/s=92.63  prediction: \": @RajenJangam Thanks! Glad you liked it\" => \" @Habwt o     o   ot ttttttt//// t/otttt\"\n",
      "batch 7640  loss=183.9768  steps/s=58.32  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @   o    e  m ttant/tttt//oo m otttðŸ›‘\"\n",
      "batch 7642  loss=172.6590  steps/s=106.63  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..coosoo///o////ttototttt/ttttt////t///\"\n",
      "batch 7643  loss=152.1276  steps/s=106.04  prediction: \"e real for this\n",
      "\n",
      "https://t.co/XuMxlWAwBE\" => \" biaallllaalrara lr \n",
      "\n",
      "  t\n",
      "\n",
      "\n",
      "tttt\n",
      "\n",
      "ttttt/\"\n",
      "batch 7644  loss=153.1928  steps/s=102.08  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"toe ae!              nnnnnnnnnnnnnn     \"\n",
      "batch 7645  loss=153.1496  steps/s=100.40  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"eyb @naeeeeeeee e eeeett\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "o o     a\"\n",
      "batch 7646  loss=159.5232  steps/s=75.99  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \"hat et e    t  lloooottttttt   s s    nn\"\n",
      "batch 7648  loss=141.6417  steps/s=103.81  prediction: \"o actually understand the program better\" => \"nt   s  t        a aaaaaa   t   a     tr\"\n",
      "batch 7649  loss=142.1169  steps/s=104.55  prediction: \"n while still being consistent each week\" => \" tho  a           l     i i iiiininnn ne\"\n",
      "batch 7650  loss=158.2712  steps/s=99.73  prediction: \"king one open rn just cause of this post\" => \" n aciaaiiia   en  nnn nn    e  s    s  \"\n",
      "batch 7651  loss=130.7636  steps/s=101.40  prediction: \"lms\n",
      "and lots and lots of trial and error\" => \"y  @d pnllll      ll                    \"\n",
      "batch 7652  loss=157.0300  steps/s=101.76  prediction: \" the 16 hour coding session, lets get it\" => \"thnn 7 7                      ossssssss \"\n",
      "batch 7654  loss=141.8375  steps/s=104.48  prediction: \" get to master idk depends on your goals\" => \"te eeee e   e  t      t   d dd d  d  o  \"\n",
      "batch 7655  loss=161.5605  steps/s=105.97  prediction: \"nus9 Thats super useful to know actually\" => \"dtma         ss ss ss eesss          o  \"\n",
      "batch 7657  loss=158.1814  steps/s=99.23  prediction: \"rip\n",
      "\n",
      "he open sourced it to @crypt0x_0 ig\" => \"enly: @oxPBIY!@NvvvjNC9WTk@_16!!Mj_N:v\"A\"\n",
      "batch 7658  loss=151.4651  steps/s=54.20  prediction: \": @teodor_io funny number go up type shi\" => \" @taT ah h   e  e ee ee          ttt0t  \"\n",
      "batch 7659  loss=144.3277  steps/s=106.23  prediction: \"re obvious. some are really hard to see.\" => \"e les timw.IY_@w2v:kyC-jTY@_.6DC0x_C:K+A\"\n",
      "batch 7660  loss=148.4294  steps/s=104.14  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"re  a    ad ad    aa   aa  a   a     nn \"\n",
      "batch 7661  loss=150.2868  steps/s=104.58  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \"ar s s             tttttttttttttttt/////\"\n",
      "batch 7662  loss=144.2805  steps/s=104.56  prediction: \"so i havent used anything like webgl yet\" => \"  so     s  s    s           n        ee\"\n",
      "batch 7663  loss=137.7520  steps/s=102.62  prediction: \"that was probably its entire purpose lol\" => \" e i itettttttt tt   t   t      t       \"\n",
      "batch 7664  loss=146.7419  steps/s=103.59  prediction: \"o you get more data) or hit a \"dampener\"\" => \"ns t  o      o                          \"\n",
      "batch 7665  loss=149.0077  steps/s=101.58  prediction: \"ely grinded like mad towards His mission\" => \" lso lllllllllllee e     ddd ddd      ii\"\n",
      "batch 7666  loss=135.6185  steps/s=103.94  prediction: \"ast 3 weeks so development has been slow\" => \"n  n     e       e  e  e eeee eeeeeeee  \"\n",
      "batch 7667  loss=160.8069  steps/s=103.47  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"e ph  trrorrrrr rr aaaaaa aaa a aaaa a  \"\n",
      "batch 7668  loss=179.1036  steps/s=103.49  prediction: \"h, global frames\n",
      "https://t.co/cXzSAmjmet\" => \"e  ntd tllllllt  llalllttttt/s////tt//tt\"\n",
      "batch 7669  loss=139.4426  steps/s=103.72  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e a at   a        e   ththhttttt////t///\"\n",
      "batch 7670  loss=152.7834  steps/s=104.11  prediction: \"f thing = free yourself to chase rewards\" => \" ae     ff rr    feeee   ee e    oe ee  \"\n",
      "batch 7671  loss=138.3015  steps/s=100.10  prediction: \"thing you do very often, like constantly\" => \" a a                                    \"\n",
      "batch 7672  loss=145.0447  steps/s=103.04  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lnt @e m               \"\"\"         aaaaa\"\n",
      "batch 7673  loss=149.0216  steps/s=101.34  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" m s  e                              ooo\"\n",
      "batch 7674  loss=150.3668  steps/s=102.05  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "rha  n r+v''_4@'L==''VwVj'==B**!'E''''A\"\n",
      "batch 7675  loss=148.6808  steps/s=102.24  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"ts    o       o           ttttttoootttt/\"\n",
      "batch 7676  loss=146.7037  steps/s=100.09  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"     s sssssss       o        n   n   n \"\n",
      "batch 7677  loss=152.7788  steps/s=103.17  prediction: \"ready having better days from this stuff\" => \"eply: @ yc=-?_-)kLjS0-Bwvv8=Wbb?!5EL:-\"A\"\n",
      "batch 7678  loss=144.8386  steps/s=104.18  prediction: \"of the network (target, a_output, loss,â€¦\" => \"n e                  ttttttttttttttttt,,\"\n",
      "batch 7679  loss=166.0808  steps/s=89.29  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" b oe               ttttttttttttttooo,tt\"\n",
      "batch 7680  loss=183.7260  steps/s=114.29  prediction: \" QUICK delete this before sphere sees it\" => \"tuee     lll    etteteeettte oeoeeoesees\"\n",
      "batch 7681  loss=144.9031  steps/s=99.89  prediction: \" the scaling laws for language models...\" => \"the e e   e       t    l   a  g g aggggg\"\n",
      "batch 7683  loss=150.0175  steps/s=105.61  prediction: \"ould help large numbers of ppl if solved\" => \"fr ereo    llllr  ee   le e   ep  l   l \"\n",
      "batch 7684  loss=140.6746  steps/s=105.26  prediction: \"emely hard to avoid being pressured into\" => \"   i   eeeee e e                   e    \"\n",
      "batch 7685  loss=142.9283  steps/s=105.48  prediction: \"DLR but could just be forward/left/right\" => \" pi p          u     u              r  r\"\n",
      "batch 7686  loss=145.3749  steps/s=105.52  prediction: \"iration theres some awesome ppl in there\" => \"n  ot   ii iii ii r s se eeeseee eeeee e\"\n",
      "batch 7687  loss=136.3705  steps/s=104.84  prediction: \"they are more than happy to pay for them\" => \"he    eee eeee ee   e     h  p   p      \"\n",
      "batch 7688  loss=194.5654  steps/s=29.71  prediction: \"ply: @andrew_pynch fundamentals compound\" => \"le  @ eee eeee e    h     h  p   p      \"\n",
      "batch 7689  loss=140.3875  steps/s=106.89  prediction: \"o him) and he begged to pay me to use it\" => \" a  i t        n                        \"\n",
      "batch 7690  loss=159.8637  steps/s=102.92  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"ene   m              s  s  t tttt//////s\"\n",
      "batch 7691  loss=148.3789  steps/s=100.70  prediction: \"important piece of advice here by a mile\" => \"np _aaaa na t  n t t     i  ee  ee e    \"\n",
      "batch 7692  loss=152.1867  steps/s=104.26  prediction: \"\" and idk what that is? Time to learn it\" => \" aoisi ss    a      a     t   t         \"\n",
      "batch 7693  loss=134.7431  steps/s=104.80  prediction: \" not their fault imo. that used to be me\" => \"tow   t                     tt          \"\n",
      "batch 7694  loss=151.2932  steps/s=104.01  prediction: \"ting the entire GOL industry as we speak\" => \" cta m         t   t                    \"\n",
      "batch 7695  loss=149.5032  steps/s=103.41  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" yo g iiiiooooon  o                    a\"\n",
      "batch 7696  loss=152.7425  steps/s=98.05  prediction: \"free could help too if thats the problem\" => \" i  @tuu uuu   l    e            t   t  \"\n",
      "batch 7697  loss=178.9745  steps/s=59.26  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"tSg   eee  el   e   o     t tt   t      \"\n",
      "batch 7698  loss=148.1473  steps/s=105.57  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efn    og@jOv'_@G,''xxw'/\"\"\n",
      "OOv.''-9.zR2\"\n",
      "batch 7699  loss=146.4984  steps/s=101.51  prediction: \"ht them the openscad to make the pulleys\" => \"et  te    h   h hh  e  t  e        e    \"\n",
      "batch 7700  loss=145.0506  steps/s=103.10  prediction: \"t\n",
      "so.. hopefully i can get it to do that\" => \" \n",
      "t t        e ee                       \"\n",
      "batch 7701  loss=154.0988  steps/s=102.10  prediction: \" gzip compression loss continues to fall\" => \"tos s  a       pp   ssssssssssssnosssoos\"\n",
      "batch 7702  loss=133.0547  steps/s=102.02  prediction: \"trained though through practice, luckily\" => \" aa ea           tt h hhhhhhhhhhhh ccc c\"\n",
      "batch 7703  loss=151.5242  steps/s=104.70  prediction: \"t 200hrs in around the same time you did\" => \" feo        00 0                        \"\n",
      "batch 7704  loss=145.0596  steps/s=104.69  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tne  eed ddd  d  d     rrrrr rrrrrr r   \"\n",
      "batch 7705  loss=169.5391  steps/s=98.32  prediction: \"yup totally agree. Very powerful mindset\" => \" e  ra  aa     a a     rre   ee r ee  ei\"\n",
      "batch 7706  loss=99.5453  steps/s=103.84  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"touOOOO \n",
      "\n",
      " aaaa    aa??aaaa??   aa   EE \"\n",
      "batch 7707  loss=148.9945  steps/s=104.70  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"amted t rtrtttretttt .ttt...t....///////\"\n",
      "batch 7708  loss=145.3458  steps/s=100.36  prediction: \"forming around AI or aroumd a fear of AI\" => \" rme t        nn      r      r  r  r    \"\n",
      "batch 7711  loss=145.4960  steps/s=104.26  prediction: \"g us calculate costs some weird jank way\" => \" t a   a       aa a   sssss sss         \"\n",
      "batch 7712  loss=161.4812  steps/s=100.44  prediction: \"minds me of this https://t.co/bGCVZbuoNU\" => \"ene         e              ttttttt//////\"\n",
      "batch 7713  loss=162.8313  steps/s=100.42  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BT  ilP@@@@@ A@Astsstttt  oo ooooo o  o\"\n",
      "batch 7714  loss=142.6189  steps/s=104.34  prediction: \"deviating\n",
      "and it lets you do that faster\" => \" no     eennanneninii i     t  t    t   \"\n",
      "batch 7715  loss=151.8827  steps/s=105.38  prediction: \"\" and idk what that is? Time to learn it\" => \" aoos\" ss    a      a     t   t         \"\n",
      "batch 7716  loss=155.7746  steps/s=91.36  prediction: \"igABAP Born to consoom, forced to signal\" => \"nAa a   d        t    o  o              \"\n",
      "batch 7717  loss=151.7861  steps/s=104.45  prediction: \" is a wild computational rabbithole man.\" => \"tm  pae     aa accc   aa aaa i aaai aabl\"\n",
      "batch 7718  loss=157.6462  steps/s=103.71  prediction: \"r, ill dm you the link when that happens\" => \"e ey i nsfZZ25ZAPZZZ+ZKK%K225Z+,5+252++Q\"\n",
      "batch 7719  loss=162.9028  steps/s=103.10  prediction: \"uper hard but I think it could be doable\" => \"terg   rprrpa rp rr       t  t        d \"\n",
      "batch 7720  loss=143.9520  steps/s=100.15  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"tout ao                         e eeigeg\"\n",
      "batch 7721  loss=144.6779  steps/s=102.47  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"rs  t    o l  l   ll pllilllllllllll  ll\"\n",
      "batch 7722  loss=143.9966  steps/s=101.45  prediction: \" time on their hands + survivorship bias\" => \"th o                                riri\"\n",
      "batch 7723  loss=139.7161  steps/s=104.39  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e e o   e    e        tt  ttttt/tt/tt///\"\n",
      "batch 7724  loss=162.5308  steps/s=102.71  prediction: \"ke to continue it. Mnist is a great idea\" => \"e g          oon n tt t nniti iit  iit i\"\n",
      "batch 7725  loss=144.9555  steps/s=97.10  prediction: \"t in a position to help you at all loool\" => \" t  bro   o  oin i         oo  oo   o  l\"\n",
      "batch 7726  loss=155.8625  steps/s=105.26  prediction: \"t habit of reaching for my phone is gone\" => \" fo   t t t tt h     h  h               \"\n",
      "batch 7727  loss=153.4642  steps/s=104.00  prediction: \" it was all tactice, but this is the way\" => \"tn  n        tt at  tt  ta t  t ttt  i  \"\n",
      "batch 7728  loss=155.1694  steps/s=95.75  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t   te             ttstttttttttttt//////\"\n",
      "batch 7729  loss=148.8687  steps/s=104.30  prediction: \"l amazing, do what you like least, first\" => \"ywea a df  e  a aa  a    a              \"\n",
      "batch 7730  loss=155.9168  steps/s=102.41  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"Uhoe s              s???????ttstttt/////\"\n",
      "batch 7731  loss=151.5393  steps/s=98.50  prediction: \" gotchu fam\n",
      "sending the link as we speak\" => \"ton               ttttth t tnnnn       k\"\n",
      "batch 7732  loss=153.5930  steps/s=100.98  prediction: \"ombies, lethal company, misc other stuff\" => \" eloloo o                               \"\n",
      "batch 7733  loss=138.7529  steps/s=104.04  prediction: \"go, the name.. none of that shit matters\" => \" o    e    oo  t e   o   n n        tttt\"\n",
      "batch 7734  loss=159.6852  steps/s=63.48  prediction: \"@yacineMTB You want us to find our moms?\" => \"laneoee   ee.   on  nn   t         ttttt\"\n",
      "batch 7735  loss=138.8142  steps/s=109.39  prediction: \" like 1hr ago lol\n",
      "\n",
      "also is that your dog\" => \"teiw ii              l llllll           \"\n",
      "batch 7736  loss=145.5801  steps/s=101.39  prediction: \"ely grinded like mad towards His mission\" => \" laallll  leeeeleeee     d dddddd      s\"\n",
      "batch 7737  loss=141.1225  steps/s=102.81  prediction: \"orce you to clean to avoid embarrassment\" => \"               c                   aaaaa\"\n",
      "batch 7738  loss=145.4509  steps/s=103.77  prediction: \"y do what sounds more interesting to you\" => \" th uoo  o    o      o    o          tt \"\n",
      "batch 7739  loss=166.8189  steps/s=103.33  prediction: \"n and are kindaâ€¦ https://t.co/zyjcsUAF4i\" => \" m   nn   n  nn  aa  a         t//t/////\"\n",
      "batch 7740  loss=142.9498  steps/s=103.10  prediction: \"s aside though, why wouldn't that work?)\" => \" aooe eseesesssts   h hh  hh  h   h w w \"\n",
      "batch 7741  loss=161.5550  steps/s=85.09  prediction: \"rdenis grats btw. site looks amazing too\" => \"e lo: @ ubxjxk9j0BTPâ€¦U,Pb2R:T,P.P,'wQQQP\"\n",
      "batch 7742  loss=147.3132  steps/s=103.50  prediction: \"ely the case for chess and debugging imo\" => \" se: @ eeeee   ee                  g ggg\"\n",
      "batch 7743  loss=140.8960  steps/s=102.89  prediction: \"\n",
      "\n",
      "good potential source of cool projects\" => \"\n",
      "onty k(av_jxk9.DBJPâ€¦P,PRPb:J,uzP,w&QxQP\"\n",
      "batch 7744  loss=138.0311  steps/s=102.12  prediction: \" can see something 1000000x better to do\" => \"tat eaaa   a   neee  e  000000000000 e  \"\n",
      "batch 7746  loss=146.2652  steps/s=101.58  prediction: \"in there for sure\n",
      "Those guys are awesome\" => \"ng   e  ee  e  ee r rr  ee ee e     ee e\"\n",
      "batch 7747  loss=170.0750  steps/s=99.87  prediction: \"agreed\n",
      "try these\n",
      "https://t.co/c9RVGmZYrn\" => \"ne aaeeer erreer eeeteeeetttttsst/tst///\"\n",
      "batch 7748  loss=147.6798  steps/s=102.32  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \" on att                   i     s ss lll\"\n",
      "batch 7749  loss=160.7701  steps/s=53.71  prediction: \": @Wooltard @paulg Or better compression\" => \" Riooio        aaa       a ssss slslllll\"\n",
      "batch 7750  loss=155.8540  steps/s=106.26  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"tac  a aa  as   s mssssssssstttst///////\"\n",
      "batch 7751  loss=136.4542  steps/s=102.25  prediction: \"he audiobook content is better than both\" => \"e   th ttuuooooooooooooooottttttttttt tt\"\n",
      "batch 7752  loss=163.0201  steps/s=98.01  prediction: \" you find running helps you work better?\" => \"touta dddd     d  nnnn nnnn  n          \"\n",
      "batch 7753  loss=201.1838  steps/s=101.00  prediction: \"indie game of the year im calling it now\" => \"ng o  ???O                              \"\n",
      "batch 7754  loss=167.0545  steps/s=103.61  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"   oe  sss s  00000000000tttt//////tt/t/\"\n",
      "batch 7756  loss=154.0305  steps/s=106.08  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"teatt             f  f  t ttttt/////////\"\n",
      "batch 7757  loss=144.5489  steps/s=103.50  prediction: \"t the truth/reality?\n",
      "\n",
      "sounds paradoxical\" => \" ts po    t ttt tttttttttttttttt\n",
      "\n",
      "aaaaaa\"\n",
      "batch 7758  loss=141.1422  steps/s=99.47  prediction: \"y is that the levels of learning theory?\" => \":cieoe         t     l         e  e  eee\"\n",
      "batch 7759  loss=149.8797  steps/s=63.06  prediction: \"@vorpal_strikes Does it replicate tho???\" => \"jezocez  ttt  tt ee  e    e  eel  eeee ?\"\n",
      "batch 7760  loss=148.5991  steps/s=105.64  prediction: \" works if you did it right, or it doesnt\" => \"thkt                      i             \"\n",
      "batch 7762  loss=151.4094  steps/s=105.01  prediction: \" of how i debug and catch inefficiencies\" => \"tf i irr rr  a           a   a i   icfic\"\n",
      "batch 7763  loss=142.7712  steps/s=102.91  prediction: \"oo, and the school wasn't even built yet\" => \"ut i                                    \"\n",
      "batch 7764  loss=153.5855  steps/s=104.14  prediction: \"orn to make cash forced to consooolidate\" => \"r tt tttttt t           c  c   o ooooooo\"\n",
      "batch 7765  loss=144.1390  steps/s=98.71  prediction: \"ng sedenions for something in your game?\" => \"g tntrg     ess ssssososooeenn        n \"\n",
      "batch 7766  loss=141.4444  steps/s=97.50  prediction: \"feeling than automating hrs of work away\" => \"orr  Neeeeeeenn      o tnnn n           \"\n",
      "batch 7767  loss=169.7199  steps/s=58.06  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tgete eeeenn n n  a nt tnn  i  o    r  ðŸ›‘\"\n",
      "batch 7768  loss=148.4016  steps/s=107.76  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"tsto m  ommemm nmmemm  pe p eppep  eeee \"\n",
      "batch 7769  loss=142.8706  steps/s=105.19  prediction: \" try to figure out why your brain worksâ€¦\" => \"thot     t   t t t  u      u   y   r rr \"\n",
      "batch 7770  loss=151.3927  steps/s=105.14  prediction: \" but its worth it\n",
      "\n",
      "just make stuff thatâ€¦\" => \"tao    t   t   tt t  ttt tttt tttttt ut \"\n",
      "batch 7772  loss=160.2160  steps/s=105.68  prediction: \"sted this first)\n",
      "https://t.co/7AHwatHv6Y\" => \" ro  oo         s stttttstttstt////////t\"\n",
      "batch 7773  loss=161.5871  steps/s=101.88  prediction: \"sing llms to their full potential rn tbh\" => \" or  e ee     s    tl tl    t    lo   tl\"\n",
      "batch 7774  loss=149.8285  steps/s=105.14  prediction: \"ate, but I think about this all the time\" => \"r bn      t  t  t     t    tt  t        \"\n",
      "batch 7775  loss=150.9122  steps/s=100.63  prediction: \"ve feedback loop\n",
      "https://t.co/SvrkOEyyVo\" => \"e yo tttiiiieeeeeeeeeepppptttttotttt////\"\n",
      "batch 7776  loss=142.9498  steps/s=104.27  prediction: \"t info, hence why I expanded past papers\" => \"hst  ah                       e       pp\"\n",
      "batch 7777  loss=163.9541  steps/s=103.53  prediction: \" you find running helps you work better?\" => \"toud  d        d  nnnn nnnn  n        e \"\n",
      "batch 7779  loss=208.7306  steps/s=100.44  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"s  1o_o EEVEEEEV !!!!!!!!!!!!!   e  teet\"\n",
      "batch 7780  loss=136.1367  steps/s=104.31  prediction: \"d hire my friends to do research with me\" => \" to                                 r   \"\n",
      "batch 7781  loss=168.8819  steps/s=45.88  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \"  @ u     r  e          r ee rr   r r  e\"\n",
      "batch 7782  loss=137.6813  steps/s=108.98  prediction: \", usually because you border more things\" => \" an  ne  e   e  e ee e u uuuuu  e  e e r\"\n",
      "batch 7783  loss=153.5271  steps/s=102.37  prediction: \"if the anthropic one is taking a beating\" => \"n oe         t   o   n     in  i  i     \"\n",
      "batch 7784  loss=154.0685  steps/s=93.39  prediction: \" version control https://t.co/syhjjWL8M6\" => \"ten e    ee onoooon oo tt ttttt   aataaa\"\n",
      "batch 7785  loss=161.9305  steps/s=105.34  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e lee o s0JJIMJZS@,.EXACT!I!JJIJIZ!\n",
      "XACT\"\n",
      "batch 7786  loss=158.2258  steps/s=100.57  prediction: \"h i dont remember getting much out of it\" => \"et de   e    eedeeeeeeeeeee e e   t     \"\n",
      "batch 7787  loss=142.0981  steps/s=104.88  prediction: \"ve implemented 50% of the mobile version\" => \"e  ae i immmmemeee   ee ee eee  e   e  e\"\n",
      "batch 7788  loss=142.0777  steps/s=97.79  prediction: \"cking it was kobe posting the whole time\" => \"k i  ieee tt                o    e      \"\n",
      "batch 7789  loss=157.6470  steps/s=102.35  prediction: \"though who knows\n",
      "https://t.co/YpddagC5uf\" => \"hes ia aa     hh hohhhhhhthhtttttot//o//\"\n",
      "batch 7792  loss=146.2031  steps/s=100.50  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \" kalw                       tt//////////\"\n",
      "batch 7793  loss=153.7494  steps/s=104.91  prediction: \"y cool implications, seems like it would\" => \":th ve        ic iiiiiioo  isssss i  ii \"\n",
      "batch 7797  loss=154.6462  steps/s=103.24  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \"  aao   i    i    i  s    s sts sss ss t\"\n",
      "batch 7798  loss=141.2767  steps/s=105.26  prediction: \" get to master idk depends on your goals\" => \"te oeee e   e  t      t   d dd d  d  o  \"\n",
      "batch 7799  loss=169.0515  steps/s=51.11  prediction: \": @0xluffyb graphics programming be like\" => \" @gamoe e   t  e      e e d          o  \"\n",
      "batch 7800  loss=156.3162  steps/s=112.43  prediction: \" w as in why tf would you use white mode\" => \"te eepe   e    n      w        u   u   u\"\n",
      "batch 7801  loss=153.3080  steps/s=103.99  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  ae ci   e    e    e             r   r \"\n",
      "batch 7802  loss=172.4487  steps/s=98.45  prediction: \"le77 Good stuff brotha\n",
      "\n",
      "looks productive\" => \"yck@cee c777777n o    t rrrttt \n",
      "\n",
      "\n",
      "oo    \"\n",
      "batch 7803  loss=140.4962  steps/s=103.97  prediction: \" some but its not easy to put into words\" => \"tee e s        s                 tt tt t\"\n",
      "batch 7804  loss=162.1718  steps/s=99.62  prediction: \"lda is better than 3D Zelda\n",
      "\n",
      "its vanilla\" => \"y  @the      t e    t        e      a a \"\n",
      "batch 7805  loss=140.4553  steps/s=105.44  prediction: \"nd me tracks and ill render them for you\" => \"d  e cd                                 \"\n",
      "batch 7806  loss=144.9739  steps/s=100.13  prediction: \" the scaling laws for language models...\" => \"the r e   e       t    l   a  g   aggggg\"\n",
      "batch 7807  loss=151.7521  steps/s=106.22  prediction: \"new following you was the right decision\" => \"ds9e iaa h    ww ww  o www  oo      e   \"\n",
      "batch 7808  loss=171.6187  steps/s=96.72  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"y  @B setttt  o  o   s   s  tttt/////itr\"\n",
      "batch 7809  loss=154.2295  steps/s=100.60  prediction: \"s a crazy valuable source of improvement\" => \" t l aaaaaa aaaa aaaaaa a              e\"\n",
      "batch 7810  loss=158.5068  steps/s=104.04  prediction: \"effJezos Right to learn\n",
      "Right to compute\" => \" uau @eeeeeeesseeeeee     RRRRR t     to\"\n",
      "batch 7811  loss=170.8145  steps/s=97.42  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"@f  eeeB i      ttttttttttttttt/////ctcc\"\n",
      "batch 7812  loss=185.5312  steps/s=78.07  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"ehefecJ           RRFFtt//////////ZZZZZ/\"\n",
      "batch 7813  loss=147.0747  steps/s=106.24  prediction: \"dont just mean wrt doing logic with them\" => \"  he   n n   nne    n   n     n   o i   \"\n",
      "batch 7814  loss=156.2060  steps/s=98.10  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"HStd notooo    ra  aaa  n n      o      \"\n",
      "batch 7815  loss=141.4033  steps/s=103.40  prediction: \"can help guide them towards better stuff\" => \"on he   e      e   e   ee   e   ttt  ttt\"\n",
      "batch 7816  loss=150.7319  steps/s=104.53  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"he               ttttttttttttttttttt////\"\n",
      "batch 7817  loss=161.5764  steps/s=100.11  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \" Fa ea aeoellleeellllooloo/oo////ttt////\"\n",
      "batch 7818  loss=145.2760  steps/s=105.22  prediction: \"ur goal is to obliterate them with ideas\" => \"s eno    ro o        o o to t tt  tte  t\"\n",
      "batch 7819  loss=163.3367  steps/s=99.65  prediction: \"racticing self control leads to strength\" => \"eprea e ldBI0x_0bbTRkRjxv,,z??,wwbL5bjFx\"\n",
      "batch 7820  loss=156.7338  steps/s=96.67  prediction: \"7 make money so you can make video games\" => \"7rmyrycci777 e n ooeo oo  o   aa   e e  \"\n",
      "batch 7821  loss=166.8005  steps/s=103.12  prediction: \"ped\n",
      "mean = 84.75 https://t.co/B3Ji1JkdXr\" => \"lre poaee eeea ea e a  4ep     tt ///JJJ\"\n",
      "batch 7822  loss=147.7765  steps/s=103.67  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \"dby ert                   i     s ss s l\"\n",
      "batch 7823  loss=149.2383  steps/s=57.53  prediction: \" @startupmillyair lichess or chessdotcom\" => \"tyet          alaa i  i   ss  sssussllll\"\n",
      "batch 7824  loss=158.0369  steps/s=107.38  prediction: \" srsly the golden age of building things\" => \"te                                    g \"\n",
      "batch 7825  loss=138.1434  steps/s=103.57  prediction: \"ny depressions ripple to other countries\" => \"  ie  o ee     esss sssss  e  e  o  oo o\"\n",
      "batch 7826  loss=144.8301  steps/s=105.71  prediction: \"r reward, wrecking the incentive to work\" => \"eiee et t_Q6QT1(ðŸ¤¯@K,10ðŸ¤¯K.Kxzz!KKK10Q&&&;\"\n",
      "batch 7827  loss=203.5227  steps/s=100.28  prediction: \"__11hz LETS GET IT\n",
      "im hyped for thursday\" => \"______________ 1 E TTTTTT  T T e        \"\n",
      "batch 7828  loss=148.8159  steps/s=101.94  prediction: \"own to play more. was a pleasure as well\" => \"   e           m               a aaaaaa \"\n",
      "batch 7830  loss=146.9373  steps/s=103.26  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"tetn  eee eee   ee eetttettttttttttt///D\"\n",
      "batch 7831  loss=156.7093  steps/s=93.68  prediction: \"hag_ its good to be on the outside again\" => \"evg   e        toto tott o  t  otttoooXt\"\n",
      "batch 7833  loss=187.7180  steps/s=41.38  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: @Aarrgg     ooto oo  t   tttotttooooH\"\n",
      "batch 7834  loss=157.4128  steps/s=118.55  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tn e ooooog ooig  ii iiiiiiiiiii        \"\n",
      "batch 7835  loss=160.7847  steps/s=99.39  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" Bn  o PAAAAAAA@As   ee      e          \"\n",
      "batch 7836  loss=147.8260  steps/s=104.88  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efe d  ogl6Ov6\"jb,61xxcL/zP\n",
      "OOv!U:61JzRD\"\n",
      "batch 7837  loss=141.8646  steps/s=105.85  prediction: \"doing stuff their mind doesnt want to do\" => \"  n            n                        \"\n",
      "batch 7838  loss=141.1941  steps/s=102.73  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \"hr e ileeeeeeeeneeeeeelelll sssssssssss \"\n",
      "batch 7839  loss=144.3220  steps/s=104.29  prediction: \"e session, just wake up without an alarm\" => \" t         e   n   ss                   \"\n",
      "batch 7840  loss=147.0695  steps/s=103.93  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"eplyme@ w.{{qUqDEKR_@M5R{_yIRMX:EE{.{#R}\"\n",
      "batch 7841  loss=145.7159  steps/s=104.45  prediction: \"sonnet3.5 for pretty much everything now\" => \"  ese eee se        et  tt     ee   tt  \"\n",
      "batch 7842  loss=200.6036  steps/s=40.21  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: teenee se   s e  tt  tt     eete et  \"\n",
      "batch 7843  loss=211.2190  steps/s=127.38  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"ei y: @ ub__m6ÊŸÊŸá´á´¡Ê€Ê€á´€á´€/_6Má´˜á´˜xÉªÉªÊ€á´›á´›ÊœPÉ´É´SI\"\n",
      "batch 7844  loss=180.2258  steps/s=101.62  prediction: \"inpeace I gotchu https://t.co/l34MQvLmOd\" => \"nge eoiiiii  not  c  t c t    tt/////tts\"\n",
      "batch 7845  loss=144.9692  steps/s=104.68  prediction: \"ink in part bc you have more to remember\" => \"ng ene iii                            e \"\n",
      "batch 7846  loss=146.9518  steps/s=104.52  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  lus   e eeeeeeeeeeeeeetetettttptt/////\"\n",
      "batch 7847  loss=140.3865  steps/s=103.42  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \"hre  a       t t    e eeleeeloe\n",
      "\n",
      "o\n",
      "\n",
      "\n",
      "ooo\"\n",
      "batch 7848  loss=191.4554  steps/s=96.92  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \" @@   euee  u uu uuueeee ooooooooo      \"\n",
      "batch 7850  loss=155.9695  steps/s=76.79  prediction: \"kul07 Time limits on tasks are so useful\" => \"    auuuu     ee  o oo          s       \"\n",
      "batch 7851  loss=157.1601  steps/s=108.42  prediction: \" your own game engine\n",
      "challenge accepted\" => \"tougwgw w        o      nnnneeneeneeeeee\"\n",
      "batch 7852  loss=152.2755  steps/s=105.52  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"eti the      hhhhhhthhhhttthttttttt/////\"\n",
      "batch 7854  loss=138.7834  steps/s=104.31  prediction: \" one of the objects that could cast them\" => \"tf  a                    ttttttttttttttt\"\n",
      "batch 7855  loss=146.9162  steps/s=105.51  prediction: \" What are your personal long term games?\" => \"the oa                    ooo    o      \"\n",
      "batch 7856  loss=149.5738  steps/s=103.76  prediction: \" but vanilla obsidian seems very mid imo\" => \"tua  er uuuul ueu laall    ia aa    ei i\"\n",
      "batch 7857  loss=148.2539  steps/s=104.15  prediction: \" of just doing what fundamentally worked\" => \"tn ttts     s  o    t     d n  na aan aa\"\n",
      "batch 7858  loss=145.0223  steps/s=98.07  prediction: \"whoa thats wild, old twitter could never\" => \"aet oset  ttt    t    ddddd ttltttttttt \"\n",
      "batch 7860  loss=147.3077  steps/s=104.59  prediction: \"im definitely not an expert in it though\" => \"n  o    iiiiiiitiiiii                   \"\n",
      "batch 7861  loss=148.8926  steps/s=102.99  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"ssou           n                        \"\n",
      "batch 7862  loss=153.3847  steps/s=104.67  prediction: \"ke half my followers came from shoutouts\" => \"e 90 lk l llll lllllll       o o  o o om\"\n",
      "batch 7863  loss=151.4099  steps/s=103.70  prediction: \"xperience that will make me live longer)\" => \"pe     eeeeeeeeeeeeeeee              lll\"\n",
      "batch 7864  loss=158.2614  steps/s=93.58  prediction: \"uine Good taste is a very powerful thing\" => \" lige eee eet  t     t  a     ee e  er  \"\n",
      "batch 7865  loss=157.8111  steps/s=100.82  prediction: \" this guy did it\n",
      "https://t.co/Mx8AIWdLRf\" => \"@he kk    k    i   i   it tt  ttttt////t\"\n",
      "batch 7866  loss=159.8951  steps/s=102.71  prediction: \"ublic Refining my problem finder program\" => \" eiili ui ii iiiii ii ii        o  ddddd\"\n",
      "batch 7867  loss=146.1931  steps/s=103.20  prediction: \"\n",
      "then do your own experiments from there\" => \"\n",
      "hhm tryyj).&209(@)-&,â€œ;-jILá´‡xUIq1+@.v,q\"\n",
      "batch 7868  loss=149.4417  steps/s=103.22  prediction: \"n and id 100% recommend it over The Goal\" => \"gt lood d  d  ddd                   e ee\"\n",
      "batch 7869  loss=152.1029  steps/s=102.86  prediction: \"hristians believe this is the case w God\" => \"e   itii  issiiiiiiesiiiiiseie ii  ss   \"\n",
      "batch 7870  loss=142.8341  steps/s=101.67  prediction: \"nin man, was a great great time as usual\" => \" s le  nnn nn   n a    aa aa aa    a aa \"\n",
      "batch 7872  loss=140.1945  steps/s=104.59  prediction: \"ressures me to say things I dont believe\" => \"epl l   m_yá´›ð—¶_B)ðŸ˜¤TGL\"ð˜1qB$[ð—µjðŸ˜­ðŸ‘Œ#$j$**p,*\"\n",
      "batch 7873  loss=150.3814  steps/s=98.95  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"g  o  na a              tttttttttt//////\"\n",
      "batch 7874  loss=141.0900  steps/s=103.43  prediction: \"cially long term stuff,  makes it harder\" => \"hcle etee   l  e                        \"\n",
      "batch 7875  loss=142.5981  steps/s=104.83  prediction: \"ces for speed and it makes the game wild\" => \"h ss e c e ee eeeee   e   e  e     e   e\"\n",
      "batch 7876  loss=169.2255  steps/s=104.72  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"t.cp t/t/////ttNNttttttt/tttt////////ttc\"\n",
      "batch 7877  loss=146.8993  steps/s=104.93  prediction: \" is better than lots of ppl not starting\" => \"ts  esess ssseereeet    t  t   tt     t \"\n",
      "batch 7878  loss=153.3831  steps/s=104.45  prediction: \"having kids, etc) may be only palliative\" => \"etg  a        i i   i                  l\"\n",
      "batch 7879  loss=142.7499  steps/s=105.93  prediction: \"have become too big and are rotting away\" => \"eti ane eeaeeeemee                      \"\n",
      "batch 7880  loss=151.5341  steps/s=99.75  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" aoara oo   t  t           j  j    ooooo\"\n",
      "batch 7881  loss=147.5548  steps/s=88.06  prediction: \"neMTB i dream in ai generated js slop :/\" => \"  saea  i                  ee ee        \"\n",
      "batch 7883  loss=139.7712  steps/s=73.16  prediction: \"love spending 30mins debugging a typo :D\" => \"yt @t m i e            nnneeegg         \"\n",
      "batch 7884  loss=137.4811  steps/s=106.40  prediction: \"mages looked smoother so it did that lol\" => \"ant  t t       t eooeoooooooooo         \"\n",
      "batch 7885  loss=144.8145  steps/s=104.16  prediction: \"the highest quality music we have so far\" => \"he   as  hh hhhhhhh                     \"\n",
      "batch 7886  loss=154.6308  steps/s=103.69  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"  e  epp 3333 o         o      o       s\"\n",
      "batch 7889  loss=139.9218  steps/s=95.89  prediction: \"tler where would you say you are on this\" => \" eu  e e   ee    ee    oo      a a     a\"\n",
      "batch 7890  loss=146.2619  steps/s=73.74  prediction: \"is would make a really cool pfp actually\" => \"n se  see e e  w e      yyy   o        a\"\n",
      "batch 7891  loss=154.2769  steps/s=106.70  prediction: \"st? I believe Jesus gave us the playbook\" => \"t  o          et eeeeeee eeeeee e       \"\n",
      "batch 7892  loss=175.3504  steps/s=101.27  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" Hit i-;;ggtggtgtg\n",
      "gr\n",
      "\n",
      "\n",
      "rrffoooooo  oo  \"\n",
      "batch 7893  loss=156.2536  steps/s=106.60  prediction: \"utput brothers karamazov, word for word\"\" => \"s  g Atutttttttootrrrrr rrrrrrro  rr rrr\"\n",
      "batch 7894  loss=151.1717  steps/s=97.93  prediction: \"ath dependence can be used strategically\" => \"ni t,t         eeeeeeene              d \"\n",
      "batch 7895  loss=155.5439  steps/s=100.24  prediction: \"ing all my money https://t.co/IXXYEJUqHm\" => \"ne ee   l ll    l l         t ttt////XX/\"\n",
      "batch 7897  loss=145.6101  steps/s=105.06  prediction: \"important piece of advice here by a mile\" => \"ne aaaaa t  a  n t t     o  ee     e    \"\n",
      "batch 7898  loss=148.9769  steps/s=105.29  prediction: \"n and id 100% recommend it over The Goal\" => \" i aood d  d dddd         n         e ee\"\n",
      "batch 7899  loss=144.7434  steps/s=100.60  prediction: \"own to play more. was a pleasure as well\" => \"   e           m               a aaaaaa \"\n",
      "batch 7900  loss=152.0639  steps/s=103.97  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"teaeee ee eeeeelee   ee                 \"\n",
      "batch 7901  loss=152.5701  steps/s=103.76  prediction: \"se and 'magically' econ makes more sense\" => \"   l    e     aaaaaaaaa  a   aaa      ee\"\n",
      "batch 7902  loss=142.5468  steps/s=103.94  prediction: \"erful tool, extremely extremely powerful\" => \"   y eeee eee le eellleeexexeeeeeeeeeeee\"\n",
      "batch 7903  loss=136.6997  steps/s=105.61  prediction: \"th itself but couldnt figure out how lol\" => \"he t  w tt ttt tt      t   t     uuu    \"\n",
      "batch 7904  loss=169.7828  steps/s=38.47  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y: @tw  t  t   tt      t   uuu   uuu    \"\n",
      "batch 7905  loss=136.7896  steps/s=113.42  prediction: \"often to be random chance\n",
      "\n",
      "i love it tbh\" => \"  tet o  o  o   o   o     n  n          \"\n",
      "batch 7906  loss=163.1556  steps/s=75.30  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"selytoo                 o   e   ee      \"\n",
      "batch 7907  loss=242.1061  steps/s=15.62  prediction: \"reply: @0xluffyb https://t.co/Qs8R6GnjEa\" => \"eply: @kuvv0á´‡qBAPIT,á´‡:k/5á´€5á´„/Iq8R6GZjE,,\"\n",
      "batch 7908  loss=155.9955  steps/s=111.07  prediction: \"ways but in many cases it holds you back\" => \"ayt     l   a      a   a  a             \"\n",
      "batch 7909  loss=144.7342  steps/s=105.15  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \" e               000000000              \"\n",
      "batch 7910  loss=161.4429  steps/s=100.23  prediction: \"uff\n",
      "\n",
      "1. frogbrot https://t.co/JfifQf9WWd\" => \"sf o o ff  fff\n",
      "\n",
      " ffrrttrtt ottttt////ff/\"\n",
      "batch 7911  loss=186.4973  steps/s=96.95  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"hno se      @@@@@jjjjjjjjjoooooOOOOOOOOO\"\n",
      "batch 7913  loss=186.0807  steps/s=94.99  prediction: \"Gotta make one and learn that skill then\" => \"ool ea   aaoa oaoaae  e                ðŸ›‘\"\n",
      "batch 7914  loss=208.4679  steps/s=20.78  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @o  aao  aaoaae ae             t  ðŸ›‘\"\n",
      "batch 7915  loss=143.4243  steps/s=109.52  prediction: \"ce for an american traveling there soon?\" => \"t s it        a aaaaaaaaaaaaaaaannee eee\"\n",
      "batch 7916  loss=154.5088  steps/s=105.60  prediction: \"r time your focus muscle will strengthen\" => \"eoirg thawSIOwwbOk?,wk:m/IOf(/xKkm.YyIOv\"\n",
      "batch 7918  loss=179.7173  steps/s=91.53  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \" o r ee  oor  ouu   muo  ui9s@@ sere_sre\"\n",
      "batch 7919  loss=146.7503  steps/s=100.39  prediction: \"y is that the levels of learning theory?\" => \":oosiel        l      l        ee e  e e\"\n",
      "batch 7920  loss=142.9415  steps/s=103.71  prediction: \"d its helped man. i shpuld sleep too lol\" => \" t nn   aa                      pppp    \"\n",
      "batch 7921  loss=152.2890  steps/s=105.08  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  o     bbbbbbbb bbbb                \"\n",
      "batch 7922  loss=143.7985  steps/s=101.65  prediction: \"was making me sleep deprived unknowingly\" => \"ay     a  a          ee eee  eee eeeenen\"\n",
      "batch 7923  loss=151.2442  steps/s=104.04  prediction: \"thought I would\n",
      "\n",
      "Now, I shall take tomoâ€¦\" => \"ha         t I       o o           l l  \"\n",
      "batch 7924  loss=194.8308  steps/s=64.71  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"s2yr7onh           o   t           l ll \"\n",
      "batch 7925  loss=145.2496  steps/s=107.49  prediction: \"light show swarm and rent it to concerts\" => \"yz      d           w           t    t t\"\n",
      "batch 7926  loss=140.3367  steps/s=103.30  prediction: \"he case for some regions outside the US.\" => \"e   t      s   s    e   e   ooooooe  ee \"\n",
      "batch 7928  loss=156.7853  steps/s=103.14  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf        i    i  i  i                  \"\n",
      "batch 7929  loss=162.2037  steps/s=105.32  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t    0                         3      nn\"\n",
      "batch 7930  loss=169.2633  steps/s=96.40  prediction: \"s9 and of course, its subscription based\" => \"                        e     issiiniiin\"\n",
      "batch 7931  loss=144.4056  steps/s=105.24  prediction: \"ink in part bc you have more to remember\" => \"ng e e iii                            e \"\n",
      "batch 7932  loss=155.2955  steps/s=101.74  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t nntn            oottttttttttttttt/////\"\n",
      "batch 7933  loss=145.6389  steps/s=104.69  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  t t  t  t t  t  t tt    llll l  ll ll\"\n",
      "batch 7934  loss=149.7762  steps/s=97.11  prediction: \"nsettler 1min in, its pretty good so far\" => \"        ee sss see    i   i   i      t  \"\n",
      "batch 7935  loss=205.5852  steps/s=20.47  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" lyn @eeee ss  t e    i   i   t      o  \"\n",
      "batch 7936  loss=155.7814  steps/s=108.83  prediction: \"ndow its just :q when inside that window\" => \"  to o  o o       s          ii   it i  \"\n",
      "batch 7937  loss=152.6203  steps/s=104.78  prediction: \" to me except this feels 100x better fug\" => \"thits ttt  t e ee e eee    e   ee eeee  \"\n",
      "batch 7938  loss=152.2552  steps/s=104.74  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"    at    aaa aaaaana    ooo   cc cc ccs\"\n",
      "batch 7939  loss=147.5670  steps/s=103.27  prediction: \"res a reason they dont but i dont see it\" => \"eply  n bbFMz0PTRI)E,[1:=b%Gqj2)W|Px2)x:\"\n",
      "batch 7940  loss=153.0136  steps/s=104.77  prediction: \"everything is simple after you learn it\"\" => \" eo        ii ini ii  i     e   e       \"\n",
      "batch 7941  loss=146.8084  steps/s=102.70  prediction: \"rd it means theyre giving you a discount\" => \"ee y   tuu(M.A0A21kf,VS1fz/;%//\"bO/?2)%z\"\n",
      "batch 7942  loss=154.7988  steps/s=58.18  prediction: \" @llamapuckey never visit sf without jug\" => \"tvur e eae    et eee e ii ei  i  ii   u \"\n",
      "batch 7943  loss=138.5296  steps/s=109.80  prediction: \" own instead of relying on school for it\" => \"tn o o onnnnon n n          n    o  o oo\"\n",
      "batch 7944  loss=152.3861  steps/s=103.17  prediction: \"el you save\n",
      "\n",
      "hmm interesting interesting\" => \"  ye     e   e e    e eememe e  eeeeiete\"\n",
      "batch 7945  loss=201.8518  steps/s=20.85  prediction: \"eply: @mynamebedan head completely empty\" => \" lye      ee e e    m eeme e e teeeeiete\"\n",
      "batch 7946  loss=145.1485  steps/s=109.09  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly who                tetteeeennnnennnnn\"\n",
      "batch 7947  loss=288.6686  steps/s=11.33  prediction: \"reply: @Sam_Kantor @yminsky Super cool ðŸ˜Ž\" => \"e lo  ruuf^Ká´›ðŸ˜ðŸ°Kc#~^~~--#-###-^æˆ‘##-â€™^ð—°ðŸ˜Žv\"\n",
      "batch 7948  loss=148.7085  steps/s=113.64  prediction: \" v. move forward/backward is layer stuff\" => \"ten   t,                rrrrrraaaaaarraa\"\n",
      "batch 7949  loss=150.1449  steps/s=105.68  prediction: \"m repeatedly\n",
      "\n",
      "What have you learned btw?\" => \"ese    t t    eetteeeteteeaeeeaeeeeee ee\"\n",
      "batch 7950  loss=157.4256  steps/s=102.70  prediction: \" useful stuff to save hrs of your day ig\" => \"tss   uu uuuuuufuffffff                 \"\n",
      "batch 7951  loss=139.4336  steps/s=104.55  prediction: \" some but its not easy to put into words\" => \"tee . e        s                 tt tt t\"\n",
      "batch 7952  loss=151.9577  steps/s=102.12  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tami i                                  \"\n",
      "batch 7953  loss=149.0945  steps/s=103.15  prediction: \"ely grinded like mad towards His mission\" => \" la:lllll l l lleee         dddddd     s\"\n",
      "batch 7954  loss=157.3893  steps/s=104.45  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \" h  g n  n    nn   o    t    ttgggg gg g\"\n",
      "batch 7955  loss=145.0426  steps/s=102.39  prediction: \" software used that widely is so awesome\" => \"toi a      a                            \"\n",
      "batch 7957  loss=141.0092  steps/s=102.10  prediction: \"so i havent used anything like webgl yet\" => \"  s  s      s    s          nn        ee\"\n",
      "batch 7958  loss=165.9510  steps/s=104.04  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.Witttt////tt/ottttttttt::tt/tt////ccc/\"\n",
      "batch 7959  loss=141.4842  steps/s=103.79  prediction: \"ful for learning https://t.co/B7rPa9oFnr\" => \" n  e   l lll l lrrrrer   p    t / ///rt\"\n",
      "batch 7960  loss=138.8051  steps/s=103.56  prediction: \"l tools for myself and they save me time\" => \"yt l   luulloo l      f                e\"\n",
      "batch 7961  loss=169.3006  steps/s=98.20  prediction: \"in a year, and this was his main opening\" => \"nk    00 2          a    a   a   aaa ia \"\n",
      "batch 7962  loss=141.0672  steps/s=104.28  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"th e nnn nnnn ene eee eeettttttts/tt/tt/\"\n",
      "batch 7963  loss=157.6970  steps/s=76.17  prediction: \"@ludwigABAP ever thought of moving here?\" => \"ludeinnn   eeeeeeetettthttttt////////ooo\"\n",
      "batch 7964  loss=140.0528  steps/s=112.30  prediction: \"e\n",
      "\n",
      "i need to try your coffee shop tactic\" => \" \n",
      " :   eeeeee                           \"\n",
      "batch 7965  loss=169.7542  steps/s=100.18  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" aett gtttodttthttt  hh  hh             \"\n",
      "batch 7966  loss=171.5689  steps/s=105.24  prediction: \"an just do this: https://t.co/1xgV5Vs635\" => \"n  o t  ut utt   t    t tts  :ttt s/t/VV\"\n",
      "batch 7967  loss=160.4367  steps/s=94.86  prediction: \"B GPT isnt wrong, just ahead of its time\" => \"Aw  an  TT TT    t  t    tt     t    s  \"\n",
      "batch 7969  loss=169.3318  steps/s=101.38  prediction: \"mk if you have any questions about usage\" => \"e et i    e    m              e        u\"\n",
      "batch 7970  loss=167.6800  steps/s=85.85  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"tiei y                 y  tttsoo/ouooFFF\"\n",
      "batch 7971  loss=169.9762  steps/s=103.39  prediction: \"up man youre gonna go far over the years\" => \"seee   e    e     e   n     n     r     \"\n",
      "batch 7972  loss=146.3545  steps/s=104.63  prediction: \"xample\n",
      "Do this and then train them on it\" => \"qcrde    e e   t    t    t   t t  t t  t\"\n",
      "batch 7973  loss=151.9895  steps/s=103.71  prediction: \"tus Even more bc this doesnt have alaska\" => \" fIrttteeeteee  e       e    t      e  a\"\n",
      "batch 7974  loss=149.7770  steps/s=103.09  prediction: \"ked bc i could make cool fun stuff in it\" => \"e f hho     oo oooo    oo   oo          \"\n",
      "batch 7975  loss=157.5314  steps/s=100.70  prediction: \"ed\n",
      "Hes just gonna keep goin up from here\" => \"  t:   eee     d ee    e     n n        \"\n",
      "batch 7976  loss=158.5962  steps/s=45.91  prediction: \": @iliekcomputers Just steal it back bro\" => \" @bonodeee     e     e e  e             \"\n",
      "batch 7977  loss=146.3653  steps/s=110.61  prediction: \"t investment for your time generally imo\" => \"hbe    etneetteeetetett te   te    ee  r\"\n",
      "batch 7978  loss=145.2903  steps/s=104.53  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"n e eon oooo  o  oo    t tt   y   t   ss\"\n",
      "batch 7979  loss=170.6892  steps/s=43.75  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y:  ve rnooo   t ot    t e  t t   s s ss\"\n",
      "batch 7980  loss=143.8767  steps/s=108.60  prediction: \"d\" and they do and then it stops failing\" => \" rateea    d   ddd ddd  n               \"\n",
      "batch 7981  loss=146.5033  steps/s=104.69  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \" th p      r         m      t    nn   LL\"\n",
      "batch 7982  loss=157.7925  steps/s=102.93  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " kn   s g%SWE%Gj%RS,Ejv%|%%||SvE|Gj||Iâ€¦\"\n",
      "batch 7983  loss=149.3076  steps/s=103.79  prediction: \"ich is a suuuuper good thing to practice\" => \"n  oo  e     s uuuuu    uuuu    o     o \"\n",
      "batch 7984  loss=140.5816  steps/s=104.79  prediction: \"code base to get something super complex\" => \"om t tee ee   ee e   e  e      e     ee \"\n",
      "batch 7985  loss=141.4928  steps/s=103.88  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hat s     eeeeeeeeeeeeeeteeeeeeeee  n nn\"\n",
      "batch 7986  loss=143.4002  steps/s=103.51  prediction: \"deviating\n",
      "and it lets you do that faster\" => \"  o a   eennanneninii i     t  t    t   \"\n",
      "batch 7987  loss=150.7263  steps/s=103.65  prediction: \"ms' meaning more straightforward success\" => \"e lleme'' '' emme mmmmmmr   rrr  rarrrrs\"\n",
      "batch 7988  loss=186.6509  steps/s=96.48  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \"WEE\n",
      "    OOOOOOI NNNNNN      h       eees\"\n",
      "batch 7989  loss=144.0298  steps/s=103.84  prediction: \"atrophy, you have to like, keep doing it\" => \"ni  tottttt  h h h                      \"\n",
      "batch 7990  loss=160.9950  steps/s=97.21  prediction: \"a exactly\n",
      "\n",
      "just mon and thurs every week\" => \"ntt  taaayyaaaav    a   t   t           \"\n",
      "batch 7991  loss=154.6505  steps/s=101.80  prediction: \"ve not! Will look tho sounds interesting\" => \"e yee  ee  eel t l    ll  oolo  oo o o  \"\n",
      "batch 7992  loss=146.3050  steps/s=103.61  prediction: \"d building things with skills new to you\" => \" ag  nn  i   iiiiiiiiiiiiiiiiii         \"\n",
      "batch 7993  loss=153.8288  steps/s=104.23  prediction: \" and mc write n\n",
      "\n",
      "https://t.co/7R6F8ZlLFS\" => \"tnd                     tttttt////////tt\"\n",
      "batch 7996  loss=138.8506  steps/s=102.07  prediction: \"companies spend that much cash on a logo\" => \"om t sveeeeeeeese                 h     \"\n",
      "batch 7997  loss=159.9273  steps/s=103.46  prediction: \"as the guide on how to beat mind viruses\" => \"n ing    s s  es         o              \"\n",
      "batch 7999  loss=140.8551  steps/s=94.51  prediction: \"es courage\n",
      "lack of courage is a weakness\" => \"    t e e ee e taaa   ooaaoc  a         \"\n",
      "batch 8000  loss=172.1716  steps/s=104.19  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"t.cotatt////t/tttttzztzzzz:t//tt////t///\"\n",
      "batch 8001  loss=165.3991  steps/s=101.72  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"  s// g gg gggg ggg g g gt t  //t/tt////\"\n",
      "batch 8002  loss=153.6167  steps/s=98.62  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"u az z n     n         ttt/////tt////WW/\"\n",
      "batch 8003  loss=153.3793  steps/s=105.23  prediction: \"rong tho, my confidence is only like 70%\" => \"eg thod x.jBIvOJv(jYAx.@99v91,b9(j9970CQ\"\n",
      "batch 8004  loss=153.1311  steps/s=104.77  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "ites nasvj!0)(LzwSzGx.@I1,Mz,AV7UBN:)%L\"\n",
      "batch 8005  loss=156.0116  steps/s=103.99  prediction: \"coordinates are busted\n",
      "just buy new ones\" => \"oneM taaaaa  a raaa  aa eeese e   e   te\"\n",
      "batch 8007  loss=161.2150  steps/s=56.56  prediction: \" @anish0209 And now hes making it run js\" => \"taaraannaa aaa nnna e s eestss    u   uu\"\n",
      "batch 8008  loss=145.3207  steps/s=112.31  prediction: \", welcome to circle gang @ineedtolocking\" => \" motgooooooooooo    c       e    ee eeee\"\n",
      "batch 8010  loss=149.0845  steps/s=103.37  prediction: \"be setting a deadline might help as well\" => \"e  ii          t         ee             \"\n",
      "batch 8011  loss=156.6158  steps/s=103.86  prediction: \"nd thursday bros\n",
      "https://t.co/zlto3SBqGF\" => \"g h e r   n     r r s   tsst tttstttttt/\"\n",
      "batch 8012  loss=152.4378  steps/s=97.41  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"t e  nn  d       tttt ttt/////tt/////888\"\n",
      "batch 8013  loss=163.4339  steps/s=102.62  prediction: \"/t.co/i4ntqAK26E https://t.co/vE1KPjEGtm\" => \"/..c  tt////t////tttttttt//tt/tt////EE/E\"\n",
      "batch 8014  loss=156.7304  steps/s=101.33  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"tn aai i iii   i  e ee      e ee eeeeeee\"\n",
      "batch 8015  loss=150.1758  steps/s=78.42  prediction: \"izmobly you have 3 days or youre blocked\" => \"nalrl  i  ayyy e   ee   e e e  e  eeeee \"\n",
      "batch 8016  loss=166.1053  steps/s=90.36  prediction: \"nicoara \"The instruction at 0x%p...\"\n",
      "Lol\" => \" zt  t yooo    ee                 e ....\"\n",
      "batch 8018  loss=166.2696  steps/s=107.36  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"/t.lI \n",
      "t/t//t/////tt/t//ZZ     x  xx   x\"\n",
      "batch 8019  loss=132.9444  steps/s=104.83  prediction: \"had an eye for it meant maybe its useful\" => \"et tt                                   \"\n",
      "batch 8020  loss=159.2747  steps/s=106.55  prediction: \"reaks). During these sessions my producâ€¦\" => \"epli  e fv-----__C)00D00000L6TS_GN_NI_â€¦_\"\n",
      "batch 8022  loss=145.4661  steps/s=104.77  prediction: \"be helpful, so I recommend taking a look\" => \"e  d  l llll   l  l    e         e      \"\n",
      "batch 8023  loss=164.5021  steps/s=96.57  prediction: \"nus9 Thats super useful to know actually\" => \" s i l        s  ssu u suuuu uu      o  \"\n",
      "batch 8025  loss=206.8293  steps/s=101.94  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"B I UTOU                            tttt\"\n",
      "batch 8026  loss=163.7279  steps/s=104.77  prediction: \"sure there are lots of 100xers out there\" => \" r   e   n e eeeee ere     e ere   e  ee\"\n",
      "batch 8027  loss=168.6678  steps/s=87.44  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yp @s  tz  ererer  ta      h       t  ee\"\n",
      "batch 8028  loss=155.7079  steps/s=104.26  prediction: \"utput brothers karamazov, word for word\"\" => \"t iAuB u   tttt ttt trrrrarrrrraaarr ooo\"\n",
      "batch 8029  loss=149.4756  steps/s=100.99  prediction: \" cs maps btw? would love to see pictures\" => \"to                     w    o  o   o    \"\n",
      "batch 8030  loss=147.5461  steps/s=106.37  prediction: \"o nothing for now but funny number go up\" => \"nas eeeeeeee oonnn no  ooo nnn   nu nnn \"\n",
      "batch 8031  loss=162.3629  steps/s=103.29  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tosh    o  o         h      h  h hhhhh h\"\n",
      "batch 8032  loss=153.7186  steps/s=102.24  prediction: \"s a crazy valuable source of improvement\" => \" fafunaaaaa aaaaaaaaaaa l              e\"\n",
      "batch 8033  loss=142.9832  steps/s=105.40  prediction: \" hold onto the ones not worth finishing.\" => \"tot o  oooooooooooooooo  o oo  o      nn\"\n",
      "batch 8034  loss=162.1011  steps/s=71.52  prediction: \"helscom a new $500k logo should fix this\" => \"e e o oooooo    o   oo  o oo   o    iiii\"\n",
      "batch 8035  loss=148.8717  steps/s=106.95  prediction: \"house? where is your phone charger? etc)\" => \"ere or oe    e re  e e      eo h  h rre \"\n",
      "batch 8036  loss=155.1766  steps/s=96.78  prediction: \"oull just be on his midbie goats list dw\" => \"ur oouuou u us u           h   ieie i   \"\n",
      "batch 8037  loss=135.8703  steps/s=104.72  prediction: \"hat \"group photo\" means several entities\" => \"eth    t      tt t   \"  \"  o o   eeeaeee\"\n",
      "batch 8039  loss=145.6164  steps/s=91.67  prediction: \" they secretly exercise and dont tell us\" => \"th ts seb     tt eeeeee eeeee ee e e    \"\n",
      "batch 8040  loss=139.4698  steps/s=103.76  prediction: \"s and sugar and i dont get tired anymore\" => \" bhe       aa  sa a      d              \"\n",
      "batch 8041  loss=156.9666  steps/s=102.33  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"td h  ee ee ee  eaa ahaattaattttt/tt/t//\"\n",
      "batch 8042  loss=143.1584  steps/s=104.24  prediction: \" (by trusting in ideas) and testing them\" => \"ty te etsssttstt     i                  \"\n",
      "batch 8043  loss=148.2907  steps/s=101.97  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"on ot e aa   aac aa      uu    uuuu ooo \"\n",
      "batch 8044  loss=143.6106  steps/s=104.63  prediction: \"eful/true)\n",
      "\n",
      "sometimes thisll take months\" => \" uee  ssssuuuuusueeeeeeeeeeesttttttttttt\"\n",
      "batch 8045  loss=160.9504  steps/s=102.81  prediction: \" a day\n",
      "weekdays usually like 9am to 10pm\" => \"tnel3 l        da aa ayaaaayyaalll ll l \"\n",
      "batch 8046  loss=163.2182  steps/s=103.34  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" a a                                    \"\n",
      "batch 8047  loss=147.6918  steps/s=99.76  prediction: \"he stopped existing after the last frame\" => \"e ig l n    e eee eeeeee  e e   tt ttt  \"\n",
      "batch 8048  loss=142.0618  steps/s=104.61  prediction: \"yping on the terminal bc it looked cool)\" => \" eai i                                  \"\n",
      "batch 8049  loss=137.7621  steps/s=101.47  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"th e nnn nnnn ene eee eeeetttttts/tt/tt/\"\n",
      "batch 8050  loss=212.8325  steps/s=24.34  prediction: \"eply: @yacineMTB dependency independency\" => \" ly: @nn nne eeee eee ettttttttt/////tt/\"\n",
      "batch 8052  loss=177.8136  steps/s=96.31  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: @ e o nne eene  et etttttt////////tt/\"\n",
      "batch 8053  loss=149.6902  steps/s=110.17  prediction: \" cs maps btw? would love to see pictures\" => \"toe                         o  o   o    \"\n",
      "batch 8054  loss=140.4924  steps/s=105.26  prediction: \"ng and figure out which freqs i care abt\" => \"  ata          n                        \"\n",
      "batch 8055  loss=162.8725  steps/s=101.83  prediction: \"meone should make a zig finetune dataset\" => \"e e @ oooooooooooo                   ee \"\n",
      "batch 8056  loss=193.4660  steps/s=93.04  prediction: \"gABAP @yacineMTB https://t.co/NDBKphrBEW\" => \" Be    oAAAAA  e a          tt   //aaett\"\n",
      "batch 8057  loss=156.1500  steps/s=93.18  prediction: \"hag_ its good to be on the outside again\" => \"esg a Aa  g         oo  t   tt otttht tðŸ›‘\"\n",
      "batch 8058  loss=148.7651  steps/s=104.43  prediction: \"6hrs on something that feels like a game\" => \"hrs1   6      on    o  h h     e e  e e \"\n",
      "batch 8059  loss=152.5432  steps/s=105.89  prediction: \"ive and do the bare minimum you may getâ€¦\" => \"ne of a ass     a e eeee a       i   e  \"\n",
      "batch 8060  loss=198.2240  steps/s=38.61  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: p abosds e   a e eeee i  m    i   y  \"\n",
      "batch 8061  loss=144.5198  steps/s=107.47  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"th  e          t                        \"\n",
      "batch 8062  loss=136.7487  steps/s=104.84  prediction: \"t you are in fact to blame for everyoneâ€¦\" => \"htt i    a   a                       e  \"\n",
      "batch 8063  loss=142.0883  steps/s=104.28  prediction: \"d stuff just happens. stochastic winning\" => \" tyt                     sssssssssssssss\"\n",
      "batch 8064  loss=139.7576  steps/s=103.70  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: ie l sese elllnlllnnllllllllllllellle\"\n",
      "batch 8065  loss=145.6450  steps/s=103.93  prediction: \"f time and space that can reach in here?\" => \" y e o   i     t e       a   aaa a      \"\n",
      "batch 8066  loss=140.7928  steps/s=100.43  prediction: \"ath dependence can be used strategically\" => \"n  o        eeeeeeeeeecen e        ee ee\"\n",
      "batch 8067  loss=150.3364  steps/s=104.37  prediction: \"ey once, will play otb w friends usually\" => \"                        l               \"\n",
      "batch 8068  loss=152.3849  steps/s=67.39  prediction: \"@IterIntellectus have you brrrytt today?\" => \"lrciiar  nnl  l    l          rrr      u\"\n",
      "batch 8069  loss=168.2746  steps/s=108.25  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"eply  i7gKAIMCZ)HZZZQ:/ðŸ‘€Vv^W#,#g`VVMRE*\n",
      "\"\n",
      "batch 8070  loss=157.0061  steps/s=100.50  prediction: \"vinwylde the r in rgb stood for retarded\" => \"en oSreeeeeeeiiniii t  t     o   oor ooo\"\n",
      "batch 8071  loss=141.1490  steps/s=106.03  prediction: \"in places where i found better solutions\" => \"ng too                  e     e ee ee ee\"\n",
      "batch 8072  loss=144.1733  steps/s=104.37  prediction: \"of the network (target, a_output, loss,â€¦\" => \"u c  e              tttttttttttttttttttt\"\n",
      "batch 8073  loss=177.3071  steps/s=37.40  prediction: \"ly: @IterIntellectus its white pill week\" => \"y    e         tt t tttt tttttttttttt,,,\"\n",
      "batch 8074  loss=147.1346  steps/s=107.62  prediction: \" your brain insanely bad in the long run\" => \"tou          r r  r  aa   aa n   n    n \"\n",
      "batch 8075  loss=144.8295  steps/s=96.37  prediction: \"MTB theyre in the arena, fighting things\" => \"TB ia  r     i  n     nn  a  a   n   ing\"\n",
      "batch 8076  loss=141.4381  steps/s=103.71  prediction: \" which uses a superset of c. so not sure\" => \"t i c, ccccc   c     ss s s s           \"\n",
      "batch 8077  loss=146.7130  steps/s=104.43  prediction: \"ach other and spiral deeper into madness\" => \"tk ea a                     eeeeeee eee \"\n",
      "batch 8078  loss=151.7416  steps/s=100.33  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"h   ore trrrtrrr  t   ttttt  it /tt////2\"\n",
      "batch 8079  loss=138.1960  steps/s=104.36  prediction: \"but for now ill run whatever ppl ask for\" => \"lt             n                        \"\n",
      "batch 8080  loss=142.9617  steps/s=94.63  prediction: \"n pulls models too, but only from github\" => \" w  t  n     ll llllll  ooo     o       \"\n",
      "batch 8081  loss=153.4671  steps/s=103.06  prediction: \"n=1)\n",
      "2 their goals are their vidya (n=2)\" => \" th u e 1  1e  r e er    r     r   r    \"\n",
      "batch 8082  loss=144.9330  steps/s=104.28  prediction: \"nomic than discord id switch immediately\" => \" the   e   oo  mo   o   dd dd d iii diii\"\n",
      "batch 8083  loss=166.8351  steps/s=104.59  prediction: \"gram rlly helped https://t.co/ymqE5CrUM0\" => \" ee    a a a a          h      ///////tt\"\n",
      "batch 8085  loss=137.1806  steps/s=104.27  prediction: \"d this on there\n",
      "\n",
      "guard your signals boys\" => \" tt ne d                                \"\n",
      "batch 8086  loss=144.5783  steps/s=100.47  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"tnd                        ssssss///////\"\n",
      "batch 8087  loss=168.3172  steps/s=99.83  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" Bb ia PlAAAAAA@ssssssttttttooooooo    o\"\n",
      "batch 8088  loss=144.2224  steps/s=96.81  prediction: \"P get him toys, play w him, lasts longer\" => \" Ing igAggggtttt t   o                  \"\n",
      "batch 8089  loss=157.8963  steps/s=100.77  prediction: \"meone should make a zig finetune dataset\" => \"e e  l o ooooooooo                   ee \"\n",
      "batch 8090  loss=133.7694  steps/s=103.91  prediction: \"learning is by doing stuff. For anything\" => \"y  ohe  n                               \"\n",
      "batch 8092  loss=139.3703  steps/s=103.15  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" te i          w             eeeeeeeeeee\"\n",
      "batch 8093  loss=143.4534  steps/s=97.76  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \"g     ao       t      eeeeee e       e  \"\n",
      "batch 8094  loss=159.3624  steps/s=68.92  prediction: \"ludwigABAP its all slop tier, always was\" => \"yd @no ww      f     ll  e    t         \"\n",
      "batch 8095  loss=155.6766  steps/s=105.60  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"toconeet//tts/ttttttthptt/pt//pt//ttp///\"\n",
      "batch 8096  loss=159.6799  steps/s=104.62  prediction: \"sing way more efficient/scalable methods\" => \" n    t                ef eeeieeeceeeeae\"\n",
      "batch 8097  loss=143.0500  steps/s=104.23  prediction: \"d its helped man. i shpuld sleep too lol\" => \" toan   aa                      pppp    \"\n",
      "batch 8098  loss=161.4747  steps/s=104.96  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"tos  D                  ttttt///////z///\"\n",
      "batch 8100  loss=161.5079  steps/s=104.40  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n  r     EEEEEE xEee    ttttt::ttt: ///7\"\n",
      "batch 8101  loss=155.5670  steps/s=100.40  prediction: \"y is nothing like early morning sunlight\" => \" 1iseleereer e  l  l l  i  i ii ni n  g \"\n",
      "batch 8102  loss=154.7236  steps/s=101.59  prediction: \"t in a position to help you at all loool\" => \" hn Thr   no non i oo   o   oo  o   lll \"\n",
      "batch 8103  loss=145.7261  steps/s=104.68  prediction: \" is better than lots of ppl not starting\" => \"tf  e ess ssseeseeet    t  t   tt     t \"\n",
      "batch 8104  loss=148.7364  steps/s=104.73  prediction: \" done in 1s, lol https://t.co/d2QCy0zBel\" => \"ton innnnnnn             t ttttttttt////\"\n",
      "batch 8105  loss=149.0546  steps/s=104.51  prediction: \"m repeatedly\n",
      "\n",
      "What have you learned btw?\" => \"ese  t t t    eetteeeteteeaeeeaeeeeee ee\"\n",
      "batch 8106  loss=148.6548  steps/s=104.93  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"k re s      '   e    e  e t  ///ttt////t\"\n",
      "batch 8107  loss=149.7061  steps/s=105.16  prediction: \"dibly efficient and powerful compression\" => \" nc ir  ii ii  ni ifiniiin   f e ee  e e\"\n",
      "batch 8108  loss=165.0054  steps/s=45.85  prediction: \"y: @radbackwards God invented it\n",
      "Idk lol\" => \"  @rer  ii if i i   in enne  f e ee  eoe\"\n",
      "batch 8109  loss=160.7717  steps/s=121.75  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" re bba    e    oo ooo oot  tottot/////Q\"\n",
      "batch 8110  loss=155.9093  steps/s=53.68  prediction: \": @moh1xabc i cooked so hard i burned it\" => \" @yactoo     o oooo    ootttt//////QQ444\"\n",
      "batch 8111  loss=145.1207  steps/s=106.87  prediction: \"thing I need to pay attention to, thanks\" => \"hir i\n",
      "ei   i  e           t tttt ttttttt\"\n",
      "batch 8112  loss=138.8291  steps/s=103.71  prediction: \"th `sudo service NetworkManager restart`\" => \"he  en  rr r r r   e  eeee ee eereeererr\"\n",
      "batch 8113  loss=158.3031  steps/s=21.87  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"nttater r  r r r   e  eeeereererrerererr\"\n",
      "batch 8114  loss=150.3095  steps/s=117.56  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"ys @rppi ir  r r      r  t t  ee  e e   \"\n",
      "batch 8115  loss=156.6622  steps/s=104.21  prediction: \" at like 8pm\n",
      "\n",
      "Every restaurant offers it\" => \"tr t ee   e ee e  8e  eeee eeeerrrrrerrf\"\n",
      "batch 8116  loss=145.7299  steps/s=106.01  prediction: \"If are not one, you stand out like crazy\" => \" \n",
      "e e  e  e    ne            oo         \"\n",
      "batch 8117  loss=188.0285  steps/s=58.15  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tp ee  eeeete  no   oo   on  oo    o    \"\n",
      "batch 8118  loss=143.5481  steps/s=109.85  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"eraaa     e    e      o  o  oo  o       \"\n",
      "batch 8119  loss=145.5121  steps/s=99.64  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" \n",
      "    y mmemmeeee       l  l           e\"\n",
      "batch 8120  loss=149.0533  steps/s=105.98  prediction: \"ger and crazier, more ambitious programs\" => \" tbg eiiggg              rr rrr iiirrrro\"\n",
      "batch 8121  loss=145.9167  steps/s=103.91  prediction: \"y areas of corporate world it seems like\" => \" womnn  a   aa aa  aaoooroor or e       \"\n",
      "batch 8122  loss=190.6286  steps/s=81.78  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \" gem e ea    a o   p oo   rt    /e    e \"\n",
      "batch 8124  loss=165.3628  steps/s=108.59  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \" aeh nhy   ooo   o t tttsttss/stootl lll\"\n",
      "batch 8125  loss=163.9462  steps/s=100.01  prediction: \"ock your 1000th follower and stay at 999\" => \" k  e e  o e   t000000ooolloo           \"\n",
      "batch 8126  loss=131.9566  steps/s=104.79  prediction: \"endeavors im going to do til ive done it\" => \" ti  t                                  \"\n",
      "batch 8127  loss=335.1826  steps/s=10.96  prediction: \"reply: @IterIntellectus no i forgot srry\" => \"eply:.err,ðŸ¤”#|â™‚#;j%ðŸ˜Žá´›Êœ1ðŸ¤”#á´›##ÊŸ%Êœ#..#1á´„â˜ [ðŸŽ‰/\"\n",
      "batch 8128  loss=171.1106  steps/s=119.50  prediction: \" a https://t.co/OmDwKUEq4p for gpt5, rip\" => \"tn    s    s sss////tt////t///// tpp ppp\"\n",
      "batch 8129  loss=159.6464  steps/s=103.74  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"g 2t  t  rt t     o      o    yo  t  t  \"\n",
      "batch 8130  loss=160.1455  steps/s=104.69  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e  ee o scqqIK$;KKKREXACT1IRRRIRIbk\n",
      "XACT\"\n",
      "batch 8131  loss=152.1995  steps/s=104.82  prediction: \" drains your energy by paying attentionâ€¦\" => \"teat ia   i  n r  n   yyyyyyyy yy y   nn\"\n",
      "batch 8132  loss=145.7019  steps/s=85.95  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"o ph aa   r    r           i    a tttttt\"\n",
      "batch 8133  loss=162.8966  steps/s=105.34  prediction: \" a day\n",
      "weekdays usually like 9am to 10pm\" => \"tnel           daaaa ayaaaaylllyll      \"\n",
      "batch 8136  loss=177.0594  steps/s=105.17  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" ttKe/ccccccLLLLLLcLLteeeeettete/t/tt///\"\n",
      "batch 8137  loss=143.2855  steps/s=104.66  prediction: \"conflicting values it would be a paradox\" => \"onv  ti lllllllllllliiii i              \"\n",
      "batch 8138  loss=145.5303  steps/s=105.28  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e lael eee t e tee  a a a  a  a   aa    \"\n",
      "batch 8139  loss=156.5547  steps/s=104.52  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o  g eeeee     %%%%%  %      3         \"\n",
      "batch 8140  loss=148.8459  steps/s=102.49  prediction: \"ng sessions for now for the discord name\" => \"t  t   o   osssnsssooo os  oo  oo  oo  o\"\n",
      "batch 8141  loss=131.3675  steps/s=104.79  prediction: \" local optima solution they got stuck in\" => \"tiet t         t   oooooooooooooottttttt\"\n",
      "batch 8142  loss=165.7288  steps/s=91.72  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \"tm tl oooo     l  aaa attt   ttttt      \"\n",
      "batch 8143  loss=144.7807  steps/s=94.58  prediction: \"f you can read graphs youre already ngmi\" => \" t   i       a  a aaaa  ap   h e    e   \"\n",
      "batch 8144  loss=310.5138  steps/s=12.85  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @rj.UzUUx0k@UI'â€¦â€¦â€¦â€¦?â€¦â€¦â€¦?â€¦â€¦â€¦Zâ€¦â€¦Ex??\"\n",
      "batch 8145  loss=141.7208  steps/s=123.07  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"   oo d  o     d                eeeeeeee\"\n",
      "batch 8146  loss=160.5609  steps/s=98.52  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" sh  e      lll  ll lpppppeppeeetett////\"\n",
      "batch 8147  loss=145.7407  steps/s=96.09  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" pll    u   sepeeee  e     oo s  ss\n",
      "s\n",
      "\n",
      "\n",
      "\"\n",
      "batch 8148  loss=144.9035  steps/s=98.27  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \" el  rooo   o  l  o    o  o  o    o  ooo\"\n",
      "batch 8149  loss=143.2487  steps/s=103.50  prediction: \"d luck to step on worms and they stopped\" => \" i             t                     t  \"\n",
      "batch 8150  loss=141.4599  steps/s=99.11  prediction: \"nt true they wouldnt put it in the title\" => \"t t d  t tttt tt tt  t t tttt t  t t  tt\"\n",
      "batch 8151  loss=143.6871  steps/s=99.18  prediction: \"c high entropy stuff that fits the curve\" => \"owp  taaaaaaaa h        t tttttttttttt t\"\n",
      "batch 8152  loss=142.0989  steps/s=103.20  prediction: \" onto it forever and never reevaluate it\" => \"tn e   o  o o  o  o    o  n eere vereeee\"\n",
      "batch 8153  loss=141.2725  steps/s=104.59  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"es  me         t                        \"\n",
      "batch 8154  loss=138.3370  steps/s=102.58  prediction: \"that was probably its entire purpose lol\" => \" e i ittttttttt tt   t   tt     t       \"\n",
      "batch 8155  loss=146.7436  steps/s=104.14  prediction: \" the ladder on what strats are possible.\" => \"thet      t              t      a   a s \"\n",
      "batch 8156  loss=168.6802  steps/s=104.29  prediction: \"obably been undervaluing its utility tbh\" => \" l  t t o\n",
      " \n",
      " bbeebbebeeeeeuuununnu uuiui\"\n",
      "batch 8157  loss=138.4313  steps/s=101.84  prediction: \"sts w good content from this perspective\" => \"  e   s        oooo  ooooo            tt\"\n",
      "batch 8158  loss=153.0044  steps/s=104.22  prediction: \"se and 'magically' econ makes more sense\" => \"  al    e     aaaaaaaaa  ace aaa      ee\"\n",
      "batch 8159  loss=195.5250  steps/s=104.68  prediction: \"__11hz LETS GET IT\n",
      "im hyped for thursday\" => \"______________11TTTTTTTTT TT         s  \"\n",
      "batch 8160  loss=156.1035  steps/s=104.32  prediction: \" right now its just learning on the side\" => \"ter a                   t   t    nn     \"\n",
      "batch 8162  loss=143.0360  steps/s=104.78  prediction: \"r the picture\" for any industry or niche\" => \"eitoe   eI'|ð—±ðŸ¤¦á´„]kvðŸ¤¯å§,W*ÉªTðŸ’ª\"W,^^vâ˜ I'T{vÉª#\"\n",
      "batch 8163  loss=145.0452  steps/s=105.72  prediction: \" about it and in 1 weekend jumped up 200\" => \"t deasa  a  a                e     eee e\"\n",
      "batch 8164  loss=151.0704  steps/s=102.91  prediction: \"ugh or is it just whatever comes to mind\" => \"sr or oorrr o  o  i     t tt   t t      \"\n",
      "batch 8165  loss=150.8479  steps/s=104.44  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"nts  i   o l  ll  ll pllilllllllllll  ll\"\n",
      "batch 8166  loss=237.8119  steps/s=11.11  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"eply    ug?hk?j)??LUv://v?â€¦?/3'bvjGqxvS?\"\n",
      "batch 8167  loss=145.7869  steps/s=108.99  prediction: \"cy and then work up to really short ones\" => \"o si t nnnnn nn n                       \"\n",
      "batch 8168  loss=155.3581  steps/s=102.33  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"td t  ee ee ee  eaa ahaattaatt/tt////t//\"\n",
      "batch 8169  loss=167.0996  steps/s=104.87  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"gser t e ttee  eeeee e d dadddadaaaaaaaa\"\n",
      "batch 8170  loss=228.8260  steps/s=99.52  prediction: \": CHECK\n",
      "DELTA TIME: CHECK\n",
      "GRAVITY: CHECK\" => \" PHocHCCCEEEEEEEETTEEEEEECEEEECCCCCCCCCC\"\n",
      "batch 8171  loss=213.5983  steps/s=29.21  prediction: \"ply: @sunsettler https://t.co/8FPo1elzOu\" => \"ly: @HCCEEEEETTTTTEEEEEECCECCCCCA:CCHCCC\"\n",
      "batch 8172  loss=170.3813  steps/s=127.88  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" tts e           h  pe  ppep//:///tt////\"\n",
      "batch 8174  loss=161.0948  steps/s=103.84  prediction: \"as the guide on how to beat mind viruses\" => \"nting    s s  es                        \"\n",
      "batch 8176  loss=95.9815  steps/s=104.12  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"touOOOO a\n",
      "  aa     ????a aa??   aa    E \"\n",
      "batch 8177  loss=162.6179  steps/s=101.75  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "   ee ee  eeeeeeeee ee ees sss s  s  s\"\n",
      "batch 8178  loss=138.7803  steps/s=104.36  prediction: \" adding the context into the computation\" => \"tnr t   se o   ee ooe t  t nt e te ttttt\"\n",
      "batch 8179  loss=149.3903  steps/s=59.55  prediction: \" @startupmillyair lichess or chessdotcom\" => \"tsr     re uo  te t ntt  t  too tc ttott\"\n",
      "batch 8180  loss=143.4097  steps/s=107.35  prediction: \"have become too big and are rotting away\" => \"av\n",
      "saei e aeeeemee                      \"\n",
      "batch 8181  loss=160.0700  steps/s=100.80  prediction: \"is i second this https://t.co/3JrtWEMXgK\" => \"n   aeeee e  ee    i     t t ttttttt/t//\"\n",
      "batch 8182  loss=142.5832  steps/s=105.03  prediction: \"reevaluating concepts you often overlook\" => \"e i s e ddO0OOOOOOá´¡OOOOOO:OO*.OOâ€œOO#{WEM\"\n",
      "batch 8183  loss=186.2900  steps/s=38.59  prediction: \"ly: @Purring_Lynx Good addition for sure\" => \"y:  aniraaaaaaaan nnnnn n  oooo o    ooo\"\n",
      "batch 8184  loss=151.7898  steps/s=112.00  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" h e eperteeenememen  e no t n t  ttntt \"\n",
      "batch 8185  loss=239.6888  steps/s=11.92  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"eply     bOOOO_LOOxOOOOOxOOOx.OOOjOxOjkO\"\n",
      "batch 8186  loss=148.2695  steps/s=106.90  prediction: \"ful defensive ai to guard you in cyber,â€¦\" => \" l te   eee eeefee eeee  e              \"\n",
      "batch 8187  loss=143.0616  steps/s=102.23  prediction: \"your post, your app has been declined :(\" => \" urnan    n    r     o            e     \"\n",
      "batch 8188  loss=140.6836  steps/s=104.23  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"t     t   t tt t  ttttttttttttttttt////p\"\n",
      "batch 8189  loss=296.8283  steps/s=10.86  prediction: \"reply: @papyruski @justalexoki elaborate\" => \"epl t  ee,888_I)8@j88NkFFFFxFb@@:FZ@.FFâ€¦\"\n",
      "batch 8190  loss=151.6825  steps/s=107.96  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"   s          ss  s       a  aaaaaa  a  \"\n",
      "batch 8191  loss=154.4228  steps/s=104.28  prediction: \"t habit of reaching for my phone is gone\" => \"hfo   ttt t tt h     h                  \"\n",
      "batch 8192  loss=145.6352  steps/s=103.69  prediction: \"ing already paved paths is the only wayâ€¦\" => \"n  t       n   r a     a a     a     a  \"\n",
      "batch 8193  loss=161.8168  steps/s=104.84  prediction: \"ou can dive unbelievably deep into these\" => \"ntttt d tY   e  n    ne eeee eeeeeeeeee \"\n",
      "batch 8194  loss=157.8680  steps/s=100.47  prediction: \"rammer you love lean? prove it (in lean)\" => \"eten:  S k__HkIx_k_@w_?_%/_k__(_y(I_IY)_\"\n",
      "batch 8195  loss=146.7328  steps/s=103.85  prediction: \" ad optimization, marketing agencies etc\" => \"tnte l o      iiootiiiiiiiiiaiiaiaiaieie\"\n",
      "batch 8196  loss=288.1792  steps/s=11.41  prediction: \"reply: @yacineMTB google necessary being\" => \"eplyo   th4B4\"z4944?T4S44,4422(44(44z4)7\"\n",
      "batch 8197  loss=140.8242  steps/s=119.42  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"nei seeee eeehheeeheeeheeeeeeeee eeeeeee\"\n",
      "batch 8198  loss=141.9917  steps/s=104.21  prediction: \"t them as axioms, and it screws you over\" => \" tt   tta  a a   a a   a         s      \"\n",
      "batch 8199  loss=147.7433  steps/s=103.83  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"eanl: @oww===4_4kk==:=(=v======w=)=-&OR;\"\n",
      "batch 8200  loss=146.0697  steps/s=103.50  prediction: \"e code a bit in /ai-tools/multicoder lol\" => \" ta to                     iiiiiiiiioooo\"\n",
      "batch 8202  loss=188.0678  steps/s=30.22  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly:f@ o  e            i ii iiiiiiooioool\"\n",
      "batch 8204  loss=183.6482  steps/s=81.49  prediction: \"ly: @gizmobly probably\n",
      "especially if bjj\" => \"y: @ oe o          i  iiii//ii/ottoiooll\"\n",
      "batch 8205  loss=148.5695  steps/s=115.71  prediction: \"s some cool shit https://t.co/Vo4w9BcSQZ\" => \" aod o   ooooo   oo   t  t tt/////tt////\"\n",
      "batch 8206  loss=151.3937  steps/s=101.91  prediction: \"output less verbose/convoluted solutions\" => \"n sue\n",
      " ttu ttt    ee  eeeoooeeoooeeoseoo\"\n",
      "batch 8207  loss=137.4400  steps/s=98.57  prediction: \"is i need to make golden gate tetris bot\" => \"n   e  ess           e ee   e  eeeetttte\"\n",
      "batch 8208  loss=148.9400  steps/s=104.74  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" eoe e,,eneeeeeeeeedeeeseeetttst//////tt\"\n",
      "batch 8209  loss=134.4527  steps/s=105.58  prediction: \" to other areas where you make decisions\" => \"thet e ee  e  et    eee   e     e  eeeee\"\n",
      "batch 8210  loss=145.7637  steps/s=100.87  prediction: \"ace to your list https://t.co/dwHsPF5vJC\" => \"ni toe                  tttttttt////////\"\n",
      "batch 8212  loss=144.1539  steps/s=104.77  prediction: \"e, i would also have liked to be yacine\"\" => \"                                        \"\n",
      "batch 8214  loss=151.3035  steps/s=105.82  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"  2 ns     aa aaaaana    ooo   oc cc ccs\"\n",
      "batch 8215  loss=163.9347  steps/s=104.50  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"th.cinnt////t/////ttttttt/////tt////t///\"\n",
      "batch 8216  loss=165.5141  steps/s=89.74  prediction: \" w as in why tf would you use white mode\" => \"th tese   e    nw w   w            u   u\"\n",
      "batch 8217  loss=154.7089  steps/s=111.10  prediction: \"activation energy as much as possible ig\" => \"nie  o o oo   oot e  o  tt  a  a s  s   \"\n",
      "batch 8218  loss=230.6620  steps/s=11.01  prediction: \"reply: @dwbypass https://t.co/k3grlVSm53\" => \"epoud pe'.S__'@QB61uwX'b__I(_@3bW.Pk-5x(\"\n",
      "batch 8219  loss=160.2999  steps/s=110.34  prediction: \" through nevada w my dad as a little kid\" => \"ahedir i i   r n    a    d   a     a a  \"\n",
      "batch 8220  loss=148.1286  steps/s=103.95  prediction: \"aw of undulation https://t.co/VdFFnrRkLH\" => \"n  do          t  a   t tttttttttttttt/F\"\n",
      "batch 8221  loss=164.0887  steps/s=104.29  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nes ouu    l  l          Nttt:tt/t//////\"\n",
      "batch 8222  loss=157.9531  steps/s=105.97  prediction: \" gzip compression loss continues to fall\" => \"aosos  s       pp s ssssssssssssoosssoos\"\n",
      "batch 8223  loss=157.4967  steps/s=98.57  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" has  h     h    llllppp peppeettttt////\"\n",
      "batch 8224  loss=151.6530  steps/s=97.41  prediction: \"builds It is factually what plants crave\" => \"etiu el b   l      ttst tttttlllttttattðŸ›‘\"\n",
      "batch 8225  loss=137.8030  steps/s=103.44  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eae  teheeeeeseseesseeeeeemeeeiiii i iii\"\n",
      "batch 8226  loss=136.7588  steps/s=105.50  prediction: \"atterns so we should do (description ofâ€¦\" => \"t  hat tt        s                ddooo \"\n",
      "batch 8227  loss=145.9874  steps/s=104.57  prediction: \"xample\n",
      "Do this and then train them on it\" => \" crfo    e e   t    t    t   t t  t t  t\"\n",
      "batch 8228  loss=154.1428  steps/s=105.42  prediction: \" it sucked but couldve been 1000x worse.\" => \"tt d  a                       eeee000000\"\n",
      "batch 8229  loss=197.7881  steps/s=30.66  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @P                   eeee e000000000\"\n",
      "batch 8230  loss=140.3923  steps/s=137.45  prediction: \"ould get my ass handed to me for suuuure\" => \"ul a     e     m              e         \"\n",
      "batch 8231  loss=148.7849  steps/s=98.25  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"td  o  aaappppp spssspssssstsssstttt////\"\n",
      "batch 8232  loss=155.9089  steps/s=104.70  prediction: \" you can do the second without the first\" => \"tou  i e                      o      t  \"\n",
      "batch 8234  loss=153.0068  steps/s=103.58  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"n     oo     o    e   eeee  eeeeeeeeeeee\"\n",
      "batch 8235  loss=175.5965  steps/s=98.97  prediction: \"77 oh whoa i didnt know abt tabs, thanks\" => \"  I0  c 77 i7  ii i          i   t   t n\"\n",
      "batch 8237  loss=143.3264  steps/s=105.60  prediction: \"d from 15 relevant studies in 10 seconds\" => \" bo muu u    e re       ee  e    1  e  s\"\n",
      "batch 8238  loss=154.5978  steps/s=100.56  prediction: \" it.\n",
      "Story sounds pretty interesting btw\" => \"tn    e r o  o   ro o t    tytt ettttett\"\n",
      "batch 8240  loss=174.8835  steps/s=105.36  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1io  t o            ttt  ttttttt/////tt\"\n",
      "batch 8241  loss=163.4272  steps/s=98.01  prediction: \"mobile works now https://t.co/vI0ds7feVt\" => \"enia  sr ror  oo o  oo ss  o  /ot/tt/o//\"\n",
      "batch 8242  loss=160.6734  steps/s=103.50  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" atioi        o  ooo  oo  onnnnn  nn    \"\n",
      "batch 8244  loss=135.5970  steps/s=104.87  prediction: \"hat \"group photo\" means several entities\" => \"et  tr t      tt t   \"  o  o o   eeeaeee\"\n",
      "batch 8245  loss=172.5792  steps/s=103.17  prediction: \"10^10^10^10^10^10^10^10^10\n",
      "so maybe 2064\" => \"0 10110^^1^^0^^00^10110110100^10^10100^0\"\n",
      "batch 8246  loss=254.4994  steps/s=39.26  prediction: \"ly: @anish0209 No problem I gotchu man ðŸ«¡\" => \"y: 10 o010010010010^10^100110^10110 00 0\"\n",
      "batch 8247  loss=180.0322  steps/s=121.73  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"t d                        s sstss ///SS\"\n",
      "batch 8248  loss=152.0413  steps/s=103.26  prediction: \"dont know much about it other than that.\" => \"  g t    tt   tt        t     tt tt  tth\"\n",
      "batch 8249  loss=138.7724  steps/s=101.48  prediction: \" the parameters corrrect from the start?\" => \"tha nan  aaa aataaaarrerrrrrrrrrrr    rt\"\n",
      "batch 8250  loss=172.3476  steps/s=102.28  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tn    r     \n",
      "   \n",
      "\n",
      "\n",
      " \n",
      "   p  p   lll  l   \"\n",
      "batch 8251  loss=145.8031  steps/s=103.18  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tn     .....ee ttt    e                 \"\n",
      "batch 8252  loss=134.9825  steps/s=104.92  prediction: \"s and had strong knowledge of the course\" => \" fh  h    d dd          nnn             \"\n",
      "batch 8253  loss=148.9136  steps/s=105.39  prediction: \" even the ones i disagreed with the most\" => \"tvee  ee  eeeeen          e ee          \"\n",
      "batch 8254  loss=137.9815  steps/s=104.96  prediction: \"seless to ppl who dont know them already\" => \"  exesseesssssses             o         \"\n",
      "batch 8255  loss=151.5390  steps/s=105.07  prediction: \"y highest elo and post cool results on x\" => \" po ooe  s  e       e    o   o   oo   os\"\n",
      "batch 8256  loss=150.7072  steps/s=100.59  prediction: \" of your day your brain will work better\" => \"tn  t t    t  rr   yy  rr y r       r   \"\n",
      "batch 8257  loss=151.5345  steps/s=103.68  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"toek a           a       t  tt  t///////\"\n",
      "batch 8258  loss=150.3704  steps/s=93.80  prediction: \"eMTB I see slop poasting is the meta now\" => \" TBm na               pptt ttttt st sttt\"\n",
      "batch 8259  loss=160.2088  steps/s=104.89  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"t..SStSt////t/ttttttttttt/////tt////t///\"\n",
      "batch 8260  loss=141.3581  steps/s=104.04  prediction: \"quote a lot bc it seems to come up a lot\" => \"uiskis  t      tt                       \"\n",
      "batch 8262  loss=136.3557  steps/s=95.87  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n  A           t                       E\"\n",
      "batch 8263  loss=152.8665  steps/s=105.02  prediction: \"xperience that will make me live longer)\" => \"ae     eeeeeeeeeeeeee e             llll\"\n",
      "batch 8264  loss=148.2134  steps/s=103.40  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" toi gnnannn nneennenueeeettttttsttt////\"\n",
      "batch 8265  loss=148.1508  steps/s=106.29  prediction: \"d \"compress\" anything into 1 byte (veryâ€¦\" => \" tt  a \"\"\"\"\" \"\" \"\"\"s\" s  n    n n       \"\n",
      "batch 8266  loss=147.2591  steps/s=104.99  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" og t       aaaaaaaaaaanannnnnnnnnnnnnnn\"\n",
      "batch 8267  loss=158.7109  steps/s=101.77  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"taa  id   e  e      l    o   o  o     o \"\n",
      "batch 8268  loss=188.4240  steps/s=85.17  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \" lel il   l  l  l  ot    tt  pt o     e \"\n",
      "batch 8269  loss=158.1289  steps/s=107.63  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"ts  lloooo oooii iiiiiiiiiiiiiiiii i i  \"\n",
      "batch 8270  loss=144.4462  steps/s=104.37  prediction: \"n while still being consistent each week\" => \" tho  a           l     i i iiinninnn ne\"\n",
      "batch 8271  loss=150.1277  steps/s=105.30  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toe eedeeeee e e     e e     ICIIIIn nnn\"\n",
      "batch 8272  loss=144.2650  steps/s=100.86  prediction: \"e or desire to practice for other things\" => \" d ot o tr r    r  rr  e    c c rr    r \"\n",
      "batch 8273  loss=133.3053  steps/s=105.87  prediction: \"lms\n",
      "and lots and lots of trial and error\" => \"y  @l  odll                             \"\n",
      "batch 8274  loss=174.0636  steps/s=58.32  prediction: \" @brianf3rnandez @crungulism Like 20mins\" => \"tsna annlnn nnn n    o                rr\"\n",
      "batch 8275  loss=160.1915  steps/s=107.49  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"eogn )nn      nnx     nn n           __ \"\n",
      "batch 8276  loss=147.7960  steps/s=102.44  prediction: \"ellite imagery onto the photos they took\" => \" sitlse et e tetee ett    tettott  tttot\"\n",
      "batch 8278  loss=173.1377  steps/s=98.84  prediction: \"i have good news https://t.co/C5gY0PwNAZ\" => \"nt te e eeeee    ooo o t tthtttttt//////\"\n",
      "batch 8279  loss=176.5090  steps/s=104.99  prediction: \"ful to me, like use every day type stuff\" => \" l        e  u l e    eee e   eeeee yy  \"\n",
      "batch 8280  loss=160.1595  steps/s=101.11  prediction: \"mewhat relevant:\n",
      "https://t.co/USV0L8wnT8\" => \"an  e      e eeeeeeeeettttttttttttt/////\"\n",
      "batch 8281  loss=132.0709  steps/s=101.51  prediction: \" learn if youre not an opening memorizer\" => \"@ewo                           nnnnnnnn \"\n",
      "batch 8282  loss=145.2522  steps/s=103.64  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"etg     kcAb'x.BJzS?ED\n",
      "IL_SR:EO6b?v'AO6V\"\n",
      "batch 8283  loss=147.3078  steps/s=105.10  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" t  e            ttttttttttttttttttttt//\"\n",
      "batch 8284  loss=145.0125  steps/s=104.32  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tate ee   e            o      o   o    i\"\n",
      "batch 8285  loss=147.9392  steps/s=104.68  prediction: \"more friction than they need to function\" => \"ereie ah       ot t tt t tt n     ee e t\"\n",
      "batch 8286  loss=151.0291  steps/s=96.40  prediction: \"7 gm pretty great how about yours brotha\" => \"7p or e cc 7   r  tttt      t    oo  ooo\"\n",
      "batch 8287  loss=136.4742  steps/s=55.70  prediction: \"sunsettler hes locked in to the outdoors\" => \" mel  eetttt e   tt         oo to u uooo\"\n",
      "batch 8288  loss=157.8311  steps/s=111.70  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e    thtotio ttt oo o  o             n  \"\n",
      "batch 8289  loss=193.1690  steps/s=99.74  prediction: \"H LETS GOOOOO\n",
      "truly a masterpiece lmaooo\" => \"SVS h nHAAAAOOOOOOOOOOO    a   aa    eae\"\n",
      "batch 8290  loss=172.4011  steps/s=103.24  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/..cs:/:////////TT//cttttt//t//t////////\"\n",
      "batch 8291  loss=156.9384  steps/s=102.55  prediction: \"tcs Some say zig has a secret 4th letter\" => \" h://ttccccccs      s   t   ststtttttttt\"\n",
      "batch 8292  loss=151.0520  steps/s=104.33  prediction: \"kind of just whatever I want to pivot to\" => \"edn rr  ii   t tt          tt tt  t  v t\"\n",
      "batch 8293  loss=148.4054  steps/s=104.67  prediction: \"house? where is your phone charger? etc)\" => \"ere  o ou u  e re  e e      eo h  h rre \"\n",
      "batch 8294  loss=142.8799  steps/s=104.92  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \"  ha  e             .....t..ttttttttt//F\"\n",
      "batch 8295  loss=148.7464  steps/s=83.87  prediction: \"amebedan since ports dont allow weapons.\" => \"nee   e    e      tpt  ttttt/ttotFFoooww\"\n",
      "batch 8297  loss=160.8772  steps/s=105.72  prediction: \"nis @startupmillyair pretty solid rating\" => \" n   eeesssssss  tttppp p ll tt   loooos\"\n",
      "batch 8298  loss=139.7867  steps/s=105.41  prediction: \"tic paper searches\n",
      "at this rate it willâ€¦\" => \" nt s  ppppp pa areaeaaa aasaea aaa   tt\"\n",
      "batch 8299  loss=143.5587  steps/s=105.01  prediction: \" usually get out of distribution results\" => \"tstootiuuuuuuu o       t   t   tttt tt t\"\n",
      "batch 8300  loss=146.6343  steps/s=102.51  prediction: \" stream but i do my actual job and stuff\" => \"tt o    o tt   t  t   t      t       a  \"\n",
      "batch 8301  loss=199.3974  steps/s=21.66  prediction: \"eply: @tszzl &gt; the present will\n",
      "how??\" => \" ly: @    tt      t   t      t       a  \"\n",
      "batch 8302  loss=141.7661  steps/s=110.25  prediction: \"ing this with terms masters commonly use\" => \"ng o  i        t            s  smmmmmmmm\"\n",
      "batch 8303  loss=158.6115  steps/s=102.35  prediction: \"reading the code, most are from zig init\" => \"eplv: @ cxzNN&B(@64_+_FF5M21FuFz2z,ZZjj?\"\n",
      "batch 8304  loss=142.9309  steps/s=105.07  prediction: \"nts of time. its like skilling up almost\" => \" eu   mem  m  m  t     s   i  iiiii  ill\"\n",
      "batch 8305  loss=163.1984  steps/s=106.05  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`@y to0 [1]]]1]1    1     s           e \"\n",
      "batch 8306  loss=151.5347  steps/s=105.34  prediction: \" so I invested my time into that instead\" => \"ttreer o o  oo e   ee e i    e  t tttt t\"\n",
      "batch 8307  loss=147.4699  steps/s=103.95  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" tn o t     a a aaa a   aaaaaaaaaagrgggg\"\n",
      "batch 8308  loss=144.2135  steps/s=104.52  prediction: \" the zero quine: https://t.co/qt0qAp9ZYk\" => \"thet t tt                t:::::///q/qqqq\"\n",
      "batch 8309  loss=157.4552  steps/s=101.07  prediction: \"yeah, tunisia... carthage would be nice\"\" => \":a ns  ..  ii.........aaa aaaaa       a \"\n",
      "batch 8311  loss=157.6177  steps/s=72.43  prediction: \"yacineMTB nooo not a 2d grid of 2d grids\" => \":c na aaiiniii..iaaaaaaaa  a a        e \"\n",
      "batch 8312  loss=145.5265  steps/s=107.18  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r o          ii siiississssststtt//////\"\n",
      "batch 8313  loss=152.4044  steps/s=105.31  prediction: \"ot good results: https://t.co/KAmykVYFyw\" => \"n  i         o  o   t   tttststtttt/////\"\n",
      "batch 8314  loss=143.2055  steps/s=103.17  prediction: \" regarded so take that w a grain of salt\" => \"terlm ii    ee       ee aa   aa   aaa  a\"\n",
      "batch 8316  loss=147.8741  steps/s=104.95  prediction: \"s, have back and forth conversations etc\" => \"  p   h s  s    a   a     c             \"\n",
      "batch 8317  loss=148.7359  steps/s=101.91  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" m o  e        e     tt               oo\"\n",
      "batch 8318  loss=146.3482  steps/s=104.87  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei      i iiiiiiii ii     i         uu \"\n",
      "batch 8320  loss=129.4897  steps/s=103.55  prediction: \"ink thats gonna be a massive rabbit hole\" => \"ng n  ttttttttttt              aaaaaabbb\"\n",
      "batch 8321  loss=139.7179  steps/s=103.40  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \"  e  o   'eeeeen    e     e     e  e   e\"\n",
      "batch 8322  loss=149.4870  steps/s=103.78  prediction: \"o make a significant impact on your life\" => \"ng i     a     i  aiiiiiiiiiiiii        \"\n",
      "batch 8323  loss=285.8038  steps/s=11.26  prediction: \"reply: @0xVonNeumann Love it! Cheers bro\" => \"eal    eghZá´NðŸ‘€á´‡vá´¡v$á´¡y%#w#`%kvkâ€$%#y##$ÉªðŸ°\"\n",
      "batch 8324  loss=129.7294  steps/s=109.35  prediction: \"hine now. unless anybody has a spare one\" => \"enkeat       nn  nnnnnnnn               \"\n",
      "batch 8325  loss=159.0349  steps/s=108.70  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"toe en   e               s   ttttt////t/\"\n",
      "batch 8326  loss=158.2746  steps/s=102.48  prediction: \"rs automatically slap that down to 10fps\" => \"e eee n bdk21@))qjCxLj@21:yjvk):501.9,91\"\n",
      "batch 8327  loss=162.3068  steps/s=99.58  prediction: \"in a year, and this was his main opening\" => \"nk o0    0         a     a  aa   aa ii  \"\n",
      "batch 8328  loss=141.0418  steps/s=106.22  prediction: \" she got into medschool after graduating\" => \"tte                 oo ooooo oooo o    t\"\n",
      "batch 8329  loss=142.1168  steps/s=105.24  prediction: \"orthless. you find the gold when you dig\" => \"  e  eeesssesssssss    s                \"\n",
      "batch 8330  loss=152.5169  steps/s=102.66  prediction: \"he phone seems to make a huge difference\" => \"e e te      e  ee  e e ee    e      eeee\"\n",
      "batch 8331  loss=142.2537  steps/s=102.56  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"s  ot tttttt tt      ppp ppppppp        \"\n",
      "batch 8332  loss=165.6327  steps/s=104.28  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"te.E  ht////tXtXtXXXtM3tt/:///tt////t//t\"\n",
      "batch 8333  loss=148.2299  steps/s=105.16  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" og t       aaaaaaaaaannnnnnnnnnnnnnnnnn\"\n",
      "batch 8335  loss=197.1267  steps/s=29.47  prediction: \"ply: @Nominus9 u should raise a series b\" => \"lyt th    aaaaanaaaannnnnnnnnnnnnnnnnnnn\"\n",
      "batch 8336  loss=163.4215  steps/s=132.01  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"ost   yannaaaa  \n",
      "aannd nonnnnnn nnnnnsii\"\n",
      "batch 8337  loss=141.0947  steps/s=108.48  prediction: \"ich is a great way to find opportunities\" => \"ni  i iiiii i                          t\"\n",
      "batch 8338  loss=175.1692  steps/s=67.42  prediction: \"@startupmillyair https://t.co/QgfnCndCQA\" => \"ykii__i     i   a              o ontnnni\"\n",
      "batch 8339  loss=134.7279  steps/s=107.86  prediction: \"learning is by doing stuff. For anything\" => \"y, @e t                                 \"\n",
      "batch 8340  loss=140.0516  steps/s=105.58  prediction: \"sfully improved their lives tremendously\" => \"  bue t sess  sseeeeeee ee eeee eeeeee e\"\n",
      "batch 8341  loss=164.0585  steps/s=105.03  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"/.cotstt////t/////t111ttt/////tt////t//t\"\n",
      "batch 8343  loss=149.5398  steps/s=105.06  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t e seeeeeeeeeeeeraeeaaa  aa   a  a \"\n",
      "batch 8344  loss=153.3497  steps/s=103.11  prediction: \"pression contest\n",
      "https://t.co/bLEHGWjFSr\" => \"lo: s  c  oooooossostttsttsttstttttt/t//\"\n",
      "batch 8346  loss=140.9142  steps/s=104.41  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l n  \n",
      "    o  o    o    ttt  ttttttttttet\"\n",
      "batch 8347  loss=157.1194  steps/s=101.43  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"too oolollllllleoolo  o o       o  o o  \"\n",
      "batch 8348  loss=154.2788  steps/s=102.49  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne oylllllllll         t  tttttttt//////\"\n",
      "batch 8350  loss=143.6690  steps/s=91.48  prediction: \"eMTB i wonder which anime pfp is his alt\" => \" TBli ii in     www      th /  p ppppsss\"\n",
      "batch 8351  loss=137.9359  steps/s=105.04  prediction: \" my chess elo to give data that it works\" => \"tame    n     en              tt    tt t\"\n",
      "batch 8352  loss=156.0236  steps/s=75.90  prediction: \"rdenis grats btw. site looks amazing too\" => \"e ly: @yubqz9MTBPj@V?,,?vx??XP2zPvTjFA?J\"\n",
      "batch 8353  loss=146.1021  steps/s=108.41  prediction: \"lex code across multiple (simple!) Files\" => \"ym  laci    oo c  o  c   ll  lll lll lll\"\n",
      "batch 8354  loss=146.7050  steps/s=104.23  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"tumdo g  ggg iggiiiiii########e#SSSSeeee\"\n",
      "batch 8355  loss=170.4997  steps/s=64.91  prediction: \"@anish0209 gpt or claude or whatever LLM\" => \"ynconbMgigggiiigieeeereeaSSSSSaeaeeeeeee\"\n",
      "batch 8356  loss=149.3326  steps/s=107.15  prediction: \"ould help large numbers of ppl if solved\" => \"ul ereo    llllr  ee   le e   ep  l   l \"\n",
      "batch 8357  loss=163.8353  steps/s=101.03  prediction: \"on\n",
      "Also doesnt apple allow emulators now\" => \"uea eeri o  o  nso    s o ll lll  llllll\"\n",
      "batch 8358  loss=152.7294  steps/s=103.92  prediction: \"itor as I was with 2 screens and a mouse\" => \"ny\n",
      "\n",
      "a a   a                  s          \"\n",
      "batch 8359  loss=143.6469  steps/s=100.82  prediction: \"xe only the strongest can take this path\" => \"p  iks         s        e tttttt   t    \"\n",
      "batch 8360  loss=163.5175  steps/s=88.28  prediction: \"binet_ Sweet!!! Let me know how 3js goes\" => \"et o        tett!!!!!!!!   ee          h\"\n",
      "batch 8361  loss=137.4851  steps/s=103.82  prediction: \" yrs. ur brain will figure it out, trust\" => \"toui         rr rrr r    ii iiii  i    u\"\n",
      "batch 8362  loss=151.5211  steps/s=103.10  prediction: \"000000000000000000000001% of the new one\" => \"000xheebLpR1wAx@3_3I-@.%x%!NL~BAT,G2DWG\"\"\n",
      "batch 8363  loss=154.6087  steps/s=102.88  prediction: \"ng term\n",
      "\n",
      "Best signal to work on for sure\" => \"g iol   tt t ttttt  t t      t  o    o  \"\n",
      "batch 8364  loss=182.4814  steps/s=91.99  prediction: \"5 custom tools speed things up a TON tbh\" => \" fo l     tetss tos tss s e  n  o       \"\n",
      "batch 8365  loss=144.2423  steps/s=103.88  prediction: \"re for blundering bc of moving too quick\" => \"epov    cgCYC_xUYPYIYYT%x%YYYY55YYqTOTOq\"\n",
      "batch 8366  loss=147.9590  steps/s=104.21  prediction: \"e component is the key to crazy stuff...\" => \" pons  oe  nnn  nn  e     e  ee  t   t  \"\n",
      "batch 8367  loss=139.9934  steps/s=104.14  prediction: \"knesses and imbalances, using space, etc\" => \"iag niieeeeneeeneaaaaaaasassaas ssssssss\"\n",
      "batch 8368  loss=160.0017  steps/s=103.85  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n  h     EEEEEE P ee   :::t:://///  ///4\"\n",
      "batch 8369  loss=178.4423  steps/s=103.22  prediction: \"list its goated) https://t.co/ZXdRLZ8a4L\" => \"yte zii   t  tt tt ttttt ttttttttt/t///Z\"\n",
      "batch 8370  loss=161.3656  steps/s=102.13  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"t it  o   o  00 0 000000ttttt///////////\"\n",
      "batch 8371  loss=177.2101  steps/s=87.76  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"_ahe2a0000000   h ttttt/tttccchtcec3aacðŸ›‘\"\n",
      "batch 8372  loss=146.9071  steps/s=105.02  prediction: \"ession youll do something until its done\" => \"  me teeeeeeoe l  ooooooooooo      i    \"\n",
      "batch 8373  loss=148.1395  steps/s=103.86  prediction: \"n just build cool fun stuff all the time\" => \"gt he          u  u    uu uu     l   ll \"\n",
      "batch 8374  loss=178.6735  steps/s=29.30  prediction: \"ply: @sunsettler im down another weekend\" => \"ly:e@e      u     u u  uu uu     l   l  \"\n",
      "batch 8375  loss=210.2590  steps/s=125.02  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"pS  rs_e EVVVVEEVE!!!!!!!!!!!    ee ttet\"\n",
      "batch 8377  loss=138.3849  steps/s=101.31  prediction: \"n in the ass to get it to stop shuffling\" => \" j h  V                   t   t   tt    \"\n",
      "batch 8378  loss=142.4165  steps/s=104.86  prediction: \"s large of a positive impact as possible\" => \" In a  aaaa                           ss\"\n",
      "batch 8379  loss=319.7106  steps/s=10.73  prediction: \"reply: @crackeddl its hard. but worth it\" => \"esly   tmm!+*P8599)89!y*9II)8KKKK*!Ik!!I\"\n",
      "batch 8380  loss=176.3519  steps/s=106.86  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \" hNT\n",
      " DADAAA AAAAA ACCC   C        ////t\"\n",
      "batch 8381  loss=175.8579  steps/s=105.51  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" m og                                   \"\n",
      "batch 8382  loss=164.7467  steps/s=44.88  prediction: \"y: @amix011 but you cant buy an audience\" => \": @Na a  [                        i     \"\n",
      "batch 8383  loss=170.3859  steps/s=108.26  prediction: \"obably been undervaluing its utility tbh\" => \" l  t t oo b bbrbbbbbeeeeeuuununnu uuiui\"\n",
      "batch 8384  loss=149.4091  steps/s=101.61  prediction: \"there like this?\n",
      "https://t.co/ZF2p1Q4n6L\" => \"he  ol          e tttttthhtttttttttt////\"\n",
      "batch 8385  loss=159.1124  steps/s=96.01  prediction: \"pmillyair lichess is like 200 elo higher\" => \"les  s tl tlili iiihhssssssi  i222222 00\"\n",
      "batch 8386  loss=154.6281  steps/s=104.40  prediction: \" monday\n",
      "\n",
      "5am (your timezone) is best imo\" => \"ton    a a    ayyyayy y yo oo      o  o \"\n",
      "batch 8387  loss=143.9681  steps/s=105.23  prediction: \"r the picture\" for any industry or niche\" => \"etto   cfI'á´‡fá´„ðŸ˜­^kvá´„{,W{ZTÊ€\"W,{Ê€v$I'T$W$$\"\n",
      "batch 8388  loss=148.0332  steps/s=104.91  prediction: \"e thing, not just messing around with it\" => \" tiat t ttt ttt  nt  t    tn      n     \"\n",
      "batch 8389  loss=148.7381  steps/s=103.31  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"t  yay                                  \"\n",
      "batch 8390  loss=154.2003  steps/s=105.54  prediction: \"illed w AI tools https://t.co/AIn5typg7l\" => \"nl ant                  ttttttttttttt///\"\n",
      "batch 8391  loss=153.5542  steps/s=103.52  prediction: \"hackers #buildinpublic #developers #SaaS\" => \"ete oeete#####iiieieeibiiididiiieiele#e#\"\n",
      "batch 8392  loss=143.4758  steps/s=104.15  prediction: \"y want to use something feeling-relatedâ€¦\" => \" c  e bb   b  ob  o         ee  eeeeeeee\"\n",
      "batch 8393  loss=135.6612  steps/s=107.01  prediction: \"tony learns domain expansion in season 5\" => \"h t  t    n nn nnn nnnnnn nnnnnnn nnnnn \"\n",
      "batch 8394  loss=174.9195  steps/s=97.08  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"n  z n nn   oon         tt   t  t ///t5/\"\n",
      "batch 8395  loss=150.9982  steps/s=96.06  prediction: \"ezm progressive overload builds strength\" => \" ) o   oe o  orrrreeees ttooo/o  a  ssss\"\n",
      "batch 8396  loss=253.9956  steps/s=10.85  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"eply: @d\n",
      "g4_!.z(z-@DD!BLTMTBSU::/D..-!FF\"\n",
      "batch 8397  loss=162.2747  steps/s=129.83  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tnu  zeoeererrrrreeeres  o  oddsts sstts\"\n",
      "batch 8398  loss=144.7611  steps/s=110.32  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"enlol @namM\n",
      "á´„á´‡xAzC@Z}$$$.MIB$$::/`v.-ðŸ¤¦kÉª\"\n",
      "batch 8399  loss=176.5047  steps/s=100.24  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:      p             0       s ///t///\"\n",
      "batch 8400  loss=145.3929  steps/s=105.35  prediction: \"you can control the models, and its free\" => \":u  occc  cc c coo   o   o              \"\n",
      "batch 8401  loss=149.4998  steps/s=102.96  prediction: \" of all time itd be sebby and his 9 alts\" => \"tf     olllll       ll               b  \"\n",
      "batch 8402  loss=177.7590  steps/s=91.67  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \"hpro slllttt         eeettttt  s 99999ss\"\n",
      "batch 8403  loss=155.4086  steps/s=103.93  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"ntititiiiiiiittit  ot   g  s  g s  ss  s\"\n",
      "batch 8405  loss=156.7368  steps/s=99.48  prediction: \"opped this, king https://t.co/XoVrIPw6zw\" => \"np bs e     d          t    t tt////t///\"\n",
      "batch 8406  loss=146.7390  steps/s=105.36  prediction: \"moves in opening\n",
      "https://t.co/hv5NypSZGV\" => \"oves s      e     e     n tttttttt//////\"\n",
      "batch 8407  loss=150.9981  steps/s=104.07  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"ew st  ssf!BSE7)PLBkxN2jDO??MMT?#MIWf(zL\"\n",
      "batch 8408  loss=143.6548  steps/s=99.85  prediction: \"utput or efficiency alone\n",
      "\n",
      "output^2/cost\" => \"t  m    uuu  u t    ff f  e ooooootootoo\"\n",
      "batch 8409  loss=146.9655  steps/s=104.05  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \" a    p   p     e      eeeeeee e ee ieii\"\n",
      "batch 8410  loss=153.0590  steps/s=104.20  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \" : @k   \n",
      "     ini ni  aae  a  i  ii tt t\"\n",
      "batch 8411  loss=157.1246  steps/s=61.41  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"tga   mi iiiiniiihnaaaaattaa a    tt  tt\"\n",
      "batch 8412  loss=145.6399  steps/s=106.03  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"tuda a    a    i   i       i  i         \"\n",
      "batch 8413  loss=143.0283  steps/s=103.92  prediction: \"rom things like chess or bjj or whatever\" => \"emsn  e av!RxE8@zL//xNk-DN??MM(?WMSWI#Tk\"\n",
      "batch 8415  loss=141.3696  steps/s=105.37  prediction: \"orthless. you find the gold when you dig\" => \"neee eeesssesssssss    s                \"\n",
      "batch 8416  loss=144.9164  steps/s=105.04  prediction: \"y do what sounds more interesting to you\" => \" th o o  o    o    o o    o           t \"\n",
      "batch 8417  loss=139.7789  steps/s=104.23  prediction: \"ything rewarding that follows from that)\" => \" imaaingigeerrrigrrrrrrg      a  r    o \"\n",
      "batch 8418  loss=158.1249  steps/s=102.03  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"theer     t   e    t ttttttttttt/////ot/\"\n",
      "batch 8419  loss=152.4084  steps/s=104.83  prediction: \"\" and idk what that is? Time to learn it\" => \" aops\" \"s    a      a         t         \"\n",
      "batch 8420  loss=302.5953  steps/s=11.21  prediction: \"reply: @djcows leveraged short positions\" => \"eply i  \"\"EGMð—°ðŸ’ª^j`@GMZ:jf\"\"á´€-&,\";kk;\",Gk\"\n",
      "batch 8421  loss=148.7668  steps/s=122.73  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \"hi h o         t                00000000\"\n",
      "batch 8422  loss=144.3801  steps/s=104.34  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"h nt nt fff iini iiiioiiiiooooroooorrror\"\n",
      "batch 8423  loss=140.5762  steps/s=99.51  prediction: \" What are your personal long term games?\" => \"thtl ili      a    rrrrroroooo   o     m\"\n",
      "batch 8424  loss=147.8669  steps/s=103.56  prediction: \"te how much some debuffs will damage yoâ€¦\" => \" pn  detete eee e     e       e     e   \"\n",
      "batch 8425  loss=140.6018  steps/s=104.71  prediction: \"people skills of almost everyone ive met\" => \"lr nen    eeeee     ll llllll     eeeeee\"\n",
      "batch 8426  loss=150.5400  steps/s=105.06  prediction: \"on chunking showed higher level playersâ€¦\" => \"     s       n       hhhhh hhhhhhe eee e\"\n",
      "batch 8427  loss=144.9964  steps/s=105.10  prediction: \" the game loop in zig, rendering in cuda\" => \"that       e   t                 ee ii  \"\n",
      "batch 8430  loss=169.5921  steps/s=100.35  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \" aaaeaeae elll e llllooloooooo///ttt////\"\n",
      "batch 8431  loss=148.9932  steps/s=105.71  prediction: \"g correct (fingers crossed its this one)\" => \" ane eerr   rrrrrrerr  rrerr  ssss s ss \"\n",
      "batch 8432  loss=141.1799  steps/s=104.70  prediction: \"marter you get the more the traps change\" => \"ole  a                 e   e   e   e    \"\n",
      "batch 8433  loss=156.1117  steps/s=104.70  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"h  gttt///////ththttttttttttt////////ttt\"\n",
      "batch 8434  loss=148.0231  steps/s=103.17  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \" t                f         tt ////tt///\"\n",
      "batch 8435  loss=152.2881  steps/s=74.50  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"nt o           c ttthhttt///////t//otp11\"\n",
      "batch 8436  loss=148.1130  steps/s=108.16  prediction: \"onder if he stuck w onnx or went w tf.js\" => \"   eleee                           w    \"\n",
      "batch 8437  loss=147.5533  steps/s=103.70  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"n(ee        e    ee e     o    a a   a l\"\n",
      "batch 8438  loss=150.2606  steps/s=102.51  prediction: \" like this too? They come in pairs often\" => \"tone  r        t     o   o    e    o  i \"\n",
      "batch 8439  loss=143.1507  steps/s=104.66  prediction: \"pick any domain/topic there are usuallyâ€¦\" => \"lxt  o  k      n     i  iio i i   e   a \"\n",
      "batch 8440  loss=155.7334  steps/s=104.32  prediction: \"outworking them\"\n",
      "\n",
      "i remember that often.\" => \"    eeeoeo    oeo o   e  eeeememeemeeeee\"\n",
      "batch 8441  loss=155.4770  steps/s=101.00  prediction: \" them for yourself initially? im curious\" => \"to                         i  iiiiiiiiii\"\n",
      "batch 8442  loss=143.4255  steps/s=100.90  prediction: \" bricked my laptop\n",
      "patronizing bloatware\" => \"tee  ed   e            pppppppppppppoaao\"\n",
      "batch 8444  loss=143.8128  steps/s=104.35  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"ec21: @s5`Éªð—¼ðŸ¤”0ð—¿B2á´„$ðŸ˜Ž$K$KTÉ´^KzÉª`$ð—¿ð—¯ðŸ¤¦`$ðŸ§ $$\"\n",
      "batch 8445  loss=144.0600  steps/s=105.79  prediction: \"s called it tho, dont practice deception\" => \" bo e                     t  t t  ttcccc\"\n",
      "batch 8446  loss=171.4629  steps/s=105.13  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"tt.tI \n",
      "ts///t/////ttQtttZZ     x  xxxx x\"\n",
      "batch 8447  loss=283.1296  steps/s=11.76  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"epli g  uIz370jQ2CWMZxw!(1jQECW3Zx71(533\"\n",
      "batch 8448  loss=175.7485  steps/s=127.50  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"nlhl  lhhhhttZZ    OOOOOOOw    e  bb  ba\"\n",
      "batch 8449  loss=170.6843  steps/s=61.67  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"ust  Toy hh a   OOOOOw wwow   bb  bee ea\"\n",
      "batch 8450  loss=161.3039  steps/s=122.69  prediction: \" the 16 hour coding session, lets get it\" => \"to n   7                         ssssss \"\n",
      "batch 8451  loss=148.4433  steps/s=99.90  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"iob   to oo ooooooooooo  n nn           \"\n",
      "batch 8452  loss=152.3669  steps/s=93.39  prediction: \"ylde lowkey cant believe zompy said that\" => \":iingiliooolll    n   n  e    ee      i \"\n",
      "batch 8453  loss=161.5285  steps/s=104.60  prediction: \"ou can dive unbelievably deep into these\" => \"nttt  d tY   e  n    ne eebebbeeeeeeeee \"\n",
      "batch 8454  loss=145.3518  steps/s=103.74  prediction: \"pl to influence what they think (cringe)\" => \"ly: n pp pp    n    n    t    t   t t  t\"\n",
      "batch 8455  loss=163.7554  steps/s=98.27  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"  g dssss!!!!!  h   t    t t  t     uuuu\"\n",
      "batch 8456  loss=142.2140  steps/s=103.15  prediction: \" end of the task off worked for you too?\" => \"tvetieeetee                  ffff    ooo\"\n",
      "batch 8458  loss=156.9123  steps/s=104.00  prediction: \"e building an army of tiny little robots\" => \" so                                     \"\n",
      "batch 8459  loss=141.9721  steps/s=105.62  prediction: \"s w java and python and studying for fun\" => \" artth    a      a a    a   n      n   n\"\n",
      "batch 8460  loss=161.2838  steps/s=67.23  prediction: \"ludwigABAP its all slop tier, always was\" => \"yd @ um aaa      a a n        n         \"\n",
      "batch 8461  loss=170.4628  steps/s=113.43  prediction: \"king stuff part of twitter is so fun wtf\" => \"in  wi g  0   ata    f tff t it w tttt s\"\n",
      "batch 8462  loss=133.2648  steps/s=99.79  prediction: \" of the tier lists of all time, for sure\" => \"tn   i t             t       s          \"\n",
      "batch 8463  loss=152.3822  steps/s=100.13  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"tatltt  lll  e e      tttttttttt/t//////\"\n",
      "batch 8464  loss=161.7107  steps/s=102.08  prediction: \"reaks). During these sessions my producâ€¦\" => \"eplim eecl+/N+x;,O)SjD)RRDRRRTR7T7S=RRâ€¦R\"\n",
      "batch 8465  loss=221.9363  steps/s=101.43  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"EhG H THSSSS SSSGGGGGGGGNNN     //////3/\"\n",
      "batch 8466  loss=249.9998  steps/s=11.33  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eplym eeCAQ/3JxP,m)Ej16:RD3-2xI??7GA7Zâ€¦ðŸ›‘\"\n",
      "batch 8467  loss=159.0594  steps/s=112.21  prediction: \"ective, its significantly more efficient\" => \" o t o   eeeei eiiiiisiiiiiiiii ii iffff\"\n",
      "batch 8468  loss=148.3980  steps/s=103.42  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyn  MfOÉªU*á´$~ð—¼|@KÉª$vâ€™á´€$ðŸ˜¢$Éª7$OðŸŒ‘ð—µðŸ˜Žv$ðŸ˜‰á´€|\"\n",
      "batch 8469  loss=200.6779  steps/s=38.32  prediction: \"ly: @pepegawitch https://t.co/SATxjQ6nk5\" => \"y: @a si             dd    d            \"\n",
      "batch 8470  loss=147.9090  steps/s=115.18  prediction: \"am and it doesnt mess your sleep up much\" => \"nee t      a                  sssss     \"\n",
      "batch 8471  loss=147.0811  steps/s=94.80  prediction: \"my database is a text file called main.c\" => \"e as@en     aa ta asa  s    e  e l lllll\"\n",
      "batch 8472  loss=155.1881  steps/s=65.33  prediction: \"dejavucoder roon was gpt5 the whole time\" => \"  e e  aaa  aa  a aa   s    t   elllllll\"\n",
      "batch 8473  loss=147.8455  steps/s=107.08  prediction: \"e thing, not just messing around with it\" => \" tiat t ttt ttt  nt  t    tn      n     \"\n",
      "batch 8474  loss=155.8542  steps/s=100.26  prediction: \"new following you was the right decision\" => \"gw e tth h    ow o   w  ww  oo     hh   \"\n",
      "batch 8475  loss=186.0336  steps/s=53.16  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @aaoinowwow  ow www w  ww   o     iti  \"\n",
      "batch 8476  loss=151.9863  steps/s=107.05  prediction: \", write one sentence after another, andâ€¦\" => \" wnd  r       o e  ee ee eeeeeeeeeeeenne\"\n",
      "batch 8477  loss=205.5385  steps/s=98.82  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"H  EHO  UPMM ES  U  U          t   /// t\"\n",
      "batch 8478  loss=164.3971  steps/s=105.49  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"EmOK  rrrorrrrr rr aaaaaa aaa a aaaa a  \"\n",
      "batch 8479  loss=162.6981  steps/s=102.68  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "o oAe ee  eeeeee ee ee ee  s s s  s  s\"\n",
      "batch 8480  loss=145.8547  steps/s=105.05  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"te            ee eee ooeeeeeeeee  o  o s\"\n",
      "batch 8481  loss=148.8053  steps/s=104.35  prediction: \" pieces until you have solved the puzzle\" => \"to  ooe        n                v      e\"\n",
      "batch 8482  loss=170.9635  steps/s=37.51  prediction: \"ly: @archived_videos am american, so idk\" => \"y:   onee ee   n         v vvv v      ee\"\n",
      "batch 8483  loss=143.6561  steps/s=110.42  prediction: \"its bad but, it has pros you can play to\" => \"n     oss s s  st    t  t   s    s      \"\n",
      "batch 8484  loss=159.3173  steps/s=104.57  prediction: \"as the guide on how to beat mind viruses\" => \"tting p  s s  es                        \"\n",
      "batch 8485  loss=95.5462  steps/s=104.74  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"touOOOO \n",
      "   aa     aa  a aa???????    E \"\n",
      "batch 8486  loss=155.3851  steps/s=103.66  prediction: \"s of adults\"\n",
      "\n",
      "i very often think of that\" => \" ah0   od od   d  dd      e  e  t   t tt\"\n",
      "batch 8487  loss=168.4082  steps/s=97.05  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u lr   l         r  r  tttsttt to////t/\"\n",
      "batch 8488  loss=153.7040  steps/s=97.87  prediction: \"ot even... this? https://t.co/vAkhEpFVm1\" => \" hc c ennn nn .... ...ttt//t///////////A\"\n",
      "batch 8489  loss=140.4106  steps/s=105.64  prediction: \"ort of like a spike strip but for boats)\" => \"u tho                                   \"\n",
      "batch 8490  loss=142.7059  steps/s=104.83  prediction: \"ies and more insights. Then will release\" => \"ns e       r   e    i iiss s  i i  i  e \"\n",
      "batch 8491  loss=139.4303  steps/s=104.35  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e g ee  e    e        tt  ttttttttttt///\"\n",
      "batch 8492  loss=153.7768  steps/s=101.88  prediction: \" people who find their work fun win more\" => \"teoro  e e o   he e e h  h w     w    w \"\n",
      "batch 8493  loss=166.3697  steps/s=97.04  prediction: \"ts just showing you their main accts now\" => \"    iols00  s  s    i h oo      in ii   \"\n",
      "batch 8494  loss=139.4965  steps/s=99.70  prediction: \"the replies here\n",
      "https://t.co/9TNeUoLw5k\" => \" e         e eeneeeeeeeeeeetttttt///////\"\n",
      "batch 8495  loss=212.3260  steps/s=26.01  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @   e eeeeeeeeeeeeteettttt/////////\"\n",
      "batch 8497  loss=142.6946  steps/s=117.73  prediction: \"us things that make your life easier ig?\" => \"tt buiiiiiiiiitttttt                    \"\n",
      "batch 8498  loss=134.9590  steps/s=104.88  prediction: \" on bookmarks from people similar to you\" => \"tf  d     bbo ooooooooooooooo  o        \"\n",
      "batch 8499  loss=142.2629  steps/s=99.89  prediction: \" do. pays dividends for a long long time\" => \"tos            ddddddddddd              \"\n",
      "batch 8500  loss=144.5538  steps/s=105.91  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"g  tt  t    t  ttt  ooo t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaa\n",
      "\n",
      "a\"\n",
      "batch 8501  loss=144.5373  steps/s=103.89  prediction: \"of the network (target, a_output, loss,â€¦\" => \"u e  e               tttttttttttttttttt,\"\n",
      "batch 8502  loss=151.5061  steps/s=106.40  prediction: \"hess isnt hard just make the right moves\" => \"e m _essss   ss   s ss s    t  t t  tt  \"\n",
      "batch 8503  loss=153.0656  steps/s=100.71  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" m e ne\n",
      "\n",
      "Reeeeeeeesseseeessesessessssee \"\n",
      "batch 8504  loss=147.9719  steps/s=104.08  prediction: \"layer type stuff, but going even further\" => \"yy   oreerr  e ee  e     t   t   e e  ff\"\n",
      "batch 8506  loss=140.1870  steps/s=104.24  prediction: \"th `sudo service NetworkManager restart`\" => \" e  en  rr r r     e  eeee ee eereeererr\"\n",
      "batch 8507  loss=150.1114  steps/s=103.67  prediction: \" strategy is short term low integrity BS\" => \"tooo e    s    ssss ss        t  t tttrt\"\n",
      "batch 8508  loss=186.1624  steps/s=67.42  prediction: \" @eyeofenceladus https://t.co/dIPbA0GNsC\" => \"tlon eee  e ss  ssstttt      t   ttttt t\"\n",
      "batch 8509  loss=152.1850  steps/s=107.61  prediction: \"for code writing https://t.co/Vlv7kxKPyM\" => \" rtin t              t   ttttt////t/////\"\n",
      "batch 8511  loss=151.5653  steps/s=100.96  prediction: \"hess isnt hard just make the right moves\" => \"e e sossss   ss   s ssss  t t    t  ttt \"\n",
      "batch 8512  loss=142.5697  steps/s=103.17  prediction: \"ing this with terms masters commonly use\" => \"ng o  f        t            s  smmmsmmmm\"\n",
      "batch 8513  loss=190.9738  steps/s=99.26  prediction: \"DE\n",
      "14hrs is wild\n",
      "also james is a gooooat\" => \"eNenvsUUDEU         ss ss ssssss    s  o\"\n",
      "batch 8515  loss=136.8885  steps/s=103.70  prediction: \"to someone on X, its laggy when it plays\" => \"                                        \"\n",
      "batch 8516  loss=132.5375  steps/s=102.09  prediction: \" and the quote tweet is the reply itself\" => \"t  t    tttttttetteetteeteeeeee ee    e \"\n",
      "batch 8517  loss=145.8365  steps/s=105.46  prediction: \"compress a lifetime into a few sentences\" => \"omp issie   s    e   iii  i          eee\"\n",
      "batch 8518  loss=151.1402  steps/s=103.71  prediction: \"l, titan, stable diffusion, a few others\" => \"y  oint a ar   sa aat  at  ai i,  i     \"\n",
      "batch 8519  loss=140.3069  steps/s=99.65  prediction: \" ways to take advantage of small nuances\" => \"tor o    o    a  aat aa aa aaaaaaaaaaa a\"\n",
      "batch 8520  loss=146.0203  steps/s=105.27  prediction: \"xample\n",
      "Do this and then train them on it\" => \" cfdo    e e   t    t    t   t t  t t  t\"\n",
      "batch 8521  loss=152.9468  steps/s=105.75  prediction: \"ang out in tunisia every once in a while\" => \"td ee   a    t    t   i  n       nn    i\"\n",
      "batch 8522  loss=161.3445  steps/s=99.86  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" th  h      u    l  eeeeppeepe////tt////\"\n",
      "batch 8523  loss=159.8324  steps/s=100.15  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"ool thlo ooo   loo   aa   .ooooo oooooo \"\n",
      "batch 8524  loss=160.8755  steps/s=105.57  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  nt e;;;gggg&eg;trttttttttoo oo  LLLLL \"\n",
      "batch 8525  loss=150.3870  steps/s=104.62  prediction: \"you find God, the truth, and help people\" => \" u  oe eeeee   ee        t      h  hh   \"\n",
      "batch 8526  loss=152.9200  steps/s=105.10  prediction: \"d cost tracking\n",
      "\n",
      "https://t.co/GwHAwU1n1Z\" => \" ti iono o too  cnttrc  ttttttstt/t///tt\"\n",
      "batch 8527  loss=153.8083  steps/s=89.68  prediction: \"tcs Some say zig has a secret 4th letter\" => \"hht os   c ts  \n",
      "    st  ss  assttwtttttt\"\n",
      "batch 8528  loss=150.7619  steps/s=104.95  prediction: \" random nonsense will escape containment\" => \"tet seeee mm m ssssnnnnen es ese eeennen\"\n",
      "batch 8529  loss=172.6358  steps/s=103.42  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"t.caaatt////t///ttzzztzzzz/t//tt////t///\"\n",
      "batch 8532  loss=146.7602  steps/s=104.38  prediction: \"tups are hidden in the fog 2 moves ahead\" => \"hsnf s st      tts                     e\"\n",
      "batch 8533  loss=210.0694  steps/s=21.16  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" lytttttt       t                     ee\"\n",
      "batch 8534  loss=151.7549  steps/s=117.78  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"n  o ttt               ee  e reeeeeemmmm\"\n",
      "batch 8535  loss=168.3375  steps/s=101.97  prediction: \"EDM and caffeine\n",
      "https://t.co/xSA2QsenCw\" => \" Sl2 ing n n   n n e e etttttttte////tte\"\n",
      "batch 8536  loss=152.4652  steps/s=102.93  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"td m mmmm m   '''' '''''    t           \"\n",
      "batch 8537  loss=165.1215  steps/s=99.30  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" i : @  u       o        t tttttto////VV\"\n",
      "batch 8538  loss=149.3623  steps/s=80.06  prediction: \"amebedan @jaivinwylde stochastic success\" => \"ne amemnn         ttttt tttttttttoctcccc\"\n",
      "batch 8539  loss=153.9270  steps/s=105.53  prediction: \"round PNGs in powerpoint xDDDDDDDDDDDDDD\" => \"eu i   ayz86z_PNGD6@6~~v66~yKKKvKK~@~:j~\"\n",
      "batch 8540  loss=177.3319  steps/s=97.70  prediction: \"ode Solidworks\n",
      "$500/yr aint gonna cut it\" => \"n  dddddddddod odoororr00000000nnnnnnnnn\"\n",
      "batch 8541  loss=164.7899  steps/s=66.58  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"niind idddooooio 0000rrrnn     nn n   a \"\n",
      "batch 8542  loss=206.0217  steps/s=37.97  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @Sdcaoooo$i 000rrkkn     r       a \"\n",
      "batch 8543  loss=130.9114  steps/s=111.13  prediction: \"ot at the same time/in the same geometry\" => \"n s  t ttt ttt  tt  t  t   e  e e ee eee\"\n",
      "batch 8544  loss=150.9630  steps/s=103.83  prediction: \")\n",
      "RAG would be very useful for requestsâ€¦\" => \"\n",
      "\n",
      "attcr tRr  oo       e    eeuuu  u u uu\"\n",
      "batch 8545  loss=147.4432  steps/s=101.99  prediction: \"ems like you have. thanks for sharing it\" => \" e n ileeeeeeeeee ee                    \"\n",
      "batch 8546  loss=135.8645  steps/s=103.43  prediction: \"er. you thaw the skill out when its time\" => \" s te eeeeeee  t   e                  t \"\n",
      "batch 8547  loss=163.8859  steps/s=102.90  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" a h s   o    o  ooo oooo onnnnn  nn    \"\n",
      "batch 8548  loss=148.0583  steps/s=95.08  prediction: \"whoa thats wild, old twitter could never\" => \"hat  seteett     l   ll     l     t     \"\n",
      "batch 8549  loss=133.1041  steps/s=100.10  prediction: \"trained though through practice, luckily\" => \" aa  a            hhhhhh hhhhhhhhh  cc c\"\n",
      "batch 8550  loss=157.5961  steps/s=103.91  prediction: \"r\"\n",
      "\"uhh no i cant tell you trust me bro\"\" => \"e eo   itdMAG`xv,``wIGI@```61xDDDkDDDDvD\"\n",
      "batch 8551  loss=137.7310  steps/s=102.06  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"ne al  e   l   leeee etee ereerrrarrraaa\"\n",
      "batch 8552  loss=137.0341  steps/s=100.46  prediction: \"ely definitely worth messing around with\" => \" yniniieiiiieieeiiiiiteeeee e i         \"\n",
      "batch 8553  loss=144.5472  steps/s=100.42  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"ta deieeee e e c    e     e      e  o   \"\n",
      "batch 8554  loss=146.6486  steps/s=103.62  prediction: \"my ability to make things I want to make\" => \"a h  i    i    n                        \"\n",
      "batch 8555  loss=168.6062  steps/s=48.41  prediction: \"y: @radbackwards God invented it\n",
      "Idk lol\" => \": @sn   i  i           i        tt      \"\n",
      "batch 8556  loss=156.4156  steps/s=107.71  prediction: \"n i googled jai\n",
      "\n",
      "https://t.co/0iPetw3vE0\" => \" th                i i    tttt//////////\"\n",
      "batch 8557  loss=160.5952  steps/s=96.16  prediction: \"Koala that would be much appreciated, ty\" => \"aswK aKaaaa aaa aaatttt    o    eeepppcp\"\n",
      "batch 8558  loss=184.7046  steps/s=103.31  prediction: \"ackwards buttons https://t.co/JO2nBFplUJ\" => \"tk   rrr  rw rr r aa bsta/t /tttt//tt//J\"\n",
      "batch 8559  loss=145.3620  steps/s=103.14  prediction: \"isten to remixes of the ost all the time\" => \"n   s s                                 \"\n",
      "batch 8560  loss=150.8720  steps/s=104.83  prediction: \"r the years for business/building things\" => \"ete   onuwjjX++b(Fj)+w+((__vF___/3)(pw$j\"\n",
      "batch 8561  loss=144.5806  steps/s=104.26  prediction: \"e\n",
      "\n",
      "swapped to mint and never looked back\" => \" \n",
      " p a  ppppppps   t ta t  e e e n   d e\"\n",
      "batch 8562  loss=146.3361  steps/s=102.30  prediction: \"e drew your whole country as the soyjack\" => \" a r   r    r r  r  r  r    r  o        \"\n",
      "batch 8563  loss=164.6331  steps/s=104.35  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \"  @mansyyyyyyyyy      dd    iiiiiiiiniii\"\n",
      "batch 8564  loss=158.0648  steps/s=97.80  prediction: \"h @tsoding Musializer looked pretty cool\" => \"ea  nsssssssss siiisiiiiiiiii  eee ee   \"\n",
      "batch 8565  loss=145.3587  steps/s=103.61  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"  ine eneneennnnennnnnnnnnnennnnonoooooo\"\n",
      "batch 8566  loss=217.2635  steps/s=21.41  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @enennennnnennnnnnnnnnonoo o oooooo\"\n",
      "batch 8567  loss=297.7655  steps/s=37.82  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"ealym   dcpA9x5341v+/++@+TAv-+++-Tx//xvz\"\n",
      "batch 8568  loss=140.3632  steps/s=108.13  prediction: \"code base to get something super complex\" => \"hm a te  e    ee e   e  e      e     e  \"\n",
      "batch 8569  loss=183.9687  steps/s=99.04  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"r etnp//////ssstBBBBBBoo      o o       \"\n",
      "batch 8570  loss=144.3864  steps/s=103.97  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" monnnnnnnoo oo        t tttttttt///////\"\n",
      "batch 8571  loss=278.3674  steps/s=11.09  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eply:   af-A=z53M1CCUx2CCCCv2x)??===-=6Z\"\n",
      "batch 8572  loss=149.0998  steps/s=107.97  prediction: \", how much info could you get from that?\" => \" an  o  i  i   m  i    oo  oo   o    o  \"\n",
      "batch 8573  loss=153.3806  steps/s=100.86  prediction: \"conclusion that the zig code IS the docs\" => \"omp 0  o cc o  to  t ttt   t    t       \"\n",
      "batch 8575  loss=166.4197  steps/s=101.65  prediction: \" a https://t.co/OmDwKUEq4p for gpt5, rip\" => \"tne   s   ss tts tt/tt////t/////     ppp\"\n",
      "batch 8576  loss=275.9116  steps/s=11.30  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @dddS+(x_0X@X:XX,.W_+OXDXKUEq4-j++\"\n",
      "batch 8577  loss=144.5618  steps/s=123.87  prediction: \"u were in vim, it should start the timer\" => \"sc ae             i               t  ttt\"\n",
      "batch 8578  loss=146.6073  steps/s=104.61  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t e  eeeeeeeeeeeeraeea a  aa  aa  a \"\n",
      "batch 8579  loss=149.9121  steps/s=104.19  prediction: \"uch data of rust + windows API functions\" => \"sh t t  n                               \"\n",
      "batch 8580  loss=151.6552  steps/s=80.95  prediction: \"ex Only if you get a lobotomy afterwards\" => \"  od                      o o o o toto  \"\n",
      "batch 8581  loss=144.8111  steps/s=104.80  prediction: \" loss (erroneously a vector) as a scalar\" => \"toi eh h       eoooooo  ee              \"\n",
      "batch 8582  loss=150.3050  steps/s=103.11  prediction: \"ugh or is it just whatever comes to mind\" => \"sh o  oorrr o  o  i     t tt   t t  t   \"\n",
      "batch 8584  loss=142.8042  steps/s=104.05  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n ,                      ttttt//////////\"\n",
      "batch 8585  loss=176.5412  steps/s=100.34  prediction: \"as irl but the ppl here are way higher x\" => \"n ic                                 e  \"\n",
      "batch 8586  loss=145.0080  steps/s=100.36  prediction: \"ugh\n",
      "\n",
      "but lud should be up there for sure\" => \"shigd        u uuuuuuuuuuuuuu           \"\n",
      "batch 8587  loss=162.8851  steps/s=66.62  prediction: \"@squirtle_says yacine what have you done\" => \"ludoo_Atutuuu  uuu  u u    hh   e       \"\n",
      "batch 8588  loss=164.8603  steps/s=105.77  prediction: \"ed in joining, repeat these instructions\" => \"  ey ee ee eieeeinnieienee    enee ettet\"\n",
      "batch 8589  loss=158.9417  steps/s=103.42  prediction: \"ething. @dnbt777 https://t.co/i9PslcwipA\" => \" co  o o oo  o  t777777t tttt.tt/tt/tt/t\"\n",
      "batch 8590  loss=147.4161  steps/s=104.76  prediction: \"d \"compress\" anything into 1 byte (veryâ€¦\" => \" te  a \"\"\"\"\" \"\" \"\"\"s\" s  n    n n       \"\n",
      "batch 8591  loss=216.7874  steps/s=21.31  prediction: \"eply: @yacineMTB https://t.co/ONnUwL3VIM\" => \" ly: @ \"\"\"\"\" \"\" \"\"sss   nnn   n t    y  \"\n",
      "batch 8592  loss=176.0452  steps/s=116.32  prediction: \"y: @yacineMTB ty @elonmusk for the dL/dW\" => \"  @tea a s\"\"s\"  ss ss n tn    t t    y  \"\n",
      "batch 8594  loss=144.7160  steps/s=106.43  prediction: \"thing I need to pay attention to, thanks\" => \"hi  i ei      e           tttttt ttttttt\"\n",
      "batch 8595  loss=166.5412  steps/s=95.25  prediction: \"d 1995 type sites are such a great style\" => \" m sso   99999 9    teee tt    a   a    \"\n",
      "batch 8596  loss=169.6489  steps/s=59.67  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tsas  t  t     t e e eee eee   a   a   s\"\n",
      "batch 8597  loss=169.1611  steps/s=106.83  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"tt.l  \n",
      "t////t/////ttQtt/ZZ     n  .x   x\"\n",
      "batch 8598  loss=176.1886  steps/s=102.62  prediction: \"erous people, very sad, but also fixable\" => \"  nn ie n i  seeeeeeee e                \"\n",
      "batch 8599  loss=160.5218  steps/s=89.58  prediction: \"ownbad Sweet! Glad it worked, which one?\" => \"n  e snn oee eeeeeee                    \"\n",
      "batch 8602  loss=143.6950  steps/s=103.77  prediction: \"ely the case for chess and debugging imo\" => \" snn   eeeeee  e                        \"\n",
      "batch 8603  loss=165.1020  steps/s=97.26  prediction: \"pin it locked up https://t.co/ULHT2ys50k\" => \"lnt  teee                       //t/////\"\n",
      "batch 8604  loss=159.3888  steps/s=103.13  prediction: \" this guy did it\n",
      "https://t.co/Mx8AIWdLRf\" => \"@h  kk         i   i  ittitt  ttttt////t\"\n",
      "batch 8605  loss=148.9272  steps/s=102.77  prediction: \"potential. then one day, it all explodes\" => \"lst pftttttttttttttt nt               l \"\n",
      "batch 8606  loss=151.8057  steps/s=103.53  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"e           eeeleeeeeee    e            \"\n",
      "batch 8607  loss=147.0785  steps/s=103.70  prediction: \" from scratch, and a bit of transformers\" => \"@onp a p      rcrcc a a                 \"\n",
      "batch 8608  loss=160.5911  steps/s=101.48  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \" ul m a    oo  o  ???h??hhhttthhttttt//V\"\n",
      "batch 8609  loss=145.0939  steps/s=103.63  prediction: \"randomly via ssh https://t.co/3MxqH9R1Ya\" => \"ens tl  sc?-AMx,DIv-Z.-J(ML?@vI:qH9R1YT3\"\n",
      "batch 8610  loss=145.9089  steps/s=100.95  prediction: \"nt know if you were wrong abt everything\" => \"delteetun  o   o      wwwww w           \"\n",
      "batch 8611  loss=153.3935  steps/s=104.67  prediction: \"es in claude does the page size decrease\" => \"    c   o  c  c   e   eeee e  e eee  ee \"\n",
      "batch 8612  loss=148.3451  steps/s=96.34  prediction: \"eadphones dead gonna recharge real quick\" => \" r  e  eeeeeeedeedde   e   ae   eererrre\"\n",
      "batch 8613  loss=141.1397  steps/s=105.74  prediction: \"ink not tho, I believe in synthetic data\" => \"ng o   t t t    t                      i\"\n",
      "batch 8616  loss=142.8077  steps/s=105.35  prediction: \"whereas, its easy to tell which is timeâ€¦\" => \"oit  t\n",
      "eete etse sesssstt e  e  t    t  \"\n",
      "batch 8617  loss=133.1975  steps/s=103.53  prediction: \"ts effortless to read/follow works in it\" => \"h  he e eeeeeteteeeee eeeeeoo oooloooooo\"\n",
      "batch 8618  loss=166.3244  steps/s=105.58  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"toch\n",
      "ttto///ttttttttSSttS/S:tttt:/t/tt//\"\n",
      "batch 8621  loss=188.0031  steps/s=100.91  prediction: \"s: added eraser) https://t.co/TAudQKjLMg\" => \" //or  r  ed er drderrereresse/et/t//d//\"\n",
      "batch 8622  loss=155.8472  steps/s=99.44  prediction: \"ee time lately\n",
      "\n",
      "it has a long ways to go\" => \" d    eeeee ee  eet eet at      a   a   \"\n",
      "batch 8623  loss=159.6680  steps/s=103.34  prediction: \" lets you debug your own problems easily\" => \"tisr t t tt  t t  u  uuu   u     o    oe\"\n",
      "batch 8624  loss=153.5848  steps/s=105.90  prediction: \" up to do multiple iterations of editing\" => \"ts   t                 t  ttti tttiiiii \"\n",
      "batch 8625  loss=148.4442  steps/s=103.86  prediction: \"soned wine games https://t.co/9edvpSK4pr\" => \" me t  e  o e  eoe   s e  ee    eeeee/pp\"\n",
      "batch 8626  loss=159.1246  steps/s=70.79  prediction: \"ludwigABAP its all slop tier, always was\" => \"ya s d www  A  s e   s sssptt/ee//ppappp\"\n",
      "batch 8627  loss=147.8655  steps/s=106.95  prediction: \"a youtube video about it and it exploded\" => \"ng t h         u       u                \"\n",
      "batch 8628  loss=168.6058  steps/s=103.43  prediction: \"of visualization goes away with practice\" => \"n         ii   ii  ioo  aaaaaao   aaa aa\"\n",
      "batch 8629  loss=149.5085  steps/s=104.45  prediction: \"put work in, etc https://t.co/8ZjkHbRuMG\" => \"ltol  i                 tttt ttttt//////\"\n",
      "batch 8630  loss=145.5758  steps/s=100.13  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"tt t  tt trppppesrssspssssstsssst//t////\"\n",
      "batch 8631  loss=201.0338  steps/s=102.68  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"ETEC ITIIIIININNNMMM AAAA     / ////////\"\n",
      "batch 8632  loss=151.7736  steps/s=104.51  prediction: \" wanted to include infinite programs too\" => \"tei  n n       n      nnnnniiiiniin iiii\"\n",
      "batch 8633  loss=156.8384  steps/s=97.50  prediction: \"utput brothers karamazov, word for word\"\" => \"s igAAA   ttttt ttt   ttta arrrorrrroooo\"\n",
      "batch 8634  loss=147.3980  steps/s=100.10  prediction: \" gotchu fam\n",
      "sending the link as we speak\" => \"@eu               aaaaa    n            \"\n",
      "batch 8635  loss=133.3316  steps/s=104.32  prediction: \"future features\n",
      "\n",
      "thanks for the idea bro\" => \" nli l tttttttteettteeeteetttttttt      \"\n",
      "batch 8637  loss=148.8961  steps/s=102.61  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"@ s hee             sssss sssstttttttt//\"\n",
      "batch 8639  loss=151.3100  steps/s=104.16  prediction: \"ts one of the fundamentals of everything\" => \"  tt n         t     e t ee   e  eeee e \"\n",
      "batch 8640  loss=145.2127  steps/s=102.63  prediction: \" end of chess, just like everyone feared\" => \"@as a             s ssss s   eeeeeeeeeee\"\n",
      "batch 8641  loss=144.9063  steps/s=99.85  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"@ts.   .e..eee net    n                 \"\n",
      "batch 8642  loss=159.5177  steps/s=104.14  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"/..t  tt////t////tttttt///tt//tt////t///\"\n",
      "batch 8643  loss=153.7970  steps/s=104.71  prediction: \"ible w lots of work??? Sign me tf up NOW\" => \"tl    s  s s s        o ?????????       \"\n",
      "batch 8644  loss=148.4128  steps/s=104.24  prediction: \"r 100x more productive, get good with it\" => \"eute  encnM-ANB,@8I(OvvL,,ANyB)f1z-b68I0\"\n",
      "batch 8645  loss=145.0414  steps/s=105.43  prediction: \"e a data pipeline that scrapes data. Orâ€¦\" => \" i o     a    a a    a   a  a e aeaaaaa \"\n",
      "batch 8646  loss=147.8538  steps/s=102.90  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"tetn neee eee e ee eeettettttttttttt////\"\n",
      "batch 8647  loss=171.7999  steps/s=98.77  prediction: \"end to work, and they pretend to pay us\"\" => \"   nre te  et  e  e  tt     t tte e  et \"\n",
      "batch 8649  loss=158.1435  steps/s=96.77  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"ya @etn tet r rr tth hhett  tttt/// /ot \"\n",
      "batch 8650  loss=153.7308  steps/s=103.19  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"tenaae l  ppaaapaaappaattttttt ttttt////\"\n",
      "batch 8651  loss=146.0145  steps/s=103.02  prediction: \"cay principles, and it ended up formingâ€¦\" => \"kleeo    d     n           ddd d dd     \"\n",
      "batch 8652  loss=144.6083  steps/s=104.24  prediction: \" try to figure out why your brain worksâ€¦\" => \"th t     t   t t t  u      u   y   r rr \"\n",
      "batch 8653  loss=159.5912  steps/s=106.62  prediction: \"you like hearing about progress updates!\" => \" u  unil ll  ii l ii       oo   or  r   \"\n",
      "batch 8654  loss=179.4047  steps/s=104.84  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"/..uu lt////t//t/OOtOtOOt//tt/tt/t//t///\"\n",
      "batch 8655  loss=162.0467  steps/s=91.52  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" p://stttttt11e 1ttttttttt/////////xxxxx\"\n",
      "batch 8656  loss=137.7313  steps/s=105.59  prediction: \"er. you thaw the skill out when its time\" => \" s te eeeeee   t   e                  t \"\n",
      "batch 8657  loss=144.8309  steps/s=104.44  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tate ee   e            o      o   o    i\"\n",
      "batch 8658  loss=128.9661  steps/s=74.34  prediction: \"you build cool stuff i follow\n",
      "\n",
      "simple as\" => \" u  be       o oo  o   fff   oo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iii\"\n",
      "batch 8659  loss=157.4580  steps/s=106.90  prediction: \"reading the code, most are from zig init\" => \"epl : @scxRIDDwvF64_N2!PgMwBN?cvSz,ADFIw\"\n",
      "batch 8661  loss=140.9374  steps/s=100.87  prediction: \" im pretty screwed when we play sap then\" => \"ts eree e  t     eeeee e eeeewwwe e     \"\n",
      "batch 8662  loss=141.5044  steps/s=103.75  prediction: \"es your data instead of storing the data\" => \"  ainn ett t ta  aaa aaa t       t   t  \"\n",
      "batch 8663  loss=150.1097  steps/s=105.28  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   t   hh  h     h     i oioiio ooooo oo\"\n",
      "batch 8665  loss=150.8576  steps/s=105.14  prediction: \"er? What does that corner look like? Etc\" => \"   tinW                        o o oooo \"\n",
      "batch 8667  loss=157.7299  steps/s=104.79  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omaeci ccco ce  e re ee   tt  te p ttttp\"\n",
      "batch 8668  loss=161.4034  steps/s=100.97  prediction: \"new following you was the right decision\" => \"  ae r h r   ew  www oowww              \"\n",
      "batch 8669  loss=145.5313  steps/s=102.61  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"tean  eee eee e ee eeettettttttt/ttt//o/\"\n",
      "batch 8670  loss=183.4082  steps/s=96.97  prediction: \"ez5341 Will do brother. Much appreciated\" => \" Nne  ee e l     llltttttrtttt.. .Dcccpp\"\n",
      "batch 8671  loss=213.1184  steps/s=100.77  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"   areairrik     t  ININIIIIININOIOOOOO \"\n",
      "batch 8672  loss=179.2150  steps/s=102.35  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \"a@p5    in   ooooooolloootltotttto/////q\"\n",
      "batch 8674  loss=151.1383  steps/s=104.61  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \" r .0s  t t     t t ttttttttttttttttt///\"\n",
      "batch 8675  loss=143.1102  steps/s=103.85  prediction: \"elated to status games or zero sum games\" => \" e si s eee   t tttttttt t              \"\n",
      "batch 8676  loss=163.2045  steps/s=106.28  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"neis  e s s  ooonooonnototootttttotttt//\"\n",
      "batch 8677  loss=151.5260  steps/s=98.12  prediction: \"the man stretches his mind and his limbs\" => \" is  l nn n     t tttt hh sss s shh   i \"\n",
      "batch 8678  loss=138.4624  steps/s=103.94  prediction: \"f, and also not lying about small things\" => \"   h g   o    ol  l     o           l   \"\n",
      "batch 8679  loss=151.6955  steps/s=103.43  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" r   tntttttttaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttttttt////\"\n",
      "batch 8680  loss=164.6571  steps/s=71.40  prediction: \"ludwigABAP ty bro\n",
      "i need to post more fr\" => \"yde@tuea\n",
      " t a \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttttt////tt/o\"\n",
      "batch 8681  loss=139.3301  steps/s=107.50  prediction: \" a lot will impact the rest of your life\" => \"t ftit         l                        \"\n",
      "batch 8682  loss=164.0919  steps/s=102.77  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"  g a g gg gggg ggg ggg gttt    tttt////\"\n",
      "batch 8683  loss=145.2630  steps/s=104.08  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  n    t  t t  t  t tt    llle l  ll ll\"\n",
      "batch 8684  loss=145.4917  steps/s=103.74  prediction: \"y do what sounds more interesting to you\" => \" to o b  o    o      o    o          tt \"\n",
      "batch 8685  loss=155.9379  steps/s=98.74  prediction: \"@arthur_d3nt cool shit\n",
      "cuda interop too?\" => \"snlsorlh rrrrrrrrr rro    o titt tottto \"\n",
      "batch 8686  loss=177.6599  steps/s=92.92  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1r a@rr rr   t      tt t tttttt//////ot\"\n",
      "batch 8687  loss=138.4513  steps/s=99.30  prediction: \"tart over again with a new hard problem?\" => \" l  ot      t  t             a a     r  \"\n",
      "batch 8688  loss=151.1198  steps/s=79.02  prediction: \"minus9 This is my new favorite edm track\" => \"enla to         ii        w  aa      e e\"\n",
      "batch 8689  loss=145.6656  steps/s=97.62  prediction: \"ochenko curious, can you elaborate more?\" => \"riat s o         i        a   e e e aerr\"\n",
      "batch 8690  loss=154.5465  steps/s=103.55  prediction: \"employees) do half the work in a company\" => \"    g oo    e  s  o  e    e             \"\n",
      "batch 8691  loss=149.9427  steps/s=106.32  prediction: \"oesnt matter if its not live.. but still\" => \" s tp e   s    t tt   t tt i   i   i  t \"\n",
      "batch 8692  loss=148.0722  steps/s=87.52  prediction: \"qc Based, a true warrior of the zig army\" => \"u ckfee   e    t t t t    rrr      t t  \"\n",
      "batch 8693  loss=161.5946  steps/s=104.43  prediction: \"igh, make schizo\n",
      "// TODO remove appendix\" => \"n ta    i   h  i  i    / /  OOOOOOO   oe\"\n",
      "batch 8694  loss=150.8535  steps/s=103.52  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"enu  a          ooooooooooooooooo       \"\n",
      "batch 8695  loss=139.6015  steps/s=104.02  prediction: \"ether they are good or bad on their face\" => \" t  u   eeeeeeeeeeee                    \"\n",
      "batch 8696  loss=146.1637  steps/s=103.52  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e  ttoee heht hthh t tt tt       d   edd\"\n",
      "batch 8697  loss=162.3303  steps/s=65.89  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"bunwhee   htt  te  t et      d d d \n",
      " nne\"\n",
      "batch 8698  loss=166.2977  steps/s=106.39  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" dett gttto tttettt  hh  hh             \"\n",
      "batch 8699  loss=145.0322  steps/s=105.35  prediction: \"ty) so they can be free to chase rewards\" => \"h nl   o    t tr    e e e  e e    eeee e\"\n",
      "batch 8700  loss=160.7896  steps/s=105.25  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \" iarr\n",
      "\n",
      "a\n",
      "\n",
      "a\n",
      "\n",
      "oa aalallllllllllct/ct/tt//\"\n",
      "batch 8701  loss=147.6457  steps/s=105.44  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei      i iiiiiiii ii     i         uu \"\n",
      "batch 8702  loss=168.6435  steps/s=104.62  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \" ao  r  m m         tttttttttttttttt////\"\n",
      "batch 8703  loss=163.9466  steps/s=102.22  prediction: \" a https://t.co/OmDwKUEq4p for gpt5, rip\" => \"t     s    sttssst//tt///tttt/  pppp ppp\"\n",
      "batch 8704  loss=151.3354  steps/s=104.42  prediction: \"you find God, the truth, and help people\" => \" u  oe eeeee   ee        t      h  hh   \"\n",
      "batch 8705  loss=147.9956  steps/s=72.77  prediction: \"paeoh Can't wait to see what ppl do w it\" => \"lct  ooe  od   e   t t  t     t h  pd   \"\n",
      "batch 8706  loss=152.3067  steps/s=106.88  prediction: \"ally fun/challenging/interesting for ppl\" => \"rl t     a   aallllllllnnnnnnnnnnnnnnnnn\"\n",
      "batch 8707  loss=135.8349  steps/s=105.10  prediction: \"hat \"group photo\" means several entities\" => \"etg  r tt     tt t   \"  o  o o   eeeseee\"\n",
      "batch 8708  loss=144.2563  steps/s=105.21  prediction: \"you can control the models, and its free\" => \" urlo cc   c c coo   o   o              \"\n",
      "batch 8709  loss=146.0053  steps/s=104.40  prediction: \"it can atrophy if you dont keep doing it\" => \"t  i thh   h  at                        \"\n",
      "batch 8710  loss=152.6100  steps/s=96.45  prediction: \"Building scratch from scratch in scratch\" => \"At iuie i u   i   i    c  ccc cr c    cc\"\n",
      "batch 8711  loss=208.5295  steps/s=102.07  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"l I U AUU       SSSS  FFF          /////\"\n",
      "batch 8712  loss=152.4073  steps/s=104.30  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t l e e               o  t t:t:/ttttt///\"\n",
      "batch 8713  loss=146.3028  steps/s=98.80  prediction: \"see more details as you unblur an image.\" => \"t el  t    e eeeeeee  s    sssuuu uuuuuu\"\n",
      "batch 8714  loss=194.6878  steps/s=92.78  prediction: \"nly read a bit so far but its super good\" => \" a / C  7oV\n",
      "\n",
      " \n",
      "\n",
      "a\n",
      " a   a  b             \"\n",
      "batch 8715  loss=153.5421  steps/s=101.06  prediction: \"resting, what kinds of tools has he made\" => \"epla: @ pfk{ðŸ˜†bvc[á´‡Ê€**DT*{Ê€#{#,%#ðŸŽ‰T~ÉªkÊ€,ð—¯\"\n",
      "batch 8716  loss=141.3891  steps/s=104.43  prediction: \"s are your own, and i need to prove that\" => \" tet t    e    r                        \"\n",
      "batch 8717  loss=144.0818  steps/s=103.61  prediction: \"g real and distracted from the adventure\" => \" ttdt                 ddddddd         ee\"\n",
      "batch 8718  loss=148.2590  steps/s=103.72  prediction: \"more friction than they need to function\" => \"eneie ah       ot t tt t nt n     ee e t\"\n",
      "batch 8719  loss=156.8848  steps/s=98.80  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  + eooe eeeedeeedeeett ttttttttt       \"\n",
      "batch 8720  loss=156.7860  steps/s=104.64  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \": asaanaaaasaas sss                     \"\n",
      "batch 8721  loss=178.4038  steps/s=38.97  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y  @ a ssasss sss y                     \"\n",
      "batch 8723  loss=156.2442  steps/s=133.17  prediction: \"oull just be on his midbie goats list dw\" => \" leo as     l  t           ii     o ei  \"\n",
      "batch 8724  loss=145.5166  steps/s=103.11  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" rt t                nnnnttttttt////////\"\n",
      "batch 8725  loss=181.4238  steps/s=100.60  prediction: \" its crack bro. be careful. i warned you\" => \"tn e i   e   i n  bbb bbt.. /..c......  \"\n",
      "batch 8726  loss=148.4310  steps/s=103.50  prediction: \"ing responses seems like a better metric\" => \"ngs oeeeieeeensnnesssessseseeeeee  eeeee\"\n",
      "batch 8727  loss=153.2121  steps/s=105.19  prediction: \"ou get faster and faster at solving them\" => \"nge          t      t   a    a a  a     \"\n",
      "batch 8728  loss=140.6053  steps/s=103.07  prediction: \"ich is a great way to find opportunities\" => \"ne    iiiii i                          i\"\n",
      "batch 8729  loss=182.5560  steps/s=102.86  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"nJe e s//////BBBBBBBBooo  oooooooo      \"\n",
      "batch 8730  loss=149.4746  steps/s=103.83  prediction: \"al, one of the most cracked players ever\" => \"ni  o  e  o   o o o    o       e     eee\"\n",
      "batch 8731  loss=166.7545  steps/s=96.79  prediction: \"owser gif editor\n",
      "https://t.co/CWUD0xLmZ4\" => \"ne f  r e  r  e    rr rrtttrtttt//t//tt/\"\n",
      "batch 8732  loss=152.8630  steps/s=103.92  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "eupr et I.ÉªIðŸ˜ðŸ˜†]â˜ IIâ˜ *,[á´„Ê€ð—°,,å€‘%*á´€%~*%Êœ%]~\"\n",
      "batch 8733  loss=140.6976  steps/s=105.23  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"esg            t                        \"\n",
      "batch 8734  loss=165.1920  steps/s=105.06  prediction: \"ed in joining, repeat these instructions\" => \"  e eeeeeeieieeeinnieienee    enee ettet\"\n",
      "batch 8735  loss=137.8562  steps/s=102.41  prediction: \"ch though if i cant fix a particular bug\" => \"h    i  hhhhhhhh                       a\"\n",
      "batch 8736  loss=140.8984  steps/s=105.62  prediction: \"robably dont ask 'will you be my mentor'\" => \"egdlt  aan))(W/)'1'1W/'cY?(W,v((bJq4JjQJ\"\n",
      "batch 8737  loss=163.2137  steps/s=89.33  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \"  l  le d  oll klk   sss a aa  b  e e   \"\n",
      "batch 8738  loss=215.9000  steps/s=102.32  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOUOOOOOOOOOOOOOOOOOOOOOOtttttttttt/J\"\n",
      "batch 8739  loss=208.2020  steps/s=97.31  prediction: \" bet, im down, whats a good time for you\" => \"te S OOK__       , t, w ttaa   oo    ooo\"\n",
      "batch 8740  loss=168.3499  steps/s=103.27  prediction: \"/t.co/T03I8pk4ER\n",
      "https://t.co/XSr1ijr0iv\" => \"t.cis:t:t/////////ptttptptttt///////////\"\n",
      "batch 8741  loss=145.3358  steps/s=98.66  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" to uu     mmmmmmmmmmemmmmmeeeeeeeee ooo\"\n",
      "batch 8742  loss=155.9260  steps/s=104.86  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"h i t s m    s          o  o   ee eeeeee\"\n",
      "batch 8743  loss=151.9935  steps/s=104.84  prediction: \"snt, now i think and focus waaaay better\" => \" te et       i            n     aaa aaa \"\n",
      "batch 8744  loss=135.6477  steps/s=101.60  prediction: \" put you so far ahead its not even funny\" => \"tu l ol   o    u                        \"\n",
      "batch 8745  loss=137.3206  steps/s=99.09  prediction: \"ndustries\n",
      "Currently building semi public\" => \"   o ddniiniiiinirrrrrreurrriiiiieii iii\"\n",
      "batch 8746  loss=149.1916  steps/s=104.25  prediction: \"rappers around statistical distributions\" => \"entem  i jL5\"MI'OOFkjCPOFVIxI00O\"jTI\"kqq\"\n",
      "batch 8747  loss=141.0890  steps/s=92.12  prediction: \"unday is a great sunday to write haskell\" => \"sdds s  s    a     aaaa  aa  a t   t t  \"\n",
      "batch 8748  loss=145.9477  steps/s=99.23  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"   :ididiiddddddddttt tdttttcttcttccccct\"\n",
      "batch 8749  loss=140.7173  steps/s=103.43  prediction: \" android OS inside of a virtual machine?\" => \"tnd annn      nn dd        i i       a  \"\n",
      "batch 8750  loss=149.2489  steps/s=87.30  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \" Mhu aa dS    idii      aaaaaa a a  etee\"\n",
      "batch 8751  loss=149.1086  steps/s=104.67  prediction: \"up computing 'why' for free all the time\" => \"s                        '              \"\n",
      "batch 8752  loss=151.4729  steps/s=100.41  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" a             h  h                     \"\n",
      "batch 8753  loss=155.1232  steps/s=101.67  prediction: \"es gets rounded up to 0.1s\n",
      "\n",
      "why? idk man\" => \"   e   eee eeees ee e  d              d \"\n",
      "batch 8755  loss=173.5402  steps/s=96.10  prediction: \"ez5341 based, i respect the grind brotha\" => \" a ease rr e d d           t          dn\"\n",
      "batch 8756  loss=145.6785  steps/s=103.19  prediction: \" if you come across any useful stuff tho\" => \"tt  o     o  o   oo   o      s    s ssff\"\n",
      "batch 8757  loss=171.1936  steps/s=103.50  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t..liitt//// /999999 t9ttppt/ttt////t/t/\"\n",
      "batch 8758  loss=162.1064  steps/s=104.47  prediction: \"ou can dive unbelievably deep into these\" => \"n ttine tY   e  n    be bbbbbbeeeeeeeee \"\n",
      "batch 8760  loss=143.4286  steps/s=104.26  prediction: \"rally where the word came from, i think)\" => \"etiii  ouc,JS@I@kq.k\n",
      "f.MM/xxMMMJMMMMMM)(\"\n",
      "batch 8761  loss=143.0056  steps/s=103.38  prediction: \"d stuff just happens. stochastic winning\" => \" pot'                   sssssssssssssssn\"\n",
      "batch 8763  loss=162.3633  steps/s=54.12  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @jecuio       t  uf ssssssssssstttssnnn\"\n",
      "batch 8764  loss=142.3900  steps/s=110.35  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"   t    ttttrtttrttattaaaaaaahhhahhhhhhh\"\n",
      "batch 8765  loss=141.3176  steps/s=100.64  prediction: \" adventure over the comfort of certainty\" => \"tnteteeeeeeeee teeee eee  e    o   oo   \"\n",
      "batch 8766  loss=158.2198  steps/s=97.54  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \" e  eeunee o o too oo  e             t t\"\n",
      "batch 8767  loss=138.5657  steps/s=101.02  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"th ennnn nnnn ene eee eeettttttt/////tt/\"\n",
      "batch 8768  loss=140.8940  steps/s=105.87  prediction: \"now how to do it https://t.co/y5LFqaVw5b\" => \" then  w       o        tttttttttt//////\"\n",
      "batch 8769  loss=144.8050  steps/s=101.81  prediction: \"e readme was a good read on ai reasoning\" => \" ao:      e      e   e e    a    a  a  a\"\n",
      "batch 8770  loss=161.7290  steps/s=104.26  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n  h     EEEEEE xEee    ttttt::tt/: ///t\"\n",
      "batch 8771  loss=153.1028  steps/s=104.29  prediction: \"y put it back, just gotta wait a few yrs\" => \":trslsll l               ttt  ttttt t t \"\n",
      "batch 8772  loss=150.6324  steps/s=96.85  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \":to em         dddddddd dddddttttt//////\"\n",
      "batch 8773  loss=139.9023  steps/s=95.65  prediction: \"nds like a super cool premise for a game\" => \" ome  h o                   o ooooo o   \"\n",
      "batch 8774  loss=175.9285  steps/s=100.49  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \" Be @H  H  sssss s ssssssssss ss      o \"\n",
      "batch 8775  loss=165.8783  steps/s=101.53  prediction: \"/t.co/hjQfCWaZxw\n",
      "https://t.co/VFbc29W7Ct\" => \"t.cceett////ttt///ttttttt//t//tt////ttt/\"\n",
      "batch 8776  loss=160.5218  steps/s=96.29  prediction: \"enko Could probably do this w ai now lol\" => \"  ooohooooCCCooCCotpppppttttttttcottwwww\"\n",
      "batch 8777  loss=144.3947  steps/s=104.94  prediction: \"se so i have no idea if this would work)\" => \"  veee   e    en   e    e    i  i       \"\n",
      "batch 8778  loss=141.0684  steps/s=104.98  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \"ht ot t     t  nooooooooooo  oo         \"\n",
      "batch 8779  loss=159.7163  steps/s=105.33  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"es\n",
      "n))nnn     nnx     nn n      n    __ \"\n",
      "batch 8780  loss=145.1631  steps/s=104.77  prediction: \"t theres probably better stuff out there\" => \"hone e e     e ebbb bbbbbbbeettttttt  tt\"\n",
      "batch 8781  loss=150.5722  steps/s=103.71  prediction: \". seems like a fancy type of hard coding\" => \" whe  .ee eeee eeeee  e e               \"\n",
      "batch 8782  loss=137.6056  steps/s=103.71  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \"  e      'eeeeen    e     e     e  e   e\"\n",
      "batch 8783  loss=153.5484  steps/s=101.79  prediction: \"d you man. Yea whenever you can do join!\" => \" ts_ i                 eeeeeeeeee       \"\n",
      "batch 8784  loss=147.7962  steps/s=104.63  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" eeeu e r t r  r rr  roo oroo o oo  o oo\"\n",
      "batch 8785  loss=154.7171  steps/s=102.87  prediction: \"lf of that was way off. all good tho nbd\" => \"y     lm                                \"\n",
      "batch 8786  loss=149.7060  steps/s=104.69  prediction: \"h4 then 2. h5 every game against him lol\" => \"e                                       \"\n",
      "batch 8787  loss=158.7777  steps/s=66.10  prediction: \"aulg We like memoizing physical patterns\" => \"nn             eeee ee       aaaaaaaa  t\"\n",
      "batch 8788  loss=157.6029  steps/s=107.32  prediction: \"te correctly lol\n",
      "https://t.co/0eYn1IVGOH\" => \" re pte      e  oottttttt/tt///////////t\"\n",
      "batch 8789  loss=222.8183  steps/s=21.43  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: s p  e  o coottttttt/t//////////ttt\"\n",
      "batch 8790  loss=147.1680  steps/s=127.83  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ng eB ddd               t tttttt////////\"\n",
      "batch 8791  loss=150.9417  steps/s=99.72  prediction: \"uote tweets work https://t.co/CCGxweEQQ8\" => \"nu   oo     www  ttttttttttt////////////\"\n",
      "batch 8792  loss=179.9904  steps/s=100.90  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"@ongsgnn  nn s   s    t  t  tt tttt/////\"\n",
      "batch 8793  loss=161.1210  steps/s=95.24  prediction: \"by_builds another $20 trillion to ludwig\" => \"e  gsibbb s  sdn ttt ht  t $tt/t/toootto\"\n",
      "batch 8794  loss=159.6040  steps/s=103.65  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \" nne  enien nnenennneene\n",
      "eeeeneno tt ttt\"\n",
      "batch 8795  loss=204.9949  steps/s=95.92  prediction: \"ch WHOA WHOA YOU WOULDNT DOWNLOAD A LEGO\" => \"eise  eneeeHHHHOWWWOAOWOUOOUOOONNODDLDOO\"\n",
      "batch 8796  loss=172.4239  steps/s=45.16  prediction: \"y: @sunsettler write a will just in case\" => \": @annneHHAHHOOOWOOOUWUUDDDNWNNLDDOAL OO\"\n",
      "batch 8797  loss=152.6905  steps/s=108.91  prediction: \"e algo show you a lot more similar posts\" => \" a   oa    o    oo  o     o    o    o   \"\n",
      "batch 8798  loss=172.4962  steps/s=63.34  prediction: \"@scheminglunatic https://t.co/9wvijoocgK\" => \"yubbeoehh  h          oo      ooo   ooss\"\n",
      "batch 8799  loss=144.9626  steps/s=109.00  prediction: \"pen theatre stairs door and ruin the run\" => \"lry   t ee tttttte t    to     rr      r\"\n",
      "batch 8800  loss=154.8634  steps/s=97.89  prediction: \"e go all the blindfold web dev positions\" => \" a        e    te  l   llllldddd  d  d  \"\n",
      "batch 8801  loss=148.2792  steps/s=102.01  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"@ en n     ee\"\"\"e\"\"\"\"\"\"\" e   e   e    e \"\n",
      "batch 8802  loss=161.1936  steps/s=103.01  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"the o  o             t  tttttttttttttt//\"\n",
      "batch 8803  loss=149.9171  steps/s=97.36  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"eply: @pixqzzá´‡ð˜&â€¦jJðŸ°â€¦.]'cá´›*zðŸ¤¯â˜ b`!ðŸ˜­*|kvvM\"\n",
      "batch 8804  loss=173.6312  steps/s=97.05  prediction: \"yacine needs a dingboard wrap on his car\" => \":c xe ee000e neennenn ne     d n     a  \"\n",
      "batch 8805  loss=146.1098  steps/s=81.26  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \" ld  y ee xe   eo   oddo d annnnoo  o\n",
      "  \"\n",
      "batch 8806  loss=161.2721  steps/s=112.50  prediction: \"n confirm this is a very goated strategy\" => \"gih  taae oaa  i         i  i         r \"\n",
      "batch 8807  loss=270.7839  steps/s=11.26  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @ oCq.CM_0fjxfb.Cb)xjzAf(vjwvjk\"x,\"\n",
      "batch 8809  loss=155.1072  steps/s=112.28  prediction: \"ore descriptive titles for the rest lool\" => \"rk n    eee   ineeiiiiiieee eettee e  tt\"\n",
      "batch 8810  loss=146.1782  steps/s=104.10  prediction: \" ad optimization, marketing agencies etc\" => \"@ te l o      iiooiiiiiiiiiiaiiaiaiaieie\"\n",
      "batch 8811  loss=161.8577  steps/s=104.04  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"&(  2s  0,]]],]1    0     s           e \"\n",
      "batch 8812  loss=151.3132  steps/s=104.32  prediction: \"r the years for business/building things\" => \"e(  i onuwwj66!b(!j)!w!((33v3303/3)(pwRj\"\n",
      "batch 8813  loss=158.8285  steps/s=102.76  prediction: \"but its ok bc I know theyre high density\" => \"et d t         t                  h h h \"\n",
      "batch 8814  loss=143.4323  steps/s=104.70  prediction: \" fly everywhere\n",
      "\n",
      "idk how lidar works btw\" => \"tuthh     t    eeeeeeeeee e      ww   ww\"\n",
      "batch 8815  loss=152.7939  steps/s=104.38  prediction: \"fected, i hope none of my followers were\" => \"  h reeede e  e e ee   o  e of  oof  ooe\"\n",
      "batch 8816  loss=138.2939  steps/s=99.55  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"   :eaeiiiii e  d ddd dd  oooooo  oo    \"\n",
      "batch 8817  loss=143.3023  steps/s=104.82  prediction: \" usually get out of distribution results\" => \"tstoosiusuuuuu o       t   t   tttt tt t\"\n",
      "batch 8818  loss=166.9347  steps/s=103.92  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"p.aet tt////tt/ottttttttt::tt/tt////t///\"\n",
      "batch 8819  loss=163.9634  steps/s=96.96  prediction: \"ily @ineedtolocking @kuberdenis detected\" => \"ni ot liloitioootooototoooccokkdddddeedd\"\n",
      "batch 8820  loss=151.8507  steps/s=101.76  prediction: \"d it! Lmk how it goes man. Hope it helps\" => \" inu io                                 \"\n",
      "batch 8821  loss=194.1565  steps/s=102.16  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"tLol          LLLLLLDDDDDEEEEETTTTTT    \"\n",
      "batch 8822  loss=146.3004  steps/s=104.49  prediction: \" ad optimization, marketing agencies etc\" => \"t te l o      iiooiiiiiiiiiiaiaaiaiaieie\"\n",
      "batch 8823  loss=143.3621  steps/s=105.54  prediction: \"anifold, like on the surface of a sphere\" => \"nt onooooo    o    o  o                e\"\n",
      "batch 8824  loss=170.5267  steps/s=101.45  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"se    r rr   rrerttttttutttttttttt//t//t\"\n",
      "batch 8825  loss=149.5534  steps/s=102.14  prediction: \" pieces until you have solved the puzzle\" => \"tou  o         n                v       \"\n",
      "batch 8826  loss=147.2026  steps/s=106.35  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"enly:e  gg^Y?,?DE.R?@?:????I?ML:7TDC7TDU\"\n",
      "batch 8827  loss=143.3471  steps/s=104.34  prediction: \"nts of time. its like skilling up almost\" => \" h    m m  m  m  t     s   i  iiiii  ill\"\n",
      "batch 8828  loss=148.1190  steps/s=105.84  prediction: \"ich is a suuuuper good thing to practice\" => \"n  so  e     s uu uu    uuuu    u     o \"\n",
      "batch 8829  loss=144.3549  steps/s=101.15  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"tais h       eec   eee    e      e  o ee\"\n",
      "batch 8830  loss=169.8353  steps/s=94.45  prediction: \"er CERN/physics bros you know what to do\" => \"   ae ttrr e c c  e csss ss  s o oo oo o\"\n",
      "batch 8831  loss=151.1923  steps/s=100.67  prediction: \" harmony until the clown nation attacked\" => \"tai  i            i      nn nnn nntn tnt\"\n",
      "batch 8832  loss=141.2570  steps/s=103.22  prediction: \"ve implemented 50% of the mobile version\" => \"e  ie i e eememeee   ee ee eee  e   e  e\"\n",
      "batch 8833  loss=151.6866  steps/s=59.59  prediction: \" @startupmillyair lichess or chessdotcom\" => \"ty m  i eememeenee    e  e      eee e eo\"\n",
      "batch 8834  loss=163.2929  steps/s=74.77  prediction: \"y: @gizmobly nooooooooo my plans, foiled\" => \": @ae epmmeemeele     e       e eee soeo\"\n",
      "batch 8835  loss=148.3918  steps/s=107.90  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" foo t ee   s  s   sss ss ss sssssse  s \"\n",
      "batch 8836  loss=147.4505  steps/s=104.60  prediction: \"s) lets you do system prompts, i believe\" => \"  n ra c  ss     ss ss ss  s  o   s     \"\n",
      "batch 8837  loss=146.5853  steps/s=105.23  prediction: \"think you can do cdn type stuff w em btw\" => \" e     i i i   n  n   o     n           \"\n",
      "batch 8838  loss=144.4821  steps/s=104.60  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" rn t lillllllnnnnn n nn  ttt tt////////\"\n",
      "batch 8839  loss=147.3097  steps/s=100.90  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"sldb  ht tttt  t tttttttsttttttt////////\"\n",
      "batch 8840  loss=144.2254  steps/s=104.61  prediction: \"ite complexity? If not, what is the max?\" => \"n ie  iiiiiiiiitiii i                   \"\n",
      "batch 8841  loss=148.9457  steps/s=103.39  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" ritiy           r rrrrrrrrrrrrrr       \"\n",
      "batch 8842  loss=158.4056  steps/s=103.68  prediction: \"sing way more efficient/scalable methods\" => \" nul  t   i           fef eeeieeeceeeeee\"\n",
      "batch 8843  loss=156.8596  steps/s=94.56  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \" kii ul   a    f  i   iiiiciiceeeeee ee \"\n",
      "batch 8844  loss=146.3847  steps/s=104.07  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"ea  i ot fEEEqx,z@PS'kjjA/zjAkA(.-ASEx)A\"\n",
      "batch 8845  loss=146.6228  steps/s=102.99  prediction: \"om the distribution of (single response)\" => \"ne)feff re  r   r  ttitiii iti  ii  i   \"\n",
      "batch 8846  loss=147.6207  steps/s=102.06  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"toa i g    e  ge    e e  g   o          \"\n",
      "batch 8847  loss=166.2146  steps/s=101.42  prediction: \"\n",
      "we'll see how things really play out ig\" => \"\n",
      "or stp  nA_FMT'21P@Y.v(:_FjðŸ’ª':ðŸ’ª.-::E(k)\"\n",
      "batch 8848  loss=144.1082  steps/s=105.10  prediction: \"anding pages or whatever feels gross idk\" => \"td wl o o      n         eee  eeeeeee ee\"\n",
      "batch 8849  loss=139.1198  steps/s=104.95  prediction: \"able for whoever owns the algorithm/site\" => \"tlor  eeee te  e ee e  ee ee e  o oe o o\"\n",
      "batch 8850  loss=165.5005  steps/s=93.04  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \"reet er  hoooo  ooo   tee   sggtoiillllt\"\n",
      "batch 8853  loss=140.6025  steps/s=105.06  prediction: \"otential for small - very small things.â€¦\" => \"       ot o    t                llllll  \"\n",
      "batch 8854  loss=150.0800  steps/s=101.35  prediction: \"ne was right the rates arent high enough\" => \"g o   aaiiaa i t      ee   rt  tth   ehe\"\n",
      "batch 8855  loss=135.8767  steps/s=103.63  prediction: \" play instead of making random moves lol\" => \"to t t              aaa    aaa          \"\n",
      "batch 8856  loss=153.5203  steps/s=104.61  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt  er ef  f   f ff      s   t /tt////t/\"\n",
      "batch 8857  loss=157.0663  steps/s=105.76  prediction: \"ething. @dnbt777 https://t.co/i9PslcwipA\" => \" t l o o oo  o  t777777t ttt..tt/tt////s\"\n",
      "batch 8858  loss=160.9386  steps/s=101.34  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"ete t isoj/88=?0.)@_?[7!y-77@77YwJD3YKJj\"\n",
      "batch 8859  loss=146.8068  steps/s=104.74  prediction: \"s, have back and forth conversations etc\" => \"  ptt h    s    a   a                 o \"\n",
      "batch 8860  loss=179.3627  steps/s=58.18  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"tbo o e e  caca a   a     c   c oaonerot\"\n",
      "batch 8861  loss=141.1605  steps/s=107.91  prediction: \" know its doable\n",
      "https://t.co/DZCdUoVn6w\" => \"ti           o    o ootttottttto/ttttt//\"\n",
      "batch 8862  loss=181.9491  steps/s=95.30  prediction: \"yacineMTB Interesting can you elaborate?\" => \" cin uyy   yy   netteettttnttte n oo aoo\"\n",
      "batch 8863  loss=141.0186  steps/s=101.08  prediction: \" able to do this approach w gpus anyways\" => \"tb e ee e  e                       p a a\"\n",
      "batch 8864  loss=150.1711  steps/s=105.58  prediction: \" here is valuable, the sooner the better\" => \"tae  yee e r  eee  eee ee e   eee ee e e\"\n",
      "batch 8865  loss=148.9169  steps/s=98.76  prediction: \"AP wow\n",
      "\n",
      "i need to pivot from using print\" => \"PAP oee ww A   e   e    o  ooo    oo  rr\"\n",
      "batch 8866  loss=136.1217  steps/s=93.20  prediction: \"er this applies outside of chess as well\" => \" ei:e@s           ii  i  oo   o       ss\"\n",
      "batch 8867  loss=148.0190  steps/s=105.23  prediction: \"y with any industry/niche and ill run it\" => \":ininniy yyy iy yyyyynnyynnnnnn  n n n  \"\n",
      "batch 8869  loss=147.2564  steps/s=103.56  prediction: \" the ladder on what strats are possible.\" => \"thet      t              t   t  a   a   \"\n",
      "batch 8870  loss=176.0164  steps/s=97.67  prediction: \"e77 @0xdiicell turkish coffee is amazing\" => \"  roh   777777   d llt t t rt   sss eeee\"\n",
      "batch 8871  loss=142.9270  steps/s=104.08  prediction: \" the ladder on what strats are possible.\" => \"thet      t              t      a   a   \"\n",
      "batch 8872  loss=147.0297  steps/s=105.62  prediction: \"ng them as irrational, then assigning 0â€¦\" => \"   taoigggg  i   ii iiiiaa  aaaiaaaninin\"\n",
      "batch 8873  loss=148.9314  steps/s=97.08  prediction: \"air they do have the best premove system\" => \"tn rrira  ii a ta  h    e     seee e e s\"\n",
      "batch 8874  loss=145.8890  steps/s=104.51  prediction: \"ntil finally training on unzoomed images\" => \" eo s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  nnnin  lillnin  nnnnnnnnno \"\n",
      "batch 8875  loss=142.7117  steps/s=105.44  prediction: \". but idk thats just my weird take on it\" => \" thhst t ttttttt    tt                  \"\n",
      "batch 8876  loss=146.0119  steps/s=104.10  prediction: \"d to seeing your progress on nand2tetris\" => \" in ooooo     eer  r  rr rrrr sr   nnnnn\"\n",
      "batch 8877  loss=140.9615  steps/s=104.82  prediction: \" of indirection? Is that why that works?\" => \"tf o       iiiiiiiiiii            t tt t\"\n",
      "batch 8878  loss=142.6504  steps/s=103.87  prediction: \"gt; practicing them -&gt; mastering them\" => \"  t   e        e tt  tttttt ttttttt tttt\"\n",
      "batch 8879  loss=154.3206  steps/s=103.17  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"teteee ee eeeeelee   ee                 \"\n",
      "batch 8880  loss=153.2288  steps/s=102.00  prediction: \"tremely good at using ai to build things\" => \"ha  met eeeeeeem  eo                    \"\n",
      "batch 8881  loss=144.9788  steps/s=103.51  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"u e  on oooo  o  oo    t tt   y   t   ss\"\n",
      "batch 8882  loss=168.1238  steps/s=104.65  prediction: \"owser gif editor\n",
      "https://t.co/CWUD0xLmZ4\" => \"u  r  r e  r  e    r  trtttrtt/t/////tt/\"\n",
      "batch 8883  loss=148.6332  steps/s=105.08  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"niza g miiiiiimi     e  t tt ttttt//////\"\n",
      "batch 8884  loss=162.7390  steps/s=98.91  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: iimes  eessm   ssssstt////////////88\"\n",
      "batch 8885  loss=174.1466  steps/s=100.26  prediction: \"ein @DrBrianKeating yea he made a portal\" => \" r eeieii@niiiiiiiniinnnnneaaea aaaaaeaa\"\n",
      "batch 8886  loss=148.8570  steps/s=99.81  prediction: \"plate btw if u wanna make ur own version\" => \"ly: @l eee e t   t  t a   a      a      \"\n",
      "batch 8887  loss=146.5076  steps/s=104.52  prediction: \"nd seem more limited in possible results\" => \"  rea       e  em mem  e e  i iiie iesee\"\n",
      "batch 8888  loss=159.8326  steps/s=98.35  prediction: \"future wife, dayum\n",
      "\n",
      "happy for you brotha\" => \" ch  a     e e   ee   u uuu  pp pyy yyy \"\n",
      "batch 8889  loss=143.4439  steps/s=101.68  prediction: \"utomatically imagine letters as colored?\" => \"s    uoo oo oa aaaa aaa aaaa a     l    \"\n",
      "batch 8890  loss=141.7314  steps/s=104.59  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" ti gee  eeeeneee eeeereeeeetitittttoooo\"\n",
      "batch 8892  loss=155.7464  steps/s=102.83  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \" tineeeeeeeee  e                        \"\n",
      "batch 8893  loss=144.4623  steps/s=104.66  prediction: \"ling down on stuff I initially dismissed\" => \"yn o  m mo oo   on n     nnn   i iiiiii \"\n",
      "batch 8894  loss=140.3014  steps/s=104.05  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "tre  nl vFX,XX5k,SS,EEEEEI000,ðŸ’ª!!!!!!!!\"\n",
      "batch 8895  loss=150.7716  steps/s=103.67  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" ei g i ioooooon  o                    a\"\n",
      "batch 8896  loss=140.4451  steps/s=95.92  prediction: \"irak seems fine to me (i am brainwashed)\" => \"ne t  eees s e s ee    e ((       aaaa a\"\n",
      "batch 8897  loss=141.5091  steps/s=102.08  prediction: \"am not fixing it https://t.co/dsgcKVp5Ha\" => \"ne      n    n   i     ittitti ttttt////\"\n",
      "batch 8898  loss=143.5564  steps/s=104.53  prediction: \"ugh the comments and it was pretty funny\" => \"sh th thhhhhh thtttt etet          tt  t\"\n",
      "batch 8899  loss=145.3492  steps/s=104.16  prediction: \"rger abstractions which eventually haveâ€¦\" => \"eea e ciin5555TS5.55ESPSSSjSSSSS5vSSjSâ€¦S\"\n",
      "batch 8900  loss=177.7230  steps/s=100.93  prediction: \".03$ a day you can help a webdev in need\" => \" .he o   000                    a      e\"\n",
      "batch 8901  loss=162.8529  steps/s=104.83  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \" tdtso;;gg;gg&eg;tgttttttttoo oo  LLLLL \"\n",
      "batch 8902  loss=176.6491  steps/s=105.86  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"toee  eeee eee             ttttttt/////S\"\n",
      "batch 8904  loss=141.6906  steps/s=100.84  prediction: \" wanted to include infinite programs too\" => \"tae  nen       n        niiiiiiniiiiiiii\"\n",
      "batch 8905  loss=151.7534  steps/s=104.48  prediction: \"king progress. Now i see it eeeverywhere\" => \"ena ai a                       eeeeeeeee\"\n",
      "batch 8906  loss=145.7027  steps/s=103.82  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \"eys un              ssss                \"\n",
      "batch 8907  loss=138.7597  steps/s=102.90  prediction: \"ide stuff on top of normal operations ig\" => \"ne  oe                o  ooooooooooooooo\"\n",
      "batch 8908  loss=167.4939  steps/s=101.01  prediction: \"its how i learned most of my tech skills\" => \"n  yo               o        o mm    m  \"\n",
      "batch 8909  loss=149.8376  steps/s=99.86  prediction: \"an esopost to english translator service\" => \"r  e    ee e e ee ee  e   ss tt   st tss\"\n",
      "batch 8910  loss=146.8181  steps/s=105.09  prediction: \" the time and not spread important info?\" => \"toe     l    e t                  t tttt\"\n",
      "batch 8911  loss=145.3205  steps/s=104.56  prediction: \"the most useful? https://t.co/w0tVqarS34\" => \"hes yr  t      e  tte t tttstttttt//t//t\"\n",
      "batch 8912  loss=151.4789  steps/s=103.79  prediction: \"sed to sound like the opposite of curses\" => \" d l l  e                 o      ooo  o \"\n",
      "batch 8913  loss=152.3571  steps/s=102.35  prediction: \"he goated advice https://t.co/gZx1K1OtSg\" => \"e th t         t  a    tttt ttttt///////\"\n",
      "batch 8914  loss=157.4950  steps/s=101.15  prediction: \"blue, someone is working harder than you\" => \"le s eee ee,ee ee e  e  o    e  e       \"\n",
      "batch 8915  loss=146.5806  steps/s=103.81  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" trit  aa   aa a   a aa       t     t  i\"\n",
      "batch 8916  loss=163.7019  steps/s=105.24  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"t..E  ht////t//X/XXXt Ptt/:t//tt////t//t\"\n",
      "batch 8917  loss=163.2941  steps/s=104.04  prediction: \"/t.co/YpddagC5uf https://t.co/GdftPhw7eI\" => \"/..c////tt/tY/t//tt/ttttttt/////tt/tt/tt\"\n",
      "batch 8918  loss=188.9258  steps/s=92.41  prediction: \"ez5341 Will do brother. Much appreciated\" => \" jiostp/ta44554   ttttttttttht..tchchchp\"\n",
      "batch 8919  loss=146.2007  steps/s=101.28  prediction: \"velsio's\n",
      "\n",
      "just gotta keep building, bros\" => \"e  lal sssss ss sss sss       e     e   \"\n",
      "batch 8920  loss=165.7564  steps/s=104.03  prediction: \"ger, LETS GET IT\n",
      "https://t.co/ZIDQZp9Vp6\" => \" t ia  a   a    TTTTTTTTTT    ttII/I/ZZZ\"\n",
      "batch 8921  loss=159.6188  steps/s=102.54  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"tn ee      aa at                     eee\"\n",
      "batch 8922  loss=140.6721  steps/s=96.85  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \"   n   t   e   meeee   nnn n          tt\"\n",
      "batch 8923  loss=144.4496  steps/s=97.26  prediction: \"the man stretches his mind and his limbs\" => \"he    xnl      ne ttt   s         i   i \"\n",
      "batch 8924  loss=140.1142  steps/s=104.01  prediction: \" personally make you a funny monkey meme\" => \"tla    l   llllllll   y    y   n n     m\"\n",
      "batch 8925  loss=145.1808  steps/s=104.64  prediction: \" two next to each other. then a 4x4. etc\" => \"the ee e   t    t  t    t      t    h e \"\n",
      "batch 8926  loss=152.1436  steps/s=105.10  prediction: \"snt, now i think and focus waaaay better\" => \" ee et       i            n     aaa aaa \"\n",
      "batch 8927  loss=149.6790  steps/s=102.65  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"n e snoo  oooo noooo   uo   e e  eeee  e\"\n",
      "batch 8928  loss=221.1328  steps/s=101.03  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"aentta aenING07ALETSHFCKIBIbG0OjCkhI'kqB\"\n",
      "batch 8929  loss=150.9493  steps/s=102.18  prediction: \"nd stop you from seeking rewards in life\" => \"  eurC            o   o        r    r   \"\n",
      "batch 8930  loss=156.2379  steps/s=103.90  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " nntn f nJmWv!GB44SWE4G4Np!K!SWE@GJJJIJ\"\n",
      "batch 8931  loss=179.7368  steps/s=81.14  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"otk e  ee e     o    ah t tt  t tt      \"\n",
      "batch 8932  loss=162.7726  steps/s=70.75  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tlu s s eoe     hotthtt t////////t   00 \"\n",
      "batch 8933  loss=141.6042  steps/s=117.26  prediction: \" ill dm you a link to it around the 25th\" => \"@n eseeeeeee                            \"\n",
      "batch 8934  loss=165.0954  steps/s=95.22  prediction: \"fsimo Lets goo!!!! Incredibly impressive\" => \" e  efeeo             !o       i        \"\n",
      "batch 8935  loss=154.1080  steps/s=104.83  prediction: \"w the game state https://t.co/jm2YeI7PB9\" => \"ii   t         t e   tt  ttttt ttttet//e\"\n",
      "batch 8937  loss=157.5750  steps/s=103.42  prediction: \"rs automatically slap that down to 10fps\" => \"e ertsn bnkN/A)\n",
      "zj'L(jTTERyjv!!)501'T,.1\"\n",
      "batch 8938  loss=157.0327  steps/s=103.17  prediction: \"ut you neeeeeed execution skill yourself\" => \"t  wrrarrrurrr reu eee eeeeeeeeeeeee uou\"\n",
      "batch 8939  loss=177.5457  steps/s=96.75  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @o es eee  ae  u t  tstitt ttt//////\"\n",
      "batch 8940  loss=148.2939  steps/s=105.05  prediction: \" by talking abt half done projects. BOOM\" => \"ted            n                        \"\n",
      "batch 8941  loss=146.5510  steps/s=94.35  prediction: \"irak seems fine to me (i am brainwashed)\" => \"ne roy eee   a   e                a  a  \"\n",
      "batch 8942  loss=136.5043  steps/s=95.81  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" eo  e sssssnssnnn e eeeeeeeeeee eeeeeee\"\n",
      "batch 8944  loss=189.6613  steps/s=39.17  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"  b  e snnnknss hh e eeeeeeeeeee eeee ee\"\n",
      "batch 8945  loss=153.1532  steps/s=120.20  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"h ot ra ttrr rrr rrr  ttttt /// /tv////t\"\n",
      "batch 8946  loss=167.0326  steps/s=99.21  prediction: \"uper loudly but yea. it helps w thinking\" => \"tltoet r  o  l   lt eu  t t  t  tt   ti \"\n",
      "batch 8947  loss=142.0958  steps/s=99.30  prediction: \"m like the future too\n",
      "is this mujoco btw\" => \"e@a 0 e eee  eeeee ee  e      t      o  \"\n",
      "batch 8948  loss=137.6234  steps/s=105.08  prediction: \"ng things work out rather than 'tactics'\" => \"   ea  g n  g ing    t    t t rt  tttt t\"\n",
      "batch 8949  loss=138.2962  steps/s=102.85  prediction: \"e first img generation models rolled out\" => \" g g           g          eeeee eeeellll\"\n",
      "batch 8950  loss=149.2301  steps/s=100.73  prediction: \"uth is the global maxima strat long term\" => \"t  nesttttttttttttt           aaaaaa a  \"\n",
      "batch 8951  loss=182.1192  steps/s=29.29  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @enttttttttttt      m  a aa aaaa   t\"\n",
      "batch 8952  loss=163.1662  steps/s=105.66  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"ANntea U UU         tt\n",
      "\n",
      "t\n",
      "ttttttttttQQQQ\"\n",
      "batch 8953  loss=143.7236  steps/s=106.19  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"edq e    aaaaaaaaaatttttttt   ssssseeeee\"\n",
      "batch 8954  loss=150.6172  steps/s=103.95  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes            h thtttttttttttttttttt///\"\n",
      "batch 8955  loss=146.4818  steps/s=104.86  prediction: \"u a why/a vision for hard work over time\" => \"tgo   o     v    i     o     o      rr  \"\n",
      "batch 8956  loss=146.5992  steps/s=102.94  prediction: \"ng, dunno why this flew over my head lol\" => \"g a   innn  nnn nt nn n n               \"\n",
      "batch 8957  loss=151.9286  steps/s=46.21  prediction: \"y: @sunsettler write a will just in case\" => \"  @rennnnnttnnn  t  t   ww              \"\n",
      "batch 8959  loss=141.9864  steps/s=106.01  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t                  hhhtttttttttttttt//o/\"\n",
      "batch 8960  loss=153.5752  steps/s=103.28  prediction: \"see this everywhere when you look for it\" => \" ta/      e eeee  eeeeeeeeeeeeeh  e    o\"\n",
      "batch 8961  loss=203.9058  steps/s=98.72  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"B  E OS MMMM EU     S              ///tt\"\n",
      "batch 8962  loss=158.1973  steps/s=104.98  prediction: \"ems like you have. thanks for sharing it\" => \" e e  ieeeeeeeeeeeee e                  \"\n",
      "batch 8963  loss=147.8077  steps/s=103.37  prediction: \"ful if youre a complete beginner like me\" => \"on  r      u  u     u e    e e ee eeee e\"\n",
      "batch 8964  loss=140.9158  steps/s=104.86  prediction: \"t them as axioms, and it screws you over\" => \" ttn  tt   a a   a a   a         s      \"\n",
      "batch 8965  loss=142.3456  steps/s=99.99  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \"nn att  t  a   me ee ee   seee e r   y  \"\n",
      "batch 8966  loss=149.8710  steps/s=103.97  prediction: \"t learning from the things theyre doing.\" => \" feen  e    i  n             t   h      \"\n",
      "batch 8967  loss=150.0847  steps/s=101.57  prediction: \"rappers around statistical distributions\" => \"enn : @  jP\n",
      "Y__:vK,kj\n",
      "Ybv&zYzN.zHjzvfj,\n",
      "\"\n",
      "batch 8968  loss=151.9113  steps/s=102.61  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"td   mmm  m   '''' ''''''   t           \"\n",
      "batch 8969  loss=162.9634  steps/s=90.72  prediction: \"yan I have fun. does that make me a CEO?\" => \":c nimn        I t    sd    t   a a aaa \"\n",
      "batch 8970  loss=140.8327  steps/s=102.55  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"ahanaaa  t tt t  t  aaa        e        \"\n",
      "batch 8971  loss=160.5430  steps/s=103.42  prediction: \" srsly the golden age of building things\" => \"at     o    o     l   o      e   l  g g \"\n",
      "batch 8972  loss=158.0392  steps/s=99.03  prediction: \"sing llms to their full potential rn tbh\" => \" z a e eel    ln llll  ll   ll  tllt ttl\"\n",
      "batch 8973  loss=164.0903  steps/s=102.07  prediction: \"p chats and 4chan are two i can think of\" => \"li:   h  r  t  t  h    a   an       aa  \"\n",
      "batch 8974  loss=152.4795  steps/s=105.06  prediction: \"building logic gates and RAM and whatnot\" => \"ei l  lbb   b l  i   ggg g g g   a   a  \"\n",
      "batch 8975  loss=167.3850  steps/s=37.77  prediction: \"ly: @larpertony @kuberdenis my elo is 10\" => \"y:)) aosbi  i  g gg  ggg         a   a a\"\n",
      "batch 8976  loss=151.4206  steps/s=107.81  prediction: \"t 200hrs in around the same time you did\" => \" beo   22   0  t                        \"\n",
      "batch 8977  loss=137.7814  steps/s=104.27  prediction: \"f, and also not lying about small things\" => \"  \n",
      "ong        ol  l     o           l   \"\n",
      "batch 8978  loss=201.5987  steps/s=39.38  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y    n  ns    o   n     o     al    l   \"\n",
      "batch 8979  loss=179.9823  steps/s=89.11  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \"  @ylt lla    o   n     o     al t  l g \"\n",
      "batch 8980  loss=159.5969  steps/s=106.83  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \"a j o&nnnn    nn   o    t    ttgggg gg g\"\n",
      "batch 8981  loss=162.0640  steps/s=99.62  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"aerto geee7   ata\n",
      "\n",
      "\n",
      "tttttttt tit tittt e\"\n",
      "batch 8982  loss=209.7081  steps/s=98.96  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOEOOOOOOOOOOOOOOOOOOOOOGGtttt////t/J\"\n",
      "batch 8983  loss=186.0757  steps/s=98.95  prediction: \"he second one Unison (Knife Party Remix)\" => \"e  s  A e        neennnn nnnnnn nnn     \"\n",
      "batch 8984  loss=150.1160  steps/s=103.39  prediction: \"s it and im unaware (would love to know)\" => \" a u.                                   \"\n",
      "batch 8985  loss=136.8097  steps/s=104.94  prediction: \"ume instead of a flat surface of a wafer\" => \"tp d           v e  a a    aaaf fffffaff\"\n",
      "batch 8986  loss=142.4859  steps/s=97.65  prediction: \"credibly cool to see this project evolve\" => \"hip   o nn     c l         o       e  ee\"\n",
      "batch 8987  loss=155.2414  steps/s=104.02  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"  i t s      o          o  o   ee eeeeee\"\n",
      "batch 8988  loss=145.8988  steps/s=101.25  prediction: \"u come up with. Forgetfulness is a bitch\" => \"tco o      o             t  t           \"\n",
      "batch 8989  loss=164.1715  steps/s=105.32  prediction: \"ded techniques too, lmk if you know more\" => \"  g e  ee  eeeeeddeeeeeee      o  o    o\"\n",
      "batch 8990  loss=145.0714  steps/s=100.53  prediction: \"ably do this for all future projects tbh\" => \"nlei  o  l        o   l           r   r \"\n",
      "batch 8992  loss=146.6345  steps/s=105.32  prediction: \"so they get into an unending doom spiral\" => \" litt tttt  tt ttt  t    nnnnnnnnnnnnn  \"\n",
      "batch 8993  loss=146.9371  steps/s=104.47  prediction: \"our sword and over time makes you deadly\" => \"u in              r    r              e \"\n",
      "batch 8994  loss=188.0399  steps/s=86.66  prediction: \"ettler @gizmobly https://t.co/ZVEh9zCAgb\" => \"  i     r     o  oo        tt/ o//eedeee\"\n",
      "batch 8995  loss=152.9049  steps/s=100.85  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"tyr pe  i i iiiiiiiiittttttttt/////////c\"\n",
      "batch 8996  loss=162.9552  steps/s=104.76  prediction: \"ng up every word you hear more than once\" => \"g  wo   o oe  o  r    o   o    r    r   \"\n",
      "batch 8997  loss=142.3004  steps/s=103.22  prediction: \"dnt mention anything related to caffeine\" => \" d lr   t t  t  ttnntn nnttnntn nt te te\"\n",
      "batch 8998  loss=142.0603  steps/s=102.64  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "i eeeeeeeeeeeee eeeeeee ee    e       \"\n",
      "batch 8999  loss=138.9967  steps/s=104.02  prediction: \"ffect has it had on you? im very curious\" => \" \n",
      "h    f                                \"\n",
      "batch 9000  loss=149.6963  steps/s=95.62  prediction: \"P get him toys, play w him, lasts longer\" => \" Ii t          t                      ss\"\n",
      "batch 9001  loss=148.5270  steps/s=98.86  prediction: \"uth is the global maxima strat long term\" => \"t  te tttttttttttt          aaaaaaaaaaa \"\n",
      "batch 9002  loss=156.0438  steps/s=104.15  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"  so/th////////hhhthtttttttt//////////PP\"\n",
      "batch 9003  loss=144.9444  steps/s=105.27  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eoa nt       neeeee  e e eeeee        \"\n",
      "batch 9005  loss=144.6539  steps/s=103.80  prediction: \"ommittal move like going on a sabbatical\" => \"npme e  mmmmamma m    e    o          aa\"\n",
      "batch 9006  loss=160.6695  steps/s=99.49  prediction: \"y brotha ty, nah no zig for this bad boy\" => \" miaamaaaatt    t       o          o   b\"\n",
      "batch 9007  loss=166.3999  steps/s=103.38  prediction: \" God for helping us both out\n",
      "it was hell\" => \"torllll ll              o   oo      t  t\"\n",
      "batch 9008  loss=143.5035  steps/s=104.17  prediction: \"ncing is just how things go in business.\" => \" uw  a eneeeiiin e i  s   i      i  n  i\"\n",
      "batch 9009  loss=150.2913  steps/s=97.15  prediction: \" I got a creality one, works well so far\" => \"t ebe  b           t      o         s   \"\n",
      "batch 9012  loss=143.7255  steps/s=103.51  prediction: \" (by trusting in ideas) and testing them\" => \"tytte  t tsttttt     i                  \"\n",
      "batch 9013  loss=156.2222  steps/s=102.95  prediction: \"ut you neeeeeed execution skill yourself\" => \"t  arrarrrurrr re  eee eeeeeeeeeeeee uou\"\n",
      "batch 9014  loss=151.7163  steps/s=106.00  prediction: \"r the years for business/building things\" => \"e(e i onuwjjc##b(\"j)#w#((##vX9\"!/!)(pQ5j\"\n",
      "batch 9016  loss=147.2816  steps/s=104.67  prediction: \" what? never heard of it lol skill issue\" => \"toeem  amee e  neeae  e re  a  e    lil \"\n",
      "batch 9017  loss=165.2562  steps/s=103.18  prediction: \"mobile works now https://t.co/vI0ds7feVt\" => \"esi iaier oo  oo o  oo oo  o ooot/tt/t//\"\n",
      "batch 9018  loss=163.3102  steps/s=102.32  prediction: \"ock your 1000th follower and stay at 999\" => \"roptle  le     0000000loolooo    o      \"\n",
      "batch 9019  loss=185.4625  steps/s=96.30  prediction: \"rs: John 14:6-14 https://t.co/37ryh1InfG\" => \"e rite ji Jf-XX,j,6-X8XX?,\n",
      "vv37?XX5v3700\"\n",
      "batch 9020  loss=162.9908  steps/s=101.95  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"e t elo l ooool oolll  ol     ufffu ut u\"\n",
      "batch 9021  loss=149.1138  steps/s=100.76  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"@s  le i  i    i  e ee      eeee  eeeeee\"\n",
      "batch 9022  loss=134.6727  steps/s=104.38  prediction: \"w up wherever decision making is present\" => \"omt d          n   eeeeeeeeeeeiiiiiiiiii\"\n",
      "batch 9023  loss=150.7567  steps/s=104.26  prediction: \"ter and more efficient than studying imo\" => \" rth  tt   rtt  tte e t eeeee eeietttttn\"\n",
      "batch 9024  loss=159.1083  steps/s=100.80  prediction: \"hich might mean making changes, so, yes?\" => \"esr rh m mm ehmm mh mi mi m  hag n  g n \"\n",
      "batch 9025  loss=141.8337  steps/s=104.57  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" to inillll  ll llllllllll,,,, ,,,,     \"\n",
      "batch 9026  loss=140.8398  steps/s=100.64  prediction: \" the dark forest from the 3 body problem\" => \"the t  e  e ee e e f  f f           o o \"\n",
      "batch 9027  loss=161.0655  steps/s=106.39  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"t..t  tt////t//tttttttttt/:t//tt////t///\"\n",
      "batch 9028  loss=151.3786  steps/s=104.97  prediction: \" so I invested my time into that instead\" => \"ttreer o o  oo e   ee e i    i  t tttt t\"\n",
      "batch 9029  loss=134.1321  steps/s=99.93  prediction: \"stening to the sidetweets podcast at 1am\" => \" r et    t         t tt eteeeet etteettt\"\n",
      "batch 9030  loss=144.3347  steps/s=105.47  prediction: \"learn and have fun building baller stuff\" => \"yv o ensn   r    n   n       n  nn  llll\"\n",
      "batch 9031  loss=135.1155  steps/s=98.81  prediction: \"if you say wala a lot are you a walawala\" => \"n   n y n      aaa aaaaaa  a  a     aaa \"\n",
      "batch 9032  loss=139.8030  steps/s=103.74  prediction: \" fundamentals.  Take the time to invest.\" => \"too         tttt  aa aa                 \"\n",
      "batch 9033  loss=176.2978  steps/s=101.03  prediction: \"7AHwatHv6Y was really really really good\" => \"  xout////HHHHHHHHtaaaaa aaaalllllllllll\"\n",
      "batch 9034  loss=131.5394  steps/s=104.14  prediction: \" local optima solution they got stuck in\" => \"ti e tt        t   oooooooooooooottttttt\"\n",
      "batch 9035  loss=147.5252  steps/s=92.38  prediction: \"irak seems fine to me (i am brainwashed)\" => \"n  tl  a sss   s s o                 a  \"\n",
      "batch 9036  loss=167.5986  steps/s=98.67  prediction: \"ers @iliekcomputers is a p strong player\" => \" s ie    iie e  i  iieiiii e ieis p s  s\"\n",
      "batch 9037  loss=154.1064  steps/s=98.15  prediction: \"amebedan @jaivinwylde stochastic success\" => \"ne  ie   eie @ @i@iiiis      sstt c s  c\"\n",
      "batch 9038  loss=137.3115  steps/s=105.19  prediction: \" adding the context into the computation\" => \"tnd t    o o   ee ooe e  t nt e te ttttt\"\n",
      "batch 9039  loss=174.0394  steps/s=98.84  prediction: \" cool\n",
      "\n",
      "ez follow\n",
      "https://t.co/F6AUVWpskt\" => \"tori i         o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ootootttttttt/////\"\n",
      "batch 9040  loss=177.1896  steps/s=102.51  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \" Be aps/s//////sBBBBB  o   o o oooo     \"\n",
      "batch 9042  loss=146.9442  steps/s=105.09  prediction: \"ouraging way, not stressful for the kid)\" => \" l   inggggggggnnnnnnnn                 \"\n",
      "batch 9043  loss=170.9079  steps/s=98.69  prediction: \"yup totally agree. Very powerful mindset\" => \":c gaan aaaa   a y  t  eee   rrrr ee  er\"\n",
      "batch 9044  loss=142.4322  steps/s=103.44  prediction: \"se? seems like death spiral potential no\" => \"  ea eeee e eeeeeeeeee  e e    s     a  \"\n",
      "batch 9045  loss=164.6299  steps/s=104.08  prediction: \"ke half my followers came from shoutouts\" => \"e l  l  ebb  l ll llll       f fooooomoo\"\n",
      "batch 9046  loss=161.8316  steps/s=96.91  prediction: \"e @sunsettler youre in the nix dimension\" => \" 4    e ee e llleeeeee e  r       i  tes\"\n",
      "batch 9047  loss=144.9099  steps/s=105.11  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tarn   i i              t ttttttt///////\"\n",
      "batch 9048  loss=155.6174  steps/s=103.42  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tu n  a    e   o    e ttttssttsss//tts//\"\n",
      "batch 9049  loss=151.1113  steps/s=105.09  prediction: \"ing responses seems like a better metric\" => \"ng \n",
      "oeeiieeeensnnesssessseseeeeee  eeeee\"\n",
      "batch 9051  loss=180.9508  steps/s=99.85  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:  Ni pp            p     tttt////t/DD\"\n",
      "batch 9052  loss=163.6210  steps/s=103.93  prediction: \"but its ok bc I know theyre high density\" => \"et e t         t                    h hh\"\n",
      "batch 9053  loss=146.7848  steps/s=103.81  prediction: \" by breaking the file into smaller files\" => \"tuts  s    b   b        i        e   lll\"\n",
      "batch 9054  loss=168.6228  steps/s=95.94  prediction: \"ped to have you join!!\n",
      "gl and have fun ðŸ«¡\" => \"lr:  er e    he    o  ii  !!  !lnl  ll  \"\n",
      "batch 9055  loss=148.7649  steps/s=100.79  prediction: \"ve you been unlocking yourself each time\" => \"e ty   tt  oo   oo      o nonnnu u eu ee\"\n",
      "batch 9056  loss=140.5852  steps/s=101.83  prediction: \" the first alien on earth thats so crazy\" => \"theeeeeee ee e t e e           ttt t t  \"\n",
      "batch 9058  loss=151.6252  steps/s=104.71  prediction: \"he just checkmated because he got lucky\"\" => \"e bi\"\"\"\"h\"\"\"hhhhhhhee eeeecceeceeeeeeee \"\n",
      "batch 9059  loss=146.3158  steps/s=105.96  prediction: \" fast eventually. i know this from chess\" => \"tud s  sss  e ee ee e                   \"\n",
      "batch 9060  loss=172.3468  steps/s=104.23  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"ebesi   Mfâ€Ê€ðŸ«¡0j217]já´„v65M$SðŸ°M%$21_á´€21cVá´€\"\n",
      "batch 9062  loss=157.0469  steps/s=100.25  prediction: \"ki i have an idea but it will cost $1600\" => \"en j m e  a    a   aa       a           \"\n",
      "batch 9063  loss=147.1422  steps/s=104.63  prediction: \"ession youll do something until its done\" => \"  me  eeeeeeoe s  ooooooooooo      i    \"\n",
      "batch 9064  loss=149.6897  steps/s=104.67  prediction: \"g Seatbelt doesn't want you to know this\" => \" ah i eeeeeeteetteeettttet ttt  t   t  t\"\n",
      "batch 9065  loss=139.8723  steps/s=102.08  prediction: \"th itself but couldnt figure out how lol\" => \" eet   t t tt  tt      t   u u uuuu u u \"\n",
      "batch 9067  loss=153.6696  steps/s=92.33  prediction: \"irak seems fine to me (i am brainwashed)\" => \"n  wtteee  e   s ee    i  e        i    \"\n",
      "batch 9068  loss=156.4361  steps/s=104.02  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \"elpLon on\n",
      "\n",
      "\n",
      "  \n",
      "\n",
      "     o      a  a  aa    \"\n",
      "batch 9069  loss=148.7301  steps/s=104.80  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"n  see  te        ee eeeeeeeeeeeeeeeeeee\"\n",
      "batch 9070  loss=152.9161  steps/s=106.17  prediction: \"sed\n",
      "\n",
      "Try it asap\n",
      "https://t.co/ZK8YpKEtoP\" => \" lf   r rr  \n",
      " \n",
      " \n",
      "a \n",
      "\n",
      "\n",
      "t\n",
      "\n",
      "sttttt////t/ttK\"\n",
      "batch 9071  loss=159.0891  steps/s=104.99  prediction: \"k checked him out, followed, thanks mate\" => \"eta o t   k\n",
      "  kc            ooo     oo  \"\n",
      "batch 9072  loss=151.5389  steps/s=100.20  prediction: \"r than age sounds like a skill issue tbh\" => \"eony: @sidWR,W@.xp,,#xá´¡vZww3,,\n",
      "$.ð—¶{[%qTá´„\"\n",
      "batch 9074  loss=148.5855  steps/s=104.76  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn no e  e  ee e eeeee e eeettttt/////tt\"\n",
      "batch 9075  loss=167.4296  steps/s=102.47  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"teae       n                  t/////////\"\n",
      "batch 9076  loss=158.8644  steps/s=97.24  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \" ee  looo   oo f  o    oo o  o  o oo ooo\"\n",
      "batch 9077  loss=203.1925  steps/s=99.96  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"t.cc ftt////tt/ot/5ttttUDD//t/t ////tt/t\"\n",
      "batch 9079  loss=158.7824  steps/s=102.07  prediction: \"was making me sleep deprived unknowingly\" => \"as   e    a        e e  eee  eee eeee ee\"\n",
      "batch 9080  loss=141.3722  steps/s=104.13  prediction: \"s are your own, and i need to prove that\" => \" tot t  s e    r                        \"\n",
      "batch 9081  loss=138.2796  steps/s=102.84  prediction: \" one of the objects that could cast them\" => \"tfs a                    ttttttttttttttt\"\n",
      "batch 9082  loss=146.8455  steps/s=105.80  prediction: \"tention/effort with no results. Not easy\" => \" r  et attttettettttttttt t    t  o t  t\"\n",
      "batch 9085  loss=178.9717  steps/s=84.67  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" n etttnennnnOLwOOO  e    e    s        \"\n",
      "batch 9086  loss=152.0053  steps/s=104.55  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \" ir art               i   i    ss  s l s\"\n",
      "batch 9087  loss=142.2462  steps/s=104.34  prediction: \", thank God we can function at all loool\" => \" hee l e e     e      a   n       an  a \"\n",
      "batch 9088  loss=152.6240  steps/s=101.24  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"d se  i n on ononnooootttotsottttt////t/\"\n",
      "batch 9089  loss=153.3689  steps/s=102.08  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \"ane nbil ll lll l l      o tttot///////t\"\n",
      "batch 9090  loss=151.7283  steps/s=104.86  prediction: \"and notice way more over time\n",
      "I suspectâ€¦\" => \"tt ne e  e   t      e   e   e  e e e  e \"\n",
      "batch 9091  loss=152.7583  steps/s=99.79  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"n              n     n   t ttttttttt////\"\n",
      "batch 9092  loss=158.0100  steps/s=104.23  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" pto it  tt   il    ttt ottttttttt//////\"\n",
      "batch 9093  loss=171.6284  steps/s=64.41  prediction: \"@codyaims 113 bots liked this one so far\" => \"jazmelb  ti   i1   ttt  ttttt////////ooo\"\n",
      "batch 9094  loss=142.5878  steps/s=117.40  prediction: \" least its not opengl like this poor kid\" => \"titt att   t   tt ttt   tt    t   o  o o\"\n",
      "batch 9095  loss=144.8676  steps/s=105.63  prediction: \"the world more, become more dysfnctional\" => \"hei            te    e   eeeeeeeeee eeoo\"\n",
      "batch 9096  loss=179.9985  steps/s=95.18  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" tia a    u eeereeeee ee ee   ttccoootoo\"\n",
      "batch 9097  loss=157.7420  steps/s=70.19  prediction: \"gizmobly @juweeism duude this is awesome\" => \" zmaoaweuuujejjjjeeee   ttt /tttso//oaaa\"\n",
      "batch 9098  loss=140.5359  steps/s=109.59  prediction: \"o the door the instant she hears it open\" => \"ug noit  o   t n  t   t    t  h   h    e\"\n",
      "batch 9099  loss=177.5829  steps/s=78.07  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eely: @lazk'KCT)Kj@w(jLL10jxL10:@\n",
      "10:v/x\"\n",
      "batch 9100  loss=167.6768  steps/s=112.19  prediction: \"ly @plasmarob you could have a miz mobly\" => \"y: @gizmz@@ @  @eoesoo    s    e  a i  e\"\n",
      "batch 9102  loss=169.0835  steps/s=105.29  prediction: \"n and are kindaâ€¦ https://t.co/zyjcsUAF4i\" => \"gm   a    n  nn      a         ttttt//t/\"\n",
      "batch 9103  loss=151.0548  steps/s=104.46  prediction: \"so much better than ppl who dont anyways\" => \"  s  o                                  \"\n",
      "batch 9104  loss=153.3322  steps/s=95.27  prediction: \" just signed up as a beta tester hehhehe\" => \"too mo      t  t s    p    a    a  eeteh\"\n",
      "batch 9105  loss=182.8867  steps/s=98.75  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \" cds ssitiri\"\"\"\"i\"\"\"\"\"pppttppppetppapppa\"\n",
      "batch 9107  loss=159.6299  steps/s=105.27  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omoec  ce o  e  e re ee   ht  t////t/ttp\"\n",
      "batch 9108  loss=160.6679  steps/s=105.33  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"iig, n nt      nx     nn n           __ \"\n",
      "batch 9109  loss=171.6121  steps/s=104.24  prediction: \"oing the deadline thing\n",
      "Works super well\" => \"nns at  tt   t    ddddddeeiiieiiiee ee e\"\n",
      "batch 9110  loss=183.3404  steps/s=101.35  prediction: \"MTB Yup, totally, would be best actually\" => \"TB a ry ne ii t  t lllt llll  u   tte  e\"\n",
      "batch 9111  loss=169.8634  steps/s=104.32  prediction: \"n `AI(short prompt)-&gt;output` programs\" => \" atota  u           r  tottttpttptptttpt\"\n",
      "batch 9112  loss=154.7941  steps/s=103.43  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" f  ioiii ioooon  o                    a\"\n",
      "batch 9113  loss=154.4614  steps/s=100.40  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"   o  c c  n nnonnooootttttsottttt/tt/t/\"\n",
      "batch 9114  loss=150.0935  steps/s=104.07  prediction: \" been some adventure man. God bless him.\" => \"tuoe  eeeeeeeee eeeeeeeeeeee            \"\n",
      "batch 9115  loss=232.2081  steps/s=62.06  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"sxwmeeM eee  eeeeeeeeeee GG GO          \"\n",
      "batch 9117  loss=144.3377  steps/s=105.72  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" b t  ta aa     eeee                   t\"\n",
      "batch 9118  loss=152.3957  steps/s=105.47  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tetutttata  t   uutttttttttttttttttttt//\"\n",
      "batch 9119  loss=146.3135  steps/s=104.91  prediction: \"iration theres some awesome ppl in there\" => \"n ow     i iiiiii r r  e eeeseee eeeee e\"\n",
      "batch 9120  loss=145.4174  steps/s=106.16  prediction: \"r reward, wrecking the incentive to work\" => \"eiecaet  n8_VVV@VI7,????I77zz7.??.?????\"\"\n",
      "batch 9121  loss=145.8413  steps/s=96.97  prediction: \" of the tier lists of all time, for sure\" => \"tf   o oo        e  t        t          \"\n",
      "batch 9122  loss=148.5453  steps/s=98.41  prediction: \"n og returns\n",
      "truly a legendary 5-9 today\" => \" t o          rtrr r rllllllle l e    ee\"\n",
      "batch 9123  loss=144.8694  steps/s=102.11  prediction: \"a single man who can bench more than 400\" => \"nboa  n n n    n      n   n  n   n      \"\n",
      "batch 9124  loss=131.8954  steps/s=105.34  prediction: \" local optima solution they got stuck in\" => \"titt tt        t   oooooooooooooottttttt\"\n",
      "batch 9125  loss=212.6254  steps/s=30.58  prediction: \"ply: @sunsettler https://t.co/8FPo1elzOu\" => \"ly: @a   ttt     ttooooooooootoottttt   \"\n",
      "batch 9126  loss=147.7169  steps/s=109.69  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" ato   ee eeeeeeieiiiii                 \"\n",
      "batch 9127  loss=239.6382  steps/s=84.10  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"VSere     e  EE E  R  R     t  s     o  \"\n",
      "batch 9128  loss=151.3762  steps/s=104.14  prediction: \"t the procedure for doing this is on mac\" => \" ses  n   r  e r  trr rer  o o   o   o  \"\n",
      "batch 9129  loss=183.0939  steps/s=78.07  prediction: \"h1xabc king shit https://t.co/UJrAexS6FM\" => \"e  toea t e  e h    t   otto  // oo     \"\n",
      "batch 9130  loss=151.0004  steps/s=106.22  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  ae a iniiidddi dd dddd  doooor ooo    \"\n",
      "batch 9131  loss=213.4098  steps/s=99.51  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"hA E OSTPM MSEB  SUUE  U     t // ////tt\"\n",
      "batch 9132  loss=161.0555  steps/s=106.94  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"sa y    t      n                        \"\n",
      "batch 9133  loss=188.6827  steps/s=97.64  prediction: \"________11hz togglesite is super helpful\" => \"__________________111_1 e      t eeeee  \"\n",
      "batch 9134  loss=175.6754  steps/s=98.65  prediction: \"ongrats on finishing the moon easter egg\" => \"n ___ioapCoa   o  onni ii in n  he   e e\"\n",
      "batch 9135  loss=153.3952  steps/s=100.29  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"n ta tct   t   t t  o  oooo ooa o oaa\n",
      "a\n",
      "\"\n",
      "batch 9136  loss=152.2550  steps/s=104.27  prediction: \"ing I wasted yrs not improving my skills\" => \"ng tF rg ggg   a              n     i  m\"\n",
      "batch 9137  loss=154.6824  steps/s=102.08  prediction: \"e an llm code its actually just this guy\" => \" a y ae   v    e          al   ll  tt   \"\n",
      "batch 9138  loss=158.9996  steps/s=104.68  prediction: \"igure out how to improve your work ethic\" => \"n  ts  t  u u  uoo  oo t oo  oooo ooo r \"\n",
      "batch 9139  loss=151.2395  steps/s=97.62  prediction: \"ot of politics is reinforcement learning\" => \"n    o  oo ooo   o  ii i i  ir ee rreeee\"\n",
      "batch 9140  loss=150.6839  steps/s=103.29  prediction: \"\n",
      "Mar         : 100 followers\n",
      "20th Apr :â€¦\" => \"\n",
      "aotiowettSMA:MF1Dfc_KbkW1p!1F2&cAvA!!â€¦2\"\n",
      "batch 9141  loss=160.8069  steps/s=96.33  prediction: \"s the unreasonable effectiveness of RNNs\" => \" aoa  tt t t tt  t  aeeee eeeeeeeeefesfe\"\n",
      "batch 9142  loss=170.6262  steps/s=107.41  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"t  ee          tt                     e \"\n",
      "batch 9143  loss=197.9434  steps/s=30.66  prediction: \"ply: @cto_junior https://t.co/BLe9cxo4Bp\" => \"ly: @e  ta        t               ee eee\"\n",
      "batch 9144  loss=151.2965  steps/s=109.95  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n   s ss  ss siss    .                  \"\n",
      "batch 9145  loss=150.1666  steps/s=104.75  prediction: \"ss I need to do keyboard input from it..\" => \"    t  l      e e    e  e  o        o   \"\n",
      "batch 9146  loss=145.2272  steps/s=105.46  prediction: \"the (fake) claim about compromising info\" => \" e  co    e    e                 oommiii\"\n",
      "batch 9147  loss=180.1083  steps/s=103.73  prediction: \" make https://t.co/s6ZBWGye2X executable\" => \"tas a\n",
      "ka  t t tt  ////  ///tt///teeetete\"\n",
      "batch 9148  loss=152.2097  steps/s=98.77  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"tes        a      oo  o  oo    s rrss es\"\n",
      "batch 9149  loss=191.0623  steps/s=65.91  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"geodoo_  a       ooo  ossss s    osq  cc\"\n",
      "batch 9150  loss=172.1716  steps/s=108.37  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"t.ca att////t///////ztzzzz////tt////t/L/\"\n",
      "batch 9151  loss=154.6620  steps/s=103.95  prediction: \"ugh or is it just whatever comes to mind\" => \"sh  r oo rr o  o  i     t tt   t t      \"\n",
      "batch 9152  loss=147.3700  steps/s=103.20  prediction: \"e online?\"\n",
      "uuuh, dont be? problem solved\" => \" y yinne eenneeeeeen uu  ?????   e   e  \"\n",
      "batch 9153  loss=149.1327  steps/s=104.30  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"yecudee e              ttttstttttttt////\"\n",
      "batch 9154  loss=158.6168  steps/s=102.65  prediction: \"f children will build my programs for me\" => \" te     m          l ll lll l l      r r\"\n",
      "batch 9156  loss=142.7840  steps/s=104.65  prediction: \"i), everything is deterministic (commonâ€¦\" => \"n          yye t    e eeeiiiiiiiiiiiiiii\"\n",
      "batch 9157  loss=157.1491  steps/s=102.03  prediction: \"ke getting flashbanged by your teammates\" => \"i\n",
      "gs   iitii   e t ggtgggge gg  e    e a\"\n",
      "batch 9158  loss=152.0941  steps/s=105.46  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \" \n",
      "e it \" \n",
      "\n",
      "ii itfofoffooofof  oooo   e  \"\n",
      "batch 9159  loss=148.5275  steps/s=105.35  prediction: \" done in 1s, lol https://t.co/d2QCy0zBel\" => \"ton innnnnnn             t tttttttt/////\"\n",
      "batch 9160  loss=189.6098  steps/s=59.73  prediction: \" @anish0209 And now hes making it run js\" => \"tmntnnnn  n    n    t   tttt///t///////l\"\n",
      "batch 9161  loss=183.4982  steps/s=97.26  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ydn@nii 0 0A   n n nn  ppppp/p/t ttt ys \"\n",
      "batch 9162  loss=162.9624  steps/s=107.03  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"t.acrc\n",
      "te///ss///tCCCttCCCC//ttt:///..//\"\n",
      "batch 9163  loss=166.9717  steps/s=79.01  prediction: \"odor_io worst metric youve heard so far?\" => \"   t ctooottsCotott  tttt.//tttthFt88PPo\"\n",
      "batch 9164  loss=164.4174  steps/s=107.79  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tt   oo l  ooo g iiiiiiiiiii iiii  i i  \"\n",
      "batch 9165  loss=163.0885  steps/s=103.57  prediction: \" funny i like it https://t.co/gxpcMrRiHL\" => \"tuefrur d  d     kk     keei i    i  /t \"\n",
      "batch 9166  loss=149.1236  steps/s=104.35  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"yy @dee                ttttstttttttt////\"\n",
      "batch 9167  loss=181.1751  steps/s=52.02  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" @TaxrirABA  i AP)@M_z,J:_;&.yK;C;TzLP50\"\n",
      "batch 9168  loss=171.0883  steps/s=91.95  prediction: \"@liljuuliet this https://t.co/MmuaB56dUP\" => \"ludrelluluulA    ttoshtttss///to///5/5q5\"\n",
      "batch 9169  loss=156.1543  steps/s=118.82  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n ale  ise  i s  t  s tttattttt/t/////YY\"\n",
      "batch 9171  loss=148.8727  steps/s=99.83  prediction: \"m like the future too\n",
      "is this mujoco btw\" => \"ete n e eee  eeeee ee  e    t t  to oooo\"\n",
      "batch 9172  loss=155.7584  steps/s=95.34  prediction: \"n just do things https://t.co/909bTHzmml\" => \" i  eet      u  t   tttt s tt ttst/99/9/\"\n",
      "batch 9173  loss=150.5738  steps/s=103.82  prediction: \"e component is the key to crazy stuff...\" => \" pons   n onnn  nn  e     e  ee  t   t  \"\n",
      "batch 9174  loss=151.1530  steps/s=106.93  prediction: \"atched this 8 times\n",
      "actually cannot stop\" => \"ni  to eoe   t t  t       t t  ataacaaat\"\n",
      "batch 9175  loss=150.1031  steps/s=99.14  prediction: \"one thing I need https://t.co/2lJdUbXtXP\" => \"   e thhhh               t ttttttttttttt\"\n",
      "batch 9176  loss=153.9895  steps/s=106.02  prediction: \" apart and send each one off to an agent\" => \"tne u     a a  ta a  d  a  e      o     \"\n",
      "batch 9177  loss=143.2729  steps/s=104.48  prediction: \"ies and more insights. Then will release\" => \"ns sd      d   e    i i ss s  i i  i    \"\n",
      "batch 9178  loss=175.1744  steps/s=58.49  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tlle t i   nd  n iiii s  s s  n i ie ee \"\n",
      "batch 9179  loss=144.7344  steps/s=106.92  prediction: \"dering doing another one of these monday\" => \" s  a   s     nn nonnnnnnnonoooo      e \"\n",
      "batch 9180  loss=162.3142  steps/s=92.41  prediction: \"77x im guessing you're super cracked huh\" => \"  ia  i ii7  nnggg gg ee  o    e eeee ee\"\n",
      "batch 9181  loss=182.6794  steps/s=93.47  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"e ly: @  j,bðŸ˜‰xðŸ˜‰)77xSE:!TSE.wA1':GI\n",
      "':x/?\"\n",
      "batch 9182  loss=275.8548  steps/s=12.39  prediction: \"reply: @cachecrab ah, the french defense\" => \"eply: @  j,bðŸ˜‰xðŸ˜‰b77xSP:!TSB.wA1':3I0':x/?\"\n",
      "batch 9183  loss=153.2291  steps/s=114.42  prediction: \"6x speed version https://t.co/yCogzpgz92\" => \"h ss            e e e  e e ssts///////o/\"\n",
      "batch 9185  loss=146.2005  steps/s=103.38  prediction: \" the most important parts of improvement\" => \"toets  o   o  oo   ottt t  t ott   tmmmm\"\n",
      "batch 9186  loss=167.2203  steps/s=103.22  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" ie  Vtan  ta  ata aa t a t   tt/ t//ttL\"\n",
      "batch 9187  loss=180.4789  steps/s=99.89  prediction: \"ost valuable RESOURCE\n",
      "\n",
      "damn i need sleep\" => \" t o  t ttt  u u   R EREEEREERaa  a    n\"\n",
      "batch 9188  loss=149.3611  steps/s=103.95  prediction: \"about things that have significant value\" => \"loe\"\n",
      "ttta t ttttt aa tt tth  hat  aiaa a\"\n",
      "batch 9189  loss=148.8673  steps/s=106.76  prediction: \"ng that solves a problem you're close to\" => \"g    t  it t  tn   s         o     oe e \"\n",
      "batch 9190  loss=143.5612  steps/s=103.58  prediction: \" commonly use amd it works insanely well\" => \"tots                                    \"\n",
      "batch 9191  loss=183.4425  steps/s=53.46  prediction: \" @thetechbrother https://t.co/nOiteSF1jC\" => \"tbes          m m              nnn  eell\"\n",
      "batch 9192  loss=173.8326  steps/s=107.59  prediction: \": @IterIntellectus here have another one\" => \" @sawovete   t f@Sf@,2:gcE2:E/vO:v/SO1jC\"\n",
      "batch 9193  loss=155.1766  steps/s=110.18  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \" iheael.     e   e           ttt//ttPPPP\"\n",
      "batch 9194  loss=181.6695  steps/s=52.21  prediction: \": @teodor_io funny number go up type shi\" => \" @ ucoente   @imâ€œJ@â€œbâ€œâ€œâ€œ9vâ€19â€œvOvâ€8'O1'C\"\n",
      "batch 9195  loss=144.5889  steps/s=112.11  prediction: \"n up a simple ec2 and try it there maybe\" => \"gt9  e  p                               \"\n",
      "batch 9196  loss=191.8604  steps/s=95.52  prediction: \" QUICK delete this before sphere sees it\" => \"tlo  ol s ll  e  ee   ee  t  te eeeeree \"\n",
      "batch 9197  loss=157.2399  steps/s=104.47  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u                      tttttttttt//////t\"\n",
      "batch 9198  loss=166.0587  steps/s=100.47  prediction: \"ng to close your eyes to and just listen\" => \"gsi  e    s  soo  o s  oo   o  o o   s  \"\n",
      "batch 9199  loss=169.6968  steps/s=104.43  prediction: \"ood combo for stuff like this, ive found\" => \"um 4 \n",
      "o ooooooooof  fffff f             \"\n",
      "batch 9200  loss=159.9799  steps/s=104.23  prediction: \"nd beyond is such a gargantuan advantage\" => \"g t f g   b                s aaaa aa aaa\"\n",
      "batch 9201  loss=146.4879  steps/s=104.77  prediction: \"e right things really really does matter\" => \" mitet te  tttt   t      r ll  lllll  ll\"\n",
      "batch 9202  loss=186.0881  steps/s=97.17  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" eit teen  nnene   ll e  tttht sttts ///\"\n",
      "batch 9203  loss=163.2559  steps/s=98.40  prediction: \"n confirm this is a very goated strategy\" => \"gth  re e  aan sn   s    s  i    a a  ta\"\n",
      "batch 9204  loss=154.9210  steps/s=100.74  prediction: \" wtf, hes goated https://t.co/o1FdLtmzSj\" => \"@o    w         e   t tt tttt /tt/tt///t\"\n",
      "batch 9205  loss=158.2092  steps/s=102.27  prediction: \"of learning is learning from the past ig\" => \"u   edaannaeannen n n nan nnn n    rr   \"\n",
      "batch 9206  loss=163.4246  steps/s=101.76  prediction: \" know any easy way to work with cuda btw\" => \"@no   o    o  y y y y  a y wwy  w wo w  \"\n",
      "batch 9207  loss=163.1495  steps/s=98.99  prediction: \" square gang wont let this happen &gt;:(\" => \"@uo  o y    a   awa   o    o t h    h   \"\n",
      "batch 9208  loss=141.0080  steps/s=104.87  prediction: \"sfully improved their lives tremendously\" => \"  ete feeses  sseeeeeee ee eeee eeeeee e\"\n",
      "batch 9209  loss=155.4865  steps/s=87.28  prediction: \"t only people named dan will have access\" => \"hth  ulyl  llllpeeeeee  ee   ll e eeee e\"\n",
      "batch 9210  loss=241.1232  steps/s=12.07  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"eply: @ oakðŸ˜­qRL)!q!!!!,W;&W&&x3?IRLwGIRL\"\n",
      "batch 9211  loss=142.6492  steps/s=116.63  prediction: \" drag down/demotivate other team members\" => \"to   d   dd  dd  ddddddooooteottte eeeem\"\n",
      "batch 9212  loss=156.6315  steps/s=102.34  prediction: \"h, that explanation/example makes sense'\" => \"e  hshhhhh hh hhaaaaaaaaaaxaaaaaaeeeeeee\"\n",
      "batch 9214  loss=147.4546  steps/s=104.42  prediction: \"d meant i could do whatever i wanted lol\" => \" ae a eaaaaa  ad          d             \"\n",
      "batch 9215  loss=145.2842  steps/s=104.43  prediction: \" and the professor thought it was a typo\" => \"tn   aiii i                             \"\n",
      "batch 9217  loss=175.9858  steps/s=88.04  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" nci  i     e  nOOOe ee   e      \" t   p\"\n",
      "batch 9218  loss=159.9290  steps/s=104.97  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"ow s e,             s??????ssssttttt///B\"\n",
      "batch 9219  loss=190.2118  steps/s=60.49  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tc   i  W WWWW????Ytsstssstttt//BBBB/Btt\"\n",
      "batch 9220  loss=158.5897  steps/s=107.20  prediction: \"te correctly lol\n",
      "https://t.co/0eYn1IVGOH\" => \" r  pte  e  te  ootttotttttttt//////////\"\n",
      "batch 9222  loss=136.2901  steps/s=103.22  prediction: \"ta but those with a data engine: iteratâ€¦\" => \" lt  ot  tttttt ttt                     \"\n",
      "batch 9223  loss=139.8197  steps/s=102.77  prediction: \" can see something 1000000x better to do\" => \"tat eaaan  a   see   e  000000000000 e  \"\n",
      "batch 9224  loss=169.5044  steps/s=102.44  prediction: \"y i havent had many problems with it tbh\" => \":busuel lee     a  a     a        m    t\"\n",
      "batch 9225  loss=152.0827  steps/s=103.66  prediction: \"ur gzip stuff? training on gzipped data?\" => \"t al                   i    iii  iii    \"\n",
      "batch 9226  loss=152.0385  steps/s=105.02  prediction: \"ms' meaning more straightforward success\" => \"e  lame'b''' emme mmmmmmr   rrr  rarrrrs\"\n",
      "batch 9227  loss=145.0848  steps/s=103.98  prediction: \"x len output, custom system prompts, etc\" => \"_p@  ee ee   uutuu uuuutuuttttt mttmmttt\"\n",
      "batch 9230  loss=149.0007  steps/s=104.15  prediction: \"n X and see people dropping crazy things\" => \"gao              eee eeppppeppppp       \"\n",
      "batch 9231  loss=146.0926  steps/s=98.35  prediction: \"ably do this for all future projects tbh\" => \"ne ro o  b  b     o   l               r \"\n",
      "batch 9232  loss=137.5850  steps/s=102.38  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \" au i     n y yetetteeeeeeeeeeeeeeeeeeee\"\n",
      "batch 9233  loss=164.9331  steps/s=104.95  prediction: \"reaks). During these sessions my producâ€¦\" => \"epl : e elS0AM%BkA)!kD).ODAN,T77Tj7I0=â€¦x\"\n",
      "batch 9234  loss=156.7345  steps/s=102.84  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne p  llllllll         t tttttttttt////H\"\n",
      "batch 9235  loss=154.1009  steps/s=104.28  prediction: \"d of just putting in more and more hours\" => \" og  o         tt tttt t                \"\n",
      "batch 9236  loss=161.0685  steps/s=104.20  prediction: \"you like hearing about progress updates!\" => \" u  enollll  ii l ii      ioor  or  r u \"\n",
      "batch 9237  loss=149.3203  steps/s=104.36  prediction: \"best way ive found so far to order tasks\" => \"u l eetttt   e t                   o    \"\n",
      "batch 9238  loss=150.7728  steps/s=104.41  prediction: \"dont know much about it other than that.\" => \" ng      tt   tt        t     tt tt  tth\"\n",
      "batch 9239  loss=139.2282  steps/s=103.48  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \"  e  o' ee eeeen    e     e     e  e   e\"\n",
      "batch 9240  loss=147.3939  steps/s=98.00  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  e  ininiii e    d       n    nooo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"\n",
      "batch 9241  loss=138.1672  steps/s=103.76  prediction: \"i is a smart idea to pitch to the public\" => \"ni sof                      t   tt tttt \"\n",
      "batch 9243  loss=223.4181  steps/s=21.20  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @                      ttt tt ttt  \"\n",
      "batch 9244  loss=149.6939  steps/s=116.80  prediction: \"ernet becomes, say, 100x more addictive?\" => \"  th  neeeeeeeeeeeeeeee                 \"\n",
      "batch 9245  loss=142.8041  steps/s=105.16  prediction: \" from that channel/vid to that x account\" => \"ti    o lo     a  a a      tttttt    tt \"\n",
      "batch 9246  loss=145.9395  steps/s=99.91  prediction: \"xes this (whether you want it to or not)\" => \" r Ve ss ss sssss hh  hh        tt  t   \"\n",
      "batch 9247  loss=198.9952  steps/s=101.30  prediction: \"@___________11hz helped me out with mine\" => \"yacrhe_  _________________   e  e   o t \"\n",
      "batch 9248  loss=151.2887  steps/s=105.55  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"ni a g mimmiiimi  e te  tete tt/tt////t/\"\n",
      "batch 9249  loss=140.5588  steps/s=103.52  prediction: \", usually because you border more things\" => \" an  ee eee  e  e ee e u uuuuuu e  e e r\"\n",
      "batch 9251  loss=216.1804  steps/s=102.05  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"IAI U  U  U  T  S SS  FFF        ///////\"\n",
      "batch 9252  loss=151.9657  steps/s=102.76  prediction: \" got chicken bone broth from walmart lol\" => \"to                                      \"\n",
      "batch 9253  loss=193.9858  steps/s=56.18  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"tO      iic ccoo     o   ooo oooo r rrll\"\n",
      "batch 9255  loss=156.2166  steps/s=106.84  prediction: \" up to do multiple iterations of editing\" => \"tst  t                 t  t ti titiiiii \"\n",
      "batch 9256  loss=146.6666  steps/s=101.22  prediction: \"ugh\n",
      "\n",
      "but lud should be up there for sure\" => \"t igo o t     uuuuuuuuuuuuuu            \"\n",
      "batch 9257  loss=169.6130  steps/s=105.32  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"g et te  teee  eeeee e d dadddadaaaaaaad\"\n",
      "batch 9258  loss=167.5254  steps/s=95.85  prediction: \"ere @jesx64 never stop having fun either\" => \" efet eejeeee  jeeee   aaaa   aao  a n  \"\n",
      "batch 9259  loss=152.1473  steps/s=105.59  prediction: \"f undulation. You probably already knowâ€¦\" => \" y tu          n    uoouoo ooooaaalaaaaa\"\n",
      "batch 9260  loss=161.8717  steps/s=86.64  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"piOO   ttaaa o nooo  ooo   l  aaa  yyy y\"\n",
      "batch 9261  loss=190.4146  steps/s=105.34  prediction: \"dnt acct for maintenance/electricity tho\" => \" tt  e   c    ct       nnancnaaacceeecee\"\n",
      "batch 9262  loss=160.2106  steps/s=105.04  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee  e e  eeeeeeennntnttntttttttt/////\"\n",
      "batch 9263  loss=140.9552  steps/s=106.16  prediction: \"my efficiency. But overall cause its fun\" => \"o e         e eee                       \"\n",
      "batch 9264  loss=140.3539  steps/s=105.78  prediction: \" in those days will have had it too easy\" => \"tt  mnsss    ss    s   ss               \"\n",
      "batch 9265  loss=164.3931  steps/s=102.20  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"tn m m  mo oooooolo  l  o    e ee     e \"\n",
      "batch 9266  loss=145.7682  steps/s=105.31  prediction: \"DLR but could just be forward/left/right\" => \"  t i i        uu    u   u          rrrr\"\n",
      "batch 9267  loss=145.2299  steps/s=105.29  prediction: \"dering doing another one of these monday\" => \" l   os s n   nnnnonnnnnnnnnoooo   o  e \"\n",
      "batch 9268  loss=173.8097  steps/s=102.34  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tuncclc g            7777722ttt/////tt//\"\n",
      "batch 9269  loss=215.2726  steps/s=96.29  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"oL uy   EEEEEEOOOOOOOOOtOthtthth t yy f \"\n",
      "batch 9270  loss=155.9012  steps/s=105.05  prediction: \"d virus that makes ppl cracked at scale?\" => \" d   e i                     a   a   aa \"\n",
      "batch 9271  loss=148.7041  steps/s=103.67  prediction: \"ight radius\n",
      "Hmm 5px or 5%? Maybe 4.9%...\" => \"nA a       t   t   t     555555      %%%\"\n",
      "batch 9272  loss=155.7030  steps/s=101.65  prediction: \"ting the entire GOL industry as we speak\" => \" nnuam  m      t t t  i   i             \"\n",
      "batch 9273  loss=147.9414  steps/s=103.44  prediction: \"d all the aliases for commands to bashrc\" => \" on ap ada   aala                       \"\n",
      "batch 9274  loss=149.0597  steps/s=102.27  prediction: \"losoft and make the circle tool yourself\" => \"ycwese soooooo s  e   e      e          \"\n",
      "batch 9275  loss=146.8362  steps/s=97.61  prediction: \"ist either way, its all about production\" => \"n  olotttt ttt t      t    a l ll oolo o\"\n",
      "batch 9276  loss=188.6406  steps/s=29.62  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly: @aittt tte e t    a    a l l oootouo\"\n",
      "batch 9277  loss=155.9237  steps/s=108.36  prediction: \"itor as I was with 2 screens and a mouse\" => \"n   a t   a                  s  s   s s \"\n",
      "batch 9278  loss=168.4352  steps/s=87.92  prediction: \"phere @gizmobly giz inc will change this\" => \"lo   a  r  r   w i       i   n  c a a aa\"\n",
      "batch 9279  loss=153.6300  steps/s=104.01  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"eply: @Haxq1IZZz]@'[å€‘].'zy,á´€vz/,xå§.2ð˜€ÊŸ/g\"\n",
      "batch 9280  loss=192.9811  steps/s=31.25  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly: @ooe e ee ee    nn e  l        a    \"\n",
      "batch 9281  loss=163.1260  steps/s=106.49  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n trl     rEEEE xEEe    ::t::::///  ///t\"\n",
      "batch 9283  loss=162.5527  steps/s=101.60  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"taa  em m    e    l l       oo  oo  o o \"\n",
      "batch 9284  loss=139.6057  steps/s=104.68  prediction: \" my chess elo to give data that it works\" => \"ty e   ne n   en              tt    tt t\"\n",
      "batch 9285  loss=146.3143  steps/s=103.07  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e e ee eee t e t e  y a a     a   aa    \"\n",
      "batch 9286  loss=148.0592  steps/s=103.24  prediction: \"isten to remixes of the ost all the time\" => \"n   l s s s                          t  \"\n",
      "batch 9287  loss=146.4047  steps/s=104.19  prediction: \"d meant i could do whatever i wanted lol\" => \" ai a eaaaaa  ad          d             \"\n",
      "batch 9288  loss=163.6113  steps/s=101.49  prediction: \" the 16 hour coding session, lets get it\" => \"thent7              o   o  o  o n  s   s\"\n",
      "batch 9289  loss=166.3301  steps/s=101.91  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"the r     ttt e  toh th ttth ttt/////to/\"\n",
      "batch 9290  loss=160.8952  steps/s=38.72  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"  al      ttt llothh th t th tt//////ooo\"\n",
      "batch 9291  loss=150.3530  steps/s=109.80  prediction: \"n just build cool fun stuff all the time\" => \"gm er       u  n  u    uu uu   u f   f  \"\n",
      "batch 9292  loss=171.9862  steps/s=37.39  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: aa ej  uu   u  u    uu uu   l f   l  \"\n",
      "batch 9293  loss=169.0229  steps/s=121.06  prediction: \"e gets servers/multiplayer working too..\" => \" t m   ig  e  se e s ee seelllrrlerrerir\"\n",
      "batch 9294  loss=175.4551  steps/s=54.21  prediction: \": @Wooltard @paulg Or better compression\" => \" @s yiar _l in 0OZpZxIzOw1v/1á´„vxbzv[:Êœ/v\"\n",
      "batch 9295  loss=175.8406  steps/s=106.93  prediction: \"nthwave channel: https://t.co/0b7orVHqb3\" => \"     t  e   nnnenneehnhnnn:::tt::://tt//\"\n",
      "batch 9296  loss=152.0202  steps/s=103.77  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \"  se           n                t///pp//\"\n",
      "batch 9297  loss=143.2171  steps/s=105.28  prediction: \"ide stuff on top of normal operations ig\" => \"ne  od               oo  ooooooooooooooo\"\n",
      "batch 9298  loss=158.5413  steps/s=103.42  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" : e tsse??ss?? s    ss tst  ttttt//t/t/\"\n",
      "batch 9299  loss=173.0535  steps/s=69.12  prediction: \"HSVSphere just barely hit max call depth\" => \"ST thedSsS rr   s    tssts  /tt/tt////ZZ\"\n",
      "batch 9301  loss=149.6797  steps/s=106.44  prediction: \" even the ones i disagreed with the most\" => \"tf e eeen  eeeen          e ee          \"\n",
      "batch 9302  loss=166.6685  steps/s=103.75  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \" ul ev    ooo  o  ohhhh?hhhhtthottttt/t/\"\n",
      "batch 9303  loss=139.0395  steps/s=104.85  prediction: \"t, bc you can edit/delete prompt history\" => \"h r  ea t a  t   c    t  tt  ee  e  tptt\"\n",
      "batch 9304  loss=136.4846  steps/s=103.96  prediction: \" you called it. may as well draft it now\" => \"tou                                     \"\n",
      "batch 9305  loss=164.4705  steps/s=104.38  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  dt ee;;g;;gteggtgttttttotoortt LL oLLt\"\n",
      "batch 9306  loss=150.6653  steps/s=104.51  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"onpot e  a   aac aa      ouuu  uouu ooo \"\n",
      "batch 9307  loss=155.1693  steps/s=101.56  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" d e \n",
      "tssseeeeaeeeseeseeessesessesssseee\"\n",
      "batch 9308  loss=168.6534  steps/s=105.34  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"toccotttl///tttttttoSSttSSS:t/tt:///tt//\"\n",
      "batch 9309  loss=167.0930  steps/s=105.66  prediction: \"for whatever they click on,play it w VLC\" => \"or ta  ot d eeevee  e ee e  e     l     \"\n",
      "batch 9310  loss=171.0394  steps/s=99.34  prediction: \"e77 build things people want/ need maybe\" => \" 7oi  o e777777    iii  l   ppp   e  n  \"\n",
      "batch 9311  loss=156.5191  steps/s=98.87  prediction: \"eadphones dead gonna recharge real quick\" => \" d ye eeeehhehd eddd een nnnnn  eea aeee\"\n",
      "batch 9312  loss=142.0309  steps/s=102.00  prediction: \"th `sudo service NetworkManager restart`\" => \" e  en  r rr r r   e  eeee ee eereeererr\"\n",
      "batch 9313  loss=96.0485  steps/s=104.02  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"@ouOOOO w   aa     aa??  aa??   aa   EE \"\n",
      "batch 9314  loss=142.6185  steps/s=105.33  prediction: \"evelopment speed\n",
      "https://t.co/YNvpK7QsyT\" => \" e t    t     eeeeeeeeepeeettttttttt////\"\n",
      "batch 9316  loss=160.4100  steps/s=103.97  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"tdt t er e  ee  eaa   atttaattttt////t//\"\n",
      "batch 9317  loss=141.8121  steps/s=104.70  prediction: \"file editing program, will show vid soon\" => \"or it  iiiiii ieiiiii i iii ll ll  i    \"\n",
      "batch 9318  loss=144.1849  steps/s=103.67  prediction: \" us safe from undetectable Dyson spheres\" => \"tp  nn  n ef    f    eeee e eeeee eeeeee\"\n",
      "batch 9319  loss=142.7611  steps/s=104.54  prediction: \"o have positive interactions its to grow\" => \"rs t o       o t  i  ititiiitiiiiiiitttt\"\n",
      "batch 9320  loss=146.6220  steps/s=104.70  prediction: \"just point to concepts and arent reality\" => \"usts  i  i    ot   oo  o t  tnn n  nnn t\"\n",
      "batch 9321  loss=147.5143  steps/s=101.49  prediction: \"a monoid in the category of endofunctors\" => \"lloross s oo o n    e o  o o      o o on\"\n",
      "batch 9323  loss=164.0262  steps/s=103.82  prediction: \"reaks). During these sessions my producâ€¦\" => \"eplie eeel`0J:J,k9).kD).9D999T77T7CCC%â€¦!\"\n",
      "batch 9324  loss=154.9278  steps/s=100.98  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" sso eeaseeeeeaeeeseeseeesseeesseses eee\"\n",
      "batch 9325  loss=172.1581  steps/s=78.72  prediction: \"sha Keep grinding ig\n",
      "\n",
      "Ppl love to see it\" => \" ene esaseeeeeieeeis iii i\n",
      "\n",
      "  \n",
      "\n",
      "\n",
      "s    e \"\n",
      "batch 9326  loss=155.0241  steps/s=107.21  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"ln t ti           \"\"\"\"\"\"                \"\n",
      "batch 9327  loss=146.9281  steps/s=102.47  prediction: \"verything app\n",
      "may take like a decade tho\" => \"ereie  eee t e t e  y a a  a  a   aa    \"\n",
      "batch 9328  loss=152.6511  steps/s=101.29  prediction: \"elf even if it overlaps with signoooling\" => \" y llll lle e  n        e    i  i  iii i\"\n",
      "batch 9329  loss=164.1801  steps/s=84.74  prediction: \"kul07 Nothing beats the classic todo.txt\" => \" by ele  e  i  t  i     e    i  iissiooo\"\n",
      "batch 9330  loss=165.7097  steps/s=104.14  prediction: \"rammer you love lean? prove it (in lean)\" => \"elly: @   kNH07wNI.@O@?ðŸŒ‘b,Rm#uá´]y(uCDX#â€¦\"\n",
      "batch 9331  loss=151.1281  steps/s=103.38  prediction: \"you find God, the truth, and help people\" => \" u  oe eeene   ee        t      h  hh   \"\n",
      "batch 9332  loss=150.5282  steps/s=103.64  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   t   hh hh     h     i oioiio ooooo oo\"\n",
      "batch 9333  loss=149.0383  steps/s=104.63  prediction: \"e component is the key to crazy stuff...\" => \" pone   n onnn  nn  e     e  ee  t   t  \"\n",
      "batch 9334  loss=145.0923  steps/s=105.73  prediction: \"learn and have fun building baller stuff\" => \"yveo aosr o r    n   n       n  nn  llll\"\n",
      "batch 9335  loss=149.7297  steps/s=101.93  prediction: \"ven a bit is a huge anti pattern i think\" => \"e yeteneenn   eeii            a    tt   \"\n",
      "batch 9336  loss=170.8345  steps/s=107.47  prediction: \" wtf is a monoidal field\n",
      "\n",
      "i want to know\" => \"ahnr er ri  m    i  a aa aia iiat  tit  \"\n",
      "batch 9338  loss=166.5854  steps/s=96.57  prediction: \"ould build the thing then maybe post it!\" => \"ut r   o    o o   u u d t  th t th e    \"\n",
      "batch 9339  loss=150.4895  steps/s=104.61  prediction: \"soned wine games https://t.co/9edvpSK4pr\" => \" mi t  e  o e  eoe   s e  ee    //eee//p\"\n",
      "batch 9340  loss=138.7881  steps/s=104.86  prediction: \"onna think in terms of utility and price\" => \"ue      nnnnnn nnnnn                    \"\n",
      "batch 9341  loss=157.8013  steps/s=97.96  prediction: \"imated stills have finally been defeated\" => \"nes ? aaa ai t n t tt   illl   a n    ee\"\n",
      "batch 9343  loss=141.7193  steps/s=101.78  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"              e eeeeeeeee              o\"\n",
      "batch 9344  loss=177.0782  steps/s=106.11  prediction: \"i have good news https://t.co/C5gY0PwNAZ\" => \"nws e   he e e    o    o    t   ///to///\"\n",
      "batch 9345  loss=147.4336  steps/s=102.49  prediction: \"now how to do it https://t.co/y5LFqaVw5b\" => \"dt,ewe        oo o    t ttttttt////////5\"\n",
      "batch 9346  loss=138.0575  steps/s=100.27  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"   o    e     eeeeeeeeeee              o\"\n",
      "batch 9347  loss=149.9203  steps/s=107.74  prediction: \" said it was his last email, he meant it\" => \"thee e  t    e  h    i  aa   a    i a   \"\n",
      "batch 9348  loss=155.9184  steps/s=96.56  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"LME  he         s    o             n   e\"\n",
      "batch 9349  loss=181.3518  steps/s=102.26  prediction: \"ecursive thread\n",
      "\n",
      "https://t.co/sc1GSL4fJx\" => \" hhh  iic e irrire  h tehetthttht//t//st\"\n",
      "batch 9350  loss=155.4849  steps/s=102.67  prediction: \" that initially seemed meaningless to me\" => \"@her  eet   ii iiiti ieeeeeeei e eee e e\"\n",
      "batch 9352  loss=142.0823  steps/s=105.69  prediction: \"s large of a positive impact as possible\" => \" anlaa aaaa                          sss\"\n",
      "batch 9353  loss=165.7942  steps/s=103.98  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"IVE yP UU           tt\n",
      "\n",
      "t\n",
      "ttttttttttQQQQ\"\n",
      "batch 9354  loss=160.6930  steps/s=104.33  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"tao   e e  ee    ...  ...  ..  ///hh////\"\n",
      "batch 9355  loss=148.5362  steps/s=102.45  prediction: \" been some adventure man. God bless him.\" => \"tuve  e eeeeeee eeeeeeeeeeee            \"\n",
      "batch 9356  loss=143.6545  steps/s=104.61  prediction: \"going into space man its truly beautiful\" => \" n  a e innn nnn  n     n              t\"\n",
      "batch 9357  loss=138.9288  steps/s=104.98  prediction: \"ve to or weak squares/pieces etc etc etc\" => \"e i ee   e   e       e  ee eeeeeeeeeeeee\"\n",
      "batch 9358  loss=175.9570  steps/s=102.11  prediction: \"? If so how much https://t.co/W2kuYHIlNP\" => \" IonA eneeie        h  h   h ////t/////t\"\n",
      "batch 9359  loss=151.7433  steps/s=99.92  prediction: \"ood direction to get more good direction\" => \"rl rreeeoe eoior oooto  oo  ooto  ooo oo\"\n",
      "batch 9360  loss=149.0662  steps/s=105.00  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"    aacou a  aaaa   tttsttttttttsstt/tt/\"\n",
      "batch 9361  loss=145.5501  steps/s=104.03  prediction: \"t on bad apple vs python library anyways\" => \"hot  t hs          p  pp    pp       yyy\"\n",
      "batch 9362  loss=148.7371  steps/s=102.14  prediction: \"han automating friction out of your work\" => \"etg\n",
      "    enetttt  ta  ttttiitti   oto o o\"\n",
      "batch 9363  loss=148.3190  steps/s=103.05  prediction: \" and use it on everything\n",
      "\n",
      "epiphany trap\" => \"tndt t  t         e     ee ee  neeeeeenn\"\n",
      "batch 9364  loss=149.5202  steps/s=102.80  prediction: \" the code in my head like an interpreter\" => \"thinirn n     h              e    e  e e\"\n",
      "batch 9365  loss=147.8789  steps/s=100.89  prediction: \"ven a bit is a huge anti pattern i think\" => \"eriieeeeenn   eeii                  t   \"\n",
      "batch 9366  loss=145.6502  steps/s=104.71  prediction: \"sively going up\n",
      "But make responsibilityâ€¦\" => \" bll   erereeee  gggggg g g  ee      e s\"\n",
      "batch 9368  loss=130.1676  steps/s=104.22  prediction: \"aybe I need to grow more tomatoes though\" => \"n   e n   e    e             ooooooooooo\"\n",
      "batch 9369  loss=157.7169  steps/s=103.29  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"lte  eellplopoop  soookkoooonoono nono  \"\n",
      "batch 9370  loss=183.2193  steps/s=95.32  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"yM s oss ololoo oinnnoo ssn  ntt  ///rrn\"\n",
      "batch 9371  loss=173.1766  steps/s=102.86  prediction: \"up man youre gonna go far over the years\" => \"seee   e    e     e   n     n     r     \"\n",
      "batch 9372  loss=165.7255  steps/s=104.52  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"@on         t !!!!!!!!!tttttttttt/////tt\"\n",
      "batch 9373  loss=228.2087  steps/s=20.12  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly  @g t   !!!!!!!!!!!tttttttttt/////tF\"\n",
      "batch 9374  loss=175.7785  steps/s=145.71  prediction: \"ode Solidworks\n",
      "$500/yr aint gonna cut it\" => \"n    t oe ddodo    os //0000 /00 t    nn\"\n",
      "batch 9375  loss=159.7118  steps/s=100.55  prediction: \"l modeling is a great one to add to this\" => \"yp @ eeaae     mi   aa   a    a  a      \"\n",
      "batch 9376  loss=160.3165  steps/s=96.76  prediction: \"7 make money so you can make video games\" => \" @ Tetllm7mem7 m o e  o   o   a    a   d\"\n",
      "batch 9378  loss=141.4465  steps/s=101.79  prediction: \"ob/business but.. its fun to think about\" => \" l            s sssssss sss  t     t   t\"\n",
      "batch 9379  loss=296.0905  steps/s=11.19  prediction: \"reply: @justalexoki He is the goat fr fr\" => \"eply: @ hh0kT_@w7jY,/xvvYDLyzz,Sr^z,KKKK\"\n",
      "batch 9380  loss=166.1581  steps/s=136.32  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"   /bsss s s    a t t    t      u    u  \"\n",
      "batch 9381  loss=170.8620  steps/s=102.65  prediction: \"rselves w builders i think\n",
      "\n",
      "and to build\" => \"eul     af9.1_xww15@/lv@!_wgb0,p5!\n",
      ",_fyc\"\n",
      "batch 9383  loss=176.7716  steps/s=96.56  prediction: \"re @ludwigABAP @sebby_builds hood braces\" => \"eply:  HtVS.T_xww@5fBlPM@BAPM@_p5!\n",
      "__fyc\"\n",
      "batch 9384  loss=156.3163  steps/s=100.95  prediction: \"t. good thing we still have comonad club\" => \"h   rh        gg    ii    li   oo       \"\n",
      "batch 9385  loss=197.1097  steps/s=21.02  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @d ddi   gg    ii    l  l oo       \"\n",
      "batch 9386  loss=161.2036  steps/s=139.46  prediction: \"builds 2012 but yet blunders mate in one\" => \"ettu isu i    i    2   t   e e   nn d   \"\n",
      "batch 9387  loss=169.3534  steps/s=62.65  prediction: \" @llamapuckey never visit sf without jug\" => \"@bebiisbd222222    e   t t e     an e   \"\n",
      "batch 9388  loss=165.8776  steps/s=122.55  prediction: \"athy @paulg @ylecun Been blocked by lex?\" => \"nhuoode pa@ ay @@@ u@@@@ l  u e en elee \"\n",
      "batch 9389  loss=176.1243  steps/s=92.78  prediction: \"Lynx the less you talk the more you walk\" => \"    od argn yy y lee lll s    e ee  eeee\"\n",
      "batch 9390  loss=155.3914  steps/s=104.11  prediction: \"itor as I was with 2 screens and a mouse\" => \"n     t   a                  s  s   s s \"\n",
      "batch 9391  loss=161.4650  steps/s=103.58  prediction: \"oing the deadline thing\n",
      "Works super well\" => \" n  at  tt   t     dedddieeiieiii e ee e\"\n",
      "batch 9394  loss=141.0677  steps/s=104.32  prediction: \"ideo of you doing some crazy stuff. damn\" => \"n  i o          o ooo ooo    o    o     \"\n",
      "batch 9395  loss=147.1251  steps/s=104.36  prediction: \" the game loop in zig, rendering in cuda\" => \"th te          t                 ee ii  \"\n",
      "batch 9396  loss=140.0597  steps/s=103.92  prediction: \"ont like tech leave\n",
      "\n",
      "bulking and cutting\" => \" t t    t ttt  t    eeeeeeeeeeee      nn\"\n",
      "batch 9397  loss=143.6377  steps/s=105.19  prediction: \"sions of significantly stronger models,â€¦\" => \" oe iooosooo oinsissisiiiiisiiinn nnnn n\"\n",
      "batch 9398  loss=177.5443  steps/s=100.62  prediction: \" 4am programming https://t.co/5THAY3txKR\" => \"tPst s     a     nmmm gtggtttt /////to//\"\n",
      "batch 9399  loss=160.6141  steps/s=88.55  prediction: \"eMTB How long until dingbots can do this\" => \" TBoa   r  m   ggngnnntg ttt/ttt  ottt t\"\n",
      "batch 9400  loss=139.3307  steps/s=106.14  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" rrna a  ae   aaa aaa    assssss//tt////\"\n",
      "batch 9401  loss=185.6248  steps/s=71.26  prediction: \"EsotericCofe i think i could add that in\" => \"R Eut spoolyti C!H@zj!b:-,!.z!!XL:8x!.FR\"\n",
      "batch 9402  loss=135.7584  steps/s=107.28  prediction: \"ta but those with a data engine: iteratâ€¦\" => \" st  ott tttttt ttt                    a\"\n",
      "batch 9403  loss=143.6667  steps/s=104.52  prediction: \"he gamer would make for some great games\" => \"e  e d                       m    e e e \"\n",
      "batch 9404  loss=165.5095  steps/s=101.55  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tide    n      n         // //t//////tt/\"\n",
      "batch 9405  loss=159.0012  steps/s=104.25  prediction: \"ks suuuuper well\n",
      "https://t.co/kQAcIS3etz\" => \"e,b @rs ss s  u uuu    uuuttttttt//t//tt\"\n",
      "batch 9406  loss=144.8017  steps/s=99.50  prediction: \"ntiers out there we dont even know about\" => \"g tB    r  o   ttt  ee   e e eeeeeee    \"\n",
      "batch 9407  loss=155.2700  steps/s=105.11  prediction: \"s the error correction mechanism go away\" => \" io w \n",
      "e\n",
      "r\n",
      " e r eer rrrerrrerreo co oocm\"\n",
      "batch 9408  loss=142.7153  steps/s=101.73  prediction: \"al hypotheses to search through and test\" => \"nl a  o  teotttptteteeee tt  hhhhhh hhh \"\n",
      "batch 9409  loss=177.9921  steps/s=83.70  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"et  o lotteeett  tsat   hh   o    r  rtt\"\n",
      "batch 9410  loss=164.9202  steps/s=105.95  prediction: \"for whatever they click on,play it w VLC\" => \" r tel oved eeevee  e ee e  e     l     \"\n",
      "batch 9411  loss=148.4799  steps/s=102.07  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \"or itae t e             ttttttstt/t/////\"\n",
      "batch 9412  loss=191.3549  steps/s=29.96  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly:  ae               t ttttttstt///////\"\n",
      "batch 9414  loss=165.9457  steps/s=111.00  prediction: \"azy like that. Cheers my English brother\" => \"n   hen n   e    t     e      e  e      \"\n",
      "batch 9415  loss=153.5834  steps/s=105.96  prediction: \"farming simulator but with a circle tool\" => \"on   ti iiii iami r  i    t    t        \"\n",
      "batch 9416  loss=145.6535  steps/s=103.25  prediction: \"ing and shipping is gonna grow immensely\" => \"ng oo  n  nnppp n ppiiininnngg g   g    \"\n",
      "batch 9417  loss=163.1465  steps/s=102.47  prediction: \"ly bc i want one https://t.co/AySfEijpuc\" => \"y: @  otr             t   ttttt//t/t//t/\"\n",
      "batch 9418  loss=205.8078  steps/s=96.03  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"   be   EEEEEEOOOOOOOOOtOtttt tw y wy y \"\n",
      "batch 9419  loss=160.7636  steps/s=85.87  prediction: \"ttler experimentation games are the best\" => \" e  cEs O OOOOeeEenttttttt at o  e  e e \"\n",
      "batch 9420  loss=154.3146  steps/s=104.58  prediction: \"ttempt to appeal to ipad kid generation?\" => \" e e expptttppp pt tpppp  a  p pa  e d a\"\n",
      "batch 9421  loss=141.0234  steps/s=104.48  prediction: \" could approximate non linear functionsâ€¦\" => \"tan  t t     o t    oooo oo  n  annnnnn \"\n",
      "batch 9422  loss=172.3221  steps/s=99.92  prediction: \"\n",
      "we'll see how things really play out ig\" => \"\n",
      "e  stro ru_FM@'21.@_F\n",
      "I('\n",
      "P,'(LP0v\n",
      "AMx!\"\n",
      "batch 9423  loss=159.3660  steps/s=103.29  prediction: \"sing way more efficient/scalable methods\" => \" ni   l t             fef eeeieeeceeeeee\"\n",
      "batch 9424  loss=154.8831  steps/s=100.27  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"eale  mt hxP~M@bjIH@..Ek(/LbpE:4X5vO\n",
      "kEY\"\n",
      "batch 9425  loss=163.8773  steps/s=97.21  prediction: \"effJezos Right to learn\n",
      "Right to compute\" => \" iuo eeesBeeee eseetttt  RRRttttht tttto\"\n",
      "batch 9426  loss=150.8956  steps/s=103.87  prediction: \"der the hood the better you can innovate\" => \" rndnt    n h  th e   tteeet e e      o \"\n",
      "batch 9427  loss=149.4088  steps/s=104.82  prediction: \"problems im overlooking, then solve them\" => \"lob  tn n           oooooooi ooooe oo   \"\n",
      "batch 9428  loss=135.3964  steps/s=104.17  prediction: \"s and had strong knowledge of the course\" => \" fi      d  dd          n               \"\n",
      "batch 9429  loss=155.5847  steps/s=94.85  prediction: \"TB you can just do things bro just do it\" => \"h Pe  aad      n   nn   d  o o    o   oo\"\n",
      "batch 9430  loss=194.1836  steps/s=79.35  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"eMTB yac MMM        Ett s tt   jjjjjojj \"\n",
      "batch 9431  loss=151.2473  steps/s=104.17  prediction: \"c too much attention + hasnt been solved\" => \"oI ie t   t    tt  tt t tttt     n    n \"\n",
      "batch 9432  loss=141.9305  steps/s=104.14  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" th     eeeee ee    e                   \"\n",
      "batch 9433  loss=150.9025  steps/s=96.67  prediction: \"ur gzip stuff? training on gzipped data?\" => \"s  r                i  iii  ii   iii    \"\n",
      "batch 9434  loss=146.4794  steps/s=99.04  prediction: \"nds like a super cool premise for a game\" => \"g   eo  ss s      s    o      pe    e   \"\n",
      "batch 9435  loss=185.6407  steps/s=27.58  prediction: \"ply: @sunsettler https://t.co/gCxzVkTiTl\" => \"ly: @s     s           o      oe    e   \"\n",
      "batch 9436  loss=132.0262  steps/s=108.35  prediction: \" local optima solution they got stuck in\" => \"tiee tt   t    t   tooooooooooooottttttt\"\n",
      "batch 9437  loss=163.4622  steps/s=105.33  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n th      EEEEE \n",
      "EEe    ::t::::///  ///t\"\n",
      "batch 9438  loss=158.5190  steps/s=101.18  prediction: \"ready having better days from this stuff\" => \"e ly  af cT,v,::bbDDDEPPvvxEEuEPPExxx.xQ\"\n",
      "batch 9439  loss=157.5663  steps/s=105.98  prediction: \" right now its just learning on the side\" => \"ter r     n             t   t    nn     \"\n",
      "batch 9440  loss=150.4304  steps/s=105.42  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \"gene  ,ed deeeeedeedeeeseeetsts///////tt\"\n",
      "batch 9441  loss=182.2674  steps/s=101.69  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"toegdg gg ig s   s    t  t  tt tttt/////\"\n",
      "batch 9443  loss=149.1837  steps/s=105.92  prediction: \"ppl who got rich playing 0 sum games tho\" => \"let  it       t        p         g      \"\n",
      "batch 9444  loss=172.1273  steps/s=102.24  prediction: \"de!!! Huge achievement\n",
      "\n",
      "What did u study\" => \"  n eeedudu!u  du   e e e e e eeeeeee t \"\n",
      "batch 9445  loss=157.1489  steps/s=104.01  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"g ee   vv  eeeeeeettttitttttstttttt////t\"\n",
      "batch 9446  loss=163.3790  steps/s=101.37  prediction: \" @discord I made my own bot from scratch\" => \"tgrcvidd sdddssndd    d         mr  o rr\"\n",
      "batch 9447  loss=144.9488  steps/s=105.21  prediction: \"thing I need to pay attention to, thanks\" => \"his  \n",
      "e is    e           t tttt tt  ttt\"\n",
      "batch 9449  loss=158.4369  steps/s=101.58  prediction: \"ng to close your eyes to and just listen\" => \"g mo      o   oo  o s  oo   o        s  \"\n",
      "batch 9450  loss=177.1838  steps/s=38.88  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @ n o  o   os  o s  oo            s  \"\n",
      "batch 9451  loss=147.2462  steps/s=118.31  prediction: \"te well is a powerful powerful advantage\" => \"hsto ciot  e   e            w ww l  a la\"\n",
      "batch 9452  loss=162.5986  steps/s=104.43  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"to D      e       e     tttt/////tt/zt/t\"\n",
      "batch 9454  loss=136.2934  steps/s=102.60  prediction: \" the skill ceiling is really really high\" => \"th             l   i iiii iillllllllllll\"\n",
      "batch 9455  loss=143.2133  steps/s=103.07  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "e e eeeeeeeeeee eeeeeee ee    e       \"\n",
      "batch 9456  loss=142.0549  steps/s=102.85  prediction: \"ant believe I havent been napping before\" => \"nd  e      e    ee eee eeeeeeeeeneen nnn\"\n",
      "batch 9457  loss=157.5974  steps/s=105.35  prediction: \"2 and 3 forever\n",
      "\n",
      "https://t.co/4TGEKmEHO0\" => \"1i ere e  e  e e     r eeee\n",
      "ett\n",
      "t\n",
      "/t/te/\"\n",
      "batch 9458  loss=152.3955  steps/s=104.64  prediction: \"/t.co/emubOEhMKJ https://t.co/Fxx5eUVcPp\" => \"tudt cttc///t/////ttttttth////tt////t///\"\n",
      "batch 9459  loss=151.1535  steps/s=104.09  prediction: \" to call in the big guns (aka @gizmobly)\" => \"tha            l                        \"\n",
      "batch 9460  loss=206.3738  steps/s=29.37  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly:  pa                            gg  g\"\n",
      "batch 9461  loss=180.8220  steps/s=149.75  prediction: \"ellectus @gfodor https://t.co/Emux6iPInC\" => \"      ltll tlll  tt   g/tt  //ttu66//gmðŸ›‘\"\n",
      "batch 9462  loss=145.5148  steps/s=105.63  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n ,t                      tttttttt////t/\"\n",
      "batch 9463  loss=158.2403  steps/s=103.64  prediction: \"makes a comeback they get a large reward\" => \"ere    s      a   a    e               e\"\n",
      "batch 9464  loss=199.2547  steps/s=30.83  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly:    a     aa  aaa   e             e e\"\n",
      "batch 9465  loss=151.8602  steps/s=134.85  prediction: \"ould get my ass handed to me for suuuure\" => \"    i     o  y m tt s   ta     d     r r\"\n",
      "batch 9467  loss=164.6306  steps/s=94.40  prediction: \"ellessen Last time was ~6:20am cali time\" => \" li lelelll se sss    t    e        uu u\"\n",
      "batch 9468  loss=181.4111  steps/s=60.27  prediction: \" @eyeofenceladus https://t.co/dIPbA0GNsC\" => \"@Sueleeeeesese  ss    t    6    aa   m m\"\n",
      "batch 9469  loss=179.2742  steps/s=62.23  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"   ktgeeeeeesel st  t t s  tm   aa  a00ðŸ›‘\"\n",
      "batch 9470  loss=168.8720  steps/s=120.39  prediction: \"dejavucoder roon was gpt5 the whole time\" => \" \n",
      "oeleeneneelll h ttt:ss:./t.  P9P  AAAðŸ›‘\"\n",
      "batch 9471  loss=172.7620  steps/s=105.43  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"t.coo ete/o//ttN/ttttttttt////ttc////ttc\"\n",
      "batch 9472  loss=146.9016  steps/s=104.76  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"thi ee         t                        \"\n",
      "batch 9473  loss=145.6843  steps/s=104.09  prediction: \"f scummy people getting more money/power\" => \" t h ea d      meeee eeeeee    mmemmeeoo\"\n",
      "batch 9474  loss=160.2276  steps/s=104.92  prediction: \"st tab\n",
      "\n",
      "other than that, not much so far\" => \"  to + tt o ttt t tttt tththtt  tt hh   \"\n",
      "batch 9475  loss=162.1236  steps/s=101.28  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly:l ot ppe  p      o   s   hoo oooh oo \"\n",
      "batch 9476  loss=152.0190  steps/s=104.41  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"esly d tck:L7T~.*:,Q:{)vm*k|8wqð˜€k}xÊœ:T8,\"\n",
      "batch 9477  loss=166.6735  steps/s=98.65  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"terle e e7 eae a\n",
      "\n",
      "hh\n",
      "tthttttoottttottt d\"\n",
      "batch 9479  loss=159.8691  steps/s=81.12  prediction: \"minglunatic @kuberdenis im also catholic\" => \"one   cehniaa  aaat tttettt  i  tt  toot\"\n",
      "batch 9480  loss=145.1659  steps/s=106.22  prediction: \"dates/incentives to fund ai safety stuff\" => \" mo oa aaaaeaeeenneeeeneennnnn  n    t  \"\n",
      "batch 9481  loss=216.4285  steps/s=102.55  prediction: \"ONE\n",
      "FREEDOOOOOM\n",
      "\n",
      "https://t.co/MAxrYM3cut\" => \"U HUGANEDEOEOOOOOEOOO\n",
      "ER \n",
      "\n",
      "\n",
      "M \n",
      "\n",
      "tMMMMM//\"\n",
      "batch 9482  loss=186.6209  steps/s=103.78  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"nd ai\n",
      "     ii    n  77  ds7777     ss s \"\n",
      "batch 9483  loss=148.2467  steps/s=105.32  prediction: \" and the professor thought it was a typo\" => \"tn i iiii i                             \"\n",
      "batch 9484  loss=145.8611  steps/s=104.74  prediction: \"ered into something super super powerful\" => \" estest  te  e  ee e  e  e  e se e eeeee\"\n",
      "batch 9485  loss=137.1946  steps/s=104.67  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" t tt ssssssssssseeeee ee ee            \"\n",
      "batch 9486  loss=141.3708  steps/s=105.42  prediction: \"in places where i found better solutions\" => \"ng to                   e     e ee ee ee\"\n",
      "batch 9487  loss=168.2917  steps/s=101.18  prediction: \"k man awesome work\n",
      "\n",
      "and super cool notes\" => \"ei   omam w ww wwwoww ooe wo    r r  ooo\"\n",
      "batch 9488  loss=144.0977  steps/s=106.20  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"te i     a a      oo  or or   rr rs     \"\n",
      "batch 9489  loss=149.6648  steps/s=104.88  prediction: \"ful if youre a complete beginner like me\" => \" lto    u     i     u e    e e ee eeee e\"\n",
      "batch 9490  loss=147.3048  steps/s=102.22  prediction: \"all of the theories that we could invent\" => \"nl   e           o     tt    t  t     e \"\n",
      "batch 9491  loss=140.5590  steps/s=104.41  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  itt ett te   e       i   i       d  d \"\n",
      "batch 9492  loss=161.0201  steps/s=100.72  prediction: \"ff has been helping ppl. I love humanity\" => \" y te m        e   e    e     pll    l l\"\n",
      "batch 9493  loss=147.3445  steps/s=106.73  prediction: \"cuda skills, so its a fun way to do both\" => \"ensedan        s  ss  ss  s             \"\n",
      "batch 9494  loss=154.9592  steps/s=100.85  prediction: \"ding man! Yeah lmk how it goes next time\" => \" no  nan   a a    a a a                 \"\n",
      "batch 9495  loss=154.4015  steps/s=104.41  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot yo     b bb  bb bb b b             o\"\n",
      "batch 9496  loss=151.1020  steps/s=104.46  prediction: \"s. im betting on that. but i am not sure\" => \"  y t t   t    t t  t t ttt tt          \"\n",
      "batch 9497  loss=172.4538  steps/s=74.76  prediction: \"yacineMTB Its addicting stuff be careful\" => \" c  y y  t t    tt tt t tt              \"\n",
      "batch 9498  loss=143.3781  steps/s=105.36  prediction: \" usually get out of distribution results\" => \"tstootiisusuuu o       t   t   tttt tt t\"\n",
      "batch 9499  loss=143.5149  steps/s=106.02  prediction: \"t on bad apple vs python library anyways\" => \"hmn tt hs          p  pp    pp       yyy\"\n",
      "batch 9500  loss=167.7358  steps/s=90.25  prediction: \"yan I have fun. does that make me a CEO?\" => \" c ieon   a a  p p    o    t a aaa  aaa \"\n",
      "batch 9501  loss=150.1001  steps/s=105.80  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"yy n d r ed e     e  t   ttttt////t//tt/\"\n",
      "batch 9502  loss=158.4436  steps/s=105.35  prediction: \" and functional, genius place for a blog\" => \"tnde   m  m      n  ninn n nn n  n  a   \"\n",
      "batch 9503  loss=142.9722  steps/s=102.10  prediction: \"al hypotheses to search through and test\" => \"nl  o e  teotttpoteteeeeeet thhhhhhhhhhh\"\n",
      "batch 9504  loss=149.9156  steps/s=100.84  prediction: \"farming simulator but with a circle tool\" => \" ne  n a tei iim  aa t    tt   t        \"\n",
      "batch 9505  loss=158.0522  steps/s=101.70  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" :eertsse??ss?? s    ts  st  ttttt////t/\"\n",
      "batch 9506  loss=172.4240  steps/s=58.61  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tjresss??  tr   s   stsstst//s//tt////ZZ\"\n",
      "batch 9507  loss=148.9281  steps/s=106.54  prediction: \"reason...\"\n",
      "Had this actually happen once\" => \"epl    t sH,O@x\"wH@j,I:\"\n",
      "HmPIUj:wy5kU,\"\n",
      "\"\n",
      "batch 9508  loss=145.1661  steps/s=100.97  prediction: \"just happen to have sicilian parents lol\" => \"ust l e       e  e    e        i   iaa a\"\n",
      "batch 9509  loss=139.3316  steps/s=104.74  prediction: \" selected\n",
      "\n",
      "Or better yet skip selection?\" => \"teesntiteeetteeteteeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 9510  loss=148.5873  steps/s=103.52  prediction: \"e context, like words, strengthen ideas?\" => \" s    o  o     t    e        e  etee eee\"\n",
      "batch 9511  loss=165.4647  steps/s=102.32  prediction: \"expected him to be maybe 55 or something\" => \" t  e   I  eee        ee  ee          5 \"\n",
      "batch 9513  loss=164.6059  steps/s=104.90  prediction: \"ame by making his brain care abt it more\" => \"ne o te memmmman     a  ii    aaa  ia   \"\n",
      "batch 9514  loss=147.7028  steps/s=103.88  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e  \n",
      "tteetheht hthh t tt tt       t   e d\"\n",
      "batch 9515  loss=174.8778  steps/s=58.74  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tleth\n",
      "e t eh  htht t at t a dd d d \n",
      "ieee\"\n",
      "batch 9516  loss=149.2632  steps/s=107.45  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"  c to   ererrrereeereeeee e se ee    i \"\n",
      "batch 9517  loss=146.5441  steps/s=104.76  prediction: \"er important first step towards progress\" => \"    g  o  p  p rr trtttt ts tttt  t rrrs\"\n",
      "batch 9518  loss=291.8564  steps/s=10.89  prediction: \"reply: @opaeoh ill lyk when i open it up\" => \"ea yt e nhv=/Xx@ZFwá´€/}x$#$ðŸŒ‘Éª|ðŸ˜­æˆ‘`#vâ€Få§fF/\"\n",
      "batch 9519  loss=138.7285  steps/s=109.49  prediction: \"g us to blow our fears out of proportion\" => \" te e  s                        oooooooo\"\n",
      "batch 9520  loss=149.8183  steps/s=97.21  prediction: \"c high entropy stuff that fits the curve\" => \"ous  taaa a aa o     r    ttffftfttt ttt\"\n",
      "batch 9521  loss=183.7943  steps/s=64.23  prediction: \"@liljuuliet this https://t.co/MmuaB56dUP\" => \"leamgaaat o t  h h   t ttfftt tt ttt   t\"\n",
      "batch 9522  loss=138.6287  steps/s=105.54  prediction: \"i is a smart idea to pitch to the public\" => \"ng so                       t   tt ttt  \"\n",
      "batch 9523  loss=153.5360  steps/s=104.66  prediction: \" absolutely mind blowing post all around\" => \"t  tlat tl llll  lllll   l  ooo  ll     \"\n",
      "batch 9524  loss=157.9406  steps/s=105.14  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u                      ttttttt//t//////t\"\n",
      "batch 9525  loss=146.9223  steps/s=104.41  prediction: \"e Bible has treasure but you have to dig\" => \" pdt  ti ii ttet    e e e e e   uu   u  \"\n",
      "batch 9526  loss=143.9971  steps/s=105.03  prediction: \" the most important parts of improvement\" => \"toet\n",
      "  oe  o  oo   ottt t  t ott   tt mm\"\n",
      "batch 9527  loss=142.4826  steps/s=104.67  prediction: \"d size to whatever you want which helps.\" => \" to t              ee  ee       w w w hh\"\n",
      "batch 9528  loss=156.1497  steps/s=78.39  prediction: \"nsettler cant spell family without AI :D\" => \"  oe ites tt     t e  ee    w whw wwhhh \"\n",
      "batch 9529  loss=157.7729  steps/s=106.72  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"trcnneet//tts///ttttthhtth:t//:t//ttp///\"\n",
      "batch 9530  loss=168.6585  steps/s=102.83  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"ne n   a da a ane aeo  eaa      re      \"\n",
      "batch 9531  loss=151.6822  steps/s=104.93  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \"hagtaa  at t t    t  t  ttt tt  t//xt///\"\n",
      "batch 9532  loss=153.9227  steps/s=100.34  prediction: \" yapping like lud mentioned sounds great\" => \"toni a  niniiiip      i       innnnnnd n\"\n",
      "batch 9533  loss=144.1066  steps/s=105.26  prediction: \"the world more, become more dysfnctional\" => \"hin a     e    te    eee eeeeeeeeee eeoo\"\n",
      "batch 9534  loss=146.5168  steps/s=104.09  prediction: \"forming around AI or aroumd a fear of AI\" => \" rms n  c     n       o      r  r  r    \"\n",
      "batch 9535  loss=143.5408  steps/s=103.05  prediction: \"have primitives if you look close enough\" => \"et  i  viviiiivvviviiiiii ii   o    ooo \"\n",
      "batch 9536  loss=172.2407  steps/s=103.40  prediction: \"up man youre gonna go far over the years\" => \"seee   e    e     e   n     n     r     \"\n",
      "batch 9539  loss=143.1420  steps/s=104.98  prediction: \"its bad but, it has pros you can play to\" => \"n   o ts sa s  st    t  t   s    s      \"\n",
      "batch 9540  loss=159.4308  steps/s=97.74  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e\n",
      "iy: eftdv..0,X1*^*,ÊŸðŸ‘ŒC#}â™‚*Z#J&fð—¶@l_D{#\"\n",
      "batch 9541  loss=145.9866  steps/s=103.47  prediction: \"just start working, and it doesnt matter\" => \"ust          t r   t  t   t rt  t  nttt \"\n",
      "batch 9542  loss=162.1157  steps/s=102.61  prediction: \"ing all my money https://t.co/IXXYEJUqHm\" => \"ng  e e   lll   l l           t t////XX/\"\n",
      "batch 9543  loss=179.0116  steps/s=89.35  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"epl : @sinCM4x@CGp_Ow,_k__WO,9:v1C.__!IX\"\n",
      "batch 9544  loss=167.8600  steps/s=104.63  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"ue xx                  \n",
      " \n",
      "\n",
      "\n",
      "\n",
      " ///o///111\"\n",
      "batch 9545  loss=145.7996  steps/s=104.49  prediction: \"t theres probably better stuff out there\" => \"hin ce es    e ebbb bbbbbbbtettttttt  tt\"\n",
      "batch 9546  loss=175.6960  steps/s=46.07  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \": @ e   t    b  bbb bbbbettttt ttttt  tt\"\n",
      "batch 9547  loss=190.4841  steps/s=60.33  prediction: \"ply: @ns123abc mad growth, what happened\" => \"ly: @e e     b ebbb bet etttt  tttt e tt\"\n",
      "batch 9548  loss=150.6936  steps/s=108.37  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tut tt attt t   uutttttttttttttttttttttt\"\n",
      "batch 9549  loss=177.0916  steps/s=99.80  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "hh  Ua  A    An4L'xz)LkRb,z\"'WFb)I\"P6FY\"\n",
      "batch 9550  loss=179.8215  steps/s=29.36  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly: @yu memm e        o    o    f t    n\"\n",
      "batch 9551  loss=145.8130  steps/s=107.00  prediction: \"g, or write something else in zig, later\" => \"  ia i         r i     t    ee iee e  e \"\n",
      "batch 9552  loss=167.6875  steps/s=91.86  prediction: \"gABAP why?? cause its fun and i like fun\" => \" Bi  ig  w  A    i??   se  n  n  n n  i \"\n",
      "batch 9553  loss=138.9759  steps/s=104.41  prediction: \" pays off immensely when I stick to them\" => \"trt  ttf ffffff ff   f         e        \"\n",
      "batch 9554  loss=153.9838  steps/s=100.24  prediction: \"ool\n",
      "\n",
      "yacine is really cooking over there\" => \"rltsy s s  o                   o    o o \"\n",
      "batch 9556  loss=164.1468  steps/s=108.26  prediction: \"ure Beautiful, and great choice of music\" => \"s  oA\n",
      "  oseiii    ll    a    o   oo    e\"\n",
      "batch 9557  loss=148.3116  steps/s=98.73  prediction: \"for getting me to read this btw, its fun\" => \" r  Sa ett t    t     te  e  t      t   \"\n",
      "batch 9558  loss=172.6338  steps/s=99.41  prediction: \"agreed\n",
      "try these\n",
      "https://t.co/c9RVGmZYrn\" => \"ne tos e  reeetreeeettteettttthttttst///\"\n",
      "batch 9559  loss=157.0966  steps/s=103.98  prediction: \"t habit of reaching for my phone is gone\" => \"hfn   ttt t tt h     h  h               \"\n",
      "batch 9560  loss=141.1710  steps/s=101.85  prediction: \" in this article\n",
      "https://t.co/8gCd6cnXXP\" => \"t  t sniniiiiiiiiiiittttttttttttttt/////\"\n",
      "batch 9561  loss=148.2209  steps/s=102.77  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" ts e   s           ssss                \"\n",
      "batch 9562  loss=167.9683  steps/s=93.91  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"hms a    n   n0 n00  a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      d  \"\n",
      "batch 9564  loss=148.5195  steps/s=103.19  prediction: \"g\n",
      "Especially the more complex things get\" => \" U n ononniioilllllllll   o   ee e e    \"\n",
      "batch 9565  loss=161.0888  steps/s=87.50  prediction: \"bly same, llms are so much faster though\" => \"eeoggngiollll lll  lll    e e h  h h  tt\"\n",
      "batch 9566  loss=172.5363  steps/s=104.53  prediction: \"er did failed\n",
      "\n",
      "ðŸ“ˆ My hit rate is only abâ€¦\" => \" yr   e vv   e   d         i  ii  t     \"\n",
      "batch 9567  loss=154.4768  steps/s=102.93  prediction: \" btw? or does onnx just work well enough\" => \"@atea ntt   t  n    o    n    s    w    \"\n",
      "batch 9568  loss=168.2444  steps/s=94.75  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"oneees e  nee  @@ jjjjo ooo    OOOOOOOOO\"\n",
      "batch 9569  loss=209.8194  steps/s=77.21  prediction: \"am_Kantor actually something came up rip\" => \"ni eMnB @nnanjo ajoooso   o OOOOOOOOOOOO\"\n",
      "batch 9570  loss=149.8283  steps/s=105.58  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tn tiiiiiiniiiiiiiiiiiiiiiiiiii         \"\n",
      "batch 9571  loss=160.1137  steps/s=105.97  prediction: \" quality than \"loading bar\" type writing\" => \"tuee  eet eetttet  t a   aaa \" a\"\"\"    t\"\n",
      "batch 9572  loss=154.3091  steps/s=104.76  prediction: \"se and 'magically' econ makes more sense\" => \" t a    e     aaa aaaaa  a ' aa  e   eee\"\n",
      "batch 9573  loss=148.5958  steps/s=106.04  prediction: \" did not answer. he just kept on yapping\" => \"tapae t t t                  e       t  \"\n",
      "batch 9574  loss=154.9868  steps/s=92.40  prediction: \"v ill send you a link around the 25th! ðŸ«¡\" => \"eo e  t e      n  n     k    kn     tn  \"\n",
      "batch 9575  loss=155.3756  steps/s=96.55  prediction: \"t new one is kinda Y shaped too in a way\" => \"ht e e sse n n    n   n a    dd d       \"\n",
      "batch 9576  loss=158.4569  steps/s=97.34  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"owleo oo ooo   naa  aaa   a ao   o o    \"\n",
      "batch 9577  loss=150.7106  steps/s=103.05  prediction: \" if they'll give you access to that zone\" => \"@n ie ei e i eeie  i i i   i    e     t \"\n",
      "batch 9579  loss=160.7057  steps/s=105.73  prediction: \"tem\n",
      "- SPHERE GUN https://t.co/tqM3ZpJCkN\" => \"hrs adddts   s  EEEEEEEEt t//////////ttt\"\n",
      "batch 9580  loss=177.9989  steps/s=84.62  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" deedus esEHGGHG H  t t ttttottttZtJJJJJ\"\n",
      "batch 9581  loss=156.9240  steps/s=105.29  prediction: \"he pot of gold at the end of the rainbow\" => \"e k t t     t o   o      t              \"\n",
      "batch 9582  loss=146.1170  steps/s=97.03  prediction: \"metimes you gotta take one for the cause\" => \"e o as   os  o o ttt t  to   tt    o  oo\"\n",
      "batch 9583  loss=154.0549  steps/s=99.58  prediction: \"oulda made stock cert flags instead, rip\" => \"nreamemaoss o  o ta    e    t     t    a\"\n",
      "batch 9584  loss=147.1781  steps/s=104.05  prediction: \"at can be beaten if you look hard enough\" => \"les ses sse ee aee   e                  \"\n",
      "batch 9585  loss=148.0934  steps/s=104.20  prediction: \"libraries or backend compute or anything\" => \"yke ee%deer er err rrrr r       e       \"\n",
      "batch 9587  loss=142.0372  steps/s=99.20  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"   o    e       eeeeeeeee              o\"\n",
      "batch 9588  loss=169.6752  steps/s=104.30  prediction: \"e77 build things people want/ need maybe\" => \" 7eo @Bce777777    iiii p     n   ee nen\"\n",
      "batch 9589  loss=154.7441  steps/s=101.36  prediction: \"ls similar to me\n",
      "larger battery capacity\" => \"y r@eirieei   is e     e  e rr t  aaaat \"\n",
      "batch 9590  loss=146.2148  steps/s=104.01  prediction: \"t immensely and give you new information\" => \"hine  e n e    n    e     e   e   n    n\"\n",
      "batch 9591  loss=147.2094  steps/s=100.31  prediction: \" v. move forward/backward is layer stuff\" => \"ten    ,  v              rrrrraraaaarr a\"\n",
      "batch 9592  loss=155.3896  steps/s=104.18  prediction: \"ed something about that, not sure though\" => \"  rs  eees eeseshe    t   h ttt ttttttt \"\n",
      "batch 9593  loss=143.6233  steps/s=102.94  prediction: \"ncing is just how things go in business.\" => \" us  a eneneiiin e i  s   i      i  n  i\"\n",
      "batch 9594  loss=147.5649  steps/s=99.25  prediction: \"s of lib arts classes they make you take\" => \" aarse esse ee e   ssss ssss  s s    e  \"\n",
      "batch 9595  loss=172.2767  steps/s=102.81  prediction: \"a have hella nostalgia in like 10yrs bro\" => \"tp  o n g e a h nnnaanea a lealnia ln l \"\n",
      "batch 9598  loss=138.2146  steps/s=104.76  prediction: \"t, bc you can edit/delete prompt history\" => \"h r  eatt a  t   c    t  tt  ee  e   ptt\"\n",
      "batch 9599  loss=149.8820  steps/s=104.52  prediction: \"nts also on the nm level, but, 3d not 2d\" => \"  om t nnnnnoo nn                       \"\n",
      "batch 9600  loss=147.6958  steps/s=103.87  prediction: \" company dgaf and you can contact those?\" => \"toye  e n a  a a a a  a   n a a n c c cc\"\n",
      "batch 9601  loss=152.4989  steps/s=103.74  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" an fo nn nn  o      e  ee  e  t t   ts \"\n",
      "batch 9602  loss=160.5355  steps/s=94.57  prediction: \"ure Beautiful, and great choice of music\" => \"re n   o tee eure uuu,  a   aa   at     \"\n",
      "batch 9603  loss=150.0973  steps/s=104.62  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"yere emr me e     e  t   ttttt ///t//tt/\"\n",
      "batch 9604  loss=152.1806  steps/s=96.50  prediction: \"o went too high. Looped back around to 0\" => \"nbew ewewoe o   hooo ho  ooo  ooo  oooo \"\n",
      "batch 9605  loss=138.6569  steps/s=103.64  prediction: \"quote a lot bc it seems to come up a lot\" => \"ueeeis         tt                       \"\n",
      "batch 9606  loss=203.0338  steps/s=104.13  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"A7 A7AAAAAA9A16191B19B1911131BA13A33333A\"\n",
      "batch 9607  loss=180.6339  steps/s=100.38  prediction: \"ke getting flashbanged by your teammates\" => \"  791  iii i i l t  g ggg e ge g       a\"\n",
      "batch 9608  loss=143.8138  steps/s=104.79  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t                 hhhhtttttttttttt//////\"\n",
      "batch 9609  loss=153.9265  steps/s=105.17  prediction: \"building logic gates and RAM and whatnot\" => \"lt ji l bi  i l  i   ggg g g g   a   a  \"\n",
      "batch 9610  loss=147.6728  steps/s=104.78  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \" i             n  e     e      e       a\"\n",
      "batch 9611  loss=142.6752  steps/s=104.58  prediction: \"people, i just post a weird mix of stuff\" => \"lr:    oo o                             \"\n",
      "batch 9612  loss=152.9964  steps/s=104.09  prediction: \"d virus that makes ppl cracked at scale?\" => \" a  oe i                     a   a   aa \"\n",
      "batch 9613  loss=176.1522  steps/s=67.40  prediction: \"@squirtle_says yacine what have you done\" => \"lelial di      aa a a      aa  aaa   a a\"\n",
      "batch 9615  loss=162.6783  steps/s=114.00  prediction: \"is the platonic form of a platonic form?\" => \"n  r   ee e s  t    tt     aao  ao  ao o\"\n",
      "batch 9616  loss=136.4621  steps/s=104.84  prediction: \"you can get a stronger 'muscle' for this\" => \" u   ot  to   t   t   t t        r      \"\n",
      "batch 9617  loss=159.9846  steps/s=104.09  prediction: \" still use the ideas several times a day\" => \"tei        s   ss   s ss  eessse seeee e\"\n",
      "batch 9618  loss=151.7550  steps/s=102.50  prediction: \"resting, what kinds of tools has he made\" => \"epl :g@ rhðŸ˜†â€™ðŸ¤”]ðŸ§ ð—¿IIL2vð—¶1BZ0Lð˜€2vð˜€BZÊŸIw0b{v\"\n",
      "batch 9620  loss=163.0575  steps/s=100.49  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \"gtre eaa  eet tet a  a       h    e ee  \"\n",
      "batch 9621  loss=141.8817  steps/s=104.11  prediction: \" put you so far ahead its not even funny\" => \"tril ol   l    u                        \"\n",
      "batch 9623  loss=152.1701  steps/s=89.12  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"nlinMTu to             t  tt    e   u   \"\n",
      "batch 9624  loss=196.0932  steps/s=104.93  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"tiry YYyyytmmmmm mt m ::t:::://t////////\"\n",
      "batch 9625  loss=142.6329  steps/s=105.00  prediction: \"robably dont ask 'will you be my mentor'\" => \"emd p  aan.!SMx~':'.YF'.A-/\".vFqXAFCKZYF\"\n",
      "batch 9626  loss=155.0539  steps/s=100.71  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"sdsn s an a  n nnn       e  e e n-------\"\n",
      "batch 9627  loss=141.4983  steps/s=104.17  prediction: \"stead of just knowing what they were, Iâ€¦\" => \" en m nenen    s   n        t  t        \"\n",
      "batch 9628  loss=145.3799  steps/s=102.33  prediction: \"y areas of corporate world it seems like\" => \" arann  n    a aa  rrroororr rr e       \"\n",
      "batch 9629  loss=165.7960  steps/s=72.48  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \"  aeeas   rrrr  n  s awww ww  w ttt   h \"\n",
      "batch 9630  loss=156.0906  steps/s=107.38  prediction: \"ad to give some direction/motivation tho\" => \"nv a   o t  oo too   oo   oooeioioiotiii\"\n",
      "batch 9631  loss=189.1749  steps/s=104.56  prediction: \" (to learn zig): https://t.co/tIgeHjq28P\" => \"tte oqQioo lzzz zzg t ggt g /tg:://ttg//\"\n",
      "batch 9632  loss=177.0037  steps/s=82.47  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"agl  oigo  gA    ttt tt////////t//t.tHHH\"\n",
      "batch 9633  loss=169.0320  steps/s=104.52  prediction: \"rselves w builders i think\n",
      "\n",
      "and to build\" => \"e an   iaf.KkQ74f1bfQlfzQQw:bQQQkk\n",
      "v7fww\"\n",
      "batch 9634  loss=144.3509  steps/s=105.02  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r o i       i i siiississssststttttt///\"\n",
      "batch 9635  loss=145.4102  steps/s=100.80  prediction: \" seen in a while\n",
      "https://t.co/TWiRoMqfMz\" => \"tee e e                      ///////////\"\n",
      "batch 9636  loss=180.9144  steps/s=104.39  prediction: \"/t.co/zlto3SBYwd https://t.co/vZrNZfgxps\" => \"/.cc#!tt/ts/t//ott//ttttt//t//tt/tt/t//Z\"\n",
      "batch 9637  loss=142.0679  steps/s=104.06  prediction: \"s are your own, and i need to prove that\" => \" tht t  b s    r                        \"\n",
      "batch 9638  loss=170.0823  steps/s=101.58  prediction: \"tiquing the zoomers that jump in his dms\" => \"hou ohe e rtuiiii  ei  t  too    t   t  \"\n",
      "batch 9639  loss=139.3883  steps/s=103.67  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  iu  eet t    e       i   i       d  d \"\n",
      "batch 9641  loss=148.4226  steps/s=103.41  prediction: \"ds (i think, music is not my strongsuit)\" => \"  g hs  s o      i  iii  i i           s\"\n",
      "batch 9642  loss=147.8008  steps/s=105.07  prediction: \"complete projects than 20 half done ones\" => \"or bnt    eeeeee  teeete      t     o o \"\n",
      "batch 9643  loss=173.3545  steps/s=96.49  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \" u oc c c7e e   o tattetttpphtt  toto 33\"\n",
      "batch 9644  loss=142.5110  steps/s=104.11  prediction: \"to work on things that make sense to you\" => \"h to  oy  o         o         t     t  t\"\n",
      "batch 9645  loss=162.5895  steps/s=89.69  prediction: \"ure Beautiful, and great choice of music\" => \" ea o   ore  uun    t   at  aae  ee    o\"\n",
      "batch 9646  loss=152.1960  steps/s=106.04  prediction: \" that initially seemed meaningless to me\" => \"ther  ret   ii tiili ieeeeeeei e eee e e\"\n",
      "batch 9647  loss=151.2291  steps/s=99.66  prediction: \"gh Ive been wanting to do a wasm project\" => \"  Aor oet      eeee e   n        a      \"\n",
      "batch 9648  loss=150.5556  steps/s=105.38  prediction: \"and notice way more over time\n",
      "I suspectâ€¦\" => \"nt nete  n   t      e   e   e  e e e  e \"\n",
      "batch 9649  loss=144.2986  steps/s=104.96  prediction: \"ered into something super super powerful\" => \" esta t  te  ee e  e  e  e    ee   eeeee\"\n",
      "batch 9650  loss=159.3883  steps/s=100.40  prediction: \" mind working better as you pay it back?\" => \"tooe n  o      n    i   r    e    e     \"\n",
      "batch 9651  loss=163.8313  steps/s=99.19  prediction: \"chine Uphill, both ways, in the snow too\" => \"o a ea   niiiiiniii t   h    ,          \"\n",
      "batch 9652  loss=151.2150  steps/s=99.34  prediction: \" a friend that did this for a CS project\" => \"@  i    i h   a    t d    t            o\"\n",
      "batch 9653  loss=141.5108  steps/s=100.90  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"un   e   o            e    eeee         \"\n",
      "batch 9654  loss=147.4690  steps/s=103.49  prediction: \"was making me sleep deprived unknowingly\" => \"ay   e    a   a      e  eee  eee eeee ee\"\n",
      "batch 9655  loss=151.1142  steps/s=105.15  prediction: \"s of useful packages python would be ded\" => \" ai       o   f      s              o   \"\n",
      "batch 9656  loss=148.8651  steps/s=105.32  prediction: \"ingly, doable) youre in for a goood time\" => \"ng  s r sryrrrr y yryyy or r  oo o  oo o\"\n",
      "batch 9657  loss=148.0959  steps/s=104.73  prediction: \"ranoid to install an extension like that\" => \"ecle: @een8A^ðŸ‘â€™)v)@~~~~A,~wDADDIDDDx,D\n",
      "T\"\n",
      "batch 9658  loss=170.6208  steps/s=98.96  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" tI  aoanna s   aa a    z  z n nll el lt\"\n",
      "batch 9660  loss=157.1476  steps/s=102.10  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" y a s                  stttsttt///////F\"\n",
      "batch 9661  loss=158.6568  steps/s=99.87  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"@f    b.....eetstttt  nn    n       i   \"\n",
      "batch 9662  loss=203.7668  steps/s=96.86  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"i  tnreeEEEEEEOOOOOOOOOaO     ww   wi   \"\n",
      "batch 9663  loss=142.2140  steps/s=102.68  prediction: \"o make a comeback. would be great to see\" => \" eeeo e                                 \"\n",
      "batch 9664  loss=153.6203  steps/s=104.78  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"ne n  t tttt  s stt tptp t tttptt/ttttt/\"\n",
      "batch 9665  loss=162.3703  steps/s=101.98  prediction: \"unches, then good luck ever finding them\" => \" tlee    e    en  h    o         e      \"\n",
      "batch 9666  loss=146.8873  steps/s=103.67  prediction: \"k in college it worked for me super well\" => \" ia b          c                      ee\"\n",
      "batch 9667  loss=185.0836  steps/s=105.89  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eple: @s rzG4!/â€¦G,%%%%W,%%W~,T3z~,,~~~1/\"\n",
      "batch 9668  loss=165.7984  steps/s=110.51  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" to  @  4e4ee  eea________ _ee   e  e   \"\n",
      "batch 9669  loss=148.0944  steps/s=103.38  prediction: \"ight radius\n",
      "Hmm 5px or 5%? Maybe 4.9%...\" => \"nA  u t rt t   t   t            5    %%%\"\n",
      "batch 9670  loss=144.9118  steps/s=104.66  prediction: \"eal interview round, not as a standalone\" => \" lio le  e  eeeneeeeee  n             aa\"\n",
      "batch 9671  loss=169.9198  steps/s=90.28  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lpp     eeeieiiii   i          a   la  n\"\n",
      "batch 9672  loss=155.0364  steps/s=106.63  prediction: \"ed something about that, not sure though\" => \"   i  sees eeheshe    t   h ttt ttttttt \"\n",
      "batch 9673  loss=157.1814  steps/s=83.14  prediction: \"amebedan since ports dont allow weapons.\" => \"lee  seesene e  i tt  t ttttt t t  tooo \"\n",
      "batch 9674  loss=132.0893  steps/s=105.79  prediction: \"to use resumes if lying becomes the meta\" => \"h e imi s ssssesessss     e  e     ee ee\"\n",
      "batch 9675  loss=142.1175  steps/s=104.59  prediction: \"it got like 2x fps rendering ocean waves\" => \"n                             e e  eeeee\"\n",
      "batch 9676  loss=150.2854  steps/s=104.48  prediction: \")\n",
      "RAG would be very useful for requestsâ€¦\" => \" Fr tct trt  oo       e    ee ue  u u uu\"\n",
      "batch 9677  loss=148.4444  steps/s=102.01  prediction: \"can be done in browser on frontend cheap\" => \"hlcte   t              n  n    n  onnnnn\"\n",
      "batch 9679  loss=149.0156  steps/s=104.90  prediction: \"e thing, not just messing around with it\" => \" 8iat ettttntt  tnt  t    tn      n     \"\n",
      "batch 9680  loss=170.3448  steps/s=98.49  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" tiag e n   e  e eesss____ __     i     \"\n",
      "batch 9681  loss=145.8794  steps/s=104.77  prediction: \" two next to each other. then a 4x4. etc\" => \"the ee eenett   t  tt   tt   t h    h . \"\n",
      "batch 9682  loss=163.8460  steps/s=104.68  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"0 -0a (  t  t      4  ttt tt ////ttp///p\"\n",
      "batch 9683  loss=173.6488  steps/s=99.26  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"ne oo    rt  tt     t tttttt  ///ctc/ttS\"\n",
      "batch 9684  loss=143.2920  steps/s=103.96  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"t         t t  t  ttttttttttttttttt////p\"\n",
      "batch 9685  loss=145.3852  steps/s=104.18  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"0 oca                 hhhttttthtt///////\"\n",
      "batch 9686  loss=151.1609  steps/s=101.23  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"taea  a  n                    o      oo \"\n",
      "batch 9687  loss=172.7304  steps/s=82.78  prediction: \"oppflightkid That could be helpful yeah!\" => \"nl a  p pff    f    a    o   eeoe ee ee \"\n",
      "batch 9688  loss=157.1148  steps/s=108.63  prediction: \"ace to your list https://t.co/dwHsPF5vJC\" => \"ni n oe t          tt ttttt  ttt tt/tt//\"\n",
      "batch 9690  loss=140.8061  steps/s=105.05  prediction: \"robably dont ask 'will you be my mentor'\" => \"ems i   anxLHMzâ€¦Tâ€¦'â€¦IT'â€¦Fâ€¦â€¦*,8â€¦â€¦b)N:KWW.\"\n",
      "batch 9691  loss=143.7785  steps/s=104.42  prediction: \"to rename all my .txt files to md though\" => \"  t e   t                      t  t  t  \"\n",
      "batch 9692  loss=157.9854  steps/s=102.95  prediction: \"bly helps that they have a faster ai now\" => \"ee h  bbob blll  hhlh h h hh h h  aaa   \"\n",
      "batch 9694  loss=159.9334  steps/s=44.77  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  @py pllpl lhl  h th h h  aha t   aa  e\"\n",
      "batch 9695  loss=168.8857  steps/s=108.92  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tosh    s      n     h      h  h hh  h h\"\n",
      "batch 9696  loss=144.7913  steps/s=104.53  prediction: \"light show swarm and rent it to concerts\" => \"yv   o              w           t    t  \"\n",
      "batch 9697  loss=152.0146  steps/s=105.39  prediction: \"how it is in c++. Trace them rays brotha\" => \"eu   e              +++++               \"\n",
      "batch 9698  loss=161.2807  steps/s=88.53  prediction: \"hones Hype, solid 4hr block, lets get it\" => \"ew                                r    t\"\n",
      "batch 9699  loss=142.7159  steps/s=105.26  prediction: \"ecurity bots monitoring my whole network\" => \" h o   r  e    t oooot oooto o o   o  oo\"\n",
      "batch 9700  loss=145.8516  steps/s=105.21  prediction: \"ney OR something extremely useful to you\" => \"d te e    n    e     eeeeeee eeeeeeeeee \"\n",
      "batch 9701  loss=141.8373  steps/s=103.81  prediction: \" life during hard times\n",
      "Thank God for it\" => \"tip iiii m i           i           d    \"\n",
      "batch 9702  loss=144.6431  steps/s=103.09  prediction: \"n people imagine\n",
      "https://t.co/ZYfaaoNir7\" => \"daie e  lne    eieeeeeeepeettttttt//////\"\n",
      "batch 9703  loss=138.9449  steps/s=104.44  prediction: \"an the last 5 bc of the skills he gained\" => \"nd e ee t e  t e                        \"\n",
      "batch 9704  loss=168.6557  steps/s=99.20  prediction: \"ped to have you join!!\n",
      "gl and have fun ðŸ«¡\" => \"lre t x l        o o  oo  !!  !  !  ae  \"\n",
      "batch 9705  loss=158.1557  steps/s=103.66  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf        r    i  i  i                  \"\n",
      "batch 9706  loss=147.1183  steps/s=106.10  prediction: \"learn thing -&gt; compress thing, repeat\" => \"yx  pe nrs\n",
      "n\n",
      "neengng ngg gtg t   g gg   \"\n",
      "batch 9707  loss=140.6780  steps/s=104.04  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \"he e e ee   eee eee    l l      t  rttrt\"\n",
      "batch 9708  loss=172.7963  steps/s=96.51  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"tlse heet       ett    t  tttttttt888888\"\n",
      "batch 9709  loss=148.5193  steps/s=103.97  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" ih an  .......s  o                     \"\n",
      "batch 9710  loss=218.4144  steps/s=20.76  prediction: \"eply: @tunahorse21 its really that good?\" => \"  yu .......   s  k                     \"\n",
      "batch 9711  loss=153.6532  steps/s=144.89  prediction: \"erIntellectus the italians have returned\" => \" si: @t IeeIItellletl l tt   tha  aeaeee\"\n",
      "batch 9712  loss=153.9668  steps/s=104.02  prediction: \" and mc write n\n",
      "\n",
      "https://t.co/7R6F8ZlLFS\" => \"tnd  n    n    n        tttttttttt//////\"\n",
      "batch 9713  loss=149.9876  steps/s=102.07  prediction: \"ful info have you learned from it so far\" => \" n  @oullul    u                        \"\n",
      "batch 9715  loss=153.7576  steps/s=97.95  prediction: \"tloader ah another tool builder, love it\" => \" e  n oobaoo ooooa ao o oorooo   oo     \"\n",
      "batch 9716  loss=160.8802  steps/s=103.84  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"ompet  rerrrrrr rr aaaaaa aaa a aa a a  \"\n",
      "batch 9717  loss=140.9797  steps/s=104.24  prediction: \" could approximate non linear functionsâ€¦\" => \"tan tt t    oo t    oo   oo  n  annnnnn \"\n",
      "batch 9718  loss=301.1956  steps/s=10.92  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"enlyohp c P,WM9Pz).x8z??(57G,2(???).??x2\"\n",
      "batch 9720  loss=138.9119  steps/s=108.38  prediction: \"file editing program, will show vid soon\" => \" n it   in ii itiiiii i iiii l l   i    \"\n",
      "batch 9722  loss=142.1245  steps/s=100.84  prediction: \"t. have they found the piece yet or what\" => \"    ei    t    t  t          eee eee  e \"\n",
      "batch 9723  loss=158.7898  steps/s=101.13  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"    toh ninee  e  e eetetieee  eee e e e\"\n",
      "batch 9725  loss=153.0706  steps/s=100.20  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"ngane araaaar aa r   aa    oo\n",
      "ooooo   tt\"\n",
      "batch 9726  loss=174.7370  steps/s=102.98  prediction: \" at 5:10 or something I just go til 9:10\" => \"tnd t  tt   t  t         t      t  t   t\"\n",
      "batch 9727  loss=161.4362  steps/s=98.24  prediction: \"r model architecture not based on tokens\" => \"eany:a yri103vA4b@A.bf@AgbI[ju:00,x}Ub(x\"\n",
      "batch 9728  loss=137.2971  steps/s=105.33  prediction: \"t you are in fact to blame for everyoneâ€¦\" => \" at i   aa   a                       e  \"\n",
      "batch 9729  loss=165.4950  steps/s=103.82  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"oad ea UU           tt\n",
      "\n",
      "t\n",
      "ttttt//////QQQ\"\n",
      "batch 9730  loss=155.8956  steps/s=105.63  prediction: \"but openai is cringe so obviously sonnet\" => \"et U    nn i   iiiiii i  i s ooooososooo\"\n",
      "batch 9731  loss=160.3202  steps/s=97.95  prediction: \"tony no but id be down rn for some games\" => \"  n t  e nonn    o  n   b            o  \"\n",
      "batch 9732  loss=172.0152  steps/s=94.27  prediction: \"d 1995 type sites are such a great style\" => \" t@r rno tn9  99 t  e    e           e  \"\n",
      "batch 9733  loss=178.7621  steps/s=39.59  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: @Wto99 99  9t e  see  ee          e  \"\n",
      "batch 9734  loss=143.6310  steps/s=110.29  prediction: \"works for the first time is the most fun\" => \"ark a e   o   or  r     r    t  t   t   \"\n",
      "batch 9735  loss=147.1069  steps/s=104.14  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yies t  s  e e ne eeleeeeleeeelllll\n",
      "\n",
      "\n",
      "ll\"\n",
      "batch 9736  loss=189.2109  steps/s=96.17  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"nk l rrereneee   e e\n",
      "    e t te////o/ooV\"\n",
      "batch 9738  loss=148.8576  steps/s=105.66  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"tha\n",
      "  tt t  a  t  t tthttttthtth///ttoot\"\n",
      "batch 9739  loss=234.9047  steps/s=11.74  prediction: \"reply: @gizmobly https://t.co/dgCgB3AN81\" => \"epli ialen@Bv_I)PMTM@BMfB\"(MTd=C=V::/:..\"\n",
      "batch 9740  loss=160.5697  steps/s=108.68  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tud  -    d  d d        a       s ss  s \"\n",
      "batch 9741  loss=144.6685  steps/s=96.17  prediction: \" sudo systemctl restart systemd-resolved\" => \"top       s  s sssssstsssttttsttttsssses\"\n",
      "batch 9742  loss=142.2473  steps/s=105.14  prediction: \"ly  small gif editing, it should be fine\" => \"y:  t  ce       llll   l   i   i    i  i\"\n",
      "batch 9743  loss=147.0783  steps/s=103.84  prediction: \"b, octane, trending on artstation 4k HD\"\" => \"e  a a,,, ,,,,    eee e n  nn nntnnnt   \"\n",
      "batch 9744  loss=166.9742  steps/s=97.64  prediction: \"ed\n",
      "Hes just gonna keep goin up from here\" => \"  3:d nedee    nnennn  n  t    no    o  \"\n",
      "batch 9745  loss=139.8068  steps/s=103.05  prediction: \"ust store those. skip the whole ML stuff\" => \"te t  tssse       ssss      t    h   e  \"\n",
      "batch 9746  loss=146.9567  steps/s=104.86  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"  eie n nn                       tt/////\"\n",
      "batch 9747  loss=156.0087  steps/s=102.32  prediction: \"ore descriptive titles for the rest lool\" => \"nk n    ene    neeiiiiiieee eettee e  tt\"\n",
      "batch 9748  loss=158.5702  steps/s=66.31  prediction: \"@calbch its gonna be a good one for sure\" => \"yacine  de iii eititt  ee t e   ee   or \"\n",
      "batch 9749  loss=161.7122  steps/s=112.16  prediction: \"reat book, glad youre enjoying it so far\" => \"epln: @aehbjM07~Im[bÊŸðŸ˜k,cTZ(bvvv,b[\n",
      "I,jÊ€\"\n",
      "batch 9750  loss=144.3611  steps/s=103.97  prediction: \"we need shape rotator models already smh\" => \"orn e   e ne  eseeee oee ooeeoo  oe aeaa\"\n",
      "batch 9751  loss=150.5391  steps/s=105.20  prediction: \"working yet btw) https://t.co/4orIleM0ID\" => \"ardsen   n      t t tttttttttttttt//////\"\n",
      "batch 9752  loss=152.0577  steps/s=101.97  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"ateien a anaaaa atttt tt t    ss  eeesse\"\n",
      "batch 9753  loss=135.9474  steps/s=101.80  prediction: \"learning is by doing stuff. For anything\" => \"y  hn gee  n                            \"\n",
      "batch 9754  loss=143.3837  steps/s=101.89  prediction: \"on mars we will make this a top priority\" => \"n    o         w                        \"\n",
      "batch 9755  loss=169.6046  steps/s=98.87  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" no  o    e     a k  ak   at  tttpo///tB\"\n",
      "batch 9756  loss=148.4692  steps/s=103.33  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n    a   o d   i  i   d AAAA d   i   d d\"\n",
      "batch 9757  loss=159.3492  steps/s=102.52  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"tdtr  ee e  ee  eaa anaattaattttt/t//t//\"\n",
      "batch 9758  loss=148.0236  steps/s=103.73  prediction: \"icians and is a net negative for society\" => \"n    a  tiiti  t          a             \"\n",
      "batch 9759  loss=147.7042  steps/s=100.65  prediction: \"farming simulator but with a circle tool\" => \" r   j ainii iin     n  ttt    t        \"\n",
      "batch 9760  loss=147.6763  steps/s=103.28  prediction: \"ven more\n",
      "\n",
      "repeat, positive feedback loop\" => \"eryn t\n",
      "tt\n",
      "\n",
      "\n",
      "\n",
      "eee\n",
      "\n",
      "\n",
      "\n",
      "eeeeeeeeeeeeee  eeee\"\n",
      "batch 9761  loss=157.5881  steps/s=95.98  prediction: \"ded something to edit gifs/clips quickly\" => \"     n  eeneeeen eoee tt e e  iiiii  iii\"\n",
      "batch 9762  loss=133.6824  steps/s=102.83  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"e id tttttt tttt  t     o      eeeeeeeee\"\n",
      "batch 9763  loss=167.5167  steps/s=103.38  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"ton nd      t !!!!!!!!t!!tttttttt//t//tt\"\n",
      "batch 9764  loss=148.5696  steps/s=102.15  prediction: \" figuring it out. it just clicked for me\" => \"tor nff  ff  i   i        t  t    t  t  \"\n",
      "batch 9765  loss=191.4802  steps/s=38.01  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: @oif fitf i t it    t  t  t          \"\n",
      "batch 9766  loss=149.5306  steps/s=109.78  prediction: \" the scaling laws for language models...\" => \"the r e  tt       t    l   l  g    ggg g\"\n",
      "batch 9767  loss=160.4962  steps/s=51.05  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @Nu e t e    t  s  lla   aa ga  lla ..\"\n",
      "batch 9768  loss=139.6164  steps/s=105.74  prediction: \" in those days will have had it too easy\" => \"tn m,\n",
      "ssns   ss s  s   ss               \"\n",
      "batch 9769  loss=170.9603  steps/s=98.25  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \" m     t0n   t0  00  hhha haaa  aa   l  \"\n",
      "batch 9771  loss=137.4579  steps/s=103.15  prediction: \"ive impact on me yrs after i had to stop\" => \"ne i   i i    it                        \"\n",
      "batch 9772  loss=152.6894  steps/s=102.51  prediction: \"rappers around statistical distributions\" => \"entyd  snhM92_;;xO@kjxz.:S/)jER/!j!8W:4!\"\n",
      "batch 9774  loss=190.9752  steps/s=29.41  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: @ e p srprr  r rsttsttattststistitii\"\n",
      "batch 9775  loss=150.3717  steps/s=136.26  prediction: \"per solid learning loop, love it love it\" => \"l i nNe psesle r rr   iiiillln  io   oo \"\n",
      "batch 9776  loss=146.1464  steps/s=100.34  prediction: \"hinks he might pick up in future decades\" => \"en  aeiinhn hhhhh  h h   i          u   \"\n",
      "batch 9777  loss=140.7357  steps/s=101.17  prediction: \" the first alien on earth thats so crazy\" => \"theteeeeee e   t e             tt  t t  \"\n",
      "batch 9778  loss=145.9935  steps/s=103.57  prediction: \" and use it on everything\n",
      "\n",
      "epiphany trap\" => \"t d  m  tte       e     ee ee  neeeeeenn\"\n",
      "batch 9779  loss=153.7492  steps/s=101.63  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"tnd   s                   s  tttt//////S\"\n",
      "batch 9780  loss=145.4917  steps/s=104.92  prediction: \"ite complexity? If not, what is the max?\" => \"n ie  ii iiiiiitiii i                   \"\n",
      "batch 9781  loss=138.7722  steps/s=103.00  prediction: \", or that would be fun/interesting to me\" => \" iuu      e    t               eettttttt\"\n",
      "batch 9783  loss=157.1916  steps/s=103.53  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" : f rsse??ss?  ?    ts  st  tt/tt////t/\"\n",
      "batch 9785  loss=156.0563  steps/s=103.17  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"  boo k  t  k     t  tt ttttttttt/////tt\"\n",
      "batch 9786  loss=146.7428  steps/s=103.54  prediction: \"uff and just pretending to do side stuff\" => \"tf n 00i n  n  f n    nn   d    dddd ttt\"\n",
      "batch 9787  loss=142.6260  steps/s=103.15  prediction: \"eeks but you get back your skill quickly\" => \"     ee    e   e   e             k    kk\"\n",
      "batch 9788  loss=149.0260  steps/s=100.41  prediction: \"forming around AI or aroumd a fear of AI\" => \" r sit  n     nn      o      r  o  r    \"\n",
      "batch 9789  loss=161.2186  steps/s=100.53  prediction: \"izer\n",
      "\n",
      "his uses a NN this uses Q learning\" => \"ne buua  slississsss ssNNNNNssss ss ss  \"\n",
      "batch 9790  loss=145.7366  steps/s=104.76  prediction: \"atrophy, you have to like, keep doing it\" => \"ni  to  t t  h h h                      \"\n",
      "batch 9791  loss=149.7697  steps/s=104.22  prediction: \"w zooming forward on an electric scooter\" => \"apu   n e o oo  wo ooo  o  on      ncc c\"\n",
      "batch 9792  loss=180.5819  steps/s=99.42  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tn   nwnn  o  nh          : t t: /t/t00/\"\n",
      "batch 9793  loss=145.6213  steps/s=100.55  prediction: \" android OS inside of a virtual machine?\" => \"tnd and d     dn dd d        i       i  \"\n",
      "batch 9794  loss=208.6745  steps/s=23.08  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @d    n  d  dd        i i       a  \"\n",
      "batch 9795  loss=142.2137  steps/s=108.76  prediction: \"yping on the terminal bc it looked cool)\" => \":e a    t i                             \"\n",
      "batch 9796  loss=155.9445  steps/s=101.07  prediction: \"u actually did the work so youre chillin\" => \"ntta ata  aaa a        t       o       o\"\n",
      "batch 9797  loss=170.3698  steps/s=102.63  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu cllc g g  g    7777777722 tt ////tc//\"\n",
      "batch 9798  loss=145.2296  steps/s=103.07  prediction: \"aking a day off caffeine helped fix this\" => \"ne non l aa aa aaa  aafaaff fffffe ffeee\"\n",
      "batch 9799  loss=152.2516  steps/s=100.47  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n  ss ss  ss siss                       \"\n",
      "batch 9800  loss=194.2984  steps/s=102.38  prediction: \" QUICK delete this before sphere sees it\" => \"thnrrsi r ll  K   K  t  t t  hh  e  nee \"\n",
      "batch 9801  loss=157.0466  steps/s=103.01  prediction: \"coordinates are busted\n",
      "just buy new ones\" => \"oulM  t aa   a rrar e a eeete     e   te\"\n",
      "batch 9802  loss=199.6660  steps/s=102.92  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"17 B2AAAAAA9A16191B19B1911131BA13A33333A\"\n",
      "batch 9803  loss=150.9424  steps/s=103.52  prediction: \"yself infinite runway to build fun stuff\" => \":  deie  n eiiiiiiiiin in     i      u  \"\n",
      "batch 9804  loss=146.8917  steps/s=98.03  prediction: \"ng sedenions for something in your game?\" => \"  d ty ey  inne snssns  ooo    o   o  n \"\n",
      "batch 9806  loss=143.4444  steps/s=102.09  prediction: \"now unless i need to paste in huge files\" => \"   omm t    ssss  s          e        ee\"\n",
      "batch 9807  loss=143.9558  steps/s=102.60  prediction: \"hange your brain. something to think abt\" => \"et  oo  ro   orr  rr rr  r     o  ni  t \"\n",
      "batch 9808  loss=142.4354  steps/s=101.52  prediction: \" which uses a superset of c. so not sure\" => \"thi cn c c c   c     ss s s s           \"\n",
      "batch 9809  loss=142.7589  steps/s=103.75  prediction: \"r) instead of giving you an easy way out\" => \"eile   a) 4H6M)BU6K_Kxzzzzxzz4@z?(zz)Z8(\"\n",
      "batch 9810  loss=144.8450  steps/s=105.06  prediction: \"re obvious. some are really hard to see.\" => \"e l . timw.T6M&w21:k\"\"--\"\"!!.4M!m(!!M!!ðŸ›‘\"\n",
      "batch 9811  loss=144.9167  steps/s=102.21  prediction: \"error signals, weakening backpropagation\" => \" seeeereerneeer r r  ennn  enkkkkkknaaaa\"\n",
      "batch 9812  loss=147.6782  steps/s=98.58  prediction: \"per solid learning loop, love it love it\" => \"lr:  Ner   sl  lel  innnnnnll oooo  ooo \"\n",
      "batch 9813  loss=134.1864  steps/s=104.98  prediction: \"en get way too absorbed into one of them\" => \"    I   t      t     ooooooooooooooooooo\"\n",
      "batch 9814  loss=170.9577  steps/s=98.11  prediction: \"ke to continue it. Mnist is a great idea\" => \"eng       t   on o t  ttn iti ti   ii   \"\n",
      "batch 9815  loss=171.4730  steps/s=96.24  prediction: \" a https://t.co/OmDwKUEq4p for gpt5, rip\" => \"tn  e s    stt /////tt///tttttUt  p tppp\"\n",
      "batch 9816  loss=156.8952  steps/s=99.12  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"Ab eeMe  t eeeeeeee eeee    s   ss   s  \"\n",
      "batch 9817  loss=163.5850  steps/s=104.31  prediction: \"ame by making his brain care abt it more\" => \"nm o t  memmmman     a  i     aaa  ia   \"\n",
      "batch 9818  loss=135.3802  steps/s=103.95  prediction: \"you can get a stronger 'muscle' for this\" => \":u ne    to   t   t   t t       '' '''' \"\n",
      "batch 9819  loss=181.5881  steps/s=30.68  prediction: \"ply: @yacineMTB sent from my xerox phone\" => \"ly: @yo  tt   tt  t   t      ''''' '    \"\n",
      "batch 9820  loss=150.3793  steps/s=109.94  prediction: \"rol you. why would they want to do that?\" => \"eblee ieppP*â™‚MTB7^@_NðŸ‘Zð—¶_NZ[[Ê€x[â€[x`kðŸ°..\"\n",
      "batch 9821  loss=157.2436  steps/s=94.25  prediction: \"builds It is factually what plants crave\" => \"ut tl tb l          t l  llt ll    ttat \"\n",
      "batch 9822  loss=163.1268  steps/s=101.04  prediction: \"azy like that. Cheers my English brother\" => \"ny ahe   e  e    t   e ee     e  e      \"\n",
      "batch 9823  loss=144.5870  steps/s=102.40  prediction: \"ings will continue until morale improves\" => \"nge P eeene e   ii   niinn  nni l      i\"\n",
      "batch 9824  loss=157.9427  steps/s=102.61  prediction: \"tus Even more bc this doesnt have alaska\" => \" f    tll ne e  e     e    o ee    ee se\"\n",
      "batch 9825  loss=147.4545  steps/s=105.18  prediction: \"house? where is your phone charger? etc)\" => \"ereeyo oe e  e re  e e      eo h  h rre \"\n",
      "batch 9826  loss=154.2093  steps/s=104.80  prediction: \"round PNGs in powerpoint xDDDDDDDDDDDDDD\" => \"emli  aaezMDz8PNG8888W88888x8WWWxjJJJJjX\"\n",
      "batch 9827  loss=161.4510  steps/s=95.47  prediction: \"Some Tal games are real art masterpieces\" => \"arer inmm   m    a   aa   ar   rar  r a \"\n",
      "batch 9828  loss=153.5023  steps/s=102.89  prediction: \"res a reason they dont but i dont see it\" => \"epli  e viMðŸŽ‰zSPNzITk,ï¸pTxbï¸ï¸ï¸%â€DDDDDDDDD\"\n",
      "batch 9829  loss=155.1337  steps/s=104.84  prediction: \" you can do the second without the first\" => \"tou  an n                     o      t  \"\n",
      "batch 9830  loss=150.0386  steps/s=100.47  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"tt  uua ttt  e eeeee eeeeeeeeeeeeeeee e \"\n",
      "batch 9832  loss=145.6630  steps/s=105.76  prediction: \" you should waste money\n",
      "&lt;/caveats&gt;\" => \"tou yi  n o    o   o      o     o aaaatt\"\n",
      "batch 9833  loss=162.6578  steps/s=100.98  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"  g me esettttetttteteeeeeeneeee i   i i\"\n",
      "batch 9835  loss=142.2283  steps/s=105.64  prediction: \"o have positive interactions its to grow\" => \"us t         o    i  ititiiitiiiiiiitttt\"\n",
      "batch 9836  loss=179.6408  steps/s=101.01  prediction: \"u helped a ton, hugely appreciate it bro\" => \"sc__ 1_111 h e    e ee     ee      pe pp\"\n",
      "batch 9837  loss=160.1497  steps/s=103.32  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" a1    n  n    n                        \"\n",
      "batch 9838  loss=147.0120  steps/s=99.17  prediction: \"ld me, no clue lool\n",
      "\n",
      "its good to be back\" => \"y  @ep eoo Te          llllool ooo ooo  \"\n",
      "batch 9839  loss=167.4888  steps/s=39.38  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y: @e   oo Te    ooll  llooool ooo oo b \"\n",
      "batch 9840  loss=184.3721  steps/s=113.77  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"ync_noeT ee e   oool  tt  oool ooo bo tðŸ›‘\"\n",
      "batch 9841  loss=153.2797  steps/s=106.04  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng     o                                \"\n",
      "batch 9842  loss=147.3022  steps/s=102.08  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \" _i idddididddddddttt t tttttttittccccc/\"\n",
      "batch 9843  loss=158.2723  steps/s=89.67  prediction: \"minglunatic @kuberdenis im also catholic\" => \"enov gicidiitt ettt tetetticiisiscccssss\"\n",
      "batch 9844  loss=153.3018  steps/s=103.16  prediction: \"h, that explanation/example makes sense'\" => \"e  'chh  h hh  aaaaaaaaaaaaaaaaaaaeeeeee\"\n",
      "batch 9845  loss=171.9735  steps/s=67.70  prediction: \"calbach_ thanks! hope its useful for you\" => \"onesi  a'hhhaaaaaataxaappeeteaaeeeeeeeee\"\n",
      "batch 9846  loss=154.3374  steps/s=108.61  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \" aw s   ss                              \"\n",
      "batch 9847  loss=148.4056  steps/s=103.14  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "Iteyr  e   e  cT!x9P9!!.?9I!9w!7Ib0!5I.\"\n",
      "batch 9848  loss=153.2075  steps/s=100.46  prediction: \"high quality patches they send to FFmpeg\" => \"enk    h lh    h h     hht    t    t  e \"\n",
      "batch 9849  loss=148.3755  steps/s=105.68  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" el lelolelelleoooooeee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tt/t/////t\"\n",
      "batch 9850  loss=156.1433  steps/s=104.34  prediction: \"n\n",
      "Took me from c to a student in college\" => \" \n",
      " ti ottoot ooo oo    t oo o  t o    t \"\n",
      "batch 9851  loss=146.2552  steps/s=103.06  prediction: \"icians and is a net negative for society\" => \"na  idtaiitti  ti         a             \"\n",
      "batch 9853  loss=149.8429  steps/s=104.79  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"edna n               t ttttttttttt//////\"\n",
      "batch 9854  loss=155.3652  steps/s=99.94  prediction: \" for yourself they pay dividends forever\" => \"toboo oooo oooooo    o    y    y y      \"\n",
      "batch 9855  loss=139.2781  steps/s=103.07  prediction: \"s using techniques right under our noses\" => \" cut o    on   s n          u   uuu u  u\"\n",
      "batch 9856  loss=175.9540  steps/s=87.30  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"_ynih  ntt ninhcninnnihhunuhu uu  nn nsn\"\n",
      "batch 9857  loss=178.7518  steps/s=103.42  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"e bt@ _  l P  PnBðŸŒ‘PzBAzxABz$$xzIG'GD&\n",
      "DT\"\n",
      "batch 9858  loss=157.6432  steps/s=102.41  prediction: \"ready having better days from this stuff\" => \"eply   dec72;D_0B,DSBAPxvvA;$bb'z6;&O6;T\"\n",
      "batch 9859  loss=152.0732  steps/s=98.40  prediction: \"imated stills have finally been defeated\" => \"ne aS aaadan nan  tee  s llle  a e   eee\"\n",
      "batch 9860  loss=163.5687  steps/s=95.72  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \" enoea  n ll   l t  f  f e   ee eoe teet\"\n",
      "batch 9862  loss=136.9599  steps/s=102.99  prediction: \"s using techniques right under our noses\" => \" pit o    on   u n        i uu  uuu u   \"\n",
      "batch 9863  loss=139.7020  steps/s=104.75  prediction: \"f you could 1.2x all the engineers there\" => \" yoalgaau$u  u  uu  d  l   l  l   eeeeee\"\n",
      "batch 9864  loss=150.0022  steps/s=104.89  prediction: \" by talking abt half done projects. BOOM\" => \"tene    nn     n                        \"\n",
      "batch 9865  loss=150.3684  steps/s=100.61  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n  ,n s   ss siss                       \"\n",
      "batch 9866  loss=156.5364  steps/s=106.10  prediction: \"rings out there that would just ruin ppl\" => \"enl$á´¡;&R$;1CQj,@&&-;11-0,-jv-k---BjjjwBk\"\n",
      "batch 9867  loss=152.5551  steps/s=103.80  prediction: \"ng cd /;sudo rm -rf * and pressing enter\" => \"   d  (  n     d                        \"\n",
      "batch 9868  loss=150.2890  steps/s=104.27  prediction: \"more friction than they need to function\" => \"edeis ah er    ot t tt t tn t     ee e t\"\n",
      "batch 9870  loss=147.0964  steps/s=106.22  prediction: \"complete projects than 20 half done ones\" => \"ou  na    eeeeee  teeete      t     o o \"\n",
      "batch 9871  loss=153.7710  steps/s=94.43  prediction: \"whoa thats wild, old twitter could never\" => \"ie  nte  ett  t  tha   t    tt t t to e \"\n",
      "batch 9873  loss=140.1574  steps/s=104.47  prediction: \"ast 3 weeks so development has been slow\" => \"n   eo   e       e  e  e eeee eeeeeeee  \"\n",
      "batch 9874  loss=157.7645  steps/s=100.04  prediction: \" @discord I made my own bot from scratch\" => \"tyrh ise sdsds sdd    d m       om  o   \"\n",
      "batch 9875  loss=159.7509  steps/s=105.24  prediction: \"w the game state https://t.co/jm2YeI7PB9\" => \"hyt            t e  t t  ttttt//tttet//e\"\n",
      "batch 9876  loss=153.4659  steps/s=101.89  prediction: \"e unbelievably interesting and beautiful\" => \" ge n    eb  beb bbebbeee eeee nnnneeenn\"\n",
      "batch 9877  loss=177.4800  steps/s=99.46  prediction: \"racticing self control leads to strength\" => \"eclr: @  r   r sG:kx'vkI'yfg'mkf\n",
      "w:;k;.;\"\n",
      "batch 9878  loss=151.2783  steps/s=100.02  prediction: \"ve you ever worked for a fast food chain\" => \"eluo ll   e e e  eee       r            \"\n",
      "batch 9879  loss=165.7308  steps/s=104.36  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "A  g nnnnnnnneeneepe pll              \"\n",
      "batch 9880  loss=132.4756  steps/s=101.50  prediction: \" a cross section now that you mention it\" => \"@  i k         s                        \"\n",
      "batch 9881  loss=132.8845  steps/s=103.61  prediction: \"tput something as unexpected as possible\" => \"hs  t ttt otttot   t           eeeee sss\"\n",
      "batch 9882  loss=172.1780  steps/s=100.56  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"e : x    l P l nB@PzBwzZmBzPbbz000\n",
      "z\n",
      "\n",
      "\n",
      "A\"\n",
      "batch 9883  loss=182.9279  steps/s=61.44  prediction: \" @pr0timr @btwphones Will post once done\" => \"@luiiimiem ge &e&;&&g;;;t;;;ggtgttgii ii\"\n",
      "batch 9884  loss=153.7266  steps/s=110.66  prediction: \" btw? or does onnx just work well enough\" => \"@une  ntt t t  n    o    o    o    w    \"\n",
      "batch 9886  loss=157.3774  steps/s=94.79  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" nt  oo   e    oo     o             sloo\"\n",
      "batch 9887  loss=139.6811  steps/s=102.35  prediction: \", or that would be fun/interesting to me\" => \" iuuel    e    t         u     tettttttt\"\n",
      "batch 9888  loss=169.2407  steps/s=99.19  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"hvt t  e tt tt        thntt  tttt \n",
      "     \"\n",
      "batch 9889  loss=140.8741  steps/s=105.13  prediction: \"r the picture\" for any industry or niche\" => \"etee  aees'm aedkv[#,W#ZTZ\"W,]#v#I'Tâ€¦v[#\"\n",
      "batch 9890  loss=186.7995  steps/s=98.65  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"ng oe yire reee  e ee    e httt////o/ooV\"\n",
      "batch 9891  loss=146.1408  steps/s=102.18  prediction: \"on the manager/grifter/sociopath problem\" => \"u  ee o o  o   ee eeer ererrr//rrrrrarrr\"\n",
      "batch 9892  loss=151.4170  steps/s=103.71  prediction: \"f undulation. You probably already knowâ€¦\" => \" I tr    nn   un    uoouoo ooooaaa aaaaa\"\n",
      "batch 9893  loss=227.2319  steps/s=65.06  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"lxctnunduffn  oo   oooooo   lOaaaa aaaaa\"\n",
      "batch 9894  loss=137.6729  steps/s=105.59  prediction: \"hem better bc you can do engine analysis\" => \"e   ct tt tttttt                    nnnn\"\n",
      "batch 9895  loss=149.3053  steps/s=105.01  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tet tt attt t   uuttttttttttttttttttt///\"\n",
      "batch 9896  loss=150.8635  steps/s=100.52  prediction: \"y is that the levels of learning theory?\" => \" tone e  l     ttt        ll      l e e \"\n",
      "batch 9897  loss=136.8831  steps/s=101.89  prediction: \"y noticed the last time i was there, lol\" => \":tz tMiieiiite ne  tttttt               \"\n",
      "batch 9898  loss=154.3754  steps/s=104.71  prediction: \"are is definitely a great career for you\" => \"n  orr  r n    e   e  e   e ee aeeee  rr\"\n",
      "batch 9899  loss=149.2831  steps/s=104.78  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"e g e y e ee   e eeeee ee eeeee eeeeeete\"\n",
      "batch 9900  loss=137.7184  steps/s=102.56  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "then          d=,==,====,v=w=,=========\"\n",
      "batch 9901  loss=142.7453  steps/s=101.72  prediction: \"d useful stuff better with the new tools\" => \" ss u luf eluuu uuuf u f   ette t tt  tt\"\n",
      "batch 9902  loss=157.8487  steps/s=96.99  prediction: \"ublic Refining my problem finder program\" => \"s diuuluilif  ii i  e  it      ee ee   r\"\n",
      "batch 9903  loss=156.1273  steps/s=103.23  prediction: \"100x bigger than the others\n",
      "\n",
      "I dunno lol\" => \"0xr0i ohas n   c~1å§Wx}jðŸ˜­}kvjÉ´Éª1[kx{`É´1æˆ‘k\"\n",
      "batch 9904  loss=145.3958  steps/s=103.51  prediction: \"ouraging way, not stressful for the kid)\" => \"u    igggegggggnnnnnnn                  \"\n",
      "batch 9906  loss=159.8565  steps/s=94.07  prediction: \"ezm progressive overload builds strength\" => \" so  agoegee   nos  esseee  or  s    s s\"\n",
      "batch 9907  loss=149.4527  steps/s=102.75  prediction: \"'ll see models get good at outputting it\" => \" lnner  eeeeeeeeeeeeeeee   o     oo  ott\"\n",
      "batch 9908  loss=154.5439  steps/s=102.24  prediction: \"you gotta gamify reporting spam bots lol\" => \":u ne g tto  oa    oo   o tg  g     ot  \"\n",
      "batch 9909  loss=144.0798  steps/s=97.65  prediction: \"TB elon lived in leafland for a bit iirc\" => \"B  a e n noe    l   iii  i n  a   a     \"\n",
      "batch 9910  loss=167.0125  steps/s=104.38  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"eoc+  eee//tte///ht/tttttp////hpD//DDp//\"\n",
      "batch 9911  loss=154.7865  steps/s=100.58  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"iilaTB t  r    r      o o     i i  i   i\"\n",
      "batch 9913  loss=148.2943  steps/s=104.60  prediction: \"an get immense alpha if you keep zooming\" => \"nd ooe    m  mmm e                      \"\n",
      "batch 9914  loss=158.6802  steps/s=97.29  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n    ne in ss    sa a aatatt tppp/p/p/pp\"\n",
      "batch 9915  loss=158.6043  steps/s=102.71  prediction: \"owed em all\n",
      "How tf do you find these ppl\" => \"u c eoolllolloollllll l  o              \"\n",
      "batch 9916  loss=139.9620  steps/s=103.92  prediction: \"started begging me to let him pay for it\" => \" ul      t     ggggggg gg               \"\n",
      "batch 9917  loss=143.4335  steps/s=104.05  prediction: \"nds like a super cool premise for a game\" => \"   oe   dn e      e    e       e    o   \"\n",
      "batch 9918  loss=168.6310  steps/s=104.23  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tor     sn     n     h      h  h hh  h h\"\n",
      "batch 9919  loss=141.9155  steps/s=104.98  prediction: \"sions of significantly stronger models,â€¦\" => \" oetiooosooo oinsissisiiiiisiinnn nnnn n\"\n",
      "batch 9920  loss=142.8355  steps/s=105.62  prediction: \"g/take a break from dopamine-exhaustingâ€¦\" => \" t so e nee aaa aaaa    a aa   aeaaaeaae\"\n",
      "batch 9921  loss=139.8868  steps/s=104.32  prediction: \"ether they are good or bad on their face\" => \"   de  ede eeeeeeeee                    \"\n",
      "batch 9922  loss=151.8279  steps/s=103.49  prediction: \" i found it really hard for some things.\" => \"tt   ii iio                             \"\n",
      "batch 9923  loss=147.1197  steps/s=101.55  prediction: \"ly know how many angels fit on a pinhead\" => \"y: I s le    ww w     n n    n          \"\n",
      "batch 9924  loss=141.7697  steps/s=101.66  prediction: \"improved from random initialization, no?\" => \"nes i     e  r rr rr  rr m iiiiiiiiiiiii\"\n",
      "batch 9925  loss=186.2529  steps/s=83.68  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yw @ ordeormdrrr om   eiiitiiiiiiaaii an\"\n",
      "batch 9926  loss=138.0159  steps/s=105.63  prediction: \"ot even remotely the same as a beginners\" => \"n s  s  e eeeeeeeeeeeeeeeeee            \"\n",
      "batch 9928  loss=156.7956  steps/s=103.60  prediction: \"owing that your food supply doesnt scale\" => \"u  i   tt  tt  ttt     oo      ooo  o   \"\n",
      "batch 9929  loss=150.9724  steps/s=87.68  prediction: \"neMTB i dream in ai generated js slop :/\" => \" M  a t i n       o           ee  sss s \"\n",
      "batch 9930  loss=172.0003  steps/s=104.73  prediction: \"rackpad &gt;&gt; 3 monitors + pc + mouse\" => \"ecly: @sit  ee n3B+v0\n",
      "b+k:x;0k,xk3&:jv3â€¦\"\n",
      "batch 9931  loss=182.0230  steps/s=99.10  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"toigsgnngii      n    t  t  tt tttt/////\"\n",
      "batch 9933  loss=163.8433  steps/s=44.73  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y  gNg+t +ns FF  tt   t  t  tt/t//t////t\"\n",
      "batch 9934  loss=131.7282  steps/s=118.38  prediction: \" learn if youre not an opening memorizer\" => \"toao                          nnnnnnn  n\"\n",
      "batch 9935  loss=284.6724  steps/s=10.99  prediction: \"reply: @CConnorMahoney mate in two* oops\" => \"eply: @yatB im BÉªI[J###^:#[:.cðŸ›‘.#*ðŸ¤£á´‡]1A{\"\n",
      "batch 9936  loss=150.0718  steps/s=114.28  prediction: \"ai car tire\n",
      "\n",
      "may not get smart money tho\" => \"t on oe aona   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a    a   aa  t     t\"\n",
      "batch 9937  loss=145.6149  steps/s=103.12  prediction: \"my ability to make things I want to make\" => \"e e ai i      it                        \"\n",
      "batch 9938  loss=176.7922  steps/s=95.81  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" ga l ii  u    jjeee tttttt  ttttt///tta\"\n",
      "batch 9939  loss=146.1519  steps/s=103.30  prediction: \"best way ive found so far to order tasks\" => \"e l eet tte  e t                   o    \"\n",
      "batch 9940  loss=159.2196  steps/s=94.62  prediction: \"wphones Love the plan, sounds meaningful\" => \"oho  s sese  e  e e      oo    oo oo  aa\"\n",
      "batch 9941  loss=139.8995  steps/s=104.97  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i   tt                t  tteeetetttt\"\n",
      "batch 9942  loss=157.2926  steps/s=102.63  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"toe  r e le  ru rrurrrrr   t ttttt//////\"\n",
      "batch 9943  loss=174.1068  steps/s=103.49  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"tn r sreaan aan#na  nnnnn tnnnst/ttt////\"\n",
      "batch 9944  loss=174.8451  steps/s=103.26  prediction: \": hold my beer.\n",
      " https://t.co/isMZrTmuiT\" => \" naicteantBaote .0:;j&.v-&&J.j!v,vM!!Tvâ€™\"\n",
      "batch 9945  loss=162.9691  steps/s=104.08  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e  ia  o n     n           ,,,,,,,,,,,1,\"\n",
      "batch 9946  loss=184.7838  steps/s=66.92  prediction: \"@IterIntellectus have you brrrytt today?\" => \"Btyiobn   ttt   t     , , ,,,  ,  11 1 1\"\n",
      "batch 9947  loss=185.2567  steps/s=113.53  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"ne n  t a  a  `` `      t t tttt ttttt /\"\n",
      "batch 9948  loss=168.7305  steps/s=101.22  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"mob op   tePe@eAPZ@ð—±vzk^bvv`{{|[g[]:|v[k\"\n",
      "batch 9949  loss=153.8472  steps/s=98.88  prediction: \"tremely good at using ai to build things\" => \" e e imeemmeeeet  et                    \"\n",
      "batch 9950  loss=146.2251  steps/s=104.06  prediction: \"n clarity from practicing visualizationâ€¦\" => \" t e eem mi    r rrrirrrriii  iciiiiaiii\"\n",
      "batch 9951  loss=162.6981  steps/s=94.65  prediction: \"77x im guessing you're super cracked huh\" => \"7  c  iitt    im i i  in  i    uuurra cc\"\n",
      "batch 9952  loss=140.5161  steps/s=103.83  prediction: \"r the picture\" for any industry or niche\" => \"eteee eees'e aeekvx^,WZá´‡TZ\"WÉª[á´‡ð—¼[I'T{~{[\"\n",
      "batch 9953  loss=135.4354  steps/s=104.24  prediction: \"through hoops\n",
      "\n",
      "its harder, until its not\" => \"henoe    t hhhhthhhhhhhhhhhh            \"\n",
      "batch 9954  loss=142.7755  steps/s=104.87  prediction: \"tiary structures. spirals within spirals\" => \"hn e marttarrttrrrtrrrstrrsssrrssiisiii \"\n",
      "batch 9955  loss=130.5620  steps/s=103.69  prediction: \"ot at the same time/in the same geometry\" => \"r e  t ttt tt   tt  t  t   e    e ee eee\"\n",
      "batch 9956  loss=147.9275  steps/s=103.59  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" t  e   s s         sssss               \"\n",
      "batch 9957  loss=153.8492  steps/s=97.71  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"eily: t tycl kee.R_RR.CRRPRPP9JSQCwYjDH_\"\n",
      "batch 9958  loss=191.6133  steps/s=46.31  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \": @ian               s    stt///////QQQQ\"\n",
      "batch 9959  loss=153.7447  steps/s=110.87  prediction: \" rivals\n",
      "\n",
      "but idk, i dont know the theory\" => \"tes o oolol    i d        dd           t\"\n",
      "batch 9960  loss=141.7598  steps/s=101.20  prediction: \"nd requires a phone app to connect to it\" => \"  9   k   ee eeeeee   e   p  p          \"\n",
      "batch 9961  loss=162.3816  steps/s=105.30  prediction: \"vars} complexity (O(f(n)) type stuff)\n",
      "-â€¦\" => \"eniworr eeer ee er e   (((((((()))))) ))\"\n",
      "batch 9963  loss=146.2247  steps/s=104.40  prediction: \"all a month ago\n",
      "Dang good stuff bro!!!!!\" => \"nly l             a aa aa  o oo  o oooo!\"\n",
      "batch 9965  loss=144.0605  steps/s=105.06  prediction: \" I didnt post AT ALL til it was 98% done\" => \"t  k    d d               L L           \"\n",
      "batch 9966  loss=135.2940  steps/s=105.31  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \"nse in  t                           eeee\"\n",
      "batch 9967  loss=147.2299  steps/s=102.87  prediction: \" sum bros.. pivot, its worth it trust me\" => \"tum  se e     .r.... oo      o ot   ttt \"\n",
      "batch 9968  loss=141.8664  steps/s=104.12  prediction: \"its bad but, it has pros you can play to\" => \"n  to os sa s  st    t  t   s    s      \"\n",
      "batch 9969  loss=140.1017  steps/s=104.12  prediction: \"reevaluating concepts you often overlook\" => \"e ln  ewst   r dZZ*ZÊœâ€á´¡ZZZ[|^|[[[É´\n",
      "á´˜]~èµ°]\"\n",
      "batch 9970  loss=136.7037  steps/s=104.13  prediction: \" the time. personally i havent done this\" => \"thes  t t    t t   e          l l      e\"\n",
      "batch 9971  loss=176.5329  steps/s=106.75  prediction: \"ecursive thread\n",
      "\n",
      "https://t.co/sc1GSL4fJx\" => \" t lt  rtheeerereehheetehetthtt/t//t//st\"\n",
      "batch 9972  loss=150.5936  steps/s=97.52  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"ym @rrteet te r thtiststsitttt ataa a ca\"\n",
      "batch 9973  loss=146.7700  steps/s=104.59  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"tuda a    an   i   i       i  i         \"\n",
      "batch 9974  loss=151.4947  steps/s=98.21  prediction: \"lly great post and great advice. thanks!\" => \"y  @ia m y ae  r   a     aa   a   aattta\"\n",
      "batch 9975  loss=143.5221  steps/s=103.18  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "e e eeeleeeeeee eeeeeee ee    e       \"\n",
      "batch 9976  loss=159.3718  steps/s=85.47  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"nt teee en e   peeee  e et t        s  s\"\n",
      "batch 9977  loss=134.3022  steps/s=104.11  prediction: \"answer in as few characters as possible\"\" => \"nd  ee ssss s  e       a  aa aaaassassss\"\n",
      "batch 9978  loss=127.3239  steps/s=103.84  prediction: \"aybe I need to grow more tomatoes though\" => \"n  ne     e   ee             ooooooooooo\"\n",
      "batch 9979  loss=232.1130  steps/s=98.22  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOOnOOOOOOOOOOOOOOOOOOOOOOttttt//ttt/\"\n",
      "batch 9980  loss=147.0380  steps/s=104.45  prediction: \"re for blundering bc of moving too quick\" => \"epln: @asi e iahOTOOOOOOOOOOOOOO/5q:I/Dq\"\n",
      "batch 9981  loss=145.9259  steps/s=103.16  prediction: \"gt; practicing them -&gt; mastering them\" => \" ;m   e  g n  tetttg ttgttg t;tttttgtttt\"\n",
      "batch 9983  loss=201.5330  steps/s=100.29  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \"oUtr&      I  I IIINNN N     h ee ee ei \"\n",
      "batch 9984  loss=141.6858  steps/s=102.93  prediction: \"ollowers type shit) he shouted me out\n",
      "\n",
      "g\" => \"n ill llle lll  e    e     e  h       e \"\n",
      "batch 9985  loss=151.5936  steps/s=104.15  prediction: \"\" and idk what that is? Time to learn it\" => \" hois\" iis          a     t   t         \"\n",
      "batch 9986  loss=153.6827  steps/s=103.66  prediction: \" you can do the second without the first\" => \"aou     n                     o      t  \"\n",
      "batch 9987  loss=138.5452  steps/s=103.05  prediction: \"ch though if i cant fix a particular bug\" => \"hen  t hhtthhhhh                        \"\n",
      "batch 9988  loss=147.2626  steps/s=102.52  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"yyre oos  e       e  t   ttttt ///t//tt/\"\n",
      "batch 9990  loss=134.2626  steps/s=104.92  prediction: \"ideo editor I posted earlier\n",
      "took 20mins\" => \"n     eeeeeee et    e    eee ee eoeeoooo\"\n",
      "batch 9991  loss=159.0896  steps/s=89.69  prediction: \"hag_ its good to be on the outside again\" => \"ed i    i to  oto  ooo    e eeoo oeoeooi\"\n",
      "batch 9992  loss=145.3433  steps/s=104.07  prediction: \"think you can do cdn type stuff w em btw\" => \" e     ott n   n  o   o     n           \"\n",
      "batch 9993  loss=172.0095  steps/s=30.66  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly: @  o       n  o   o                 \"\n",
      "batch 9994  loss=152.1412  steps/s=123.75  prediction: \"ne was right the rates arent high enough\" => \"gl    ian aa ii       r   tat  rth   eee\"\n",
      "batch 9995  loss=165.7795  steps/s=98.03  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"hi    i  nt tt0  h tt aarraa rgaa    g  \"\n",
      "batch 9996  loss=149.8272  steps/s=101.95  prediction: \"rappers around statistical distributions\" => \"entyd ki nu t wi*IZZjIk^~vZkjð—¶]ÊŸ^jâ€É´]ÊŸÊœ!\"\n",
      "batch 9997  loss=144.9240  steps/s=103.33  prediction: \"n just build cool fun stuff all the time\" => \" w he    n     u  u    uu uu   u l   ll \"\n",
      "batch 9998  loss=177.1486  steps/s=84.04  prediction: \"mobly @amix011 May do this in the future\" => \"ane  t u nu       u1 1 u   ff  l l   t t\"\n",
      "batch 9999  loss=149.8179  steps/s=105.75  prediction: \"worst part, as demonstrated by the graph\" => \"hrr  lt ee tttt   t     st t tt  t t   t\"\n",
      "batch 10000  loss=149.3549  steps/s=100.89  prediction: \"lity is really really powerful, actually\" => \"yo @iAwAPAt A     llll lllllyrlll   aall\"\n",
      "batch 10001  loss=186.8770  steps/s=80.53  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \" reliiliiiilyli l llll  l ttll //  aalll\"\n",
      "batch 10002  loss=164.6011  steps/s=106.40  prediction: \"ors let you get to the meat of it faster\" => \" e l a   lr   et      ttt  tett t t  te \"\n",
      "batch 10003  loss=157.9824  steps/s=105.19  prediction: \"ying/whatever, every monday and thursday\" => \":n longiin/gnginnenereeevereeeeeeey dddy\"\n",
      "batch 10004  loss=146.9014  steps/s=99.85  prediction: \" long long time\n",
      "\n",
      "https://t.co/svmrGr008p\" => \"@ot     n   o    g g    t  ttttt/tt/t///\"\n",
      "batch 10005  loss=142.7387  steps/s=104.66  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"p to    e   e   eeeeeeeee              o\"\n",
      "batch 10006  loss=160.3748  steps/s=51.76  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @n e   e  eee  ee eee e  o   oo     no\"\n",
      "batch 10007  loss=182.9293  steps/s=127.42  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yn @ e eoee e    ezzzee w  a  oo      iðŸ›‘\"\n",
      "batch 10008  loss=158.0647  steps/s=105.96  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \"rrar i\n",
      "\n",
      "l aLaaa aalallllllllllctuct/tt//\"\n",
      "batch 10009  loss=161.0019  steps/s=102.44  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"s  a a ss n    ononnnnoott/ntt/tt////t//\"\n",
      "batch 10011  loss=143.2428  steps/s=103.56  prediction: \"t (for example working when youre tired)\" => \" moush ooroo ooo o  o r     r       e   \"\n",
      "batch 10012  loss=144.2683  steps/s=104.91  prediction: \"me good advice\n",
      "What do you think of him?\" => \"o t     s e  ooo     ddo ooo o o        \"\n",
      "batch 10013  loss=142.8415  steps/s=105.53  prediction: \" and the professor thought it was a typo\" => \"t d  iiiaii                             \"\n",
      "batch 10014  loss=150.7392  steps/s=99.61  prediction: \"ly got above len=2 for the longest time.\" => \"y: @0iegta a   t o         e     e e e  \"\n",
      "batch 10015  loss=212.7671  steps/s=24.05  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @ t                   o     e e ee \"\n",
      "batch 10016  loss=147.5066  steps/s=108.59  prediction: \"problems im overlooking, then solve them\" => \"lob  t  nn           ooooooi ooooe oo   \"\n",
      "batch 10017  loss=152.9576  steps/s=69.58  prediction: \"sunsettler hes locked in to the outdoors\" => \" p nin  n   m   oo ooooko onnn ooeeeeoe \"\n",
      "batch 10018  loss=165.3557  steps/s=106.47  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "n  tennnnnnnneeneene lll              \"\n",
      "batch 10019  loss=148.5388  steps/s=103.15  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"neett tks\n",
      "m\n",
      "\n",
      "\n",
      "m mmmmm\n",
      "\n",
      "mm\n",
      "&&&;;;;\n",
      "\n",
      "\n",
      "tttu\"\n",
      "batch 10020  loss=163.0171  steps/s=102.44  prediction: \"is the platonic form of a platonic form?\" => \"n e o  ee e it te   tt      oo   o  c fo\"\n",
      "batch 10021  loss=171.5292  steps/s=61.18  prediction: \"@JsonBasedman just veto their veto, easy\" => \"lanleE ee e i  n    tt      to   o  o   \"\n",
      "batch 10022  loss=138.4063  steps/s=105.79  prediction: \"you have to learn in order to build them\" => \" ur s   s        e                r     \"\n",
      "batch 10023  loss=153.7305  steps/s=99.63  prediction: \"coder trust me bro im high iq, see above\" => \"om e  aar etee   r r     e              \"\n",
      "batch 10024  loss=189.9003  steps/s=58.01  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"traj ae e ett r rr r                   e\"\n",
      "batch 10025  loss=150.3027  steps/s=106.61  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"an  p          t   ttt  ttttttttttt/////\"\n",
      "batch 10026  loss=153.2920  steps/s=103.59  prediction: \"ang out in tunisia every once in a while\" => \"ny e i  t    t    t   i  n       nn    i\"\n",
      "batch 10027  loss=139.8215  steps/s=101.91  prediction: \"s and sugar and i dont get tired anymore\" => \" ahe  u  t aa asa a  a               d  \"\n",
      "batch 10028  loss=141.2114  steps/s=104.58  prediction: \"d stuff just happens. stochastic winning\" => \" so      d               ssssssssssssssn\"\n",
      "batch 10029  loss=190.2686  steps/s=37.74  prediction: \"ly: @justalexoki https://t.co/XmWFPd7zQu\" => \"y: g''n d     ut     ss sssssssssssssnnn\"\n",
      "batch 10030  loss=141.4719  steps/s=107.66  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"  e  etat   a  t   a       e e ee eeeee \"\n",
      "batch 10031  loss=189.5002  steps/s=30.40  prediction: \"ply: @2wlearning https://t.co/8ri7u6xMxw\" => \"ly: i t   g    a   a     eee eeee eeeeew\"\n",
      "batch 10032  loss=142.2639  steps/s=115.82  prediction: \" the gap\n",
      "\n",
      "down the energy gradient we go\" => \"th  t h                    eeeeegeeeeeee\"\n",
      "batch 10033  loss=145.3377  steps/s=103.77  prediction: \" your brain insanely bad in the long run\" => \"tou     r r  r r  r  aa   aa n   n    n \"\n",
      "batch 10034  loss=163.5324  steps/s=101.88  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"toeer    ett     t   to ttthhttt/////oo/\"\n",
      "batch 10035  loss=148.4079  steps/s=102.40  prediction: \"d xD but maybe its trying to communicate\" => \" so l l l   b  bb         t   t  t  i  t\"\n",
      "batch 10036  loss=223.7179  steps/s=100.25  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"hAP  OSOP  PP   SSUSE  S R   t /  / E/ 7\"\n",
      "batch 10037  loss=155.8152  steps/s=104.87  prediction: \"elf even if it overlaps with signoooling\" => \" lyllll lleee  f        e    i  i  iii o\"\n",
      "batch 10038  loss=135.5255  steps/s=103.66  prediction: \" one of the objects that could cast them\" => \"tf  a                    ttttttttttttttt\"\n",
      "batch 10040  loss=148.8272  steps/s=105.67  prediction: \"n and id 100% recommend it over The Goal\" => \" a aood d  d   d    00              e ee\"\n",
      "batch 10041  loss=130.3993  steps/s=105.19  prediction: \"endeavors im going to do til ive done it\" => \"  i   o ott                             \"\n",
      "batch 10042  loss=147.7182  steps/s=97.99  prediction: \"e ive been thinking the exact same thing\" => \" yo aeevvv e e e innn nnn  i       e    \"\n",
      "batch 10043  loss=146.8990  steps/s=100.09  prediction: \"ait to see what you cook up with giz inc\" => \"nv n  l   t    t  t t t    e    o   o  i\"\n",
      "batch 10044  loss=147.0169  steps/s=105.10  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tad ia ii itiit ii iiii r rr            \"\n",
      "batch 10045  loss=203.3446  steps/s=98.61  prediction: \"RAFT clone?????? https://t.co/LpT9VeD8p0\" => \" .iEa   ll l    ???????????  ttttt//////\"\n",
      "batch 10046  loss=164.7268  steps/s=89.39  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"nl a.l  l  l   ni    t tt  t/ ttto  pptt\"\n",
      "batch 10047  loss=165.6215  steps/s=105.54  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" si f   l  l            s   ttttt////c//\"\n",
      "batch 10048  loss=189.3333  steps/s=84.37  prediction: \"eigecamry @sunsettler shredded that shit\" => \" gs fi e ii   sm ssttssttts////thctJJqqq\"\n",
      "batch 10049  loss=155.4199  steps/s=105.36  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \"g\n",
      "ei sisiililiilillll    i              \"\n",
      "batch 10050  loss=170.1805  steps/s=45.85  prediction: \"ly: @0xbingllm we gettin it we gettin it\" => \"y  sinsiinllliilll h             a     a\"\n",
      "batch 10051  loss=150.4860  steps/s=135.44  prediction: \"v ill send you a link around the 25th! ðŸ«¡\" => \"eiaiiclllil  l n             r  a t d  t\"\n",
      "batch 10052  loss=141.4853  steps/s=105.01  prediction: \"cool ML/studying/building posts are gone\" => \"onaeoi    t    ooooo/ooiiiiiiiiiiiiigg g\"\n",
      "batch 10053  loss=155.2056  steps/s=105.63  prediction: \"he HTML/CSS to render (show) the webpage\" => \"e rmpu e e            e  r      e     ee\"\n",
      "batch 10054  loss=140.1457  steps/s=100.98  prediction: \"d work that into my current program haha\" => \" ih                             rrr rrrr\"\n",
      "batch 10055  loss=156.6304  steps/s=103.43  prediction: \"\n",
      "\n",
      "pride, however, stops error correction\" => \"\n",
      "tt   cm oe  no ML/C6?,xx6??xPxxTTv/kSS?\"\n",
      "batch 10056  loss=142.2131  steps/s=105.68  prediction: \"a good way to beat addictions in general\" => \"nf i w  s   o ooooo    a  aa aa   ii    \"\n",
      "batch 10057  loss=154.2897  steps/s=105.01  prediction: \" 10% is figuring out a fix + applying it\" => \"a0trere  te  i  ii       ii  i       i  \"\n",
      "batch 10058  loss=175.3331  steps/s=65.04  prediction: \"@ludwigABAP ever thought of moving here?\" => \"audeerx   i     ii    t  ii        i gg \"\n",
      "batch 10059  loss=185.6284  steps/s=118.40  prediction: \"re @ludwigABAP @sebby_builds hood braces\" => \"eply: @ ere  ensTp/vBjP`@BAPp@_vf?x_v0%9\"\n",
      "batch 10060  loss=155.5076  steps/s=99.82  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"e e  ge                 t tttt tttt/////\"\n",
      "batch 10061  loss=153.5512  steps/s=103.37  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" ioo tt  tt    n    ttt tttttttttt//////\"\n",
      "batch 10062  loss=150.5264  steps/s=103.56  prediction: \"the community give me energy to do these\" => \"he  e t t t    t    e    ee e e eeee  ee\"\n",
      "batch 10063  loss=156.7940  steps/s=102.01  prediction: \"... and 4\n",
      "\n",
      "idk about other spaces though\" => \" ..   .........n4.                      \"\n",
      "batch 10064  loss=149.5426  steps/s=104.42  prediction: \"times and pick up new details every timâ€¦\" => \"ho ks k  n     n        n      d    eeee\"\n",
      "batch 10065  loss=145.4626  steps/s=101.86  prediction: \"forming around AI or aroumd a fear of AI\" => \" rie    n nn  or      o  r   r  r  r    \"\n",
      "batch 10066  loss=151.9350  steps/s=102.83  prediction: \"your .env and fill it out\n",
      "\n",
      "then it works\" => \":urt  n  nn   en   n             t    tt\"\n",
      "batch 10067  loss=149.9431  steps/s=103.44  prediction: \"s, 30% make garbage, and 64% ruin things\" => \"   o  n g             aa aaaaaa         \"\n",
      "batch 10068  loss=156.0847  steps/s=103.42  prediction: \"ut you neeeeeed execution skill yourself\" => \"   ar arrrrrr  re  eee eeeeeeeeeeeee uou\"\n",
      "batch 10069  loss=147.2536  steps/s=103.72  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"y    aanyg    aaa    ttstttttttts/t//tt/\"\n",
      "batch 10070  loss=162.1827  steps/s=102.91  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nesod \n",
      " l  l             N :::::/t//////\"\n",
      "batch 10071  loss=156.0845  steps/s=104.62  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \" bo oiu utu  u      h  tttt ttttt/////QQ\"\n",
      "batch 10072  loss=169.9223  steps/s=101.81  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"aiatP_A@a@a aaa tataa s  s s     errrrss\"\n",
      "batch 10073  loss=136.1684  steps/s=104.76  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"eulys  coi  i  n!*vIG@*U:O@,,KKKOKIECY(I\"\n",
      "batch 10074  loss=162.1918  steps/s=45.56  prediction: \"y: @astroButter @karpathy @MagnusCarlsen\" => \"  @peor rrtrtterrttttttarreereetttttteee\"\n",
      "batch 10075  loss=151.4695  steps/s=118.27  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ng a    l n    n     n    tttttttttttt//\"\n",
      "batch 10077  loss=158.1904  steps/s=99.50  prediction: \" joining man, looking forward to thurs!!\" => \"auts neon nonn n ononoonnnn ooooo      r\"\n",
      "batch 10079  loss=149.1355  steps/s=104.14  prediction: \"ot of politics is reinforcement learning\" => \"uh o oo on ooo   iliii iiir irr r  r rnn\"\n",
      "batch 10080  loss=170.0354  steps/s=59.53  prediction: \"@squirtle_says yacine what have you done\" => \"auboor_  o to    i  iiiini ert  e rrrnnn\"\n",
      "batch 10081  loss=147.0317  steps/s=106.72  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hem s            thttttttttttttttttttt//\"\n",
      "batch 10082  loss=148.6063  steps/s=103.57  prediction: \"the community give me energy to do these\" => \"ha  e t t t    t    e  e ee e e eeee  ee\"\n",
      "batch 10083  loss=137.0352  steps/s=101.60  prediction: \" of the tier lists of all time, for sure\" => \"tf   o oon       e  e        t          \"\n",
      "batch 10084  loss=144.6449  steps/s=103.91  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"nl\n",
      "\n",
      "ntn nntnnnitttttttitttttttttttttt///\"\n",
      "batch 10085  loss=165.6228  steps/s=94.25  prediction: \"ped to have you join!!\n",
      "gl and have fun ðŸ«¡\" => \"lrt   t n     ta t t  aa t!!/ !oaanass  \"\n",
      "batch 10086  loss=220.9050  steps/s=11.89  prediction: \"reply: @dwbypass https://t.co/k3grlVSm53\" => \"eply: @0 ee eo hp.LWv'Rkjv,juv3!jNVd!!bH\"\n",
      "batch 10087  loss=141.0527  steps/s=108.67  prediction: \"indirections/abstractions/contexts oh ok\" => \"ngesl  lllliiiiiiiiiiiiisssssssstttttttt\"\n",
      "batch 10088  loss=144.8309  steps/s=106.69  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"  lieiiidededde  ddtdoddnooooootoooo    \"\n",
      "batch 10089  loss=150.3553  steps/s=81.11  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"e on ie ta  ooo oooo ooo  o    n o l  il\"\n",
      "batch 10090  loss=140.4586  steps/s=105.47  prediction: \"your post and are considering followingâ€¦\" => \"ou   lp  p              o    o   ooooooi\"\n",
      "batch 10091  loss=263.1561  steps/s=11.09  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"e lhz  ine   oe )*D/**GYj*:'Y**xxx)x:(3.\"\n",
      "batch 10092  loss=147.7538  steps/s=140.36  prediction: \"lly great post and great advice. thanks!\" => \"y e  raea  aa ara  a    eaa   d a da   e\"\n",
      "batch 10093  loss=141.8691  steps/s=104.39  prediction: \"e usually surrounded with those coloredâ€¦\" => \" yane e er r  urruuuluuuuuuu ud     e   \"\n",
      "batch 10094  loss=162.1003  steps/s=106.52  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"eheer  oy i tjo @/jz!:!,f.:/fD.Yx,D3Y(Jâ€¦\"\n",
      "batch 10095  loss=148.4022  steps/s=104.04  prediction: \"ich is a suuuuper good thing to practice\" => \"ne  o  cs    suuu uu    uuuu    u     o \"\n",
      "batch 10096  loss=146.6996  steps/s=102.80  prediction: \"rol you. why would they want to do that?\" => \"eble tis eiseeeiNk@PN$ká´€_N$vá´‡æˆ‘|$â€kfÊŸ$ðŸ˜‰..\"\n",
      "batch 10097  loss=148.4220  steps/s=102.71  prediction: \" easy to use too\n",
      "https://t.co/EjkhiWdtX3\" => \"tdoenee nt     s    tttttttttttt///////t\"\n",
      "batch 10098  loss=185.3221  steps/s=104.02  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"h    \n",
      "th tt//tttt FtCWCtCtt////ttt.F/FF/\"\n",
      "batch 10099  loss=175.8499  steps/s=81.23  prediction: \"phones Thanks man! its going well so far\" => \"lot/ ottonossssb\n",
      "htt st//tt////totHooVoF\"\n",
      "batch 10100  loss=158.5797  steps/s=106.12  prediction: \"hts move away from the edge of the board\" => \"e 's l         a         e  e e  oe   oe\"\n",
      "batch 10101  loss=140.1315  steps/s=104.50  prediction: \"conflicting values it would be a paradox\" => \"onve  a ll llllllllliiii i              \"\n",
      "batch 10102  loss=143.4787  steps/s=105.37  prediction: \"nds like a super cool premise for a game\" => \"t  t  t ln             e      ee    o   \"\n",
      "batch 10103  loss=138.3435  steps/s=104.06  prediction: \"entation, the cooler everything will get\" => \"  to  to motttetttttoooeeeeeeeee eeeee  \"\n",
      "batch 10105  loss=204.8412  steps/s=20.42  prediction: \"eply: @MafiaJoeg https://t.co/kGkkdevlHa\" => \" ly: @tototttttootoooeeeeeeeeeee ee  e  \"\n",
      "batch 10106  loss=147.3630  steps/s=120.11  prediction: \"there like this?\n",
      "https://t.co/ZF2p1Q4n6L\" => \" ef o t    e    e e tttthhttttthtttttttt\"\n",
      "batch 10107  loss=217.4444  steps/s=96.81  prediction: \"ch WHOA WHOA YOU WOULDNT DOWNLOAD A LEGO\" => \"oeae a  r  W  AAWWWOAOUOUOU OOWWDODDLNLL\"\n",
      "batch 10108  loss=178.3776  steps/s=104.62  prediction: \"/t.co/zlto3SBYwd https://t.co/vZrNZfgxps\" => \"/.ccohtt/ts/t/to/t//ttttt:/t//tt/tt/t//Z\"\n",
      "batch 10109  loss=144.9312  steps/s=103.18  prediction: \"its bad but, it has pros you can play to\" => \"n   o o  sa s  st    t  t   s    s      \"\n",
      "batch 10110  loss=164.8612  steps/s=98.08  prediction: \" ...but will it work, thats the question\" => \"t.rts\n",
      "\n",
      "A.t...  bt  i    t  ttt  tt t  ts\"\n",
      "batch 10111  loss=216.2138  steps/s=104.23  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \" %KWzTT0lllTl00lMMtM03ML30LL00444tt0ttto\"\n",
      "batch 10112  loss=190.7893  steps/s=37.24  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: lq9a2 VVV90MMMMtMLO0LF0L444tu0ttottto\"\n",
      "batch 10113  loss=173.2093  steps/s=113.10  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \" poi cfo   f  o  o o o  o t  tt ottoooot\"\n",
      "batch 10114  loss=145.6069  steps/s=103.94  prediction: \"and completely unknown to the other half\" => \"nd o o  l  llllllllll  nnnnnnnn         \"\n",
      "batch 10115  loss=207.0006  steps/s=20.78  prediction: \"eply: @yacineMTB https://t.co/H0UMjZbPTA\" => \" ly: @l l llllllllllnnnnnnnnnn          \"\n",
      "batch 10116  loss=147.5473  steps/s=106.85  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" ieeu t rte r  trr   r o oroo o ooo o oo\"\n",
      "batch 10117  loss=139.4069  steps/s=103.91  prediction: \" different distribution of training data\" => \"tov eeeeee  e eeeeeeetttiititiiiiiiinini\"\n",
      "batch 10118  loss=149.0044  steps/s=103.41  prediction: \"ng sessions for now for the discord name\" => \"t  t a\n",
      "ll iis  nssioo  os  oo  oo  oo  o\"\n",
      "batch 10120  loss=152.7139  steps/s=96.37  prediction: \"w site! Not gonna say much til it's done\" => \"aIone  eesen   NN   oo         n   i    \"\n",
      "batch 10121  loss=141.1433  steps/s=102.18  prediction: \"t progress/mistakes made/lessons learned\" => \" ro eo o  sr rssrrssssssseesssseessessse\"\n",
      "batch 10122  loss=150.5213  steps/s=102.03  prediction: \"it all up, and chatgpt is in on the scam\" => \"n  sa        la                         \"\n",
      "batch 10123  loss=166.6675  steps/s=85.66  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"e ly: @thgsrcheoTI@M!VNy1!!N,!q0zk,W!PT,\"\n",
      "batch 10124  loss=142.0077  steps/s=104.88  prediction: \"ind. also so my brain doesnt deteriorate\" => \"ng go   dd                             r\"\n",
      "batch 10125  loss=142.4892  steps/s=102.36  prediction: \"fundamentals is a smart smart smart move\" => \" l  an aena ta ta       as as s sssmma m\"\n",
      "batch 10126  loss=146.2542  steps/s=104.83  prediction: \"dering what was on that list, thanks man\" => \"  a i  e nen   w    w           tttttt t\"\n",
      "batch 10127  loss=145.1966  steps/s=104.73  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne  o    mim mieeememeeemeeee eee eeee e\"\n",
      "batch 10129  loss=160.8013  steps/s=100.27  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \"    p adhr d ddddd addd d d n     n     \"\n",
      "batch 10130  loss=151.7613  steps/s=104.32  prediction: \"r months or yrs\n",
      "\n",
      "https://t.co/7N4QDEMGnO\" => \"eme d   ml t i eR:DO,LEz#q,L:7#4vRR:7N4.\"\n",
      "batch 10131  loss=159.9129  steps/s=99.67  prediction: \"tony no but id be down rn for some games\" => \"  t t  oononn t  o  o   o            oo \"\n",
      "batch 10133  loss=166.2095  steps/s=100.93  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"emny  @  o  ie iR-&O,;/w$.v-&uN;-wE:;NO.\"\n",
      "batch 10134  loss=157.8846  steps/s=99.28  prediction: \"ct\n",
      "\n",
      "also, interesting advice in the clip\" => \"o ae  oootroo ooootteteeeeiiniii tiii i \"\n",
      "batch 10135  loss=145.8898  steps/s=101.66  prediction: \"s. let the people decide. for danmocracy\" => \"  ule teett eee ee eee eeee ee e ddd d  \"\n",
      "batch 10136  loss=133.6130  steps/s=105.77  prediction: \"they are more than happy to pay for them\" => \"herhe e  eteeeeee   e     h  p   p   p  \"\n",
      "batch 10138  loss=151.7147  steps/s=101.25  prediction: \"he building -&gt; increase skillset loop\" => \"ar ai   i i iiiiiiiigi  i i    ii ss ssl\"\n",
      "batch 10139  loss=149.9587  steps/s=101.37  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \"hi   hook     ht                o 000000\"\n",
      "batch 10140  loss=152.0426  steps/s=104.19  prediction: \"/t.co/dWiO4erSb1 https://t.co/VaQuvIKJWu\" => \"/.dqpp tt///t//toottttttt::t//tt////t//.\"\n",
      "batch 10141  loss=140.1789  steps/s=102.83  prediction: \"to a prompt, auto copied to my clipboard\" => \"  y  t t        t t       o    o      o \"\n",
      "batch 10142  loss=141.0793  steps/s=101.47  prediction: \"ols is kinda like cookie clicker but irl\" => \" lo ioi itiiii ii iii i  i  iikkkkckkc  \"\n",
      "batch 10143  loss=201.1943  steps/s=100.73  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"/.cc s l/t//tt/lt/B/tttt  //t/t ////tt/t\"\n",
      "batch 10144  loss=140.3197  steps/s=103.50  prediction: \"to work on things that make sense to you\" => \"h to  oe                            t  t\"\n",
      "batch 10145  loss=163.7709  steps/s=104.61  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"to             l                    nn n\"\n",
      "batch 10146  loss=148.1012  steps/s=104.49  prediction: \"snt, now i think and focus waaaay better\" => \" teptt t t   t            n     aaa aaa \"\n",
      "batch 10147  loss=139.2982  steps/s=105.07  prediction: \"tw, my b, but ill hop in on the next one\" => \" pae ite t m      t                     \"\n",
      "batch 10149  loss=210.7330  steps/s=20.44  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" ly   s m     b   t                     \"\n",
      "batch 10150  loss=160.3164  steps/s=113.85  prediction: \"arning, josh waitzkin\n",
      "\n",
      "Gigacracked books\" => \"nt yte e  e   n    iii iiininai\n",
      "a\n",
      "aaiaa \"\n",
      "batch 10151  loss=156.5835  steps/s=104.39  prediction: \" through nevada w my dad as a little kid\" => \"the ir  nnn  r n    v    d   a     a a  \"\n",
      "batch 10152  loss=141.1690  steps/s=103.37  prediction: \"ginal returns idea seems to pop up a lot\" => \" no  ona raa  n   raa  eee es   ee      \"\n",
      "batch 10155  loss=155.7219  steps/s=94.12  prediction: \"ezm progressive overload builds strength\" => \" ure omo rerrs rsreeesseee oo  oo      s\"\n",
      "batch 10156  loss=139.3720  steps/s=101.70  prediction: \"e seen it from all possible perspectives\" => \" ore    e e   en                 ss ppee\"\n",
      "batch 10157  loss=191.6204  steps/s=86.33  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \" e eene  s n   n    oss ssspspsse/epeees\"\n",
      "batch 10158  loss=157.2866  steps/s=103.70  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"too   e e  re    ...  ...  ..  ///hh////\"\n",
      "batch 10159  loss=160.9207  steps/s=97.49  prediction: \"e go all the blindfold web dev positions\" => \" oo:    d e    le     ellllo  l      do \"\n",
      "batch 10160  loss=152.3690  steps/s=100.82  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"g  eereemdnmeem m elelll   e        t   \"\n",
      "batch 10161  loss=184.4518  steps/s=19.88  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly:d@d d omeem m llell    e        t   \"\n",
      "batch 10162  loss=148.5636  steps/s=116.07  prediction: \"worst part, as demonstrated by the graph\" => \"hrk  det e tt t   t     attt ttt t t   t\"\n",
      "batch 10164  loss=149.5377  steps/s=103.61  prediction: \"ective, its significantly more efficient\" => \" h t    ceeceii ii ii iiiiiiiii ii iffff\"\n",
      "batch 10165  loss=146.7402  steps/s=102.52  prediction: \"ng and converged to guessing really well\" => \"g aee e  nen  nen      e e ggggg g   gee\"\n",
      "batch 10166  loss=139.1475  steps/s=102.13  prediction: \", or that would be fun/interesting to me\" => \" tu       e    t               ttttttttt\"\n",
      "batch 10167  loss=158.1191  steps/s=102.37  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"   e  tceeree eeeeee   e   ttttt////t/t/\"\n",
      "batch 10168  loss=153.0146  steps/s=100.59  prediction: \"u actually did the work so youre chillin\" => \" htlettaa a   a                o  o    o\"\n",
      "batch 10170  loss=154.3467  steps/s=97.53  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  +e ooeeedeeddeedeeettetttt tttt       \"\n",
      "batch 10171  loss=137.6392  steps/s=104.68  prediction: \" interesting to see what it hallucinates\" => \"@t  i tt ttttt ttttt     t              \"\n",
      "batch 10173  loss=154.8453  steps/s=98.11  prediction: \"ent in pygame and the network in pytorch\" => \"ptnre nneennen nn     n ee e    e       \"\n",
      "batch 10174  loss=152.2682  steps/s=105.26  prediction: \"ed something about that, not sure though\" => \"   e  eees eeseshe    t   a ttt ttttttt \"\n",
      "batch 10175  loss=144.5869  steps/s=100.49  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th  e   nnnn nininiiiiiiiiiii          s\"\n",
      "batch 10176  loss=148.4951  steps/s=103.54  prediction: \"my camera by accident so maybe thats why\" => \"e tai i mme   a   a ca c   ca a  a     a\"\n",
      "batch 10177  loss=147.0747  steps/s=101.81  prediction: \"libraries or backend compute or anything\" => \"yke@5r% ener rrerr rrrr r               \"\n",
      "batch 10178  loss=170.0372  steps/s=101.83  prediction: \"\n",
      "we'll see how things really play out ig\" => \"\n",
      "at  eYo rfe  o'21,@_F\n",
      ".k'T50'+/50%\n",
      "/f'+\"\n",
      "batch 10179  loss=158.2800  steps/s=102.26  prediction: \"inful to stfu but it works suuuuper well\" => \"ng   k  s   s ut    u   t ut  uuutu    u\"\n",
      "batch 10180  loss=154.2307  steps/s=99.85  prediction: \"n pick your own time though its flexible\" => \"g1 lits        n  i    o   o    to   tl \"\n",
      "batch 10181  loss=144.2513  steps/s=104.85  prediction: \" your brain insanely bad in the long run\" => \"tou     r    r r     aa   aa n   n    n \"\n",
      "batch 10182  loss=144.7960  steps/s=99.87  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n a   s   ss siss                       \"\n",
      "batch 10184  loss=145.3278  steps/s=105.00  prediction: \"layer type stuff, but going even further\" => \"yl on reeere e ee  e     t   t   e e  ff\"\n",
      "batch 10185  loss=146.0502  steps/s=101.05  prediction: \"ding stuff for fun also helped immensely\" => \" ne t  iiut i gf fff ffff   f           \"\n",
      "batch 10186  loss=144.3431  steps/s=105.32  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er e  h rh       e   re   t ttt/////tt//\"\n",
      "batch 10187  loss=141.4829  steps/s=102.10  prediction: \"r been a better time to be a corn kernel\" => \"eb n: @rtaslThtuj_Tw)IkT,jjx)T,IIkj:,j(.\"\n",
      "batch 10189  loss=145.4925  steps/s=104.49  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn  hoe  n nee e eeeee e eeettttt/////tt\"\n",
      "batch 10190  loss=146.4967  steps/s=105.20  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" el lelelelllleoooo eee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttt/////t\"\n",
      "batch 10191  loss=164.8313  steps/s=103.81  prediction: \" God for helping us both out\n",
      "it was hell\" => \"terl ll lol             o   oo      t  t\"\n",
      "batch 10192  loss=142.0732  steps/s=104.96  prediction: \"usually good metrics, good feedback, etc\" => \"s9 t o   us    o ooo    o oooooooood d  \"\n",
      "batch 10193  loss=153.8113  steps/s=99.42  prediction: \"here for the funny symbols and recursion\" => \"er   er r    r re    e             s   n\"\n",
      "batch 10195  loss=157.1867  steps/s=102.98  prediction: \"a, thats super coool!!!!! how did it go?\" => \"l   tam s thhss s s   o!!!!!!!!!!oo o  o\"\n",
      "batch 10196  loss=141.6464  steps/s=104.49  prediction: \"whereas, its easy to tell which is timeâ€¦\" => \"ois  t ette etse sesssstt e  e  t    t  \"\n",
      "batch 10197  loss=220.3913  steps/s=97.51  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"todot\n",
      "et//s e///ZhZZZhZtthhtth th ti //B\"\n",
      "batch 10198  loss=147.9750  steps/s=103.75  prediction: \" end of chess, just like everyone feared\" => \"txs a         s   s   s  s   eeeeeeeeeee\"\n",
      "batch 10199  loss=181.5315  steps/s=29.90  prediction: \"ply: @sunsettler https://t.co/2ERTWsJiwS\" => \"ly: @            ssssss  eee eeeeeeeeeee\"\n",
      "batch 10200  loss=147.1981  steps/s=123.91  prediction: \" personally wasted many years bc of this\" => \"trse tneeeeell  ee l   aaa  yyyyy  a    \"\n",
      "batch 10201  loss=142.7128  steps/s=105.18  prediction: \"ard to realize. lies are really blinding\" => \"lp  e r    a   aa          eeeeeeellllll\"\n",
      "batch 10202  loss=145.3906  steps/s=105.39  prediction: \"e walking through a memory palace maybe)\" => \" d  l t  l ll      l       o o     aaa a\"\n",
      "batch 10203  loss=145.4455  steps/s=104.05  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"h re te h  '' e e    e  e t  ///ttt////t\"\n",
      "batch 10205  loss=136.9097  steps/s=102.09  prediction: \"category so the rule is to tell everyone\" => \"hn e e ot tooott     ee  e        e  e e\"\n",
      "batch 10206  loss=137.4528  steps/s=101.59  prediction: \" for  processing info and learning stuff\" => \"toa  o        g                 nnnnnnnn\"\n",
      "batch 10207  loss=147.9693  steps/s=102.47  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \"  le    t etttettttt   ee eeee l   c    \"\n",
      "batch 10208  loss=172.0586  steps/s=97.99  prediction: \"Incredibly based\n",
      "https://t.co/IOxblXKnJv\" => \" taceccneeeebb e bblelbeee sttc/t//co///\"\n",
      "batch 10209  loss=188.7723  steps/s=20.77  prediction: \"eply: @btwphones Thanks! more on the way\" => \" ly: @cneeeebbb \n",
      "bbleleetttttt/////co///\"\n",
      "batch 10210  loss=151.2055  steps/s=112.14  prediction: \"many roadblocks trying to automate stuff\" => \"el  it     t  ob  ooo oo     o ottt tttt\"\n",
      "batch 10211  loss=144.5510  steps/s=104.50  prediction: \"lions of random steps beforesetting ep=0\" => \"yn a s l  il  il      o o  s ssssseeesee\"\n",
      "batch 10212  loss=153.9492  steps/s=104.75  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  ae ci e e    e    e             r   r \"\n",
      "batch 10213  loss=137.4751  steps/s=103.53  prediction: \" for hrs and hrs and the time just flies\" => \"toe     n                               \"\n",
      "batch 10214  loss=145.6354  steps/s=105.27  prediction: \" works if you did it right, or it doesnt\" => \"thkt ito t t              i             \"\n",
      "batch 10215  loss=190.8341  steps/s=44.53  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: k  o.   o      i  iiiii              \"\n",
      "batch 10216  loss=145.7141  steps/s=109.05  prediction: \"y with any industry/niche and ill run it\" => \" ts eein  yn inyyyyyynnyynnnnnn  n n n  \"\n",
      "batch 10217  loss=157.2932  steps/s=104.43  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "eg i eaOr  he l!QOH*!vO:$[A.x*,HG'$WA$m\"\n",
      "batch 10218  loss=144.4116  steps/s=103.55  prediction: \" can instantly runit w the runit command\" => \"to  e    n    a nnn  n n t   t          \"\n",
      "batch 10219  loss=157.9069  steps/s=97.14  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \" kte ee  sott oo o    t    nnn     oo o \"\n",
      "batch 10220  loss=181.8030  steps/s=102.06  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" t   ueen  o eno    n n ntttht\n",
      "\n",
      "tttoo///\"\n",
      "batch 10221  loss=161.5273  steps/s=105.20  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e  a n o n    tn             ,,,,,,,,,1,\"\n",
      "batch 10222  loss=152.9701  steps/s=104.66  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"09))@s aas  a aaaaana    ooo   oc cc ccs\"\n",
      "batch 10223  loss=137.5955  steps/s=102.82  prediction: \"go, the name.. none of that shit matters\" => \" o s ie  thoe tt e   o   n n    t   tttt\"\n",
      "batch 10224  loss=133.5125  steps/s=103.71  prediction: \" front end. i want minimal backend stuff\" => \"iou        n   n       nnnnn    n n n   \"\n",
      "batch 10225  loss=140.1739  steps/s=105.26  prediction: \"st powerful learning techniques there is\" => \" ises  oosot   e    e    e eeeeneneeeeee\"\n",
      "batch 10226  loss=142.8557  steps/s=104.94  prediction: \" far dang the format looks so much nicer\" => \"ior      r     f   f   o  ooo oo  ooo  o\"\n",
      "batch 10227  loss=140.3416  steps/s=103.88  prediction: \"erful tool, extremely extremely powerful\" => \" y e eeell le ee eellleeexexeeeeeeeeeeee\"\n",
      "batch 10228  loss=166.3435  steps/s=101.73  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl e et ti   Bd/.$B8/æˆ‘á´€^=ðŸ“ˆ8ð—¼$ÊœðŸ¤¦==â™‚ð—±#ðŸ‘^1\"\n",
      "batch 10229  loss=150.8392  steps/s=106.26  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  o  k  bbbb bbb bb b bb            o\"\n",
      "batch 10230  loss=136.9756  steps/s=104.15  prediction: \" in bend you should post, sounds awesome\" => \"it aaatnn nnn i n  n    o  oooo oosss os\"\n",
      "batch 10231  loss=138.0300  steps/s=106.42  prediction: \"ad a concept of \"I\" they would probablyâ€¦\" => \"no       c     c                        \"\n",
      "batch 10232  loss=149.8377  steps/s=100.92  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"t    n  n  aa            ttttttt///////t\"\n",
      "batch 10233  loss=147.8384  steps/s=100.13  prediction: \"my ability to make things I want to make\" => \"a t           i                         \"\n",
      "batch 10234  loss=138.9179  steps/s=103.75  prediction: \"ink not tho, I believe in synthetic data\" => \"ng a   t  n   t t                      i\"\n",
      "batch 10235  loss=136.8366  steps/s=103.21  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of  on f nf   f nn    nn nttttt////////\"\n",
      "batch 10237  loss=151.6612  steps/s=88.00  prediction: \"t only people named dan will have access\" => \"hir of  n   nnlnee peee/tt/t///hhhl11aac\"\n",
      "batch 10238  loss=157.5529  steps/s=102.05  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \":to oau utuu u           tt tttt///////Q\"\n",
      "batch 10239  loss=160.0345  steps/s=103.38  prediction: \"orn to make cash forced to consooolidate\" => \"n tt ttttttt t          c  c  oo ooooooo\"\n",
      "batch 10240  loss=143.1214  steps/s=104.51  prediction: \"iration theres some awesome ppl in there\" => \"n  ht   iiniiiiii r r  e eeeseee eeeee e\"\n",
      "batch 10241  loss=138.8670  steps/s=104.12  prediction: \" good at developing your own techniquesâ€¦\" => \"testern tot     oo  ooo oo  oo  oo o n  \"\n",
      "batch 10242  loss=183.4647  steps/s=103.07  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e itul  o thiioox6.7.7P/EC,\"\"\n",
      "I,I;8W.??x\"\n",
      "batch 10243  loss=172.2153  steps/s=98.94  prediction: \"ecursive thread\n",
      "\n",
      "https://t.co/sc1GSL4fJx\" => \" ts:t@ rthi  re rhhheetthett\n",
      "tttt//t//ct\"\n",
      "batch 10244  loss=221.9956  steps/s=102.99  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \" G TGcry GOi eH WHAKCNGEWO,KONGIN;Fps:1O\"\n",
      "batch 10245  loss=152.9691  steps/s=99.54  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n  ss s   ss siss  s                    \"\n",
      "batch 10246  loss=142.0385  steps/s=103.07  prediction: \"ling down on stuff I initially dismissed\" => \"yt    mv oono   on n     nnn   i iiiiii \"\n",
      "batch 10247  loss=139.1557  steps/s=105.18  prediction: \"e knows what a kernel or text editor are\" => \" poee   een   we           e    e      e\"\n",
      "batch 10248  loss=161.0193  steps/s=93.09  prediction: \"uine Good taste is a very powerful thing\" => \"sl oen   ooo   a   a    teee  ee  rr r r\"\n",
      "batch 10249  loss=155.5603  steps/s=101.22  prediction: \" them for yourself initially? im curious\" => \"th       m               i i ii lii iiii\"\n",
      "batch 10250  loss=143.9721  steps/s=103.92  prediction: \"u a why/a vision for hard work over time\" => \"sw    e  v v     i     o     o      r   \"\n",
      "batch 10251  loss=146.0067  steps/s=101.87  prediction: \"f this song and never listen to it again\" => \" to     t  s s s  s    n   n     n      \"\n",
      "batch 10252  loss=167.3129  steps/s=92.47  prediction: \"gABAP why?? cause its fun and i like fun\" => \" Bme   s   g      ??   ss    n  nn    ii\"\n",
      "batch 10253  loss=169.9426  steps/s=78.28  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eply: @ edeo etAPO,cB??bABIx,yvOO/,uBf/,\"\n",
      "batch 10254  loss=154.4299  steps/s=112.19  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"en  ust  e o ooYYYou oool n  l l t    l \"\n",
      "batch 10255  loss=150.4662  steps/s=104.72  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"re'on i  ent  e    ttttttttttttttt////s/\"\n",
      "batch 10257  loss=154.9787  steps/s=103.76  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" un l t nl     o  o  tttttt  ttttt////t/\"\n",
      "batch 10258  loss=220.6964  steps/s=102.63  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OTOITA NN\n",
      "NON  N ON  TNOU        / /tt//\"\n",
      "batch 10259  loss=162.6526  steps/s=102.90  prediction: \"ng to close your eyes to and just listen\" => \"  h b     st  so  o s  oos  o        s  \"\n",
      "batch 10260  loss=141.7623  steps/s=102.75  prediction: \" what fever dream anime your pfp is from\" => \"@itt l   t f   f    a    e   e          \"\n",
      "batch 10261  loss=154.3605  steps/s=97.59  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"end  j   ee  e            tt tttti/////r\"\n",
      "batch 10262  loss=150.9329  steps/s=104.84  prediction: \"xample losslessâ€¦ https://t.co/1abTqawnLU\" => \"oc tottot oo   e seessssssssssstssttt///\"\n",
      "batch 10263  loss=165.4938  steps/s=100.20  prediction: \"gh Ive been wanting to do a wasm project\" => \" ttt  t    eee ee e ee           n      \"\n",
      "batch 10264  loss=142.7022  steps/s=102.40  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yy  id d  cd  i        uuu uuuuuuuuuuuuu\"\n",
      "batch 10265  loss=200.5794  steps/s=20.50  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly:  d mi   iic  u    uuuouuuuuuuuuuuuu\"\n",
      "batch 10266  loss=170.2276  steps/s=161.20  prediction: \"fsimo Lets goo!!!! Incredibly impressive\" => \" ,m e\n",
      "l   m  mi o !!!!ooo !r  crr r  rys\"\n",
      "batch 10267  loss=136.4245  steps/s=104.75  prediction: \"w the entire thing works when you use it\" => \" l  en h nh   et                        \"\n",
      "batch 10268  loss=150.4771  steps/s=104.13  prediction: \"ng that solves a problem you're close to\" => \"  no thttt tt tt     t       o   o oe e \"\n",
      "batch 10269  loss=173.7451  steps/s=59.34  prediction: \" @pilpulon will release v1 at some point\" => \"t0i tittttn    t     e       e   oooee o\"\n",
      "batch 10270  loss=158.1176  steps/s=107.70  prediction: \"tem\n",
      "- SPHERE GUN https://t.co/tqM3ZpJCkN\" => \"hrn/addet  t s E E  EEE t tt tt///////t/\"\n",
      "batch 10271  loss=154.8460  steps/s=103.44  prediction: \"h, that explanation/example makes sense'\" => \"e   s h  h hh  haaaaaaaaaaaaaaeaaaeaeeee\"\n",
      "batch 10272  loss=151.3501  steps/s=105.02  prediction: \"er/common, insurance will drive adoption\" => \" sS g eet tteeneemennnnnnnnn         i  \"\n",
      "batch 10273  loss=138.1235  steps/s=104.74  prediction: \" in those days will have had it too easy\" => \"tn monssns n ss    s   ss               \"\n",
      "batch 10274  loss=151.0285  steps/s=98.71  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"ya  insenstttsw  iiis     h  i  aaa aaaa\"\n",
      "batch 10275  loss=154.1108  steps/s=100.27  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"g    t  tinee ii  e eetet eee  e e e e e\"\n",
      "batch 10276  loss=136.1702  steps/s=100.18  prediction: \"companies spend that much cash on a logo\" => \"omis seeeteee esee                h     \"\n",
      "batch 10277  loss=149.8562  steps/s=103.94  prediction: \"6hrs on something that feels like a game\" => \"hr  r1   ro   n  o  o  h hh    h e  e e \"\n",
      "batch 10278  loss=151.0310  steps/s=106.53  prediction: \" surprised at how clean of a read it was\" => \"ton  ars  ss   s                        \"\n",
      "batch 10279  loss=151.4512  steps/s=101.26  prediction: \"rd it means theyre giving you a discount\" => \"e ly  @omnehve ,21xf@!Yx\n",
      "IIY://kNTk1v6Nv\"\n",
      "batch 10280  loss=151.9142  steps/s=99.29  prediction: \"coder trust me bro im high iq, see above\" => \"omt   ear edttt rr rr    r  i      i    \"\n",
      "batch 10281  loss=148.1653  steps/s=101.13  prediction: \"new super super early on she was the one\" => \" M rt  e re   ur    eee r er    es ee  s\"\n",
      "batch 10282  loss=135.0782  steps/s=105.57  prediction: \"in but u see it everywhere after a while\" => \"ne te t t t          eeeeeeeeeeeeeeeeeee\"\n",
      "batch 10283  loss=148.1929  steps/s=104.95  prediction: \"sk for, then train them to ask, then act\" => \"  et      t    t t    t t t t  t    t   \"\n",
      "batch 10284  loss=171.6779  steps/s=105.54  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"t..oo ho:///tt/ottXXtttXXXX///ttc///tt//\"\n",
      "batch 10285  loss=158.1198  steps/s=101.25  prediction: \"f many useful things i can build for ppl\" => \" tht   t   f            s     i         \"\n",
      "batch 10286  loss=166.4018  steps/s=98.49  prediction: \"fyb is there a SWE equivalent of goggins\" => \"  ln  uu f    t       e          a  a   \"\n",
      "batch 10287  loss=171.8963  steps/s=104.88  prediction: \"/t.co/gufhF6ZVD6 https://t.co/0ldvn5Oi6t\" => \"/..co/ t ////t///t//666t6666//ttt////t//\"\n",
      "batch 10288  loss=146.6315  steps/s=99.73  prediction: \"e others (including your past self) with\" => \" of i ottot t te e       n              \"\n",
      "batch 10289  loss=156.6898  steps/s=78.18  prediction: \" miss the good old completion model days\" => \"tacc mot t tteeno    o   ppp            \"\n",
      "batch 10290  loss=141.2613  steps/s=106.25  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" io oinelee  ll llllllllll,,,, ,,,,     \"\n",
      "batch 10291  loss=144.6365  steps/s=103.49  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e tee leetne eet e  e a a  a  a   aa    \"\n",
      "batch 10292  loss=161.4920  steps/s=103.03  prediction: \"kedin slop\n",
      "you vill post engagement bait\" => \"     ll nii   i llio l  l lo p     nen e\"\n",
      "batch 10293  loss=158.3145  steps/s=98.97  prediction: \"Building scratch from scratch in scratch\" => \"Abk@eiies i u   i i      s    cr ccc  cc\"\n",
      "batch 10294  loss=156.7160  steps/s=101.02  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"g  tt\n",
      "t tt  t t r o  r   o    yo  t  t r\"\n",
      "batch 10295  loss=163.3968  steps/s=105.08  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" th i    , ,, ,,,,,,4,..........  xx xxx\"\n",
      "batch 10296  loss=168.4389  steps/s=104.99  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/..lt \n",
      " /t/s ///tQQt//tt t  a  n aa.   .\"\n",
      "batch 10297  loss=161.7405  steps/s=102.22  prediction: \"r him, thanks! Sounds useful potentially\" => \"etni  tKjI'CWa_xá´€'(_$x'ðŸ˜†(æˆ‘xL`1~25xâ€œ1~25$\"\n",
      "batch 10298  loss=139.2762  steps/s=102.73  prediction: \"egression to my past actions and results\" => \" oin  re sero ss    s          s  s   s \"\n",
      "batch 10299  loss=151.0092  steps/s=104.80  prediction: \"tputs timestamps of ads =&gt; remove ads\" => \"hseses tut tttu tsttssss   ss t  s  ;;  \"\n",
      "batch 10300  loss=158.0625  steps/s=105.26  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" deo o  d e   e t  ttttt tttt tttt/t/VVV\"\n",
      "batch 10301  loss=204.5611  steps/s=104.97  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"2913A6^20Qá´›ðŸ˜†ð—¿8856B5,4k54v529416v70B40B4\"\"\n",
      "batch 10302  loss=194.2286  steps/s=54.26  prediction: \": example output https://t.co/jRATFli0Ik\" => \" @lanoe2a12Ae 026B5,43547529416v788R0B\"\"\"\n",
      "batch 10303  loss=162.3498  steps/s=109.14  prediction: \"elf improve\n",
      "\n",
      "id be very lost without God\" => \" see eeemelm   me          e  e         \"\n",
      "batch 10304  loss=148.5101  steps/s=105.16  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"u  s os    s  ss  s       a aaaaaaa  a  \"\n",
      "batch 10305  loss=132.1717  steps/s=103.39  prediction: \"to use resumes if lying becomes the meta\" => \"  e  ei s sessssessss     e  e    eee ee\"\n",
      "batch 10306  loss=140.0352  steps/s=104.51  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i   tt t              t  tteeetdtttt\"\n",
      "batch 10307  loss=168.8153  steps/s=104.70  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"/t.lSl\n",
      " /t/s ///th t/ttttt  a  n a..x  .\"\n",
      "batch 10308  loss=149.8850  steps/s=104.64  prediction: \"snt, now i think and focus waaaay better\" => \" te  t  nt   t            n     aaa aaa \"\n",
      "batch 10309  loss=150.0643  steps/s=102.41  prediction: \"anything else would kneecap learning no?\" => \"nd w e  t ih ihni     nn n  e ee ennennn\"\n",
      "batch 10310  loss=163.4541  steps/s=95.99  prediction: \"ey sandwich has been achieved internally\" => \"   tr  nno n   ne   een  a eeeae eneeeee\"\n",
      "batch 10311  loss=174.8329  steps/s=103.33  prediction: \": hold my beer.\n",
      " https://t.co/isMZrTmuiT\" => \" haaatia thaot:TH/:AWA..!!!!.!!v/vMZB/pu\"\n",
      "batch 10312  loss=143.8219  steps/s=100.26  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" i t  eaa  a    ee e                   r\"\n",
      "batch 10313  loss=145.2720  steps/s=104.97  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" wre   aa  aaa a   a aa       t     t  i\"\n",
      "batch 10314  loss=125.0916  steps/s=31.41  prediction: \"st: caffeine is steroids but for posting\" => \" :rea  aa    a a   a        t t     i  i\"\n",
      "batch 10315  loss=193.7925  steps/s=142.26  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"  t   loa a   a    o o    ttt s  iis   s\"\n",
      "batch 10316  loss=154.3821  steps/s=105.38  prediction: \"ready having better days from this stuff\" => \"epog: i tohas m12bD12!I.12!Ix,::Zw!,B!kM\"\n",
      "batch 10317  loss=159.0110  steps/s=99.39  prediction: \"/t.co/KAmykVYFyw https://t.co/Fg3PbzaDJZ\" => \"/..tepep///tt////tttttVtty/t//F:///FF///\"\n",
      "batch 10318  loss=144.5654  steps/s=108.63  prediction: \"t. have they found the piece yet or what\" => \"  a  i    t    t            e    eee  e \"\n",
      "batch 10319  loss=155.6986  steps/s=104.62  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"n                      tttttttttt//////t\"\n",
      "batch 10320  loss=150.5755  steps/s=103.27  prediction: \"y put it back, just gotta wait a few yrs\" => \" irsl llllll  t          ttt  ttttt t t \"\n",
      "batch 10321  loss=155.9050  steps/s=102.51  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"td tt ee e reen eaa  haattaattttt/tttt//\"\n",
      "batch 10322  loss=177.0544  steps/s=102.33  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"lwt at   i s       AAA T  T   /t//t/EEE/\"\n",
      "batch 10323  loss=157.6673  steps/s=98.42  prediction: \"lly great post and great advice. thanks!\" => \"y  @ ee a VVVVVV   t t   attt a   aa   a\"\n",
      "batch 10325  loss=147.0339  steps/s=99.37  prediction: \"nt true they wouldnt put it in the title\" => \" omsp  t i ttt   t     t   tt t  ttt ttt\"\n",
      "batch 10326  loss=150.3580  steps/s=99.19  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" llas a a aaaaewalllllllellll l lliiii i\"\n",
      "batch 10327  loss=180.6470  steps/s=50.85  prediction: \": @yacineMTB better start skilling up ig\" => \" @towto tot @to.`@kMfB,AMfB,Avf$É´á´€R$É´á´„2É´\"\n",
      "batch 10328  loss=154.5289  steps/s=137.44  prediction: \"irak seems fine to me (i am brainwashed)\" => \"teMTBaeaeesea  seee    ee    i liiiaaai \"\n",
      "batch 10329  loss=151.1945  steps/s=102.31  prediction: \"efitted from tracking sleep and whatnot?\" => \" uey  eeeeteeeete  te         ee   e    \"\n",
      "batch 10330  loss=162.5125  steps/s=84.32  prediction: \"ler i wish it tasted as good as it looks\" => \"y yevo ee ffffft  t  t tte  e  d a  oo t\"\n",
      "batch 10331  loss=158.3414  steps/s=105.19  prediction: \"w the game state https://t.co/jm2YeI7PB9\" => \"iw             t e  t t  ttttt tttt t//e\"\n",
      "batch 10332  loss=175.5593  steps/s=50.53  prediction: \": @yacineMTB Action produces information\" => \" @aacealospleopBC:g:â€¦ykA',â€¦â€¦Amkv\n",
      "w:_vb._\"\n",
      "batch 10334  loss=159.4968  steps/s=120.18  prediction: \"I understand what you're saying now yeah\" => \" ro  aeaaa a  aat tn t dtdta t no oa  oo\"\n",
      "batch 10335  loss=149.6969  steps/s=103.23  prediction: \"er useful building block to get good at.\" => \"      us u uuuuuuuuu  lbll              \"\n",
      "batch 10336  loss=149.5291  steps/s=102.83  prediction: \"ting should not be taking customer calls\" => \"hoeri, cro cooou o  n  on  nn nt  t  t  \"\n",
      "batch 10338  loss=144.5341  steps/s=104.51  prediction: \"at can be beaten if you look hard enough\" => \"l s seassse ae tee   e                  \"\n",
      "batch 10339  loss=149.1649  steps/s=104.77  prediction: \" is a wild computational rabbithole man.\" => \"tn  paea    aa a c    aa aaa i aaaiiaaii\"\n",
      "batch 10340  loss=170.3306  steps/s=29.71  prediction: \"ply: @yacineMTB you chose efficient mode\" => \"lay tp a    a  wcc    aa aaaii aaat aab \"\n",
      "batch 10341  loss=187.8868  steps/s=90.07  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y  h seac   c  tcca caaa aaaiiiaatt aal \"\n",
      "batch 10342  loss=139.1207  steps/s=108.30  prediction: \"ink not tho, I believe in synthetic data\" => \"ng     t  n   t t                      i\"\n",
      "batch 10343  loss=148.0699  steps/s=102.21  prediction: \"e, and i know i need to get back into it\" => \"  es si        n              e         \"\n",
      "batch 10344  loss=162.5100  steps/s=99.54  prediction: \"n just do things https://t.co/909bTHzmml\" => \"darrl u nt      n    t t tttt tt tttt///\"\n",
      "batch 10345  loss=157.8132  steps/s=105.02  prediction: \"st tab\n",
      "\n",
      "other than that, not much so far\" => \" ato+t ttoo tt  t tttt tttthtt  tt hh   \"\n",
      "batch 10346  loss=145.2188  steps/s=105.30  prediction: \"a youtube video about it and it exploded\" => \"rt t e   ae   ud       u                \"\n",
      "batch 10347  loss=179.6392  steps/s=96.11  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \"gtr t  euueeee jjeee  ttttt  tttt /totoo\"\n",
      "batch 10348  loss=158.7824  steps/s=100.50  prediction: \"ho. i like it much much better than rome\" => \"en it o i  n   n   i  i         th    tt\"\n",
      "batch 10349  loss=141.6015  steps/s=106.03  prediction: \"ve implemented 50% of the mobile version\" => \"ir ab i e eememeee e ee ee eee  e   e  e\"\n",
      "batch 10350  loss=143.0881  steps/s=101.87  prediction: \"e transformer architecture works so well\" => \" to   n n  n  n rr rrrrrrrrrrrrrrrrrr e \"\n",
      "batch 10351  loss=145.9019  steps/s=100.17  prediction: \"o nothing for now but funny number go up\" => \"nte toteet    onnn no  oo  nnn   nu nnn \"\n",
      "batch 10352  loss=152.6400  steps/s=105.48  prediction: \"\" and idk what that is? Time to learn it\" => \" ao s\" iis   aa     a         t         \"\n",
      "batch 10353  loss=139.6108  steps/s=104.30  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n ma     tt              tttttt///tt////\"\n",
      "batch 10354  loss=142.7284  steps/s=104.68  prediction: \"usually good metrics, good feedback, etc\" => \"tt   t   us      o o    o ooooooooo     \"\n",
      "batch 10355  loss=149.7616  steps/s=100.34  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"tok      n nnnnonnoooooooooo            \"\n",
      "batch 10356  loss=133.5808  steps/s=105.52  prediction: \"uscle and you get better as you practice\" => \"t   t    t       u       te  ee     t tt\"\n",
      "batch 10357  loss=134.3434  steps/s=105.58  prediction: \"ck and forth as much as possible I think\" => \"t iem m m o    n        a           s s \"\n",
      "batch 10358  loss=146.6782  steps/s=105.01  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"n \n",
      "\n",
      "ntn nnnnntitttttttittttttttttt//////\"\n",
      "batch 10359  loss=165.0557  steps/s=93.74  prediction: \"yb is this founder mode or manager mode?\" => \" s eti inii  t i tthtt ttttd/  oa aoor s\"\n",
      "batch 10360  loss=162.6635  steps/s=98.36  prediction: \"Thanks for joining! You guys are awesome\" => \"Be nsn hs f   nn  no   oo no   oa a rres\"\n",
      "batch 10361  loss=136.9063  steps/s=105.23  prediction: \"ffect has it had on you? im very curious\" => \" eh e    ff                             \"\n",
      "batch 10362  loss=168.2517  steps/s=64.78  prediction: \"@yacineMTB You want us to find our moms?\" => \"pacqf4e       a                     ou  \"\n",
      "batch 10363  loss=154.5987  steps/s=110.64  prediction: \"hdaily how does it compare to 100m leads\" => \"ea cinillh o   wlo  o oo  o  o o  o    0\"\n",
      "batch 10364  loss=139.5268  steps/s=103.87  prediction: \"d into using dishonest middlewit tactics\" => \" le t  eed  e n   sssnssssi isssiididiti\"\n",
      "batch 10365  loss=142.5182  steps/s=104.59  prediction: \"tiary structures. spirals within spirals\" => \"hne  y/ryrrrrttrrrtrrrstrrsssrrssiisiii \"\n",
      "batch 10366  loss=158.6858  steps/s=100.89  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"tee ai  m m         l               o o \"\n",
      "batch 10367  loss=147.3939  steps/s=97.95  prediction: \"im gonna read the whole library of babel\" => \"naBA ee n nn  e     o    ee  e e   o    \"\n",
      "batch 10368  loss=153.0229  steps/s=99.72  prediction: \"n pick your own time though its flexible\" => \"ga iec  n      n  o    o   oo     t  ee \"\n",
      "batch 10369  loss=143.1643  steps/s=102.06  prediction: \"utomatically imagine letters as colored?\" => \"t yo oo aoo aaoaaaa aaa aaal ttt   e  e \"\n",
      "batch 10370  loss=135.9449  steps/s=103.64  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \":ar arn  ae    aa aaa   aassssss//tt////\"\n",
      "batch 10371  loss=145.2845  steps/s=101.05  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"  doo o d     nd       n    n   \n",
      "eee eee\"\n",
      "batch 10372  loss=143.5464  steps/s=104.64  prediction: \"best ways to improve for stuff like this\" => \"e f i n  t t  e                 ffffffff\"\n",
      "batch 10373  loss=148.1911  steps/s=104.90  prediction: \"ll be easy to remember every single move\" => \"y  t lllll    el   e  eeeeeeeeeeeeeeeeee\"\n",
      "batch 10374  loss=148.6259  steps/s=104.57  prediction: \"aster i u know its just abt authenticity\" => \"n  tot ttt    tt  t        t    ttt ttt \"\n",
      "batch 10375  loss=149.6653  steps/s=100.23  prediction: \" v. move forward/backward is layer stuff\" => \"ten       v             rrrarraraaaaar a\"\n",
      "batch 10376  loss=157.2404  steps/s=100.49  prediction: \"neMTB @justalexoki the rise of carmacine\" => \"  ot y     v  ororoakarkkk  r   rr aa ff\"\n",
      "batch 10377  loss=142.0912  steps/s=105.24  prediction: \"d stuff just happens. stochastic winning\" => \" syo     d     u        sssssssssssssssn\"\n",
      "batch 10378  loss=160.3737  steps/s=103.22  prediction: \"em man, I had to share, its a crazy tool\" => \"      o        n   a      a   a       a \"\n",
      "batch 10379  loss=163.7314  steps/s=92.51  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \" wo   n        o    o   tts  tt a///PPco\"\n",
      "batch 10380  loss=161.6038  steps/s=100.42  prediction: \"rse21 doing is a fundamental of learning\" => \"e ly: @wea    ab'$@ðŸ§ Nbá´€21Ib&21:I$0.kI/P,\"\n",
      "batch 10381  loss=135.7034  steps/s=102.13  prediction: \"category so the rule is to tell everyone\" => \"hn i o  t tsoott     ee  e        e  e e\"\n",
      "batch 10382  loss=139.8872  steps/s=103.02  prediction: \"quote a lot bc it seems to come up a lot\" => \"cartitAt t    ttt                       \"\n",
      "batch 10383  loss=163.4040  steps/s=101.69  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"n  a     aeaa eaeeae e eaa       a      \"\n",
      "batch 10385  loss=146.1987  steps/s=102.48  prediction: \"nd then vcs give u money for some reason\" => \"  ao       n  en                        \"\n",
      "batch 10386  loss=160.4144  steps/s=94.60  prediction: \"y based. how do you compile zig to wasm?\" => \":aa az  b b    s      o    o o e o  e o \"\n",
      "batch 10387  loss=181.2589  steps/s=105.41  prediction: \"ful to me, like use every day type stuff\" => \" l    l   l  l l e    eee e   eeeee y   \"\n",
      "batch 10388  loss=153.5658  steps/s=105.21  prediction: \" and mc write n\n",
      "\n",
      "https://t.co/7R6F8ZlLFS\" => \"tnd  a    n             ttttttttt///////\"\n",
      "batch 10389  loss=195.1830  steps/s=59.71  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tcd  a  n  n   n  tttttttttt////////tFFF\"\n",
      "batch 10390  loss=156.8580  steps/s=118.38  prediction: \"nism oooh possibly, thats a good thought\" => \" n o   aoooooooooooosss ooss  ss  tooo  \"\n",
      "batch 10391  loss=174.3532  steps/s=104.99  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"o eia s s  st    s \n",
      "t  ttt  t\n",
      " /t/stt/tt\"\n",
      "batch 10392  loss=172.7734  steps/s=80.04  prediction: \"qc Based, a true warrior of the zig army\" => \"ui@Htos etts    \n",
      "  \n",
      "tt ttttr///ot fftt m\"\n",
      "batch 10393  loss=144.8746  steps/s=107.14  prediction: \" distracting any kind of multitasking is\" => \"tooe ht  tt t   i           n   i   iiii\"\n",
      "batch 10394  loss=149.5984  steps/s=104.88  prediction: \"hemes\n",
      "John waitzkin called this chunking\" => \"e t teatettetteeeeee e n e  n   ii tii  \"\n",
      "batch 10395  loss=158.2267  steps/s=106.37  prediction: \"lsio recursive mind exploding adventures\" => \"y  @eir:leele ieeieeie eie  ii  idndddnn\"\n",
      "batch 10396  loss=145.1911  steps/s=101.92  prediction: \"on said we cant use that word any more!!\" => \"u                            a       a  \"\n",
      "batch 10397  loss=192.3830  steps/s=29.90  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly: @s b                     aa      a  \"\n",
      "batch 10398  loss=158.2004  steps/s=138.03  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"u   ir iin ni    oo sst  ttt//tt/ t//JJQ\"\n",
      "batch 10399  loss=146.0980  steps/s=88.11  prediction: \"neMTB i dream in ai generated js slop :/\" => \" MTBs   i ni      tt  t  tttt ttsrtytyyy\"\n",
      "batch 10400  loss=140.4496  steps/s=104.88  prediction: \", thank God we can function at all loool\" => \" ir  i e r    aee     a   n      aan  a \"\n",
      "batch 10401  loss=180.2778  steps/s=74.23  prediction: \"owTiedFox 16hrs every day is crazy,  wow\" => \"nihtli i d  d  d      e n n  a   a ll lo\"\n",
      "batch 10402  loss=153.3968  steps/s=108.11  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \" e ni a i    i    i  s    s st  s s ss t\"\n",
      "batch 10404  loss=187.6774  steps/s=29.87  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly: @ a i n  i  iii  s    s sts s s s  t\"\n",
      "batch 10405  loss=171.9342  steps/s=119.02  prediction: \"ng jai??? Instantly 10x more interesting\" => \"   n l  ii    ???????a               t  \"\n",
      "batch 10406  loss=150.0238  steps/s=100.61  prediction: \"ur gzip stuff? training on gzipped data?\" => \"  ii          i        i    innnnnnni   \"\n",
      "batch 10407  loss=142.2102  steps/s=104.01  prediction: \"eres so little time to things in the day\" => \"   seeeee ee  t     ttttttttttt tt      \"\n",
      "batch 10408  loss=165.7212  steps/s=102.16  prediction: \"sist... bait.... https://t.co/FSXHHMMAoD\" => \" tse t..................tt ttttttt/////H\"\n",
      "batch 10410  loss=145.7514  steps/s=102.88  prediction: \"e transformer architecture works so well\" => \" ts     n  n  n rr rrrrrrrrrrrrrrrrrrr  \"\n",
      "batch 10411  loss=151.4268  steps/s=104.92  prediction: \" absolutely mind blowing post all around\" => \"ts tlin tl llll  llll    l  ooo  llo    \"\n",
      "batch 10412  loss=151.0903  steps/s=104.08  prediction: \", write one sentence after another, andâ€¦\" => \" at  rrdddd o   ee ee  e eeeeneeeee enee\"\n",
      "batch 10413  loss=160.5794  steps/s=104.35  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"toet D    e       e      tttee///tt/tt/t\"\n",
      "batch 10414  loss=148.6911  steps/s=101.34  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r  y t t e             t tttttt//t/////\"\n",
      "batch 10415  loss=143.1261  steps/s=104.32  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"yceneet aa n   e     n    t   ttttt////G\"\n",
      "batch 10416  loss=183.9173  steps/s=102.50  prediction: \"dgrammer it was a really fun time though\" => \"  a H m1m@ r @r@mmrrmrrmmmwa    aae  aa \"\n",
      "batch 10417  loss=165.5753  steps/s=104.61  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"to   n      t!!!!!!!!!t!!tttttttt /tt/tt\"\n",
      "batch 10418  loss=142.7443  steps/s=98.80  prediction: \"ntiers out there we dont even know about\" => \"git     ro o    te  ee   e e eeeeeee    \"\n",
      "batch 10419  loss=158.3305  steps/s=105.03  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th  o  ot o   o      t  ttttttt tttt////\"\n",
      "batch 10420  loss=138.6429  steps/s=103.64  prediction: \"n, tons of alpha is already in your head\" => \"g ntintnt ttt at o  a a   aaaa          \"\n",
      "batch 10421  loss=137.2943  steps/s=104.18  prediction: \"ment it with all the details that pop up\" => \"e e in iene         t  tttttttttttttttt \"\n",
      "batch 10422  loss=142.9589  steps/s=103.79  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"rl to e yl t                            \"\n",
      "batch 10423  loss=149.1366  steps/s=105.41  prediction: \"thats a good one, comparing with experts\" => \" e o ,   tt   tt      oooooo  oo    n i \"\n",
      "batch 10424  loss=151.0288  steps/s=104.08  prediction: \"y started pushing the boulder 5x as much\" => \" hr admaeaet tdt    e    e  e    e      \"\n",
      "batch 10425  loss=152.4848  steps/s=99.98  prediction: \" this long lost treasure of a song, damn\" => \"tor r o   n  o n        o t  o o      o \"\n",
      "batch 10426  loss=176.9572  steps/s=97.09  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"aaei   o n o    t t ttsts tt  ssoo    FF\"\n",
      "batch 10427  loss=167.9933  steps/s=89.47  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"hgd   oo igAA     tttttt/////::///Foo222\"\n",
      "batch 10428  loss=166.6956  steps/s=101.30  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" BAe   AwA  P bb tttsstppttppoooottooouðŸ›‘\"\n",
      "batch 10429  loss=149.4465  steps/s=105.58  prediction: \" but vanilla obsidian seems very mid imo\" => \"aerep r ruuu  ueu laall    sa aa    ei i\"\n",
      "batch 10430  loss=143.0767  steps/s=97.07  prediction: \"custom extension to watch yt on 4x speed\" => \"aseM B    t t   tt    t tt   t t  t     \"\n",
      "batch 10431  loss=179.0154  steps/s=105.54  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" t ttcEcceccLcLLLccectceceeetet c /ttt//\"\n",
      "batch 10432  loss=153.3531  steps/s=104.76  prediction: \"dable and makes debugging not so bad tbh\" => \"  g sirr a a   aada aeee edadggn    g b \"\n",
      "batch 10433  loss=147.3824  steps/s=99.01  prediction: \"e enlightened than me, i need to wake up\" => \" te    e   eele e eeeenenen eeee   e ee \"\n",
      "batch 10434  loss=182.9490  steps/s=47.49  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"y  ore rrleeeeene ee en nen eeee   e ee \"\n",
      "batch 10435  loss=157.8555  steps/s=111.81  prediction: \"... and 4\n",
      "\n",
      "idk about other spaces though\" => \" ..  i........4444                      \"\n",
      "batch 10436  loss=167.6481  steps/s=104.05  prediction: \"oing the deadline thing\n",
      "Works super well\" => \"un tt   t nt tn    ddddiieiiieiie e ee e\"\n",
      "batch 10437  loss=143.5679  steps/s=105.04  prediction: \"tory by far. it continues to surprise me\" => \"  nac  aanaaaaan                        \"\n",
      "batch 10438  loss=157.7267  steps/s=101.92  prediction: \"y the paper i thought it was a neat read\" => \" aile p p ht  hpppp  h   hhhht   t     a\"\n",
      "batch 10439  loss=137.4145  steps/s=104.82  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"uns  pp oon    ne    eeeee eeee         \"\n",
      "batch 10440  loss=135.6631  steps/s=104.35  prediction: \"asily, and they compound with each other\" => \"nt e ea l    l l     y                 h\"\n",
      "batch 10441  loss=145.1080  steps/s=103.89  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \" t l     w www www                      \"\n",
      "batch 10442  loss=156.9532  steps/s=100.82  prediction: \"nvm then, enjoy your rain water counting\" => \" ebo tht tttt \n",
      "tt n n  n  n r n r   r   \"\n",
      "batch 10443  loss=147.1846  steps/s=104.46  prediction: \"ould keep going) https://t.co/zZj3emr1oN\" => \"u     b  l    e           t  t ttt//////\"\n",
      "batch 10444  loss=148.8088  steps/s=101.47  prediction: \"n just do things https://t.co/909bTHzmml\" => \" mat e  st      o   ttttss/tt/tt////9/9t\"\n",
      "batch 10445  loss=166.9857  steps/s=59.45  prediction: \" @pilpulon will release v1 at some point\" => \"tsu su ul t  n n  ttttt////t//t999999zmm\"\n",
      "batch 10446  loss=147.2572  steps/s=111.67  prediction: \"ding up the drive thru for 1000 episodes\" => \" nn h    enn  n                  0000000\"\n",
      "batch 10447  loss=142.5537  steps/s=104.38  prediction: \" games because we trusted each other lol\" => \"tet   aemems eme e ee se ee ee see ee ee\"\n",
      "batch 10448  loss=139.2996  steps/s=104.84  prediction: \"o have positive interactions its to grow\" => \"um        t  o t  i ii itiiitiiiiiiitttt\"\n",
      "batch 10449  loss=135.2760  steps/s=102.71  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"ne s      ea eae  ee eee     e e   e    \"\n",
      "batch 10450  loss=133.7250  steps/s=98.95  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \"  e a  aean   ettetteeeeeeeeeeeeeeeeeeee\"\n",
      "batch 10451  loss=132.8959  steps/s=105.51  prediction: \"p infested regions of their latent space\" => \"li e ou       tteeeeeeeeeee       e     \"\n",
      "batch 10452  loss=154.1789  steps/s=98.56  prediction: \"rse21 doing is a fundamental of learning\" => \"e ly: @y     @tw--@5-5-215@-21---~------\"\n",
      "batch 10453  loss=136.6996  steps/s=100.58  prediction: \"t. have they found the piece yet or what\" => \"  a ti    t    t            eeee eee  e \"\n",
      "batch 10454  loss=173.9422  steps/s=99.44  prediction: \"MTB Yup, totally, would be best actually\" => \"TB @ynyire  e e  y ty t  tul  e e  t   l\"\n",
      "batch 10456  loss=158.3461  steps/s=100.43  prediction: \"inful to stfu but it works suuuuper well\" => \"neMTB   s   s  t    u   t ut  uuuuu    u\"\n",
      "batch 10458  loss=149.6007  steps/s=103.20  prediction: \"ld almost suspect God is on their side..\" => \"y  @sodisdossssssssss s   s             \"\n",
      "batch 10459  loss=172.3756  steps/s=103.49  prediction: \"ived did. Its pribably more fun that way\" => \"ne ov  e v i   ii       i     b         \"\n",
      "batch 10460  loss=142.0087  steps/s=103.72  prediction: \"d to take over the years\n",
      "\n",
      "4 minute miles\" => \" ta ett ttt   tee  e ee ee ee ee e      \"\n",
      "batch 10461  loss=166.6772  steps/s=105.20  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \"a d    oonnooooo o         t//tt////t//t\"\n",
      "batch 10462  loss=203.4987  steps/s=100.98  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"IIhGrW N AETETETETETT  OE   tt///////tt/\"\n",
      "batch 10463  loss=201.5010  steps/s=78.67  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"      rHETTEE7S  ðŸŒ‘      t tt/t/ ///Qtpcp\"\n",
      "batch 10464  loss=155.3426  steps/s=107.39  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"epge  nt e  adeb2ðŸ«¡m12ðŸ«¡:ðŸ«¡1BOkðŸ«¡m:bvmki\n",
      ",EY\"\n",
      "batch 10466  loss=153.3764  steps/s=102.38  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"a e i     lleeeleeeeeee    e            \"\n",
      "batch 10467  loss=159.6303  steps/s=102.85  prediction: \"nonstop about that compression challenge\" => \" t o nonnennnne tttttttttttttooooooooo  \"\n",
      "batch 10468  loss=139.1103  steps/s=104.61  prediction: \" good at developing your own techniquesâ€¦\" => \"testern tot   oooo  ooo oo  oo  oo o n  \"\n",
      "batch 10469  loss=142.8896  steps/s=105.16  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"ewlfl(aar m    \n",
      "`$á´¡â€á´‡ð—¼#á´$(#$ð—²#ðŸŒ‘($á´›É´@Êœ(ð—±|\"\n",
      "batch 10470  loss=141.1909  steps/s=104.23  prediction: \"l possible golden gate bridge existences\" => \"yfexxl   ll  l  ll  l        ee ee eeeee\"\n",
      "batch 10472  loss=150.0432  steps/s=98.22  prediction: \"w site! Not gonna say much til it's done\" => \"hio e  e ses  gN               i   ii   \"\n",
      "batch 10473  loss=141.7906  steps/s=98.92  prediction: \"see more details as you unblur an image.\" => \"  c  ee  e  eee  ee   a       u  u      \"\n",
      "batch 10475  loss=189.0719  steps/s=84.39  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \"  ce  lo  saeei 000   @usuuuu   u    ro_\"\n",
      "batch 10476  loss=162.9357  steps/s=103.03  prediction: \"azy like that. Cheers my English brother\" => \"r  oh   ne ne t  t   e e      e  h      \"\n",
      "batch 10477  loss=194.1591  steps/s=23.80  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @t    te    t   e ee     e  h      \"\n",
      "batch 10478  loss=158.8925  steps/s=103.55  prediction: \"ly: @IterIntellectus its white pill week\" => \"y: a n  e   e t  t e eee      e hi  hehh\"\n",
      "batch 10479  loss=154.1053  steps/s=111.76  prediction: \"ng to caffeine+building/studying for fun\" => \"g oe  in ingiii iiiiiiniiiingnininiinini\"\n",
      "batch 10481  loss=142.9126  steps/s=103.48  prediction: \"e transformer architecture works so well\" => \" aon    n  n  n  r rrrrerrrrrrrrrrrrrre \"\n",
      "batch 10482  loss=175.3054  steps/s=75.44  prediction: \"nicoara \"The instruction at 0x%p...\"\n",
      "Lol\" => \" ont   naoarr  errrrtttrrtttrrr t  w  ..\"\n",
      "batch 10483  loss=168.0193  steps/s=107.32  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" icrerarrrhee isssrr0000  rar rrp   r   \"\n",
      "batch 10484  loss=144.4487  steps/s=104.85  prediction: \"e info produced by exploring new options\" => \" iia iin n n   nn        d  e         o \"\n",
      "batch 10485  loss=173.2881  steps/s=104.38  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"t.1cittt.///ttt///ttttttt://t/ttz///tt//\"\n",
      "batch 10487  loss=173.7467  steps/s=101.62  prediction: \" know some ppl this would help immensely\" => \"tenk t  ! k   m  m  po  p  o   p   ll   \"\n",
      "batch 10488  loss=140.0399  steps/s=104.10  prediction: \"ngry each chunk) it pretty much kills it\" => \"g ytaila l                              \"\n",
      "batch 10489  loss=146.1544  steps/s=104.72  prediction: \"m scratch in numpy like i did w backprop\" => \"ote  t   ss                             \"\n",
      "batch 10490  loss=134.4132  steps/s=103.81  prediction: \"uture w her, and what that would be like\" => \"   tn  te e    e             h          \"\n",
      "batch 10491  loss=151.9177  steps/s=101.26  prediction: \"free could help too if thats the problem\" => \" omrotuur r    le            t  tt   t  \"\n",
      "batch 10492  loss=143.1712  steps/s=104.23  prediction: \"d it tho, was a change of weather for me\" => \" tt eieeemet  ttt              aa      e\"\n",
      "batch 10493  loss=140.1377  steps/s=101.43  prediction: \"ellite imagery onto the photos they took\" => \" s s sstete  aatee e e   etetto t ototot\"\n",
      "batch 10494  loss=143.3179  steps/s=103.86  prediction: \"m parts of your brain will want to do it\" => \"efe   etttr rr rr r rro  rr         t   \"\n",
      "batch 10495  loss=143.0317  steps/s=103.92  prediction: \"g his own CAD thing and calls it dingcad\" => \" oes     s s          n   nn        n   \"\n",
      "batch 10496  loss=151.6343  steps/s=101.52  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et  t  ttto oooooo  ooooo ooossssssusuuu\"\n",
      "batch 10497  loss=144.0388  steps/s=100.25  prediction: \" have another tweet promoting AB testing\" => \"tok  tt   ee  e  e eeeeeeetttt tt tttttt\"\n",
      "batch 10498  loss=138.7576  steps/s=104.61  prediction: \" hold onto the ones not worth finishing.\" => \"tot t t oooooottooooooo oo oo  o      nn\"\n",
      "batch 10500  loss=147.7041  steps/s=103.89  prediction: \" of just doing what fundamentally worked\" => \"tn  tts s ttt t     t       n  na aan aa\"\n",
      "batch 10501  loss=142.0449  steps/s=102.42  prediction: \"marter you get the more the traps change\" => \"ett  aoatt h  te       t   e  ee   e    \"\n",
      "batch 10502  loss=149.2903  steps/s=41.63  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \": @ao a   re   ee      t e ee  e   e   t\"\n",
      "batch 10504  loss=171.2473  steps/s=126.06  prediction: \" job adding the australian language pack\" => \"tur  t t0  ne   e      t t a  aat aa gaa\"\n",
      "batch 10505  loss=151.8151  steps/s=103.75  prediction: \"ive and do the bare minimum you may getâ€¦\" => \"ne  a s  ss  ea a d eeee a       ie     \"\n",
      "batch 10506  loss=136.8443  steps/s=101.40  prediction: \"or a site with a manipulatable algorithm\" => \"u_  oo  oto   at      a  aaaaa a aaaaaaa\"\n",
      "batch 10507  loss=159.1472  steps/s=97.24  prediction: \"Simple p5. Will look into matter though.\" => \"SmpNpo  e      p   ii i lil  tt  tttt tt\"\n",
      "batch 10508  loss=143.0563  steps/s=102.86  prediction: \"just start working, and it doesnt matter\" => \"ust          t r   r  t   t rt  t  nttt \"\n",
      "batch 10509  loss=146.4893  steps/s=104.19  prediction: \"ill you get better at as you practice it\" => \"nl ta      l     t  tt   t      t  t  a \"\n",
      "batch 10510  loss=147.2920  steps/s=102.20  prediction: \"kes a lot of sacrifice and energy though\" => \"e s t stetge as  s  aa aa  a  e   e     \"\n",
      "batch 10511  loss=145.9447  steps/s=100.28  prediction: \"ick and no login and as free as possible\" => \"ne w  ou       n   n     n   n       ss \"\n",
      "batch 10512  loss=148.9426  steps/s=104.34  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "tupr c rIt I t.ð—¯II^^,á´€â€œðŸ˜¢|,,Éªèµ°É´^^ðŸ˜|`@`?@\"\n",
      "batch 10513  loss=184.2267  steps/s=69.50  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"yde we \n",
      "dwddd ddaap aapppppp pp   o     \"\n",
      "batch 10514  loss=139.1106  steps/s=105.82  prediction: \" know its doable\n",
      "https://t.co/DZCdUoVn6w\" => \"tit  ot  t n oo   o ootttottttt/////tt//\"\n",
      "batch 10515  loss=143.7132  steps/s=104.78  prediction: \"y abt compression, which is intelligence\" => \" t  aap  aat  tt   t   i   iii issiiiii \"\n",
      "batch 10517  loss=146.8513  steps/s=102.41  prediction: \"n is a great way to beat some addictions\" => \"gmwoe    st ts itttt    a  t  ta   aaa  \"\n",
      "batch 10518  loss=173.4848  steps/s=103.25  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "ue : zi  LL  me\n",
      "L!!0(L\"!((x/fx,,)):xxf.\"\n",
      "batch 10519  loss=156.1953  steps/s=88.39  prediction: \"bly same, llms are so much faster though\" => \"ue\n",
      "i z e me   wmmm   m      o fffftf  nt\"\n",
      "batch 10520  loss=146.5580  steps/s=105.17  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y  tantlnnenaaaaaaaaaaaattttttt/////////\"\n",
      "batch 10521  loss=183.5863  steps/s=81.79  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn eil ainaaaaanggtAAstttt/tt/ttttaecedd\"\n",
      "batch 10522  loss=147.7938  steps/s=105.01  prediction: \"hemes\n",
      "John waitzkin called this chunking\" => \"e s :rasettet eeeeee e n e  n   ii tii  \"\n",
      "batch 10523  loss=153.2838  steps/s=102.12  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" ms   e  n w    i    t  tttttttt///////4\"\n",
      "batch 10525  loss=190.2022  steps/s=94.17  prediction: \"ez5341 based, i respect the grind brotha\" => \" ms   w w    iss  t sts ttttttthtthhhZ ðŸ›‘\"\n",
      "batch 10526  loss=158.3189  steps/s=96.97  prediction: \"bootloader fast and frictionless is king\" => \"et o obobaoodo boa  o rt  at   i iiii  i\"\n",
      "batch 10527  loss=171.5017  steps/s=89.79  prediction: \"UBalis welcome to circle tool gang, king\" => \"PE\n",
      " c @e   U  de@1f,_bkd,\"Sfg\"\"x\"Nb\"\"\"N+\"\n",
      "batch 10528  loss=149.8386  steps/s=102.90  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"t ln     t e  ane \"\"\"\"\"\" \"\"\"\"\"   e   se \"\n",
      "batch 10529  loss=145.2176  steps/s=104.26  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t ?te s               o  t t to:ttttt///\"\n",
      "batch 10530  loss=151.4790  steps/s=99.64  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"u eI  e  tte  ut t  ooao oooooaaoo\n",
      "a\n",
      "\n",
      "a\n",
      "\"\n",
      "batch 10531  loss=217.4290  steps/s=104.79  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \" rzrzaTtllltl00MMMtM03ML30LL00LF0tt0ttto\"\n",
      "batch 10532  loss=154.6897  steps/s=99.42  prediction: \"uters. i dont like those tbh. weird shit\" => \"n i     e n    n          t    t        \"\n",
      "batch 10533  loss=148.4660  steps/s=105.67  prediction: \"ful if youre a complete beginner like me\" => \" l  r tiu     i     u e    e e ee eeee e\"\n",
      "batch 10534  loss=160.4795  steps/s=104.95  prediction: \"ded techniques too, lmk if you know more\" => \"  g e= eenedeededdeeeeeee      o  o    o\"\n",
      "batch 10535  loss=158.5297  steps/s=102.61  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"e e  bo lonloo  oollol ul     uffuuffu u\"\n",
      "batch 10536  loss=179.7063  steps/s=90.50  prediction: \"gABAP @yacineMTB https://t.co/NDBKphrBEW\" => \" BAM le lenol    f    tts  sttss t/ttoo \"\n",
      "batch 10537  loss=155.1006  steps/s=39.01  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @BuBA ri A @  f  tttts  sttss/// BBBðŸ›‘\"\n",
      "batch 10538  loss=145.7474  steps/s=106.92  prediction: \"at can be beaten if you look hard enough\" => \"nes  es sse ae tee   e                  \"\n",
      "batch 10539  loss=147.8392  steps/s=104.47  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tn tiiiiiinniiiiiiiiiiiiiiiiiii         \"\n",
      "batch 10540  loss=155.6243  steps/s=104.19  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"once t a  o cee e re ee   ht  t////t/ttp\"\n",
      "batch 10542  loss=146.7651  steps/s=103.91  prediction: \" of just doing what fundamentally worked\" => \"tu ttt  s sts to    t     d n  nanaan aa\"\n",
      "batch 10543  loss=137.5400  steps/s=103.44  prediction: \"that was probably its entire purpose lol\" => \" e i ttettettt  ttt  t   t      t   r   \"\n",
      "batch 10544  loss=152.8559  steps/s=103.31  prediction: \"nsions have a different message, I think\" => \" eit et nennssenssses e  neeee e e  eee \"\n",
      "batch 10545  loss=146.8162  steps/s=99.15  prediction: \"resting, what kinds of tools has he made\" => \"eply: @a e lo  my@Aá´€/G:AFÉ´.G:,/w.VTTk5IV\"\n",
      "batch 10546  loss=181.6233  steps/s=102.13  prediction: \"7AHwatHv6Y was really really really good\" => \"   @qto///t/HtHHHHHwwwaa aaallll alllll \"\n",
      "batch 10547  loss=170.6540  steps/s=32.56  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: @ t7/ttt Hwwwwwa aaaa aallllllllllll \"\n",
      "batch 10548  loss=167.4727  steps/s=113.93  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yt s u6       t       e  e ee eeeee ooee\"\n",
      "batch 10549  loss=154.4395  steps/s=100.12  prediction: \"el editor and gameplay, that sounds cool\" => \" la a ee l     l      a aaaa aaaa aaa   \"\n",
      "batch 10550  loss=171.3009  steps/s=105.68  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"@ he ela a a aaaaa  aaa  tttt  tttts///9\"\n",
      "batch 10551  loss=147.7383  steps/s=104.44  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"ni\n",
      "re lhltahh  raaa r      rer    ee  ee\"\n",
      "batch 10552  loss=139.3235  steps/s=103.53  prediction: \" from that channel/vid to that x account\" => \"ti   lo lol   tt  a a      t tttt    tt \"\n",
      "batch 10553  loss=135.9480  steps/s=101.15  prediction: \"the angle of ur screens after she leaves\" => \"he  o    a                  eee eeeeeeee\"\n",
      "batch 10554  loss=133.6678  steps/s=103.39  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"ne a    e eg  ie  ee eee       e   e    \"\n",
      "batch 10555  loss=142.5194  steps/s=103.13  prediction: \" deadlines dont really get done the same\" => \"toi   n d d de d  ddd eeee de   e te  ee\"\n",
      "batch 10556  loss=141.5854  steps/s=104.88  prediction: \"onna get wiiiild man like reeeeally wild\" => \"  n o s gerniiien gn  i iiiiii e l  l   \"\n",
      "batch 10557  loss=143.0896  steps/s=102.16  prediction: \"oo, and the school wasn't even built yet\" => \" d a     a a   t                        \"\n",
      "batch 10558  loss=164.0419  steps/s=46.21  prediction: \"y: @radbackwards God invented it\n",
      "Idk lol\" => \": @JeM a a         o   o               t\"\n",
      "batch 10559  loss=148.1894  steps/s=108.53  prediction: \"an get immense alpha if you keep zooming\" => \"nd oo    em mmmm e                      \"\n",
      "batch 10560  loss=200.5966  steps/s=21.36  prediction: \"eply: @visakanv The attack of the clowns\" => \" ly  @a m m mmem e e                    \"\n",
      "batch 10561  loss=139.8435  steps/s=116.81  prediction: \"ns you get the yellow letters on lichess\" => \"t  an t mo    t    t   e   ee eeeee  ee \"\n",
      "batch 10563  loss=164.2992  steps/s=104.09  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"igA oeuu@ n @ AABABBB B B B        a a a\"\n",
      "batch 10564  loss=148.6530  steps/s=97.72  prediction: \"cking it was kobe posting the whole time\" => \"t1a  Pngdon i  ii                       \"\n",
      "batch 10565  loss=144.5950  steps/s=104.80  prediction: \"w, weve been going for a few weeks or so\" => \"i  d  o        w   e    e          e   e\"\n",
      "batch 10568  loss=143.4288  steps/s=105.85  prediction: \"r minds after realizing thats not rly it\" => \"eit l(ika)   f g[`zð—µâ€¦]v[]))#bC#[]|`[]ðŸ‘á´„ð—ª\"\n",
      "batch 10569  loss=146.5655  steps/s=105.42  prediction: \"ng sessions for now for the discord name\" => \"    i  el iis  nssioo  os  oo  oo  oo  o\"\n",
      "batch 10570  loss=149.1900  steps/s=103.60  prediction: \"ter and more efficient than studying imo\" => \" rt  t t t   t  tte   tteeeee eeiettttin\"\n",
      "batch 10571  loss=158.4733  steps/s=105.02  prediction: \"is DEEP\n",
      "Example: https://t.co/C4k7PyeOGW\" => \"n e ee    r EEE x eh  ::::t:://///  ///t\"\n",
      "batch 10572  loss=197.7762  steps/s=21.22  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly: @i EEEEEEE x e:::::::t://////  //4t\"\n",
      "batch 10573  loss=144.7009  steps/s=110.90  prediction: \" fundamentals.  Take the time to invest.\" => \"too  t    nttttta  a aa                 \"\n",
      "batch 10574  loss=145.0816  steps/s=104.98  prediction: \"es success, but there is a causal factor\" => \"  iut e eess  uusssseessse es    a  a a \"\n",
      "batch 10575  loss=143.3209  steps/s=103.11  prediction: \"mind responds to and processes phenomena\" => \"enttr t  r  o  n o   oo        sssssssss\"\n",
      "batch 10576  loss=165.7074  steps/s=102.57  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yte  e6       s       e  e ee\n",
      "eeeee ooee\"\n",
      "batch 10577  loss=143.9675  steps/s=105.33  prediction: \"ach other and spiral deeper into madness\" => \"lk a     t                  eeeeeee eee \"\n",
      "batch 10578  loss=142.3075  steps/s=105.66  prediction: \"aking a day off caffeine helped fix this\" => \"ne ao  l nanaa aaa  aafaaff fffffe ffe  \"\n",
      "batch 10579  loss=162.5453  steps/s=103.83  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yne    e      s       ee   ffeeeeee ooee\"\n",
      "batch 10580  loss=141.1165  steps/s=104.68  prediction: \"t on bad apple vs python library anyways\" => \"hmi tt h      o    p  pp    pp p     yyy\"\n",
      "batch 10581  loss=137.9463  steps/s=102.88  prediction: \" my weird posts but im happy nonetheless\" => \"tote er  tete  t      t                 \"\n",
      "batch 10582  loss=139.2861  steps/s=104.53  prediction: \"oast. silencio until youve made progress\" => \"ul ttt    t   is tiii iiiii  i    o     \"\n",
      "batch 10583  loss=158.5521  steps/s=99.27  prediction: \"a exactly\n",
      "\n",
      "just mon and thurs every week\" => \"tp uu  aa eeaa c t  y  tn   t     n  ree\"\n",
      "batch 10584  loss=134.1834  steps/s=102.27  prediction: \" will get back to you when this is fixed\" => \"tahe   w l ll l                         \"\n",
      "batch 10585  loss=159.3082  steps/s=92.09  prediction: \"bly same, llms are so much faster though\" => \"uy w l l lll  lll    l      h    h    t \"\n",
      "batch 10586  loss=160.1849  steps/s=101.25  prediction: \"ff has been helping ppl. I love humanity\" => \" i  e m f  f  ee        e       l    l l\"\n",
      "batch 10587  loss=167.1648  steps/s=108.05  prediction: \"JUST POST so i dropped a draft out there\" => \"osy rus  f S ST T                      t\"\n",
      "batch 10588  loss=163.6064  steps/s=46.00  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \": @ ufs   T T Ts            d          t\"\n",
      "batch 10589  loss=192.8096  steps/s=136.85  prediction: \"Dev i gotchu bro https://t.co/RX6EFjv6Nb\" => \" diySa ue  i     op pp   r  at/o /t/to66\"\n",
      "batch 10590  loss=139.4189  steps/s=102.36  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"ertil ii i    e          e   ii iiiiiiii\"\n",
      "batch 10591  loss=149.3066  steps/s=102.25  prediction: \"eting ppl on here\n",
      "\n",
      "the next half WE BALL\" => \"      eeette   e  e     eee ee eee      \"\n",
      "batch 10592  loss=234.9077  steps/s=85.70  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"VSehe        n  E FFRFR e ttttt/W/WW WLL\"\n",
      "batch 10593  loss=211.8204  steps/s=104.89  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \" rJrRaTtlTlTl00MMMtM03ML30LL00L44tt0ttto\"\n",
      "batch 10594  loss=142.4568  steps/s=103.83  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"  ien         g       eeeeeegegeeehhh h \"\n",
      "batch 10595  loss=145.0526  steps/s=103.38  prediction: \"ions you choose, like oregon or whatever\" => \"nn te  o o ooono ooo  ooooooooo o o  o o\"\n",
      "batch 10596  loss=148.4685  steps/s=104.54  prediction: \"s how to do this w reasonable efficiency\" => \" oend   so oo  oo         oo o      e  a\"\n",
      "batch 10597  loss=152.6361  steps/s=105.38  prediction: \"mentals can be really really hard to see\" => \"e t me monssnna  n aaa  aaalall  alll   \"\n",
      "batch 10598  loss=152.7295  steps/s=96.29  prediction: \"anks maaan. i want it to load SUPER fast\" => \"n  iea annaa aaaaa   a a      a  t      \"\n",
      "batch 10599  loss=158.0463  steps/s=75.20  prediction: \"izmobly you have 3 days or youre blocked\" => \"nma faaaaaaa  aan  a      a             \"\n",
      "batch 10600  loss=146.7529  steps/s=105.40  prediction: \"plate btw if u wanna make ur own version\" => \"ly: @st eete tt  t  t a   a      a      \"\n",
      "batch 10601  loss=154.6473  steps/s=105.23  prediction: \"leneck is my lack of knowledge of opengl\" => \"ystut eeet   tne e        kkko       ooe\"\n",
      "batch 10602  loss=138.9821  steps/s=105.74  prediction: \"rself or others interested in something?\" => \"esi o  i tan i nGb4+7%.bvqqD7D.xw+DbD7q?\"\n",
      "batch 10603  loss=142.8230  steps/s=98.52  prediction: \"nds like a super cool premise for a game\" => \"t  ess sss    s   s    e e  e ee    o   \"\n",
      "batch 10604  loss=149.3510  steps/s=103.06  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e iy:socnts li nBT==LGTbvL====.k,==b=8?8\"\n",
      "batch 10605  loss=156.1628  steps/s=101.68  prediction: \"nd beyond is such a gargantuan advantage\" => \"t  oioe  b    n            a aaaaaaa aaa\"\n",
      "batch 10606  loss=154.6822  steps/s=100.42  prediction: \"ieved internally https://t.co/tbnU75n8eA\" => \"nc ae e e eneeeen  e  a   tttt///////ttt\"\n",
      "batch 10607  loss=160.7240  steps/s=97.27  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \" li eiie n n l n  hh tttthttttt ////tt//\"\n",
      "batch 10608  loss=138.8742  steps/s=105.43  prediction: \"sfully improved their lives tremendously\" => \"  ete tfss s   seeeeeee ee eeee eeeeee e\"\n",
      "batch 10610  loss=198.2263  steps/s=104.03  prediction: \"needed to dl this. meme delivery service\" => \"gs h     ee   ed       e d  deeeeeeeeeee\"\n",
      "batch 10611  loss=157.6412  steps/s=90.95  prediction: \"minglunatic @kuberdenis im also catholic\" => \"ent     en n  d tt   eeeeee ie    ee eee\"\n",
      "batch 10612  loss=150.0661  steps/s=104.08  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"etw wln tott ootoo                  a  t\"\n",
      "batch 10613  loss=140.4536  steps/s=99.79  prediction: \"ellite imagery onto the photos they took\" => \" sia sltetee tttee e te  ttetto t  totot\"\n",
      "batch 10614  loss=147.9694  steps/s=103.71  prediction: \"ts one of the fundamentals of everything\" => \"  ns n   io  o       e  tee e e  ee e e \"\n",
      "batch 10616  loss=143.1610  steps/s=103.89  prediction: \"king useful things, so it didnt work out\" => \"en  kl   k k   l                        \"\n",
      "batch 10617  loss=139.4262  steps/s=104.73  prediction: \" good at developing your own techniquesâ€¦\" => \"testern tot   tooo  ooo oo  oo  oo o n  \"\n",
      "batch 10618  loss=153.7178  steps/s=103.56  prediction: \"enjoyable is such a gargantuan advantage\" => \" tiu tagnng  nn        aa aaaaaa aa aaaa\"\n",
      "batch 10620  loss=148.1032  steps/s=105.10  prediction: \"mething to run from (getting called out)\" => \"atet veeetsee t e    o          t  g t t\"\n",
      "batch 10621  loss=148.1609  steps/s=105.41  prediction: \"olve for the entire past week was a typo\" => \" ee e  en        e e e      eeeeee    e \"\n",
      "batch 10622  loss=160.1356  steps/s=100.94  prediction: \"t just means youre on par with a supergm\" => \"hte t l stsessssts   o                  \"\n",
      "batch 10623  loss=155.4938  steps/s=92.76  prediction: \"ucoder Any cracked accts you wanna list?\" => \"s  t st j    o  rc    ca      a    auu  \"\n",
      "batch 10624  loss=156.0554  steps/s=104.98  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"@s ii isniiiisi,ssssstttttttt/////////tt\"\n",
      "batch 10625  loss=161.7770  steps/s=100.59  prediction: \" stuff! Thanks, hope yours went well man\" => \"@i i hos ono   ts    h hh   h  o    e e \"\n",
      "batch 10626  loss=144.7748  steps/s=103.63  prediction: \"ploring become really clear to your mind\" => \"ly: ebae r n  be  eee ee leele  ll e  or\"\n",
      "batch 10627  loss=142.7291  steps/s=105.88  prediction: \"best ways to improve for stuff like this\" => \"u   i t  t t  e                 ffffffff\"\n",
      "batch 10628  loss=151.7607  steps/s=97.21  prediction: \"eadphones dead gonna recharge real quick\" => \" re t eehehee peee e ooe   a   rre rrree\"\n",
      "batch 10629  loss=156.1446  steps/s=43.33  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \"  @tSVeehhhee deaea   ee r re rrre   eee\"\n",
      "batch 10630  loss=151.5320  steps/s=112.93  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tai te   e t    t ttttt  tttttttttt/////\"\n",
      "batch 10631  loss=144.4130  steps/s=95.85  prediction: \"feeling than automating hrs of work away\" => \"  mi Ne eete  n ett tttatt ttt t  f s s \"\n",
      "batch 10632  loss=144.1721  steps/s=104.45  prediction: \"i can keep it up https://t.co/aDUupaUfqR\" => \"nt  s  s e c       e   p    p  pptpp///U\"\n",
      "batch 10633  loss=183.5448  steps/s=35.48  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y  ns    e e       ep  p  t /  //tpUUU/U\"\n",
      "batch 10634  loss=137.6132  steps/s=106.86  prediction: \" selected\n",
      "\n",
      "Or better yet skip selection?\" => \"tuss n neeeteeeteteeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 10635  loss=162.7869  steps/s=104.78  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne   ee M s s es   @@@@  rr rrrrr rrarrr\"\n",
      "batch 10636  loss=183.7782  steps/s=60.55  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tMu\" esussess   @@    rr rr r r  arraaaa\"\n",
      "batch 10637  loss=144.4540  steps/s=107.87  prediction: \"ers too! dunno\n",
      "\n",
      "love the experiment idea\" => \"   e tlolol oo oooooooooo oo eeeeeeeeeee\"\n",
      "batch 10638  loss=178.8360  steps/s=98.68  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tf tolint        t   ttt tttttttttt/////\"\n",
      "batch 10640  loss=147.8155  steps/s=103.39  prediction: \"isten to remixes of the ost all the time\" => \"n  ts   s s                          t  \"\n",
      "batch 10641  loss=144.5652  steps/s=99.19  prediction: \"ait to see what you cook up with giz inc\" => \"nn  it  t t   et  t t  o o o   oo   o  i\"\n",
      "batch 10642  loss=149.8192  steps/s=102.88  prediction: \"ull potential. That would be surprising.\" => \"sde       ttttt  t   tttl  t ll        u\"\n",
      "batch 10643  loss=159.1253  steps/s=98.93  prediction: \"in a year, and this was his main opening\" => \"nk e       0  0    a     a  aa   aaaii  \"\n",
      "batch 10644  loss=142.2316  steps/s=107.89  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \" n  ppp oog    g  e   eeee eee    e     \"\n",
      "batch 10645  loss=142.8044  steps/s=104.86  prediction: \"10mins on a puzzle just try ur best gues\" => \"602   ee les ef\n",
      "Kqjqq10WkjqWfqqqqqNNNWkâ€¦\"\n",
      "batch 10646  loss=146.0772  steps/s=105.00  prediction: \"learning models\n",
      "\n",
      "https://t.co/KAmykVYFyw\" => \"ys  rnr non ee eneeoeeeennet//ts////ttmt\"\n",
      "batch 10647  loss=145.8043  steps/s=104.04  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t le  e               o  t t:t//ttttt///\"\n",
      "batch 10650  loss=144.7250  steps/s=103.80  prediction: \"ck inside my brain. not sure what though\" => \"eeceotcetie    ci     iii i i    n      \"\n",
      "batch 10651  loss=133.4948  steps/s=101.58  prediction: \"and run it in the front end of a browser\" => \"nde     d                               \"\n",
      "batch 10652  loss=165.4990  steps/s=99.43  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" y e y  e i     k    tt  ttt  ttt o///co\"\n",
      "batch 10653  loss=144.2487  steps/s=104.00  prediction: \"d building things with skills new to you\" => \" tg  n  n n  iiiiiiiiiiiiiiiiii         \"\n",
      "batch 10654  loss=146.2324  steps/s=102.02  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"  ns ansada ssa s            n   n      \"\n",
      "batch 10655  loss=176.4451  steps/s=98.40  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \" hnslanant    a      LLLLLLtttttttt////9\"\n",
      "batch 10657  loss=161.3088  steps/s=97.42  prediction: \"t new one is kinda Y shaped too in a way\" => \" we    ontn   s       s s a  Ya a  ooooo\"\n",
      "batch 10658  loss=154.3873  steps/s=95.44  prediction: \" it sucked but couldve been 1000x worse.\" => \"tn n A  n     t         u    e    e   00\"\n",
      "batch 10659  loss=148.7637  steps/s=92.46  prediction: \"ttler experimentation games are the best\" => \" in  t net te e  eutt  eene ee e eeee ee\"\n",
      "batch 10661  loss=142.1750  steps/s=98.62  prediction: \" time on their hands + survivorship bias\" => \"th t      o   t                   r rr i\"\n",
      "batch 10662  loss=149.5599  steps/s=106.20  prediction: \"nd super useful: https://t.co/i2lqZZ1GQR\" => \"g it  vo suu uuuu  uuu  sssst: :/t//tZ/Z\"\n",
      "batch 10663  loss=138.3365  steps/s=105.52  prediction: \"n, tons of alpha is already in your head\" => \"g ntontot ttt at o  a a   aaaa          \"\n",
      "batch 10664  loss=130.9838  steps/s=105.39  prediction: \"ounts for new lengths of weeks/months ig\" => \"u wn n o n   o   n   n       eeeee  e e \"\n",
      "batch 10665  loss=182.4704  steps/s=103.29  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns  n   n          o   ttt  tttttt////t/\"\n",
      "batch 10666  loss=141.4973  steps/s=104.41  prediction: \"good idea but whatever, i wanna have fun\" => \" odtnn  no    o    t        aa   aaaa aa\"\n",
      "batch 10667  loss=177.0629  steps/s=29.70  prediction: \"ply: @yacineMTB sent from my xerox phone\" => \"ly: @g   d     d   t        aa   aaaa aa\"\n",
      "batch 10668  loss=144.5627  steps/s=109.65  prediction: \"ven a bit is a huge anti pattern i think\" => \"er  te\n",
      "eebn   beii            a    tt   \"\n",
      "batch 10669  loss=142.4986  steps/s=104.75  prediction: \"10mins on a puzzle just try ur best gues\" => \"6 r    e lee er\n",
      "9Hj$$109kj$994$$%#####k4\"\n",
      "batch 10670  loss=178.6836  steps/s=91.31  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \"hen g nnn t a e  a      t  t t   /t s   \"\n",
      "batch 10672  loss=146.5666  steps/s=104.24  prediction: \"ill consider leaning into it more though\" => \"nl        n    dl l  i iiiniiii         \"\n",
      "batch 10673  loss=156.8520  steps/s=101.61  prediction: \"le brotha, ill dm you a link on the 25th\" => \"ya @sx ec tc tt   l  l l                \"\n",
      "batch 10674  loss=146.6869  steps/s=103.90  prediction: \"e real for this\n",
      "\n",
      "https://t.co/XuMxlWAwBE\" => \" bea llalaa  a a lr \n",
      "\n",
      "  t\n",
      "\n",
      "\n",
      "tttt\n",
      "/t/ttt/\"\n",
      "batch 10675  loss=143.3740  steps/s=102.69  prediction: \"nly do this technique if I involve words\" => \"gy u                          iii       \"\n",
      "batch 10676  loss=156.3704  steps/s=104.06  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" rn   n  p il   l lll   l tt    ttt//t/3\"\n",
      "batch 10677  loss=159.4050  steps/s=96.82  prediction: \"e to you brother https://t.co/nLfQJqRwZ9\" => \" piaeo  oe i    o  htt tt/////tt////tt..\"\n",
      "batch 10679  loss=151.5076  steps/s=95.44  prediction: \" literally can\n",
      "not good for computer tho\" => \"tii yoy    e lllyl llttooo oooonooo tooo\"\n",
      "batch 10680  loss=136.3280  steps/s=101.02  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \"el  un   n n                            \"\n",
      "batch 10681  loss=156.3946  steps/s=99.43  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"ene   a nd n         s  s  t ttttt/////t\"\n",
      "batch 10682  loss=155.6362  steps/s=101.90  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \" \n",
      " i siciililiiillllll   i              \"\n",
      "batch 10683  loss=155.6650  steps/s=106.92  prediction: \"le brotha, ill dm you a link on the 25th\" => \"y  @te ec tc  t   l                     \"\n",
      "batch 10684  loss=138.3727  steps/s=102.43  prediction: \"sts w good content from this perspective\" => \"  e     s s  o ooooo ooooo t  tt      tt\"\n",
      "batch 10685  loss=134.5724  steps/s=104.91  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia te  lllt  t t   nntttttttttttntttttt\"\n",
      "batch 10686  loss=166.5144  steps/s=102.59  prediction: \"like scalars\n",
      "\n",
      "d(Mx)/dx = M\n",
      "\n",
      "d(Mx)/dM = x\" => \"yksreate see   aaaasaa\n",
      "sxx\n",
      "\n",
      "MMxMMxMxdMMx\"\n",
      "batch 10689  loss=196.2458  steps/s=44.96  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \": @reice eas ss \n",
      "aasxx xMM\n",
      "\n",
      "\n",
      "MxMx)Md===x\"\n",
      "batch 10690  loss=143.4126  steps/s=107.47  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  t     t t  t t  t tt    llle l  ll ll\"\n",
      "batch 10691  loss=167.2034  steps/s=102.54  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yke y   t     t       e  e ee eeeee ooee\"\n",
      "batch 10692  loss=162.1684  steps/s=105.42  prediction: \"ng up every word you hear more than once\" => \"   wor  o eo     r    o   o    r    r   \"\n",
      "batch 10693  loss=164.3601  steps/s=100.56  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \" l    weee   eet  e!eee e e    t    nn  \"\n",
      "batch 10694  loss=135.1624  steps/s=105.06  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" t ts ssseesssssseeeee ee ee            \"\n",
      "batch 10695  loss=173.0602  steps/s=101.54  prediction: \"eople be bookmarking anything these days\" => \" sii @__re  e   ee e    k  a  nanannnn n\"\n",
      "batch 10697  loss=138.2144  steps/s=103.80  prediction: \" or not so i dont have much data on that\" => \"tf   oo    o                            \"\n",
      "batch 10698  loss=159.9367  steps/s=103.17  prediction: \" funny i like it https://t.co/gxpcMrRiHL\" => \"tunfrurrnun      ee       ei i  t i  /t \"\n",
      "batch 10699  loss=162.3661  steps/s=96.44  prediction: \"y based. how do you compile zig to wasm?\" => \" m uizy bib    b ed     / coco cccppiit \"\n",
      "batch 10700  loss=152.7554  steps/s=96.43  prediction: \"the man stretches his mind and his limbs\" => \"hem tlx    m    e  th  th         i  is \"\n",
      "batch 10701  loss=168.1977  steps/s=45.07  prediction: \"y: @01beigecamry https://t.co/qAESPOcfdy\" => \": @0xn0 n n   eeeh hs  sh            is \"\n",
      "batch 10702  loss=170.0858  steps/s=125.00  prediction: \" job adding the australian language pack\" => \"tu e c jjn ne  te  ts  a t a   an aallaa\"\n",
      "batch 10704  loss=140.2256  steps/s=103.82  prediction: \"reevaluating concepts you often overlook\" => \"eply  aw n    rb|Q##X#ð—¯#å€‘QQ{ZðŸ˜­ÊŸQå€‘{ðŸ¤¯$ÊŸ$]|\"\n",
      "batch 10705  loss=157.4147  steps/s=103.78  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"   t et ttn t b r o  r   o    yo  t  t r\"\n",
      "batch 10707  loss=167.3799  steps/s=95.49  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \"_kf ert t    o w  y  yr rt  t tt  t  t  \"\n",
      "batch 10708  loss=155.0159  steps/s=100.27  prediction: \"ny part of a much bigger long term thing\" => \"   t  aaaaana n                     gggg\"\n",
      "batch 10709  loss=148.0356  steps/s=103.48  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tad ia ii it it ii iiii r ii            \"\n",
      "batch 10710  loss=155.3163  steps/s=90.09  prediction: \"eMTB i wonder which anime pfp is his alt\" => \" TB ittinn i i  i i d     hi            \"\n",
      "batch 10711  loss=154.1586  steps/s=104.57  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"epe\n",
      "  a   t    .Pz@G-&Gx;GGGBG,JJ-v&0;;6\"\n",
      "batch 10713  loss=182.4051  steps/s=29.83  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"lex @paee nee            t       ii  i  \"\n",
      "batch 10714  loss=141.9499  steps/s=109.18  prediction: \"x len output, custom system prompts, etc\" => \"_pv tet  e   uutuu uuuutuuttttt mttmtttt\"\n",
      "batch 10715  loss=154.3636  steps/s=104.78  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"se.ceetta///tt///ttS44tS444:tttt:///tt//\"\n",
      "batch 10716  loss=165.4812  steps/s=104.74  prediction: \"/t.co/YpddagC5uf https://t.co/GdftPhw7eI\" => \"/..c:t00:Y/:YYt//tt//ttttt/////ptp/ttdtt\"\n",
      "batch 10717  loss=172.0177  steps/s=102.81  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/..c::/  ////T/////OOttOOO////ttt////t//\"\n",
      "batch 10718  loss=140.3900  steps/s=104.95  prediction: \"irl. So in irl it is probably not as bad\" => \"nn a    r  n  ii  i   i  i  i        b  \"\n",
      "batch 10719  loss=149.1178  steps/s=103.30  prediction: \"son but thats OK https://t.co/f85X6nDeZy\" => \" m a r o e  e  st tt  st tt tttttt ttttt\"\n",
      "batch 10720  loss=153.8923  steps/s=102.60  prediction: \"el you save\n",
      "\n",
      "hmm interesting interesting\" => \"  rr  r  eu  e e    e eeeeme e teeentene\"\n",
      "batch 10721  loss=158.3848  steps/s=104.24  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"n e te                              o oo\"\n",
      "batch 10722  loss=171.5873  steps/s=73.85  prediction: \"yon Super hyped to see what youre cookin\" => \" u  ho  ,y         he    h hho  ho ooooo\"\n",
      "batch 10723  loss=144.6629  steps/s=110.44  prediction: \"utomatically imagine letters as colored?\" => \"r  b oo uoo aaoaaaa aaa aaaa tt    e  e \"\n",
      "batch 10725  loss=145.8006  steps/s=100.15  prediction: \"plate btw if u wanna make ur own version\" => \"ly:    eebt  tm  t  t a   a      a      \"\n",
      "batch 10726  loss=192.5607  steps/s=97.32  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eely: @g oeno 1n@7Q1Qx0f:Q7I)))k.H,k7.:,\"\n",
      "batch 10727  loss=152.5334  steps/s=104.45  prediction: \"mes often times.\n",
      "anyone can pivot though\" => \"e  ere ess teeeese eeeneennnnenn  nnnn  \"\n",
      "batch 10728  loss=146.0731  steps/s=99.95  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"esly: @ itlc adhjå€‘'#Z+0'ká´f.)ð˜€):[H,{j]ww\"\n",
      "batch 10729  loss=147.7126  steps/s=94.46  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"ta dere eene een    e e   ee     s  s oo\"\n",
      "batch 10730  loss=147.5478  steps/s=105.13  prediction: \" muscle for mentally doing them will get\" => \"tott err terr r rr   e   ll   le    mll \"\n",
      "batch 10731  loss=164.5517  steps/s=75.92  prediction: \"aulg We like memoizing physical patterns\" => \"ns h r   le e  eoe  ml   nn   ly  i tl  \"\n",
      "batch 10732  loss=149.2696  steps/s=106.74  prediction: \"ey once, will play otb w friends usually\" => \"  a   n don             l               \"\n",
      "batch 10733  loss=141.6417  steps/s=105.89  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"ewlflnaarnmr   \n",
      "èµ°|{â˜ #[}ðŸš€|(#Êœá´˜#â€(}[`$`(â€¦Ê€\"\n",
      "batch 10735  loss=173.5216  steps/s=100.53  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \" t thno  me   n   ee   e   thttttt//////\"\n",
      "batch 10737  loss=150.0096  steps/s=99.36  prediction: \"mirages keep getting crazier and crazier\" => \"enh a       ee eeeteeettttttgrtttr crrrz\"\n",
      "batch 10739  loss=153.8334  steps/s=103.16  prediction: \"ncy, and bitcoin was invented by midwits\" => \" e oi eini    nn           nnnn  nn     \"\n",
      "batch 10740  loss=174.1046  steps/s=98.84  prediction: \"Incredibly based\n",
      "https://t.co/IOxblXKnJv\" => \"nca  acn  nc bn bbb bbb  ttttte/ttt i///\"\n",
      "batch 10741  loss=132.9354  steps/s=105.52  prediction: \" to ignore such gaps in order to make aâ€¦\" => \"toe s a   n o er                r       \"\n",
      "batch 10742  loss=145.5202  steps/s=102.49  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"tooii wr g w   e    e e  g    o         \"\n",
      "batch 10744  loss=150.6014  steps/s=104.84  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lo   o     bbbb bbb bb b bb             \"\n",
      "batch 10745  loss=146.7783  steps/s=104.15  prediction: \"al, one of the most cracked players ever\" => \"nl  ooe   o   o o o    o       e     eee\"\n",
      "batch 10746  loss=139.6808  steps/s=105.20  prediction: \"ngry each chunk) it pretty much kills it\" => \"g   e da l                              \"\n",
      "batch 10747  loss=158.1156  steps/s=106.05  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" nao      e    eee eee e l ffffff f     \"\n",
      "batch 10748  loss=140.4055  steps/s=104.91  prediction: \"our phone constantly. i had this problem\" => \"ulol  n  con   cooononn  n   n h        \"\n",
      "batch 10749  loss=144.6558  steps/s=102.55  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" k n    d dd  d               ??????    \"\n",
      "batch 10750  loss=167.1014  steps/s=78.95  prediction: \"wphones Love the plan, sounds meaningful\" => \"ahn y    doo    o   tt  ???    oos      \"\n",
      "batch 10751  loss=159.6138  steps/s=105.55  prediction: \" harmony until the clown nation attacked\" => \"tad dn  dn    t i  l     n  nt  nnan nna\"\n",
      "batch 10752  loss=167.8403  steps/s=104.47  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"g eneter eeeee eeeee e d dadddadaaaaaaad\"\n",
      "batch 10754  loss=154.0428  steps/s=104.13  prediction: \"matching pixels\n",
      "Reward for clearing rows\" => \"eneiror non     im   i    r   a  errrr e\"\n",
      "batch 10755  loss=143.0063  steps/s=104.13  prediction: \" games because we trusted each other lol\" => \"tee   aemems eme e ee se ee ee see e  ee\"\n",
      "batch 10756  loss=129.1943  steps/s=102.40  prediction: \"to use resumes if lying becomes the meta\" => \"    ies s sessssessss     e  e     ee ee\"\n",
      "batch 10757  loss=171.7189  steps/s=101.18  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"      g gg gggg  gg ggg gttt   ttttt////\"\n",
      "batch 10759  loss=154.7122  steps/s=105.57  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"   t/ts:h////tt//ththhttttt////ttt////P/\"\n",
      "batch 10760  loss=169.0027  steps/s=100.64  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "an pr@Rri.O GMAz)GMWPS?)(`Z\"vá´›:vkPHDZ6B\"\n",
      "batch 10761  loss=148.8936  steps/s=102.03  prediction: \" of your day your brain will work better\" => \"tnp t r t  e  rr   yy  r  y r       r   \"\n",
      "batch 10762  loss=143.6134  steps/s=105.76  prediction: \"y, gpt 4o was bad at the first iteration\" => \": r a   nl t      a      a       t  t tt\"\n",
      "batch 10763  loss=144.9492  steps/s=100.94  prediction: \"ding up the drive thru for 1000 episodes\" => \" v  e e  e n  n                   000000\"\n",
      "batch 10764  loss=143.3150  steps/s=103.65  prediction: \" end of the task off worked for you too?\" => \"tx tdneteett                  f      ooo\"\n",
      "batch 10765  loss=139.8303  steps/s=105.66  prediction: \"code base to get something super complex\" => \"hmik tet tet   e e   e  e      e     ee \"\n",
      "batch 10766  loss=178.7307  steps/s=96.20  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" B t tet e  bbbb sbb t    ss suuu hooo h\"\n",
      "batch 10767  loss=146.2806  steps/s=105.90  prediction: \"y with any industry/niche and ill run it\" => \":si aei y yn inyyyyyynnnynnnnnn  n n n  \"\n",
      "batch 10768  loss=220.4268  steps/s=11.72  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"epli  e        oPQ@ðŸ’ªðŸ’ªkQðŸ’ªðŸ’ªðŸ’ªkDHxCTMKjvTHQðŸ’ª\"\n",
      "batch 10769  loss=142.8581  steps/s=108.75  prediction: \"y fundamentals are hidden in plain sight\" => \"om  a ymmnanmamnaaannaaa   nn  nn     in\"\n",
      "batch 10770  loss=144.5704  steps/s=104.91  prediction: \"discovering new unseen fundamentals, too\" => \" n  e   d en  edn nnennnneenennnneennnen\"\n",
      "batch 10771  loss=144.6457  steps/s=105.92  prediction: \"ly harder than the last. repeat forever.\" => \"y: @Ri g thehhhhhhhhh h  t      t  eeeee\"\n",
      "batch 10772  loss=154.1755  steps/s=104.38  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"ejgs iWe si \"W \"W/{q!xZvFFvR\"Lð—µÊ€-jjITTâ€¦I\"\n",
      "batch 10773  loss=145.6055  steps/s=104.93  prediction: \" know. But this will help you immensely.\" => \"te    d no   o t                 l    ll\"\n",
      "batch 10774  loss=150.3304  steps/s=102.76  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e  t:s@cndsocikn\n",
      "T.qBMTR$L/6R^â€™$É´æˆ‘W~vTâ€¦y\"\n",
      "batch 10775  loss=159.0167  steps/s=89.94  prediction: \"hones Hype, solid 4hr block, lets get it\" => \"eu   eee sese e el l  ll   oo   l os   t\"\n",
      "batch 10776  loss=146.7906  steps/s=104.82  prediction: \" realize big companies innovated anymore\" => \"teskdnd dod  d   iiii ii iiiniiinnnannn \"\n",
      "batch 10777  loss=140.2197  steps/s=104.12  prediction: \" us safe from undetectable Dyson spheres\" => \"tn enne neen   f     eeee e eeeee eeeeee\"\n",
      "batch 10778  loss=168.1407  steps/s=38.45  prediction: \"ly: @morew4rd Gettin there, yup\n",
      "Soooooon\" => \"y: @nn  fe e   fe  e eeee e eeeee eeeeee\"\n",
      "batch 10779  loss=153.1468  steps/s=110.42  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltee nellslsposps koookkoooonoono nono  \"\n",
      "batch 10780  loss=156.6007  steps/s=103.17  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"eple  nt eelapebTTxML,/jZkiZ,E:4v,.cy@EY\"\n",
      "batch 10781  loss=173.2489  steps/s=52.90  prediction: \": @IterIntellectus here have another one\" => \" Glab  t e  apeiTTxML:/j\n",
      ".iR,E:4v,.cyMEY\"\n",
      "batch 10782  loss=146.1507  steps/s=112.86  prediction: \"ols is kinda like cookie clicker but irl\" => \"ut  ioi i iiiitii  ii iiii oikkkkkc ci i\"\n",
      "batch 10783  loss=139.5153  steps/s=104.48  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  a     at              tttttt///tt////\"\n",
      "batch 10785  loss=159.0737  steps/s=102.67  prediction: \"ameboy emulator) https://t.co/og8bnpdUHw\" => \"ne sead ebeb  e a   a     t   ttttt////o\"\n",
      "batch 10786  loss=153.7334  steps/s=102.88  prediction: \"ore descriptive titles for the rest lool\" => \"rk ee   ene   rneeiiiiiieee eettre e  tt\"\n",
      "batch 10787  loss=137.3809  steps/s=104.33  prediction: \"mands it outputs\n",
      "https://t.co/dWiO4erSb1\" => \"andti t nn     ot ttttttttttttttttt/t//t\"\n",
      "batch 10788  loss=145.6578  steps/s=104.52  prediction: \"s, have back and forth conversations etc\" => \"  ht  h  sha    a   a                   \"\n",
      "batch 10789  loss=139.6582  steps/s=104.88  prediction: \" use commonly are invisible fundamentals\" => \"tps  ep   le  l  l     l   e      e nann\"\n",
      "batch 10790  loss=164.3445  steps/s=88.74  prediction: \"igABAP Born to consoom, forced to signal\" => \"nA t ee m mmo m  o  oo o n noo    nenann\"\n",
      "batch 10791  loss=142.8863  steps/s=104.45  prediction: \" dingboard. Several others ive seen irl.\" => \"tone       i  e            eeeeeeee eeee\"\n",
      "batch 10792  loss=160.5897  steps/s=99.67  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"to iini d e ttne eetettteetht tttt////t/\"\n",
      "batch 10794  loss=149.4886  steps/s=100.88  prediction: \"ind groups of ppl who love what you love\" => \"ne y ts                     o  o       o\"\n",
      "batch 10795  loss=155.3493  steps/s=103.88  prediction: \"ce nice\n",
      "Any idea what youre gonna print?\" => \"a  to  no  cnn n  ni    e  e    a    oo \"\n",
      "batch 10796  loss=176.1570  steps/s=103.86  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \" e u\n",
      "tes t ts s o  t o oosoossoooooooooo\"\n",
      "batch 10797  loss=144.3941  steps/s=100.91  prediction: \"the beta (should be around the 25th)\n",
      ": D\" => \"he ls   n ee  ee                        \"\n",
      "batch 10798  loss=140.1201  steps/s=103.99  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"@reos m    mmmm mmmm  m mmttt ttttttpppp\"\n",
      "batch 10799  loss=143.1007  steps/s=105.16  prediction: \"house? where is your phone charger? etc)\" => \"er eyoroe e  e re  e e      eo h  h rre \"\n",
      "batch 10800  loss=148.9947  steps/s=94.65  prediction: \"r cool. i wish llms were better with zig\" => \"etoy  ? az  bateOOOOvv.(OOO.cOOO.O(?OOOO\"\n",
      "batch 10801  loss=155.9693  steps/s=104.48  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nraaa al nnananammmmmmmmm mmmm          \"\n",
      "batch 10802  loss=144.2077  steps/s=104.82  prediction: \"onder if he stuck w onnx or went w tf.js\" => \"u   lelele                              \"\n",
      "batch 10803  loss=147.0376  steps/s=98.59  prediction: \"uick free working solution, see my tweet\" => \"nl       ie    k kk    kooooo  o    t   \"\n",
      "batch 10804  loss=137.0512  steps/s=104.09  prediction: \"entation, the cooler everything will get\" => \"  te  to moottettttoooeeeeeeeeee eeeee e\"\n",
      "batch 10805  loss=163.7717  steps/s=101.85  prediction: \"cost) is probably a better way to put it\" => \"hmienlttniitiiiii bbb bbbb bb           \"\n",
      "batch 10806  loss=139.4731  steps/s=103.34  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"eply: @sa s    !YBâ€œÉ´!á´€B[*(Z]Z*($`å€‘$$ðŸ˜­Z)É´\"\n",
      "batch 10807  loss=177.1593  steps/s=96.17  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"etty: @     i  \n",
      "YB@j!:/@j.BB,z48W4TB8Z)T\"\n",
      "batch 10808  loss=147.8275  steps/s=104.86  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t  k a   e r  Ir     r   o   o  o    t  \"\n",
      "batch 10809  loss=145.7223  steps/s=105.00  prediction: \"de you hate work\n",
      "https://t.co/2jmiAqT1C6\" => \"  ini n th a  h       ttttttttt/////////\"\n",
      "batch 10810  loss=153.4243  steps/s=102.18  prediction: \"ce nice\n",
      "Any idea what youre gonna print?\" => \"o cioo no ecnncn  ee    e  e e  eo   oa \"\n",
      "batch 10811  loss=166.3558  steps/s=97.45  prediction: \"ly @plasmarob you could have a miz mobly\" => \"y: @ic inn n   na a  y   uu    o    a n \"\n",
      "batch 10813  loss=150.7899  steps/s=104.61  prediction: \" drains your energy by paying attentionâ€¦\" => \"tett ia  nn   gr  n   y yyyyyy yyyy   nn\"\n",
      "batch 10814  loss=137.3320  steps/s=106.73  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \"     t t tt ttotttooooooo ott s         \"\n",
      "batch 10815  loss=149.4613  steps/s=103.00  prediction: \"n\n",
      "Meet the new boss\n",
      "Same as the old boss\" => \" \n",
      "sen  een eeet neeee eesee e   e   e  s\"\n",
      "batch 10816  loss=139.9353  steps/s=102.35  prediction: \"ot a lot of sleep last night, feels good\" => \"u  de t  t ooo    o l   l        t  eee \"\n",
      "batch 10817  loss=138.2814  steps/s=106.13  prediction: \"e forever with a simple 5min interaction\" => \" sif oeeefeneeffe                iiiiiii\"\n",
      "batch 10818  loss=146.7070  steps/s=104.36  prediction: \" carry/drop 100s per run\n",
      "\n",
      "auto lifeguard\" => \"tat    a rarrr   rrr  rrr rrrrr  r   u r\"\n",
      "batch 10819  loss=152.9372  steps/s=95.60  prediction: \"nes @micsolana same for my history class\" => \"gcalronroron  s ass   a    r        u  r\"\n",
      "batch 10820  loss=149.4175  steps/s=103.74  prediction: \"sy and they put bugs in the concrete lol\" => \"      ba n n   n                        \"\n",
      "batch 10821  loss=189.2480  steps/s=83.26  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"0 g 0 t r   @E_05@EwUC-mxvCx21Skz9v9kz9O\"\n",
      "batch 10822  loss=147.5773  steps/s=104.79  prediction: \"lding w ai is gonna get left in the dust\" => \"y   ii iln l i i                        \"\n",
      "batch 10823  loss=143.6731  steps/s=101.50  prediction: \"ans are measured in centuries. (im ngmi)\" => \"n  e TBT  n     a  aae  ee eeee eeeeiii \"\n",
      "batch 10824  loss=145.0287  steps/s=103.18  prediction: \"think you can do cdn type stuff w em btw\" => \" e     ott n   n  n   o     n           \"\n",
      "batch 10825  loss=152.6228  steps/s=101.01  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "rteg @aa4 th_emZI,1jIZ$[jI$Ê€ðŸ“ˆm{|{*`,}^k\"\n",
      "batch 10826  loss=154.7750  steps/s=104.37  prediction: \"ort (effort is proportional to time butâ€¦\" => \"ne te o te ttff fff r oooooooo otooo to \"\n",
      "batch 10828  loss=142.6916  steps/s=103.98  prediction: \"elated to status games or zero sum games\" => \" p ie s tte t t tttttttt                \"\n",
      "batch 10829  loss=142.4379  steps/s=107.78  prediction: \"tler where would you say you are on this\" => \" yr  ateett eee e e         o o         \"\n",
      "batch 10830  loss=183.6282  steps/s=52.43  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" @atns@ o sn nnAP?@?v6?6?_zq?)q(qx:FF4_F\"\n",
      "batch 10832  loss=151.3125  steps/s=117.94  prediction: \"an wrong something something bla bla bla\" => \"n ei  rrn n  nom o  g  oomnn ogg eo   g \"\n",
      "batch 10833  loss=188.0893  steps/s=92.93  prediction: \"ez5341 Will do brother. Much appreciated\" => \" i ei w na m  i   o  oooh t h e   aa  aa\"\n",
      "batch 10834  loss=151.3377  steps/s=101.61  prediction: \"gh Ive been wanting to do a wasm project\" => \" t illr l  l   e e   e en               \"\n",
      "batch 10835  loss=169.0498  steps/s=73.61  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \"nwlh    eb ee  nnnn nn               a  \"\n",
      "batch 10836  loss=140.3306  steps/s=107.39  prediction: \"ns you get the yellow letters on lichess\" => \"g eai i s     te           ee eeeeeelee \"\n",
      "batch 10837  loss=157.6290  steps/s=104.02  prediction: \"st tab\n",
      "\n",
      "other than that, not much so far\" => \"  tt t ttoo tth t tttt tttthtt  tt hh   \"\n",
      "batch 10839  loss=157.0685  steps/s=100.59  prediction: \"[listen to tpod] https://t.co/T4E8ws1uTP\" => \"0e   tel st t ttttt ttt tttttttt//////TT\"\n",
      "batch 10840  loss=143.1081  steps/s=105.32  prediction: \"10mins on a puzzle just try ur best gues\" => \"0 r k s0 l e ee\n",
      "q?j??10Bkj?FF2?qFFFFFZkF\"\n",
      "batch 10842  loss=166.1980  steps/s=104.31  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"  es  t sesses00000  t000 /ttt 0///tt/t/\"\n",
      "batch 10843  loss=156.4128  steps/s=102.89  prediction: \"o church\n",
      "Starting everything immediately\" => \" fonoo ot  c  nthttttttttttttttrtiiiiiei\"\n",
      "batch 10844  loss=152.6843  steps/s=105.55  prediction: \"f children will build my programs for me\" => \"ogoot   m      r      l  l  l l      r r\"\n",
      "batch 10845  loss=148.1799  steps/s=100.75  prediction: \" surprised at how clean of a read it was\" => \"toa ean   rs  es                        \"\n",
      "batch 10846  loss=138.6964  steps/s=105.51  prediction: \"d of random strings, and removing a bitâ€¦\" => \" an i n  n n   n n    nn n     nn       \"\n",
      "batch 10847  loss=199.0368  steps/s=90.60  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eeoy: @i  4i   wOM_1kE0OI^Ou:IEOA^:[O.8S\"\n",
      "batch 10848  loss=150.6870  steps/s=102.58  prediction: \"surely you will not regret this decision\" => \" pit raattt    t loo    l   r    tee tei\"\n",
      "batch 10849  loss=147.0543  steps/s=100.86  prediction: \"ly know how many angels fit on a pinhead\" => \"y: @I    l w    ww    n n          n    \"\n",
      "batch 10850  loss=148.2738  steps/s=100.31  prediction: \"od simclusters chosen principle engineer\" => \"u ee e    o o m   sss ssss sscss cnnnnne\"\n",
      "batch 10851  loss=147.1460  steps/s=101.01  prediction: \"re just doin their part to get us to AGI\" => \"e ly  \n",
      "s dl e jl'M_1\n",
      "TMzIq..jIqk.6w+k\n",
      "Th\"\n",
      "batch 10852  loss=149.5330  steps/s=104.83  prediction: \"he just checkmated because he got lucky\"\" => \"e  i\"\"\"\"hh\" hhshhhhee eeeecceeceeeeeeee \"\n",
      "batch 10855  loss=152.7829  steps/s=103.31  prediction: \"ls similar to me\n",
      "larger battery capacity\" => \"ye  t  ese  s es e     e  a rr raraaaarr\"\n",
      "batch 10856  loss=144.2581  steps/s=104.49  prediction: \"at can be beaten if you look hard enough\" => \"res  es sse ae tee   e                  \"\n",
      "batch 10857  loss=203.2974  steps/s=105.85  prediction: \"ly @covix2772 â˜ ï¸ https://t.co/2A3p3rDVtF\" => \"y: stn    bb    2 22 2  t    tt  /// oo3\"\n",
      "batch 10858  loss=135.0097  steps/s=99.78  prediction: \"to it so you can share with your friends\" => \"  t e   t ts                            \"\n",
      "batch 10859  loss=138.2208  steps/s=105.38  prediction: \"igh quality outputs with infinite tokens\" => \"nA b    uhhg    uu uu  uuttitttiitititii\"\n",
      "batch 10860  loss=149.9975  steps/s=101.36  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"uit  noo ronoo nooo    o      ee eeee  e\"\n",
      "batch 10861  loss=158.7056  steps/s=102.60  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" oon ' n on    n    o o            m    \"\n",
      "batch 10862  loss=149.4191  steps/s=101.19  prediction: \" of why i used to get work sniped looool\" => \"tu e he gf    w                         \"\n",
      "batch 10863  loss=145.1780  steps/s=103.43  prediction: \" into an age with a lot of visual beauty\" => \"tn eg nenne   n                         \"\n",
      "batch 10864  loss=138.1538  steps/s=103.23  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "Iren n ul h u d8,66,8666,k688,66666YYYY\"\n",
      "batch 10865  loss=142.5823  steps/s=102.95  prediction: \"hinks he might pick up in future decades\" => \"ep  ini nin  hihh  i h   i              \"\n",
      "batch 10867  loss=168.0185  steps/s=99.77  prediction: \"w! I love hearing what works/what doesnt\" => \"h'd   e  l   en  e        w     wh  wwaw\"\n",
      "batch 10868  loss=150.4018  steps/s=102.76  prediction: \"thats a good one, comparing with experts\" => \" ie   et tt    t  o     oooo  oo    e e \"\n",
      "batch 10869  loss=138.1100  steps/s=99.05  prediction: \"ould color their pill white for the lolz\" => \"ur h  s lo ooolooo    rll   li     i    \"\n",
      "batch 10870  loss=194.0125  steps/s=97.16  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \"0@y  a etnare  n41ISIBvIBRBvRLRLOWONSRSP\"\n",
      "batch 10873  loss=167.8393  steps/s=29.63  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly: @huuer euuur  uuprr i iB B  o   OO O\"\n",
      "batch 10874  loss=140.7285  steps/s=107.88  prediction: \"oast. silencio until youve made progress\" => \"ud  tt     es is tiii iiiii  i    o     \"\n",
      "batch 10875  loss=142.5756  steps/s=98.27  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"ter      n a  a  a o  o   o      rr   rs\"\n",
      "batch 10876  loss=146.9120  steps/s=102.04  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" disg g ion to n  o                    a\"\n",
      "batch 10877  loss=141.1616  steps/s=104.56  prediction: \"ion, which allows better problem solving\" => \"nn   te oo co co oooo  o  o   t   e  ell\"\n",
      "batch 10878  loss=143.6498  steps/s=102.30  prediction: \"isten to remixes of the ost all the time\" => \"n a s s s s                          t  \"\n",
      "batch 10879  loss=139.5666  steps/s=103.03  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"ewlyt  sa s  s \n",
      "Zâ€œIZ~z$$'Z{VG'E`}ð˜xÉª|Z`G\"\n",
      "batch 10880  loss=153.7099  steps/s=102.72  prediction: \"outworking them\"\n",
      "\n",
      "i remember that often.\" => \"u   eeee      oeo o   e eeeeeme eemeeeee\"\n",
      "batch 10881  loss=176.1593  steps/s=94.37  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nA  o   ggggygy gyyy mymmmtttttt/t//t //\"\n",
      "batch 10882  loss=153.0665  steps/s=102.49  prediction: \" way I implemented it might be different\" => \"tae  e aee  eeee e    em em me    ie iee\"\n",
      "batch 10883  loss=142.7262  steps/s=101.37  prediction: \"ns\n",
      "you me and andrew, that was super fun\" => \" t   es soso   s   o  d   d       a    a\"\n",
      "batch 10884  loss=167.7123  steps/s=66.04  prediction: \"@vorpal_strikes Does it replicate tho???\" => \"lixqh so eos   dd  d de   w  aa aaa    u\"\n",
      "batch 10885  loss=137.9297  steps/s=105.72  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e e e   et   en       tt  ttttttttttt///\"\n",
      "batch 10886  loss=140.3117  steps/s=105.06  prediction: \"ink in part bc you have more to remember\" => \"ng i e  n it  i                       e \"\n",
      "batch 10887  loss=152.3813  steps/s=103.35  prediction: \"you so here I am https://t.co/ZHK8egA7Q1\" => \" urdeoloo oo o                tttt//////\"\n",
      "batch 10888  loss=157.7147  steps/s=99.58  prediction: \"keep that in mind\n",
      "idk what brypto is btw\" => \"    ll l wle                t    t  t   \"\n",
      "batch 10889  loss=145.3800  steps/s=103.94  prediction: \"r 100x more productive, get good with it\" => \"ele :llcieeninn\n",
      "_w'gA.bGcIz'G'j11I4)3D40\"\n",
      "batch 10890  loss=138.5789  steps/s=103.40  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  tttestt tb  be       i   i       d  d \"\n",
      "batch 10891  loss=148.6760  steps/s=74.96  prediction: \"unsettler Ive made a few, its fun indeed\" => \" i ttteeettet et     d d   dd      d dd \"\n",
      "batch 10892  loss=139.3044  steps/s=108.08  prediction: \"finite strings, such as the digits of pi\" => \" llz en een ii niiiii ssssss s          \"\n",
      "batch 10893  loss=143.9217  steps/s=101.04  prediction: \"o much suffering for the DUMBEST reasons\" => \"ubnied enee       fe fffff f            \"\n",
      "batch 10894  loss=153.1281  steps/s=103.96  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \" aw   s sn     s                        \"\n",
      "batch 10895  loss=157.1313  steps/s=102.77  prediction: \" I gotta make the disc announcement oops\" => \"t  t  h tot     tt   to   ta  at    e   \"\n",
      "batch 10896  loss=209.0979  steps/s=10.85  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"eplyn Oe ne oreI\"g\"wOl/m\",.DUIwwLObO,v1k\"\n",
      "batch 10898  loss=144.8119  steps/s=112.03  prediction: \"een enough to find mentorable candidates\" => \" dt   h  e     n                nn nnnaa\"\n",
      "batch 10899  loss=145.9447  steps/s=105.45  prediction: \"n run on my laptop, which I can do w ML?\" => \" ar e    e n                            \"\n",
      "batch 10900  loss=158.5950  steps/s=86.27  prediction: \"igABAP Born to consoom, forced to signal\" => \"nh    u  o no m  no oooo co oo  c       \"\n",
      "batch 10901  loss=173.9176  steps/s=103.27  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "ye   @seee6 le16ðŸ«¡B,D:ðŸ«¡?c0:Ig100LbSD5vMH\"\n",
      "batch 10903  loss=142.3080  steps/s=102.32  prediction: \"marter you get the more the traps change\" => \"eke  asattth  te       t   e   e   e    \"\n",
      "batch 10904  loss=145.6374  steps/s=98.60  prediction: \"f you can read graphs youre already ngmi\" => \" yo is ooy    t         r    rre    aaea\"\n",
      "batch 10905  loss=150.7362  steps/s=104.75  prediction: \"e and remember as much as possible after\" => \" sia   a sa   mme e mmmmm      s  s  sss\"\n",
      "batch 10906  loss=148.8048  steps/s=102.59  prediction: \"one thing I need https://t.co/2lJdUbXtXP\" => \"u  e  nhht t            ttttttttt///////\"\n",
      "batch 10907  loss=158.6078  steps/s=106.21  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"tor  l e rec r   rurrrrr   tttt/////////\"\n",
      "batch 10908  loss=175.7870  steps/s=104.53  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OO\n",
      "\n",
      "\n",
      "a  an             d   ttttt////////\"\n",
      "batch 10909  loss=163.0304  steps/s=92.36  prediction: \"ctus infobalking https://t.co/B3UT9nTonq\" => \"o lee t nonn ele nt  tt/t/////t:////..//\"\n",
      "batch 10910  loss=141.0492  steps/s=105.38  prediction: \"y want to use something feeling-relatedâ€¦\" => \" c  aobbbbb    b  o         ee  eeeeeeee\"\n",
      "batch 10911  loss=189.4945  steps/s=76.18  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"llt  neo   t  u  oo  tt  eeeeetneeeeeete\"\n",
      "batch 10912  loss=144.9892  steps/s=114.62  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"nni   e ntgaaagaaaaaaaaa aaaaaa  a    LL\"\n",
      "batch 10913  loss=147.2626  steps/s=101.65  prediction: \"efforts\n",
      "\n",
      "mcafee still remained installed\" => \" uteee tte\n",
      "t\n",
      "\n",
      "\n",
      "f\n",
      "\n",
      "\n",
      "eeeeeleeeel leeeeeill\"\n",
      "batch 10915  loss=166.3750  steps/s=68.77  prediction: \"@codyaims 113 bots liked this one so far\" => \"lamonlef\n",
      "f\n",
      "fffeff  l  elleee  iii ee ell\"\n",
      "batch 10916  loss=151.2338  steps/s=108.56  prediction: \"ger projects the smaller ones get faster\" => \" t  tne roeer eree  re ee  lelee s eee  \"\n",
      "batch 10917  loss=147.5274  steps/s=102.34  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" of ea a  aa  re e  t  t   ttttt  /tt///\"\n",
      "batch 10918  loss=159.4504  steps/s=104.12  prediction: \"uper hard but I think it could be doable\" => \"terge lr rrpe rp rr  r    t  t        d \"\n",
      "batch 10919  loss=147.5603  steps/s=100.45  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"toaging eg we  e    e e       o         \"\n",
      "batch 10920  loss=161.1092  steps/s=101.15  prediction: \"meone should make a zig finetune dataset\" => \"e e  e  @seooonoeo  e          e     e  \"\n",
      "batch 10921  loss=138.0302  steps/s=104.95  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l ne \n",
      "a  w    o        ttt  ttttttttttet\"\n",
      "batch 10922  loss=164.2552  steps/s=97.31  prediction: \"s message is NOT approved by square gang\" => \" the in sms s  e     s t ee   pe  eeeree\"\n",
      "batch 10923  loss=138.2656  steps/s=104.41  prediction: \"et back up and get back at it eventually\" => \" i i a  ta t  a                         \"\n",
      "batch 10924  loss=142.2701  steps/s=104.71  prediction: \"il of the recall/visualization over time\" => \"nl ua    t    e e    l llllllllliiiiiiio\"\n",
      "batch 10925  loss=168.2926  steps/s=102.38  prediction: \"a have hella nostalgia in like 10yrs bro\" => \"ll  s   'eera   nnnaanea a l a nna leal \"\n",
      "batch 10926  loss=154.7507  steps/s=104.92  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \"   saanaasasasa sss                     \"\n",
      "batch 10927  loss=270.4307  steps/s=10.71  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"epl l ioe meee r$d$É´|å§#!{kð—»èµ°$$ðŸ“‰$,${,,$,H\"\n",
      "batch 10928  loss=142.5211  steps/s=138.43  prediction: \"ait to see what you cook up with giz inc\" => \"nt isi    t    t  t t  o       uo   o   \"\n",
      "batch 10929  loss=158.0031  steps/s=98.20  prediction: \" just signed up as a beta tester hehhehe\" => \"tuiz i    t s  t s    o    a    t    tet\"\n",
      "batch 10930  loss=149.4399  steps/s=95.86  prediction: \"feeling than automating hrs of work away\" => \" elybg  eeten ne  a a aa a tt   t    her\"\n",
      "batch 10931  loss=140.7334  steps/s=104.71  prediction: \"e the reward dips down below the average\" => \" aeire hereerrrerer  d dddd    we    e  \"\n",
      "batch 10933  loss=179.9807  steps/s=73.16  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" tao t  teere rd d  oo    w p   e    ee \"\n",
      "batch 10934  loss=137.6191  steps/s=107.04  prediction: \"ed around the data that flows through it\" => \"   ttan ea ed ed dd  d  aa  a t  t tt tt\"\n",
      "batch 10935  loss=141.0256  steps/s=100.02  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"theta a  t t  t tta   t      a          \"\n",
      "batch 10936  loss=138.4394  steps/s=104.62  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \"hi  o t notn   nooooooooooo  oo         \"\n",
      "batch 10937  loss=155.7789  steps/s=102.46  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" oresee te      e  gtegtt eee\n",
      "eeee t e  \"\n",
      "batch 10938  loss=212.7395  steps/s=95.06  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"o  ot  aEEEtEEOOOOOOOO\n",
      "\n",
      "Oe \n",
      "t te        \"\n",
      "batch 10939  loss=155.3736  steps/s=103.36  prediction: \" I'm super down for another one thursday\" => \"t   ! n!!!s   ds          o    o   o    \"\n",
      "batch 10940  loss=149.8589  steps/s=104.61  prediction: \"s, 30% make garbage, and 64% ruin things\" => \"  gt  g g gg          aa aaaa           \"\n",
      "batch 10941  loss=162.4718  steps/s=99.36  prediction: \"h mines a $10 quintillion metal asteroid\" => \"etgso  ent t   m   i    in    iiii iitit\"\n",
      "batch 10942  loss=153.4268  steps/s=104.54  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "pt  e a to i)\n",
      "Lz.SzGv2ðŸ˜­I1Jâ€™z1AV7UB0:)2L\"\n",
      "batch 10943  loss=143.7557  steps/s=106.00  prediction: \"y do what sounds more interesting to you\" => \" thouob  b b  o    o o    o           t \"\n",
      "batch 10944  loss=140.0540  steps/s=103.77  prediction: \"indirections/abstractions/contexts oh ok\" => \"nge l  llliiiiiiiiiiiiiissssssscctttttto\"\n",
      "batch 10945  loss=198.7168  steps/s=101.82  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \" ibleilioissaiis000siinssnintsttstsstoos\"\n",
      "batch 10947  loss=147.2221  steps/s=102.25  prediction: \"ld love to hear if you dont mind sharing\" => \"y  @s r  lloo  l          o             \"\n",
      "batch 10948  loss=180.0300  steps/s=74.21  prediction: \"xluffyb Its almost side project saturday\" => \"pe   l l  ot   t   o      d    o       n\"\n",
      "batch 10949  loss=140.4303  steps/s=105.58  prediction: \" get to master idk depends on your goals\" => \"te oee  e   t tt      t   d dd d  d  o  \"\n",
      "batch 10950  loss=164.3262  steps/s=103.99  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"htA oeu @ n A AABABBB B B B   vv  va a a\"\n",
      "batch 10951  loss=149.9377  steps/s=100.01  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"@aid me  ene eeccc  e     e      s  e   \"\n",
      "batch 10952  loss=159.2394  steps/s=102.23  prediction: \"oull just be on his midbie goats list dw\" => \"  inein  l  l  n    ee    ei   io o sis \"\n",
      "batch 10953  loss=153.0540  steps/s=103.59  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "At   s  t .   â€™:jY_+4j:TP+:mT3/N3MNQ5+3\"\n",
      "batch 10954  loss=144.9085  steps/s=99.02  prediction: \"nin man, was a great great time as usual\" => \" s oo n nhn n i n a     a aa aa a aa  a \"\n",
      "batch 10955  loss=144.5430  steps/s=103.69  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \" d       e u  y    uuu hh h hhhhhhhhu pp\"\n",
      "batch 10957  loss=142.3202  steps/s=104.25  prediction: \"we need shape rotator models already smh\" => \"hrn e   eene  epeeee oee ooeeoo  oe eeaa\"\n",
      "batch 10958  loss=152.1943  steps/s=103.77  prediction: \"your .env and fill it out\n",
      "\n",
      "then it works\" => \":u    nn tn   en   n             t    tt\"\n",
      "batch 10959  loss=139.1157  steps/s=104.86  prediction: \" get to master idk depends on your goals\" => \"te oee  e   t tt      t   d dd d  d  o  \"\n",
      "batch 10960  loss=150.3629  steps/s=104.70  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" rla tnee t ataaa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttt///////\"\n",
      "batch 10961  loss=148.2177  steps/s=100.98  prediction: \"f this song and never listen to it again\" => \" to siness s s s  s    n   n     n      \"\n",
      "batch 10962  loss=142.5675  steps/s=105.07  prediction: \"rids\n",
      "gpus are 2d grids of 2d grids so 4d\" => \"ed  o eeteeteeee4/jj9AxB2T139-,,\n",
      "ww@@4@I\"\n",
      "batch 10963  loss=142.4636  steps/s=105.35  prediction: \"anding pages or whatever feels gross idk\" => \"td  lro n n n on         eee   eeeeee ee\"\n",
      "batch 10964  loss=179.7382  steps/s=53.01  prediction: \": @yacineMTB better start skilling up ig\" => \" @aoyqng  atet B4_jjM3_N22L3q!jLMDp@L4O.\"\n",
      "batch 10965  loss=149.2349  steps/s=107.36  prediction: \"n doing on a method of learning faster)â€¦\" => \"gw e  e nnnnn n     n    o      n  n    \"\n",
      "batch 10966  loss=138.6447  steps/s=105.01  prediction: \"too, its good to break your priors intoâ€¦\" => \"  t     t ttoootooooooooo o      o     r\"\n",
      "batch 10967  loss=142.2839  steps/s=106.21  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"nt  tt  n   c iciccccciiaiaaiaaaaaaaaa h\"\n",
      "batch 10968  loss=143.2536  steps/s=105.07  prediction: \"tention/effort with no results. Not easy\" => \" r  e  tteenettettttttttt t    t  o t  t\"\n",
      "batch 10969  loss=174.2078  steps/s=60.68  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tvtetttneettn rntt  ttt  ///t  oo o t  s\"\n",
      "batch 10970  loss=168.4184  steps/s=116.95  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"inb ym@ ul e  Am@zyAm.P)/v.P,/H\n",
      ",J0L823U\"\n",
      "batch 10971  loss=141.4462  steps/s=105.16  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"      naayna aaba aaaa  a               \"\n",
      "batch 10972  loss=172.7209  steps/s=99.22  prediction: \"end to work, and they pretend to pay us\"\" => \"     e tn  e   e  n     e   t e e    en \"\n",
      "batch 10973  loss=156.7673  steps/s=104.79  prediction: \"h's run are: samplesize=64, epochs=100,â€¦\" => \"a e hh  r r   n   r   asssseessee===e=e=\"\n",
      "batch 10974  loss=146.6393  steps/s=104.57  prediction: \"gram faster which made him have more fun\" => \" a   m oer mr rr a  h  h hhh  hhmh h mm \"\n",
      "batch 10975  loss=149.2404  steps/s=105.77  prediction: \"sicily, i hope to see the island one day\" => \" dar m  mmimiii ii      e      e  ee   e\"\n",
      "batch 10976  loss=165.9484  steps/s=102.24  prediction: \"tiquing the zoomers that jump in his dms\" => \" oa  iia erteiuii iit  t  to    tt   t  \"\n",
      "batch 10977  loss=141.6487  steps/s=104.90  prediction: \"elated to status games or zero sum games\" => \" i s  sette t t tttttttt t              \"\n",
      "batch 10978  loss=134.0063  steps/s=105.65  prediction: \"do 16hrs tmrw, test this and report back\" => \"  a t   nh    t6        ttt             \"\n",
      "batch 10980  loss=151.5182  steps/s=21.35  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \" t  to    n n        tttttt             \"\n",
      "batch 10981  loss=147.2162  steps/s=141.26  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"ekti   aaaaaaataatttthtt t    ss   eesse\"\n",
      "batch 10982  loss=140.0969  steps/s=104.64  prediction: \"ies and more insights. Then will release\" => \"nl ed    n rn  e    i i ss s  i i  i    \"\n",
      "batch 10984  loss=169.3488  steps/s=95.67  prediction: \"shiridesu 100 raspberry pis would fix me\" => \" ioie  erieie erss000000 rrsrrrrs  rl   \"\n",
      "batch 10985  loss=147.3272  steps/s=104.16  prediction: \"tial art and he generalizes between them\" => \"hno  oo mrr aa aaa   a  a  e  eee  eee e\"\n",
      "batch 10987  loss=146.6154  steps/s=99.68  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"Aw @cnB e eeeeteeee eeeee  sss  ss  s   \"\n",
      "batch 10988  loss=179.8873  steps/s=31.16  prediction: \"ply: @andrew_pynch fundamentals compound\" => \"ly: @l eeeteeee eeee  eees ssss ss  s s \"\n",
      "batch 10989  loss=152.4441  steps/s=128.20  prediction: \"us @yacineMTB nonononononononononononono\" => \"t igAeane e    n n nnnonnnoonnnnooononoo\"\n",
      "batch 10991  loss=138.9445  steps/s=103.98  prediction: \"tion WAY more than if its someone else's\" => \" me r sosonoouo   to                  es\"\n",
      "batch 10992  loss=140.3726  steps/s=97.56  prediction: \"you should do sidetweets with the aliens\" => \":u suon     o  dooo  d d ds etteett ees \"\n",
      "batch 10993  loss=146.5173  steps/s=100.94  prediction: \"ly using the word prior kinda wrong here\" => \"y: @ om m   b u b    r   i    rr r  r  r\"\n",
      "batch 10994  loss=139.4614  steps/s=100.80  prediction: \" time on their hands + survivorship bias\" => \"th o  t t o t t                     ri i\"\n",
      "batch 10995  loss=164.5271  steps/s=105.31  prediction: \"zzl\n",
      "\n",
      "Or maybe he got it from someone idk\" => \"eob wreB wTO IedxðŸ«¡IkQ#+ðŸ˜­cVðŸ˜­,kcCC,,@#XðŸ“‰+@\"\n",
      "batch 10996  loss=141.4173  steps/s=99.75  prediction: \"e or desire to practice for other things\" => \" too tcctert  t r   r  e    c c rr    r \"\n",
      "batch 10997  loss=140.3974  steps/s=103.11  prediction: \" is a no go\n",
      "\n",
      "dang that sounds like a lot\" => \"tt b    b  n  nn                        \"\n",
      "batch 10998  loss=143.2233  steps/s=104.59  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" ii   t ita  a a    t ttth hhtttst//t/tt\"\n",
      "batch 10999  loss=147.9552  steps/s=99.38  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"trmcgia iinc      g    g ttttt////////t/\"\n",
      "batch 11000  loss=139.4364  steps/s=104.87  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  a     tt t            tttttt///tt////\"\n",
      "batch 11002  loss=153.8180  steps/s=96.63  prediction: \"TB elon lived in leafland for a bit iirc\" => \"h  Fot i n    n i    ii  t tf fff o   ti\"\n",
      "batch 11003  loss=155.1948  steps/s=105.54  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" in ae  aneev  d       tttttttttt///////\"\n",
      "batch 11004  loss=147.4964  steps/s=104.12  prediction: \"chnical debt kind of effect over time. F\" => \"a pa th   e   tt         e    e    eeee \"\n",
      "batch 11005  loss=157.4147  steps/s=102.07  prediction: \"y the paper i thought it was a neat read\" => \" iepe a  \n",
      "h\n",
      "t hhppp  h   hhhht   t     a\"\n",
      "batch 11006  loss=147.2130  steps/s=106.73  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t r  a rsa r  Ir     p   o   o  o    t  \"\n",
      "batch 11007  loss=148.4170  steps/s=105.64  prediction: \"ve gradient it lives in? Something else?\" => \"er  tit tneiniiiiieiiiiiiiii i      e ee\"\n",
      "batch 11008  loss=161.2966  steps/s=97.73  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"ane o   niei  n      t  t tt tttt////t/s\"\n",
      "batch 11009  loss=150.1078  steps/s=104.17  prediction: \"essing\n",
      "You help cure that if you do this\" => \"  e e  esns s  s    e e                 \"\n",
      "batch 11010  loss=151.4134  steps/s=102.79  prediction: \"nsions have a different message, I think\" => \" est e snennss nsssese   neeeese e  eees\"\n",
      "batch 11011  loss=152.5620  steps/s=100.53  prediction: \"ne that sends the html/js/etc files over\" => \"  se ee   te  he  t et t th ttet tt   e \"\n",
      "batch 11012  loss=145.9444  steps/s=104.60  prediction: \", increases both HP and MP significantly\" => \" tok et er neeeeeee ee     PPPPPP   n  i\"\n",
      "batch 11013  loss=151.2553  steps/s=101.22  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"nl  t  s aal  llllllllllllllttttt//t//55\"\n",
      "batch 11014  loss=139.4563  steps/s=105.22  prediction: \"cies and come up w better ways to learn'\" => \"hn aeneiiiniiecc      e                 \"\n",
      "batch 11016  loss=158.3515  steps/s=105.37  prediction: \"ou can dive unbelievably deep into these\" => \"r tti d ne tnee n    n  bbbbbbeeeeeeeee \"\n",
      "batch 11017  loss=146.5970  steps/s=104.43  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \"fclent ttt t tetttttt eee eeelll        \"\n",
      "batch 11018  loss=134.6302  steps/s=105.96  prediction: \" will get back to you when this is fixed\" => \"thae   w l llll                         \"\n",
      "batch 11019  loss=144.8042  steps/s=104.25  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "eotiniw mdn h@n#|#KX##**V##*X#.`[{#å€‘-'$\"\n",
      "batch 11020  loss=137.4659  steps/s=106.00  prediction: \" or not so i dont have much data on that\" => \"tf   oo    t                            \"\n",
      "batch 11022  loss=147.4436  steps/s=102.24  prediction: \" of your day your brain will work better\" => \"tnp t r t     rr       r  y r      rr  o\"\n",
      "batch 11023  loss=134.7362  steps/s=104.88  prediction: \"en clusters into single tokens like this\" => \" t  e  eteetn ett    s      n      n    \"\n",
      "batch 11026  loss=178.2980  steps/s=103.36  prediction: \"ctus infobalking https://t.co/B3UT9nTonq\" => \"tize toeltntlll nn inintt  ttst  t//t //\"\n",
      "batch 11027  loss=140.3666  steps/s=101.90  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \" ne  tp  o o   g         e  ee    e     \"\n",
      "batch 11028  loss=145.3073  steps/s=104.61  prediction: \"ve to somewhere else\n",
      "\n",
      "idk just a thought\" => \"e a eeeoe eooennee eeeeeeeeeeee e      t\"\n",
      "batch 11029  loss=145.6522  steps/s=104.42  prediction: \"put work in, etc https://t.co/8ZjkHbRuMG\" => \"lt l      u u           tttt ttt////////\"\n",
      "batch 11030  loss=144.7603  steps/s=104.09  prediction: \"ploring become really clear to your mind\" => \"ly:t oaee  n  be  eee ee leele  ll e   r\"\n",
      "batch 11031  loss=172.4770  steps/s=106.85  prediction: \"houlda stuck to planting apple trees smh\" => \"ew  aea  n o oul  ololla   a  aapl a pee\"\n",
      "batch 11032  loss=147.6725  steps/s=103.22  prediction: \"res a reason they dont but i dont see it\" => \"epli  aynin hhenLIck,777577779994K@2v444\"\n",
      "batch 11034  loss=144.8474  steps/s=104.70  prediction: \"s) lets you do system prompts, i believe\" => \"  n  a c tss  s  ss ss ss  s  m   s  p  \"\n",
      "batch 11035  loss=193.7504  steps/s=20.96  prediction: \"eply: @yacineMTB dependency independency\" => \" ly: @tsc ss     ss ss ss  s  m      e  \"\n",
      "batch 11036  loss=140.8934  steps/s=107.72  prediction: \"lgos to live by, and the art of learning\" => \"ye   e  et  t  e  l  l  e               \"\n",
      "batch 11037  loss=148.4574  steps/s=102.87  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"ep dy @ eOeee@w\n",
      "#|@O#Éª*JvVOX]~`X[|ÊŸkðŸ°ð—¿É´ÊŸ\"\n",
      "batch 11039  loss=138.7342  steps/s=105.30  prediction: \"s w java and python and studying for fun\" => \" a tt   tnn n    a a    n   n      n   n\"\n",
      "batch 11040  loss=136.7203  steps/s=104.79  prediction: \"ressures me to say things I dont believe\" => \"epr r elm y  l@yX[GV*QðŸ’ª*ð—±{á´›#j~V*ðŸ˜j$z[[$$\"\n",
      "batch 11041  loss=141.4749  steps/s=105.40  prediction: \"d its helped man. i shpuld sleep too lol\" => \" maa    aa  n nn                lplp    \"\n",
      "batch 11042  loss=156.1082  steps/s=105.07  prediction: \"/t.co/zlto3SBYwd https://t.co/Izzdx8c2HJ\" => \"bhtes r/od///toooctttttottt:/tt/tt/zzzzz\"\n",
      "batch 11043  loss=139.0249  steps/s=105.15  prediction: \"sfully improved their lives tremendously\" => \" oct  tf f s   seeeeeee ee eeee eeeeee e\"\n",
      "batch 11044  loss=147.6242  steps/s=104.07  prediction: \"e thing, not just messing around with it\" => \" tiat etttt tttttnt  t    tn      n     \"\n",
      "batch 11045  loss=155.8321  steps/s=103.32  prediction: \" his story you wont regret it, its crazy\" => \"tas aa aa\n",
      "  sss  sss         rrr rtr  tt\"\n",
      "batch 11046  loss=136.7941  steps/s=101.27  prediction: \" the atmosphere, such a great experience\" => \"the   e t  eo  eeee ee            eeeeee\"\n",
      "batch 11047  loss=159.3119  steps/s=95.95  prediction: \" bet, im down, whats a good time for you\" => \"tat aattt t o m  ,        aa    a      o\"\n",
      "batch 11048  loss=139.3329  steps/s=104.74  prediction: \"gger stuff, maybe thatll make me faster?\" => \" \n",
      "  to    gg   g g      t  t  t   m  a  \"\n",
      "batch 11049  loss=156.5928  steps/s=102.20  prediction: \" learning how things work under the hood\" => \"tore  nr ren n     nn hn  n   nn   nn   \"\n",
      "batch 11050  loss=139.4384  steps/s=103.06  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"t  t  t tiirrrarrttattaaaaaaahhaahhhhhhh\"\n",
      "batch 11051  loss=145.1874  steps/s=100.52  prediction: \" inference than gpus\n",
      "\n",
      "but what do i know\" => \"tm    nnenn nnennnnnenneen  e  t        \"\n",
      "batch 11053  loss=148.5241  steps/s=104.31  prediction: \" never rule things out as impossible tbh\" => \"tete ssstttteett  eet  t       s sss iss\"\n",
      "batch 11054  loss=143.5988  steps/s=100.75  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"      o  i  i    i  i  t ttttt/t///////t\"\n",
      "batch 11055  loss=161.9958  steps/s=103.99  prediction: \"ur enemy when they are making a mistake\"\" => \"t  neeeenrer  ee e ee e  yy n  ne  mnea \"\n",
      "batch 11056  loss=140.8603  steps/s=103.67  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"tia  el  ooolo ooololll llllllll a   a  \"\n",
      "batch 11057  loss=151.9177  steps/s=100.09  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"ese  nx    t            t tttt ttt//////\"\n",
      "batch 11058  loss=148.8480  steps/s=102.13  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"nd o \" o y      y   y   tttttttt/t//////\"\n",
      "batch 11059  loss=168.4056  steps/s=93.92  prediction: \"kul07 Nothing beats the classic todo.txt\" => \"edta na  oty   t ttttt ttttt///cccsssbtt\"\n",
      "batch 11060  loss=143.1482  steps/s=104.01  prediction: \" end of the task off worked for you too?\" => \"txetdneteettet               ffff    ooo\"\n",
      "batch 11061  loss=155.7256  steps/s=103.61  prediction: \"owing that your food supply doesnt scale\" => \"   i nitti  t  ttt     oo      ooo  o   \"\n",
      "batch 11062  loss=181.0925  steps/s=28.95  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: n  nn n     tt     oo   o ooo    s  \"\n",
      "batch 11063  loss=151.5117  steps/s=112.03  prediction: \"r tweet was epictetus's two handles idea\" => \"etlt: urissteingxW22W\n",
      "b:v/5.'Q/K4444@I74\"\n",
      "batch 11064  loss=192.1977  steps/s=21.04  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly: @t   e w ee eeteeeeteetttt tts   ss\"\n",
      "batch 11065  loss=142.1018  steps/s=127.84  prediction: \"on said we cant use that word any more!!\" => \"u  b n                  a     t   t  a  \"\n",
      "batch 11066  loss=169.8416  steps/s=53.44  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @dan neace eMcgx!!v'\n",
      "T:v/!.'!/5kLSIIIz?\"\n",
      "batch 11067  loss=140.0605  steps/s=105.63  prediction: \"nomena that i used to not have words for\" => \"gwl tennenenn n                         \"\n",
      "batch 11069  loss=142.2750  steps/s=104.80  prediction: \" pool (at least once seems cold tho ngl)\" => \"trtt o o to t  t        e   e e eee  e  \"\n",
      "batch 11073  loss=159.0881  steps/s=102.66  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \"hofri  oilil l000000001?1100???0?0?l  ??\"\n",
      "batch 11074  loss=147.1960  steps/s=101.65  prediction: \"m like the future too\n",
      "is this mujoco btw\" => \"eteo  eteee  e eee ee  e    t t  t   oo \"\n",
      "batch 11076  loss=143.1223  steps/s=105.04  prediction: \"tention/effort with no results. Not easy\" => \" r  isttteenettettttttttt t    t  o t  t\"\n",
      "batch 11077  loss=156.9623  steps/s=99.34  prediction: \"@sunsettler fight me (i would 100% lose)\" => \"geapiene nenteeet  tt e   e    i        \"\n",
      "batch 11079  loss=155.3384  steps/s=96.89  prediction: \"my database is a text file called main.c\" => \"e i at et ttt att  a   e    t  e lll lll\"\n",
      "batch 11080  loss=244.5208  steps/s=11.81  prediction: \"reply: @papyruski @justalexoki elaborate\" => \"eply: @HinSphy eP.y/@x.:/vT1,,?x()g9xxxx\"\n",
      "batch 11081  loss=138.4395  steps/s=108.24  prediction: \"your life (which is what happened to me)\" => \" ur r    ye  li        ii       hhh   h \"\n",
      "batch 11082  loss=170.5178  steps/s=82.28  prediction: \"kul07 Super awesome dude, great stuff!!!\" => \" tt ar    ulr r i    ww h    eeee   tea \"\n",
      "batch 11083  loss=153.4738  steps/s=95.47  prediction: \"neMTB i dream in ai generated js slop :/\" => \"g ant a  e r    iee  ae ee e eee ttet ! \"\n",
      "batch 11084  loss=153.0272  steps/s=103.87  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y  eyass sss ss ss s ss  sttstt/t//////t\"\n",
      "batch 11085  loss=158.9533  steps/s=103.29  prediction: \"ou get faster and faster at solving them\" => \"n     t t    ttt    t   a      a  a     \"\n",
      "batch 11087  loss=139.8414  steps/s=104.66  prediction: \"ong term advantage) you consolidate andâ€¦\" => \"ue  .  .r. ereea aaa aa aa   ao  ooo oaa\"\n",
      "batch 11088  loss=197.7270  steps/s=104.41  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"1 V4//tt/\n",
      "t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "so\n",
      "\n",
      "\n",
      "\n",
      "ss\n",
      "ss/ss//tp/s//t\"\n",
      "batch 11089  loss=171.8030  steps/s=92.89  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"nldtttt\n",
      "s\n",
      "\n",
      "\n",
      "ookkitttttottttt//ttssrsspss\"\n",
      "batch 11090  loss=177.1201  steps/s=52.23  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \": @jaxt\n",
      "\n",
      "o\n",
      "xkisiitttttpt/tttorttssrpspps\"\n",
      "batch 11091  loss=162.5284  steps/s=114.03  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \" t rtckeeegee eee  a e e   tttttt/ttt/tc\"\n",
      "batch 11092  loss=150.5545  steps/s=104.62  prediction: \"ut what it meant https://t.co/XYAZfowlv5\" => \"     o  t    tt  tttt tt ttttttttttttttt\"\n",
      "batch 11093  loss=150.1091  steps/s=99.57  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"tt  uuuu  ceeeeeeieeceeeeeeeeee eeeee n \"\n",
      "batch 11094  loss=144.2233  steps/s=105.74  prediction: \"t am article to help ppl understand theâ€¦\" => \" meuet  t   t  t                 p      \"\n",
      "batch 11095  loss=153.0790  steps/s=101.77  prediction: \"if the anthropic one is taking a beating\" => \"n e  o    eent   o   o  i  i   i  i     \"\n",
      "batch 11096  loss=179.4658  steps/s=103.47  prediction: \"d @gizmobly @covix2772 store files in it\" => \" tet oo taanr io oooo    7i72 77    ii  \"\n",
      "batch 11097  loss=147.0261  steps/s=103.42  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"tpto m eo e m  dmmeeee  e   epp s  eee  \"\n",
      "batch 11098  loss=172.1861  steps/s=96.83  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @5 oso s  eps s sssssststtttttptttt8\"\n",
      "batch 11099  loss=186.6976  steps/s=100.69  prediction: \"layzXD @ludwigABAP Based\n",
      "Python/zig gang\" => \"yt @pexieleellDil  lABBBBBBBPPPPAPP////t\"\n",
      "batch 11100  loss=144.8783  steps/s=104.28  prediction: \"al of life that pays some huge dividends\" => \"nln            f                        \"\n",
      "batch 11101  loss=145.1640  steps/s=99.80  prediction: \"visualize 5d and if so whats your method\" => \"elyn ou ui        a                     \"\n",
      "batch 11104  loss=175.9465  steps/s=46.14  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @nusu  i  i id                      oo\"\n",
      "batch 11105  loss=144.8792  steps/s=110.12  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  a s e e e eeneeeeeeeeetetettttptt//ttt\"\n",
      "batch 11106  loss=146.6499  steps/s=101.21  prediction: \"ill consider leaning into it more though\" => \"nd      b      di     iiinniiiii        \"\n",
      "batch 11107  loss=152.5494  steps/s=99.52  prediction: \"l remember the book much better too. ime\" => \"yt   ao b\n",
      "o   beebbeemeeee  ee     ee   \"\n",
      "batch 11108  loss=156.1107  steps/s=104.75  prediction: \"ental growth is king. get that bread son\" => \" t    eereeet  rr  t      g ggt  t t   t\"\n",
      "batch 11109  loss=175.2641  steps/s=77.12  prediction: \"atedro @gizmobly https://t.co/IFzJo2qtyj\" => \"n  a em  te r go  tt     tt t tt t     t\"\n",
      "batch 11111  loss=143.6714  steps/s=106.85  prediction: \"mance feedback you hear abt friendly ppl\" => \"eke  a tr eceebe eeeeeeaeaa   a    a   e\"\n",
      "batch 11112  loss=140.4560  steps/s=105.04  prediction: \" are no forests where 2+2 truly equals 5\" => \"t         e    re   ereeeeee e ee2      \"\n",
      "batch 11113  loss=211.1623  steps/s=99.32  prediction: \" NO BLACKPILLING https://t.co/djaWm13aKZ\" => \"toeI e  e tttLLLNLLLLNN  tttt  tttt /ttt\"\n",
      "batch 11114  loss=160.2336  steps/s=103.09  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e ly: @bt reehxz;k-Ozc@-+ND@MkBN@:qBNP-:\"\n",
      "batch 11115  loss=144.1050  steps/s=102.39  prediction: \"d to seeing your progress on nand2tetris\" => \" uo o oon  g  ner  r  rr rrrr or   nnnnn\"\n",
      "batch 11116  loss=152.2140  steps/s=104.76  prediction: \"amount of time, or did you just enjoy it\" => \"rp       ian   n  o o      oo           \"\n",
      "batch 11117  loss=137.1761  steps/s=104.38  prediction: \" yrs. ur brain will figure it out, trust\" => \"toui  n r  rrrr rrr r    ii iiii  i    u\"\n",
      "batch 11118  loss=158.4413  steps/s=100.09  prediction: \" @discord I made my own bot from scratch\" => \"tard i ioidddi sdd    d             o   \"\n",
      "batch 11119  loss=164.3083  steps/s=36.76  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"y: @ iddde edsd  d    d      o      t   \"\n",
      "batch 11120  loss=140.8175  steps/s=109.67  prediction: \"es your data instead of storing the data\" => \" saina netetnte aaaa aaa a       t   t  \"\n",
      "batch 11121  loss=159.8306  steps/s=100.58  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"4nb ymap  dep AwUz@ALSPI.N\n",
      "PE,ENI,kBNb?:\"\n",
      "batch 11122  loss=151.2273  steps/s=101.56  prediction: \"tings, and speeding up my workflow, you?\" => \" ne ataed n  nned neeen e            ooo\"\n",
      "batch 11123  loss=173.9977  steps/s=68.49  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"aaaaa aedie eede                oo  oooo\"\n",
      "batch 11124  loss=144.8938  steps/s=105.80  prediction: \"at can be beaten if you look hard enough\" => \"les  et ste te tee   e                  \"\n",
      "batch 11125  loss=143.7788  steps/s=104.84  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"ta n   i   n            t tttttt////////\"\n",
      "batch 11126  loss=177.6535  steps/s=101.52  prediction: \"7AHwatHv6Y was really really really good\" => \"  h  to/c/tHHtHHHHawwaaa aaaaaa  allllyy\"\n",
      "batch 11127  loss=157.3355  steps/s=100.99  prediction: \"utput brothers karamazov, word for word\"\" => \"s ioa Aut   o t  tr  rarraaaaraaarrr ooo\"\n",
      "batch 11128  loss=151.2831  steps/s=105.78  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" an io)n)o    )      e  ee  e  t t   ts \"\n",
      "batch 11129  loss=150.1690  steps/s=99.24  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"e    nt    a   e        a    aaa   a aaa\"\n",
      "batch 11130  loss=141.4850  steps/s=104.61  prediction: \" is better than lots of ppl not starting\" => \"tf  ps ss s  eeseeet    t  t  ttt     t \"\n",
      "batch 11131  loss=139.4829  steps/s=104.17  prediction: \" a lot of chess is abt how to think less\" => \"tn   o   t     t                        \"\n",
      "batch 11132  loss=149.0916  steps/s=102.91  prediction: \" strategy of perception?\n",
      "Dang thats cool\" => \"toru   u ts t     eeee eeee eeeett tt tt\"\n",
      "batch 11133  loss=162.0438  steps/s=69.09  prediction: \"@IterIntellectus have you brrrytt today?\" => \"ltiea  estet elee eee eeee o  trrttttooo\"\n",
      "batch 11135  loss=143.5829  steps/s=106.94  prediction: \"f scummy people getting more money/power\" => \" t s ea  e s   meeee eeeeee    mmemmmeoe\"\n",
      "batch 11136  loss=175.2857  steps/s=67.54  prediction: \"rrawnyy cool ass wasm cube bro\n",
      "\n",
      "followed\" => \"eolha  torriin N)@IPHxBAPH2(IH).\"H\"(2PI.\"\n",
      "batch 11137  loss=141.5010  steps/s=110.03  prediction: \"hings way easier\n",
      "https://t.co/SoZ8VeXTFk\" => \"engo  an tnn   a    attt  ttttt/t//t////\"\n",
      "batch 11138  loss=154.1027  steps/s=98.20  prediction: \"resy you can already talk to one of them\" => \"eply: @ n e wl C)+IVCuubPXb(:V)4.kb(S!Z8\"\n",
      "batch 11139  loss=146.8382  steps/s=104.45  prediction: \"ut what it meant https://t.co/XYAZfowlv5\" => \"s    o  t    tt  tttt tt tttttttt/////tt\"\n",
      "batch 11140  loss=168.8097  steps/s=99.32  prediction: \" job adding the australian language pack\" => \"tunn t tt  je  nn  tdt a ata  aat aallaa\"\n",
      "batch 11141  loss=142.2538  steps/s=104.01  prediction: \"light show swarm and rent it to concerts\" => \"ygb     do          w           t    t  \"\n",
      "batch 11142  loss=156.5942  steps/s=104.11  prediction: \"aftinginterpreters\n",
      "- got back into 3d pâ€¦\" => \"nten o  ettr terertrrrererttrrtttttt    \"\n",
      "batch 11143  loss=162.1676  steps/s=99.06  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t cntnetn    pe    tssttttststtttsttt///\"\n",
      "batch 11144  loss=143.6662  steps/s=104.38  prediction: \"ite complexity? If not, what is the max?\" => \"n in  ii  inii tiii t                   \"\n",
      "batch 11145  loss=148.3337  steps/s=104.55  prediction: \"n i did eventually. hypothesis confirmed\" => \" me ee  aedn  nnd   nn    eee   e    hei\"\n",
      "batch 11146  loss=157.0703  steps/s=104.89  prediction: \" is from u a g:\n",
      "\n",
      "https://t.co/WkQRLnq0Jt\" => \"t  w ww    t             t tttttttt/////\"\n",
      "batch 11147  loss=160.5012  steps/s=102.33  prediction: \" know any easy way to work with cuda btw\" => \"tne   nu uoo  y o y y  w y wwy  w wo    \"\n",
      "batch 11148  loss=221.1567  steps/s=102.56  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"yte .4n--))))0))))0.).)(((...((...5.5.5.\"\n",
      "batch 11149  loss=154.0529  steps/s=104.92  prediction: \"r the years for business/building things\" => \" hh i enn nI{ZZb(Zj)ZwZ((ZZvZZZM/M)(MwMM\"\n",
      "batch 11150  loss=176.8906  steps/s=104.13  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tt   e eeddeeee         t  tttttttt/////\"\n",
      "batch 11151  loss=163.9471  steps/s=97.39  prediction: \"builds mcdonalds just wants to grill man\" => \"et e ede  dd dd d  tssstttst tttt tt ttt\"\n",
      "batch 11152  loss=156.7850  steps/s=99.96  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"aata B tette  ll      a         i  i   i\"\n",
      "batch 11153  loss=144.7274  steps/s=104.90  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"   n, nennnennenennnnnnnnnnonnnnonoooooo\"\n",
      "batch 11154  loss=148.8271  steps/s=103.45  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" h        ddddd d dd     t              \"\n",
      "batch 11155  loss=192.1609  steps/s=59.68  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tar d tdnh  dd d  t  tt  t            l \"\n",
      "batch 11156  loss=178.0094  steps/s=112.06  prediction: \"xluciusv cool cool goal\n",
      "progress so far?\" => \"p0 i n hnhnt te o h  to  ol   oco     l \"\n",
      "batch 11158  loss=160.8474  steps/s=107.12  prediction: \"uper hard but I think it could be doable\" => \"rp ge graarpa rp rr  r    t  t        d \"\n",
      "batch 11159  loss=151.9005  steps/s=100.35  prediction: \"r cool. i wish llms were better with zig\" => \"eily: @gndnnf$@ITxbI[k.ð—¿É´kð—¼.k[dL.â€œ[v/Éª$f\"\n",
      "batch 11160  loss=132.9741  steps/s=103.59  prediction: \" a cross section now that you mention it\" => \"t ki k  k     ss                        \"\n",
      "batch 11161  loss=140.1856  steps/s=102.33  prediction: \"ols is kinda like cookie clicker but irl\" => \"ulcdioi s iiiinii  ii ii i  ikkkkkcccc  \"\n",
      "batch 11163  loss=145.6014  steps/s=101.28  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \"   n     w w   ww                      e\"\n",
      "batch 11164  loss=143.6938  steps/s=104.75  prediction: \"nomic than discord id switch immediately\" => \"gthove en  oo omo   o   i  d  d iii diii\"\n",
      "batch 11165  loss=137.6127  steps/s=105.09  prediction: \"to a few people its a gargantuan problem\" => \"h s i o t  t   t  e           aaa aa aa \"\n",
      "batch 11166  loss=157.3551  steps/s=101.44  prediction: \" mind working better as you pay it back?\" => \"tot  n  oor    n    i   rr   t    t     \"\n",
      "batch 11168  loss=142.1065  steps/s=97.58  prediction: \"see more details as you unblur an image.\" => \"  oe         ee  eeee e    s  uu uuu u  \"\n",
      "batch 11169  loss=148.8299  steps/s=101.08  prediction: \" to make it better before (if) I release\" => \"toe   eedn m eeet  t tt te ee e     ere \"\n",
      "batch 11170  loss=141.3294  steps/s=105.41  prediction: \"ant to make many measurements per second\" => \"ndu n   n  t         m mmmmameeemme eeee\"\n",
      "batch 11172  loss=150.0148  steps/s=103.75  prediction: \"tebooks with 45 cells each, 4 docker imâ€¦\" => \" dose  oenoonoot  o         4    4  ce  \"\n",
      "batch 11174  loss=273.1132  steps/s=11.14  prediction: \"reply: @calbch its the year of the monad\" => \"eal   scaraup.df$á´˜Êœ^.[[yð˜[#æˆ‘^:$[}[45:$]$\"\n",
      "batch 11175  loss=135.1492  steps/s=117.32  prediction: \"seful instances of delayed gratification\" => \"   n  f   net  n ss sss    eee eee aa aa\"\n",
      "batch 11176  loss=147.4869  steps/s=105.48  prediction: \"ng, dunno why this flew over my head lol\" => \"  oo iintnee ne nt  n n n               \"\n",
      "batch 11177  loss=141.1091  steps/s=104.91  prediction: \"unny for your runway\n",
      "\n",
      "Idk just a thought\" => \"nd tein m nn  errr nnrrr \n",
      "y \n",
      "\n",
      "\n",
      "\n",
      "   uuuu \"\n",
      "batch 11178  loss=139.6458  steps/s=99.65  prediction: \"anning on putting this in an actual bot?\" => \"td  eu  nnan nnnnnnnn nn       t  a   aa\"\n",
      "batch 11179  loss=144.2448  steps/s=103.83  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \"te ae    e et et    hhhtttttttttt//////h\"\n",
      "batch 11180  loss=171.3271  steps/s=100.40  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1 oe  unhhbttt   t  t:t::////t//3333333\"\n",
      "batch 11181  loss=151.6654  steps/s=103.79  prediction: \" make no?\n",
      "\n",
      "maybe @yacineMTB can add this\" => \"tase   e  eem oem\n",
      "    \n",
      "e aeee aaaaaaan  \"\n",
      "batch 11182  loss=199.4934  steps/s=76.97  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \" e  ekpe  \n",
      "0m ome    \n",
      "\n",
      "eeBB  naaaa ddddM\"\n",
      "batch 11183  loss=155.4530  steps/s=105.15  prediction: \"t. good thing we still have comonad club\" => \"    tx   et   o     iii   t    o        \"\n",
      "batch 11184  loss=159.0534  steps/s=100.84  prediction: \"ur enemy when they are making a mistake\"\" => \"n   n eeneer  ee e eeey  e  n  nea an a \"\n",
      "batch 11185  loss=146.9154  steps/s=104.77  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \"  jd n  n nn  \n",
      "  i  i  i+ +++++xxx      \"\n",
      "batch 11186  loss=161.9917  steps/s=99.70  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tt e o ogo soisi iiiiiiiiiiiiiiii  i    \"\n",
      "batch 11187  loss=145.4411  steps/s=104.99  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"th  ee      t  t                        \"\n",
      "batch 11188  loss=150.2701  steps/s=104.93  prediction: \"pi key and throw it in the settings\n",
      "done\" => \"ln eo  a  a  aa                ttttit tt\"\n",
      "batch 11189  loss=143.5074  steps/s=104.07  prediction: \"ting your axioms can bring immense alpha\" => \" ot emeeeaaaaaaeaau  a  aa  iii  mmn    \"\n",
      "batch 11190  loss=160.3681  steps/s=103.05  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  a e t eegtt eeee e e e   ttttt////t///\"\n",
      "batch 11191  loss=154.5789  steps/s=93.26  prediction: \"irak seems fine to me (i am brainwashed)\" => \"neaee eee r a  n eet   t       ta aaaatt\"\n",
      "batch 11192  loss=138.7068  steps/s=100.07  prediction: \" least its not opengl like this poor kid\" => \"tiaeaat    et att t t           i    i e\"\n",
      "batch 11193  loss=142.2020  steps/s=101.59  prediction: \"e latent space of \"make things ppl want\"\" => \" taa  tan  t tat  t     e  e  e  e     p\"\n",
      "batch 11194  loss=135.3326  steps/s=98.44  prediction: \"if you say wala a lot are you a walawala\" => \"n aTB   n  e      aa aaa   a         aaa\"\n",
      "batch 11195  loss=153.9040  steps/s=104.28  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"tore   t toeo   o o \n",
      "\n",
      "ee\n",
      "\n",
      "\n",
      "ttttt////s///\"\n",
      "batch 11196  loss=160.5071  steps/s=99.02  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" ao gea en  n     oo  tott tt/t///////VV\"\n",
      "batch 11197  loss=149.8797  steps/s=104.08  prediction: \"ful if youre a complete beginner like me\" => \" l  n toi   u i     u e    e e ee eeee e\"\n",
      "batch 11198  loss=145.8028  steps/s=105.30  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yfe     t  t t     t   ttt ttttttttt////\"\n",
      "batch 11199  loss=175.2045  steps/s=37.01  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y    t  t t  i t   tt ttttttttttt/////YY\"\n",
      "batch 11200  loss=137.4976  steps/s=109.28  prediction: \"hem better bc you can do engine analysis\" => \"e    t tt tett t                    nnnn\"\n",
      "batch 11201  loss=140.4619  steps/s=103.21  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"t  etee e eeehteeeheeeheeeeeeeee eeeeeee\"\n",
      "batch 11202  loss=151.8299  steps/s=99.02  prediction: \" busy so i havent been posting much my b\" => \"tes  ee bss s           eee e    n   en \"\n",
      "batch 11203  loss=150.6198  steps/s=100.89  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"aik TB t trer rt      o   i   i i  i   i\"\n",
      "batch 11204  loss=155.2024  steps/s=103.31  prediction: \"rs automatically slap that down to 10fps\" => \"e e   n n nwsMTBOj.x.:\n",
      "k.:50v\"\",501xz,x1\"\n",
      "batch 11205  loss=142.0261  steps/s=103.17  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"ews t  aw sws%Q]^]`[][á´„â˜ ^ÉªÊœ]##Eá´¡|Éª1á´€â€â€}1\"\n",
      "batch 11206  loss=150.4990  steps/s=96.71  prediction: \" they secretly exercise and dont tell us\" => \"thetitee ed eetne eeeeeeeeeee e eennnnn \"\n",
      "batch 11207  loss=152.6626  steps/s=104.87  prediction: \" to me except this feels 100x better fug\" => \"thets tt  t  e e  e eee    e  eee eeee  \"\n",
      "batch 11208  loss=151.8608  steps/s=104.78  prediction: \" of why i used to get work sniped looool\" => \"tf e  e  f    t                         \"\n",
      "batch 11209  loss=170.1950  steps/s=77.86  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yc oho   yo        tt..   ttt s// oooool\"\n",
      "batch 11210  loss=253.6690  steps/s=15.47  prediction: \"reply: @esiarpze its good to be back man\" => \"eply: @stinblzd@v\"jgkvj=\".x:\"j\".Wu={zD4T\"\n",
      "batch 11211  loss=147.4130  steps/s=109.37  prediction: \"o make a significant impact on your life\" => \"uc i  a   n    n  aiiiiiiiiiiiii        \"\n",
      "batch 11212  loss=162.2742  steps/s=100.45  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"tou  t    t tf  ffffff  f ttttttttt/////\"\n",
      "batch 11213  loss=137.9551  steps/s=102.38  prediction: \"the angle of ur screens after she leaves\" => \" en y    tn   e                 e eeeeee\"\n",
      "batch 11214  loss=149.9939  steps/s=105.47  prediction: \"eting ppl on here\n",
      "\n",
      "the next half WE BALL\" => \"    e eeettet  e  e    eeee ee eee    h \"\n",
      "batch 11215  loss=138.9524  steps/s=103.31  prediction: \"works for the first time is the most fun\" => \" rA   e  too  or  r     r    t  t   t   \"\n",
      "batch 11216  loss=171.3573  steps/s=68.37  prediction: \"koslib Also just saw the Eu/acc, respect\" => \"e g koko  rt o    s     t  t e  t t s  t\"\n",
      "batch 11217  loss=138.6413  steps/s=109.15  prediction: \"or a site with a manipulatable algorithm\" => \"uk   o oooor  at      a  aaaaa a aaaa aa\"\n",
      "batch 11219  loss=141.2319  steps/s=102.79  prediction: \"e money now bc you can get 10x more done\" => \" ton e eemen  me                        \"\n",
      "batch 11220  loss=192.8799  steps/s=36.44  prediction: \"ly: @justalexoki https://t.co/XmWFPd7zQu\" => \"y: @Hmmeenen  en  o                     \"\n",
      "batch 11221  loss=158.6687  steps/s=130.58  prediction: \"izmobly you have 3 days or youre blocked\" => \"nm no  momnb  o           c        o  eo\"\n",
      "batch 11222  loss=138.9151  steps/s=105.62  prediction: \"too, its good to break your priors intoâ€¦\" => \"h t    otot oootooooooooo o      o    rr\"\n",
      "batch 11223  loss=145.8305  steps/s=104.56  prediction: \"ooks like from someone elses perspective\" => \"ukhan t  a e  o    oooooooeeeeeeeeeeeeee\"\n",
      "batch 11224  loss=148.5932  steps/s=105.23  prediction: \" then maybe do a bit of chess, or watchâ€¦\" => \"to   t   ett  b                         \"\n",
      "batch 11225  loss=139.3242  steps/s=105.61  prediction: \" long run in weird ways you dont realize\" => \"tona     ln n  n                        \"\n",
      "batch 11226  loss=172.1450  steps/s=100.51  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \"     n   oo0 0 0000e   ee rrrrtt////////\"\n",
      "batch 11227  loss=153.3360  steps/s=101.93  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"eblin  aanu i  f$v^$bá´›$j1â€ÊŸxÊŸ1_jxðŸš€1,0xU$\"\n",
      "batch 11228  loss=168.6852  steps/s=93.76  prediction: \"ere @jaivinwylde prime rgb lore revealed\" => \"  ooe tS jje   jeeetteeppeeeptee eoraere\"\n",
      "batch 11230  loss=153.2580  steps/s=103.13  prediction: \"output less verbose/convoluted solutions\" => \"nrsss ttt\n",
      " tt     ee  eeooooeeoooeeoesoo\"\n",
      "batch 11231  loss=150.4388  steps/s=102.79  prediction: \"ill you get better at as you practice it\" => \"nl be      l     t  tt   t      t  t  a \"\n",
      "batch 11232  loss=147.9380  steps/s=105.12  prediction: \"mul, transitions from one derivative toâ€¦\" => \"enc m e t m mitittitiinin nnn   n io   i\"\n",
      "batch 11233  loss=173.5054  steps/s=98.67  prediction: \"ein @DrBrianKeating yea he made a portal\" => \" r e @ iinneiinininniriiineeeea eaaaa   \"\n",
      "batch 11234  loss=171.8174  steps/s=101.72  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"tnit  reenrtereertutettte tttttttt/////t\"\n",
      "batch 11235  loss=185.4640  steps/s=88.57  prediction: \"dup QUICK do something that doesnt scale\" => \" vt p ueunuuntQeC ttet hthtthLtt/t8X8ooo\"\n",
      "batch 11236  loss=177.6978  steps/s=104.16  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"ltce P@  i o  AATT TTTTA A    ////E/EEE/\"\n",
      "batch 11237  loss=161.3180  steps/s=100.40  prediction: \"tic strategy\n",
      "Positional chess type stuff\" => \" ceat  ooc ostt tttttttttttssssisssstsss\"\n",
      "batch 11238  loss=143.2197  steps/s=103.29  prediction: \"did something similar w his site i think\" => \" n     i ani   mim  ii   mi ssii  ii  ii\"\n",
      "batch 11239  loss=137.9762  steps/s=101.24  prediction: \"thing you do very often, like constantly\" => \"hife    si nn     o                     \"\n",
      "batch 11240  loss=136.1017  steps/s=103.92  prediction: \" adding the context into the computation\" => \"tnr t\n",
      "   e s  eee ooe e  t nt e te ttttt\"\n",
      "batch 11241  loss=151.6509  steps/s=104.71  prediction: \"6hrs on something that feels like a game\" => \"hr 1 1   ro   ns o  o  h hh      e  e e \"\n",
      "batch 11242  loss=151.6346  steps/s=111.71  prediction: \"nes @micsolana same for my history class\" => \" M Ie 1  somsss nss o a  a m   s e  e a \"\n",
      "batch 11244  loss=147.9389  steps/s=104.47  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "Iettr  u,wd@xðŸ°AT@x6bN5q.?IqxqwwqTk1g6ZZ\"\n",
      "batch 11245  loss=184.7271  steps/s=104.29  prediction: \"YYYYYYYYYYYYYYY\n",
      "\n",
      "https://t.co/xt0RP3tmNR\" => \"oYYYYYYYYYYYYYYYYYYYYYBB\n",
      "\n",
      "\n",
      "B BYB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tR\"\n",
      "batch 11246  loss=233.8652  steps/s=38.97  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"y:YYYYYYYYYYYYYYYYYB\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "B///B\n",
      "//ttRRR\"\n",
      "batch 11247  loss=171.4277  steps/s=119.19  prediction: \" a while before I add it to the site tho\" => \"@leaylyllil    l      e e         t   t \"\n",
      "batch 11248  loss=152.6393  steps/s=104.02  prediction: \"' bc thats the name of the 4min mile guy\" => \"re   e' ' t   tt t t t  t  t   e    e e \"\n",
      "batch 11249  loss=156.4550  steps/s=104.95  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"  e   pp 3333 %         o      o       s\"\n",
      "batch 11251  loss=147.8930  steps/s=97.85  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"eke  p a an aat aaaat t hh     s e  esse\"\n",
      "batch 11252  loss=178.7620  steps/s=99.67  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly: @ idp   n     00 0 0     ttt///tt///\"\n",
      "batch 11253  loss=140.0197  steps/s=104.93  prediction: \" in those days will have had it too easy\" => \"at  o nsns n ss s  s   ss               \"\n",
      "batch 11254  loss=176.2063  steps/s=79.31  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"epiy: @ occG4.TBGj-8w?ðŸ¤”.YYYYY:YYYYY-8F?Q\"\n",
      "batch 11256  loss=162.1032  steps/s=103.51  prediction: \"ho. i like it much much better than rome\" => \"en it o i  n o n   i       t    th    tt\"\n",
      "batch 11257  loss=151.6957  steps/s=107.26  prediction: \"r full potential https://t.co/jR1cEbfQlo\" => \"efto  enb\n",
      "wk.g=0$kk[$[ðŸ‘€$$wðŸ°bá´›#ug]bbf`[èµ°`\"\n",
      "batch 11258  loss=147.5923  steps/s=104.69  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \"  n  n  n  n  \n",
      "  i  i  i+ +++++xxx      \"\n",
      "batch 11259  loss=154.9490  steps/s=101.19  prediction: \"unctional adults that they interact with\" => \"sd rf s  fn dd i n    t t  t  ttttt tttt\"\n",
      "batch 11260  loss=136.8571  steps/s=104.05  prediction: \", or that would be fun/interesting to me\" => \" suu e   t  t  t               etttttttt\"\n",
      "batch 11261  loss=167.8402  steps/s=58.94  prediction: \" @pilpulon will release v1 at some point\" => \"tme  e  t t t  l    e    e  etttt ttt  e\"\n",
      "batch 11262  loss=156.2988  steps/s=107.18  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"  sotth:h////tthtttthhttttt////ttt////PP\"\n",
      "batch 11264  loss=184.4824  steps/s=96.29  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"etg  /nnoLonhh.hnt..hht/t...//.t./ZZZt22\"\n",
      "batch 11265  loss=211.0803  steps/s=103.95  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"yte .4z--))))0))))0.)))((({.(((...5.5.5.\"\n",
      "batch 11266  loss=177.4978  steps/s=89.92  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" m(  oo  poppep.ppcocpoo.c.o... eeeysese\"\n",
      "batch 11267  loss=134.7233  steps/s=104.45  prediction: \"ounts for new lengths of weeks/months ig\" => \"n wn n o n   o   n   n       e eee  e e \"\n",
      "batch 11269  loss=139.5523  steps/s=104.37  prediction: \"s large of a positive impact as possible\" => \" Inea  aa   a                        sss\"\n",
      "batch 11271  loss=162.6170  steps/s=103.64  prediction: \"us @BasedBeffJezos Some are on the money\" => \"stsnks @ees ee eBBBeBeeeseeeeeee ee  e  \"\n",
      "batch 11272  loss=142.7395  steps/s=104.40  prediction: \"anding pages or whatever feels gross idk\" => \"td a  o n n n on         eee   eeeeee re\"\n",
      "batch 11273  loss=145.5368  steps/s=100.07  prediction: \"t lately\n",
      "\n",
      "Your RPA loop is pretty useful\" => \"hiothel t  lllt lllll                   \"\n",
      "batch 11274  loss=155.6666  steps/s=104.77  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "iau w@grBwP GMA@_GM}}Ik0z}I0xXXk}}}}kx.\"\n",
      "batch 11276  loss=180.1847  steps/s=97.46  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"eply:    rn eIBA@_)S/:Ik0IM)0xH:k_+.:k/B\"\n",
      "batch 11278  loss=139.8452  steps/s=104.58  prediction: \"all the way down https://t.co/uP6ieWqBYQ\" => \"nl talta nal    ll      ttttt/tt////////\"\n",
      "batch 11279  loss=152.8182  steps/s=102.91  prediction: \" I'm super down for another one thursday\" => \"@ s ! n!!!s s  d          o    o   o  rr\"\n",
      "batch 11280  loss=139.0345  steps/s=103.90  prediction: \"file editing program, will show vid soon\" => \" n iti  in ii ieiiiii i iiii l l   i    \"\n",
      "batch 11281  loss=142.3678  steps/s=105.21  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sth en  nse  e         ttt tttttttt////\"\n",
      "batch 11282  loss=144.6151  steps/s=103.45  prediction: \", how do WE figure out where things are?\" => \" yo  i  no                     e   e    \"\n",
      "batch 11283  loss=152.3220  steps/s=103.55  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne le llllllll         t tttttttttt////H\"\n",
      "batch 11284  loss=150.7822  steps/s=103.59  prediction: \"how it is in c++. Trace them rays brotha\" => \"euea  l  l  s          ++ +             \"\n",
      "batch 11285  loss=163.4240  steps/s=96.63  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"e: @mig   in ii+iniiacc    m aa   r  t a\"\n",
      "batch 11286  loss=144.1158  steps/s=104.99  prediction: \"g real and distracted from the adventure\" => \" htut s     n         ddddddd         ee\"\n",
      "batch 11287  loss=186.1368  steps/s=98.63  prediction: \"layzXD @ludwigABAP Based\n",
      "Python/zig gang\" => \"yti@ epeeleellXXllll d BBBBBPPPPBPPPt ee\"\n",
      "batch 11288  loss=153.3257  steps/s=100.69  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" nseseRsRaeeee eeeseeseeessesessesss ee \"\n",
      "batch 11289  loss=137.3895  steps/s=105.02  prediction: \"file editing program, will show vid soon\" => \" n iti  in  i ieiiiii i iiii l l   i    \"\n",
      "batch 11290  loss=159.8171  steps/s=103.57  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"ta    y    br    ...  ...  .....h/hh////\"\n",
      "batch 11291  loss=138.0035  steps/s=104.52  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of  on f nif n  nn    nntnttttttt/t////\"\n",
      "batch 11293  loss=136.3748  steps/s=103.70  prediction: \"ffect has it had on you? im very curious\" => \"  hie    ff f                           \"\n",
      "batch 11294  loss=148.9581  steps/s=101.40  prediction: \"it all up, and chatgpt is in on the scam\" => \"n ya  lla    la   a                     \"\n",
      "batch 11295  loss=146.4391  steps/s=100.12  prediction: \"pany uses it often for researching stuff\" => \"lnx ttonymnom  oo o    o o   e  r   r  r\"\n",
      "batch 11296  loss=180.6973  steps/s=105.44  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" eotttcocec\n",
      "dc dccocom   to ooootto///co\"\n",
      "batch 11298  loss=146.3246  steps/s=104.60  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er o  h be h  vv e   re   t tttoottott//\"\n",
      "batch 11299  loss=182.8224  steps/s=99.57  prediction: \"s must flow\n",
      "\n",
      "BILLIONS MIST BACKPROPOGATE\" => \" br t it t ss stt t\n",
      "\n",
      "\n",
      "ILIIIIISIIIOOOOOOT\"\n",
      "batch 11300  loss=145.2761  steps/s=103.31  prediction: \" software used that widely is so awesome\" => \"to  a n fa    a      e             s    \"\n",
      "batch 11301  loss=154.8853  steps/s=104.38  prediction: \"ny part of a much bigger long term thing\" => \"   e  a aaana n                gg   gggg\"\n",
      "batch 11302  loss=268.6725  steps/s=11.08  prediction: \"reply: @graffioh HA thats really awesome\" => \"eply: @ o s,eDHAHATB)kjPONkxMWTDOBATKOR(\"\n",
      "batch 11303  loss=140.0713  steps/s=108.42  prediction: \"pired link broadcast out to the most ppl\" => \"lt a w h e                      t tttttt\"\n",
      "batch 11304  loss=145.0777  steps/s=100.56  prediction: \" billion zimbabwe dollars of labor hours\" => \"tcsi bl blla bi bbbblbllll l  lllo llooo\"\n",
      "batch 11305  loss=155.6430  steps/s=102.28  prediction: \"owing that your food supply doesnt scale\" => \"   i n tt n t  tt      oo      ooo  o   \"\n",
      "batch 11306  loss=168.8214  steps/s=101.62  prediction: \"/t.co/i4ntqAK26E https://t.co/vE1KPjEGtm\" => \"/..c  nt/hi/t//4/tt/tttttt////tt/EEEE//E\"\n",
      "batch 11307  loss=151.1872  steps/s=103.36  prediction: \"libraries or backend compute or anything\" => \"ykei eneetr rrrerr rrrr r               \"\n",
      "batch 11308  loss=147.1512  steps/s=103.96  prediction: \"im definitely not an expert in it though\" => \"n  o u  ihiiiieniiiii                   \"\n",
      "batch 11309  loss=144.9062  steps/s=105.05  prediction: \"es success, but there is a causal factor\" => \"  iut e eees  utsssseesese es    a  a a \"\n",
      "batch 11311  loss=141.8201  steps/s=102.89  prediction: \"hange your brain. something to think abt\" => \"et  so  ror  orr  rr r   r     o  ni  i \"\n",
      "batch 11312  loss=142.0427  steps/s=104.82  prediction: \" games because we trusted each other lol\" => \"ter   aemems eme e ee se ee ee see e  ee\"\n",
      "batch 11313  loss=153.9703  steps/s=100.56  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"tatett llt l t e     ttttt ttttt tttt///\"\n",
      "batch 11314  loss=148.1473  steps/s=103.41  prediction: \"nd then vcs give u money for some reason\" => \"     a     n  en                        \"\n",
      "batch 11315  loss=139.3792  steps/s=103.96  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"e u yeeetseese teeee eeh e o o\n",
      "\n",
      "jj     \n",
      "\"\n",
      "batch 11316  loss=187.3581  steps/s=84.45  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \"u elshleethhhee e    t   \n",
      "\n",
      "t o        ss\"\n",
      "batch 11317  loss=137.8301  steps/s=106.27  prediction: \" or not so i dont have much data on that\" => \"tf   oo    t                            \"\n",
      "batch 11318  loss=164.7182  steps/s=104.14  prediction: \"of visualization goes away with practice\" => \"u i  es\n",
      "  if   ii  ioo  aaaaaao   aaa aa\"\n",
      "batch 11319  loss=172.9389  steps/s=100.34  prediction: \"yacine needs a dingboard wrap on his car\" => \":c\n",
      " a0 a00aea ieine n  aada  i  aoa aa  \"\n",
      "batch 11320  loss=146.2805  steps/s=104.41  prediction: \" of just doing what fundamentally worked\" => \"in  tc  s sse j     t     n n  nanann aa\"\n",
      "batch 11321  loss=140.8127  steps/s=99.23  prediction: \"ick and no login and as free as possible\" => \"ns/oa u     u  nn  nnnn  n   a  a    as \"\n",
      "batch 11322  loss=142.0697  steps/s=99.08  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \"  s ani eenan nnannnaaannnn          a  \"\n",
      "batch 11323  loss=135.8047  steps/s=101.01  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \" e  tt t t   toto ooooooo  o  s         \"\n",
      "batch 11324  loss=139.0637  steps/s=102.76  prediction: \" literally can\n",
      "not good for computer tho\" => \"@ott at   llllllallll\n",
      "  ooo ooo ooo   oo\"\n",
      "batch 11325  loss=172.2774  steps/s=101.95  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" @r  t  ni inolooooolloootlootttto//////\"\n",
      "batch 11326  loss=178.3895  steps/s=102.12  prediction: \" make https://t.co/s6ZBWGye2X executable\" => \"@as  s  k a    t   tt/  ///tt////eeeteee\"\n",
      "batch 11327  loss=176.1001  steps/s=64.16  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"yaninhM  tk t t/t/////ZZZttGGX eXeeeteee\"\n",
      "batch 11328  loss=141.9453  steps/s=106.28  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"u e e n nonn  o  oo    t tt   t   t   ss\"\n",
      "batch 11330  loss=156.2494  steps/s=106.67  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n  o   imien    i    ga     tthhttttt//O\"\n",
      "batch 11331  loss=182.9163  steps/s=87.11  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yb o o ezcc e a n  tata chh ht h/hhQQQDD\"\n",
      "batch 11332  loss=139.1900  steps/s=106.21  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"esg m  e t nt  t                        \"\n",
      "batch 11333  loss=143.6310  steps/s=104.00  prediction: \" been some adventure man. God bless him.\" => \"tuee  eee  nee eeeeeeeeeeeee            \"\n",
      "batch 11334  loss=157.0263  steps/s=104.74  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u aont n   tt                   0  0   \"\n",
      "batch 11335  loss=169.0879  steps/s=101.90  prediction: \"eople be bookmarking anything these days\" => \" pu ___iMer e   ee b    o  a   o gnn n n\"\n",
      "batch 11336  loss=149.3137  steps/s=102.63  prediction: \"forming around AI or aroumd a fear of AI\" => \" rme    ne n  tn      o      r  r  r    \"\n",
      "batch 11337  loss=170.5216  steps/s=98.55  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" oo o  nnnankna    rzzrrzz r            \"\n",
      "batch 11338  loss=151.1807  steps/s=101.25  prediction: \"wesome looking pieces though, im jealous\" => \"irAB P @ll leli  ooooe eeee eee         \"\n",
      "batch 11339  loss=139.5726  steps/s=104.88  prediction: \" only improve by improving their skills)\" => \"tfe  snnn non i      o    i   iiiiiiii i\"\n",
      "batch 11340  loss=146.8041  steps/s=104.11  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" o   anngnan n eennae eetetttsst//tt////\"\n",
      "batch 11341  loss=160.8868  steps/s=104.77  prediction: \" seems to be doing pretty good with both\" => \"tee aeg eee  e s  ee  ee  e  t tt to oot\"\n",
      "batch 11342  loss=141.8961  steps/s=105.50  prediction: \" away looks smoother than a bowling ball\" => \"tn   faaa aa  ffoo ao a oaao   o ooao  a\"\n",
      "batch 11343  loss=139.9767  steps/s=105.21  prediction: \" a lot of chess is abt how to think less\" => \"tn   ot  t o   t                        \"\n",
      "batch 11344  loss=137.8517  steps/s=103.75  prediction: \"your life (which is what happened to me)\" => \" u  ear lye  li        ii       hhh   h \"\n",
      "batch 11345  loss=140.4683  steps/s=103.64  prediction: \" onto it forever and never reevaluate it\" => \"tf e  non not no  o       n eerevveveeee\"\n",
      "batch 11346  loss=139.2170  steps/s=103.51  prediction: \"e other side of the conversation is like\" => \" tot     nh t  t          e e eeee     i\"\n",
      "batch 11347  loss=210.4296  steps/s=98.38  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"g het ttkeek eSIee  ININNIININIOOIEOOOON\"\n",
      "batch 11348  loss=170.6580  steps/s=96.50  prediction: \"ure Beautiful, and great choice of music\" => \"  riAete net ei eie   i     a     e   c \"\n",
      "batch 11349  loss=159.5408  steps/s=101.60  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"e el  e lonlool oollll oo     u fuufuu u\"\n",
      "batch 11351  loss=166.2767  steps/s=105.15  prediction: \"caml my caml, our fearful thread is done\" => \"ansse    m   mmmmmmm                    \"\n",
      "batch 11352  loss=180.3832  steps/s=58.56  prediction: \" @pilpulon will release v1 at some point\" => \"@Ame ml l\n",
      "m c amll a   a  a  a   ar     \"\n",
      "batch 11353  loss=149.4537  steps/s=105.24  prediction: \"sk for, then train them to ask, then act\" => \"   t     at t  t t   tt t t t  t    t   \"\n",
      "batch 11354  loss=158.7775  steps/s=105.34  prediction: \"Wooltard Thanks mayne. Good vibes indeed\" => \"owt  wottoon   raa aaa    a a      e    \"\n",
      "batch 11355  loss=182.5753  steps/s=90.13  prediction: \"a @teodor_io teo mercy killed anime pfps\" => \"ns  eo   zznnrrtoo  e   eo   ee    ieeee\"\n",
      "batch 11356  loss=166.4889  steps/s=75.07  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"lw zotaa @oeteo To  e  eoo   le e  iee  \"\n",
      "batch 11357  loss=148.0859  steps/s=107.22  prediction: \" the code in my head like an interpreter\" => \"@hini n ntn             h    e    e    e\"\n",
      "batch 11358  loss=155.6361  steps/s=97.41  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \"geth_t oothc otc o o   iee   a    a  e e\"\n",
      "batch 11359  loss=157.7081  steps/s=102.90  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  i t teeeggt eeee e   t   ttttt////t/tc\"\n",
      "batch 11360  loss=147.9609  steps/s=100.19  prediction: \"plate btw if u wanna make ur own version\" => \"ly: @l  eet tt   t  t a   a      a      \"\n",
      "batch 11361  loss=129.3040  steps/s=105.63  prediction: \" local optima solution they got stuck in\" => \"titt  t   tat  t   oooooooooooooottttttt\"\n",
      "batch 11362  loss=154.9437  steps/s=102.73  prediction: \"l modeling is a great one to add to this\" => \"yl ie  mmemme tmi   aa   a    a         \"\n",
      "batch 11363  loss=147.3189  steps/s=105.32  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  looro  r  oererrrre reroooeooeoo olol\"\n",
      "batch 11364  loss=141.1778  steps/s=102.26  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"e t  eeetseese teeee eeh e \n",
      " o\n",
      "\n",
      "\n",
      "j     j\"\n",
      "batch 11365  loss=159.2028  steps/s=104.17  prediction: \"re. Turns out it actually had a solution\" => \"ep5et es n.  uny}}}}}!,}(v(()(5zX99=`F`(\"\n",
      "batch 11366  loss=158.8711  steps/s=100.31  prediction: \"ice didnt know they made it that low, ty\" => \"ne n  a  n e  i i  n en i  e   tt  ttt  \"\n",
      "batch 11367  loss=157.8383  steps/s=38.88  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y: @Waic  ni  n t    de i  t   tt  t t  \"\n",
      "batch 11368  loss=138.6071  steps/s=112.71  prediction: \" own instead of relying on school for it\" => \"tf o n oonn nn n n          n    o  o oo\"\n",
      "batch 11369  loss=168.5771  steps/s=93.03  prediction: \"d 1995 type sites are such a great style\" => \" bnoooW   n9   r    ee e  e        r r  \"\n",
      "batch 11370  loss=158.1726  steps/s=105.95  prediction: \"ou can dive unbelievably deep into these\" => \"nltti d ne tnee n    n  ebbe eeeeeeeeee \"\n",
      "batch 11371  loss=157.5747  steps/s=97.49  prediction: \"ure Beautiful, and great choice of music\" => \"s  te meeteuuebuu uua   dee   ee  eec  o\"\n",
      "batch 11372  loss=159.7323  steps/s=76.73  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"oeetreeutu t eut      t    i i         t\"\n",
      "batch 11373  loss=142.0026  steps/s=105.63  prediction: \"e ive been thinking the exact same thing\" => \" tY: Beei    ee   e   ii   i   t   tt tt\"\n",
      "batch 11374  loss=146.5021  steps/s=100.82  prediction: \"mirages keep getting crazier and crazier\" => \"and e  ee r re eeeggeee eeet  ta e a azz\"\n",
      "batch 11375  loss=136.7765  steps/s=102.69  prediction: \"y noticed the last time i was there, lol\" => \":de iniiiiiitiett  ttttt                \"\n",
      "batch 11376  loss=182.0693  steps/s=63.50  prediction: \" more to 400! Been a crazy two weeks lol\" => \"@ef iiien et   t    te              eee \"\n",
      "batch 11377  loss=160.9873  steps/s=117.77  prediction: \"@arthur_d3nt cool shit\n",
      "cuda interop too?\" => \"Alyoiom e t thrtttt t t   c t    o  toet\"\n",
      "batch 11378  loss=136.0052  steps/s=102.22  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yt  do  m d m              uuuuuuuuuuuuu\"\n",
      "batch 11379  loss=178.2977  steps/s=100.06  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \" in c n na t  a     LLLLLsttststt/t/////\"\n",
      "batch 11380  loss=153.0836  steps/s=104.94  prediction: \"rf spatial in problem solving efficiency\" => \"e oe  esnemnekmeBL@M;;m@z;z:;;;.;;bLkJ;B\"\n",
      "batch 11381  loss=148.1055  steps/s=104.02  prediction: \"ms' meaning more straightforward success\" => \"a ble t'bt'b e me mmmmmme   rrr  rarrrrs\"\n",
      "batch 11382  loss=162.1968  steps/s=100.14  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \"hlre  noeen niet  e!eee e e         ee  \"\n",
      "batch 11383  loss=176.3602  steps/s=59.37  prediction: \" @ludwigABAP moo deng v selo who wins???\" => \"@sot etitii ninl  e eee   e         ii n\"\n",
      "batch 11384  loss=144.0586  steps/s=113.03  prediction: \"mes? maybe you could make a mod you want\" => \"atl e n   y mya   y                     \"\n",
      "batch 11385  loss=148.0036  steps/s=103.88  prediction: \"ugh or is it just whatever comes to mind\" => \"re  t o  rr o  o  i     t tt   t t  t   \"\n",
      "batch 11386  loss=149.4116  steps/s=104.01  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"u u n n   o   XX o!!!!!!!!!!ttttt///////\"\n",
      "batch 11387  loss=181.1827  steps/s=84.18  prediction: \"h1xabc king shit https://t.co/UJrAexS6FM\" => \"euu   aonnaa !n\n",
      "!!tt\n",
      "tt//tt://///./55666\"\n",
      "batch 11388  loss=156.4224  steps/s=106.37  prediction: \"cking a computable number from the reals\" => \"aeex  ni ni cini a  p m     o m m  r ere\"\n",
      "batch 11389  loss=150.5474  steps/s=104.87  prediction: \"tputs timestamps of ads =&gt; remove ads\" => \" s sesetut utt  tstsssss   ss t  s  tm  \"\n",
      "batch 11392  loss=152.9345  steps/s=105.00  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"nl a s   a aa lllllllllllllttttttt//////\"\n",
      "batch 11393  loss=153.4936  steps/s=104.86  prediction: \"king progress. Now i see it eeeverywhere\" => \"i g at a  t   a      s         eee eeeee\"\n",
      "batch 11394  loss=152.2980  steps/s=100.19  prediction: \"ke getting flashbanged by your teammates\" => \"i g tt il ti i e g gg gggge gg  b y  y a\"\n",
      "batch 11395  loss=138.6842  steps/s=103.42  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" toe e  etemr me    e                   \"\n",
      "batch 11396  loss=164.9107  steps/s=103.50  prediction: \"orks but is mvp\n",
      "\n",
      "https://t.co/0jdbSxKeVi\" => \"uk amemmmmes         \n",
      "\n",
      "\n",
      "\n",
      " s ttt/////////\"\n",
      "batch 11397  loss=155.9527  steps/s=102.23  prediction: \"ught it was a cool idea so i speedran it\" => \" eit\n",
      "to\n",
      "et\n",
      "tttit t        o             \"\n",
      "batch 11398  loss=154.6377  steps/s=93.20  prediction: \"builds It is factually what plants crave\" => \"et\n",
      "tiibb tt t t        aa    aa    aaa  \"\n",
      "batch 11399  loss=146.3297  steps/s=105.44  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \" /n  n  n  n  \n",
      "  i  i  i+ ++++xxxx      \"\n",
      "batch 11400  loss=157.0952  steps/s=100.26  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ngMTo d d  d  d           tt t//////////\"\n",
      "batch 11401  loss=139.2344  steps/s=104.07  prediction: \"people, i just post a weird mix of stuff\" => \"lr     okoo   t                         \"\n",
      "batch 11402  loss=164.7954  steps/s=94.20  prediction: \"77x im guessing you're super cracked huh\" => \"    lei 7   s 7s s s  esss       r    uu\"\n",
      "batch 11403  loss=179.4715  steps/s=105.71  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lc  b  ssi  suuuu           ttttttttt///\"\n",
      "batch 11404  loss=194.6662  steps/s=31.03  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly: @  s us uuu         tt tttttt///////\"\n",
      "batch 11405  loss=146.5439  steps/s=109.06  prediction: \"r 100x more productive, get good with it\" => \"etey: lcninne@nePA@S/vbvc,By(_bTLP36bMb0\"\n",
      "batch 11406  loss=173.5952  steps/s=52.96  prediction: \": @IterIntellectus here have another one\" => \" @tacwlc enIe@ppPA@B/,bv,,gg(qbTLP&6bMb0\"\n",
      "batch 11407  loss=147.4811  steps/s=105.52  prediction: \"n is a great way to beat some addictions\" => \"gtwoi n   t tstitttt    a  t  aa   aaa  \"\n",
      "batch 11409  loss=154.9050  steps/s=105.24  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"  co/th:h////tthhttthhhh/tt////ttt////t/\"\n",
      "batch 11410  loss=149.3835  steps/s=103.21  prediction: \"n and id 100% recommend it over The Goal\" => \"gi aoot d  d   d                    e ee\"\n",
      "batch 11411  loss=140.4889  steps/s=105.32  prediction: \"t info, hence why I expanded past papers\" => \"htoe ah  n  n h               e       pp\"\n",
      "batch 11412  loss=144.0103  steps/s=105.77  prediction: \"y be a way to do it without grad descent\" => \" bhnet  t      y               t  t dt  \"\n",
      "batch 11413  loss=157.0760  steps/s=46.69  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \"  @ ee  be n  a             t  t  d dttt\"\n",
      "batch 11414  loss=150.8493  steps/s=107.87  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"/..csists///t//st///ttttts////tt////P//P\"\n",
      "batch 11415  loss=143.1363  steps/s=104.98  prediction: \"elated to status games or zero sum games\" => \" s s  sette t t tttttttt t              \"\n",
      "batch 11416  loss=179.4623  steps/s=102.62  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \" ecitei tt a  tttt tttaa aaaa a    a    \"\n",
      "batch 11417  loss=143.1721  steps/s=105.67  prediction: \"ype \"get cracked at the basics\" strategy\" => \" e re i  o m       e  e  te  tt    t t a\"\n",
      "batch 11418  loss=144.3887  steps/s=100.94  prediction: \" adventure over the comfort of certainty\" => \"t ee eeee tneeeteeee eeee re   oo  o t  \"\n",
      "batch 11419  loss=156.3613  steps/s=100.91  prediction: \"n @grapplingdev HA i love it, lets do it\" => \" ir eeena@n aaanann        v            \"\n",
      "batch 11420  loss=133.8310  steps/s=100.66  prediction: \"stening to the sidetweets podcast at 1am\" => \" isetl   nn  nt    i ttee teee eettetttt\"\n",
      "batch 11421  loss=149.7694  steps/s=105.50  prediction: \"r time your focus muscle will strengthen\" => \"eoerg tomm aOwlnOk)/wkym/bOf(Ab@kmu(y/Ov\"\n",
      "batch 11422  loss=143.0988  steps/s=104.64  prediction: \", how do WE figure out where things are?\" => \" io  i  n  i                   e   e    \"\n",
      "batch 11423  loss=158.9777  steps/s=104.82  prediction: \" at like 8pm\n",
      "\n",
      "Every restaurant offers it\" => \"tnet ee f eekee    e eeeee eeeerrrrr rr \"\n",
      "batch 11424  loss=192.7857  steps/s=31.29  prediction: \"ply: @ludwigABAP https://t.co/TLPu6oMgJO\" => \"ly: @oe   f  ee   \n",
      "e eeeeereee rrrrr rr \"\n",
      "batch 11425  loss=142.5742  steps/s=119.95  prediction: \"i have a few libraries in there sadly :9\" => \"nt  i laaaa a   a  a                 e  \"\n",
      "batch 11426  loss=158.0977  steps/s=103.00  prediction: \"d you man. Yea whenever you can do join!\" => \" igs       i  m      eeeeeeeeee e       \"\n",
      "batch 11428  loss=157.0202  steps/s=103.98  prediction: \"erminal sub window alongside your files?\" => \"   er  a t ta       a  an  a   n  no    \"\n",
      "batch 11430  loss=155.5673  steps/s=101.74  prediction: \"file llm editing stuff is the future imo\" => \" c lt llllefellilllliiiiii it ff fft    \"\n",
      "batch 11431  loss=159.7077  steps/s=91.56  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \" e  e lelte eiir   ttti    t  tt   t   e\"\n",
      "batch 11432  loss=158.1565  steps/s=104.18  prediction: \"he phone seems to make a huge difference\" => \"e e t       e tee  e   ee    e      eeee\"\n",
      "batch 11433  loss=163.7257  steps/s=101.23  prediction: \"sist... bait.... https://t.co/FSXHHMMAoD\" => \" t.lt ..................tt ttttttt//////\"\n",
      "batch 11434  loss=142.6107  steps/s=101.01  prediction: \" able to do this approach w gpus anyways\" => \"@nee ee b bb  b                    p a a\"\n",
      "batch 11435  loss=163.7157  steps/s=105.55  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" ni t on'on  n n                        \"\n",
      "batch 11436  loss=149.8656  steps/s=103.59  prediction: \"l ideas\n",
      "\n",
      "say if youre trying to learn ML\" => \"yige eeeleneieel         eyyy y   y     \"\n",
      "batch 11437  loss=147.9510  steps/s=104.77  prediction: \"w zooming forward on an electric scooter\" => \"aou e na wo oon oo ooo  o  on      nc  c\"\n",
      "batch 11438  loss=145.8084  steps/s=105.60  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"the  iii tnt         s       a aaa aaaaa\"\n",
      "batch 11439  loss=151.6957  steps/s=99.98  prediction: \" busy so i havent been posting much my b\" => \"ter  eesbss s s          e  e n  e tnen \"\n",
      "batch 11440  loss=188.0713  steps/s=103.66  prediction: \"dnt acct for maintenance/electricity tho\" => \"  hs ee ca  t ct       nnanceaaacneeecet\"\n",
      "batch 11441  loss=165.0076  steps/s=105.32  prediction: \"probably because we were ballin too hard\" => \"lo: @N onooabb aaebbbbbeeeeeeeeeeee e   \"\n",
      "batch 11442  loss=146.2008  steps/s=104.55  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng  ooso n gg nn                 uuuuuu \"\n",
      "batch 11444  loss=179.9863  steps/s=98.05  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "re  U@  ALLt_A!jL?OBvL.A.??B?vjAH?wjAHB\"\n",
      "batch 11445  loss=157.8611  steps/s=99.50  prediction: \"keep that in mind\n",
      "idk what brypto is btw\" => \"  w llee kl l n             i    i      \"\n",
      "batch 11446  loss=149.1566  steps/s=104.58  prediction: \"s it and im unaware (would love to know)\" => \" ye s   t  ss n                         \"\n",
      "batch 11447  loss=164.7804  steps/s=99.46  prediction: \"ot even... this? https://t.co/vAkhEpFVm1\" => \"r hhi in  n  n...t ...t t tttt.ttt//////\"\n",
      "batch 11448  loss=168.3227  steps/s=97.65  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BA  el nl@n  e@Attttttttt ooeoooooo   o\"\n",
      "batch 11449  loss=198.1913  steps/s=19.38  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly: @PiPi@n@s@esttttttt   oo ooooo    o\"\n",
      "batch 11450  loss=167.7358  steps/s=145.02  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"hean t @enww tneh eeseooee e eee e e GEE\"\n",
      "batch 11451  loss=146.4084  steps/s=98.57  prediction: \"wesome looking pieces though, im jealous\" => \"i ABAPl@lleleeweeoooee ee e e   o       \"\n",
      "batch 11452  loss=147.1419  steps/s=103.37  prediction: \"tial art and he generalizes between them\" => \"hoe  om mrr aa aaa   a  a     eee  eee e\"\n",
      "batch 11453  loss=157.7780  steps/s=99.23  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e ay:  e \n",
      "f l@g&gj@BdP:21AOk21AA3zð—ª0LbS?\"\n",
      "batch 11454  loss=141.1837  steps/s=103.39  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hae s   t  emeneeeeeeeeeteeeeeeeee  nnnn\"\n",
      "batch 11455  loss=142.6309  steps/s=103.35  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"yce esj t  t   e     n    t   ttttt////G\"\n",
      "batch 11456  loss=146.6889  steps/s=103.58  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n  t a   \n",
      " d  gi  i   d   AA d   i     d\"\n",
      "batch 11457  loss=153.8843  steps/s=99.80  prediction: \"tloader ah another tool builder, love it\" => \"heng  oobaoo o ooa oo o  o  oo   eo le l\"\n",
      "batch 11458  loss=157.6101  steps/s=101.41  prediction: \"y the paper i thought it was a neat read\" => \":iile p  \n",
      "hEt hhppp      hhhht   t t   a\"\n",
      "batch 11459  loss=264.9245  steps/s=12.71  prediction: \"reply: @esiarpze its good to be back man\" => \"eply: @sremneUd_%@RU_b@%McBC%MAB%TM%c%!k\"\n",
      "batch 11461  loss=136.5359  steps/s=112.24  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"tae   d t gg      pppppppp              \"\n",
      "batch 11462  loss=192.8805  steps/s=45.96  prediction: \"ly: @justalexoki https://t.co/bQLKyhfmhI\" => \"y: @gt   g     ppppppp                p \"\n",
      "batch 11463  loss=165.0079  steps/s=107.23  prediction: \"caml my caml, our fearful thread is done\" => \"hsase    m   mmmmmmm                    \"\n",
      "batch 11464  loss=158.3762  steps/s=96.44  prediction: \"utput brothers karamazov, word for word\"\" => \"s igAA uti    t  ttrrrtarraaaaa rrr oorr\"\n",
      "batch 11465  loss=152.5869  steps/s=104.62  prediction: \", write one sentence after another, andâ€¦\" => \" aad  rdd dwo d ee ee  e eeeeneeeee enee\"\n",
      "batch 11466  loss=139.3385  steps/s=105.13  prediction: \" in those days will have had it too easy\" => \"tt mm ssss n ss    s   ss               \"\n",
      "batch 11467  loss=151.3110  steps/s=104.66  prediction: \"' bc thats the name of the 4min mile guy\" => \"ra i e' ' t   tt t t t  t  t   e    e e \"\n",
      "batch 11468  loss=150.6822  steps/s=103.56  prediction: \"ld love to hear if you dont mind sharing\" => \"y   tp   lloloel          o             \"\n",
      "batch 11469  loss=145.3851  steps/s=100.85  prediction: \"to play chess sometime, my li is dnbt777\" => \"  t  b   o            s s   m m         \"\n",
      "batch 11470  loss=145.5857  steps/s=106.56  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \"frle    tt n tettttt  eeeeeeeeel   c  e \"\n",
      "batch 11471  loss=136.7649  steps/s=104.80  prediction: \" yrs. ur brain will figure it out, trust\" => \"aoui  n r  rrrr rrr r    ii iiii  i    u\"\n",
      "batch 11472  loss=146.3141  steps/s=104.53  prediction: \"ions you choose, like oregon or whatever\" => \"nn o   onoetnono ooo  ooooooooo o o  oeo\"\n",
      "batch 11473  loss=149.3081  steps/s=101.95  prediction: \"ool challenge. amazing its down to 112mb\" => \"n  i  s   c   ccllll aaa a a  a n       \"\n",
      "batch 11474  loss=211.6861  steps/s=100.18  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"SphGrWH  TTTETETETAAA OAA     ///////ttE\"\n",
      "batch 11475  loss=158.4617  steps/s=95.47  prediction: \"hnote uuuh i have a license for thse sir\" => \"es eaastte tu   hu    u h    e e  s s ss\"\n",
      "batch 11476  loss=146.2030  steps/s=103.45  prediction: \"acked spends their time on fb linked etc\" => \"ni  s pfyd  d edddd  ede  eee    e ee ee\"\n",
      "batch 11477  loss=159.0218  steps/s=104.11  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee  e e  ne eeee nnentt tttttt/t/////\"\n",
      "batch 11478  loss=209.3689  steps/s=24.17  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" lya @mee e ne  eee nnttttttttt///t/////\"\n",
      "batch 11479  loss=154.3949  steps/s=123.57  prediction: \"but i followed just in case you do pivot\" => \"etk           w                         \"\n",
      "batch 11480  loss=157.0020  steps/s=103.21  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "id i ea es h20@!jOUU!vO)cð˜€Aâ™‚x#,^ðŸŒ‘U\n",
      "UA)(\"\n",
      "batch 11481  loss=145.5138  steps/s=104.61  prediction: \"de it one of the best ive had in a while\" => \" rh   t dit t it  t      e   e          \"\n",
      "batch 11482  loss=137.6626  steps/s=101.80  prediction: \"seless to ppl who dont know them already\" => \"t eepssesseeese s             o         \"\n",
      "batch 11483  loss=136.7388  steps/s=104.31  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"nn  ppp oo e  en   e  eeee eeee         \"\n",
      "batch 11484  loss=213.4990  steps/s=99.97  prediction: \"DE\n",
      "14hrs is wild\n",
      "also james is a gooooat\" => \"ediau00 EDEEUD E  4 \n",
      "\n",
      "\n",
      "\n",
      "l l   l ss sa s \"\n",
      "batch 11485  loss=147.8013  steps/s=98.56  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"AT @UiT e  eeeteeee eeeees ss sssss     \"\n",
      "batch 11486  loss=166.6629  steps/s=39.18  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @BABeene eeeneee   es ssss sss      s\"\n",
      "batch 11487  loss=142.7255  steps/s=107.51  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"      aalynaeaaaa aaaa  a               \"\n",
      "batch 11488  loss=162.1455  steps/s=104.18  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"O DA a em t t   U   e \n",
      "\n",
      "t\n",
      "tttttt/////QQQ\"\n",
      "batch 11490  loss=215.7129  steps/s=104.45  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \" GOEsntt COMivvvWChKINM:WO.KINKINjjWRLRO\"\n",
      "batch 11492  loss=152.2907  steps/s=102.58  prediction: \"ow readable zig is. how does ak do it???\" => \"rig  n  ee w  er      e                 \"\n",
      "batch 11493  loss=140.2229  steps/s=97.66  prediction: \"ews on the internet\n",
      "id say it worked lol\" => \"   r ngi nnt   e  e n eeee e   i        \"\n",
      "batch 11494  loss=130.4035  steps/s=98.85  prediction: \"to it so you can share with your friends\" => \"  t    tt tss  s                        \"\n",
      "batch 11496  loss=156.4904  steps/s=104.97  prediction: \"... and 4\n",
      "\n",
      "idk about other spaces though\" => \". oA   ......44444                      \"\n",
      "batch 11497  loss=181.9030  steps/s=58.45  prediction: \" @anish0209 And now hes making it run js\" => \"tbteeee...444 eddd  d       a    t    hu\"\n",
      "batch 11498  loss=149.0250  steps/s=108.36  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" i e   d  dd dd d dd     t              \"\n",
      "batch 11499  loss=135.2479  steps/s=104.66  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" o    s e eteeetee              ot t  t \"\n",
      "batch 11500  loss=155.4672  steps/s=103.48  prediction: \"plex projects in it but it was super fun\" => \"ly: @p e  e e cce  e                    \"\n",
      "batch 11501  loss=154.7921  steps/s=103.13  prediction: \"ad to give some direction/motivation tho\" => \"ne o  y o   to too   oo   ooo ioioiotiio\"\n",
      "batch 11502  loss=147.8778  steps/s=105.27  prediction: \"w zooming forward on an electric scooter\" => \"it  e    wowoon oo ooo  o  on      nc  c\"\n",
      "batch 11504  loss=186.9866  steps/s=94.50  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"n    zo  w  oon   n     nnee rttcc /tttc\"\n",
      "batch 11505  loss=147.6560  steps/s=97.51  prediction: \"s. let the people decide. for danmocracy\" => \"  ee rteett eee ee  e  eeee ee e e eeddd\"\n",
      "batch 11506  loss=159.8964  steps/s=99.05  prediction: \" stuff! Thanks, hope yours went well man\" => \"@e  t    one   fo    h h       e   oe   \"\n",
      "batch 11507  loss=162.8530  steps/s=103.94  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" tes is//?/k????????????k   ??o ll     n\"\n",
      "batch 11508  loss=143.7888  steps/s=105.48  prediction: \"il of the recall/visualization over time\" => \"nl ap    t    e e    l llllllllliiiiiiio\"\n",
      "batch 11510  loss=145.3705  steps/s=104.80  prediction: \"at can be beaten if you look hard enough\" => \"t s sesssse te tee   e                  \"\n",
      "batch 11511  loss=164.0866  steps/s=106.62  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"tua ini t e ttnetette ttttt thtttt//////\"\n",
      "batch 11512  loss=150.9818  steps/s=104.84  prediction: \"eting ppl on here\n",
      "\n",
      "the next half WE BALL\" => \" te e eeetten  e  e    eeee ee eee    h \"\n",
      "batch 11513  loss=180.3403  steps/s=53.29  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @Ainm oi\n",
      "soe-vMTvMT---MTCCB.PBxPq5C3PHW\"\n",
      "batch 11515  loss=139.6956  steps/s=114.17  prediction: \"if you have enough courage to go for it.\" => \"n   e    o a                   o  oooooo\"\n",
      "batch 11516  loss=142.8073  steps/s=104.72  prediction: \" tons of stuff, for yrs, and that worked\" => \"thet n  t  t   s    ffff fff            \"\n",
      "batch 11517  loss=145.3533  steps/s=105.11  prediction: \"ions you choose, like oregon or whatever\" => \"nn re nonoetnono ooo  ooooooooo o o  oeo\"\n",
      "batch 11518  loss=160.2869  steps/s=68.99  prediction: \"ludwigABAP ty bro\n",
      "i need to post more fr\" => \"ydhtens c   ooo  o  eoo  ee  oo o o  ere\"\n",
      "batch 11519  loss=174.7870  steps/s=101.85  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"n  lonnA c cy ty i OOee OOe  o   ooe  rr\"\n",
      "batch 11520  loss=143.3233  steps/s=104.68  prediction: \"l possible golden gate bridge existences\" => \"yt ol l   l ll lol  l        ee ee eeeee\"\n",
      "batch 11521  loss=151.3125  steps/s=100.03  prediction: \"new super super early on she was the one\" => \"  arti e ret   r    eee r er    es e   s\"\n",
      "batch 11522  loss=144.7176  steps/s=105.44  prediction: \"x reddit is the strange people attractor\" => \"ps  ieTexxxxee te e   e       eet ee ete\"\n",
      "batch 11523  loss=136.8812  steps/s=104.61  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" a nada  aerr  aa aaa    asssssst/tt////\"\n",
      "batch 11524  loss=202.1830  steps/s=104.12  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"1B A2AAAA7A1A19191B19B1911131BA13A33333A\"\n",
      "batch 11525  loss=147.9390  steps/s=106.09  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tard t i tin            t tttttt////////\"\n",
      "batch 11526  loss=150.2531  steps/s=105.38  prediction: \"e a dog\n",
      "\n",
      "thats how i feel abt it anyways\" => \" a a    ko l  a    o                    \"\n",
      "batch 11527  loss=169.8411  steps/s=104.42  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"tocl\n",
      "ttt\n",
      "///ttQ:tttoSSttSSS:tttt:///tt//\"\n",
      "batch 11528  loss=149.6364  steps/s=103.90  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"n  eeelhet hh  raaa r      rer    ee  ee\"\n",
      "batch 11530  loss=137.8761  steps/s=101.45  prediction: \"ure the first man on mars thats so crazy\" => \"s  tt eee ee eet                      s \"\n",
      "batch 11532  loss=141.0087  steps/s=103.07  prediction: \"and then pivot to doing a project in zig\" => \"nd ee  ininin t n     n  t     o o      \"\n",
      "batch 11533  loss=165.2250  steps/s=93.58  prediction: \"builds 2012 but yet blunders mate in one\" => \"et   ibbni d   t   t                    \"\n",
      "batch 11534  loss=144.7607  steps/s=102.69  prediction: \"it playable on lichess and post the link\" => \"n   ca   elllllel ll    l  a           s\"\n",
      "batch 11535  loss=149.9473  steps/s=99.87  prediction: \"xe only the strongest can take this path\" => \"am nl    egg yego e se    t   tt tt t ta\"\n",
      "batch 11537  loss=184.4483  steps/s=98.56  prediction: \"re @ludwigABAP @sebby_builds hood braces\" => \"eply:  HmxS PIzd01NxB0P2@BAPL@_7IEy_1jxE\"\n",
      "batch 11538  loss=184.5851  steps/s=101.33  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"u e eps//////BssBBBB BoB   o o  o  l   e\"\n",
      "batch 11539  loss=156.5459  steps/s=104.27  prediction: \"k checked him out, followed, thanks mate\" => \"eui \n",
      " t  chk  uc            ooo     o,  \"\n",
      "batch 11541  loss=139.0938  steps/s=102.45  prediction: \"companies spend that much cash on a logo\" => \"hm   sveete n esee                h     \"\n",
      "batch 11542  loss=150.9364  steps/s=101.18  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"  aee mai ni       t t  ttttt ttttt/////\"\n",
      "batch 11543  loss=159.3781  steps/s=97.32  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tv   e nc  en t  h tttt::::////t.////00O\"\n",
      "batch 11544  loss=170.8553  steps/s=104.27  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "oih p h io j~@nxjÉ´E#_â˜ |~2/xB()~bf|7_/-%\"\n",
      "batch 11545  loss=142.8757  steps/s=104.22  prediction: \"s aside though, why wouldn't that work?)\" => \" aoo    eeskes ts   h hh  hh  h   h w w \"\n",
      "batch 11546  loss=149.3093  steps/s=104.88  prediction: \"n i did eventually. hypothesis confirmed\" => \" my ee d edi  nnd   nn    eee   e    iii\"\n",
      "batch 11547  loss=162.9613  steps/s=92.69  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @ id  denn itin ia ythalliha i i  iii\"\n",
      "batch 11548  loss=153.5755  steps/s=105.28  prediction: \" you can do the second without the first\" => \"tou        a   n              o      t  \"\n",
      "batch 11549  loss=172.5759  steps/s=78.43  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" ng   i    OO   OOOe ee   eeo \"\"\"\" hhh  \"\n",
      "batch 11550  loss=150.2986  steps/s=109.62  prediction: \"it all up, and chatgpt is in on the scam\" => \"n  aa        la   a                     \"\n",
      "batch 11551  loss=167.6453  steps/s=105.40  prediction: \"ich in this case, is their lack of speed\" => \"nk ste  hshs    h    ss  i i  ii        \"\n",
      "batch 11552  loss=165.2227  steps/s=104.20  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" mo    anfana rata aa t a t   t// t//ttL\"\n",
      "batch 11553  loss=161.0976  steps/s=95.58  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"aM             ge  ppopnnpo.n n n  b   b\"\n",
      "batch 11554  loss=132.9441  steps/s=104.75  prediction: \"nse and you can't efficiently work withâ€¦\" => \"ge   oe  nnm   n           n            \"\n",
      "batch 11555  loss=150.0882  steps/s=103.32  prediction: \"nal golf, really https://t.co/XJ8ijD0rEK\" => \" ti  n n nennne l lllllllllltttttttt//tt\"\n",
      "batch 11556  loss=144.5240  steps/s=104.04  prediction: \", how do WE figure out where things are?\" => \" so  i  n  i                   e   e    \"\n",
      "batch 11557  loss=183.4053  steps/s=65.43  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"leo4hzo oo o              e    eee   e e\"\n",
      "batch 11558  loss=138.4491  steps/s=112.39  prediction: \" the first alien on earth thats so crazy\" => \"thee  neeh t   r e             ttt t t  \"\n",
      "batch 11559  loss=144.1756  steps/s=104.37  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \" diy  u  e    y    uu  hh h  hhhhhhhh   \"\n",
      "batch 11560  loss=159.5753  steps/s=103.15  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"taa eA  mmmem m     t       ot  o   o o \"\n",
      "batch 11561  loss=160.5223  steps/s=81.29  prediction: \"drew_pynch Sounds like a good comfy time\" => \" eg Bea  e  l      oo     l     ooo   ee\"\n",
      "batch 11562  loss=165.4796  steps/s=106.54  prediction: \"n `AI(short prompt)-&gt;output` programs\" => \" atttp us  s  r     r  tottttpttptptttpt\"\n",
      "batch 11563  loss=162.9564  steps/s=91.04  prediction: \"thy I wonder how attention relates to IQ\" => \" ant sehr t I ro ootrtttottttotttoorrrrt\"\n",
      "batch 11564  loss=133.6568  steps/s=102.77  prediction: \"ntext into a computation to make it pure\" => \"   i t   nnnt n     tttttttttttttttt t  \"\n",
      "batch 11565  loss=145.5253  steps/s=105.65  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"en h i   bbe  hbe  eeeeeoe i  sii i     \"\n",
      "batch 11566  loss=157.4566  steps/s=80.34  prediction: \"arcyan now you can make pokemon real too\" => \"nei too tes n qo   oo  s   i  o o       \"\n",
      "batch 11567  loss=149.6762  steps/s=104.90  prediction: \"o beta testers, and the world soon after\" => \" ie   te  e  e t  te  ttt  et   t   o  o\"\n",
      "batch 11568  loss=143.8251  steps/s=104.72  prediction: \"every useful thing I do the cooler it is\" => \" e remnemerereer eeeee             o    \"\n",
      "batch 11569  loss=170.0314  steps/s=101.90  prediction: \"e77 build things people want/ need maybe\" => \" 7 re rie@7e77     iii  l   e l e ee nee\"\n",
      "batch 11570  loss=150.6278  steps/s=103.20  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" de   nee t  ta\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttt/t//////\"\n",
      "batch 11571  loss=192.9245  steps/s=101.48  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" tea  naei M  \n",
      "\n",
      "\n",
      "\n",
      "tttttt///////////..c//\"\n",
      "batch 11572  loss=161.7693  steps/s=100.80  prediction: \"ing all my money https://t.co/IXXYEJUqHm\" => \"ne  e     lel   l l           t t//t/XX/\"\n",
      "batch 11573  loss=153.4692  steps/s=74.10  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" me  t  l  l  ul   ott /tt/:///XXX///JJU\"\n",
      "batch 11574  loss=184.3280  steps/s=85.85  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"@Cal a     l   oo tttt:////./////c//6WUU\"\n",
      "batch 11575  loss=165.8090  steps/s=86.13  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"@Cal a  ell l nooltttt//tttsc.c/ccnns4nðŸ›‘\"\n",
      "batch 11576  loss=155.8415  steps/s=119.96  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \" eeu tucetinsses sstsestttttstt/////tt//\"\n",
      "batch 11578  loss=156.4875  steps/s=98.41  prediction: \"ing\n",
      "\"ai, make me a pacman game in sokol\"\" => \"ng  ttotponoiii  mm  mmma a  aaa  aa  a \"\n",
      "batch 11579  loss=148.9498  steps/s=101.48  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" sh ht    t  th ttttttttttt ttttttt  tt \"\n",
      "batch 11580  loss=147.2096  steps/s=102.94  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \" e h n  n n t o                 00000000\"\n",
      "batch 11581  loss=146.8483  steps/s=104.97  prediction: \"m scratch in numpy like i did w backprop\" => \"ete  tp  msst r                         \"\n",
      "batch 11582  loss=149.5521  steps/s=103.26  prediction: \"is not concrete enough to put into words\" => \"n   a  nnn etnnn  tn nn no   o t  ot  oo\"\n",
      "batch 11583  loss=149.0052  steps/s=103.46  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \" ai t t   tt    t    t ee    e    e  o  \"\n",
      "batch 11584  loss=150.6266  steps/s=104.24  prediction: \" is a wild computational rabbithole man.\" => \"t  ypse     aa acc    aa aaa i aaaibaabl\"\n",
      "batch 11585  loss=151.7365  steps/s=102.75  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"ne s s   aal lllllllllllll ttttttttt////\"\n",
      "batch 11586  loss=144.9412  steps/s=97.36  prediction: \" sudo systemctl restart systemd-resolved\" => \"te a       e oes  tssttttttttsttttsssses\"\n",
      "batch 11587  loss=140.0658  steps/s=102.63  prediction: \"r, it felt a little linkediny over there\" => \"e  y: @r, sBbZvYAPZZYZZZZZZZIâ€¦â€¦##I#API##\"\n",
      "batch 11588  loss=147.9227  steps/s=105.05  prediction: \"is not concrete enough to put into words\" => \"n/ /n  nnn etnnn  tn nn no   o t  ot  oo\"\n",
      "batch 11589  loss=150.6142  steps/s=103.98  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "gdpr  r IgcI!vJ{I,#ÊŸ,#^ðŸ‘ŒÊ€,,{ðŸš€#][{É´[â€[[ÊŸ\"\n",
      "batch 11590  loss=167.6171  steps/s=99.94  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"rk \n",
      "\n",
      "o iin w   o oo  ss  tss  sts to/tyy\"\n",
      "batch 11592  loss=149.0776  steps/s=101.92  prediction: \"ked bc i could make cool fun stuff in it\" => \"e fhhho t   ooooooo    oo   oo    o     \"\n",
      "batch 11593  loss=145.4980  steps/s=103.60  prediction: \" possibly even take classes remotely idk\" => \"tod os o lso  b   e        eee eeeeeeeee\"\n",
      "batch 11594  loss=136.4595  steps/s=104.89  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e ahat   a a  eh  e   ththhttttth/t/t///\"\n",
      "batch 11595  loss=176.3283  steps/s=100.50  prediction: \"rackpad &gt;&gt; 3 monitors + pc + mouse\" => \"emby  egize ,+he3I+0xvx+&w,;1:'V;3&0qI3g\"\n",
      "batch 11596  loss=156.0462  steps/s=105.14  prediction: \"illed w AI tools https://t.co/AIn5typg7l\" => \"nl ant  g l t            ttttttttttt////\"\n",
      "batch 11597  loss=265.0207  steps/s=11.29  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"epe uL@BLmfeQðŸ˜Ž\n",
      "h[]ð—¯å§#Êœ#[á´€[]á´€ð—µÉªk^á´„å§ðŸ¤·kxká´„A\"\n",
      "batch 11598  loss=196.1110  steps/s=143.77  prediction: \": @EsotericCofe what are you working on?\" => \" @aou as zfevX\n",
      "f3v8v8XvxXXX\n",
      "25???D@Bxk?A\"\n",
      "batch 11599  loss=194.8843  steps/s=38.13  prediction: \"eply: @visakanv The attack of the clowns\" => \" ly: @l t  Ct el   tttt tttt//////////t7\"\n",
      "batch 11600  loss=172.8979  steps/s=111.13  prediction: \"ived did. Its pribably more fun that way\" => \"ne ok    v     ii       ii              \"\n",
      "batch 11601  loss=141.6173  steps/s=101.29  prediction: \"ood and helps you not waste future years\" => \" d    i o                    o     t utu\"\n",
      "batch 11602  loss=151.2770  steps/s=101.22  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"tt e nt  ht a  naaaa  ada aa   a    e   \"\n",
      "batch 11603  loss=146.2596  steps/s=105.27  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"re  o d  ndeand   aa   aa  a   a     nn \"\n",
      "batch 11605  loss=176.9188  steps/s=103.68  prediction: \"load this prompt https://t.co/Ug4apoNeat\" => \"yteca o  a aoooo   tttttt ttppttttt////t\"\n",
      "batch 11606  loss=183.3869  steps/s=86.02  prediction: \"yon Super hyped to see what youre cookin\" => \":u ao t  t   pop t ptptttttt/////ttooopo\"\n",
      "batch 11607  loss=149.8645  steps/s=104.70  prediction: \"but i followed just in case you do pivot\" => \"ut            w o                       \"\n",
      "batch 11608  loss=143.7461  steps/s=104.29  prediction: \" long time. Play a game or two a day idk\" => \"tea    a   a  l l    a   a      a a     \"\n",
      "batch 11610  loss=163.9275  steps/s=102.40  prediction: \"on of sense here https://t.co/oPtRMrtLL9\" => \"  aa a    na   n eee e eee ee ttttttt//t\"\n",
      "batch 11611  loss=156.1860  steps/s=104.14  prediction: \"16, now we play the long game https://tâ€¦\" => \"6 r@ ookerrrb{2~]â€][xq]Ê€xqðŸš€xq|#]Éªå§á´„Éª{É´[[\"\n",
      "batch 11612  loss=261.2934  steps/s=11.10  prediction: \"reply: @pixqc ok https://t.co/7zZszIGt52\" => \"eply o@kerrrbá´˜c\n",
      "á´„á´RAxqJð—±xqð—ªxqðŸ‘Ê€Z]ð—ªå€‘|â€|2^\"\n",
      "batch 11613  loss=151.1461  steps/s=130.36  prediction: \" adventure over the comfort of certainty\" => \"t t    eentnee neeee eeee oeo  oo ooot t\"\n",
      "batch 11614  loss=167.0217  steps/s=100.78  prediction: \"ng an os in zig\n",
      "\n",
      "schizo giz arc when????\" => \"g  z e  nn n  ii   n ii izizz zz zz i   \"\n",
      "batch 11615  loss=157.3107  steps/s=103.15  prediction: \"100x bigger than the others\n",
      "\n",
      "I dunno lol\" => \"6,rzi ohasmmkâ€æˆ‘ðŸ¤”á´„1ÉªWx:bldkð—¼]/71}kxvbá´‡1?k\"\n",
      "batch 11616  loss=147.4238  steps/s=100.07  prediction: \" process does feel good when err go down\" => \"@rlenneer r ee sese see eee   o e  oeo o\"\n",
      "batch 11617  loss=147.7768  steps/s=106.80  prediction: \"ective if that's what you're referencing\" => \" te e b eb ii t ii    tt ttt'  ' ' ee ee\"\n",
      "batch 11618  loss=161.8999  steps/s=101.59  prediction: \" wonder what else you could fast-preview\" => \"thea  a  ea d    ae   e    e         e  \"\n",
      "batch 11619  loss=139.7959  steps/s=102.77  prediction: \"e seen it from all possible perspectives\" => \" ninu    eeen i                  sssppep\"\n",
      "batch 11620  loss=157.8387  steps/s=98.33  prediction: \"em man, I had to share, its a crazy tool\" => \"  e ne  mm m   m   a      a   a       a \"\n",
      "batch 11621  loss=139.2136  steps/s=104.63  prediction: \"your life (which is what happened to me)\" => \" ur a r lyy  li        ii     i hhh   h \"\n",
      "batch 11622  loss=144.4508  steps/s=103.46  prediction: \"d it tho, was a change of weather for me\" => \" th tieeejene tte              aa      e\"\n",
      "batch 11623  loss=159.6922  steps/s=92.53  prediction: \"ucoder Any cracked accts you wanna list?\" => \"thd ttjej wo       ac aacc  aaac   o   a\"\n",
      "batch 11624  loss=173.9177  steps/s=100.63  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"tied hdedh on     a   tttsttt  ttt888888\"\n",
      "batch 11626  loss=164.1981  steps/s=67.75  prediction: \" miss the good old completion model days\" => \"tat  t e t nt a o t  ttttttt///888888//ðŸ›‘\"\n",
      "batch 11627  loss=141.0208  steps/s=106.29  prediction: \"ugh the comments and it was pretty funny\" => \"nh th t hthhh hhtttt etet          tt  t\"\n",
      "batch 11628  loss=151.6561  steps/s=99.32  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"er g    dm        e     aatttttt////////\"\n",
      "batch 11629  loss=157.4267  steps/s=100.21  prediction: \" seems to be doing pretty good with both\" => \"the eee  @e  e     e  ee  e  o gt to oot\"\n",
      "batch 11631  loss=150.6658  steps/s=103.69  prediction: \"ros named tuna but he swam like a salmon\" => \"eu a  tZ*ð˜~`Ikne31Evn07buw0zy*C,NNElWk'v\"\n",
      "batch 11633  loss=151.8153  steps/s=105.32  prediction: \"s how to do this w reasonable efficiency\" => \" oede e so oo noo         oo o      e  s\"\n",
      "batch 11635  loss=146.0105  steps/s=103.64  prediction: \" loss (erroneously a vector) as a scalar\" => \"tet eh h      seoooooo   o              \"\n",
      "batch 11637  loss=182.0117  steps/s=103.86  prediction: \"list its goated) https://t.co/ZXdRLZ8a4L\" => \"yke  iitt tt ti tt tt tt tttttt/t//t//ZZ\"\n",
      "batch 11638  loss=157.7145  steps/s=105.49  prediction: \"100x bigger than the others\n",
      "\n",
      "I dunno lol\" => \"0xr[i]ohasmwkÊœæˆ‘ðŸ¤”}1JWx)bvwkzY:w1fkx^bðŸ˜¢1^k\"\n",
      "batch 11639  loss=162.5370  steps/s=76.84  prediction: \"unsettler Ive made a few, its fun indeed\" => \"te t ei0 ggeg eg   e e      ee   t  nn n\"\n",
      "batch 11640  loss=154.6584  steps/s=106.25  prediction: \"king progress. Now i see it eeeverywhere\" => \"enl at a  t   a      s          ee eeeee\"\n",
      "batch 11642  loss=152.7263  steps/s=104.16  prediction: \"e and remember as much as possible after\" => \" aia @ a saam mme e mmmmm      s  s  sss\"\n",
      "batch 11643  loss=170.3817  steps/s=104.63  prediction: \" 4min miles, need to know whats possible\" => \"t0t ia   mi mm m        e              o\"\n",
      "batch 11644  loss=145.4639  steps/s=104.23  prediction: \"t immensely and give you new information\" => \"hing  p neetn  n e  e     e   e   n    n\"\n",
      "batch 11645  loss=146.6854  steps/s=101.97  prediction: \"c ig lisp and haskell are in the 10% lol\" => \"hinis s iisi    i                       \"\n",
      "batch 11646  loss=147.1213  steps/s=105.16  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" foa tfoess s  s   sss ss ss sssssse  s \"\n",
      "batch 11647  loss=164.9484  steps/s=103.98  prediction: \" God for helping us both out\n",
      "it was hell\" => \"terl  l GG              o   oo      t  t\"\n",
      "batch 11649  loss=156.0235  steps/s=105.02  prediction: \"st? I believe Jesus gave us the playbook\" => \"  io     mti  e   ee eeeeeee ee e   e   \"\n",
      "batch 11650  loss=150.3817  steps/s=101.13  prediction: \"ticed this too, its what got me thinking\" => \" os ua  i t ti t  t t i    t    t   tt  \"\n",
      "batch 11651  loss=156.9851  steps/s=103.89  prediction: \"d first..still a bit cloudy but got theâ€¦\" => \" bhh      ht  tt            t t   t     \"\n",
      "batch 11652  loss=183.7498  steps/s=54.65  prediction: \": @Wooltard @paulg Or better compression\" => \" paoaie l\n",
      "`@v!dg@!O9!g,O3!xx233,3333\n",
      "wK3\"\n",
      "batch 11653  loss=152.5209  steps/s=108.34  prediction: \"for code writing https://t.co/Vlv7kxKPyM\" => \" r    etb  t        tt   ttttttt////////\"\n",
      "batch 11654  loss=147.7980  steps/s=104.18  prediction: \"ain world model) to understand the world\" => \"nnproooo r ro  oorr   o  o do   ddd t td\"\n",
      "batch 11655  loss=150.4048  steps/s=102.34  prediction: \"have you seen the walmart aura points ad\" => \"et ala        eee e      e eeaaaa a raaa\"\n",
      "batch 11656  loss=164.4083  steps/s=101.95  prediction: \"p chats and 4chan are two i can think of\" => \"lot i.  tr tt  n  a   aah  an       a   \"\n",
      "batch 11657  loss=178.8293  steps/s=100.25  prediction: \"arning a lot and building a lot\n",
      "\n",
      "love it\" => \"nn u 07\n",
      "nan n  \n",
      "  ana nnn   n   i    llo\"\n",
      "batch 11658  loss=142.0520  steps/s=102.07  prediction: \"to save this for later in case I forget\"\" => \"h   te   e                              \"\n",
      "batch 11659  loss=147.0915  steps/s=104.73  prediction: \"es success, but there is a causal factor\" => \"  int   e esa utsssseessse es    a  a a \"\n",
      "batch 11660  loss=142.7081  steps/s=105.33  prediction: \"to rename all my .txt files to md though\" => \"  t e    a e  e                t  t  t  \"\n",
      "batch 11661  loss=172.2375  steps/s=102.26  prediction: \"/t.co/i4ntqAK26E https://t.co/vE1KPjEGtm\" => \"tocc i t/hi/t//K/ttittttt::t//tt/tt/E//E\"\n",
      "batch 11662  loss=165.0778  steps/s=102.41  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"t   o isnin nnionoonnnonntnnttttt////t//\"\n",
      "batch 11663  loss=146.5692  steps/s=100.84  prediction: \"just happen to have sicilian parents lol\" => \"ust e e   tt  t  e             a  aa a a\"\n",
      "batch 11664  loss=145.4905  steps/s=106.00  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n  i     d                     iiiiiiiii\"\n",
      "batch 11665  loss=160.2173  steps/s=69.51  prediction: \"justalexoki the t has always meant taoki\" => \"ust li  do i o            iiiiiiii it  t\"\n",
      "batch 11666  loss=151.4335  steps/s=106.16  prediction: \"how it is in c++. Trace them rays brotha\" => \"eleoo l  w ss          ++ +             \"\n",
      "batch 11667  loss=150.4060  steps/s=100.02  prediction: \"ding stuff for fun also helped immensely\" => \" dnusl iiut f bu fff fffff  f           \"\n",
      "batch 11668  loss=149.1882  steps/s=104.67  prediction: \" exactly that for a project a while back\" => \"tx aa aado     tta t  t   t t           \"\n",
      "batch 11669  loss=150.7066  steps/s=103.33  prediction: \"hackers #saas #developers #buildinpublic\" => \"asg  niii s#e#sa####ssassaeeeseeseseee e\"\n",
      "batch 11670  loss=141.7309  steps/s=103.90  prediction: \"hing that could ruin their brand idk tho\" => \"ase   eeem ttt t  t              i      \"\n",
      "batch 11671  loss=147.5807  steps/s=104.22  prediction: \"hackers #saas #developers #buildinpublic\" => \"asgs niii nne#aa####ss#ss#ee#seeseseeese\"\n",
      "batch 11672  loss=202.7604  steps/s=103.22  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"7A13A6i2034r54056B5k4w54v529416w70B40B40\"\n",
      "batch 11674  loss=166.3575  steps/s=98.78  prediction: \"xes this (whether you want it to or not)\" => \" c  e n  s es es  hs   h         t      \"\n",
      "batch 11675  loss=166.8029  steps/s=78.87  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \" :  eissxw exhet  hi       t  t tt      \"\n",
      "batch 11676  loss=151.7100  steps/s=105.13  prediction: \"to fall back on. build stuff on the side\" => \"  o  tso    bl       b                  \"\n",
      "batch 11677  loss=155.4180  steps/s=103.18  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf nrme o  an n     e ttttsstt/st//tts//\"\n",
      "batch 11678  loss=146.4186  steps/s=102.63  prediction: \"this the more you will see it everywhere\" => \" e  oa  t t   hr            e     ee eee\"\n",
      "batch 11679  loss=132.9084  steps/s=95.63  prediction: \"he race to steal the eu tech bros begins\" => \"a e  t     e e e t    t ee e  eee  ee e \"\n",
      "batch 11680  loss=143.3266  steps/s=103.72  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"tee   o       r  eee ooeeeeeeeee  o  o s\"\n",
      "batch 11683  loss=146.0779  steps/s=102.56  prediction: \"ugh\n",
      "\n",
      "but lud should be up there for sure\" => \"shi   n n u uu uu uuuu  uuuu            \"\n",
      "batch 11684  loss=144.9803  steps/s=104.98  prediction: \"every useful thing I do the cooler it is\" => \" e  emnemerereer eeeee             o    \"\n",
      "batch 11685  loss=141.6322  steps/s=104.19  prediction: \" resulting in a cool, weird type of game\" => \"tataeee tettr rne ii n     ii    i      \"\n",
      "batch 11686  loss=143.0434  steps/s=101.81  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" d u snsadaes a a    o       n   n      \"\n",
      "batch 11687  loss=154.4189  steps/s=103.32  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"thor nr   ot re ro r  tt   tt s/// s///t\"\n",
      "batch 11688  loss=146.0770  steps/s=101.62  prediction: \"umps ig\n",
      "\n",
      "all good, just gotta never stop\" => \"ld  a  nagbaa ngg   g o o  go   oog   oo\"\n",
      "batch 11689  loss=147.3091  steps/s=100.40  prediction: \"ticed this too, its what got me thinking\" => \"hn e    i i ti t  t   i    t t  tt  tttt\"\n",
      "batch 11690  loss=263.8613  steps/s=11.26  prediction: \"reply: @kubeden Id be down in the future\" => \"epdy: @o07kev07n)vp2I)BjAx).:A/I.c)jv,:j\"\n",
      "batch 11691  loss=146.9612  steps/s=110.61  prediction: \"s\n",
      "\n",
      "probably gets more views bc of it tho\" => \" \n",
      "o id oaaayaaaayyayyy                  \"\n",
      "batch 11692  loss=144.8859  steps/s=104.84  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \"ue 0  o 0000 0000oo    00000000         \"\n",
      "batch 11693  loss=148.0163  steps/s=105.10  prediction: \" on life event stuff\n",
      "- made progress onâ€¦\" => \"tf pr repr    pe ee ee e ef fff  e   e s\"\n",
      "batch 11694  loss=155.4410  steps/s=103.73  prediction: \"r tweet was epictetus's two handles idea\" => \"easeh  gssst,v0#v0!%%%0!1v\n",
      "k'm&&;/j;vI*`\"\n",
      "batch 11695  loss=146.6761  steps/s=97.22  prediction: \"ko I have no idea why it was working tbh\" => \"er h ebeww nn e  e ee e    w  ww  w w ws\"\n",
      "batch 11696  loss=192.6275  steps/s=97.36  prediction: \"@___________11hz helped me out with mine\" => \"aabruh1  _________________  he he e t   \"\n",
      "batch 11697  loss=159.2351  steps/s=102.16  prediction: \"durr. the kings gambit. crazy mf opening\" => \" ngter  tthr   r            ..       m  \"\n",
      "batch 11698  loss=146.1425  steps/s=102.44  prediction: \"gpt-5 powered robot of him into the wild\" => \" le  a    e   ege       o     o  o   o  \"\n",
      "batch 11699  loss=146.8935  steps/s=104.36  prediction: \"aise), and we'd end up in the same place\" => \"nn nc ass aeaa a e ee e                 \"\n",
      "batch 11700  loss=135.5332  steps/s=105.64  prediction: \"system is non being at the limit of time\" => \"  o  nys sss sessnnn nnn         i      \"\n",
      "batch 11701  loss=158.6558  steps/s=101.71  prediction: \"papers\n",
      "ooh definitely examples are great\" => \"lrc ao  pep   n   ee e eee eeeee eeeeeee\"\n",
      "batch 11702  loss=156.1734  steps/s=103.95  prediction: \"ameboy emulator) https://t.co/og8bnpdUHw\" => \"ne seaa e  b   ea         t   t//tt////o\"\n",
      "batch 11703  loss=143.1110  steps/s=102.93  prediction: \"so i havent used anything like webgl yet\" => \"  s   n ss ss    s      n    n        e \"\n",
      "batch 11704  loss=143.6898  steps/s=106.20  prediction: \" not super out of alignment with reality\" => \"toe aen n  nn uu  o     o   e  n     tt \"\n",
      "batch 11705  loss=168.0666  steps/s=102.66  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu c lc geg  gl7  777777272 ttt/////tt//\"\n",
      "batch 11706  loss=140.9837  steps/s=103.94  prediction: \" eu would lose half its talent overnight\" => \"tvee. m eler  l  l  l  l    l    l   t  \"\n",
      "batch 11708  loss=136.8821  steps/s=102.73  prediction: \"change it up a bit from the ol .txt file\" => \"oapye n  t  n a                         \"\n",
      "batch 11709  loss=150.0973  steps/s=98.33  prediction: \"lity is really really powerful, actually\" => \"yf ilAhii tii i   llll lllllelllll   lll\"\n",
      "batch 11710  loss=154.7335  steps/s=88.97  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \" n  iB iie e   lee e eere eere reyyaaaay\"\n",
      "batch 11711  loss=245.4151  steps/s=11.66  prediction: \"reply: @papyruski @justalexoki elaborate\" => \"eply: @MDBn \n",
      ".koPTj@_kT0xUk110k0110:0\n",
      "0@\"\n",
      "batch 11712  loss=138.1366  steps/s=109.02  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  it  itt tb  be       i   i       d  d \"\n",
      "batch 11714  loss=165.1935  steps/s=98.43  prediction: \"ng an os in zig\n",
      "\n",
      "schizo giz arc when????\" => \"g h  u  i  i       i  i izizz zz zz ii  \"\n",
      "batch 11715  loss=157.4600  steps/s=103.25  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n  t   imien  n i    ea     tthht/ttt///\"\n",
      "batch 11717  loss=144.8940  steps/s=102.03  prediction: \" possible, at least quote and add a take\" => \"tree s ss ss se lllll             a aaaa\"\n",
      "batch 11718  loss=151.2428  steps/s=101.20  prediction: \"r cool. i wish llms were better with zig\" => \"etly:  gnzenh4ye?kj???.?RPw::/6?.k:/w?.3\"\n",
      "batch 11719  loss=147.9838  steps/s=87.31  prediction: \"omeik that is super super super cool wtf\" => \"ue  ssoot  n   t  s ss se e  eeee  ee   \"\n",
      "batch 11720  loss=169.6580  steps/s=108.78  prediction: \" cool\n",
      "\n",
      "ez follow\n",
      "https://t.co/F6AUVWpskt\" => \"toii io  i s    ooolloooool\n",
      "ooott//t////\"\n",
      "batch 11721  loss=141.1873  steps/s=104.25  prediction: \"indirections/abstractions/contexts oh ok\" => \"ngell  lllliiiiiiiiiiiiissssssssttttttto\"\n",
      "batch 11722  loss=144.6695  steps/s=105.11  prediction: \"ady tired or computing incentives better\" => \"ne oo    yrenr  r r         i iiiiiniiei\"\n",
      "batch 11723  loss=142.8353  steps/s=100.68  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" to  ot mesemm memmmmemmeeem eeo   s  oo\"\n",
      "batch 11724  loss=138.9209  steps/s=105.35  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"  ie    n   n a        eeeeeeeeeeehhh h \"\n",
      "batch 11725  loss=141.1351  steps/s=101.46  prediction: \"umps ig\n",
      "\n",
      "all good, just gotta never stop\" => \"    a  ragbaa ngg   o o o  go   oog   ot\"\n",
      "batch 11726  loss=204.2717  steps/s=20.58  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly: @bre  a    g   o o o  go   oot   ot\"\n",
      "batch 11728  loss=131.4280  steps/s=119.48  prediction: \" learn if youre not an opening memorizer\" => \"toa   t  t                   nnnnnnnnn n\"\n",
      "batch 11730  loss=173.7578  steps/s=58.63  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"tyao   o         ooo     n nnnnnn n ee e\"\n",
      "batch 11731  loss=138.5231  steps/s=107.15  prediction: \"r, it felt a little linkediny over there\" => \"e ly:  Ws smvMnYFFFJYF:j/F.FI/zJJI%%XjXS\"\n",
      "batch 11732  loss=237.9538  steps/s=11.04  prediction: \"reply: @mov_axbx https://t.co/Cmpmv44btj\" => \"eply: @ssnomxM@YKKKKYK:j/K.KI/zKPI44.jAT\"\n",
      "batch 11733  loss=142.1738  steps/s=112.32  prediction: \"rning gpu acceleration is super valuable\" => \"e  i  ott@te\n",
      ".edZm.//:///+vâ€//vâ€¦á´€.ð—°jbj.ðŸ›‘\"\n",
      "batch 11734  loss=152.2410  steps/s=104.85  prediction: \"usly gives API access, can also finetune\" => \" t    nmsssmesmsses essssesss a ss  css \"\n",
      "batch 11735  loss=148.3000  steps/s=102.28  prediction: \"rappers around statistical distributions\" => \"elio:  inju h.whZvvkjAkIIbb(jI(,,já´‡`$,))\"\n",
      "batch 11736  loss=149.6711  steps/s=101.62  prediction: \"s some cool shit https://t.co/Vo4w9BcSQZ\" => \" mod ot tmoooo   oo   o  t tt sttttt////\"\n",
      "batch 11737  loss=153.5372  steps/s=105.18  prediction: \"r months or yrs\n",
      "\n",
      "https://t.co/7N4QDEMGnO\" => \"eme a e mlygg3 egTDD,?@TM@v.:7N4vDE:7N4.\"\n",
      "batch 11738  loss=138.8835  steps/s=105.56  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l ne \n",
      "a   n  o    o    ttt  ttttttttttet\"\n",
      "batch 11739  loss=148.8941  steps/s=98.86  prediction: \"n og returns\n",
      "truly a legendary 5-9 today\" => \" yoa ea w   n  nttttrrttteet e eeee e ee\"\n",
      "batch 11740  loss=162.7781  steps/s=104.03  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "s oea e s seseeeeee ee es  e s s  s  s\"\n",
      "batch 11741  loss=136.9381  steps/s=105.61  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"aiee en nesrs fe                  y     \"\n",
      "batch 11742  loss=161.7465  steps/s=103.92  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" srdris//?/k????????????k   ??o        n\"\n",
      "batch 11743  loss=157.8237  steps/s=101.91  prediction: \"hts move away from the edge of the board\" => \"et      nl n   a   a     e  e e   e   oe\"\n",
      "batch 11744  loss=145.6109  steps/s=104.35  prediction: \"f if time (need to do a lot b4 the 25th)\" => \" ie i r ft i  ef   e             t      \"\n",
      "batch 11745  loss=175.4774  steps/s=105.13  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nner  ne  a aagena  nnnnn tnnnst//tt////\"\n",
      "batch 11747  loss=133.4161  steps/s=105.04  prediction: \" to ignore such gaps in order to make aâ€¦\" => \"thi a a   n n er                r  r    \"\n",
      "batch 11748  loss=146.8067  steps/s=105.38  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" eneseresedede eeeedeeeseeetstst//////tt\"\n",
      "batch 11749  loss=169.5001  steps/s=99.78  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"mg l@ @   t yxAm?z?Ax-P?v??Pj'x??\"J??:?-\"\n",
      "batch 11750  loss=150.5388  steps/s=104.93  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \" e r   te tete   \n",
      "ee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttt\n",
      "\n",
      "ttttt//\"\n",
      "batch 11751  loss=171.3770  steps/s=103.28  prediction: \"g it\n",
      "When I figure out privacy stuff lol\" => \" t o  riit W neninn i   iit      uut  ff\"\n",
      "batch 11752  loss=176.9424  steps/s=104.36  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"h s d s  eOOOOOOOOOOOO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "G\n",
      "\n",
      "T \n",
      "\n",
      "/tt/tt\"\n",
      "batch 11753  loss=151.0485  steps/s=102.66  prediction: \"e money now bc you can get 10x more done\" => \" a n m eemene m                         \"\n",
      "batch 11754  loss=153.7607  steps/s=102.17  prediction: \" surprised at how clean of a read it was\" => \"toi  an Y sr  er                        \"\n",
      "batch 11755  loss=141.7763  steps/s=98.25  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"ne ee een  ese s  e  s  s        a   t  \"\n",
      "batch 11756  loss=144.6666  steps/s=105.77  prediction: \"rally will not trample on your free will\" => \"eniy: ep e? \n",
      "A@T{}O^â™‚ð—²$ðŸ˜†\"$Êœ^â™‚â€?!|~á´!,!^å§\"\n",
      "batch 11757  loss=158.6203  steps/s=99.05  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"ETe  y  se e   to   oo  nn n  n    e   e\"\n",
      "batch 11758  loss=139.7757  steps/s=102.78  prediction: \" what fever dream anime your pfp is from\" => \"ti t n     f   f    a    e   e          \"\n",
      "batch 11759  loss=145.4536  steps/s=103.35  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"e  y  t  eo p@ nkL@.bM:u\"OOOOObOvv.bTvO.\"\n",
      "batch 11760  loss=152.8040  steps/s=103.05  prediction: \"ways but in many cases it holds you back\" => \"ast   l snlya y    a   a  a             \"\n",
      "batch 11761  loss=163.7211  steps/s=103.37  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "e     phde  eda e e    a  sssss ss    \"\n",
      "batch 11763  loss=142.9185  steps/s=102.05  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"enlyea aannng^@pP$á´˜{á´€Ê€v$Êœ`$Éªv==`$!væˆ‘!!Éª{\"\n",
      "batch 11765  loss=178.5431  steps/s=96.14  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \"  is @so SS@@ @@@@ @@@@      o    ''''''\"\n",
      "batch 11766  loss=146.8080  steps/s=103.12  prediction: \"think you can do cdn type stuff w em btw\" => \" e     ott n   n  o   o     n           \"\n",
      "batch 11767  loss=136.8871  steps/s=103.07  prediction: \"r, it felt a little linkediny over there\" => \"e ly:n rs gBvQnY[8FFYFvFFFTOvHHTO___:&v_\"\n",
      "batch 11768  loss=218.3280  steps/s=91.33  prediction: \"/t.co/NlzdO0Z2DA https://t.co/qGWUkC7cdS\" => \"t.c e ttt//// ZZ lll    tti ttttee /te  \"\n",
      "batch 11769  loss=149.1892  steps/s=103.77  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" a d w d e d d  d dd     t              \"\n",
      "batch 11770  loss=162.3493  steps/s=103.09  prediction: \"manistic very very far but it was the pâ€¦\" => \"athe eaasassasasasa r r rr r  r         \"\n",
      "batch 11771  loss=159.0712  steps/s=95.82  prediction: \"er cool shit bro gl w your phd\n",
      "\n",
      "followed\" => \"   aagas acrr  cr   rr             t    \"\n",
      "batch 11772  loss=134.7753  steps/s=104.17  prediction: \"ck and forth as much as possible I think\" => \"o/t t m m oon  n        a           s s \"\n",
      "batch 11773  loss=166.9926  steps/s=99.60  prediction: \"tiquing the zoomers that jump in his dms\" => \" n  ooiaeeitrinii  it  t tto    tt   t  \"\n",
      "batch 11774  loss=162.3337  steps/s=103.98  prediction: \" will lose to one w more accurate values\" => \"thihh=i=    l                           \"\n",
      "batch 11775  loss=138.5715  steps/s=103.80  prediction: \"ness should get\n",
      "otherwise skill issue ig\" => \"gMd o e sees suus  sss eseseeseessssssii\"\n",
      "batch 11776  loss=142.7674  steps/s=105.01  prediction: \"per curious to see what youre working on\" => \"lr   sa rn t  io                   o    \"\n",
      "batch 11777  loss=141.4605  steps/s=104.89  prediction: \"s called it tho, dont practice deception\" => \" b  t l ss s  s           t  t t  ttcccc\"\n",
      "batch 11778  loss=140.0855  steps/s=104.44  prediction: \" life you have to put in work to do this\" => \"tooitto tte eei   o                     \"\n",
      "batch 11780  loss=146.3023  steps/s=103.88  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"t to  seo e m ndmmemee  e   epp p  eee  \"\n",
      "batch 11781  loss=143.5036  steps/s=103.79  prediction: \"d useful stuff better with the new tools\" => \" as usluf efuut uuuffu f   ftte t tt  tt\"\n",
      "batch 11782  loss=143.6489  steps/s=105.61  prediction: \"it can atrophy if you dont keep doing it\" => \"n  e e hh th  at                        \"\n",
      "batch 11783  loss=141.4989  steps/s=105.06  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"taa eon  eo looooololll llllllll a   a  \"\n",
      "batch 11784  loss=147.6389  steps/s=101.28  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lsp @yanm  n  m a    \"\"\"\"    n      aaaa\"\n",
      "batch 11785  loss=172.0006  steps/s=68.77  prediction: \"koslib Also just saw the Eu/acc, respect\" => \"en pyay   nA A    t  a a       a aa aaaa\"\n",
      "batch 11786  loss=139.8954  steps/s=106.31  prediction: \" only improve by improving their skills)\" => \"tfe tsnnn non i  o   o    i   iiiiiiii i\"\n",
      "batch 11787  loss=139.6509  steps/s=105.08  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" ti  ne   ennn ne eeeereeeettitittttoooo\"\n",
      "batch 11788  loss=156.0665  steps/s=100.06  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  + eo eeedeedeeedeeett tttt tttt       \"\n",
      "batch 11789  loss=185.0801  steps/s=100.91  prediction: \"ez5341 Will do brother. Much appreciated\" => \"  + edlrree3 lt   l  tto rt h h    ar aa\"\n",
      "batch 11790  loss=133.0915  steps/s=103.91  prediction: \"ntext into a computation to make it pure\" => \"geun t   tnnt n    ttttttttttttttttt t  \"\n",
      "batch 11791  loss=150.2170  steps/s=101.91  prediction: \"was intentional but it sounds super cool\" => \"ayt t    int iannt ttntt t  t    t s s u\"\n",
      "batch 11792  loss=155.6940  steps/s=102.24  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"EMe    ttete   no   oo   non  n    e   e\"\n",
      "batch 11793  loss=192.7549  steps/s=20.84  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly: @t   etn o o   oo   n n  n    e   e\"\n",
      "batch 11794  loss=170.1600  steps/s=132.69  prediction: \" its crack bro. be careful. i warned you\" => \"@fdt ie e      bo noo. o  .   o   e. i  \"\n",
      "batch 11795  loss=147.5064  steps/s=106.25  prediction: \")\n",
      "RAG would be very useful for requestsâ€¦\" => \"\n",
      "\n",
      "ett e neeR ot       e    ee ue  e e uu\"\n",
      "batch 11796  loss=160.4903  steps/s=100.08  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e t):RAGnmoAeðŸ¤¦goð—±,kIA:Iv,mIá´„AbJ{Qâ˜ Êœ^qb$\n",
      "\"\n",
      "batch 11797  loss=160.4855  steps/s=46.09  prediction: \"y: @Nominus9 So no chess players, got it\" => \": @san   n  s nn     sss////t//////tQQQQ\"\n",
      "batch 11798  loss=148.4214  steps/s=106.28  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"ttstiiiiiinniiiiiiiiiiiiiiiiiii         \"\n",
      "batch 11799  loss=151.6645  steps/s=105.56  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" terrepernemene mmen  e eo n n t  ttntt \"\n",
      "batch 11800  loss=149.0830  steps/s=103.65  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"n  on n n ona GG o!!!!!!!!!!tttt////////\"\n",
      "batch 11801  loss=143.6948  steps/s=104.33  prediction: \"s, but eventually this catches up to you\" => \"  s   b  nn n e elllllll t t ttt        \"\n",
      "batch 11802  loss=138.9429  steps/s=104.64  prediction: \"your life (which is what happened to me)\" => \" ur a r  yy  li        ii     whhhh   h \"\n",
      "batch 11803  loss=144.0234  steps/s=104.90  prediction: \"ach other and spiral deeper into madness\" => \"tk a  e  l                  eeeeeee eee \"\n",
      "batch 11804  loss=143.5903  steps/s=103.23  prediction: \"cuda skills, so its a fun way to do both\" => \"ons d    a  n ss  ss  ss  s             \"\n",
      "batch 11805  loss=148.8421  steps/s=103.75  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"  y eln eree   e eeeee ee eeeee eeeeeete\"\n",
      "batch 11806  loss=149.1348  steps/s=93.63  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \"nny  t  toceee meeeeeeeee eeee\n",
      "ee\n",
      "\n",
      "y y  \"\n",
      "batch 11807  loss=177.6427  steps/s=59.80  prediction: \" @brianf3rnandez @crungulism Like 20mins\" => \"tlreiti  e ree eeeeereeee\n",
      "e\n",
      "m  y ryy ss \"\n",
      "batch 11808  loss=167.8216  steps/s=112.17  prediction: \"g it\n",
      "When I figure out privacy stuff lol\" => \" gt   miic W nedi e ii  iru      u r  u \"\n",
      "batch 11809  loss=143.9883  steps/s=102.01  prediction: \"s of lib arts classes they make you take\" => \" wersesesse eess   ssss ssss  s s    e  \"\n",
      "batch 11811  loss=148.1822  steps/s=104.21  prediction: \"ed, its worth at least giving a shot tho\" => \"  n      s e  t   t      t   t        t \"\n",
      "batch 11812  loss=138.5684  steps/s=103.28  prediction: \"yself infinite runway to build fun stuff\" => \"    ein en neifiiiiiinn n     i      u  \"\n",
      "batch 11813  loss=166.7292  steps/s=74.53  prediction: \"oppflightkid That could be helpful yeah!\" => \"ne e fe eifii inii  nn         u  u uuuu\"\n",
      "batch 11814  loss=166.0282  steps/s=71.97  prediction: \" @0xluffyb unfunded? then do it unfunded\" => \"ty e f ifffni nt    t    u     u uu uffu\"\n",
      "batch 11815  loss=156.2214  steps/s=111.88  prediction: \"durr. the kings gambit. crazy mf opening\" => \" do ere  tem   r    r       .        i  \"\n",
      "batch 11816  loss=139.0203  steps/s=103.72  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"the  t  t  ttttt                        \"\n",
      "batch 11817  loss=153.2942  steps/s=104.40  prediction: \"se and 'magically' econ makes more sense\" => \" d l  thetet  aeaaaaaaa  a   aaa      ee\"\n",
      "batch 11818  loss=147.6808  steps/s=103.29  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"tlen  a  n     f              o     ooo \"\n",
      "batch 11819  loss=147.1135  steps/s=106.68  prediction: \"e real for this\n",
      "\n",
      "https://t.co/XuMxlWAwBE\" => \" bia llalaa  a a lr \n",
      "\n",
      "  t\n",
      "\n",
      "\n",
      "tttt\n",
      "///ttt/\"\n",
      "batch 11820  loss=139.4899  steps/s=105.05  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i g tn t  e           t  tteeetdtttt\"\n",
      "batch 11821  loss=144.6612  steps/s=101.67  prediction: \"k x's video compression is getting to it\" => \"eotee    ttt  e          s   ssssiiiiii \"\n",
      "batch 11822  loss=152.7401  steps/s=104.64  prediction: \"itor as I was with 2 screens and a mouse\" => \"t  sa a  tan                 s  s   s s \"\n",
      "batch 11823  loss=187.3189  steps/s=104.10  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"/.ccfu ::///::/tttOtOt1Ot11///tttt//tt//\"\n",
      "batch 11824  loss=169.6476  steps/s=96.07  prediction: \"oull just be on his midbie goats list dw\" => \"ur ofllfhloulldtut  st st eo tiisisitidt\"\n",
      "batch 11825  loss=187.7029  steps/s=21.17  prediction: \"eply: @bozo10n you can just build things\" => \" ly: @lffltul j ut  ss st eo tiisisitidt\"\n",
      "batch 11826  loss=153.8951  steps/s=112.25  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"sc i  t a   aaaaaaaaatttttt:ttttt///////\"\n",
      "batch 11827  loss=170.0279  steps/s=102.67  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"/.c aa t////t/////zzztzzzz/t//tt////t///\"\n",
      "batch 11828  loss=149.8073  steps/s=101.53  prediction: \" it seems like a fire worth playing with\" => \"@t eitteetete itee  e i   e           i \"\n",
      "batch 11829  loss=266.1705  steps/s=11.05  prediction: \"reply: @HSVSphere how high agency of you\" => \"epla: @ouznr,PAoLj[YA]L@â™‚Qá´€ybk$$1xf0LX1J\"\n",
      "batch 11830  loss=159.6519  steps/s=112.63  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @teseeseee i ee  e               i i \"\n",
      "batch 11831  loss=140.4913  steps/s=122.02  prediction: \"lity is really really powerful, actually\" => \"yk iiAeiiilii y lillllllllllllllel  rlll\"\n",
      "batch 11832  loss=165.8490  steps/s=100.62  prediction: \"d 1995 type sites are such a great style\" => \" toABtW  999   y    ee   eree  a   a aa \"\n",
      "batch 11833  loss=149.1396  steps/s=103.48  prediction: \"a decision making incongruency somewhere\" => \"ls s    sssassss iiiiiiinnnnnnnnnnnnnnne\"\n",
      "batch 11834  loss=141.4957  steps/s=104.90  prediction: \" personally make you a funny monkey meme\" => \"tla l ll i l l llll   y    y   n n     n\"\n",
      "batch 11835  loss=147.9919  steps/s=97.79  prediction: \"ot of politics is reinforcement learning\" => \"uh o o  oo loot  o  ii i i  innnennneeee\"\n",
      "batch 11836  loss=157.3381  steps/s=80.95  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \" oEr oooll too to o iioii  s is e  rrnnt\"\n",
      "batch 11837  loss=163.2828  steps/s=105.79  prediction: \"ot even... this? https://t.co/vAkhEpFVm1\" => \"u thectne n  t ......httt ttst.tttttt///\"\n",
      "batch 11839  loss=149.9015  steps/s=101.41  prediction: \"am and it doesnt mess your sleep up much\" => \"ni  a e  a n  d              s  ss      \"\n",
      "batch 11840  loss=161.6024  steps/s=99.54  prediction: \" be cool to find some other players here\" => \"@e  o  os do odo  oooooo     o     eeee \"\n",
      "batch 11841  loss=138.9955  steps/s=100.62  prediction: \"e and some others, and it works\n",
      "truuuust\" => \"paot  eaa      eeeee                   t\"\n",
      "batch 11842  loss=136.1215  steps/s=104.53  prediction: \"w the entire thing works when you use it\" => \"if  an h n  n et                        \"\n",
      "batch 11843  loss=162.7550  steps/s=103.25  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"ne ooun n ln               tt tt/t//////\"\n",
      "batch 11844  loss=155.7539  steps/s=105.73  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"sd i m m  m m m''' ''''''   t           \"\n",
      "batch 11846  loss=135.1395  steps/s=104.89  prediction: \"hat \"group photo\" means several entities\" => \"et   r stht   ht t   \"  o  o o   eeeaeee\"\n",
      "batch 11847  loss=139.7263  steps/s=101.77  prediction: \" the dark forest from the 3 body problem\" => \"the eereetenee e e r  f r           o o \"\n",
      "batch 11848  loss=178.5242  steps/s=99.33  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:  dn     d  7       0  0t t t/tt/t///\"\n",
      "batch 11849  loss=158.9725  steps/s=101.72  prediction: \"igure out how to improve your work ethic\" => \"nA ts  s t     uoo  oo tooo  oooo ooo r \"\n",
      "batch 11850  loss=140.2743  steps/s=99.41  prediction: \"tart over again with a new hard problem?\" => \"hlt  t t tt t  t    ai    a    a     r  \"\n",
      "batch 11853  loss=152.6730  steps/s=102.04  prediction: \"ng to caffeine+building/studying for fun\" => \"     e n inmii++i+++iiniiiingnininiinini\"\n",
      "batch 11854  loss=136.4346  steps/s=104.30  prediction: \"assume that had a large effect back then\" => \"nteo  s  s s   s  aaaaaaaaaa            \"\n",
      "batch 11855  loss=146.6150  steps/s=99.46  prediction: \"y be a way to do it without grad descent\" => \":crn et t      a            t  tt t dt  \"\n",
      "batch 11856  loss=136.9036  steps/s=103.26  prediction: \" own instead of relying on school for it\" => \"tn o ngoonn nn n o          n    o  o oo\"\n",
      "batch 11858  loss=220.8810  steps/s=101.06  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"PTIFU  UU UUU  ST SSFFFFFF F     /t/////\"\n",
      "batch 11859  loss=142.4958  steps/s=103.41  prediction: \"a wave of weird suspensions going around\" => \"nme   t  ae se s    e  sssssss s si  oso\"\n",
      "batch 11860  loss=143.0087  steps/s=104.61  prediction: \"is God for sure. but ive grown confident\" => \"n  e        s                           \"\n",
      "batch 11861  loss=157.4293  steps/s=108.32  prediction: \"e @sunsettler youre in the nix dimension\" => \" s     s h seresruur   r        n i ieni\"\n",
      "batch 11862  loss=171.1905  steps/s=82.47  prediction: \"npaul_ai Improves irl ppls responses too\" => \" rhe e ssseuereur  rrreee       n n eseo\"\n",
      "batch 11863  loss=152.0586  steps/s=104.81  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"eti    ttto o tooo  ooooo ososssssuu uuu\"\n",
      "batch 11864  loss=145.1492  steps/s=105.70  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" on t      n a aaaaaaannnnnnnnnnnnnnnnnn\"\n",
      "batch 11865  loss=180.3866  steps/s=97.40  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \"  y t ntnan aa adasn nnnsss tttnns//niXX\"\n",
      "batch 11866  loss=148.8280  steps/s=101.48  prediction: \"broth but it tastes awful lol any advice\" => \"uis  ooo bb b n t tttttt tt             \"\n",
      "batch 11867  loss=143.4962  steps/s=98.57  prediction: \", Heaven and hell are both one step away\" => \" iot o  ss en   eaeaee     a        e   \"\n",
      "batch 11868  loss=142.3051  steps/s=105.05  prediction: \" bc random twitter guy said itd be funny\" => \"te m ma mem         t      t       d    \"\n",
      "batch 11869  loss=144.6041  steps/s=104.63  prediction: \"rger abstractions which eventually haveâ€¦\" => \"ee yn chhTB$)Xn X)XXXXPXX)jX%))%%v%%j)â€¦(\"\n",
      "batch 11871  loss=160.5691  steps/s=100.63  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"ent  ea dd s  s      s  h  s ttttt/////t\"\n",
      "batch 11872  loss=149.1218  steps/s=103.97  prediction: \"just have to connect/reconnect the wifi'\" => \"ust t i tt  t    o    o  oonoccnccccecee\"\n",
      "batch 11874  loss=139.4282  steps/s=104.67  prediction: \"ment it with all the details that pop up\" => \"e e pu   neit i     t  ttttttttt tttttt \"\n",
      "batch 11875  loss=141.9864  steps/s=104.69  prediction: \"ecurity bots monitoring my whole network\" => \" t     a re r tt oooo  oooto o o   o  oo\"\n",
      "batch 11876  loss=151.1696  steps/s=102.88  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"teatm  mmmm   d    ee                   \"\n",
      "batch 11877  loss=156.1985  steps/s=103.89  prediction: \"e building an army of tiny little robots\" => \" so        n  n                         \"\n",
      "batch 11878  loss=150.4057  steps/s=101.74  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \" d       w nw  www                     e\"\n",
      "batch 11879  loss=151.9712  steps/s=103.73  prediction: \"everything is simple after you learn it\"\" => \" eo       gne  n  ii  i     e           \"\n",
      "batch 11880  loss=148.5696  steps/s=103.52  prediction: \" strategy is short term low integrity BS\" => \"too  e   as s essss ss        t  t tttrt\"\n",
      "batch 11881  loss=159.8848  steps/s=101.23  prediction: \"o make rlly complex interactive web apps\" => \" fe a      f  o           lll ee ee  eee\"\n",
      "batch 11882  loss=145.0666  steps/s=103.93  prediction: \" far dang the format looks so much nicer\" => \"tork     t a   f   f   o    o oo  ooo  o\"\n",
      "batch 11883  loss=135.5061  steps/s=101.16  prediction: \"d work that into my current program haha\" => \" ih   o    ww  w                rrr rrrr\"\n",
      "batch 11884  loss=165.6831  steps/s=96.98  prediction: \"Koala that would be much appreciated, ty\" => \"ao aoa aaa aaaa tta   t     u  r p papaa\"\n",
      "batch 11885  loss=151.9168  steps/s=96.61  prediction: \"mirages keep getting crazier and crazier\" => \"pnt  o a  r r    e ete   ee  ecaaa ar rr\"\n",
      "batch 11886  loss=149.1849  steps/s=103.50  prediction: \"rap out of them\n",
      "\n",
      "dont worship complexity\" => \"ec2y  hen gl,Gylj1,bvk2.jz280%L.uL.80%,@\"\n",
      "batch 11887  loss=152.7193  steps/s=101.72  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"d  os e n  I n onnonootttttoott/tt////t/\"\n",
      "batch 11888  loss=146.4941  steps/s=102.83  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"    ididididddddddttt t tttttttitttccccs\"\n",
      "batch 11889  loss=147.2926  steps/s=104.89  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"y  etun  ueeu          ttttsstttt///////\"\n",
      "batch 11890  loss=155.1929  steps/s=95.70  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"he r  ie tnn  nennttnu nttt////////tt/tK\"\n",
      "batch 11891  loss=182.1033  steps/s=70.61  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"yd @iu un nnnn n ntt ://tttt//K/teootssðŸ›‘\"\n",
      "batch 11892  loss=154.0646  steps/s=107.53  prediction: \"d first..still a bit cloudy but got theâ€¦\" => \" dhh   b  ht  tt            t t   t     \"\n",
      "batch 11894  loss=183.9643  steps/s=51.57  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" CToa eeeeleeMen#~#99#~9#v:#9M95XðŸ¤”M45X8T\"\n",
      "batch 11896  loss=155.7792  steps/s=111.62  prediction: \"ught it was a cool idea so i speedran it\" => \"shitnto\n",
      "\n",
      "t tttit t        o             \"\n",
      "batch 11897  loss=149.0412  steps/s=104.34  prediction: \"s of useful packages python would be ded\" => \" ba      n s  o      s              o   \"\n",
      "batch 11898  loss=277.3939  steps/s=8.02  prediction: \"reply: @djcows leveraged short positions\" => \"eply  @eeee,eÉªmhðŸ«¡vð—µâ™‚[á´¡Ê€{vbÉªðŸš€]^|$.**$$*$m\"\n",
      "batch 11899  loss=160.1685  steps/s=116.54  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \"irk   s  b ot  o ????h  hhhttthhtttpt//V\"\n",
      "batch 11900  loss=144.0120  steps/s=105.01  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"   ni tennnennenennnnnnnnnn nnnnonoooooo\"\n",
      "batch 11901  loss=162.9865  steps/s=105.10  prediction: \"for whatever they click on,play it w VLC\" => \" r tr v tedeveevee  e ee e  e     l     \"\n",
      "batch 11902  loss=153.3296  steps/s=100.36  prediction: \"ad to give some direction/motivation tho\" => \"n o  y      to too   oo   ooo ioioiotiii\"\n",
      "batch 11903  loss=139.3749  steps/s=104.96  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \"hto t t totn   nooooooooooo  oo         \"\n",
      "batch 11904  loss=143.2490  steps/s=104.32  prediction: \"ly when you try to build the thing again\" => \"y   s ck ccc   c                        \"\n",
      "batch 11905  loss=144.4107  steps/s=100.71  prediction: \"r been a better time to be a corn kernel\" => \"ea y  @otisITxgd@YT_,vDT.BYvYqjYv(.=/q8x\"\n",
      "batch 11906  loss=136.0871  steps/s=103.01  prediction: \"ol shit way more than alcohol and gaming\" => \"u :lni i n i                      aaaaaa\"\n",
      "batch 11907  loss=162.6824  steps/s=100.41  prediction: \"eadme updates :( https://t.co/FAmcprLRrm\" => \" li  no  de  eeaeeee e    t::::tt///////\"\n",
      "batch 11909  loss=150.2606  steps/s=105.10  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \" in.   te t te   \n",
      "ee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttt\n",
      "/t//tt//\"\n",
      "batch 11911  loss=143.9023  steps/s=104.58  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \"ne aeee  e et et    tthtttttttttttt/////\"\n",
      "batch 11912  loss=137.5504  steps/s=104.40  prediction: \", usually because you border more things\" => \" ant ns ese ees e ee u u uuuuu  e  e e e\"\n",
      "batch 11913  loss=170.7885  steps/s=65.91  prediction: \"@jamstack_guru Speed of launches as well\" => \"yumiaeae seceusuu  e ee  uu  ur ee e e e\"\n",
      "batch 11914  loss=158.9123  steps/s=102.64  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \" :he ajustaeruau     e  o u uu  e   almðŸ›‘\"\n",
      "batch 11916  loss=147.2801  steps/s=106.23  prediction: \"her is metagocnition (for your own mind)\" => \"e  a  prnhn trgne  ooot ooo ioooo  oo o \"\n",
      "batch 11917  loss=140.2353  steps/s=104.18  prediction: \"y want to use something feeling-relatedâ€¦\" => \" ci aoe bbb    b  o         ee  eeeeeeee\"\n",
      "batch 11918  loss=216.1525  steps/s=24.63  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @bb   n      o        eee  eeeeeeee\"\n",
      "batch 11919  loss=206.2389  steps/s=64.25  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @bbbony  ))  t      e eee  eeeeeete\"\n",
      "batch 11920  loss=138.6781  steps/s=108.26  prediction: \"ideo of you doing some crazy stuff. damn\" => \"ne i      tt    o ooo  oo    o    o     \"\n",
      "batch 11921  loss=154.1945  steps/s=85.80  prediction: \"tard Interesting can you elaborate more?\" => \" ri   a t t    e  oo  o       yu   aa mm\"\n",
      "batch 11922  loss=156.6083  steps/s=104.53  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"am i    w   0000000                   o \"\n",
      "batch 11923  loss=160.3099  steps/s=104.51  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nk o  me mer  Ce   e    e               \"\n",
      "batch 11924  loss=191.0260  steps/s=20.91  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @\n",
      "eteet  CC   e e  e   e           \"\n",
      "batch 11925  loss=166.2792  steps/s=121.83  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"nk te  e he22 e 9  l  t ttt attttt//////\"\n",
      "batch 11926  loss=146.2744  steps/s=105.71  prediction: \"hat easy guys, you learn like way faster\" => \"et t  e lat   a y yyy yyy              a\"\n",
      "batch 11927  loss=134.1078  steps/s=98.78  prediction: \"chat is this what sweat equity means????\" => \"tels   t at t it t    s  t    t    eeete\"\n",
      "batch 11928  loss=146.6372  steps/s=104.91  prediction: \"ven more\n",
      "\n",
      "repeat, positive feedback loop\" => \"er ugnhtt\n",
      "\n",
      " \n",
      " ne\n",
      "\n",
      "\n",
      "\n",
      "eeeeeeeeeeeeee  eeee\"\n",
      "batch 11929  loss=151.5336  steps/s=105.04  prediction: \" absolutely mind blowing post all around\" => \"t  tlin tl loll  lllll   l  ooo  llo    \"\n",
      "batch 11930  loss=128.8229  steps/s=101.82  prediction: \"ntext into a computation to make it pure\" => \"g  o t   nnnt n     tttttttttttttttt    \"\n",
      "batch 11931  loss=140.5182  steps/s=105.23  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \" ceaaei an niiiiiiniiittttttttttt/////tt\"\n",
      "batch 11932  loss=146.2203  steps/s=105.22  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"nd na p  ndeadd   aa   aa  a   a     nn \"\n",
      "batch 11933  loss=164.3603  steps/s=99.65  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \" p d @  n eb  ne   e  tt tt t  ttt/tc///\"\n",
      "batch 11934  loss=148.3543  steps/s=104.65  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"eltne   e vveTh wwGy/mk)\"\"(q((:KI9.0Sq35\"\n",
      "batch 11935  loss=158.3326  steps/s=102.88  prediction: \"you gotta gamify reporting spam bots lol\" => \" u reg  n@ot o     oo   t gg  g     oo  \"\n",
      "batch 11936  loss=146.6286  steps/s=102.81  prediction: \"nkedin phase\n",
      "\n",
      "we'll teach them hopefully\" => \"g thet  hnh nihi e eeeee eeeh ehee he ee\"\n",
      "batch 11937  loss=159.2999  steps/s=44.63  prediction: \"y: @mayfer easy, just ask it what to ask\" => \"  @log hreirneh  e eeeee eheh ehhe eelle\"\n",
      "batch 11938  loss=153.5161  steps/s=140.77  prediction: \"nes @micsolana same for my history class\" => \"g the   enenees ll s  ea   em  hh t t ls\"\n",
      "batch 11939  loss=153.1695  steps/s=85.20  prediction: \"_software its c to wasm using emscripten\" => \"io si@nes@no aasa  s         m m  ss   s\"\n",
      "batch 11940  loss=139.1956  steps/s=107.38  prediction: \"tony learns domain expansion in season 5\" => \"  ton t   ot  onnn nn nnn nnnnnnninnnnn \"\n",
      "batch 11941  loss=139.7108  steps/s=101.95  prediction: \"e readme was a good read on ai reasoning\" => \" tol    rhs   a  e   a a    a    a  a  a\"\n",
      "batch 11942  loss=162.3556  steps/s=104.30  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"[(o@tjr ,n,n ,]]0   ,     s    s      e \"\n",
      "batch 11943  loss=147.3725  steps/s=104.41  prediction: \"y with any industry/niche and ill run it\" => \" iedseiny yn inyyyyyynnnynnnnnni n n n  \"\n",
      "batch 11944  loss=179.6702  steps/s=103.82  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" o  tkcpceeodce ccocom   to ooootto///co\"\n",
      "batch 11945  loss=143.9999  steps/s=95.25  prediction: \"ich is a great way to find opportunities\" => \"ni ff i i inc w                        i\"\n",
      "batch 11946  loss=147.5983  steps/s=115.60  prediction: \"nd stop you from seeking rewards in life\" => \"d fi i    ny  u   o   o        r    r   \"\n",
      "batch 11947  loss=152.5426  steps/s=104.10  prediction: \" it sucked but couldve been 1000x worse.\" => \"tn ann    n n t    u   uu eeeeee eee 000\"\n",
      "batch 11949  loss=147.2040  steps/s=104.38  prediction: \"ng game becomes abt strategizing aroundâ€¦\" => \"d   o  g   n   g  e    e  ettttttaaaaaat\"\n",
      "batch 11950  loss=173.6177  steps/s=74.07  prediction: \"wlearning \"Pricing it in\" now 15% faster\" => \"oel   wg g  eeeg ae  t  ttttiin  a aaa  \"\n",
      "batch 11951  loss=127.8767  steps/s=105.57  prediction: \" into local files when you need to build\" => \"tn  nd   n t                            \"\n",
      "batch 11952  loss=155.7533  steps/s=46.70  prediction: \"y: @sunsettler gl w luffy tomorrow bro ðŸ«¡\" => \"  @ded     a  t  ll l l     ee  e       \"\n",
      "batch 11953  loss=185.8002  steps/s=112.18  prediction: \"ARA \"dont talk to me or my retard again\"\" => \"PA  @SbA b n  A A                  r    \"\n",
      "batch 11954  loss=154.1799  steps/s=98.64  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"ere\"  d    a            a    aaaeeaaeaaa\"\n",
      "batch 11955  loss=153.6145  steps/s=104.69  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "itic  iivp e)(Lz:SzGv2FI1FFz1AV7UB?:)vL\"\n",
      "batch 11956  loss=265.5455  steps/s=11.65  prediction: \"reply: @calbch its the year of the monad\" => \"eply  @i vp e)(Lz:SzGv2?I1FFz1AV7UBO:)vL\"\n",
      "batch 11958  loss=181.0854  steps/s=133.78  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @toc i  en!e)iLz:SzG:/,I.ZMz1AV7UB45XvL\"\n",
      "batch 11959  loss=161.2463  steps/s=109.95  prediction: \"_opener oops i misread your comment my b\" => \"iofat@o_@_oooooo  ooooo o     r    mm   \"\n",
      "batch 11960  loss=142.1803  steps/s=102.60  prediction: \"nin man, was a great great time as usual\" => \"gs eo n n n n m n a    aaaaa aa aaaa aa \"\n",
      "batch 11961  loss=138.0735  steps/s=103.76  prediction: \"ng term\n",
      "\n",
      "Best signal to work on for sure\" => \"g   o   t t  t tttt t tt     t  o    o  \"\n",
      "batch 11962  loss=144.8508  steps/s=103.88  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"s  to to n no  oooo      ttt  ttttt////s\"\n",
      "batch 11963  loss=138.3235  steps/s=104.31  prediction: \"tic paper searches\n",
      "at this rate it willâ€¦\" => \" no   sp p p pe ereaeaaa aasaea aaa   tt\"\n",
      "batch 11964  loss=155.0682  steps/s=105.05  prediction: \"16, now we play the long game https://tâ€¦\" => \"  ryl ororrre{vv^`}ð˜xqá´„^xqá´‡xq#å€‘#â€ð—²á´‡á´›}#}å§\"\n",
      "batch 11965  loss=160.2439  steps/s=102.21  prediction: \"\n",
      "\n",
      "pride, however, stops error correction\" => \"\n",
      "a t   mnon ann Pvj!7@7xxMkBvMxx:Tv/!!â€¦ðŸ›‘\"\n",
      "batch 11966  loss=222.0223  steps/s=99.72  prediction: \"CKING GOO!!!!!!\n",
      "\n",
      "Build to learn das rite\" => \"ornt:  l0 ILE0S FCKINBCKIBkzGOOx:TB/!!kB\"\n",
      "batch 11968  loss=150.7085  steps/s=104.18  prediction: \"y put it back, just gotta wait a few yrs\" => \" sosenlllll   t          ttt  ttttt t t \"\n",
      "batch 11969  loss=166.7060  steps/s=104.70  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edo i @lMlhfi0f 17ÊŸ,ï¸v65Mâ€™S^M6521_`M1cVC\"\n",
      "batch 11970  loss=141.0675  steps/s=102.10  prediction: \"its bad but, it has pros you can play to\" => \"n   iats n\n",
      " s  st    t  t   s    s      \"\n",
      "batch 11971  loss=141.2402  steps/s=104.70  prediction: \"for typos and a list of other dumb stuff\" => \" r t a c cc   tt                        \"\n",
      "batch 11972  loss=152.0667  steps/s=102.78  prediction: \"here for the funny symbols and recursion\" => \"e es er r   rrrre    ee   e        n   n\"\n",
      "batch 11973  loss=137.6212  steps/s=104.33  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y7 jil i   lllep                 a     a\"\n",
      "batch 11975  loss=158.0162  steps/s=104.46  prediction: \"r you choose is not technically infinite\" => \"eas tiocnli @x1dU\n",
      "`&b7á´‡b`É´X.b{|xâ€™vÊœ^}#.á´‡\"\n",
      "batch 11976  loss=143.1093  steps/s=103.43  prediction: \"g/take a break from dopamine-exhaustingâ€¦\" => \" tusodt vee n a aaa     a a  a aeaaaeaaa\"\n",
      "batch 11977  loss=136.8728  steps/s=103.89  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \" e eoe eem em e eee    t l      t  rttrt\"\n",
      "batch 11978  loss=238.8824  steps/s=11.17  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eplsso@ hnnewIg L,_Y_7,:v__.25?v?Aj2_vb7\"\n",
      "batch 11979  loss=154.7186  steps/s=110.34  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"g.cnneet/iotn//ht/t//hhtth:t//:t//tt.///\"\n",
      "batch 11980  loss=190.8193  steps/s=97.35  prediction: \"layzXD @ludwigABAP Based\n",
      "Python/zig gang\" => \"yte@iipi n e@lDiDDBlBBBBBPPPPPPPoPPtoogg\"\n",
      "batch 11981  loss=139.8636  steps/s=102.61  prediction: \"conflicting values it would be a paradox\" => \"onte n  llil lillllliiii i              \"\n",
      "batch 11982  loss=145.7289  steps/s=103.94  prediction: \" sudo systemctl restart systemd-resolved\" => \"tuet      no  ads ssstsssstttsstteetsses\"\n",
      "batch 11983  loss=262.2805  steps/s=99.50  prediction: \": CHECK\n",
      "DELTA TIME: CHECK\n",
      "GRAVITY: CHECK\" => \" @HiieCTi: JHLTS:DCLE:KCHMLKARHLVKYGRAVI\"\n",
      "batch 11984  loss=174.5142  steps/s=95.35  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"eLsC     ese   HH    on       n    T e e\"\n",
      "batch 11985  loss=145.5380  steps/s=104.84  prediction: \"y areas of corporate world it seems like\" => \":a snea n   aa aa  rrooororr rr e       \"\n",
      "batch 11986  loss=145.4288  steps/s=104.48  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" mhoh   mde meemoeue tt te t t  ttettttt\"\n",
      "batch 11987  loss=147.5450  steps/s=105.72  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"n \n",
      "\n",
      "nynnnnitin tttttttitttttttttttt/////\"\n",
      "batch 11988  loss=145.4840  steps/s=101.64  prediction: \"on said we cant use that word any more!!\" => \"     n         n        a    t    t  t  \"\n",
      "batch 11989  loss=149.1043  steps/s=102.22  prediction: \"ted to see how cracked you get long term\" => \" re   trr teteeee  e eeeee     e e e   o\"\n",
      "batch 11990  loss=141.7611  steps/s=104.50  prediction: \"s is pretty cool https://t.co/2VR6GTbI3d\" => \" ioae    h t  t  t t    tttttttoot//tt//\"\n",
      "batch 11991  loss=164.9590  steps/s=66.23  prediction: \"@btwphones thanks! its going well so far\" => \"yekiore t     t thttt  ttt t////////loos\"\n",
      "batch 11992  loss=146.3468  steps/s=107.24  prediction: \" in terms of your thoughts in each \"era\"\" => \"tt e ee  im r rm        o  o   oo t     \"\n",
      "batch 11993  loss=148.7713  steps/s=104.09  prediction: \" if they'll give you access to that zone\" => \"tn ie  iie ieeeie  i i i   y    e     t \"\n",
      "batch 11995  loss=140.4172  steps/s=105.43  prediction: \" keep doing it for more and more phrases\" => \"tnw n enneegnepe  e                 r   \"\n",
      "batch 11996  loss=138.0089  steps/s=100.56  prediction: \"nds like a super cool premise for a game\" => \"    e n nn  n          o o    ee    o   \"\n",
      "batch 11997  loss=149.9974  steps/s=102.89  prediction: \"re advanced in the art of shape rotating\" => \"eply  55uninf,,IIÊŸb'^}S#b{XSâ€¦k#ðŸ‘{ð—»Éª^#ð—¶#,\"\n",
      "batch 11998  loss=206.1792  steps/s=92.33  prediction: \" ayyy thanks!!! LETS GOO FINALLY SHIPPED\" => \"tne  y ya a ayyn !!!   !!   OO  OO  LIIL\"\n",
      "batch 11999  loss=170.4367  steps/s=93.23  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @yyyyynyn ninian a a     SaS  St  t a\"\n",
      "batch 12000  loss=159.9475  steps/s=95.07  prediction: \"hag_ its good to be on the outside again\" => \"et s aianign i tit  a       ea    t  ttt\"\n",
      "batch 12001  loss=143.0843  steps/s=102.93  prediction: \"marter you get the more the traps change\" => \"ek   am rtth  t        t   e   e   e    \"\n",
      "batch 12002  loss=161.0858  steps/s=100.99  prediction: \"ight go back to ML stuff instead of this\" => \"nAsa     tg gg g                tt  t f \"\n",
      "batch 12003  loss=191.5895  steps/s=58.43  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"@ a it   h           tt    ttt   f ff   \"\n",
      "batch 12004  loss=138.4011  steps/s=111.72  prediction: \" the first alien on earth thats so crazy\" => \"@hee enee  t   t e e     e     tt  t t  \"\n",
      "batch 12005  loss=149.2076  steps/s=101.83  prediction: \" for yourself they pay dividends forever\" => \"@oooo  ooooooo o     o    yy y y      e \"\n",
      "batch 12006  loss=162.1524  steps/s=104.03  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"][o@ ro [n00 1][0   0     s    s      e \"\n",
      "batch 12007  loss=152.1566  steps/s=101.91  prediction: \"ai car tire\n",
      "\n",
      "may not get smart money tho\" => \"t on oa  \n",
      "aaa n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a    a   aa  t     t\"\n",
      "batch 12008  loss=173.6252  steps/s=101.65  prediction: \"? If so how much https://t.co/W2kuYHIlNP\" => \" o\n",
      "\n",
      "A  een f               t ////t//t//t\"\n",
      "batch 12010  loss=167.4751  steps/s=91.95  prediction: \"7 make money so you can make video games\" => \"0L a nc c7  me m o    oo  co  tou ck   m\"\n",
      "batch 12011  loss=160.2422  steps/s=100.32  prediction: \"azy like that. Cheers my English brother\" => \"t9 T on n  ne t  t   e e      e  e      \"\n",
      "batch 12012  loss=157.5165  steps/s=106.37  prediction: \"le77 if they install the meat addon, yes\" => \"y  lrnB ii  7 7h t  ee  e   tll hh   e  \"\n",
      "batch 12013  loss=137.2781  steps/s=101.85  prediction: \"and run it in the front end of a browser\" => \"ndcc c     n                            \"\n",
      "batch 12014  loss=139.1997  steps/s=104.77  prediction: \" different distribution of training data\" => \"tov evee h  t  eeeeeetttiititiiiiiiinini\"\n",
      "batch 12015  loss=140.0726  steps/s=102.89  prediction: \" figuring it out. it just clicked for me\" => \"tar o f  ff tif  i        t  t    t     \"\n",
      "batch 12016  loss=157.3711  steps/s=98.16  prediction: \"new following you was the right decision\" => \"   f  irneni   l o w o  ww  o           \"\n",
      "batch 12017  loss=147.5812  steps/s=104.30  prediction: \"anything else would kneecap learning no?\" => \"nd  ierit  hiiani      n n  n ee en ennn\"\n",
      "batch 12018  loss=156.8989  steps/s=66.84  prediction: \"ludwigABAP its all slop tier, always was\" => \"yd  iigigiin  wn l  llee e  eeeeeaa annn\"\n",
      "batch 12019  loss=149.7589  steps/s=106.99  prediction: \"ull potential. That would be surprising.\" => \"sd  t     tn tt  t   tttl  t ll        u\"\n",
      "batch 12020  loss=154.9002  steps/s=99.41  prediction: \"ideos Its good to be back on the streets\" => \"n  fh ee iiltot tt   oo  ooo         e  \"\n",
      "batch 12021  loss=171.3239  steps/s=29.54  prediction: \"ply: @dgant wild https://t.co/0HTLsAprAT\" => \"ly: @fredtidooo  t   oo  oo          e  \"\n",
      "batch 12022  loss=147.5874  steps/s=108.47  prediction: \" random nonsense will escape containment\" => \"tot sme emm sm msssnnnsen es ese eeennen\"\n",
      "batch 12024  loss=144.8479  steps/s=102.72  prediction: \" to call in the big guns (aka @gizmobly)\" => \"the        a   l                        \"\n",
      "batch 12025  loss=142.1163  steps/s=105.24  prediction: \"re obvious. some are really hard to see.\" => \"e l t nim .a,,yw2v+k\"\"-j\"\"+9.+/=m7+=AAAA\"\n",
      "batch 12026  loss=159.7965  steps/s=103.87  prediction: \"houghts on this\n",
      "\n",
      "https://t.co/BV7iOyFnzq\" => \"eue m  nn  h  hhohhhhthhthths///tt////tt\"\n",
      "batch 12027  loss=211.4093  steps/s=99.44  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"Sphere    EEETETATATT OAA   /ttt/ ///EtE\"\n",
      "batch 12028  loss=173.4377  steps/s=96.62  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"ena  uT  Y o Yo YYo   oot t t ttnnt t lp\"\n",
      "batch 12029  loss=180.1216  steps/s=102.88  prediction: \"ARA \"dont talk to me or my retard again\"\" => \"PAP @S A b n  b A                      r\"\n",
      "batch 12030  loss=150.6336  steps/s=102.42  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"on o  e an c a c aa      ouu   uouu ooo \"\n",
      "batch 12031  loss=161.7903  steps/s=98.67  prediction: \" now i have this https://t.co/NCsyY5vpWl\" => \"@ov ett n  f           hhhttttt ttt/////\"\n",
      "batch 12032  loss=143.3783  steps/s=104.61  prediction: \"reevaluating concepts you often overlook\" => \"eplyo ww%T\"]#{rdá´„^~ðŸ°#á´›:á´‡`ðŸ«¡.^ï¸#NÊŸ~Q\n",
      "{ðŸ¤¦ðŸŽ‰#^\"\n",
      "batch 12033  loss=156.3151  steps/s=105.21  prediction: \"activation energy as much as possible ig\" => \"nt     odtct   ot e  o    e a  a s  s   \"\n",
      "batch 12034  loss=151.5666  steps/s=103.66  prediction: \"forward, forever\n",
      "https://t.co/zlto3SBYwd\" => \" r  n  lwe o  rrrrrrrrrrrrrrrrrtttttt///\"\n",
      "batch 12035  loss=172.2593  steps/s=103.82  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t.ec t t////:///9999899ttppt/ttt////t///\"\n",
      "batch 12036  loss=151.8082  steps/s=101.25  prediction: \"you should do it, youd learn a ton i bet\" => \":u  ajn   u u no o  o  oo    d          \"\n",
      "batch 12038  loss=139.1993  steps/s=103.07  prediction: \" can see something 1000000x better to do\" => \"tot ea an na  eseee  e  000000000000 e  \"\n",
      "batch 12039  loss=162.7357  steps/s=103.15  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e ar Rototiot  t oo o  o             n  \"\n",
      "batch 12040  loss=138.4743  steps/s=104.39  prediction: \"ark a bit so i felt like writing this up\" => \"nn n em  t    t              i iiiiiiiii\"\n",
      "batch 12041  loss=160.6098  steps/s=102.12  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"a t  se Borloo  oolll  oo     uffuufuu u\"\n",
      "batch 12042  loss=140.8931  steps/s=102.97  prediction: \"e firework chair https://t.co/J6w6odDBx3\" => \" tin n    ne ene  rr rrrrrr rtr ttttt666\"\n",
      "batch 12043  loss=149.3601  steps/s=104.80  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"nh e eleen hh  raaa r      rer    ee  ee\"\n",
      "batch 12044  loss=146.3342  steps/s=104.72  prediction: \"g correct (fingers crossed its this one)\" => \" a e erret  rrrrrrerr crrerr  ssss s ss \"\n",
      "batch 12045  loss=186.9003  steps/s=97.26  prediction: \" QUICK delete this before sphere sees it\" => \"t e  ogorUler e ett  tesseee ss se ssee \"\n",
      "batch 12046  loss=146.9350  steps/s=99.93  prediction: \" they secretly exercise and dont tell us\" => \"theb ehe eteeetse eeeeeeeeeeere ee   e  \"\n",
      "batch 12047  loss=141.7301  steps/s=104.09  prediction: \"ant to make many measurements per second\" => \"ndu o   w            m mmmmameeemme eeee\"\n",
      "batch 12048  loss=156.3092  steps/s=100.75  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \" s  ooi  t t  asa    aaaa s    naaaa    \"\n",
      "batch 12049  loss=146.7265  steps/s=98.51  prediction: \"feels better than giving to the homeless\" => \" r   h nehn neete  tt e    ttt    t     \"\n",
      "batch 12050  loss=142.3046  steps/s=103.29  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \"  o  ensstseseaee    an  nn  n         i\"\n",
      "batch 12051  loss=126.8001  steps/s=102.60  prediction: \"veryone in the past was a caveman/moron\"\" => \"ers ed en e eeaeee             aaaaaaaaa\"\n",
      "batch 12052  loss=150.3719  steps/s=102.99  prediction: \"to fill them in fast, like you mentioned\" => \"    ts t i  t  t                        \"\n",
      "batch 12054  loss=138.5036  steps/s=103.61  prediction: \"people, i just post a weird mix of stuff\" => \"lrb    olo    i                         \"\n",
      "batch 12055  loss=142.3645  steps/s=103.12  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"  ncn e ctneeeneeeeeeeeeeett:::/t//t////\"\n",
      "batch 12056  loss=157.1419  steps/s=104.28  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o  g o netn2 %%%%%%%  % 333333         \"\n",
      "batch 12057  loss=155.0249  steps/s=99.25  prediction: \"c high entropy stuff that fits the curve\" => \"aom   aa  anaaa           ttfftttttt ttt\"\n",
      "batch 12058  loss=154.3556  steps/s=100.88  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"n   e aede e   ee  e  e e     e         \"\n",
      "batch 12059  loss=155.1752  steps/s=97.64  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"@ind  d od   d\n",
      "   d    h       o so oo  \"\n",
      "batch 12060  loss=156.8867  steps/s=101.37  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" yn ook  god  o    o   ooo o  o         \"\n",
      "batch 12061  loss=151.4392  steps/s=97.51  prediction: \"tand on the shoulders of retarded giants\" => \" r oa    e a  nn  s e  oo  o   eee derd \"\n",
      "batch 12062  loss=147.6909  steps/s=103.63  prediction: \"ng, dunno why this flew over my head lol\" => \"t oo sitnnee nu nt  n n n               \"\n",
      "batch 12063  loss=140.6309  steps/s=98.71  prediction: \" im pretty screwed when we play sap then\" => \"@s es nee t   r  se ee ewweeewewe w   ee\"\n",
      "batch 12064  loss=151.5853  steps/s=104.81  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \" eell  dlllnll  ll o\"\"o ooo  ooo oo    !\"\n",
      "batch 12065  loss=146.0170  steps/s=104.69  prediction: \" something rudimentary could be possible\" => \"tptike .n t ttn   iini n           e    \"\n",
      "batch 12066  loss=143.0852  steps/s=102.77  prediction: \"ut from having 1/3rd the progress per hr\" => \"s  n   u n n  t              r  rr rrrrr\"\n",
      "batch 12067  loss=151.2008  steps/s=104.11  prediction: \"makes it an order of magnitude harder...\" => \"ara  at n  ai               o        rdd\"\n",
      "batch 12069  loss=139.8208  steps/s=103.74  prediction: \"d will be free. so far, thats everything\" => \" ho innntt e enn    eee    e      r    t\"\n",
      "batch 12070  loss=145.6276  steps/s=105.29  prediction: \" possibly even take classes remotely idk\" => \"tou ss oobso  b   e        eee eeeeeeeee\"\n",
      "batch 12071  loss=143.5951  steps/s=105.34  prediction: \"r minds after realizing thats not rly it\" => \"eathl(ikk) uef@gæˆ‘ÊŸz`vá´„v##))XXCÊœð—±á´‡QÊœðŸ“ˆá´ðŸŒ‘^#\"\n",
      "batch 12072  loss=158.7042  steps/s=103.52  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" g ahi   f               sttttt////////F\"\n",
      "batch 12073  loss=148.5847  steps/s=104.34  prediction: \"alize the fundamentals mattered the most\" => \"nl  veee ee e nee eeeeeea aateattte tttt\"\n",
      "batch 12074  loss=142.1555  steps/s=104.73  prediction: \"a good way to beat addictions in general\" => \"nwei w  s   ttooooo    a  aa aa   ii    \"\n",
      "batch 12075  loss=149.0486  steps/s=101.04  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng ig tttnei tneettitiatataataaa aa aa  \"\n",
      "batch 12076  loss=177.2449  steps/s=94.67  prediction: \"le77 Good stuff brotha\n",
      "\n",
      "looks productive\" => \"yx @rinteie 777g t s  aaataa\n",
      "\n",
      "aa\n",
      "a\n",
      " lo  \"\n",
      "batch 12078  loss=146.9716  steps/s=100.44  prediction: \"to play chess sometime, my li is dnbt777\" => \"h t  e   e            s s     e         \"\n",
      "batch 12079  loss=140.3097  steps/s=104.82  prediction: \"t them as axioms, and it screws you over\" => \" th   t etttta   a a   a       s s      \"\n",
      "batch 12081  loss=170.1020  steps/s=103.16  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.ritt t////t//ottttttttt::tt/tt////t///\"\n",
      "batch 12082  loss=155.2833  steps/s=94.14  prediction: \"is i need to make golden gate tetris bot\" => \"n   tswtopentod  d     e  o o  t ttttttt\"\n",
      "batch 12084  loss=143.5680  steps/s=104.03  prediction: \"rom things like chess or bjj or whatever\" => \"emiya nye o wzgnD3SBYAk,,AAAA:,VSV2jDSxk\"\n",
      "batch 12085  loss=148.3367  steps/s=105.11  prediction: \"y highest elo and post cool results on x\" => \" ai o\n",
      "r  st s st    e    o   o   oo   os\"\n",
      "batch 12086  loss=139.0859  steps/s=99.86  prediction: \"ey come you keep going\n",
      "Law of undulation\" => \"   o  te   me  eeeeeeeeee              o\"\n",
      "batch 12087  loss=159.0539  steps/s=102.75  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"  i te esetettetttteteeeeeeneeeeein  i i\"\n",
      "batch 12088  loss=158.4780  steps/s=104.64  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"aublee__nneInI IIII  eee e      ii   i  \"\n",
      "batch 12089  loss=155.1700  steps/s=103.74  prediction: \"t habit of reaching for my phone is gone\" => \"hfo    at tatthh     h  h               \"\n",
      "batch 12090  loss=212.6125  steps/s=98.53  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"eihy:  su s_i0w á´á´¡Ê€Ê€á´€á´€ÊŸ_á´¡_á´˜á´˜á´ÉªÉª_á´›á´›Êœ_É´É´á´¡_\"\n",
      "batch 12092  loss=146.3161  steps/s=101.46  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"ant            aa sssssssstttstttt//////\"\n",
      "batch 12093  loss=175.7798  steps/s=76.51  prediction: \"izmobly you have 3 days or youre blocked\" => \"ne  o    ssa  ee   ass  tttt//////// tNN\"\n",
      "batch 12094  loss=161.7087  steps/s=109.94  prediction: \"uine Good taste is a very powerful thing\" => \"slt timo mo   es   a s  t s   rrrerrere \"\n",
      "batch 12095  loss=145.5172  steps/s=105.26  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \" rs  iege=l )=m,@)_,3pÊŸ_B1==B0(/,,0_v_,B\"\n",
      "batch 12096  loss=152.3929  steps/s=100.96  prediction: \"ool challenge. amazing its down to 112mb\" => \"nl a  c   c   cc lll laa aa a a n       \"\n",
      "batch 12097  loss=171.4051  steps/s=99.62  prediction: \"king stuff part of twitter is so fun wtf\" => \" n07 c a  g0g  gaan af  ff   i tt  t   t\"\n",
      "batch 12098  loss=152.5737  steps/s=104.88  prediction: \"mes often times.\n",
      "anyone can pivot though\" => \"e aare ees see ese eeeseennnnenn nnnnn  \"\n",
      "batch 12100  loss=144.6030  steps/s=104.39  prediction: \"as soon as there are melons in the shop)\" => \"nh  l   s s  so o     a   e    e e ee e \"\n",
      "batch 12101  loss=152.5640  steps/s=104.65  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "ie   d.d@Iâ€™x@Iâ€™::Y_AGR:_4G:963/N3!NQk43\"\n",
      "batch 12102  loss=151.5640  steps/s=100.46  prediction: \" pried the shift key off w a screwdriver\" => \"tan a a   re     ee  e     f         f  \"\n",
      "batch 12103  loss=143.0681  steps/s=105.17  prediction: \"y do what sounds more interesting to you\" => \" th u b  b bb      o o    o           t \"\n",
      "batch 12104  loss=136.8080  steps/s=105.21  prediction: \"ng signals from constant individual lies\" => \"  ee ri i g   ig     ss  nnnnnninnnniiii\"\n",
      "batch 12105  loss=175.3592  steps/s=80.62  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"en dineini laaCC n  nn nnnn nnnni i iiii\"\n",
      "batch 12106  loss=150.6528  steps/s=104.17  prediction: \"ernet becomes, say, 100x more addictive?\" => \" stte  eeneeeeteeeeeeee         0       \"\n",
      "batch 12107  loss=175.8529  steps/s=103.73  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"@n ne e  a n   t                      e \"\n",
      "batch 12108  loss=141.3293  steps/s=104.96  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"  e  aa ta  t  g   a         e ee eeeee \"\n",
      "batch 12109  loss=152.8727  steps/s=104.32  prediction: \"itor as I was with 2 screens and a mouse\" => \"n a a a  tan                 s  s   s s \"\n",
      "batch 12110  loss=138.8510  steps/s=104.92  prediction: \"t, hence why lack of sleep kills my whys\" => \"  , s,  see r n e     e        e  ll lll\"\n",
      "batch 12111  loss=194.4948  steps/s=19.85  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @s rerne n e     e     e  e lll l  \"\n",
      "batch 12112  loss=147.3497  steps/s=108.23  prediction: \"I figure if we just do it, ppl will join\" => \" fuldbiiddiiiii                         \"\n",
      "batch 12113  loss=163.1944  steps/s=107.07  prediction: \" bet, im down, whats a good time for you\" => \"tuid ld t     w  w  w w   w     t      o\"\n",
      "batch 12114  loss=178.1132  steps/s=104.75  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \" ac  a l   y  at   Q                    \"\n",
      "batch 12115  loss=140.4816  steps/s=104.90  prediction: \"fficulty level, progressive overload etc\" => \"    e aufefefl llllllelleeeeeevvvvveveve\"\n",
      "batch 12116  loss=146.7937  steps/s=102.98  prediction: \"be allocate some time to do fun projects\" => \"u i o   n  a  e          t        o    o\"\n",
      "batch 12117  loss=140.1814  steps/s=103.83  prediction: \" like 1hr ago lol\n",
      "\n",
      "also is that your dog\" => \"aeaa ii  i    il     llllllll           \"\n",
      "batch 12118  loss=142.0735  steps/s=104.95  prediction: \"ty) so they can be free to chase rewards\" => \"  n o to reao ts    e e e  e e    eeee e\"\n",
      "batch 12119  loss=190.4435  steps/s=29.62  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"lypeo  ot t o  e    e e e  e     eeeee e\"\n",
      "batch 12120  loss=134.9277  steps/s=110.27  prediction: \"to someone on X, its laggy when it plays\" => \"      o    n  o                         \"\n",
      "batch 12121  loss=140.0780  steps/s=104.80  prediction: \"ng and figure out which freqs i care abt\" => \"  tt       e  nnn                       \"\n",
      "batch 12122  loss=136.1308  steps/s=103.05  prediction: \" own instead of relying on school for it\" => \"af o n oonn nn n o          n    o  o oo\"\n",
      "batch 12123  loss=151.3725  steps/s=103.72  prediction: \"e and remember as much as possible after\" => \" aoa   s saem ame e mmmmm      s  s  sss\"\n",
      "batch 12124  loss=170.2223  steps/s=60.29  prediction: \": @IterIntellectus here have another one\" => \" @yui a thoh_Ygo7gqkvx:L\n",
      "Ex:b1/bzFkvu1T\n",
      "\"\n",
      "batch 12126  loss=157.2193  steps/s=113.10  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"n ar l   .............       o          \"\n",
      "batch 12127  loss=167.3846  steps/s=104.76  prediction: \"caml my caml, our fearful thread is done\" => \"hlalo   im   mmmmmmm                    \"\n",
      "batch 12129  loss=148.4464  steps/s=105.20  prediction: \"k in college it worked for me super well\" => \" l    b     c  l                      ee\"\n",
      "batch 12130  loss=143.2087  steps/s=105.27  prediction: \"hitectures. it only finds different MLPs\" => \"as  ienet ectetttet       i  i    i f   \"\n",
      "batch 12131  loss=145.8792  steps/s=102.80  prediction: \"e latent space of \"make things ppl want\"\" => \" ton  t n  t tat  t     e  t  e  e     p\"\n",
      "batch 12132  loss=128.0733  steps/s=103.49  prediction: \" into local files when you need to build\" => \"an  nd   n t   t                        \"\n",
      "batch 12133  loss=144.0289  steps/s=99.69  prediction: \"ht them the openscad to make the pulleys\" => \"e    h   ettt tthhe eeee  e        e   e\"\n",
      "batch 12134  loss=144.9500  steps/s=97.97  prediction: \"e ive been thinking the exact same thing\" => \" ao  t itnne eee ne   nn  e    e   e ee \"\n",
      "batch 12135  loss=149.2483  steps/s=100.52  prediction: \"o beta testers, and the world soon after\" => \"ugee  be  et e t  te  ttt  e    t   o   \"\n",
      "batch 12136  loss=182.3840  steps/s=104.95  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"  o//!tt  t/ttt6tzzttFttbtt////tttcF/FF/\"\n",
      "batch 12137  loss=189.4260  steps/s=94.14  prediction: \"ez5341 based, i respect the grind brotha\" => \" s  rrzrrzteebsb\n",
      "bttppstpttcestcttotoVoF\"\n",
      "batch 12138  loss=141.2431  steps/s=105.96  prediction: \" from that channel/vid to that x account\" => \"trr  ao lol   dt  a a      tttttt    tt \"\n",
      "batch 12139  loss=139.7189  steps/s=104.46  prediction: \" life during hard times\n",
      "Thank God for it\" => \"tep  iei m  m n        i           d   d\"\n",
      "batch 12140  loss=144.6357  steps/s=102.98  prediction: \"f this song and never listen to it again\" => \" ao  im stess  s  s    n  nn     n      \"\n",
      "batch 12141  loss=162.1622  steps/s=39.28  prediction: \"ly: @larpertony @kuberdenis my elo is 10\" => \"y i@ st  s  ss s  n    n   n n          \"\n",
      "batch 12142  loss=131.6695  steps/s=108.28  prediction: \"en get way too absorbed into one of them\" => \"      g n   t tt     ooooooooooooooooooo\"\n",
      "batch 12145  loss=150.1343  steps/s=97.38  prediction: \"us im in, gonna do this rn, on the rocks\" => \"tee   n  a no nn o oo   nn  o    n      \"\n",
      "batch 12146  loss=220.1627  steps/s=100.84  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOO!EUGOOOOOOOOOOOOOOOOOOOOOOthhh//ttJJ\"\n",
      "batch 12147  loss=178.8206  steps/s=101.30  prediction: \" a day\n",
      "weekdays usually like 9am to 10pm\" => \"@bdkl3l -  as eyaaaayyyasayalyayll a    \"\n",
      "batch 12148  loss=154.9797  steps/s=104.45  prediction: \"sy and they put bugs in the concrete lol\" => \"  r   ba n aa  n                        \"\n",
      "batch 12149  loss=160.9967  steps/s=101.80  prediction: \"ct\n",
      "\n",
      "also, interesting advice in the clip\" => \"h e  b  occo  \n",
      "ooottettettti iiieeiii ei\"\n",
      "batch 12151  loss=145.4265  steps/s=104.28  prediction: \" possibly even take classes remotely idk\" => \"tru is o b o  b   e        eee eeeeeeeee\"\n",
      "batch 12152  loss=191.2270  steps/s=30.59  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @loooe sl ll ee     essseeeeeeeeeeee\"\n",
      "batch 12154  loss=150.3438  steps/s=119.57  prediction: \"lad its helpful man, which did you read?\" => \"ygesicc  n l lll lll   l                \"\n",
      "batch 12155  loss=144.4972  steps/s=103.85  prediction: \"ve you been unlocking yourself each time\" => \"e  iort o  \n",
      "n o eo      o nonnnn u eu ee\"\n",
      "batch 12156  loss=141.7431  steps/s=104.86  prediction: \"ion, which allows better problem solving\" => \"nn  at  eooco wo oooo  w  w   t   l  ell\"\n",
      "batch 12157  loss=143.4629  steps/s=103.26  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"eclye\n",
      " aann\n",
      "[ð—±neIw#ðŸ¤”JI2##ðŸ¤£$;##ðŸ˜Ž;â€ð—»#$â€/k&\"\n",
      "batch 12158  loss=158.2142  steps/s=98.54  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"t  t  ttdndoemm m    o     e        a   \"\n",
      "batch 12160  loss=147.0440  steps/s=102.81  prediction: \"libraries or backend compute or anything\" => \"ykeiteneebr rrr rrrrrrr r       r       \"\n",
      "batch 12161  loss=173.3571  steps/s=99.27  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"l t  oo  b0000 0000    tttttttt/t///////\"\n",
      "batch 12162  loss=166.3442  steps/s=100.17  prediction: \"ers @iliekcomputers is a p strong player\" => \"   i     ein ek ie iieiiii e iris p s  p\"\n",
      "batch 12163  loss=150.0923  steps/s=105.65  prediction: \" is actually happening behind the scenes\" => \"@n e    w     t  a aa aaa    nn  nn  eee\"\n",
      "batch 12164  loss=148.4759  steps/s=104.08  prediction: \"potential. then one day, it all explodes\" => \"lst ent t ttttttttt  nt               l \"\n",
      "batch 12165  loss=152.1459  steps/s=99.44  prediction: \"ding man! Yeah lmk how it goes next time\" => \" ns  nnn a  naa   a a a                e\"\n",
      "batch 12166  loss=173.1954  steps/s=60.32  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"@br r na   ana   a  a      o           e\"\n",
      "batch 12167  loss=146.9379  steps/s=107.79  prediction: \"one thing I need https://t.co/2lJdUbXtXP\" => \"ue hh nhht t            tttttttttt//////\"\n",
      "batch 12168  loss=190.9957  steps/s=72.38  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"suwineM  e tn ie tt tttt ttt////////!XXX\"\n",
      "batch 12169  loss=166.5176  steps/s=105.04  prediction: \"\n",
      "\n",
      "and give it slightly higher privileges\" => \"\n",
      "ii i i orsP!7t Pyv0v@NMTBbNMTByv(0xS1x,\"\n",
      "batch 12171  loss=150.3978  steps/s=102.92  prediction: \"nes @micsolana same for my history class\" => \"tM oe t  n nie@eaa  a aa   h h hr r yi i\"\n",
      "batch 12172  loss=146.4154  steps/s=104.77  prediction: \"ng game becomes abt strategizing aroundâ€¦\" => \"d   r og   g   g  e    e  ettttttaaaaaat\"\n",
      "batch 12173  loss=148.7060  steps/s=102.78  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \"e e  bul l m lo l l      ottttottt/////t\"\n",
      "batch 12174  loss=144.2584  steps/s=104.01  prediction: \" and the professor thought it was a typo\" => \"t    ii\"\"iid                            \"\n",
      "batch 12175  loss=151.1233  steps/s=99.75  prediction: \"xe only the strongest can take this path\" => \"plidgse  egg eego o tt  ttt t tt  t    a\"\n",
      "batch 12176  loss=149.1019  steps/s=101.70  prediction: \" for yourself they pay dividends forever\" => \"@oooo  oooooooo o    y  y yyyy y        \"\n",
      "batch 12177  loss=147.5780  steps/s=99.77  prediction: \"ood direction to get more good direction\" => \"ul l   eoern oege o  o  oo  e eo   oo oo\"\n",
      "batch 12178  loss=144.1614  steps/s=104.14  prediction: \" two next to each other. then a 4x4. etc\" => \"@he e  e tent n t  tt   tt   t t    h 4 \"\n",
      "batch 12179  loss=146.4444  steps/s=103.04  prediction: \"oud walk away w a much stronger skillset\" => \"u  \n",
      "  oddd d   ww    ww                 \"\n",
      "batch 12180  loss=143.4905  steps/s=101.49  prediction: \" ig i still dont understand comonads yet\" => \"tt h h   i i i  i i     t    t  nnnddddn\"\n",
      "batch 12181  loss=195.6937  steps/s=100.84  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"P @yAGSGLLLLINIAIILILIIIIS t ttttt//////\"\n",
      "batch 12182  loss=158.7985  steps/s=100.87  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" xe       t   tth            o nnnnnonnn\"\n",
      "batch 12183  loss=147.5934  steps/s=101.06  prediction: \"r taxes and splitting with other winners\" => \"eth   f )gBIz@gyQ#@$)bâ˜ ;+#ðŸ°J(#&bbxI$]$((\"\n",
      "batch 12184  loss=150.8429  steps/s=98.13  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"en ouuo xtYYoo YYYY noootnn    t t    er\"\n",
      "batch 12185  loss=164.6225  steps/s=104.34  prediction: \"kers #math #saas https://t.co/99Y0IouvaF\" => \"e   idiiiin# #s####sssasssssssstt/t////9\"\n",
      "batch 12186  loss=150.8085  steps/s=104.54  prediction: \"sy and they put bugs in the concrete lol\" => \"  re  ba n ba  n                        \"\n",
      "batch 12187  loss=134.4952  steps/s=105.13  prediction: \" on bookmarks from people similar to you\" => \"tf  d     oo   oooooooooooooo  o        \"\n",
      "batch 12188  loss=193.4518  steps/s=30.83  prediction: \"ply: @tszzl no :( 4o is still goated tho\" => \"ly: @ , boobooboo oo ooooooo  mo        \"\n",
      "batch 12189  loss=158.3513  steps/s=151.69  prediction: \"v ill send you a link around the 25th! ðŸ«¡\" => \"e@   ao e l n al  o     o  l ioa  e     \"\n",
      "batch 12190  loss=169.0870  steps/s=105.19  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.. tt t////tt/ottttttttt::tt/tt////t///\"\n",
      "batch 12191  loss=169.5496  steps/s=93.49  prediction: \"hag_ its good to be on the outside again\" => \"et  . htshtttoottttoootttoottt6octtZocct\"\n",
      "batch 12192  loss=164.2706  steps/s=97.78  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \"  ttpttor rr inu   ws\n",
      " ws sshhh ththaht \"\n",
      "batch 12193  loss=171.3548  steps/s=104.95  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"/. cyt t.///tt///tttttttt:///ttt://ttt//\"\n",
      "batch 12196  loss=139.6434  steps/s=105.96  prediction: \" of twitter it usually means engineering\" => \"tf h  n    tttttttttt t t     a   ee  ee\"\n",
      "batch 12197  loss=143.6063  steps/s=104.96  prediction: \"onna get wiiiild man like reeeeally wild\" => \"n n o   gosngiie  gn  i iiiiii e l  l   \"\n",
      "batch 12198  loss=162.9624  steps/s=103.21  prediction: \"fects the rest of the day. Cheers brotha\" => \"      ttff teet eettt           e   ee e\"\n",
      "batch 12199  loss=169.0097  steps/s=100.91  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \" r  zefna n sat   hohha     ttoo o    oo\"\n",
      "batch 12200  loss=146.2293  steps/s=104.15  prediction: \"on the manager/grifter/sociopath problem\" => \"n  e  o oeme  aeeeeeer ererrrrerrrrrtrrr\"\n",
      "batch 12202  loss=139.0645  steps/s=103.40  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \" rm   t  e bttet   eeeeeleeelleoo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " o\"\n",
      "batch 12203  loss=160.2162  steps/s=102.71  prediction: \" gzip compression loss continues to fall\" => \"aos s  a a p  sppp  ssssssssssssnnss oos\"\n",
      "batch 12204  loss=215.1825  steps/s=11.95  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eptyo @ hnwe41, CIO,y7z?CCz?,CV2VZDV4QC*\"\n",
      "batch 12205  loss=138.5430  steps/s=107.86  prediction: \"hinking and just saying what feels right\" => \"en  t   tg g         nn                 \"\n",
      "batch 12206  loss=142.9778  steps/s=105.62  prediction: \"ed for editing videos would be so goated\" => \"  o e geenendeieeeiii i iid d   do  o  o\"\n",
      "batch 12207  loss=152.8116  steps/s=104.02  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"thor no  t a re ro r  tt   tt s tt 7///t\"\n",
      "batch 12208  loss=153.1976  steps/s=105.47  prediction: \"d cost tracking\n",
      "\n",
      "https://t.co/GwHAwU1n1Z\" => \" toocon  n oco  cntt c  ttttttstt/tt//tt\"\n",
      "batch 12209  loss=150.0396  steps/s=104.61  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"h e  \n",
      "   l   e         aaaaayt:t//ttt///\"\n",
      "batch 12210  loss=172.9598  steps/s=102.76  prediction: \"ou get like 5 seconds to shoot your shot\" => \"nr R e  R                     ooo  o  s \"\n",
      "batch 12211  loss=144.8293  steps/s=104.24  prediction: \"so they get into an unending doom spiral\" => \"  itt  te  ttt ttt  t    n nnnnnnnnnnn  \"\n",
      "batch 12212  loss=147.2086  steps/s=103.64  prediction: \" have to reprompt it like 1/3rd the time\" => \"tad           o                         \"\n",
      "batch 12213  loss=153.5209  steps/s=100.74  prediction: \"u actually did the work so youre chillin\" => \"rdtattta  t t a                        o\"\n",
      "batch 12215  loss=170.6838  steps/s=101.45  prediction: \"g it\n",
      "When I figure out privacy stuff lol\" => \" td      a W W  iee i   ire u    uur  u \"\n",
      "batch 12216  loss=139.4221  steps/s=103.60  prediction: \"and i think that helped me a ton in life\" => \"nd o tr nn t in    t t   h              \"\n",
      "batch 12217  loss=147.9719  steps/s=106.11  prediction: \" off with a basic template and modify it\" => \"tu tiot  tftt  t     a    aa aataa a aa \"\n",
      "batch 12218  loss=158.4364  steps/s=102.60  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nlaaa aa nnananimmmmmmmmm mmmm          \"\n",
      "batch 12219  loss=158.9570  steps/s=104.37  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"tor  leeerec l   rrr  ur   t ttttt//////\"\n",
      "batch 12221  loss=149.3479  steps/s=101.96  prediction: \"nd stop you from seeking rewards in life\" => \"   u  l  d y  o   o   o                 \"\n",
      "batch 12222  loss=167.7444  steps/s=103.53  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tol   @ sn    hn     h      h  h hh  h h\"\n",
      "batch 12223  loss=139.9481  steps/s=105.51  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \"  ist gtn  t        t tt ttttt-t--t-ttot\"\n",
      "batch 12224  loss=165.4917  steps/s=104.55  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"tere     e en b               ttttt/////\"\n",
      "batch 12225  loss=173.5205  steps/s=46.11  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \"  @n n  ne n  e         ttttttt/////////\"\n",
      "batch 12226  loss=156.7685  steps/s=107.69  prediction: \" of actions a hyperparam was a cool idea\" => \"an  kaessssssne s      aaaa  aaaaaaaaa  \"\n",
      "batch 12227  loss=167.9051  steps/s=102.90  prediction: \"a have hella nostalgia in like 10yrs bro\" => \"nmng    gieraeh nenaanea a lea nia lnal \"\n",
      "batch 12228  loss=147.1892  steps/s=104.55  prediction: \"nd stop you from seeking rewards in life\" => \"   a       y ou   o   o             r   \"\n",
      "batch 12229  loss=163.0629  steps/s=99.58  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"aYcaYcs shse            h      s  sss s!\"\n",
      "batch 12230  loss=148.2748  steps/s=104.37  prediction: \"rce on github to figure some of this out\" => \"eh in @en in64it/64kTYIIIwzzb,IN16bIj!!!\"\n",
      "batch 12231  loss=151.6625  steps/s=103.87  prediction: \"s the error correction mechanism go away\" => \" au g  e\n",
      "r\n",
      "\n",
      "e e eer rrrerrrerreo co oocc\"\n",
      "batch 12232  loss=169.3752  steps/s=101.15  prediction: \" grows ur skills\n",
      "https://t.co/9ZBc4ushgS\" => \"trot ot  t ot g s ss sssststtstttt//////\"\n",
      "batch 12233  loss=152.4035  steps/s=103.65  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tii ie     t eg t   ttt  ttttt.t//t/////\"\n",
      "batch 12234  loss=153.6335  steps/s=102.08  prediction: \"ee time lately\n",
      "\n",
      "it has a long ways to go\" => \" mi   reer  ee2eeee tee lt   l  a l s   \"\n",
      "batch 12235  loss=161.7023  steps/s=66.14  prediction: \"@calbch its gonna be a good one for sure\" => \"yinamememh ieeeleet  ae a    a  a t s   \"\n",
      "batch 12236  loss=140.9361  steps/s=106.12  prediction: \"of those bc there are uncountably many c\" => \"n e bn nnaob                  e     a  a\"\n",
      "batch 12238  loss=146.9833  steps/s=103.75  prediction: \"ng game becomes abt strategizing aroundâ€¦\" => \"g w o  g   n   g  e    e  ettttttaaaaaa \"\n",
      "batch 12239  loss=144.9273  steps/s=102.40  prediction: \"inds the shortest path to get everything\" => \"ng i    t  n      tssttttttt ttttt tttte\"\n",
      "batch 12240  loss=148.5708  steps/s=97.63  prediction: \"mirages keep getting crazier and crazier\" => \"eneg   a  s re eee eeet  ee  ege rr rrrr\"\n",
      "batch 12241  loss=157.6228  steps/s=102.82  prediction: \"ely grinded like mad towards His mission\" => \" pat tllen le el le       dddddd     i s\"\n",
      "batch 12242  loss=148.5721  steps/s=104.21  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"u  s o    ss   s  s       a  aaaaaa  a  \"\n",
      "batch 12243  loss=159.1720  steps/s=102.50  prediction: \"re. Turns out it actually had a solution\" => \"ep5)t  sing T8n 8b88v!vv(v)())5)!U#v###(\"\n",
      "batch 12244  loss=148.5795  steps/s=101.46  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"to  i gr g we  e    e e       o         \"\n",
      "batch 12246  loss=158.6017  steps/s=99.99  prediction: \" as an information distillery, I like it\" => \"tn m oa    a ao  o   no iioi iitiili iii\"\n",
      "batch 12247  loss=154.6092  steps/s=97.90  prediction: \"rse21 help poor sama out, he needs ideas\" => \"eely:  _oetc9@gux9@zvxv21v)521[z&$$v}{m(\"\n",
      "batch 12250  loss=136.0637  steps/s=104.44  prediction: \"this is the same as the place where theâ€¦\" => \"hi       e t  e                  eeeeeee\"\n",
      "batch 12251  loss=134.2869  steps/s=101.32  prediction: \"answer in as few characters as possible\"\" => \"nd t  sssss s  e            aa    sassss\"\n",
      "batch 12252  loss=146.8696  steps/s=103.85  prediction: \"eakens your life-problem solving ability\" => \" l t  g nn g   n      e   elelllllll lll\"\n",
      "batch 12253  loss=140.9162  steps/s=104.23  prediction: \"he case for some regions outside the US.\" => \"e   t s e  s  i     e   e   oooooos  ee \"\n",
      "batch 12254  loss=149.5766  steps/s=105.11  prediction: \"ve gradient it lives in? Something else?\" => \"ero rn  ineiniiiiieiii i iii i      e ee\"\n",
      "batch 12255  loss=181.3230  steps/s=96.04  prediction: \"er CERN/physics bros you know what to do\" => \"  irrtteteEitt i  i i i   s    o        \"\n",
      "batch 12256  loss=149.3222  steps/s=104.39  prediction: \"er useful building block to get good at.\" => \"       s u uuuuu uuu  l ll              \"\n",
      "batch 12257  loss=147.1363  steps/s=104.55  prediction: \"uch data of rust + windows API functions\" => \"sh   t  nn t                            \"\n",
      "batch 12258  loss=168.6315  steps/s=93.56  prediction: \"wigABAP thats why they call him zigmobly\" => \"otkn     ad A A       th   hh   h    i  \"\n",
      "batch 12259  loss=149.8024  steps/s=105.66  prediction: \"y highest elo and post cool results on x\" => \" @e eet  st s st    e    o   o   oo   os\"\n",
      "batch 12260  loss=156.4712  steps/s=102.95  prediction: \"igure out how to improve your work ethic\" => \"nn  s  s t     uoo  oo tooo  oooo ooo r \"\n",
      "batch 12261  loss=145.2855  steps/s=104.64  prediction: \" something rudimentary could be possible\" => \"tptine nn n ttn   iin in           e    \"\n",
      "batch 12262  loss=139.6229  steps/s=101.48  prediction: \" able to do this approach w gpus anyways\" => \"t  e ee b  b                       p   a\"\n",
      "batch 12263  loss=148.7049  steps/s=104.47  prediction: \"s. im betting on that. but i am not sure\" => \"  y t at hty  nn t  t t ttt tt          \"\n",
      "batch 12264  loss=156.8876  steps/s=99.06  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e l : i neo@_xdeZ$ZJâ˜ :/ðŸ˜¢Z7lf,9JIQCkI}D$I\"\n",
      "batch 12265  loss=146.6846  steps/s=99.96  prediction: \"you really need to make your own company\" => \":u a nP a  aa e  a e  e    e            \"\n",
      "batch 12266  loss=144.1089  steps/s=101.82  prediction: \"ng and converged to guessing really well\" => \"   ea e nn n  nen      e ggggggggg g g e\"\n",
      "batch 12267  loss=169.2577  steps/s=103.76  prediction: \"an just do this: https://t.co/1xgV5Vs635\" => \"nd _or__utt  t   t    t tt::::ttt s///VV\"\n",
      "batch 12268  loss=171.5105  steps/s=29.09  prediction: \"ply: @andrew_pynch fundamentals compound\" => \"ly: @ptou t tt   t    tttt:://t/t V/VVVV\"\n",
      "batch 12269  loss=148.3083  steps/s=120.44  prediction: \"own to play more. was a pleasure as well\" => \"r ae nm  n n   m                   a a  \"\n",
      "batch 12270  loss=145.7103  steps/s=103.80  prediction: \"eakens your life-problem solving ability\" => \" l d  g nn g   n      e  eeleellllll lli\"\n",
      "batch 12271  loss=189.9840  steps/s=44.91  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y ng ne  n  n e   eeeee  elloollllllilii\"\n",
      "batch 12272  loss=180.0668  steps/s=107.28  prediction: \" @0xluffyb Deserved\n",
      "You build cool stuff\" => \"tsatene  a    nee ereeooooloolll obbblii\"\n",
      "batch 12273  loss=142.9090  steps/s=106.96  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly eo   nh n        e teeteeeennnnennnnu\"\n",
      "batch 12274  loss=186.1184  steps/s=53.32  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @0aop@uienrwJyucá´[{å§]--$-:7ðŸš€-~5X&M45X8T\"\n",
      "batch 12275  loss=154.6255  steps/s=107.83  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o al t nenmt n %%%%%  % 333333         \"\n",
      "batch 12277  loss=147.9470  steps/s=93.83  prediction: \"metimes you gotta take one for the cause\" => \"e e   o  mmm o ett t     t    o   oo  oo\"\n",
      "batch 12278  loss=148.7923  steps/s=104.04  prediction: \" muscle for mentally doing them will get\" => \"iort errenetr e or   e   l    le    mll \"\n",
      "batch 12279  loss=143.5611  steps/s=103.85  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"etga w@ e nb'@n JzM():\n",
      "IWMM?:AO6b9v'AO6:\"\n",
      "batch 12280  loss=181.8143  steps/s=60.46  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tgr a ggr   t    ll ttttllttttt////t/ttG\"\n",
      "batch 12281  loss=174.5090  steps/s=114.20  prediction: \"mobly @amix011 May do this in the future\" => \"ero  g w giAA @  4e111St  t othhhtnntttt\"\n",
      "batch 12282  loss=147.8048  steps/s=104.73  prediction: \"BAP lud the goat herder back at it again\" => \" P dwu A AlAe     eh th  ao   he     tt \"\n",
      "batch 12283  loss=144.4613  steps/s=104.33  prediction: \"e info produced by exploring new options\" => \" iia iin n n   nn        d  e         o \"\n",
      "batch 12285  loss=172.0367  steps/s=40.62  prediction: \"ly: @sunsettler @anish0209 Truly amazing\" => \"y  @linn      edd        o  e        ooo\"\n",
      "batch 12286  loss=159.8583  steps/s=112.57  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \"hr as e shseteteeeeettttttttttttttt/////\"\n",
      "batch 12287  loss=146.7017  steps/s=102.93  prediction: \"b, octane, trending on artstation 4k HD\"\" => \"e l de,,, ,,,,d , eee e n  nn nntntnt   \"\n",
      "batch 12288  loss=146.0213  steps/s=106.24  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yse     t  t t     t   tttttttttttt//YYY\"\n",
      "batch 12290  loss=141.7578  steps/s=105.18  prediction: \"ve implemented 50% of the mobile version\" => \"e  a  i e ee emeee e ee ee eee  e   e  e\"\n",
      "batch 12292  loss=152.1689  steps/s=104.31  prediction: \"ull potential. That would be surprising.\" => \"sd  t     tn tte t   tttl  t ll        u\"\n",
      "batch 12293  loss=142.7800  steps/s=98.05  prediction: \"lity is really really powerful, actually\" => \"yk iiAAii tilii lillllllllll lllll  rlll\"\n",
      "batch 12295  loss=148.0848  steps/s=104.08  prediction: \"to fill them in fast, like you mentioned\" => \"  g  s t  t t  t                        \"\n",
      "batch 12296  loss=143.2695  steps/s=106.04  prediction: \"have the opposite happen, do more stuff?\" => \"evp soe t oo  te   pp pppp   pppp pe   o\"\n",
      "batch 12297  loss=154.7531  steps/s=103.98  prediction: \"l. but really, I have absolutely no clue\" => \"y  @gng pr p pp            al   a lll ll\"\n",
      "batch 12298  loss=146.6170  steps/s=103.24  prediction: \"gpt-5 powered robot of him into the wild\" => \" te  p    e   ege       o     o  o   o  \"\n",
      "batch 12299  loss=181.3864  steps/s=91.06  prediction: \"ubed making gpt2 from scratch in c(obol)\" => \"sli a p pgepe  eog    o o  o o  ot t    \"\n",
      "batch 12300  loss=142.0305  steps/s=100.82  prediction: \"for getting me to read this btw, its fun\" => \" re  a  tg g  g t     tt   e t      t t \"\n",
      "batch 12301  loss=148.2427  steps/s=104.96  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"eltnt e vsvv__h wwOy/k_)1S(\"((:KI9.0Bq35\"\n",
      "batch 12302  loss=147.0634  steps/s=102.55  prediction: \"onna gm post w this video I guarantee it\" => \"n   n enon  n s          s           t  \"\n",
      "batch 12303  loss=139.3476  steps/s=104.07  prediction: \" eu would lose half its talent overnight\" => \"tvee  m eler  l  l  l  l    l    l   e  \"\n",
      "batch 12304  loss=142.7455  steps/s=105.56  prediction: \"erally the divide between autist and npc\" => \"  ton t  rl rrl\n",
      "llllleiee ieieee eeeeeee\"\n",
      "batch 12305  loss=176.6961  steps/s=29.54  prediction: \"ply: @10x_er he saw food and came runnin\" => \"le\n",
      " @ort  letilllllileiee ieiiee  eee tt\"\n",
      "batch 12306  loss=162.2858  steps/s=140.44  prediction: \"by_builds another $20 trillion to ludwig\" => \"e lo li __lilii e  ttete $$$ieti  enn tt\"\n",
      "batch 12307  loss=144.0948  steps/s=105.98  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"4 xc  k    00            ttttt//////////\"\n",
      "batch 12308  loss=164.2373  steps/s=105.85  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" andi p  , ,, ,,,,4444.........   xx xxx\"\n",
      "batch 12309  loss=173.4737  steps/s=76.96  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yde 0 ,, t4       .....  t  x ////m  m  \"\n",
      "batch 12310  loss=143.3071  steps/s=104.85  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"e iilnwi i i             e   ii  iiiiiii\"\n",
      "batch 12311  loss=138.1590  steps/s=102.63  prediction: \"yself infinite runway to build fun stuff\" => \"   dein  n n  fiiiiiin in     i      u u\"\n",
      "batch 12312  loss=143.1449  steps/s=101.78  prediction: \"all of the theories that we could invent\" => \"n e  r           o      t   ee  t     e \"\n",
      "batch 12315  loss=149.0420  steps/s=98.33  prediction: \"w site! Not gonna say much til it's done\" => \"isone   eneNe  tN   tt                t \"\n",
      "batch 12316  loss=158.0889  steps/s=103.96  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" e one     g  s   oo ooo  o nnnn  nn    \"\n",
      "batch 12317  loss=182.0318  steps/s=98.62  prediction: \"row)\n",
      "\n",
      "deletes 10 lines backwards in nvim\" => \"emly:  eow)\n",
      ",dF](@y11(0bL)vkxG)(kxwJ104T\"\n",
      "batch 12318  loss=162.4956  steps/s=98.37  prediction: \"oull just be on his midbie goats list dw\" => \" rror g  lo ll uu    ess   i s ds si  a \"\n",
      "batch 12319  loss=178.0865  steps/s=93.69  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1oo uaun  bu b      i  t :: stts s///33\"\n",
      "batch 12320  loss=133.3493  steps/s=104.38  prediction: \"vision how great itll be once youre done\" => \"en  e a n n   n                        e\"\n",
      "batch 12321  loss=160.0620  steps/s=102.49  prediction: \"as a BLAST dude. voice twitter is fun af\" => \"n    ea   t ta                e       t \"\n",
      "batch 12322  loss=152.6096  steps/s=100.63  prediction: \" busy so i havent been posting much my b\" => \"te   ses bs s s      e  eee e t  e    n \"\n",
      "batch 12323  loss=151.4418  steps/s=101.16  prediction: \"nt get too random with high stakes stuff\" => \"ei pea  tt et  ta  o t  oo      hh  hh h\"\n",
      "batch 12325  loss=152.1815  steps/s=104.46  prediction: \"d virus that makes ppl cracked at scale?\" => \" t   e i e  n n              a   a   aa \"\n",
      "batch 12326  loss=135.6369  steps/s=104.20  prediction: \"assume that had a large effect back then\" => \"n eo     s s   s   aaaaaaaaaa           \"\n",
      "batch 12327  loss=154.4940  steps/s=103.67  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \"entn nconan n \n",
      "\n",
      "     o      a  a  aa    \"\n",
      "batch 12329  loss=143.8652  steps/s=104.37  prediction: \"d it tho, was a change of weather for me\" => \" th e eeejete tte              aa      e\"\n",
      "batch 12331  loss=136.2568  steps/s=101.55  prediction: \"change it up a bit from the ol .txt file\" => \"oa eo n  t  t a                         \"\n",
      "batch 12332  loss=134.4018  steps/s=103.68  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" s th sssheessssseeeee ee ee            \"\n",
      "batch 12333  loss=141.9081  steps/s=103.66  prediction: \" onto it forever and never reevaluate it\" => \"tn e  non not no  o       n eerevveveeee\"\n",
      "batch 12334  loss=199.6531  steps/s=22.17  prediction: \"eply: @Nominus9 a unicorn would fix tpot\" => \" ly: @tonenono t  o  n e  rreevevveveeee\"\n",
      "batch 12335  loss=146.4657  steps/s=118.31  prediction: \"eft\n",
      "right looks right\n",
      "its a miracle init\" => \"  olloe  flfllol l oootttttttt  it iiiii\"\n",
      "batch 12337  loss=148.6685  steps/s=98.97  prediction: \"ly pretending to give unsolicited advice\" => \"y   g e t rtee t ee        e ei ii iiii \"\n",
      "batch 12338  loss=148.3967  steps/s=105.24  prediction: \"\n",
      "\n",
      "the command runit runs the last output\" => \"\n",
      "it   oeooblh\"XðŸ§ Qâ€œ*â€œæˆ‘gv{4byvvá´›ðŸ¤¯4á´‡ðŸ›‘\n",
      "&y&&ð—µ\"\n",
      "batch 12339  loss=144.5842  steps/s=104.99  prediction: \" to it. Cant be fully sure but it seemsâ€¦\" => \"thi ee      t  t                        \"\n",
      "batch 12340  loss=141.5057  steps/s=103.48  prediction: \"ed for editing videos would be so goated\" => \"  e   geonenoeieieeii i iiddd   oo  o  o\"\n",
      "batch 12341  loss=150.1967  steps/s=103.88  prediction: \"ter and more efficient than studying imo\" => \"hmt yos    rtt  tte e tteeeee eeiettttin\"\n",
      "batch 12342  loss=167.0807  steps/s=104.31  prediction: \"ot which will drain your web3 wallet. hâ€¦\" => \" h   a  lhl  l  lllll           www w   \"\n",
      "batch 12344  loss=144.6589  steps/s=103.64  prediction: \" far dang the format looks so much nicer\" => \"torb  n  t a   f       o   oo oo  ooo  o\"\n",
      "batch 12345  loss=155.4639  steps/s=101.97  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" d n \n",
      "RaRReeee eeeseesieeseesessesesseee\"\n",
      "batch 12347  loss=196.2833  steps/s=104.55  prediction: \"needed to dl this. meme delivery service\" => \"dsta     n e  et       e d  deeeeeeeeeee\"\n",
      "batch 12348  loss=143.7934  steps/s=104.94  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng so d    gg nn                 uuuuuu \"\n",
      "batch 12349  loss=162.9486  steps/s=41.81  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"  t los  o n oig nn             uu      \"\n",
      "batch 12350  loss=138.0583  steps/s=107.21  prediction: \"useful directions to take the project in\" => \"st o efefefeeeufee   e tt tttt ttttt tt \"\n",
      "batch 12351  loss=139.2197  steps/s=105.11  prediction: \" arent tired when you dont have caffeine\" => \"ile   t t t t et                        \"\n",
      "batch 12352  loss=178.8118  steps/s=58.31  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"ile   et  tet  t  t          o         e\"\n",
      "batch 12353  loss=158.6261  steps/s=108.99  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e lys @3b rrhYbtjkIJUc@I1T0kMIBY@HLBYj.k\"\n",
      "batch 12354  loss=145.8038  steps/s=100.85  prediction: \"so much to develop it? regulatory maybe?\" => \" me    s st    t               t      to\"\n",
      "batch 12355  loss=148.1098  steps/s=103.29  prediction: \" of your day your brain will work better\" => \"ife p r t  et rr   y   r  r r       r   \"\n",
      "batch 12356  loss=142.0771  steps/s=105.95  prediction: \"we need shape rotator models already smh\" => \"  n e   eene  eseeee eee ooeeeoe oeeeeaa\"\n",
      "batch 12357  loss=142.9388  steps/s=101.52  prediction: \"oo, and the school wasn't even built yet\" => \"rd a  a  a a  a                         \"\n",
      "batch 12358  loss=153.3616  steps/s=103.21  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nn t t   l  t      t \"\"\"\"\"              \"\n",
      "batch 12360  loss=139.3104  steps/s=104.84  prediction: \"d segments of the godfather and seinfeld\" => \" be ee eeenn eee e     e  e   e         \"\n",
      "batch 12362  loss=145.9149  steps/s=100.06  prediction: \"f many useful things i can build for ppl\" => \" yl   h   ff            s           i   \"\n",
      "batch 12363  loss=145.5729  steps/s=102.94  prediction: \" of just doing what fundamentally worked\" => \"tf  tn  s ssa t     t       a  na ann aa\"\n",
      "batch 12364  loss=166.5069  steps/s=94.70  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" thtr a nn ni  h a azz azznn   nll tl le\"\n",
      "batch 12366  loss=155.0542  steps/s=102.70  prediction: \"16, now we play the long game https://tâ€¦\" => \"6h n oororrr\n",
      "Trrá´˜@T{xqâ€â˜ xqkxq*ÊœQ{&*{&;ðŸ˜Ž&\"\n",
      "batch 12367  loss=154.6441  steps/s=96.96  prediction: \"free could help too if thats the problem\" => \" e  se u  ue   l    eo o  o     tttttt  \"\n",
      "batch 12368  loss=135.5274  steps/s=100.52  prediction: \" for people who the process filtered for\" => \"@oi      o p  pl                 eeeeeee\"\n",
      "batch 12369  loss=150.7048  steps/s=104.49  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"@oe  vo mi as a  a       t  tt /////////\"\n",
      "batch 12370  loss=149.9481  steps/s=90.16  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \" v s an  n  g  o    ott/tt/////tPP/PPP.s\"\n",
      "batch 12371  loss=150.6547  steps/s=103.19  prediction: \"pany uses it often for researching stuff\" => \"lrt @yinomn m  oo o    o     e  r   r r \"\n",
      "batch 12372  loss=191.2676  steps/s=24.86  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: @ny  om  ~mo n    o  e ee  r   r  f\"\n",
      "batch 12373  loss=183.8826  steps/s=97.71  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"  n  p ny on  ~~t ntt  o ee ee rr   r ff\"\n",
      "batch 12374  loss=144.9262  steps/s=114.58  prediction: \"you should do it, youd learn a ton i bet\" => \":uo   n   u u no o  o   o               \"\n",
      "batch 12375  loss=135.4404  steps/s=99.26  prediction: \" of the tier lists of all time, for sure\" => \"@f   o o n e  t     t   t    l          \"\n",
      "batch 12376  loss=143.0937  steps/s=104.79  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng  oo   n gg nn                 uuuuuu \"\n",
      "batch 12377  loss=212.6576  steps/s=100.17  prediction: \"DE\n",
      "14hrs is wild\n",
      "also james is a gooooat\" => \" Yblul   nE\n",
      " D \n",
      "  ii  \n",
      "ss s     ss ss s \"\n",
      "batch 12378  loss=155.0956  steps/s=101.71  prediction: \"there like this?\n",
      "https://t.co/ZF2p1Q4n6L\" => \" en       tee   eeettttthhtttttttt/t////\"\n",
      "batch 12379  loss=143.5919  steps/s=104.92  prediction: \"re for blundering bc of moving too quick\" => \"eply: @ ,nnh.$ngjT222?jjjj##:kU$.jqUZj2q\"\n",
      "batch 12380  loss=151.2035  steps/s=102.64  prediction: \"i know bedrock api has a chat window too\" => \"nk  o t b on  bb           a   a a      \"\n",
      "batch 12381  loss=152.3750  steps/s=100.04  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"eply  uthen @Aslj@AD7vjjjjgxBE:4xj.UvjEY\"\n",
      "batch 12382  loss=146.2367  steps/s=104.23  prediction: \"rol you. why would they want to do that?\" => \"eble c epheek@rd7{@PN:/Z_N**â˜ EY4É´É´á´›&â€œð—µ..\"\n",
      "batch 12383  loss=147.0664  steps/s=105.69  prediction: \"n a bit and just work later into the day\" => \" rho      ei                      t  t t\"\n",
      "batch 12384  loss=163.3283  steps/s=39.88  prediction: \"ly: @IterIntellectus its white pill week\" => \"y  eiee                      t  t t  t t\"\n",
      "batch 12385  loss=132.6447  steps/s=110.61  prediction: \"ts effortless to read/follow works in it\" => \"  th  e eeteeteteeeee eeeeeoo oooloooooo\"\n",
      "batch 12386  loss=178.5061  steps/s=82.41  prediction: \"yon Super hyped to see what youre cookin\" => \" u' eff efee tete  ee  ooo eewowo  o oo \"\n",
      "batch 12387  loss=151.9311  steps/s=106.48  prediction: \"dable and makes debugging not so bad tbh\" => \" ytrsirr aene  aada aeee gdadggn    g b \"\n",
      "batch 12388  loss=145.3484  steps/s=104.47  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" mid e  mdeemeem eoe tttte t t  ttmtttt \"\n",
      "batch 12389  loss=140.8774  steps/s=105.83  prediction: \"e readme was a good read on ai reasoning\" => \" mods e rhs   a  e   a e    a    a  a aa\"\n",
      "batch 12390  loss=141.4648  steps/s=104.63  prediction: \"anding pages or whatever feels gross idk\" => \"td a    o n n on  g      eee   eeeeee ee\"\n",
      "batch 12391  loss=135.3299  steps/s=104.21  prediction: \" adding the context into the computation\" => \"tnd t   oe \n",
      "  eee ooe e  t nt e te ttttt\"\n",
      "batch 12392  loss=142.8189  steps/s=104.86  prediction: \"ginal returns idea seems to pop up a lot\" => \" nl  ona raa  n   raa  eee es   ee      \"\n",
      "batch 12393  loss=215.5894  steps/s=11.54  prediction: \"reply: @pixqc ok https://t.co/7zZszIGt52\" => \"e is  equn  m_r 52x22://2xx#/7zZqzIGqmq.\"\n",
      "batch 12394  loss=145.4650  steps/s=108.75  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efee  ngoloOv_ lb,A1xxc:/z1\n",
      "OOvZqfIxqzR.\"\n",
      "batch 12396  loss=160.9905  steps/s=104.15  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \" t( bn  d d d   d     i  idddd ddddddddn\"\n",
      "batch 12398  loss=159.5314  steps/s=94.60  prediction: \"xoki How do I know this isnt a lie tho ðŸ¤”\" => \"^k l  s d dd d        d    i    snn  t  \"\n",
      "batch 12399  loss=147.9176  steps/s=103.78  prediction: \"quickly that require a variety of skills\" => \"uireal  iat r rqq  rqq  r rrrar   r  r  \"\n",
      "batch 12400  loss=174.5092  steps/s=102.29  prediction: \"? If so how much https://t.co/W2kuYHIlNP\" => \" dheA  nen ?? e     h  h   h ////t//t//t\"\n",
      "batch 12401  loss=161.8785  steps/s=103.55  prediction: \"o projects, kinda like how momentum does\" => \" me 2 re   t  g  eeet    o    o   ooe mm\"\n",
      "batch 12402  loss=157.9412  steps/s=103.56  prediction: \"uper hard but I think it could be doable\" => \" e  r lr arpe rp rr       t  t        d \"\n",
      "batch 12403  loss=150.7255  steps/s=102.14  prediction: \"ld almost suspect God is on their side..\" => \"y s@ osu sos ss sssss s                 \"\n",
      "batch 12404  loss=147.7051  steps/s=101.08  prediction: \"broth but it tastes awful lol any advice\" => \"eo   ooo bb b t t tttttt tt             \"\n",
      "batch 12405  loss=175.3729  steps/s=98.98  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @m  mo s  st s  sssststttttt///////8\"\n",
      "batch 12406  loss=173.3728  steps/s=34.21  prediction: \"ly: @justalexoki https://t.co/bQLKyhfmhI\" => \"y: @dede s s s s  stsssttttt///t////8888\"\n",
      "batch 12407  loss=145.3421  steps/s=118.54  prediction: \"m like the future too\n",
      "is this mujoco btw\" => \"ewe   o eee teteeeeee  ee   ttt  t   ooo\"\n",
      "batch 12409  loss=132.6757  steps/s=103.23  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"e  b  btttt tt t  t     o      eeeeeeeee\"\n",
      "batch 12410  loss=151.0709  steps/s=103.70  prediction: \"s and $billions\n",
      "\n",
      "https://t.co/JAfCka4QWD\" => \" ao ed ddaeddd       ss ssssssttt/t/////\"\n",
      "batch 12411  loss=217.7200  steps/s=101.27  prediction: \"indie game of the year im calling it now\" => \"n   I    O n ie i  i  e  e e  i  ai  l i\"\n",
      "batch 12412  loss=174.4566  steps/s=101.73  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \" e c tes t ss soo  t o ooooosooooooooooo\"\n",
      "batch 12413  loss=153.4261  steps/s=105.18  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nl t t t t  t h  \"\"\"\"\"\"\"                \"\n",
      "batch 12414  loss=185.8362  steps/s=98.04  prediction: \"s must flow\n",
      "\n",
      "BILLIONS MIST BACKPROPOGATE\" => \" wa   it n sn  tt       IIIIIBBBBSSSSSSP\"\n",
      "batch 12415  loss=174.3547  steps/s=104.03  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"anei  s se sDtf  s \n",
      "\n",
      "  ttt  t\n",
      " st stt/tt\"\n",
      "batch 12416  loss=144.1961  steps/s=104.34  prediction: \"a good way to beat addictions in general\" => \"nfei w  s   ttotooo    a  aa aa   ii    \"\n",
      "batch 12417  loss=164.6704  steps/s=100.91  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" aiag a  y e                            \"\n",
      "batch 12418  loss=198.3914  steps/s=21.35  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @a  e                        i     \"\n",
      "batch 12419  loss=151.8048  steps/s=109.02  prediction: \"for code writing https://t.co/Vlv7kxKPyM\" => \" r    ttb  t        tt   ttttttttttt////\"\n",
      "batch 12420  loss=136.6365  steps/s=105.33  prediction: \" adding the context into the computation\" => \"tnd e   oer\n",
      "o  ee ooe e  t nt e te ttttt\"\n",
      "batch 12421  loss=138.4774  steps/s=102.85  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \" xt b d aa ltt t   eeeeeleeelle\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oo\"\n",
      "batch 12422  loss=144.0860  steps/s=104.91  prediction: \"xample\n",
      "Do this and then train them on it\" => \"tcf of  tt em tt    t    t   t t  t t  t\"\n",
      "batch 12423  loss=152.5643  steps/s=106.35  prediction: \"ed for simple stuff but couldn't handleâ€¦\" => \"   r  sete  r     s      f    uuu  u    \"\n",
      "batch 12424  loss=170.1621  steps/s=89.86  prediction: \"ates Hear me out https://t.co/M8bURSdiT1\" => \"t  w tee seer s e   ut utu  tttt///tt dd\"\n",
      "batch 12425  loss=159.0683  steps/s=105.07  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"toe o  otgoo  e      t  ttttttt/////t///\"\n",
      "batch 12426  loss=157.3406  steps/s=103.35  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"epl : rinqmkBá´yo9jÉªPMTBm@ETBá´›@Eâ™‚já´€kqkvv!\"\n",
      "batch 12427  loss=143.3713  steps/s=104.75  prediction: \"ike the programming skillset example is.\" => \"ne  g   h t   h                  lllllll\"\n",
      "batch 12428  loss=138.3090  steps/s=105.14  prediction: \"file editing program, will show vid soon\" => \" r iti iiniii itiiiii i iii  l l   i    \"\n",
      "batch 12429  loss=180.4431  steps/s=94.95  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \" \n",
      "    eiwiniii  ddm  m  l s ttt    / ooX\"\n",
      "batch 12430  loss=158.0380  steps/s=102.44  prediction: \"ely grinded like mad towards His mission\" => \" la llllen leeel le      d dddd      sss\"\n",
      "batch 12431  loss=144.0727  steps/s=103.00  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \"ga l   o a anaaaa aaaataaaaanannahheeee \"\n",
      "batch 12432  loss=172.9825  steps/s=99.42  prediction: \"OOYAH\n",
      "gl brotha\n",
      "Gonna join you in 6hrs ðŸ«¡\" => \"OO ebn eneOteOr\n",
      "\n",
      "O\n",
      "a\n",
      "\n",
      "\n",
      "nnnnnnnnn   nn   \"\n",
      "batch 12433  loss=160.8300  steps/s=101.70  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"@oreini t enttn tttte ttt ttt t tt/// //\"\n",
      "batch 12434  loss=189.0188  steps/s=100.92  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"ade  e z@on@o @7o@722777222//tt////7///t\"\n",
      "batch 12435  loss=155.8303  steps/s=103.99  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"n s at  sa a  lllll lllllllltttttt///555\"\n",
      "batch 12436  loss=146.7541  steps/s=105.46  prediction: \"icians and is a net negative for society\" => \"n    aaai tti nti         a             \"\n",
      "batch 12437  loss=170.5103  steps/s=94.59  prediction: \"nus9 Thats super useful to know actually\" => \" xteee  a n s    sss e es  e eu   o  o  \"\n",
      "batch 12438  loss=147.6714  steps/s=103.44  prediction: \"sk for, then train them to ask, then act\" => \" e t     at t  t t    t t t    t    t   \"\n",
      "batch 12439  loss=206.7649  steps/s=24.17  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: @t t hn  ,t    ttttt t t  t    t   \"\n",
      "batch 12440  loss=163.3293  steps/s=117.77  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"the rr   e te h  thh th ttth ttt tttttoo\"\n",
      "batch 12441  loss=243.2537  steps/s=11.40  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @aelg o@ evz@OOHAP0vK2fD9CAz6S:MAN\"\n",
      "batch 12442  loss=142.4684  steps/s=106.57  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"heaeino enn n nc ii      ee  e   tette t\"\n",
      "batch 12443  loss=170.8918  steps/s=78.14  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \"sw a teeiigeA gn on  e  eee  tt  ttttttt\"\n",
      "batch 12445  loss=161.8620  steps/s=107.87  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" n    s////k??????????????  ?oo l      n\"\n",
      "batch 12446  loss=208.6026  steps/s=93.71  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"egt ih@L g4 PxTLAPxSWTFS:WTF.:b777:5zD70\"\n",
      "batch 12447  loss=167.6725  steps/s=81.35  prediction: \"amebedan @jaivinwylde stochastic success\" => \"n  ire tss nbiss loF   to  lttsocc/ tcce\"\n",
      "batch 12448  loss=150.2689  steps/s=106.23  prediction: \"nce I did one in django I perma switched\" => \"ge\n",
      "er    cd   n         n       n n     \"\n",
      "batch 12449  loss=148.5085  steps/s=105.07  prediction: \" focus/attention to a negative direction\" => \"tort   s  tt tuuottoottt  ttttttt  t t e\"\n",
      "batch 12450  loss=173.9902  steps/s=101.59  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e, pndi#ei## #c##a#aaaaasssaststt///////\"\n",
      "batch 12451  loss=278.4210  steps/s=18.97  prediction: \"reply: @opaeoh ill lyk when i open it up\" => \"eplet @ wwo.bQggAâ€¦â™‚QXuQ`É´Qá´‡Q`XXá´„{ð—ªá´€wk``â€™\"\n",
      "batch 12452  loss=141.8239  steps/s=109.51  prediction: \"gger stuff, maybe thatll make me faster?\" => \" \n",
      "e to    ig     g      t  t  t   a  a  \"\n",
      "batch 12453  loss=174.7789  steps/s=29.83  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @c  gi ig  g    t   t  t  m   a  ee \"\n",
      "batch 12454  loss=140.8827  steps/s=110.90  prediction: \"on\n",
      "\n",
      "im guessing you do that a lot to huh\" => \"   ta tat  es  ns ss               t    \"\n",
      "batch 12455  loss=151.9685  steps/s=102.73  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r   tpt tt ttn tr      ss rr rrr rr r r\"\n",
      "batch 12456  loss=138.1615  steps/s=105.05  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l nei\n",
      "a   n  o    o    ttt  ttttttttttet\"\n",
      "batch 12457  loss=139.0079  steps/s=105.65  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i i s tt t  e           t  tteeetdtttt\"\n",
      "batch 12459  loss=180.3093  steps/s=86.18  prediction: \"ettler @gizmobly https://t.co/3UPliJk8JG\" => \"  i\n",
      "s se ttit    ttlttttl ttttndtttt ttt\"\n",
      "batch 12460  loss=179.3200  steps/s=103.36  prediction: \"ed_videos Thanks!! Yea I took like 0.3mg\" => \"  t\n",
      "st e iiedoo  ott  !!  !!! e/oo k kkk\"\n",
      "batch 12462  loss=149.5835  steps/s=104.25  prediction: \"ective, its significantly more efficient\" => \" t ti   ceecei eiiiiisiiiiiiiii ii ifffi\"\n",
      "batch 12463  loss=134.6672  steps/s=104.49  prediction: \"assume that had a large effect back then\" => \"tee  ss  s s   s  aaaaaaaaaaa           \"\n",
      "batch 12464  loss=144.5333  steps/s=99.38  prediction: \"ans are measured in centuries. (im ngmi)\" => \"tde se    m aa      eee eeeeeee ee    n \"\n",
      "batch 12465  loss=155.0596  steps/s=104.16  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" hn t t nt nt  o  o  tttttt  tttttot//t/\"\n",
      "batch 12467  loss=161.0177  steps/s=102.46  prediction: \" useful stuff to save hrs of your day ig\" => \"tsi  uN  uuu uufuuu f  f                \"\n",
      "batch 12468  loss=151.2549  steps/s=103.77  prediction: \" the past two months and its so worth it\" => \"thi  ov  teet et   tt     t t t   s  s  \"\n",
      "batch 12469  loss=184.7933  steps/s=105.41  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"/..ofu ::///t:/tt1OtOt11OO/Ot/tttt//tt//\"\n",
      "batch 12470  loss=155.8639  steps/s=100.80  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \"he //hton   n e    t           000000000\"\n",
      "batch 12471  loss=181.2894  steps/s=101.13  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"LIN ILSGGNNLLNALGAAAANALAA    tt//t/////\"\n",
      "batch 12472  loss=148.1249  steps/s=103.14  prediction: \"y clip of polnareff LBJing up the stairs\" => \":miaihg  a                              \"\n",
      "batch 12475  loss=173.8949  steps/s=96.70  prediction: \"0x_0 how is crypto this good at replying\" => \"x Br0sr0xneeh@we7F@0x_7v0x_0000Pv\"IGNA\"I\"\n",
      "batch 12476  loss=180.3539  steps/s=66.11  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"aeyie0l_ t tc rp co  pi   oo  tt  oo  o \"\n",
      "batch 12477  loss=155.3372  steps/s=106.84  prediction: \"darin and english which they are meh at)\" => \" yn  em  anae n nn nn n      h hh hh h  \"\n",
      "batch 12479  loss=152.1230  steps/s=99.40  prediction: \"Building scratch from scratch in scratch\" => \"  cicmi m iiniu   r ccccchc crcr cc  ccc\"\n",
      "batch 12480  loss=196.9570  steps/s=18.60  prediction: \"eply: @Laz4rz glad you brought the stuff\" => \" ly: @i deri iu   r cccccrc c cr cc  ccc\"\n",
      "batch 12481  loss=155.5621  steps/s=141.71  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"  ae   ddnnn mm m om   m   e        a   \"\n",
      "batch 12482  loss=147.5287  steps/s=105.17  prediction: \"y its been a useful learning experience?\" => \":is eca  sy s     u   euee   eeee  eeeee\"\n",
      "batch 12483  loss=174.3894  steps/s=104.25  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"aCnaariii ii_ik__@___777i i7777  7iii i \"\n",
      "batch 12484  loss=151.3049  steps/s=99.42  prediction: \"om gpt10 how strong could you make gpt2?\" => \"u    a ttet t            oo o ooo       \"\n",
      "batch 12485  loss=146.3177  steps/s=102.74  prediction: \"onscious does work in the background idk\" => \"u y esb b ssooosooooso   s       k    k \"\n",
      "batch 12486  loss=141.5693  steps/s=101.35  prediction: \"ant believe I havent been napping before\" => \"nd oto   e d  e ee eee eeeeeeeeenennnnnn\"\n",
      "batch 12487  loss=146.6319  steps/s=103.90  prediction: \"I figure if we just do it, ppl will join\" => \"Gwuldbiuddiiiii                         \"\n",
      "batch 12488  loss=140.5688  steps/s=105.11  prediction: \"of those bc there are uncountably many c\" => \"n  abn nnaob                  e     a  a\"\n",
      "batch 12489  loss=169.4746  steps/s=104.01  prediction: \"our gpt api key\n",
      "\n",
      "https://t.co/qBtIejDpHA\" => \"usd i   d dp      p   p pppttttt/tttt///\"\n",
      "batch 12490  loss=142.8920  steps/s=104.01  prediction: \"r coding lol. And some chess. Great move\" => \"es  mpeeyew h$nt7/$$($$k$$$vW:$v($.1AA$)\"\n",
      "batch 12491  loss=150.1221  steps/s=103.13  prediction: \"tebooks with 45 cells each, 4 docker imâ€¦\" => \" d se  oonoenoon  o         e        e  \"\n",
      "batch 12492  loss=168.0984  steps/s=98.94  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \" pS io      \"\"e    t ttttttttttstttst///\"\n",
      "batch 12493  loss=156.3422  steps/s=84.72  prediction: \"almost as bad as jan blocking his bishop\" => \"nl t l let l  s  s   a as   s a  i iiiih\"\n",
      "batch 12494  loss=147.0990  steps/s=106.37  prediction: \"d at that too\n",
      "\n",
      "Get skilled w both id say\" => \" te  g   g tttttttttttttttt             \"\n",
      "batch 12495  loss=160.1809  steps/s=101.76  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"as t  t  i l ii      i    tt tttt/t/////\"\n",
      "batch 12496  loss=166.7497  steps/s=100.60  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" Bi  l  @iAl   @AAtttttttttooooooooo   o\"\n",
      "batch 12497  loss=143.8720  steps/s=104.95  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"ete s p, ta e4y,@!PS!kj(SATj@k3(y-YqNO),\"\n",
      "batch 12498  loss=146.0220  steps/s=104.87  prediction: \"der the hood the better you can innovate\" => \" rnt n   nn n ehhheh  tteeet e e      o \"\n",
      "batch 12499  loss=143.2048  steps/s=104.12  prediction: \"f time and space that can reach in here?\" => \" ii  o        e  e       a  aaaa a      \"\n",
      "batch 12500  loss=172.3660  steps/s=104.28  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \" fo  O   m  m   m  tt tttttttttttttt////\"\n",
      "batch 12501  loss=137.4723  steps/s=104.45  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" ar aan  aern  aa aaa    a sssss//tt////\"\n",
      "batch 12502  loss=159.8132  steps/s=99.10  prediction: \"s message is NOT approved by square gang\" => \" mhta n sms s \n",
      "\n",
      "sse es p pp  ppo  pppr e\"\n",
      "batch 12503  loss=187.1693  steps/s=22.00  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: @g smee  essse es p pp  pp   pp r e\"\n",
      "batch 12504  loss=169.2187  steps/s=138.28  prediction: \"uff @allgarbled Ah, true, nice inversion\" => \" f tsi t ftf f l aa   ae  e       e e ee\"\n",
      "batch 12505  loss=156.3969  steps/s=98.05  prediction: \"em man, I had to share, its a crazy tool\" => \"  p no  oa                a   a       a \"\n",
      "batch 12506  loss=165.4969  steps/s=101.64  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tunc lc geggcgu7  222222272t7tt/////tt//\"\n",
      "batch 12507  loss=145.1589  steps/s=104.91  prediction: \"it seems like using a spoon vs a scalpel\" => \"n oos    ele es ee  e s      ss  ss    s\"\n",
      "batch 12508  loss=145.0431  steps/s=105.22  prediction: \"that can run for under $1000 of compute?\" => \"he s a tt thttn      n     r     0000000\"\n",
      "batch 12509  loss=159.8168  steps/s=102.82  prediction: \"mewhat relevant:\n",
      "https://t.co/USV0L8wnT8\" => \"eth ea  se em eeeeeeeeettttttttttttt/t//\"\n",
      "batch 12510  loss=180.5046  steps/s=97.58  prediction: \"rs: John 14:6-14 https://t.co/37ryh1InfG\" => \"eta : e :  _hxY 4!6-yJ5OWy04$6-14y5I37Gk\"\n",
      "batch 12511  loss=159.2474  steps/s=100.17  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" se       n               o             \"\n",
      "batch 12512  loss=146.5943  steps/s=103.01  prediction: \"ns the returns are high on more of it :)\" => \" t s  he hse  t ese re      hh  rr      \"\n",
      "batch 12513  loss=145.7436  steps/s=103.72  prediction: \"ttin you do all that stuff, drop out etc\" => \"he e   et uytt t    t t    ttt t  t t  t\"\n",
      "batch 12514  loss=126.3496  steps/s=103.47  prediction: \"veryone in the past was a caveman/moron\"\" => \"e  a   enee een ee             aaaaaaaaa\"\n",
      "batch 12515  loss=140.9988  steps/s=105.06  prediction: \"nd me tracks and ill render them for you\" => \"   een  n   n                           \"\n",
      "batch 12516  loss=138.5410  steps/s=102.96  prediction: \"o him) and he begged to pay me to use it\" => \" al   t n nin hn                        \"\n",
      "batch 12517  loss=141.3687  steps/s=106.28  prediction: \"\n",
      "shit like this: https://t.co/Z4JE4KMgHs\" => \"\n",
      "oos  i   g ec  AI:I\"I//f'/:'(Z4JZ:JEHKM\"\n",
      "batch 12518  loss=179.2344  steps/s=97.95  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"he    r  ht/////  HHHHHHHHQ..p...Bpp=p==\"\n",
      "batch 12520  loss=153.9884  steps/s=105.96  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o   m    ee  ee ee r    e  e      we ee\"\n",
      "batch 12521  loss=147.2321  steps/s=103.15  prediction: \"n is a great way to beat some addictions\" => \"gtwoe n   t tst tttt    a  t  aa   aaa  \"\n",
      "batch 12522  loss=135.2988  steps/s=102.98  prediction: \" is it some kind of info storage system?\" => \"tt t, ittessi gi  i    i       o    o   \"\n",
      "batch 12523  loss=143.6552  steps/s=104.79  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"iu  h D  n    t t    ttttttttttttt//t//t\"\n",
      "batch 12525  loss=148.8375  steps/s=103.70  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"ie eee een  le lee   ee    e            \"\n",
      "batch 12526  loss=145.8948  steps/s=105.59  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"omeedr seteter  tttt........t.....tt////\"\n",
      "batch 12527  loss=148.5219  steps/s=105.20  prediction: \"kind of just whatever I want to pivot to\" => \"enn  r  ir  iti t    e     t ett  t  v t\"\n",
      "batch 12528  loss=183.9383  steps/s=104.42  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns      n   n      t t ttt  tttttt////t/\"\n",
      "batch 12529  loss=152.4834  steps/s=102.24  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"ll  @  ee p p pp  ee    e  e eee eec c  \"\n",
      "batch 12530  loss=142.0555  steps/s=99.72  prediction: \"ood and helps you not waste future years\" => \"rd      o                    o         e\"\n",
      "batch 12531  loss=140.2967  steps/s=104.57  prediction: \" resulting in a cool, weird type of game\" => \"tataeee t tnr rne ii l     ii    i      \"\n",
      "batch 12532  loss=161.9426  steps/s=99.67  prediction: \"day night and posted this sunday morning\" => \" ta  e  iadi t na d nd   dt   sttd d d s\"\n",
      "batch 12533  loss=136.3656  steps/s=98.30  prediction: \" of the tier lists of all time, for sure\" => \"tf   e   n e  n  e  t        s          \"\n",
      "batch 12535  loss=143.2372  steps/s=104.15  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" iret  aa    a a   a aa       t     t  i\"\n",
      "batch 12536  loss=149.4266  steps/s=104.88  prediction: \"mped billions/decades into w no solution\" => \"elllemb   ddee d ddeedd idded d    o oo \"\n",
      "batch 12537  loss=145.5424  steps/s=100.40  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" le esnaads ssaeeaea a  nn  nnnn n     i\"\n",
      "batch 12538  loss=146.0167  steps/s=101.80  prediction: \"custom extension to watch yt on 4x speed\" => \"onlM      te  u ttttt t tt   tttt t     \"\n",
      "batch 12539  loss=143.9690  steps/s=104.71  prediction: \"y, gpt 4o was bad at the first iteration\" => \"  i e t na    a   a      a       t  t tt\"\n",
      "batch 12540  loss=165.2261  steps/s=101.74  prediction: \"prob 2.5M tokens\n",
      "https://t.co/6FbmJG4MmF\" => \"lotl@ 2 os              ttttttttt/t/////\"\n",
      "batch 12541  loss=155.2594  steps/s=105.08  prediction: \"d some stuff!!!!\n",
      "https://t.co/160qafZKAk\" => \" ts   ts ss  s!!!!!!!!!!tttttts/tt/tt///\"\n",
      "batch 12542  loss=135.6114  steps/s=103.70  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" s  e s e etee  e               ot t  t \"\n",
      "batch 12543  loss=142.7664  steps/s=103.01  prediction: \"e transformer architecture works so well\" => \" ae     n  n  n rr rrrrrrrrrrrrrrrrrrre \"\n",
      "batch 12544  loss=219.1302  steps/s=95.97  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"  ht taaraekrrS@ei  ININNIINININO  OOOO \"\n",
      "batch 12545  loss=138.6353  steps/s=103.24  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e    t  ta a  e   e   ththhttttth/t/t///\"\n",
      "batch 12547  loss=165.3244  steps/s=72.68  prediction: \"aulg We like memoizing physical patterns\" => \"nt ao  e le r  oehe ttttthht//tt///ttKpK\"\n",
      "batch 12548  loss=154.2139  steps/s=104.29  prediction: \"plex projects in it but it was super fun\" => \"ly  @p e  eee cce  e                    \"\n",
      "batch 12550  loss=154.5130  steps/s=104.22  prediction: \"leneck is my lack of knowledge of opengl\" => \"yvtutteeet  ttne e        kkko       ooe\"\n",
      "batch 12551  loss=156.8821  steps/s=97.28  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \"  oto   t       t  ttttt tttt tttt/VVV/V\"\n",
      "batch 12552  loss=164.4171  steps/s=104.09  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"ne  oi   n     d     d        r     DTTT\"\n",
      "batch 12553  loss=152.9322  steps/s=98.52  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" ad e e  r  t ttt    t     j  j    yy yo\"\n",
      "batch 12554  loss=182.0253  steps/s=82.85  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \" lco llhuut t u      t     yoyoo  oooo o\"\n",
      "batch 12556  loss=154.8503  steps/s=72.08  prediction: \"@calbch its gonna be a good one for sure\" => \"laororlilh @iig   t  t e  /ooo///o ooo8ðŸ›‘\"\n",
      "batch 12558  loss=141.6534  steps/s=105.61  prediction: \" fly everywhere\n",
      "\n",
      "idk how lidar works btw\" => \"tiihh  t  ee  vveeeeeeeee e      ww   ww\"\n",
      "batch 12559  loss=176.1138  steps/s=96.27  prediction: \" was truly L tier. not L tier but L tier\" => \"ta  re t  wwr rrr  r   L L  LL   L  LL L\"\n",
      "batch 12560  loss=159.7246  steps/s=96.01  prediction: \"hess isnt hard just make the right moves\" => \"e   onisss n sss   t s t  t    t e  it  \"\n",
      "batch 12561  loss=137.2249  steps/s=101.67  prediction: \"or a site with a manipulatable algorithm\" => \" _   on ooo   a       a  aaaaa a aaaaaaa\"\n",
      "batch 12562  loss=142.1304  steps/s=103.60  prediction: \"zations seem like they could be improved\" => \"mrsll  e rr d_n 7'$7.zFDj.WFZ4Szz$,$kj.'\"\n",
      "batch 12563  loss=168.6026  steps/s=73.15  prediction: \"izmobly circle gang is TRULY unstoppable\" => \"natiitii niee iiil  e e    e  e       oe\"\n",
      "batch 12564  loss=142.8342  steps/s=105.95  prediction: \"ite complexity? If not, what is the max?\" => \"niin  ii  in iitiii i                   \"\n",
      "batch 12566  loss=156.8290  steps/s=102.44  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" m  o   wd d  o    o   ooooo  o     f   \"\n",
      "batch 12567  loss=134.6843  steps/s=100.18  prediction: \"answer in as few characters as possible\"\" => \"nd tt mssss s            aaa aaaa s ssss\"\n",
      "batch 12568  loss=206.0837  steps/s=22.20  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: @sseees   s       aaaaa aaaasssssss\"\n",
      "batch 12569  loss=197.7444  steps/s=63.92  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: @ssseee  es    aaaaaaaaaaaassssssss\"\n",
      "batch 12570  loss=155.3391  steps/s=114.28  prediction: \"of learning is learning from the past ig\" => \"r a eda neafnnaen n n nan nnn n    r    \"\n",
      "batch 12571  loss=142.1030  steps/s=104.30  prediction: \"pl make it interesting/fun/useful? dunno\" => \"le: e   nh n        e teeteeennnnnenunnu\"\n",
      "batch 12572  loss=148.6351  steps/s=103.80  prediction: \"nd stop you from seeking rewards in life\" => \"  ,eos d n y  u   o   o        r        \"\n",
      "batch 12573  loss=146.8042  steps/s=104.64  prediction: \"lay this game\n",
      "\n",
      "happy wheels was gold too\" => \"yy  l n t te  \n",
      " t  a   ppppppe e        \"\n",
      "batch 12574  loss=159.7537  steps/s=92.41  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \" k ll   tl ema aaayaa hhhh   h       e  \"\n",
      "batch 12576  loss=217.4928  steps/s=100.94  prediction: \"ETURNS\n",
      "Wb wb. Great zig project idea btw\" => \"  NGET@ eHoULWSoWD.IG.DGzSzURzSj.jG\n",
      "j.cG\"\n",
      "batch 12577  loss=148.7754  steps/s=104.07  prediction: \"sed to sound like the opposite of curses\" => \" r lelt lld s s           o  o   ooo  o \"\n",
      "batch 12580  loss=149.4418  steps/s=104.61  prediction: \"rflowsucks and never went on there again\" => \"eao   n i   kYgeZYIYWYQYZQ12ZZ999=Q=====\"\n",
      "batch 12581  loss=145.8721  steps/s=102.30  prediction: \"s\n",
      "\n",
      "so super frictionless, it sounds like\" => \" \n",
      "i   e  net sn  ssr sss ss ss  sssss ss\"\n",
      "batch 12582  loss=143.5304  steps/s=103.27  prediction: \"ppl who got rich playing 0 sum games tho\" => \"lls  e   t t  o        p                \"\n",
      "batch 12583  loss=146.3538  steps/s=102.72  prediction: \"worst part, as demonstrated by the graph\" => \"ard    teh tttt   t      ttt ttt ttt   t\"\n",
      "batch 12584  loss=138.3047  steps/s=104.35  prediction: \". some, years later, have paid off a ton\" => \" if s  sesseeeeseeeeeeeeeeeeaaa a       \"\n",
      "batch 12585  loss=147.1070  steps/s=103.75  prediction: \"c too much attention + hasnt been solved\" => \"oslie     tt  ttt  tt t tttt     n    n \"\n",
      "batch 12586  loss=169.1068  steps/s=91.03  prediction: \"ownbad Sweet! Glad it worked, which one?\" => \"n  t oa   b ttStt tt    aa t     n n  e \"\n",
      "batch 12588  loss=147.3829  steps/s=104.66  prediction: \"snt, now i think and focus waaaay better\" => \" ee tttt t   t            n     aaa aaa \"\n",
      "batch 12589  loss=260.4957  steps/s=11.54  prediction: \"reply: @IterIntellectus no i forgot srry\" => \"eply: @ ohceevh W-vYWYx!bGIxIR-I9k=I=kqq\"\n",
      "batch 12590  loss=159.3845  steps/s=111.23  prediction: \"e in milan venice florence.. sorrento rn\" => \" to  onnn\n",
      "li  n inni nnnnnne  e  eeee.e \"\n",
      "batch 12591  loss=155.5770  steps/s=102.53  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"E  sd ,       YH    s???????ts////t////B\"\n",
      "batch 12592  loss=148.4762  steps/s=98.99  prediction: \" ill dm you a link to it around the 25th\" => \"tn e eeee te   l                o  t t  \"\n",
      "batch 12594  loss=144.9384  steps/s=104.49  prediction: \"icians and is a net negative for society\" => \"n   idtai tnia na         a             \"\n",
      "batch 12596  loss=199.8663  steps/s=46.56  prediction: \"y: @BenjaminDEKR https://t.co/XKzK1sR0d2\" => \"  @didtaniiiia$$          t            e\"\n",
      "batch 12597  loss=140.8927  steps/s=106.75  prediction: \"this. or you can win by trading seats wâ€¦\" => \" e  u   n n   n                         \"\n",
      "batch 12598  loss=140.7115  steps/s=104.93  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  ie    n   in                        \"\n",
      "batch 12599  loss=162.5403  steps/s=97.82  prediction: \"an!\n",
      "Gpt 4o came in clutch for the images\" => \"nd thei  nnan     a      cccccc         \"\n",
      "batch 12600  loss=142.9203  steps/s=104.02  prediction: \"cy and then work up to really short ones\" => \"o  i tt ennn ne n                       \"\n",
      "batch 12601  loss=163.5947  steps/s=98.10  prediction: \"e huge win, and yeah consistency is king\" => \" to !!!!g! gg eg              n n nnn nn\"\n",
      "batch 12602  loss=141.9591  steps/s=101.27  prediction: \" fast, only clear the bushes in your way\" => \"tun net te g   n     e    e     e       \"\n",
      "batch 12603  loss=158.8952  steps/s=79.32  prediction: \"kaysh No I have to run the code manually\" => \"il0  n  n  en  l   e      e    e   u    \"\n",
      "batch 12604  loss=179.7682  steps/s=105.36  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tf tsc n   lt        ttttttttttt////////\"\n",
      "batch 12606  loss=149.9752  steps/s=102.07  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" oflea a  an  re e     t   ttttt////t///\"\n",
      "batch 12607  loss=150.1279  steps/s=104.66  prediction: \"d of just putting in more and more hours\" => \" is  iii i n  ttt tttt t                \"\n",
      "batch 12609  loss=162.2843  steps/s=105.21  prediction: \"esponses\n",
      "4 repeat step 3 til you have 1â€¦\" => \" s gt  esssesssseeeesseeeee e  e        \"\n",
      "batch 12610  loss=206.7400  steps/s=17.88  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @nee es sseeseesseeeee e  e        \"\n",
      "batch 12612  loss=143.2923  steps/s=110.02  prediction: \"tups are hidden in the fog 2 moves ahead\" => \"hrnf f stes    tts                     e\"\n",
      "batch 12614  loss=184.0532  steps/s=87.14  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"ut ottstoa s  ai   OO e OO  e  e  o   ea\"\n",
      "batch 12615  loss=150.8600  steps/s=104.72  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"ut ootee  tet ut    a aoaoo ooaa oabbba\n",
      "\"\n",
      "batch 12617  loss=143.4217  steps/s=101.89  prediction: \"for getting me to read this btw, its fun\" => \" roo    r  t  tet n    t  e  t      t ts\"\n",
      "batch 12618  loss=144.2869  steps/s=104.25  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" ti     d dd  d                         \"\n",
      "batch 12620  loss=153.2713  steps/s=102.90  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"tanton em m   d    ee                   \"\n",
      "batch 12621  loss=152.9942  steps/s=101.44  prediction: \"n theres ppl who dont code like this????\" => \" j \n",
      " y  reeen enee eee           ooo  oo\"\n",
      "batch 12622  loss=173.9468  steps/s=51.76  prediction: \": @ns123abc meet only one of her parents\" => \" @ooumannihhhIr vTWkwjwb)O&2I;AzjM:xLvkw\"\n",
      "batch 12623  loss=229.0845  steps/s=20.88  prediction: \"reply: @yacineMTB google necessary being\" => \"eply: @n n 3hWg1vTWkwjwb)O&2I;AzjM:xLvkw\"\n",
      "batch 12624  loss=149.8935  steps/s=158.17  prediction: \"us im in, gonna do this rn, on the rocks\" => \"t an un  aa   nn o nnn oon       t   rn \"\n",
      "batch 12625  loss=143.5285  steps/s=103.30  prediction: \"erfect timing actually if thats the case\" => \"pein  tttetteitttitttiti  t  t      t t \"\n",
      "batch 12626  loss=160.9451  steps/s=101.98  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"e ei Ro norloo  oololl oo     uf uufuf u\"\n",
      "batch 12627  loss=144.4237  steps/s=103.63  prediction: \", increases both HP and MP significantly\" => \" wnk e  er teeeeeee ee         PPP  i  i\"\n",
      "batch 12628  loss=156.6246  steps/s=101.36  prediction: \"ve not! Will look tho sounds interesting\" => \"e eo   e n en    l  l lo  oolo   ooo t  \"\n",
      "batch 12629  loss=151.5103  steps/s=102.55  prediction: \"your .env and fill it out\n",
      "\n",
      "then it works\" => \":ur  cnn ann  en   n             t    tt\"\n",
      "batch 12630  loss=151.7589  steps/s=103.66  prediction: \"makes it an order of magnitude harder...\" => \"eye  a  t  ai               o        rdd\"\n",
      "batch 12631  loss=153.0332  steps/s=98.81  prediction: \"ezm progressive overload builds strength\" => \" \n",
      "mn omo m en  rero ee o    odd dd d r..\"\n",
      "batch 12632  loss=143.5849  steps/s=104.95  prediction: \"tention/effort with no results. Not easy\" => \" r  is tteenettettttttttt t    t  o t  t\"\n",
      "batch 12633  loss=136.8043  steps/s=103.33  prediction: \"mals have uncanny valley detection genes\" => \"altio   sssi  a   aaaaaaaaanaaaen eeeene\"\n",
      "batch 12634  loss=136.6981  steps/s=103.53  prediction: \"o make a comeback. would be great to see\" => \" seeo e  o e  n  e                      \"\n",
      "batch 12635  loss=160.0021  steps/s=104.12  prediction: \"re. Turns out it actually had a solution\" => \"eplet e  ig TUn IbUU\n",
      "'hv(5)())5z,pOvOV\n",
      "(\"\n",
      "batch 12636  loss=137.5091  steps/s=101.26  prediction: \"th itself but couldnt figure out how lol\" => \" e t   t t t tett      t   t   uuu u  u \"\n",
      "batch 12637  loss=188.7404  steps/s=89.04  prediction: \"gABAP @yacineMTB https://t.co/NDBKphrBEW\" => \" BAt   ewiteA      t   t   tttt /// oooo\"\n",
      "batch 12638  loss=147.4400  steps/s=105.04  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"y    a nnaan a aa    ttstttttttt////ttt/\"\n",
      "batch 12639  loss=141.0015  steps/s=104.52  prediction: \"d stuff just happens. stochastic winning\" => \" syo     d  t nt        sssssssssssssssn\"\n",
      "batch 12640  loss=130.1675  steps/s=102.62  prediction: \" --. .. ...- . / -.-- --- ..- / ..- .--.\" => \"@-  . - ...........-. -----------      .\"\n",
      "batch 12641  loss=175.4086  steps/s=98.25  prediction: \"eaply making synthetic training data? :)\" => \" se  n   na n  annna nnnn nnniinntiiiia \"\n",
      "batch 12642  loss=165.9638  steps/s=102.36  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"   - -ch  nanaaan aaaa   iaaaad  aaaldd \"\n",
      "batch 12644  loss=139.5474  steps/s=105.89  prediction: \"evelopment speed\n",
      "https://t.co/YNvpK7QsyT\" => \" e e    ten teneeeeeeeepeeettttttttt////\"\n",
      "batch 12645  loss=196.6768  steps/s=93.03  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"t.dp tpte////eeeettttttttt///////////t//\"\n",
      "batch 12646  loss=153.8278  steps/s=101.46  prediction: \"y\n",
      "\n",
      "gotta tie everything back to the goal\" => \":\n",
      " pozeetetttteteeettettttttet ttt t t  \"\n",
      "batch 12647  loss=174.9189  steps/s=101.70  prediction: \"ost valuable RESOURCE\n",
      "\n",
      "damn i need sleep\" => \"ut orto to  suuH  RR RREEEREEC a    e  l\"\n",
      "batch 12648  loss=144.6889  steps/s=101.00  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"to  u u sw                  s s    s h  \"\n",
      "batch 12649  loss=267.1807  steps/s=11.73  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @geBePgá´„nRPSOUzCá´‡[kÊœKmKUð—¼â€[[[vâ€^{`\"\n",
      "batch 12650  loss=168.5252  steps/s=130.98  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \"qy Heibe g @ i ih hh thhthtttttt tt tt//\"\n",
      "batch 12651  loss=144.4615  steps/s=103.39  prediction: \"ady tired or computing incentives better\" => \"ne oo e eyreyrr r r         i iiiiiniiei\"\n",
      "batch 12652  loss=148.8255  steps/s=105.16  prediction: \"and notice way more over time\n",
      "I suspectâ€¦\" => \"n  nete  n  ntt     e   e   e  e e e  e \"\n",
      "batch 12653  loss=158.8044  steps/s=105.41  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  dt ee;gtgge&eg;trttttttttoo oo    ot  \"\n",
      "batch 12655  loss=138.3067  steps/s=105.31  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  itt ett tb  be       i   i       d  d \"\n",
      "batch 12656  loss=159.7085  steps/s=101.13  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" oe   a te g      o    o   ttttttt//////\"\n",
      "batch 12657  loss=156.4709  steps/s=104.58  prediction: \" still use the ideas several times a day\" => \"toi   a       lss   s s   eessse seee  e\"\n",
      "batch 12658  loss=162.1883  steps/s=98.39  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"ne l d a ne f ane ae aaeaa a    ra      \"\n",
      "batch 12660  loss=145.5507  steps/s=104.12  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  luo e e e eeneeeeeeeeepetettttptt/////\"\n",
      "batch 12661  loss=135.8464  steps/s=103.86  prediction: \"g us to blow our fears out of proportion\" => \" te e  s as s                  ooooooooo\"\n",
      "batch 12662  loss=168.6331  steps/s=79.31  prediction: \"minus9 hmm still pixels on my end, weird\" => \"ane  t s i          o     oo    o  o oor\"\n",
      "batch 12663  loss=139.3404  steps/s=105.69  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"un  ppp oo o   n    eeee e eeee         \"\n",
      "batch 12664  loss=157.9457  steps/s=101.80  prediction: \"f flipped around https://t.co/tQfmcgFqBM\" => \" ih  ti  pfefpeepppppppppptttttttttt////\"\n",
      "batch 12665  loss=154.2941  steps/s=45.91  prediction: \"y: @Nominus9 So no chess players, got it\" => \": @pazippfpffpfd   pppt ppttttt/t/tt/tt/\"\n",
      "batch 12666  loss=146.8524  steps/s=114.86  prediction: \"ly pretending to give unsolicited advice\" => \"y: @g e e rteeht ee  t     e n eii  iii \"\n",
      "batch 12668  loss=135.7603  steps/s=105.49  prediction: \"i is a smart idea to pitch to the public\" => \"nw s   o                    t   tt ttt  \"\n",
      "batch 12670  loss=139.9226  steps/s=104.43  prediction: \" information for improvement, like above\" => \"ts    a ennan fooooo ioiooooomommmmm  ee\"\n",
      "batch 12671  loss=148.0580  steps/s=106.24  prediction: \"erIntellectus the italians have returned\" => \" eslorattten teeetttt  tet   ttie aeaeee\"\n",
      "batch 12672  loss=150.4951  steps/s=77.87  prediction: \"ochenko curious, can you elaborate more?\" => \"uet eIbeectnnt e itttl   a a aaaeaaarere\"\n",
      "batch 12673  loss=161.6424  steps/s=107.08  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"the rr   e te h  toh th ttthhttt /tttoo/\"\n",
      "batch 12675  loss=148.7527  steps/s=103.85  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toedee etdetdede     e eI IICICIICCn nnn\"\n",
      "batch 12676  loss=147.1276  steps/s=103.69  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" oi fo aae b af abababb   aaaa a aaaaaaa\"\n",
      "batch 12677  loss=161.6128  steps/s=91.58  prediction: \"neMTB @justalexoki the rise of carmacine\" => \" ell fl se\n",
      "f  \"baoall   a    e   aaaaacc\"\n",
      "batch 12678  loss=153.8546  steps/s=101.28  prediction: \"s every time I'm getting comfortable lol\" => \" oi yr m  erm r eee ee e  tmm   m tett  \"\n",
      "batch 12679  loss=143.0802  steps/s=104.99  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yst  s aemm m m llllel llsllllssstt/t///\"\n",
      "batch 12680  loss=150.3811  steps/s=102.44  prediction: \"tebooks with 45 cells each, 4 docker imâ€¦\" => \" d te  oenoenoot  o         e    4   e  \"\n",
      "batch 12682  loss=165.6744  steps/s=84.87  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yuehtneoobo      .   ...  h    c/cc c   \"\n",
      "batch 12683  loss=145.9334  steps/s=105.36  prediction: \"llows you to better descend the gradient\" => \"y s  wolww llol o   o   e  e   e  eeee t\"\n",
      "batch 12685  loss=166.7810  steps/s=103.38  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"to d n   i!!t !!!!!!!!t!!tttttttt  ///tt\"\n",
      "batch 12686  loss=140.0122  steps/s=105.28  prediction: \". some, years later, have paid off a ton\" => \" i    tse seeeeseeeeeeeeeeeeaaa a  a    \"\n",
      "batch 12687  loss=145.0338  steps/s=103.94  prediction: \" and use it on everything\n",
      "\n",
      "epiphany trap\" => \"tnd  t  tn tn a   e     ee ee  neeeeeenn\"\n",
      "batch 12688  loss=143.3728  steps/s=101.34  prediction: \"han automating friction out of your work\" => \"en te   enen tt  tn itttiiitii   ot  o o\"\n",
      "batch 12689  loss=143.7312  steps/s=104.91  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"tepdonigggg giigiiiiii########e##SSSeeee\"\n",
      "batch 12690  loss=179.5488  steps/s=97.09  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \" u Be c 77  e   aee eee  t sette t//iii/\"\n",
      "batch 12691  loss=147.7838  steps/s=104.58  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"epl s @tcitnsQge8:,fðŸ˜‰V)v,9k|ðŸ¤·wqá´˜kð—¯*8:F8,\"\n",
      "batch 12692  loss=149.4903  steps/s=105.14  prediction: \"having kids, etc) may be only palliative\" => \"en   aa     i h i   i                  l\"\n",
      "batch 12693  loss=152.0504  steps/s=105.30  prediction: \"uth is the global maxima strat long term\" => \"s ite ti  th t tt t      a   aaaaaaaaa t\"\n",
      "batch 12694  loss=157.1834  steps/s=97.37  prediction: \"us @yacineMTB nonononononononononononono\" => \"st ts iie e   gn n  oaononoonononoononon\"\n",
      "batch 12695  loss=148.3740  steps/s=104.72  prediction: \" exercise days, and just work a bit less\" => \"txe e menaenee s                        \"\n",
      "batch 12696  loss=153.2733  steps/s=106.41  prediction: \"k checked him out, followed, thanks mate\" => \" ig o    chk kuc    h       ooo     o,  \"\n",
      "batch 12699  loss=145.6110  steps/s=96.48  prediction: \"gonna code to one song and one song only\" => \" a    in nn n nn o oo ooo   nn  o   nnno\"\n",
      "batch 12700  loss=145.5716  steps/s=105.27  prediction: \"imize model performance (we are talkingâ€¦\" => \"ni        im m eeememoeemeeee eee eeee e\"\n",
      "batch 12701  loss=204.5757  steps/s=96.43  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"i  exi  EEEEEEROOOOOOOOOOO a  ww w w    \"\n",
      "batch 12702  loss=161.5104  steps/s=99.51  prediction: \"ncredibly mesmerizing to watch. dang bro\" => \" eeg e ieii eer emeeeemi   e     t    t \"\n",
      "batch 12703  loss=173.0469  steps/s=30.97  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: @e iniiiieemeieeee i              t \"\n",
      "batch 12705  loss=152.4551  steps/s=119.20  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \"  ieeeeeesede s     e                   \"\n",
      "batch 12706  loss=150.5296  steps/s=100.37  prediction: \"lity is really really powerful, actually\" => \"ykeiBA ii iii i   llll lllllyrlll    lll\"\n",
      "batch 12707  loss=151.0659  steps/s=103.92  prediction: \"n i did eventually. hypothesis confirmed\" => \" m  ee  tede  nnd   nn    eee   e    iei\"\n",
      "batch 12708  loss=140.7200  steps/s=103.96  prediction: \"n for games (more encouraging?) but canâ€¦\" => \" p sot     tP n   o     e   ooroggggg   \"\n",
      "batch 12709  loss=164.8246  steps/s=104.12  prediction: \"n `AI(short prompt)-&gt;output` programs\" => \"gadsttr s  `  r        ttttttpttttptttpt\"\n",
      "batch 12710  loss=146.1122  steps/s=103.30  prediction: \"f scummy people getting more money/power\" => \" t haer  e     meeee eeeeee     me meeoe\"\n",
      "batch 12711  loss=142.3864  steps/s=104.28  prediction: \"ession youll do something until its done\" => \"  le  peppeeperl  ooooooooooo      i    \"\n",
      "batch 12712  loss=175.2938  steps/s=30.25  prediction: \"ply: @calbch do it\n",
      "i double dog dare you\" => \"le  @e i eeepollo oooooooo  o  i i i    \"\n",
      "batch 12713  loss=201.0804  steps/s=123.78  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"the eaee    T TTTT T  OOOOO  t /////////\"\n",
      "batch 12714  loss=142.6502  steps/s=103.37  prediction: \"he actual serious dangers of being smart\" => \"er .o n  a    ua    a  aa      s      s \"\n",
      "batch 12715  loss=145.3958  steps/s=103.11  prediction: \"like a really really interesting project\" => \"yte see sleeele llellle lllleeeee errere\"\n",
      "batch 12716  loss=134.0693  steps/s=103.75  prediction: \"int as fast as possible on loop, idk tho\" => \"ng  a p p  ps pa   sss sss  ss  o ooo  o\"\n",
      "batch 12717  loss=199.6951  steps/s=20.93  prediction: \"eply: @yacineMTB dependency independency\" => \" ly:  ptp saa paa  sss sss    o o oo   o\"\n",
      "batch 12718  loss=166.8307  steps/s=137.28  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \"g  tits ns    ts o  t  oe oo oe eoo oe t\"\n",
      "batch 12719  loss=161.1209  steps/s=103.85  prediction: \"o projects, kinda like how momentum does\" => \" mea  r    t  go eeet    k    o   ooe  m\"\n",
      "batch 12720  loss=142.8746  steps/s=103.90  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"etoy  ierIee1j@ 21Êœð—±â€¦á´‡ðŸ¤£ð—²â€]XXðŸ¤¦[ð—¯ðŸ¤·á´€ð—²]|â€â€™}]\"\n",
      "batch 12721  loss=248.1461  steps/s=11.18  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"eply: @eryse1j@ 21,VV}XVá´€][â˜ ðŸŒ‘,XðŸ¤”|ï¸Z[â€|]ð—µ\"\n",
      "batch 12722  loss=157.6029  steps/s=118.88  prediction: \" could you tell\" https://t.co/968GsOvdfW\" => \"tow   d                     tttt/t//////\"\n",
      "batch 12723  loss=135.6082  steps/s=101.93  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"t t e                ssssssssst/////////\"\n",
      "batch 12724  loss=168.6446  steps/s=69.18  prediction: \"dejavucoder roon was gpt5 the whole time\" => \"           s ase  a s s/tstt/t//////wt t\"\n",
      "batch 12725  loss=148.1294  steps/s=105.42  prediction: \"hemes\n",
      "John waitzkin called this chunking\" => \"er c:iane\n",
      "ten\n",
      "eeeeee n n e  n   ii tii  \"\n",
      "batch 12726  loss=168.5151  steps/s=103.65  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" ti eaennn nhn hzazaz  laa li   el nllnn\"\n",
      "batch 12727  loss=139.8890  steps/s=104.61  prediction: \"th `sudo service NetworkManager restart`\" => \" e  eteaw re r r   e  eeee ee eereeererr\"\n",
      "batch 12728  loss=138.6985  steps/s=105.16  prediction: \"robably dont ask 'will you be my mentor'\" => \"euu i   a    Te 'L'*NL'jU/CMNv_fb*`MU***\"\n",
      "batch 12729  loss=142.8831  steps/s=105.04  prediction: \"just point to concepts and arent reality\" => \"usv    s h  n ot   oo  o t  tnn n  nnn t\"\n",
      "batch 12730  loss=162.1272  steps/s=100.32  prediction: \"e + 5] yr old ceo living in the hamptons\" => \" a la a  y                              \"\n",
      "batch 12731  loss=182.0078  steps/s=104.20  prediction: \" make https://t.co/s6ZBWGye2X executable\" => \"tos .skaa a    t  ///t  ///tt//tteeeteee\"\n",
      "batch 12732  loss=164.2087  steps/s=104.21  prediction: \"a fckton of time https://t.co/HOKGcS3zKn\" => \"np   \n",
      "ttn  \n",
      "  ott o    t   tttt /tt  ///\"\n",
      "batch 12733  loss=177.2946  steps/s=66.29  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"ludwautto  ff f  t  ttst / ttoto///!!K33\"\n",
      "batch 12734  loss=172.8072  steps/s=105.50  prediction: \"ou get like 5 seconds to shoot your shot\" => \"u  R ey n ny                  ooo  o  s \"\n",
      "batch 12735  loss=143.6104  steps/s=103.52  prediction: \"ing and shipping is gonna grow immensely\" => \"ng\n",
      "oo    en  pp nippiiiiinnngg g   g    \"\n",
      "batch 12737  loss=195.6884  steps/s=57.28  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tgtpe gnnhppippniig iinnngggg       nn  \"\n",
      "batch 12738  loss=144.3433  steps/s=107.76  prediction: \" (by trusting in ideas) and testing them\" => \"tytte  y htt tnt     i                  \"\n",
      "batch 12739  loss=136.1908  steps/s=104.02  prediction: \"w the entire thing works when you use it\" => \"of  an h n  n et                        \"\n",
      "batch 12740  loss=135.4119  steps/s=104.40  prediction: \" adding the context into the computation\" => \"tn  t   oe \n",
      "   ee ooe e  t nt e te ttttt\"\n",
      "batch 12741  loss=157.0009  steps/s=101.21  prediction: \"oodhart that too https://t.co/AKZnb9fRgL\" => \"nd  t or et t ttooaot totttttottttt /// \"\n",
      "batch 12742  loss=144.0338  steps/s=104.03  prediction: \"ession youll do something until its done\" => \"   e  pepp epell  ooooooooooo      i    \"\n",
      "batch 12744  loss=147.1378  steps/s=102.95  prediction: \"you could just make move that looks good\" => \" u hntn hyhn  u   u     u          o  oo\"\n",
      "batch 12745  loss=141.0015  steps/s=104.28  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"tar eel  oo looooololll llllllll a   aa \"\n",
      "batch 12746  loss=146.4257  steps/s=104.38  prediction: \"aster i u know its just abt authenticity\" => \"n  tobtttt it tt  t        t    ttt ttt \"\n",
      "batch 12747  loss=163.9212  steps/s=99.46  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"leapP_A@ ka aka tatas s  s s    ee eeeee\"\n",
      "batch 12748  loss=187.2458  steps/s=68.41  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"lndph__y__a_att  asss ttssse  ereereesss\"\n",
      "batch 12750  loss=146.6196  steps/s=108.90  prediction: \"y be a way to do it without grad descent\" => \":@e abe t                   t  o  t  t  \"\n",
      "batch 12751  loss=167.5907  steps/s=105.10  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \"  netun  fun  u         r    r          \"\n",
      "batch 12752  loss=142.0135  steps/s=98.36  prediction: \"feeling than automating hrs of work away\" => \" so  eee enen     n   aana  at    e     \"\n",
      "batch 12753  loss=147.2677  steps/s=103.92  prediction: \" strategy is short term low integrity BS\" => \"too  e   as ssessss ss        t  t t trt\"\n",
      "batch 12754  loss=147.9461  steps/s=105.67  prediction: \"on chunking showed higher level playersâ€¦\" => \"u t  st s  n nn      hhhhh hhhhhhe eeele\"\n",
      "batch 12755  loss=157.8150  steps/s=100.89  prediction: \" making anifusion in the first place btw\" => \"teydt   t   a nn inniinnniiniiiii       \"\n",
      "batch 12757  loss=158.7606  steps/s=38.11  prediction: \"ly: @andrew_pynch i think about it a ton\" => \"y: @t t a  a  g  iin innniinii i     t  \"\n",
      "batch 12758  loss=165.8226  steps/s=120.56  prediction: \"king one open rn just cause of this post\" => \"eng hraacrin   on  nnn  n    n  us   ts \"\n",
      "batch 12759  loss=150.1951  steps/s=105.02  prediction: \"ective, its significantly more efficient\" => \" tct o  leecei eii ii iiiiiiiii ii iffff\"\n",
      "batch 12760  loss=145.3321  steps/s=104.88  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"ehe  ingoloov_ltb,:jxxgq/zq\n",
      "OOv:Ef3x4zRE\"\n",
      "batch 12761  loss=170.2518  steps/s=101.54  prediction: \"k man awesome work\n",
      "\n",
      "and super cool notes\" => \"it  anme  weawewwwoww wow ao    \n",
      " eo o  \"\n",
      "batch 12762  loss=139.9405  steps/s=104.53  prediction: \"dition, just kpis to optimize right now)\" => \" nt n  n ni nn n i   i    o  iiiii iiiii\"\n",
      "batch 12763  loss=146.7364  steps/s=100.87  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \" e  i@ii esss rssss o onoooo         t  \"\n",
      "batch 12764  loss=143.2069  steps/s=96.29  prediction: \"e ive been thinking the exact same thing\" => \" d   @eiien  eeennnnn nnnn t   t   ata  \"\n",
      "batch 12765  loss=150.1396  steps/s=99.29  prediction: \"appen. i know it https://t.co/jDUR7SknBb\" => \"ne i ee n     n          t ttttt////////\"\n",
      "batch 12766  loss=148.7994  steps/s=103.02  prediction: \"ing responses seems like a better metric\" => \"n s\n",
      "eeeennesenonnesssessseseeeeee  eeeee\"\n",
      "batch 12767  loss=129.8723  steps/s=104.41  prediction: \"had an eye for it meant maybe its useful\" => \"eto t t       a                         \"\n",
      "batch 12768  loss=229.6779  steps/s=106.88  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"t..tt  t/eeQQ/ZQ h  ZhZZZhhtt tttttts//t\"\n",
      "batch 12769  loss=137.2323  steps/s=104.91  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \"te te t   tt  t  t  t t          u   u  \"\n",
      "batch 12770  loss=178.6953  steps/s=102.02  prediction: \"his\n",
      "Lets build some cool stuff. So hyped\" => \"esi   e Lenn  L i  eiss   oo   oo   oo  \"\n",
      "batch 12771  loss=141.8619  steps/s=103.83  prediction: \"good idea but whatever, i wanna have fun\" => \" od nno no    o    t        aa   aaaa aa\"\n",
      "batch 12772  loss=168.8440  steps/s=39.18  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"y  @st  do id      aa       aaa  aaaa aa\"\n",
      "batch 12773  loss=155.1619  steps/s=122.52  prediction: \"future wife, dayum\n",
      "\n",
      "happy for you brotha\" => \" nts audrer ued  euee    a \n",
      "  appyy   yy\"\n",
      "batch 12774  loss=155.3920  steps/s=103.27  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltte tellsls oop  soook oooonoono nono  \"\n",
      "batch 12775  loss=155.0434  steps/s=101.66  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" d  n         n    o                    \"\n",
      "batch 12776  loss=139.1116  steps/s=103.98  prediction: \"able for whoever owns the algorithm/site\" => \"ttor  eete tr    ee e  ee ee e  o oe o o\"\n",
      "batch 12777  loss=162.4557  steps/s=104.78  prediction: \"ded techniques too, lmk if you know more\" => \" ag el een ddededdeeeeeee      o  o    o\"\n",
      "batch 12779  loss=132.8466  steps/s=105.43  prediction: \"you can get a stronger 'muscle' for this\" => \" u  eMth  hgt     t   t t        ' '''' \"\n",
      "batch 12780  loss=154.0217  steps/s=105.80  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \"pm kn eee n  e s ess  es s          er r\"\n",
      "batch 12782  loss=140.5828  steps/s=104.96  prediction: \"good idea but whatever, i wanna have fun\" => \" o tnno io    o    t        aa   aaaa aa\"\n",
      "batch 12783  loss=134.7915  steps/s=102.18  prediction: \"seful instances of delayed gratification\" => \" dng  f  eft   n  s       ee   eee  aaaa\"\n",
      "batch 12785  loss=288.6419  steps/s=11.05  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"eply:s@cararc|eYá´„ÊŸ,{Yå§á´¡É´}}ÊŸ}ðŸ¤·ï¸á´‡ÊŸ~ð—²{{|,,Éª\"\n",
      "batch 12786  loss=139.5577  steps/s=112.22  prediction: \"fundamentals is a smart smart smart move\" => \" n sin aena ta ta       aaaaa s sssmm  m\"\n",
      "batch 12787  loss=153.7704  steps/s=105.41  prediction: \"ways but in many cases it holds you back\" => \"hnteea  ln ya      a   a  a             \"\n",
      "batch 12788  loss=157.1792  steps/s=101.05  prediction: \" joining man, looking forward to thurs!!\" => \"tuesantnneno non ononoononnnooooo      o\"\n",
      "batch 12789  loss=149.4173  steps/s=103.67  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"einmTyntetter rt      i         i  i   i\"\n",
      "batch 12790  loss=148.5046  steps/s=89.07  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \" MTBo rtteeTll lii l  ia  a a d d tt   t\"\n",
      "batch 12791  loss=193.3021  steps/s=104.73  prediction: \"needed to dl this. meme delivery service\" => \" MTB     d e  ed       e d  deeeeeeeeeee\"\n",
      "batch 12792  loss=148.1662  steps/s=105.66  prediction: \"e thing, not just messing around with it\" => \" tiat etttt nttt nt  t    tn      n     \"\n",
      "batch 12793  loss=170.2361  steps/s=100.25  prediction: \"eople want. Nowâ€ https://t.co/yxXaaiHzQ1\" => \" sine ieeh p eeee      tt t ttt/////////\"\n",
      "batch 12794  loss=157.0026  steps/s=102.43  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"   ati isetetthtttteteeeeeeneeeeein  i i\"\n",
      "batch 12795  loss=156.0341  steps/s=108.32  prediction: \"ake with two snakes would be interesting\" => \"ne t e  nientttt   n  eeee    e      e e\"\n",
      "batch 12796  loss=145.7133  steps/s=103.97  prediction: \"esting example of goodharting the reward\" => \"  bttetteneeettneee eeeee eoooo  o o   r\"\n",
      "batch 12797  loss=271.1029  steps/s=11.76  prediction: \"reply: @Wooltard the gradients must flow\" => \"eplie @  dm  Fd XXYYXFYFY@F,FF_FFFFZwFZZ\"\n",
      "batch 12798  loss=153.6721  steps/s=130.91  prediction: \"ttempt to appeal to ipad kid generation?\" => \"herstene ttapppppt tpppp  p  p  a    i a\"\n",
      "batch 12799  loss=156.9410  steps/s=102.93  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nlaaa aa nnananammmmmmmmm mmmm          \"\n",
      "batch 12800  loss=136.7824  steps/s=102.73  prediction: \"on + analysis, considering posting on gh\" => \"n ta nooa anaaa aannisiiiniiiiiiisininin\"\n",
      "batch 12801  loss=155.6317  steps/s=103.43  prediction: \"/t.co/zlto3SBYwd https://t.co/Izzdx8c2HJ\" => \"/.eVd d/or////too3tttttottt://t/tt//zzzz\"\n",
      "batch 12802  loss=156.6976  steps/s=100.61  prediction: \" this pic of him https://t.co/IPAvfCvWwd\" => \"th  enieein i n  i            tt////////\"\n",
      "batch 12803  loss=177.6917  steps/s=106.53  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \"n inenkkn ooo h  h     ttttsttgtttto W  \"\n",
      "batch 12804  loss=157.0112  steps/s=97.52  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nABAPoo  gggogi gggyststottttt////// 6//\"\n",
      "batch 12805  loss=139.9201  steps/s=105.19  prediction: \"e forever with a simple 5min interaction\" => \" so  oeeefeneeffe                iiiiiii\"\n",
      "batch 12807  loss=144.9296  steps/s=104.66  prediction: \"learn thing -&gt; compress thing, repeat\" => \"yxr )nenndenrn ennn  nn   tg t   g gg   \"\n",
      "batch 12808  loss=156.8302  steps/s=104.55  prediction: \"e playing blind) https://t.co/3G3m7ZAvmV\" => \" so  nn  ppin l l lll   i tt    ttt/3333\"\n",
      "batch 12809  loss=179.5751  steps/s=104.51  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \" SNT\n",
      " DTDDAAT AA A  C CC  A     / t/t//t\"\n",
      "batch 12810  loss=157.0058  steps/s=103.57  prediction: \"o much suffering for the DUMBEST reasons\" => \"ngiieeiin one    ffe fffff f            \"\n",
      "batch 12811  loss=171.1613  steps/s=91.36  prediction: \"rdenis grats btw. site looks amazing too\" => \"e o : @kh~BufGrivLgb,,EGAEODUUBBkSTb.8zH\"\n",
      "batch 12812  loss=166.1086  steps/s=103.86  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"hgk  eu u d @ diB@BBB B B B   vv  va a a\"\n",
      "batch 12813  loss=153.2231  steps/s=103.55  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nnst t t t  t     \"\"\"\"\"\"\"               \"\n",
      "batch 12814  loss=149.4689  steps/s=101.12  prediction: \"y is nothing like early morning sunlight\" => \":@usu n errellr l  l l  l  i ii    ning \"\n",
      "batch 12815  loss=152.1899  steps/s=96.63  prediction: \"ok me a second but damn thats a good one\" => \"ni re t o  n  k e  e e  o  nnn   a a aa \"\n",
      "batch 12816  loss=170.7223  steps/s=105.74  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t  000001211221          2 636333 \n",
      "   \n",
      " \"\n",
      "batch 12817  loss=169.5741  steps/s=96.07  prediction: \"ake with two snakes would be interesting\" => \"niut 2  i      t   w          ee   enn n\"\n",
      "batch 12818  loss=189.0977  steps/s=83.94  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"ei y: @1 o4az.er.-5-1R3RR33kRRcRv#2da.0:\"\n",
      "batch 12819  loss=148.7986  steps/s=107.77  prediction: \"x len output, custom system prompts, etc\" => \"_ua me   em euutuu uuuutu ttttt mttmmttt\"\n",
      "batch 12820  loss=173.3234  steps/s=100.23  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \" g apen  a t  a      ts  sttststttt/////\"\n",
      "batch 12821  loss=147.6559  steps/s=105.04  prediction: \"e thing, not just messing around with it\" => \" tiat atttt nttttnt  t    tn      n     \"\n",
      "batch 12822  loss=151.9189  steps/s=101.72  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" ye  tg  hth htth            o nnnnnnnnn\"\n",
      "batch 12823  loss=166.4828  steps/s=76.81  prediction: \"am_Kantor actually something came up rip\" => \"tp t t t nt h n     lll onnnn nnnnccnnee\"\n",
      "batch 12825  loss=143.9754  steps/s=106.09  prediction: \"s changing how I think abt models a lot.\" => \" a e\n",
      " ata netn\n",
      "  n  hhhn  h  hh n       \"\n",
      "batch 12826  loss=140.1854  steps/s=104.05  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" ti e    e en   e     e eeeeeeeieeeieeee\"\n",
      "batch 12827  loss=146.6869  steps/s=100.36  prediction: \"ers had a username but idk his name name\" => \"  lne eertt r dre   e a                m\"\n",
      "batch 12828  loss=156.6384  steps/s=79.26  prediction: \"eCachet Consistency is a deadly strategy\" => \" slhetee  t s  nessee e    i    d a    a\"\n",
      "batch 12829  loss=148.9315  steps/s=105.12  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" ofle  ae an  re i ii  t   ttttt  /tt///\"\n",
      "batch 12830  loss=156.1186  steps/s=105.05  prediction: \"n confirm this is a very goated strategy\" => \" +ofl raen in ti    s  s s  i    t  s t \"\n",
      "batch 12831  loss=147.7372  steps/s=100.64  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \" t e     w nw  www                     e\"\n",
      "batch 12832  loss=136.6393  steps/s=104.69  prediction: \"ng signals from constant individual lies\" => \"  re ri   g  sig     sss nnnnnninnnniiii\"\n",
      "batch 12833  loss=155.6688  steps/s=99.33  prediction: \"n confirm this is a very goated strategy\" => \" tre ri en an mm    s    s  i    a a  t \"\n",
      "batch 12834  loss=158.1451  steps/s=81.35  prediction: \"wphones Love the plan, sounds meaningful\" => \"hh   n n norn iis   s    sa s  std a ete\"\n",
      "batch 12835  loss=180.7478  steps/s=105.95  prediction: \"7AHwatHv6Y was really really really good\" => \" 1 @ tp//oHHHtt HHttaaa  aaalaal allllly\"\n",
      "batch 12836  loss=138.3728  steps/s=104.45  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y\n",
      " ei ei   lllip                 a     a\"\n",
      "batch 12837  loss=155.3501  steps/s=103.27  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"n boa    k bt VV  t  tt ttttttttt/o///tt\"\n",
      "batch 12838  loss=143.3196  steps/s=103.89  prediction: \"nomic than discord id switch immediately\" => \" tted  ane om omo   o   i  d id iii diii\"\n",
      "batch 12839  loss=180.8424  steps/s=97.82  prediction: \"(im not mexican) https://t.co/PYTZ3vBjrX\" => \"2ncemt oo  no  oo  n   ttt cttc tt/ct/ t\"\n",
      "batch 12841  loss=144.4174  steps/s=103.29  prediction: \" far dang the format looks so much nicer\" => \"@or   n  t a   f   f   o   oo oo  ooo  o\"\n",
      "batch 12842  loss=163.2324  steps/s=79.68  prediction: \"cle77 arabian mate is a similar good one\" => \"oep b r batr7 arra aaa  ass   s     i ro\"\n",
      "batch 12843  loss=154.3876  steps/s=106.55  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"tdda m m  m m mi'' '''''    t           \"\n",
      "batch 12844  loss=143.1009  steps/s=97.60  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"   m aninenieee  dd dsdd  d   o  ooo    \"\n",
      "batch 12845  loss=141.7463  steps/s=103.53  prediction: \"l possible golden gate bridge existences\" => \"yceol l     ll lol  l        ee ee eeeee\"\n",
      "batch 12846  loss=152.1557  steps/s=98.78  prediction: \"oger @sunsettler @tunient baller name xD\" => \"nraaal ooogootteeseteeeeeteetneet eennen\"\n",
      "batch 12847  loss=150.7099  steps/s=97.88  prediction: \"bootloader fast and frictionless is king\" => \"uoto @loteborootottot tt  a    in  i   i\"\n",
      "batch 12848  loss=149.5265  steps/s=103.45  prediction: \"ective, its significantly more efficient\" => \" o tco  leecei eiiiiisiiiiiiiii ii iffff\"\n",
      "batch 12849  loss=152.5856  steps/s=104.41  prediction: \"rings out there that would just ruin ppl\" => \"ecale  ttd1eakot7&.w;100k\"jvwkw:@'jjjwI'\"\n",
      "batch 12850  loss=169.5249  steps/s=102.72  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"t  i   oo000 000000    tttt tttsttt/////\"\n",
      "batch 12851  loss=152.1792  steps/s=96.98  prediction: \" yapping like lud mentioned sounds great\" => \"@oui nianinip ip      i       innn nn  n\"\n",
      "batch 12852  loss=147.2163  steps/s=110.34  prediction: \"ot of politics is reinforcement learning\" => \"   o o  ol l l   i iii iii  ieeee nreeen\"\n",
      "batch 12853  loss=150.3446  steps/s=94.16  prediction: \"ko I have no idea why it was working tbh\" => \"   o obolt nn      i  e i  e e  w r innn\"\n",
      "batch 12855  loss=149.0006  steps/s=104.26  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" -ogt ntt  tstt ttsssttsss  s ss ssss   \"\n",
      "batch 12856  loss=141.7235  steps/s=104.51  prediction: \"d into using dishonest middlewit tactics\" => \" be s teer  n n   s snssssi isdsiididiti\"\n",
      "batch 12857  loss=153.7071  steps/s=105.28  prediction: \"king progress. Now i see it eeeverywhere\" => \"  l at a  t   a      s         eee eeeee\"\n",
      "batch 12858  loss=142.8472  steps/s=105.24  prediction: \"anding pages or whatever feels gross idk\" => \"td a ao n n n on         eee   eeeeee re\"\n",
      "batch 12859  loss=178.7523  steps/s=97.80  prediction: \"an that sounds like such a relaxing time\" => \"ld n a   rtyann naa    t s sl e eslsi   \"\n",
      "batch 12861  loss=151.5915  steps/s=104.30  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  o     bkbbbbbb bb b bb            o\"\n",
      "batch 12862  loss=159.3598  steps/s=97.00  prediction: \"ily @ineedtolocking @kuberdenis detected\" => \"nd okul l ileleile nen  l o   k   rreede\"\n",
      "batch 12863  loss=157.8002  steps/s=103.67  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tud  i     ddd d        a       s ss  s \"\n",
      "batch 12864  loss=150.6258  steps/s=104.03  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"ne    too  k  e             tttt////////\"\n",
      "batch 12865  loss=151.5280  steps/s=103.71  prediction: \"l, titan, stable diffusion, a few others\" => \"y es rls ta s asa,aat tat  ai ii  i     \"\n",
      "batch 12869  loss=151.6639  steps/s=103.05  prediction: \" come to your house, and move mario back\" => \"tor eeeet t e ee  e e  o   o  oo  o    o\"\n",
      "batch 12870  loss=142.1558  steps/s=100.70  prediction: \"ant believe I havent been napping before\" => \"nd    te e d  e ee eee eeeeeeeee e nnnne\"\n",
      "batch 12871  loss=174.7253  steps/s=99.20  prediction: \"ctus infobalking https://t.co/B3UT9nTonq\" => \"oulne teltne l   nn   nntnnttptp/t//pn//\"\n",
      "batch 12872  loss=179.7586  steps/s=100.05  prediction: \"dgrammer best languages in your opinion?\" => \"    Her@@ar  remmea ag e gga ggga eeo  o\"\n",
      "batch 12873  loss=162.6164  steps/s=99.63  prediction: \"day night and posted this sunday morning\" => \" yg  d  iddi tadd   n  t  t   sts   ss s\"\n",
      "batch 12874  loss=136.8612  steps/s=103.51  prediction: \"lots of stuff you learn way way way more\" => \"yu  o          s   f             yyyyy y\"\n",
      "batch 12875  loss=161.6315  steps/s=89.47  prediction: \"hag_ its good to be on the outside again\" => \"en  o  ss sf   to   oo      a    a  a a \"\n",
      "batch 12876  loss=144.3600  steps/s=103.55  prediction: \" been some adventure man. God bless him.\" => \"tuse ve e  nee eeeeeeeeeeeee            \"\n",
      "batch 12877  loss=154.4655  steps/s=100.97  prediction: \"l do bro, never had a french beer before\" => \"yae eb b b d  od  r          r e   eeere\"\n",
      "batch 12878  loss=154.9264  steps/s=102.64  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf t r   rd   ri  i  i                  \"\n",
      "batch 12879  loss=142.1271  steps/s=105.03  prediction: \"ns you get the yellow letters on lichess\" => \"  yr  t   t   t    e   e   ee eeeee llll\"\n",
      "batch 12880  loss=151.2719  steps/s=104.04  prediction: \"se and 'magically' econ makes more sense\" => \" ' l  thete   aeaaaaaaa  a   aaa      ee\"\n",
      "batch 12881  loss=151.7715  steps/s=105.62  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"ii e yrt ttet rl      o         i      i\"\n",
      "batch 12882  loss=164.4269  steps/s=44.75  prediction: \"y: @tunahorse21 wasm babyyyyyyyyyyyyyyyy\" => \"  @tewtr re   Bl   a  ii  i   i i  r   0\"\n",
      "batch 12883  loss=175.8165  steps/s=123.39  prediction: \"inpeace I gotchu https://t.co/l34MQvLmOd\" => \"ng aa ai gineee   t    t tc ctcc///// QQ\"\n",
      "batch 12884  loss=198.3947  steps/s=101.83  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"@atl         LLLLLLLDEEEEEEEETTT TTE  E\n",
      "\"\n",
      "batch 12885  loss=207.3622  steps/s=21.66  prediction: \"eply: @yacineMTB https://t.co/ONnUwL3VIM\" => \" lio @t     LLLLLLDEEEEEEEEETTTT T E   \n",
      "\"\n",
      "batch 12886  loss=156.1295  steps/s=110.93  prediction: \" this long lost treasure of a song, damn\" => \"@oo rro   ninohn        o s  o s        \"\n",
      "batch 12887  loss=156.3434  steps/s=105.22  prediction: \"rusted with this https://t.co/78lPrhtd11\" => \"eta e iavoy@e:'eNI*'á´„TbgðŸ’ª*$z$78Nk'EL3kIM\"\n",
      "batch 12888  loss=146.6257  steps/s=105.28  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \" \n",
      "nd n  n nn ss: i  i  i   ++++xxx      \"\n",
      "batch 12889  loss=144.8533  steps/s=106.11  prediction: \"t immensely and give you new information\" => \"hiee  e neetn  n e  e     e   e   n    n\"\n",
      "batch 12890  loss=156.4907  steps/s=99.12  prediction: \"python or c??? ðŸ¤” https://t.co/XQktKXHLU2\" => \"ln tsnso o oo oo ???   ?     tt  t//XXt/\"\n",
      "batch 12891  loss=142.2395  steps/s=105.89  prediction: \"e usually surrounded with those coloredâ€¦\" => \" ca e eeeaer  urruuuluuuuuuu ud     o  o\"\n",
      "batch 12892  loss=139.9666  steps/s=104.98  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h a    o  rr  ogooo ooo oo o   o o    o \"\n",
      "batch 12893  loss=151.2513  steps/s=97.40  prediction: \"bootloader fast and frictionless is king\" => \"eo totbobboodoobooe  er  af    f sisii i\"\n",
      "batch 12894  loss=153.2197  steps/s=97.35  prediction: \"e IRL, its fundamentals all the way down\" => \" pt: addaea s  sss   a  aaaallnllll   l \"\n",
      "batch 12895  loss=150.4181  steps/s=102.03  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" yoh a    t   tt         lll n nn nnonnn\"\n",
      "batch 12896  loss=158.4049  steps/s=103.60  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"Vmphes rerr rr   r aaaeaa aaa a aa a at \"\n",
      "batch 12897  loss=152.9267  steps/s=100.10  prediction: \"free could help too if thats the problem\" => \" o  iecs  ueu  u     e o  t     t  t t  \"\n",
      "batch 12898  loss=155.9319  steps/s=102.12  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"u    s  .............        o          \"\n",
      "batch 12899  loss=143.3231  steps/s=103.46  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"em2ymeiery.ekðŸ˜†s }1}@S}ðŸ¤¦ðŸ˜¤QkÊ€Qð—¶}kðŸŽ‰ð—ª{ð—»^}á´ðŸŽ‰Ê€\"\n",
      "batch 12900  loss=153.1522  steps/s=101.41  prediction: \"es gets rounded up to 0.1s\n",
      "\n",
      "why? idk man\" => \"  yar  eerseeees ee e  d              \n",
      " \"\n",
      "batch 12901  loss=155.5510  steps/s=101.97  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \"ukablab b bwb o              tttttt/////\"\n",
      "batch 12902  loss=145.7823  steps/s=103.71  prediction: \"g correct (fingers crossed its this one)\" => \" a e erret  rrrrrrerr crrerr  ssss s ss \"\n",
      "batch 12903  loss=144.8268  steps/s=104.79  prediction: \"ar mongering gets attention (clicks etc)\" => \"tee  e eesren nee  ee eeettttntttnttt  t\"\n",
      "batch 12905  loss=199.0368  steps/s=21.69  prediction: \"eply: @btwphones Thanks! more on the way\" => \" lys   ee eenenee  ee etettttntttnttt  t\"\n",
      "batch 12906  loss=146.5296  steps/s=107.57  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" ai  n  ....s..s  o                     \"\n",
      "batch 12907  loss=184.9321  steps/s=37.88  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y: @jf.... .. .d kk                  ess\"\n",
      "batch 12908  loss=142.1887  steps/s=108.89  prediction: \"nly do this technique if I involve words\" => \"ge  t    n t                   ii       \"\n",
      "batch 12909  loss=139.5228  steps/s=104.31  prediction: \"oast. silencio until youve made progress\" => \"u  eit   tses is tiii iiiii  i    o     \"\n",
      "batch 12910  loss=145.0179  steps/s=103.20  prediction: \"r fearing stops success\n",
      "Reduce it to fix\" => \"efe   ngoloOvAotb,@Sxxg\"/z0ROOv0.f0x(zR0\"\n",
      "batch 12911  loss=137.3515  steps/s=101.73  prediction: \"better generalizer than the classic MLP?\" => \"ect e t  eteteteeeeeeeeeereee e        a\"\n",
      "batch 12912  loss=159.2938  steps/s=98.94  prediction: \"rse21 help poor sama out, he needs ideas\" => \"ee  :  _o dc @gdv,@7/bw21I7\n",
      "214MLP|xz|x5\"\n",
      "batch 12913  loss=165.5345  steps/s=103.59  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \"omonoV anwant nata aa t a t   /// t//tto\"\n",
      "batch 12915  loss=152.7910  steps/s=98.79  prediction: \" cs maps btw? would love to see pictures\" => \"toy      o                  o  o   o    \"\n",
      "batch 12916  loss=136.6686  steps/s=104.84  prediction: \"w the entire thing works when you use it\" => \" ft hn   n  n et                        \"\n",
      "batch 12917  loss=152.1412  steps/s=101.16  prediction: \" or so more to go. Lookin forward t o it\" => \"tn    o !o !o oooooooooooooooooo        \"\n",
      "batch 12918  loss=156.3668  steps/s=104.18  prediction: \" is better though, I should check it out\" => \"tn bemeabe ee te eee  e      hh hhh  h h\"\n",
      "batch 12919  loss=150.7242  steps/s=103.53  prediction: \"would be insanely useful to do this with\" => \" rdm    r uon   ee ie ee u uul      e   \"\n",
      "batch 12920  loss=153.5267  steps/s=103.49  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \":  saa aanas a\n",
      " sss                     \"\n",
      "batch 12921  loss=158.3732  steps/s=105.09  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  dtse;ietgge&eg;trttttttttoo oo    ot  \"\n",
      "batch 12923  loss=169.0975  steps/s=61.05  prediction: \"@IterIntellectus have you brrrytt today?\" => \"ltwtietggttttelortrrt ot o oLLLLr t tt t\"\n",
      "batch 12924  loss=165.8674  steps/s=107.10  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"re xx nxxf      f      \n",
      "   \n",
      "  ///o///111\"\n",
      "batch 12925  loss=145.6648  steps/s=103.98  prediction: \"just start working, and it doesnt matter\" => \"usta         t r   t  t   t rt  t  nttt \"\n",
      "batch 12927  loss=153.4309  steps/s=103.62  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tami  cc   c  t                         \"\n",
      "batch 12928  loss=143.3048  steps/s=103.16  prediction: \"t. have they found the piece yet or what\" => \"h i  o    t t tt  t           e  eee  e \"\n",
      "batch 12929  loss=165.1099  steps/s=100.43  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \"he a cnt tet ses stts tttttt ttppttttt//\"\n",
      "batch 12930  loss=147.3853  steps/s=103.20  prediction: \"r 100x more productive, get good with it\" => \"eoerel@cxgnYnMnevWPO@,bkR,W(q?b11((bRYR0\"\n",
      "batch 12931  loss=172.2152  steps/s=97.43  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"h  a sm   sapaaa  aaaad  daaadd  ladl  l\"\n",
      "batch 12932  loss=156.5594  steps/s=104.02  prediction: \"that there were pink cubes at some point\" => \"har t   e te erre re     e    e e ee e t\"\n",
      "batch 12933  loss=169.9804  steps/s=96.18  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u   o  77e ee  e e   p  t p tt  t//s333\"\n",
      "batch 12935  loss=149.3662  steps/s=101.87  prediction: \"re just doin their part to get us to AGI\" => \"eply   Tg_w bMelkM_..TMvyq++jFq:++k.AbTh\"\n",
      "batch 12936  loss=170.6523  steps/s=99.06  prediction: \"yup totally agree. Very powerful mindset\" => \":p  uy  ea yH  y y t  rrre a ee   ee  er\"\n",
      "batch 12937  loss=162.5966  steps/s=104.85  prediction: \"ed in joining, repeat these instructions\" => \"  e  eeeneneeeieinnieienee    enee ettet\"\n",
      "batch 12938  loss=144.4020  steps/s=102.27  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" tin    d dd dd d                ???    \"\n",
      "batch 12939  loss=146.8842  steps/s=104.70  prediction: \"king useful things, so it didnt work out\" => \"ena  d   k k  l                         \"\n",
      "batch 12940  loss=144.5177  steps/s=102.95  prediction: \"d to seeing your progress on nand2tetris\" => \" oe\n",
      "o oorg ge ner er  r  rrrr or   nnnnn\"\n",
      "batch 12941  loss=155.2981  steps/s=38.04  prediction: \"ly: @horseracedpast Hows it goin so far?\" => \"y: @o  oe  n  e r  rror  rr r or   nnnnn\"\n",
      "batch 12942  loss=146.2987  steps/s=107.51  prediction: \" elon keep going once they have billions\" => \"txi   i lhl p ee  e  e eeeeee      ee   \"\n",
      "batch 12943  loss=143.4165  steps/s=104.69  prediction: \"d now your follower base is more aligned\" => \" fi     ne  n en oo oooo o     e    e  e\"\n",
      "batch 12944  loss=140.7883  steps/s=103.90  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"u   eot nonn  o  oo    t tt   t   t   ss\"\n",
      "batch 12946  loss=140.9422  steps/s=106.38  prediction: \"d luck to step on worms and they stopped\" => \" t  t    t    tt                     t  \"\n",
      "batch 12947  loss=210.7141  steps/s=91.21  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"mrztzi@LSg4rzTeLAF,SLTFS:WTF.:/777:5/D7U\"\n",
      "batch 12948  loss=167.5690  steps/s=47.83  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \": @Lazz4z4tLLLLSSSo    tt   ttto///ttpee\"\n",
      "batch 12949  loss=156.5351  steps/s=130.84  prediction: \"resy you can already talk to one of them\" => \"eply:  SSLnAWWFFTP4xz:////.z.://5z5DD0U0\"\n",
      "batch 12950  loss=142.6534  steps/s=104.39  prediction: \"to the planning phase with more momentum\" => \"hr  ea     tn  n  nnnnnn               m\"\n",
      "batch 12951  loss=171.7652  steps/s=87.15  prediction: \"rdenis grats btw. site looks amazing too\" => \"e o : @d\n",
      "QQ;w-eeHjQI-k.:x/-..BBzB.xjB-z\"\"\n",
      "batch 12952  loss=145.8327  steps/s=104.95  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"efe s p, tv.vWttH\"PSWkj(x/Vj.k7(\"-x/:0)\"\"\n",
      "batch 12953  loss=143.5720  steps/s=104.55  prediction: \" far dang the format looks so much nicer\" => \"tor   s  t a   f   t   o    o oo  ooo  o\"\n",
      "batch 12954  loss=141.2076  steps/s=105.30  prediction: \"s called it tho, dont practice deception\" => \" b  t   ss J  t           t  t t  cccccc\"\n",
      "batch 12955  loss=144.9707  steps/s=105.52  prediction: \"g correct (fingers crossed its this one)\" => \" a e erret  rrrrrrerr crrerr  ssss ssss \"\n",
      "batch 12956  loss=142.2978  steps/s=101.11  prediction: \" the scaling laws for language models...\" => \"the t e  tt t t   t    a   a  g    ggggg\"\n",
      "batch 12957  loss=137.7796  steps/s=105.23  prediction: \"f you could 1.2x all the engineers there\" => \" aoa e auuuauu uuu  d  l   l  l   ee eee\"\n",
      "batch 12958  loss=164.0983  steps/s=101.71  prediction: \"sist... bait.... https://t.co/FSXHHMMAoD\" => \" nse r................tttt ttttt///////H\"\n",
      "batch 12959  loss=148.3521  steps/s=103.95  prediction: \"esting example of goodharting the reward\" => \"  ittetteneeettneee eeee   oooo  o o   r\"\n",
      "batch 12960  loss=137.4496  steps/s=100.74  prediction: \"ntiers out there we dont even know about\" => \" eTe t otor    ttt  ee   e e eeeeeee    \"\n",
      "batch 12961  loss=158.7467  steps/s=106.03  prediction: \"amming you can make bigger leaps though.\" => \"ne  n   nnn r m  m m   m    gg     g  g \"\n",
      "batch 12962  loss=140.8741  steps/s=105.19  prediction: \"entation, the cooler everything will get\" => \" t og moomoettottttooooeeeeeeeee eeeee e\"\n",
      "batch 12963  loss=140.4339  steps/s=105.29  prediction: \"that leads nowhere + info that clustersâ€¦\" => \" es is    n n e o    e     e       t t  \"\n",
      "batch 12964  loss=213.5804  steps/s=100.82  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"eitym  sus__iAg á´á´¡Ê€Ê€á´€á´€ÊŸá´á´¡_á´˜á´˜á´ÉªÉªÊ€á´›á´›Êœá´‡É´É´á´¡á´¡\"\n",
      "batch 12965  loss=152.7609  steps/s=103.21  prediction: \"rough a floppy disk inserted in my brain\" => \"euai  nueenIá´€á´€á´€e@vcÉªbÉªá´›Êœá´‡yÉ´á´„á´¡bká´á´„á´€Ê€á´„á´€2/k\"\n",
      "batch 12966  loss=141.7453  steps/s=103.68  prediction: \"atrophy, you have to like, keep doing it\" => \"ri  to  t t thth h                      \"\n",
      "batch 12967  loss=142.0455  steps/s=103.85  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"t  et  ttt ot  ott  ooo t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaa\n",
      "\n",
      "a\"\n",
      "batch 12968  loss=161.7701  steps/s=70.17  prediction: \"minus9 This is my new favorite edm track\" => \"aloia ni nott i\n",
      "s s se \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a aaaaaaaaaa\"\n",
      "batch 12969  loss=147.8380  steps/s=107.42  prediction: \" apart and send each one off to an agent\" => \"tn er a   t a  ta a  d  a  e      n     \"\n",
      "batch 12970  loss=147.6315  steps/s=103.97  prediction: \"ing vidya except w only positive effects\" => \"ng  iin nigiiii                    e ee \"\n",
      "batch 12971  loss=166.6919  steps/s=46.20  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \": @giiii id ein    e               e ee \"\n",
      "batch 12972  loss=174.1414  steps/s=59.36  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @liedninegen   e y      i    o e ee \"\n",
      "batch 12973  loss=145.8026  steps/s=130.98  prediction: \"king spheres are infinitely many circles\" => \"en  ieene g nee s ss e  eniii  i i yy cy\"\n",
      "batch 12974  loss=153.0844  steps/s=105.60  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"n  (i t tttt    s t tptp t ttt////tttttz\"\n",
      "batch 12975  loss=150.3420  steps/s=101.38  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"tld i    o a    a       s ts/ss///////WW\"\n",
      "batch 12977  loss=150.1927  steps/s=105.27  prediction: \"ver\n",
      "replace youtube embed with the video\" => \"ir\n",
      "a e  rerte re ee eee eeeeeeeeeeee e  \"\n",
      "batch 12978  loss=142.4103  steps/s=104.87  prediction: \"light show swarm and rent it to concerts\" => \"yke     dh    e     w           t    t  \"\n",
      "batch 12979  loss=143.5173  steps/s=103.78  prediction: \"n while still being consistent each week\" => \" thr rs  h    a   l     i i  iinni nn ne\"\n",
      "batch 12980  loss=138.9280  steps/s=103.17  prediction: \"egression to my past actions and results\" => \" oine re mens  s    o          s  s     \"\n",
      "batch 12981  loss=151.6842  steps/s=105.50  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"ton ae!!G n   e         nnnnnnnn nn     \"\n",
      "batch 12982  loss=179.5786  steps/s=80.54  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn  eea en g r nnA AAn nninennrreree enn\"\n",
      "batch 12983  loss=146.8789  steps/s=106.33  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \":tr oop ra n  m      m  m   t    LLLLLLL\"\n",
      "batch 12984  loss=144.4311  steps/s=105.89  prediction: \"d now your follower base is more aligned\" => \" fi     ne  n  n oo oooo o     e    e  e\"\n",
      "batch 12985  loss=149.1804  steps/s=105.50  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \" \n",
      "e it \"\"\n",
      "\n",
      "ii otio  ofooofof  oooo   e  \"\n",
      "batch 12986  loss=141.9743  steps/s=104.71  prediction: \"ncing is just how things go in business.\" => \" he h  enen eien i i  n   i      i  n  i\"\n",
      "batch 12987  loss=193.0940  steps/s=30.10  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly: @  en n ein  i i  n   g      i  nssi\"\n",
      "batch 12988  loss=151.9754  steps/s=112.07  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"ne  n oo  or og   e   eeee  eeeeeeeeeeee\"\n",
      "batch 12989  loss=142.0444  steps/s=100.22  prediction: \" the scaling laws for language models...\" => \"the t e   t t t   t    l   a  g g  ggggg\"\n",
      "batch 12990  loss=159.0525  steps/s=104.21  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \" h wwB   c         . ..   .....//.t////t\"\n",
      "batch 12991  loss=152.2308  steps/s=104.24  prediction: \"rf spatial in problem solving efficiency\" => \"eioe  esnem@v7se@B@Z$jmy~BIv;ð—¯~k:^x;{;~;\"\n",
      "batch 12992  loss=154.6857  steps/s=103.59  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nn to ttintiitiit  ot   t  s  s ss gs s \"\n",
      "batch 12993  loss=158.3848  steps/s=101.18  prediction: \"st went from rome to naples two days ago\" => \" ahti e  etit r    r t     t      o     \"\n",
      "batch 12995  loss=134.8940  steps/s=104.22  prediction: \"en clusters into single tokens like this\" => \" t  e eeteetn  tt    s      n      kkk k\"\n",
      "batch 12996  loss=178.2932  steps/s=81.21  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"ust oy tezet tn stssss    onn   ke etees\"\n",
      "batch 12997  loss=160.0915  steps/s=108.90  prediction: \" thought they became ugly when they fell\" => \"toe  de dhht  ht    e e       e    e   e\"\n",
      "batch 12998  loss=138.3313  steps/s=100.63  prediction: \"d work that into my current program haha\" => \" io        ww                   rrr rrrr\"\n",
      "batch 12999  loss=160.0305  steps/s=103.39  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \" edo oo    1 o  1              e    eeee\"\n",
      "batch 13000  loss=161.6357  steps/s=44.97  prediction: \"y: @thevalidcode Was just gonna say this\" => \": @Hoo u o1  o     o          se  e eeee\"\n",
      "batch 13001  loss=149.1902  steps/s=108.29  prediction: \"ng sessions for now for the discord name\" => \"    m \n",
      "l  i6s inssioo  os  oo  oo  oo  o\"\n",
      "batch 13002  loss=144.6374  steps/s=104.97  prediction: \"e info produced by exploring new options\" => \" iia iinin n   nn        d  e         o \"\n",
      "batch 13003  loss=151.8299  steps/s=103.33  prediction: \" to me except this feels 100x better fug\" => \"thets tt     e e  e eee    e  e0000000  \"\n",
      "batch 13004  loss=178.1380  steps/s=44.30  prediction: \": @pindjouf @thomasbocquet7 ayyy lets go\" => \" @tocte ura@ðŸ‘€Xhl@gj$kqj,I/qx@j77vu,,7g//\"\n",
      "batch 13005  loss=147.4900  steps/s=109.52  prediction: \"ys a bad thing just good to keep in mind\" => \" \n",
      "i e s saas a\n",
      "Naaa a              t    \"\n",
      "batch 13006  loss=158.7000  steps/s=104.55  prediction: \" filter out slop https://t.co/RA1wtAYLES\" => \"too ff fff f  ft    t  tttttttttttt/////\"\n",
      "batch 13007  loss=138.6046  steps/s=105.11  prediction: \"l tools for myself and they save me time\" => \"yie ui uuu l o l                       e\"\n",
      "batch 13008  loss=157.1052  steps/s=104.46  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omc    c corcee\n",
      "e re ee   ht  t////t/ttp\"\n",
      "batch 13009  loss=147.2520  steps/s=103.26  prediction: \"mes there are 10x rewards for doing this\" => \"e t e\n",
      "nsmmteteeee  eee rreere  r   rr   \"\n",
      "batch 13010  loss=141.3135  steps/s=105.14  prediction: \"hing that could ruin their brand idk tho\" => \"ev  emeeet ttt t  t              i      \"\n",
      "batch 13012  loss=146.4448  steps/s=103.11  prediction: \"anything else would kneecap learning no?\" => \"nd,  ertt th ihni     nn n  e ee en ennn\"\n",
      "batch 13013  loss=145.6609  steps/s=104.75  prediction: \" can instantly runit w the runit command\" => \"ioo e   on    I nnn  n n t   t          \"\n",
      "batch 13014  loss=142.4975  steps/s=104.84  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" re t  illltnlnnnnn n nn  ttt tt/t//////\"\n",
      "batch 13017  loss=143.3413  steps/s=102.79  prediction: \"ing and shipping is gonna grow immensely\" => \"ng  e e  en  pp n pppiininngggng   g    \"\n",
      "batch 13018  loss=164.5944  steps/s=98.82  prediction: \" @btwphones whoa https://t.co/dCCbEgrV7b\" => \"t_tpt  ahh shsnnhh  h hh hs    ///////CC\"\n",
      "batch 13019  loss=143.4137  steps/s=105.24  prediction: \"uch  there would be to take into account\" => \"lcyan  h  n nh                      t   \"\n",
      "batch 13020  loss=141.1935  steps/s=101.82  prediction: \"e rotators\n",
      "\n",
      "we color c, e, f, g the same\" => \" too  oa  oa oaoooooororoo oo  ,  , ,   \"\n",
      "batch 13021  loss=159.6067  steps/s=105.24  prediction: \", or just Jesus? https://t.co/GsoAQ2Ip2z\" => \" io   re f tee   es  s ssss sttts////s /\"\n",
      "batch 13022  loss=140.0555  steps/s=103.17  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  tt  ett tbe be       i   i       d  d \"\n",
      "batch 13023  loss=154.2198  steps/s=102.96  prediction: \"wesome looking pieces though, im jealous\" => \" rAB Ptillele ieeeeeee eeee eee         \"\n",
      "batch 13024  loss=129.6264  steps/s=104.04  prediction: \"had an eye for it meant maybe its useful\" => \"et  t t       a                         \"\n",
      "batch 13025  loss=155.2004  steps/s=104.62  prediction: \"e. I can teach you a bit too if you want\" => \"   :  n n an  a     a                   \"\n",
      "batch 13026  loss=170.4308  steps/s=44.80  prediction: \"y: @yacineMTB ty @elonmusk for the dL/dW\" => \"  @ an    a         a         o      o  \"\n",
      "batch 13029  loss=169.1073  steps/s=115.62  prediction: \"tiquing the zoomers that jump in his dms\" => \"hoa  a seeitqitii  ot  t tth    tt   t  \"\n",
      "batch 13030  loss=148.7816  steps/s=102.04  prediction: \"ems like you have. thanks for sharing it\" => \"   e  een lsseneeee                     \"\n",
      "batch 13031  loss=150.3947  steps/s=102.88  prediction: \"ting should not be taking customer calls\" => \"hce i  cgo cuoou o  n  on  nn nt  t  t  \"\n",
      "batch 13032  loss=161.2657  steps/s=103.25  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne e 2    s s es      @@rrr rrrrr rrarrr\"\n",
      "batch 13033  loss=174.4494  steps/s=102.31  prediction: \"gonna humble him\n",
      "https://t.co/HUMAzXB4rm\" => \" n\"s    ha n  n  n   h  h   h h ///ht//U\"\n",
      "batch 13034  loss=160.1850  steps/s=96.83  prediction: \" ...but will it work, thats the question\" => \"@  gwn A.n... hl . t t  tt tttt tthtthtt\"\n",
      "batch 13035  loss=160.3229  steps/s=70.02  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" an   u.belll ulll ttt  ttttt/t/tt tt tðŸ›‘\"\n",
      "batch 13036  loss=180.1670  steps/s=89.65  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"ludwugA  bl l  i ttttt:/t:/://t//tqqPqnðŸ›‘\"\n",
      "batch 13037  loss=175.4644  steps/s=105.80  prediction: \"; O(TREE3) btw)\n",
      "These all probably exist\" => \"&ge;&g&gBggg tt)EE))TTTT))          bbbb\"\n",
      "batch 13038  loss=180.0037  steps/s=104.26  prediction: \"tler good knight https://t.co/lACUcp7zMH\" => \"heng; EE t  t e  ttt  t tt   ttlll//ll l\"\n",
      "batch 13039  loss=165.3926  steps/s=104.41  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"t.ukthht////t///ttt11tttt1/t//tt////tt//\"\n",
      "batch 13041  loss=159.6037  steps/s=101.84  prediction: \"mewhat relevant:\n",
      "https://t.co/USV0L8wnT8\" => \"e   ett se em  eeeeeettttt:tttt//t//////\"\n",
      "batch 13042  loss=157.2676  steps/s=99.49  prediction: \"n og returns\n",
      "truly a legendary 5-9 today\" => \" js e     een trrrttrrtttrrllelela  enee\"\n",
      "batch 13043  loss=136.4433  steps/s=102.33  prediction: \"tput something as unexpected as possible\" => \"hs  t totootottt           eee eeeeeesss\"\n",
      "batch 13044  loss=162.6783  steps/s=94.70  prediction: \"xoki I'm always right\n",
      "Except when im not\" => \" kptuetutt imi s      a xxxxxxepeese ee \"\n",
      "batch 13045  loss=137.1666  steps/s=100.64  prediction: \"ure the first man on mars thats so crazy\" => \"s aee  ee e  eer                      s \"\n",
      "batch 13046  loss=137.5675  steps/s=103.04  prediction: \"th itself but couldnt figure out how lol\" => \" e t  tttt t tett      t   t   uuuuou u \"\n",
      "batch 13047  loss=165.8389  steps/s=100.65  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"sstee reeruuureuruututtttttttttttt//tttt\"\n",
      "batch 13048  loss=128.8698  steps/s=104.79  prediction: \"veryone in the past was a caveman/moron\"\" => \"e y  e ede eeeeeee             aaaaaaaaa\"\n",
      "batch 13049  loss=142.6260  steps/s=104.37  prediction: \"ion, which allows better problem solving\" => \"nn  tta eooco wo oooowww  w   t   l  ell\"\n",
      "batch 13050  loss=156.4619  steps/s=103.58  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"stattp e erreenreaa   atttaattttt/tt/tt/\"\n",
      "batch 13051  loss=169.2434  steps/s=96.13  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"e ty:  ss dh.Aea1f@Sk1f@:Mk!.svC3ARTkWZO\"\n",
      "batch 13052  loss=148.0780  steps/s=103.77  prediction: \"l release results soonish #buildinpublic\" => \"yto stn  Welel  le eelesss ssssss sssiis\"\n",
      "batch 13053  loss=155.1820  steps/s=103.86  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o  g \n",
      " fenfn %%%%%%%  %      3   3     \"\n",
      "batch 13054  loss=146.2780  steps/s=103.86  prediction: \"mple py script manages building/updating\" => \"eltats r oolpp\n",
      " pp psp pessp    iiieii a\"\n",
      "batch 13055  loss=147.8840  steps/s=103.22  prediction: \"wn for a game sometime? also lichess ftw\" => \"ant  oto    f        m m    em       ses\"\n",
      "batch 13056  loss=142.2040  steps/s=105.32  prediction: \"link, and then pretended to be my server\" => \"yto t ca taat a      n eeeeeeeeee   e ee\"\n",
      "batch 13057  loss=147.7384  steps/s=104.43  prediction: \"be allocate some time to do fun projects\" => \"e i o   n  a  e                   o    o\"\n",
      "batch 13058  loss=283.3855  steps/s=10.95  prediction: \"reply: @kubeden Id be down in the future\" => \"eple y@k/ssw$ðŸ˜dnj{,$$jjâ€ðŸ¤·â€™$j]â€èµ°ð˜‚{,æˆ‘$â€™ðŸ§ ðŸ˜,\"\n",
      "batch 13059  loss=138.6753  steps/s=108.54  prediction: \" know its doable\n",
      "https://t.co/DZCdUoVn6w\" => \"tit  nt  t  noo   o ootttottttto/ttttt//\"\n",
      "batch 13060  loss=144.0923  steps/s=104.34  prediction: \"w. Might do one every mon and every tues\" => \"a oe  o rottto too  o  o   o        eee \"\n",
      "batch 13061  loss=138.7656  steps/s=102.84  prediction: \" own instead of relying on school for it\" => \"tn oongoonn nn n o          n    o  o oo\"\n",
      "batch 13062  loss=153.2234  steps/s=103.67  prediction: \"ang out in tunisia every once in a while\" => \"ny ee a t    tt   t   i  n       n     i\"\n",
      "batch 13063  loss=138.8598  steps/s=103.23  prediction: \"ideo of you doing some crazy stuff. damn\" => \"ne i e    ti    o  oo  oo    o    o     \"\n",
      "batch 13064  loss=153.8994  steps/s=101.86  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"t d ee ese a   e    sssss ssssttttt/////\"\n",
      "batch 13065  loss=134.8979  steps/s=100.08  prediction: \" learn if youre not an opening memorizer\" => \"tit h t  a                       nnnnn n\"\n",
      "batch 13066  loss=155.8880  steps/s=101.40  prediction: \"ding man! Yeah lmk how it goes next time\" => \" ea  nrn a rnaf n a a a                 \"\n",
      "batch 13067  loss=151.1493  steps/s=99.19  prediction: \"he second one Unison (Knife Party Remix)\" => \"eng   m eanee P  e  nnnnnnonnn nn    n e\"\n",
      "batch 13068  loss=140.9691  steps/s=104.43  prediction: \"for typos and a list of other dumb stuff\" => \" r t a c tc                             \"\n",
      "batch 13069  loss=143.8900  steps/s=99.71  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"tha a a tt t  tatt    a a      a        \"\n",
      "batch 13070  loss=143.4321  steps/s=104.01  prediction: \" I didnt post AT ALL til it was 98% done\" => \"t sk ee d d   d             L           \"\n",
      "batch 13071  loss=154.9213  steps/s=99.75  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \"    eeeeeseseese e  e                   \"\n",
      "batch 13072  loss=151.8494  steps/s=97.46  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" ade s  e epe rse           o       so o\"\n",
      "batch 13073  loss=144.9783  steps/s=103.71  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"se to woon no  oooo      ttt  ttttt////s\"\n",
      "batch 13074  loss=171.8661  steps/s=43.82  prediction: \"y: @arithmoquine https://t.co/Aj4WZoykKU\" => \": @_o  roon n  ro  ttpp tttt.///ttt//sss\"\n",
      "batch 13075  loss=170.1063  steps/s=137.96  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BA   owwonoo u o  tsssstttocosrssssssss\"\n",
      "batch 13076  loss=199.6015  steps/s=21.52  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @wAwonoA PPo  tssssttto??ssssssssss\"\n",
      "batch 13077  loss=152.1268  steps/s=135.71  prediction: \", even my llm is on 3 cups of coffee bro\" => \" sod ey  y e  n l    l         s  o eeee\"\n",
      "batch 13078  loss=168.2750  steps/s=96.60  prediction: \"ped to have you join!!\n",
      "gl and have fun ðŸ«¡\" => \"lnt   n ne l  n    o  oo  oo   o !  f   \"\n",
      "batch 13079  loss=154.6376  steps/s=99.45  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"neMTB    rr   aa i   aalggoa\n",
      "\n",
      "oaaao   d \"\n",
      "batch 13080  loss=140.8969  steps/s=104.03  prediction: \"iterate certain ppl, but those are large\" => \"n'o o  ae e te tttt t    tttttt         \"\n",
      "batch 13081  loss=145.7866  steps/s=99.42  prediction: \" set at 5mins by default when unblocking\" => \"tti dt  t tt t                     n   n\"\n",
      "batch 13082  loss=146.1880  steps/s=102.04  prediction: \"eMTB I see slop poasting is the meta now\" => \" TB itt t n  s s see  s    n  nn      nn\"\n",
      "batch 13083  loss=144.0831  steps/s=105.35  prediction: \"rids\n",
      "gpus are 2d grids of 2d grids so 4d\" => \"ed  oee6ebnlbM9e7AjjbATA2:kv!!j,\n",
      "ww4!4jI\"\n",
      "batch 13084  loss=161.0965  steps/s=101.11  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \" d ir d oy rrdhd   ad d d   n           \"\n",
      "batch 13085  loss=146.3258  steps/s=103.32  prediction: \" have to reprompt it like 1/3rd the time\" => \"tan           e                         \"\n",
      "batch 13086  loss=140.5186  steps/s=98.06  prediction: \"ive sum game players\n",
      "tautologically true\" => \"ne ve    s  s em          aaeaatalalllal\"\n",
      "batch 13088  loss=150.9296  steps/s=101.34  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \" ane  s ss  s ss                        \"\n",
      "batch 13089  loss=150.4463  steps/s=102.78  prediction: \"ns must magnetically align their protons\" => \"   i  i   iis n i  llllliallllalllll    \"\n",
      "batch 13090  loss=146.2192  steps/s=103.38  prediction: \"mes there are 10x rewards for doing this\" => \"e t e\n",
      "nemmteteeee  eee rreere  r   rr   \"\n",
      "batch 13091  loss=158.4719  steps/s=105.02  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"@ud)\n",
      "-   o ddd d        a       s       \"\n",
      "batch 13092  loss=140.3066  steps/s=104.23  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h gr  uo  rn  ogooo ooo oo o   o o    o \"\n",
      "batch 13093  loss=151.0367  steps/s=102.08  prediction: \"stone cpus in it https://t.co/UsFG7LjU6T\" => \" :n    en nne  en     n   t t t t//t/t//\"\n",
      "batch 13094  loss=149.4264  steps/s=101.71  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"re cnn   ett  e    ttttttttttttttt//////\"\n",
      "batch 13095  loss=144.5494  steps/s=103.62  prediction: \" the most important parts of improvement\" => \"to  \n",
      "  oettoo oo   ottt t  t ott   tt mm\"\n",
      "batch 13096  loss=224.3413  steps/s=11.46  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"e li  @eaff,hke _TUbJGJKk,AIJx3IUJXG7,jD\"\n",
      "batch 13097  loss=137.7799  steps/s=108.03  prediction: \"ont like tech leave\n",
      "\n",
      "bulking and cutting\" => \"ut t f  t t    t    eeeeeeeeeeee e     n\"\n",
      "batch 13099  loss=152.1585  steps/s=105.28  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \"ploll dll!ldllo ll o\"\"o ooo  ooo oo    !\"\n",
      "batch 13102  loss=170.2726  steps/s=44.93  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \"  @lldel \"l  ln  o o n   oo    o oo !! !\"\n",
      "batch 13103  loss=151.1927  steps/s=108.51  prediction: \"would be insanely useful to do this with\" => \"irln   erdueu   ee ie ee u uul      e   \"\n",
      "batch 13104  loss=153.0415  steps/s=99.93  prediction: \"nt get too random with high stakes stuff\" => \"  Mdee  tt en  ta  o    oo      h hhhh  \"\n",
      "batch 13105  loss=154.5766  steps/s=104.34  prediction: \"makes a comeback they get a large reward\" => \"erer hai      a   a    e               e\"\n",
      "batch 13106  loss=161.7350  steps/s=60.34  prediction: \"@btwphones thanks! its going well so far\" => \"ytcieoa     eak aaae   e          ee e e\"\n",
      "batch 13107  loss=148.7501  steps/s=105.61  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \" n  ie    n    nn nn nnnennnneneeeenenee\"\n",
      "batch 13108  loss=167.1082  steps/s=105.30  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"@e c gc geg  g 2  7777772 2 /// ////tt//\"\n",
      "batch 13109  loss=138.7573  steps/s=104.11  prediction: \"ast 3 weeks so development has been slow\" => \"n  e  n    3  s  e  e  e eeee eeeeeeee  \"\n",
      "batch 13110  loss=174.4452  steps/s=29.31  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @e   n s  s  eeeee eeeeee eeeeeees s\"\n",
      "batch 13111  loss=142.5123  steps/s=109.00  prediction: \"did something similar w his site i think\" => \" n    ii ani   mim  ii   mi isii  ii  ii\"\n",
      "batch 13112  loss=160.1942  steps/s=104.76  prediction: \" goes over the massive 4096 token window\" => \"to  sssssoo oose   ee  ee      e    e   \"\n",
      "batch 13113  loss=156.0401  steps/s=101.71  prediction: \"t just means youre on par with a supergm\" => \"hts t ocscs sssmms                  r   \"\n",
      "batch 13114  loss=180.6412  steps/s=84.94  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"urho st  j ss m    OO   OOe   a  a    r \"\n",
      "batch 13115  loss=168.7411  steps/s=36.99  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @ su  ss  y  OOOO  OOOO   a  a    rðŸ›‘\"\n",
      "batch 13116  loss=162.2121  steps/s=112.91  prediction: \"papers\n",
      "ooh definitely examples are great\" => \"lst t   pe   pnr  ee o eeeoeeeee eeee ee\"\n",
      "batch 13117  loss=155.2616  steps/s=104.09  prediction: \"E gambits dude\n",
      "Punish mode is goated too\" => \"soLlOen ete,e?9eGky?PPT2qqIxLOVEjR3R:M++\"\n",
      "batch 13120  loss=173.4497  steps/s=104.68  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"t.ec\n",
      "ette///tt///tttttttt://t/tt:///tt//\"\n",
      "batch 13121  loss=164.8403  steps/s=104.40  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"  s   stnntteodomzo  oeot  e   t    t   \"\n",
      "batch 13122  loss=165.3873  steps/s=81.57  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lot/  mooeoenmm i   \"  o   e   l    a   \"\n",
      "batch 13123  loss=141.6482  steps/s=105.73  prediction: \"d luck to step on worms and they stopped\" => \" i  o i  t    tt                     t  \"\n",
      "batch 13124  loss=134.3320  steps/s=101.92  prediction: \"ure the first man on mars thats so crazy\" => \"n  ne  ee eeeeet                   s  s \"\n",
      "batch 13126  loss=148.9977  steps/s=101.77  prediction: \"i know bedrock api has a chat window too\" => \"nca t b t ob  bb           a   a a    a \"\n",
      "batch 13127  loss=154.6196  steps/s=100.02  prediction: \"eaply making synthetic training data? :)\" => \" di  n   na n  aann inn n  nniiintiiii a\"\n",
      "batch 13128  loss=146.9012  steps/s=104.71  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"yy eden  ueeu          ttttstttttttt////\"\n",
      "batch 13129  loss=158.5137  steps/s=70.48  prediction: \" miss the good old completion model days\" => \"tor  n uss ns tno ttsssttttptttt////////\"\n",
      "batch 13131  loss=175.0384  steps/s=89.31  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"ertm   enetll eoo   optpttt/t:/o//cocXXX\"\n",
      "batch 13132  loss=160.9170  steps/s=122.50  prediction: \"nis @sunsettler sun yearns for the mines\" => \" n  i ee soesseset  stt settss ooc ooH ðŸ›‘\"\n",
      "batch 13134  loss=167.8029  steps/s=80.56  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" di  ssuesstne set  ee     oo  oee ool l\"\n",
      "batch 13135  loss=175.8851  steps/s=104.34  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"@oe sgnggiinnnn  s    t     tt tt/t/////\"\n",
      "batch 13136  loss=151.5181  steps/s=105.31  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"@on ae! nen   e       n nnnnnnnnn       \"\n",
      "batch 13137  loss=155.3745  steps/s=104.89  prediction: \"at the beginning\n",
      "https://t.co/3p7b8v9xhe\" => \"n ire  eb te tee tetitnnntttttttttttt///\"\n",
      "batch 13138  loss=145.3412  steps/s=102.50  prediction: \"f time and space that can reach in here?\" => \"oi e ono         e       a aaaaa a      \"\n",
      "batch 13139  loss=136.8027  steps/s=100.82  prediction: \"y noticed the last time i was there, lol\" => \":he iMiiiieiteeteettttttt               \"\n",
      "batch 13140  loss=149.4418  steps/s=99.84  prediction: \"tand on the shoulders of retarded giants\" => \" l       etn  nt  t s  e   s   eeereerre\"\n",
      "batch 13141  loss=160.8727  steps/s=102.03  prediction: \"ke half my followers came from shoutouts\" => \"e e0 eo e b blyll llll       f fooooomoo\"\n",
      "batch 13142  loss=169.0177  steps/s=102.53  prediction: \"0x_0 how is crypto this good at replying\" => \"0lPros  xne.h@ e,g@0x_z,ox_0/E..ET337fff\"\n",
      "batch 13143  loss=149.6500  steps/s=100.65  prediction: \"new super super early on she was the one\" => \" syeler  ret  er    eee r er    es e   s\"\n",
      "batch 13144  loss=142.4393  steps/s=106.43  prediction: \"ings will continue until morale improves\" => \"ngBAP eeewese nnii   n n n  nnn l      e\"\n",
      "batch 13146  loss=144.6551  steps/s=101.79  prediction: \"ly beautiful\n",
      "Love seeing stuff like this\" => \"y: @Tnsananaaauelleleeeeeeeeeeeeeeee  e \"\n",
      "batch 13147  loss=165.1585  steps/s=79.32  prediction: \"zmobly has selo made the circle tool yet\" => \"mo od @gc mhf-wnL1v4--T4WWwTA?QQ4QQQQ4QQ\"\n",
      "batch 13148  loss=139.5141  steps/s=105.45  prediction: \"d luck to step on worms and they stopped\" => \" i  t i  t    tt                     t  \"\n",
      "batch 13149  loss=152.1046  steps/s=102.91  prediction: \"rings out there that would just ruin ppl\" => \"en l   shiiPaC t7&,;1104(xjvx).F,gjjj4zR\"\n",
      "batch 13151  loss=154.9609  steps/s=102.19  prediction: \"here for the funny symbols and recursion\" => \"er   er r   rrr e    h             n   n\"\n",
      "batch 13152  loss=153.5378  steps/s=103.63  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"ejii n  w   8 0 0000000               o \"\n",
      "batch 13153  loss=166.5062  steps/s=83.68  prediction: \"qc Based, a true warrior of the zig army\" => \"u r   x  t 0  n      t    o  o    o too \"\n",
      "batch 13154  loss=163.4045  steps/s=45.06  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y: @t no 0    t      rr  oo oo      to  \"\n",
      "batch 13155  loss=137.5815  steps/s=109.90  prediction: \" interesting to see what it hallucinates\" => \"@t  iutt tt tttttttt     t              \"\n",
      "batch 13156  loss=141.3744  steps/s=103.33  prediction: \"ling down on stuff I initially dismissed\" => \"yt o  monmnon   on n     nnn   i iiiiii \"\n",
      "batch 13158  loss=150.3569  steps/s=103.15  prediction: \"TB strategy is an abstraction of tactics\" => \"h ta e nn  Mn tts        aaia  itii iiis\"\n",
      "batch 13159  loss=161.9780  steps/s=102.25  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "  m\n",
      "a e s seseeeeeeeee ee  sss s  s  s\"\n",
      "batch 13160  loss=140.1819  steps/s=99.18  prediction: \"anning on putting this in an actual bot?\" => \"nd ea    nnn nnnnn  n nn  t       n    t\"\n",
      "batch 13161  loss=172.1578  steps/s=99.98  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"m Aud ecxBsdBx_ B@PzB}zkmBzP/Lz.jv/z&//;\"\n",
      "batch 13162  loss=143.1619  steps/s=105.01  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" re t  illllnlnnnnn n nn  ttt tt////////\"\n",
      "batch 13163  loss=152.6668  steps/s=104.48  prediction: \" to me except this feels 100x better fug\" => \"thits tt     e e  e eee    e  eee eeee  \"\n",
      "batch 13164  loss=162.4227  steps/s=99.42  prediction: \"utput brothers karamazov, word for word\"\" => \"s igAA u     tt tt t  t r    rr  arr  rr\"\n",
      "batch 13165  loss=172.8398  steps/s=99.94  prediction: \"inpeace I gotchu https://t.co/l34MQvLmOd\" => \"ng Ao ti pi e ec     t t tctott//////ooo\"\n",
      "batch 13166  loss=140.5351  steps/s=105.62  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \"  e e teett    . .......tt.t.tttttt/////\"\n",
      "batch 13167  loss=139.0816  steps/s=104.65  prediction: \"useful directions to take the project in\" => \"sefg efefefeeeueee   e tt t tt tttt  tt \"\n",
      "batch 13168  loss=161.9986  steps/s=79.16  prediction: \"minus9 hmm still pixels on my end, weird\" => \"ene t u eiu e ie   iti tt  t     e e  t \"\n",
      "batch 13169  loss=141.5032  steps/s=106.71  prediction: \" software used that widely is so awesome\" => \"toe a n  a    a                    s    \"\n",
      "batch 13170  loss=139.5070  steps/s=104.79  prediction: \"se so i have no idea if this would work)\" => \"  veeene n    n    e    e    i  i       \"\n",
      "batch 13171  loss=142.2441  steps/s=104.77  prediction: \"video w that id, it starts at that frame\" => \"ed  eni  et       i   t    tttttt t  ttt\"\n",
      "batch 13172  loss=153.1462  steps/s=102.74  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"eti  o ttto ootooo  ooooooooossssuuusuuu\"\n",
      "batch 13173  loss=163.8600  steps/s=104.15  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"t.us hst////t//1t11111ttt:////tt////t///\"\n",
      "batch 13174  loss=150.7350  steps/s=105.24  prediction: \"strategies like this. Gets way more data\" => \"    st tt tttessetts teeee ss    s      \"\n",
      "batch 13176  loss=154.2921  steps/s=98.26  prediction: \" can so can you. But maybe im projecting\" => \"tar      n s          a               m \"\n",
      "batch 13177  loss=173.3813  steps/s=102.93  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \" to      mt ma  m  mt tttttttttttttt////\"\n",
      "batch 13178  loss=142.4885  steps/s=100.74  prediction: \"the replies here\n",
      "https://t.co/9TNeUoLw5k\" => \" et     i  ne e eeeeeee eeehttttt///////\"\n",
      "batch 13179  loss=146.0837  steps/s=104.81  prediction: \"em all the cool ML stuff out there thatâ€¦\" => \" se t t     l  ll    l            t  tt \"\n",
      "batch 13180  loss=158.8391  steps/s=102.69  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"n   ret t t t t          eee   eeeeemeee\"\n",
      "batch 13181  loss=149.6055  steps/s=104.84  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" --gt;nte; t&t  ttsssttsss  s sssssss   \"\n",
      "batch 13182  loss=163.7603  steps/s=103.45  prediction: \"ame by making his brain care abt it more\" => \"nmeo  e mem  men     a  i     aaa  ba   \"\n",
      "batch 13183  loss=146.8914  steps/s=104.03  prediction: \"n run on my laptop, which I can do w ML?\" => \"gatoo r  e                              \"\n",
      "batch 13185  loss=158.9868  steps/s=103.65  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" tao  o   e e  eee eee e l ffffff f     \"\n",
      "batch 13186  loss=141.1941  steps/s=100.04  prediction: \"ont need sleep, your mind goes wide open\" => \"  e en  yee    ne   eee  e o    e    d  \"\n",
      "batch 13187  loss=145.3054  steps/s=105.81  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th     nnen  n niniiiiiiiiiii           \"\n",
      "batch 13188  loss=166.8792  steps/s=36.14  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \"  @see n \n",
      "iiniiiiniiiiii  i             \"\n",
      "batch 13189  loss=151.0971  steps/s=108.39  prediction: \" talking drains your energy for building\" => \"thie md d  nma n  ai n nn a  rnrrn r r r\"\n",
      "batch 13191  loss=178.8492  steps/s=98.40  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"t leinsa r aaa   kr ar er rt   t//or///9\"\n",
      "batch 13192  loss=147.1926  steps/s=104.91  prediction: \" elon keep going once they have billions\" => \"tve  n  l l   ee  e  e eeeeee      ee   \"\n",
      "batch 13193  loss=162.1529  steps/s=104.92  prediction: \"us @BasedBeffJezos Some are on the money\" => \"s @nese@ees eeseBBBeBeeeseeeeeee ee  e  \"\n",
      "batch 13194  loss=159.0871  steps/s=104.50  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"n@ s  e  me\n",
      "e \n",
      "e   e    e               \"\n",
      "batch 13195  loss=180.0867  steps/s=95.71  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \"  er ueener  eee   tt   tt tkt  ttt..///\"\n",
      "batch 13196  loss=157.2204  steps/s=100.51  prediction: \"lsio recursive mind exploding adventures\" => \"y  ilo eleeneeiee eiieeei i iiedidddddni\"\n",
      "batch 13197  loss=145.6884  steps/s=103.25  prediction: \"r something as small as starting on boot\" => \"ew_n  owrdy,w_p \"â€¦â€¦â€¦MIâ€¦â€¦â€¦:I:â€¦.â€¦â€¦câ€¦:xâ€¦G2C\"\n",
      "batch 13198  loss=146.0167  steps/s=106.08  prediction: \" function w gpt3.5 instead of uppercaseâ€¦\" => \"tinl  t ttef   6  t     ttt            p\"\n",
      "batch 13199  loss=189.1685  steps/s=91.56  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \"to r atilnnn6 it 0i   nii i9 s  eppereoe\"\n",
      "batch 13200  loss=151.7559  steps/s=103.10  prediction: \"t some point ill probably make it public\" => \" iol  t t   m            ob bbb       b \"\n",
      "batch 13201  loss=143.4151  steps/s=103.55  prediction: \" a lot will impact the rest of your life\" => \"ttdtn g na nn  l                        \"\n",
      "batch 13202  loss=169.9350  steps/s=100.78  prediction: \"pin it locked up https://t.co/ULHT2ys50k\" => \"ln    n t ei      t ttt  tttttpt//t//oo/\"\n",
      "batch 13203  loss=147.4822  steps/s=104.86  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" eoe eresededeeedeedeeeseeetstst//////tt\"\n",
      "batch 13204  loss=275.4187  steps/s=10.89  prediction: \"reply: @djcows leveraged short positions\" => \"ep y  @ h hhhxi 9,FFx-j@vjY8Fâ€¦xgâ€¦Yâ€¦â€¦L:ð—¼-\"\n",
      "batch 13205  loss=155.9558  steps/s=111.56  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " knd  pngnmev  ###S#-#v###++XSvK+ZZ+:I-\"\n",
      "batch 13206  loss=174.4688  steps/s=99.08  prediction: \"yacine needs a dingboard wrap on his car\" => \" c crcce0neec aea eeddnae da  d an  a   \"\n",
      "batch 13207  loss=203.6534  steps/s=11.61  prediction: \"reply: @mov_axbx https://t.co/Cmpmv44btj\" => \"eply: @f _ mnx_iz,@Sx-jvj@wB@wSvEI4gL:jI\"\n",
      "batch 13209  loss=181.1320  steps/s=63.36  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @crneenne   da e ddnae da  d an  aa  \"\n",
      "batch 13210  loss=149.0271  steps/s=111.41  prediction: \" the past two months and its so worth it\" => \"th   ov  te t et   tt     t   t   s  s  \"\n",
      "batch 13211  loss=160.6863  steps/s=104.15  prediction: \"hese it wants, i.e. (1, 0, 0, -1, -1, 1)\" => \"e  a   o n    tt           ,,,,,,,,,,,1,\"\n",
      "batch 13212  loss=159.2944  steps/s=101.44  prediction: \" flick of the wrist instead of traveling\" => \"toni Ps  f i          i i tt    tt   t  \"\n",
      "batch 13213  loss=145.2510  steps/s=105.41  prediction: \"heir own version\n",
      "https://t.co/9TSah3niap\" => \"er e  h rh    rr e   re   t tttoot//tt//\"\n",
      "batch 13214  loss=136.0469  steps/s=103.73  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \"te te t   tt  t  t  t t          u   u  \"\n",
      "batch 13215  loss=144.8920  steps/s=103.89  prediction: \"t\n",
      "so.. hopefully i can get it to do that\" => \" \n",
      "j tt      peeee                       \"\n",
      "batch 13216  loss=148.4362  steps/s=104.00  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \"hoo  o  fi tiiii iii                   o\"\n",
      "batch 13218  loss=145.0667  steps/s=103.86  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"yyr d n  teeu          ttttssttttt//////\"\n",
      "batch 13219  loss=157.6046  steps/s=103.87  prediction: \"erminal sub window alongside your files?\" => \"   sa et n ta       a aan  w   n  ii    \"\n",
      "batch 13220  loss=148.0792  steps/s=101.62  prediction: \"ted to see how cracked you get long term\" => \" rm  olet  ereeee  e   eee     e e e    \"\n",
      "batch 13221  loss=168.7391  steps/s=89.30  prediction: \"npaul_ai Improves irl ppls responses too\" => \" u    eet  oe ete  ee  oe   e   o    reo\"\n",
      "batch 13222  loss=140.8741  steps/s=104.98  prediction: \"our phone constantly. i had this problem\" => \"nlol  n  con   cooononn  n   n h        \"\n",
      "batch 13223  loss=144.7221  steps/s=104.35  prediction: \"did it again w feedback itd be the paper\" => \" fn  d d d  d i                         \"\n",
      "batch 13225  loss=184.5278  steps/s=54.47  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @aed rmkeehmRmo21â€¦TRL'''vI'yâ€¦55RI'8Z55w\"\n",
      "batch 13226  loss=149.6617  steps/s=108.58  prediction: \"ms' meaning more straightforward success\" => \"a bhe t btem eeme mmmmmme   rrr  rarrrrs\"\n",
      "batch 13227  loss=144.1805  steps/s=105.46  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" wht  t int  a a    t ttth hhtttst//t/t/\"\n",
      "batch 13228  loss=143.5560  steps/s=105.18  prediction: \"tory by far. it continues to surprise me\" => \"h  ac  a na naa                         \"\n",
      "batch 13229  loss=153.3552  steps/s=101.86  prediction: \"es gets rounded up to 0.1s\n",
      "\n",
      "why? idk man\" => \" t an  eenseee s ee e  d              d \"\n",
      "batch 13230  loss=163.9895  steps/s=103.22  prediction: \"like scalars\n",
      "\n",
      "d(Mx)/dx = M\n",
      "\n",
      "d(Mx)/dM = x\" => \"yktree e re ss aaaa\n",
      "\n",
      "\n",
      " sMMMMMMxMMxMx\n",
      "M=x\"\n",
      "batch 13231  loss=146.2466  steps/s=101.49  prediction: \"i have a few libraries in there sadly :9\" => \"twaaa   a   a   a              e  eeee  \"\n",
      "batch 13232  loss=167.8311  steps/s=103.32  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"   ot t0se0s0s0e000k t000///tt s///tt/t/\"\n",
      "batch 13233  loss=164.4425  steps/s=86.19  prediction: \"odor_io worst metric youve heard so far?\" => \"  oseo ooseee0et ttt  t/// t/tocct ceRRe\"\n",
      "batch 13234  loss=143.9379  steps/s=106.45  prediction: \"us things that make your life easier ig?\" => \"stibiiiiiiiitit tt  tt                  \"\n",
      "batch 13235  loss=137.9541  steps/s=105.07  prediction: \" different distribution of training data\" => \"tot evee h  t  eeeeeetttiititiiiiiiinini\"\n",
      "batch 13236  loss=145.8547  steps/s=101.26  prediction: \"o my head\n",
      "\n",
      "empirical blog posts are king\" => \" de ee      eem  ee  ei         oo    o \"\n",
      "batch 13237  loss=134.2493  steps/s=103.62  prediction: \"uture w her, and what that would be like\" => \"s  nn  te   t ee             w          \"\n",
      "batch 13238  loss=152.3913  steps/s=102.07  prediction: \"n\n",
      "Meet the new boss\n",
      "Same as the old boss\" => \"t\n",
      " e e eeknetet neeee eesee e   e   e  s\"\n",
      "batch 13239  loss=149.9508  steps/s=100.92  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \" ul  t ethhw               ttttttttt////\"\n",
      "batch 13240  loss=149.2699  steps/s=105.76  prediction: \"ow readable zig is. how does ak do it???\" => \" ig  n  ee n  er      e                 \"\n",
      "batch 13241  loss=165.6376  steps/s=99.79  prediction: \"e77 build things people want/ need maybe\" => \" 7oi @ciecee7iiii    i  l   e e   ee  e \"\n",
      "batch 13243  loss=180.4386  steps/s=96.15  prediction: \"w many GFLOPS? Are these legal in CA????\" => \"hml      o  i w      O    e e ee ee    e\"\n",
      "batch 13244  loss=134.0504  steps/s=103.88  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"e  d  btttt tt t  t     s      ieeeeeeee\"\n",
      "batch 13245  loss=137.9366  steps/s=104.04  prediction: \"hinking and just saying what feels right\" => \"es  t o tg g/n  n n nnn                 \"\n",
      "batch 13246  loss=133.0117  steps/s=34.85  prediction: \"st: caffeine is steroids but for posting\" => \" a  t  gnnnnnn n    nn                  \"\n",
      "batch 13247  loss=137.5333  steps/s=109.16  prediction: \"f you could 1.2x all the engineers there\" => \" aoarga u u uu uuu  d  l   l  l   eeeeee\"\n",
      "batch 13248  loss=137.5259  steps/s=103.59  prediction: \"ovate too and come up w cool experiments\" => \" e l ne nono  onooo         o        e e\"\n",
      "batch 13249  loss=145.3132  steps/s=104.41  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n  a i   h d   i  i   d  AAA d   i   d d\"\n",
      "batch 13250  loss=151.4698  steps/s=98.41  prediction: \"see more details as you unblur an image.\" => \" d      t     e  ee   a          u   u u\"\n",
      "batch 13251  loss=147.7285  steps/s=100.35  prediction: \"kes a lot of sacrifice and energy though\" => \"e   tngtettesas  s  aa aa  a  e   e     \"\n",
      "batch 13252  loss=159.3344  steps/s=103.26  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \"hish s     s  s   oo ooo  onnnnn  nn    \"\n",
      "batch 13253  loss=169.8156  steps/s=102.47  prediction: \"up man youre gonna go far over the years\" => \"sei   tepp  p u   e   n     n     r     \"\n",
      "batch 13254  loss=194.7308  steps/s=26.71  prediction: \"eply: @bozo10n you can just build things\" => \" ly:   ep   e p   e   n                 \"\n",
      "batch 13255  loss=166.8770  steps/s=152.80  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" d!  u uusuen  n  a n o    oo   ooee eee\"\n",
      "batch 13256  loss=153.5035  steps/s=101.73  prediction: \" a friend that did this for a CS project\" => \"@  u    ea an a      dd   ti       o   r\"\n",
      "batch 13257  loss=148.4704  steps/s=103.13  prediction: \"to fill them in fast, like you mentioned\" => \"    ys t ettt t                         \"\n",
      "batch 13258  loss=143.6076  steps/s=103.32  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" ts l   s   s g     ssss                \"\n",
      "batch 13259  loss=136.8958  steps/s=102.75  prediction: \" was mated instead, so he resigned lmaoo\" => \"tan  hn   tt   t               eeeeeeeee\"\n",
      "batch 13260  loss=145.3828  steps/s=104.51  prediction: \"hat easy guys, you learn like way faster\" => \"at a le l t   a y yyy yyy              a\"\n",
      "batch 13261  loss=139.5147  steps/s=104.02  prediction: \"pired link broadcast out to the most ppl\" => \"ln a w h e                      t tttttt\"\n",
      "batch 13262  loss=139.8384  steps/s=103.95  prediction: \"ed hard at improving, mostly by studying\" => \"  w     rhrr  dd   r r    o  o        yy\"\n",
      "batch 13265  loss=140.6616  steps/s=105.23  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" to oit leeenll llllllllll ,,, ,,,,,    \"\n",
      "batch 13266  loss=148.6198  steps/s=102.83  prediction: \"broth but it tastes awful lol any advice\" => \"ein  ooo bb b t t tttttt tt             \"\n",
      "batch 13268  loss=142.9596  steps/s=105.38  prediction: \"randomly via ssh https://t.co/3MxqH9R1Ya\" => \"enn   e signgM  2IzHF:/JB?-AMvM:zH9.1YC3\"\n",
      "batch 13269  loss=147.8150  steps/s=103.04  prediction: \"libraries or backend compute or anything\" => \"yktiteneeir rrr rr rrrr r               \"\n",
      "batch 13270  loss=156.2147  steps/s=103.16  prediction: \"movie)\n",
      "\n",
      "Wifi mode when its high (gaming)\" => \"adR is   niniimi i iii  ii ii   i  h hh \"\n",
      "batch 13271  loss=158.2473  steps/s=105.33  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"ea\n",
      "n  \n",
      "nt n   hnx     nn n          ___ \"\n",
      "batch 13272  loss=152.2184  steps/s=99.40  prediction: \"feeling than automating hrs of work away\" => \" r   e eeeten n   n    ana  a           \"\n",
      "batch 13273  loss=144.6297  steps/s=103.23  prediction: \"have the opposite happen, do more stuff?\" => \"et    e t oo  te o pp pppp   pppp pe   o\"\n",
      "batch 13274  loss=157.0995  steps/s=97.28  prediction: \" stuff! Thanks, hope yours went well man\" => \"tee  ho ooto   ts    h h       o    e   \"\n",
      "batch 13275  loss=145.7148  steps/s=97.99  prediction: \"ait to see what you cook up with giz inc\" => \"tn  oi  t t    t  t t  o o o    o   o   \"\n",
      "batch 13276  loss=139.7465  steps/s=102.99  prediction: \" of indirection? Is that why that works?\" => \"tf e        fiiiiiiiii           tt tt t\"\n",
      "batch 13277  loss=170.1043  steps/s=96.70  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" t oldoidAce@eneeees______ __           \"\n",
      "batch 13278  loss=146.9490  steps/s=103.36  prediction: \"error signals, weakening backpropagation\" => \"  enee ee nee r rr e eene nnnankaaknaaaa\"\n",
      "batch 13279  loss=145.4326  steps/s=97.42  prediction: \"c ig lisp and haskell are in the 10% lol\" => \"htss  s iiii  ii       l  l    l        \"\n",
      "batch 13280  loss=146.2796  steps/s=101.04  prediction: \" billion zimbabwe dollars of labor hours\" => \"@uvi bl bala bi bbbb b blbll  lllll looo\"\n",
      "batch 13281  loss=162.6922  steps/s=103.10  prediction: \"??\n",
      "\n",
      "oh wow it is https://t.co/dShiVDjfFr\" => \" ?\n",
      " w h ro?? wn ww w       s  // ///////\"\n",
      "batch 13282  loss=149.1385  steps/s=99.86  prediction: \"plate btw if u wanna make ur own version\" => \"ly:  l  ebt ttm  t  a a   a             \"\n",
      "batch 13283  loss=136.8880  steps/s=104.63  prediction: \" my weird posts but im happy nonetheless\" => \"tote tneetete  t      t                 \"\n",
      "batch 13284  loss=155.8766  steps/s=104.95  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"h sonth h////tthtttthhttttth///ttt////PP\"\n",
      "batch 13285  loss=183.1617  steps/s=44.09  prediction: \"y: @EsotericCofe https://t.co/qJ19YldyDK\" => \"  @ne ntt/thRththtttthh//tt.///PPP/PPttD\"\n",
      "batch 13286  loss=146.3158  steps/s=107.25  prediction: \"ful defensive ai to guard you in cyber,â€¦\" => \" netewa  ereperfee eeee  e              \"\n",
      "batch 13287  loss=155.6156  steps/s=69.69  prediction: \"is would make a really cool pfp actually\" => \"n  e t fsewuue  ee e   e l    oo       u\"\n",
      "batch 13288  loss=239.4221  steps/s=16.38  prediction: \"reply: @papyruski @justalexoki elaborate\" => \"eply: thisdhhW o\n",
      "@?/W?xF)bgx,!Cx?,Pbcx,â€¦\"\n",
      "batch 13289  loss=196.3239  steps/s=72.99  prediction: \"eply: @kayzee_ow https://t.co/y0ck4lbyrK\" => \" ly: ep s efdef e  e   e l   ooo   u  ay\"\n",
      "batch 13290  loss=151.9979  steps/s=115.57  prediction: \"u actually did the work so youre chillin\" => \"sce tttt  t t a                o       o\"\n",
      "batch 13291  loss=192.1067  steps/s=21.63  prediction: \"eply: @btwphones Thanks! more on the way\" => \" ly: att aaat t                o       o\"\n",
      "batch 13293  loss=144.5671  steps/s=106.97  prediction: \"discovering new unseen fundamentals, too\" => \" ne ted d\n",
      "edi edn nnennnneenennnneennnen\"\n",
      "batch 13294  loss=138.9181  steps/s=106.00  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"toisgsttn iiniet        lll ll  l   ee e\"\n",
      "batch 13295  loss=146.1710  steps/s=97.04  prediction: \" takes a lot of work and years of it tho\" => \"thie oi nisell lll o   ooo  ne e        \"\n",
      "batch 13296  loss=142.6682  steps/s=104.69  prediction: \"d meant i could do whatever i wanted lol\" => \" ae t eaaaaat  d          d             \"\n",
      "batch 13297  loss=138.9424  steps/s=99.01  prediction: \"u were in vim, it should start the timer\" => \"sgetr y  i n  i                   tttttt\"\n",
      "batch 13298  loss=164.5829  steps/s=39.15  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @ye     i  i i              tt tttttt\"\n",
      "batch 13299  loss=213.9994  steps/s=140.07  prediction: \"icCapital COMMENCE OPERATION BRAIN DRAIN\" => \"nh arr riiiCC CC   CCEElE E tOtAA N NN R\"\n",
      "batch 13300  loss=142.4449  steps/s=105.48  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" re t  itnlnnlnnnnn n nn  ttt tt////////\"\n",
      "batch 13301  loss=152.5501  steps/s=103.34  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"tlyt t   t  t      \"\"\"\"\"\"               \"\n",
      "batch 13302  loss=160.1340  steps/s=88.07  prediction: \"_software its c to wasm using emscripten\" => \" e_li n ttw  t\"wt  ttt  w w        s    \"\n",
      "batch 13303  loss=155.1749  steps/s=103.42  prediction: \"a get my future kids on this kinda stuff\" => \"npoe ween n t nn             e    i     \"\n",
      "batch 13304  loss=162.5747  steps/s=99.60  prediction: \"sing llms to their full potential rn tbh\" => \" oe    eel rr e    l  tllt  li  tli   tl\"\n",
      "batch 13306  loss=147.0012  steps/s=102.27  prediction: \"ns the returns are high on more of it :)\" => \"gt a     hsh  ttes  re       h  rr      \"\n",
      "batch 13307  loss=164.0466  steps/s=103.75  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"tene n   e en n                t////////\"\n",
      "batch 13308  loss=154.2558  steps/s=102.45  prediction: \"very instructive zig raylib example/code\" => \"e   i i   s   i i ii i ri iii    ii  iee\"\n",
      "batch 13309  loss=167.1759  steps/s=99.67  prediction: \" wtf is a monoidal field\n",
      "\n",
      "i want to know\" => \"@orr nr rt rtmn  i    aaiaie iialll\n",
      "ee  \"\n",
      "batch 13310  loss=137.9953  steps/s=103.13  prediction: \"cting statements, they cease to conflict\" => \"oitlt   nonint ettttttttttteeeeeeeeeee  \"\n",
      "batch 13311  loss=170.5921  steps/s=97.47  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"lernP_taata ttaatataa s  s e    ee eeeee\"\n",
      "batch 13312  loss=170.5221  steps/s=101.03  prediction: \"king stuff part of twitter is so fun wtf\" => \"in atk t00s s  ta t  f tff t r  e tsisis\"\n",
      "batch 13313  loss=144.6591  steps/s=102.54  prediction: \"f time and space that can reach in here?\" => \" iierono e       e       a aaaaa a      \"\n",
      "batch 13314  loss=141.5804  steps/s=102.86  prediction: \"dnt mention anything related to caffeine\" => \"  t l tetltttt    nn n nnttnntn  t te t \"\n",
      "batch 13315  loss=141.2168  steps/s=105.00  prediction: \"e the reward dips down below the average\" => \" ie h  hereerrrdrer  d  ddd    we    e  \"\n",
      "batch 13316  loss=163.2237  steps/s=69.39  prediction: \"justalexoki the t has always meant taoki\" => \"jst ge rtedrerrd d d d    w w w w   eee \"\n",
      "batch 13317  loss=165.3494  steps/s=53.76  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: @ue  tedeerdd dh    ww s w e     ao  \"\n",
      "batch 13319  loss=157.0520  steps/s=118.00  prediction: \"reading the code, most are from zig init\" => \"eply:  ooonk64  O64_3I3bvZ44y&XQbyv8m888\"\n",
      "batch 13320  loss=159.6422  steps/s=101.74  prediction: \"papers\n",
      "ooh definitely examples are great\" => \"lni    rpep   n   ee o eee eeeee eeeeeee\"\n",
      "batch 13321  loss=159.3105  steps/s=105.22  prediction: \"ke half my followers came from shoutouts\" => \"e l0    e b bllll llll       o fooooomoe\"\n",
      "batch 13322  loss=143.5639  steps/s=105.07  prediction: \"ably one of the bests way to get smarter\" => \"nli io  onoboo   o                    t \"\n",
      "batch 13323  loss=172.7915  steps/s=102.26  prediction: \"n.. animate it bros. that's 60fps almost\" => \"  ite  etetnn.t. t. .. tattt ts   t ss  \"\n",
      "batch 13324  loss=159.6566  steps/s=103.66  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"iene  e  u en e               //////////\"\n",
      "batch 13325  loss=151.7628  steps/s=104.10  prediction: \"rf spatial in problem solving efficiency\" => \"eioeaiesnemnej ejjjjjjjjjjjjj;;60;&6060;\"\n",
      "batch 13326  loss=153.6768  steps/s=100.98  prediction: \"d it! Lmk how it goes man. Hope it helps\" => \" toi i   i                              \"\n",
      "batch 13327  loss=146.0988  steps/s=105.26  prediction: \"g Seatbelt doesn't want you to know this\" => \" ah ieeeeegeteetteeeetttet ttt  t   t  t\"\n",
      "batch 13328  loss=145.3040  steps/s=105.83  prediction: \" cliff in one go. like, good luck w that\" => \"toot ot  f     f                        \"\n",
      "batch 13329  loss=138.3999  steps/s=105.28  prediction: \" different distribution of training data\" => \"tov htee h  t eeeeeeetttiititiiiiiiinini\"\n",
      "batch 13330  loss=177.9012  steps/s=83.34  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn he feeteditddiittiittti ttiitnnn n na\"\n",
      "batch 13331  loss=161.2438  steps/s=104.79  prediction: \"y the paper i thought it was a neat read\" => \":type a  nEEn hhppp  h   hhhht   t     a\"\n",
      "batch 13332  loss=149.8697  steps/s=101.47  prediction: \" yapping like lud mentioned sounds great\" => \"tout nimnin iiii      ii      innn nn  n\"\n",
      "batch 13333  loss=156.4235  steps/s=106.10  prediction: \"sunami\n",
      "- job stuff\n",
      "\n",
      "Mistakes/to improveâ€¦\" => \" reG  T nonon on    o f\n",
      "\n",
      "\n",
      "\n",
      "ss\n",
      "sssstsstst\"\n",
      "batch 13334  loss=126.5355  steps/s=102.68  prediction: \" --. .. ...- . / -.-- --- ..- / ..- .--.\" => \"@- .. /.......... . . ----------- -   ..\"\n",
      "batch 13335  loss=194.5892  steps/s=100.70  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \" nicn r er uereu tututttt//ttt///t//ttt/\"\n",
      "batch 13336  loss=145.7190  steps/s=103.76  prediction: \"urself, if you can manage to pull it off\" => \"  lnee ll l l y y                       \"\n",
      "batch 13337  loss=193.6693  steps/s=72.91  prediction: \"H LETS GOOOOO\n",
      "truly a masterpiece lmaooo\" => \"Sbi   te  AOOO OOOOOOOO O  a  aa   a a  \"\n",
      "batch 13338  loss=156.7416  steps/s=121.33  prediction: \"ressure either turns to dust or to a gem\" => \"eply: dBunhJBzt JOzETSOGETS&GALkOwLCPTGw\"\n",
      "batch 13339  loss=174.5546  steps/s=69.81  prediction: \"helscom a new $500k logo should fix this\" => \"ereee esss rerJeeereere   st ss  t t  o \"\n",
      "batch 13340  loss=139.6640  steps/s=106.05  prediction: \", thank God we can function at all loool\" => \" iee i e r d  te      a   n       an  a \"\n",
      "batch 13341  loss=155.0659  steps/s=104.94  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"t.cnneet//::N///ttttthhtth:t//:t//ttp///\"\n",
      "batch 13342  loss=140.5145  steps/s=105.23  prediction: \"s large of a positive impact as possible\" => \" Iieaa aa aaa                        sss\"\n",
      "batch 13343  loss=157.9282  steps/s=99.29  prediction: \"r model architecture not based on tokens\" => \"eety   yri\n",
      "Xn3n bGABwGyA0II)L:wW9:wkkW-I\"\n",
      "batch 13344  loss=149.2756  steps/s=101.00  prediction: \" for yourself they pay dividends forever\" => \"tovoo loooooooooo    o       y ydd ddddd\"\n",
      "batch 13345  loss=149.2353  steps/s=101.32  prediction: \"rner u can actually set them to 2x speed\" => \"eeay n@angxbeOtsbGABww*:ð—¼II)b:r2x:wkMW-2\"\n",
      "batch 13347  loss=153.5982  steps/s=21.02  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \" tto o  r   cc   cc       t   t  t t  t \"\n",
      "batch 13348  loss=167.4501  steps/s=116.89  prediction: \"te wow\n",
      "\n",
      "followed https://t.co/riXL2UlhdY\" => \"hr  reo  to w  ooooooltwltotttttttt/////\"\n",
      "batch 13349  loss=149.7066  steps/s=101.74  prediction: \"is such a great productivity improvement\" => \"n  a    uu                    t itttiiii\"\n",
      "batch 13350  loss=138.7130  steps/s=103.96  prediction: \"too, its good to break your priors intoâ€¦\" => \"h t     t ttoootooooooooo o      o    rr\"\n",
      "batch 13351  loss=181.6355  steps/s=105.01  prediction: \"/t.co/zlto3SBYwd https://t.co/vZrNZfgxps\" => \"/.eu hnt/nn/t//o/t//ttttt:/t//tt/tt/t//Z\"\n",
      "batch 13352  loss=146.4604  steps/s=103.24  prediction: \"e the last clip\n",
      "\n",
      "https://t.co/CPSXwfs38G\" => \" thrn esehtees e ett\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tt\n",
      "\n",
      "tttt/ttttt/\"\n",
      "batch 13353  loss=151.9240  steps/s=95.44  prediction: \"ok me a second but damn thats a good one\" => \"n  me t    m  t e  e e  t ttdtt tttt aa \"\n",
      "batch 13354  loss=178.2349  steps/s=99.90  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"i_l @wed@BgPBxï¸ B,PzBwzá´‡:BzP.cz|CPbzwwyb\"\n",
      "batch 13355  loss=183.0367  steps/s=68.38  prediction: \"@yacineMTB so youre no longer locked in?\" => \"lacpi0Aie  eg  g&;;gg;;gtggtggggttmiim i\"\n",
      "batch 13356  loss=165.8367  steps/s=107.08  prediction: \"minus9 This is my new favorite edm track\" => \"eze   rmeneBT ti    te gntt t triieiee i\"\n",
      "batch 13357  loss=145.7675  steps/s=105.71  prediction: \"ain world model) to understand the world\" => \"tn r oo oo ro  oorr   o  o do   ddd t td\"\n",
      "batch 13358  loss=140.0696  steps/s=105.21  prediction: \"o halt with a general halting function?\"\" => \" st eomtn  ttt t  t t      aaa a  a nnn \"\n",
      "batch 13359  loss=152.1727  steps/s=102.39  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"neo   oo  on oo   e   eeee  eeeeeeeeeeee\"\n",
      "batch 13360  loss=155.8853  steps/s=103.54  prediction: \"ught it was a cool idea so i speedran it\" => \" hit\n",
      "to\n",
      "et tttit t        o             \"\n",
      "batch 13361  loss=152.0522  steps/s=100.37  prediction: \"ll send you a link to it around the 25th\" => \"y y    y lsss   y     l                t\"\n",
      "batch 13362  loss=156.2809  steps/s=102.58  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"AV m  ,       HW    s??????tssstttt/////\"\n",
      "batch 13364  loss=163.4840  steps/s=90.44  prediction: \"minglunatic @kuberdenis im also catholic\" => \"enoi s,  n n??n  tt kssssttstsssBBBttooo\"\n",
      "batch 13365  loss=141.0400  steps/s=104.97  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" to iitllee nll llllllllll ,,, ,,,,     \"\n",
      "batch 13366  loss=178.0667  steps/s=99.24  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "hen  @ihALLtEme\n",
      "Lxz.\n",
      "L-jB-zOSj.APPQjjj6\"\n",
      "batch 13367  loss=140.7968  steps/s=104.56  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" st p t  e  n   e     e eeeeeeeieeeieeee\"\n",
      "batch 13368  loss=144.5654  steps/s=104.96  prediction: \"ain world model) to understand the world\" => \"nn rroo  o ro  oorr   o  d do   ddd t td\"\n",
      "batch 13369  loss=145.6171  steps/s=105.10  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tf c i  siss soss sss sss   t   t   ta a\"\n",
      "batch 13370  loss=227.4341  steps/s=104.17  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"B EFU  U UUJUTSST SSFFFFFF FF  t ///////\"\n",
      "batch 13371  loss=191.8335  steps/s=30.80  prediction: \"ply: @camhowe1729 No problem, good tweet\" => \"lyc @O O   TS SST S FFFFFF F  /t//////E/\"\n",
      "batch 13372  loss=164.6745  steps/s=122.98  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"hi B  a etr        r  o       i i  i   @\"\n",
      "batch 13373  loss=147.0028  steps/s=103.60  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \" rs iii i   n   n                       \"\n",
      "batch 13374  loss=186.4717  steps/s=86.41  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"yt  Cin n s\n",
      "n ln000   e\n",
      " t dd dt        \"\n",
      "batch 13375  loss=146.6355  steps/s=104.84  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne   mi   im mieeememoeemeeee eee eeee e\"\n",
      "batch 13376  loss=144.2186  steps/s=104.00  prediction: \"video w that id, it starts at that frame\" => \"ed  eiee et       i   t    tttttt t  ttt\"\n",
      "batch 13378  loss=159.8874  steps/s=82.82  prediction: \"builds mcdonalds just wants to grill man\" => \"lt s eb   t tdd d  ddd  stst tttt tt  a \"\n",
      "batch 13379  loss=142.0644  steps/s=106.23  prediction: \"igh quality outputs with infinite tokens\" => \"net   n uhhuu huuu uu  uuttitttiitititii\"\n",
      "batch 13380  loss=146.5122  steps/s=99.68  prediction: \"ait to see what you cook up with giz inc\" => \"ln r a  t t    t  t t t         o   o   \"\n",
      "batch 13381  loss=140.7397  steps/s=99.88  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"rns  pp  o o  e    e  eee  eeee         \"\n",
      "batch 13382  loss=169.8277  steps/s=96.89  prediction: \" wtf is a monoidal field\n",
      "\n",
      "i want to know\" => \"tao  go gt me n  o    aa a\n",
      "\n",
      "\n",
      "l \n",
      "l  \n",
      "\n",
      "t  \"\n",
      "batch 13383  loss=134.6084  steps/s=103.16  prediction: \" and the quote tweet is the reply itself\" => \"t  et e tettettetteetteeteeeeee eee   e \"\n",
      "batch 13384  loss=141.8553  steps/s=103.75  prediction: \"tal clarity and less of a need for sleep\" => \" ls   n neenn  laal ll    a             \"\n",
      "batch 13385  loss=231.8227  steps/s=96.86  prediction: \"UR BROBLEM GREEN https://t.co/mstazBvsCM\" => \"AN\n",
      "REA WðŸ“ˆ}YYUUxYBUDLLMMGGEMNNREMNp::/C.:\"\n",
      "batch 13387  loss=155.2755  steps/s=104.73  prediction: \"mentals can be really really hard to see\" => \"e taie nonss na  n aaa  aallall  alll   \"\n",
      "batch 13388  loss=149.7263  steps/s=104.86  prediction: \"ally fun/challenging/interesting for ppl\" => \"n  t  ma a n a llllllllnnnnnnnnnnnnnnnng\"\n",
      "batch 13389  loss=143.8459  steps/s=105.40  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r o     t  si i siiississssststt///////\"\n",
      "batch 13390  loss=140.0796  steps/s=104.65  prediction: \"et back up and get back at it eventually\" => \" t i aa tatt  a                         \"\n",
      "batch 13391  loss=158.2162  steps/s=102.66  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" :   r s??  f?s s    ts  st  ttttt////t/\"\n",
      "batch 13392  loss=147.9445  steps/s=105.25  prediction: \"n a bit and just work later into the day\" => \" yoo   s eei                      t  t t\"\n",
      "batch 13393  loss=142.8010  steps/s=100.65  prediction: \"r been a better time to be a corn kernel\" => \"es y  @ct@sITcfrB+T.5v:T0,gvI+)IvvI.@J;z\"\n",
      "batch 13394  loss=180.5514  steps/s=104.65  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lr  b  ssi  sue u           ttttttt/////\"\n",
      "batch 13395  loss=146.8843  steps/s=99.04  prediction: \"s. let the people decide. for danmocracy\" => \"  see eeett te  ee eee eeee ee eeeooeddc\"\n",
      "batch 13396  loss=136.3332  steps/s=104.36  prediction: \" will get back to you when this is fixed\" => \"taaw p i w l lw                         \"\n",
      "batch 13397  loss=139.6630  steps/s=102.57  prediction: \"thing you do very often, like constantly\" => \"hi i    fi ts n     o                   \"\n",
      "batch 13398  loss=163.0557  steps/s=104.46  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"t.ck sst////t//1t11111ttt:////tt////t///\"\n",
      "batch 13399  loss=140.0180  steps/s=104.46  prediction: \"experience but i work w someone who does\" => \" pt   n ennenee eeeee                ooo\"\n",
      "batch 13400  loss=143.5613  steps/s=105.04  prediction: \"d take a bite of a giant company's lunch\" => \" to s    a                 a     aa  a  \"\n",
      "batch 13401  loss=157.7309  steps/s=102.88  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"ntaaa aa nn nanammmmmmmmm mmmm          \"\n",
      "batch 13402  loss=144.6371  steps/s=102.41  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"tans mem em  eecec  ee    ee     e  o oo\"\n",
      "batch 13403  loss=164.2226  steps/s=105.24  prediction: \"kers #math #saas https://t.co/99Y0IouvaF\" => \"ed2 iniiiin# #s####ssssssssssssttttt///9\"\n",
      "batch 13404  loss=278.2063  steps/s=10.61  prediction: \"reply: @daltonc its a form of rumination\" => \"e lye !  vy g,Kp[b:*ðŸ°ðŸ‘€.,,,[Ê€${qð˜‚k`*Éª{*â€œ]\"\n",
      "batch 13407  loss=142.7955  steps/s=109.44  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tate rn  nrn  no       o      o   o   ii\"\n",
      "batch 13408  loss=152.3027  steps/s=104.59  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"tote - t t eo  -o o  \n",
      "ee\n",
      "\n",
      "\n",
      "ttttt/tt/s///\"\n",
      "batch 13409  loss=177.9645  steps/s=38.35  prediction: \"ly: @gizmobly probably\n",
      "especially if bjj\" => \"y  @g-tt  oee  eoo\n",
      "\n",
      "\n",
      "\n",
      "tetppttttt////s///\"\n",
      "batch 13410  loss=143.0045  steps/s=106.84  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" dte        n g      nnnnnttttttttt/////\"\n",
      "batch 13412  loss=151.4832  steps/s=100.28  prediction: \"ly pretending to give unsolicited advice\" => \"y   h e 5 rreeht ee        e e eii niiie\"\n",
      "batch 13413  loss=142.9763  steps/s=103.84  prediction: \"the most useful? https://t.co/w0tVqarS34\" => \"he   r  tr     e  tte t tttstttttt//tttt\"\n",
      "batch 13414  loss=150.3893  steps/s=103.49  prediction: \"o you get more data) or hit a \"dampener\"\" => \"nsoo  o o(o  oo                         \"\n",
      "batch 13415  loss=150.8342  steps/s=100.85  prediction: \"ings will continue until morale improves\" => \"ng   egeewem  ntt       ii    iil  n   i\"\n",
      "batch 13416  loss=171.1518  steps/s=40.66  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @tinwiauBaPeTr P?Tz.(G):Gð—°zÊœG*w[ðŸ¤·\"Vqb:S\"\n",
      "batch 13417  loss=139.2898  steps/s=106.50  prediction: \"started begging me to let him pay for it\" => \" al  t   t  tgeggggggg gg               \"\n",
      "batch 13418  loss=161.9418  steps/s=104.93  prediction: \"ors let you get to the meat of it faster\" => \"n a  t   rlt e t      ttt    tttt    t  \"\n",
      "batch 13419  loss=155.8278  steps/s=102.33  prediction: \"s the unreasonable effectiveness of RNNs\" => \" aoa  t  t  rtnt t  aeeee eeeeeeeeefesee\"\n",
      "batch 13420  loss=166.4719  steps/s=100.80  prediction: \"looking fractals https://t.co/PNG9vTa8x5\" => \"ys @t io  noo aoll ata ataatttttstttt///\"\n",
      "batch 13421  loss=147.3762  steps/s=101.30  prediction: \" realize big companies innovated anymore\" => \"teskdnd ded ddn  i   iii iiiniiinnninnna\"\n",
      "batch 13422  loss=142.2709  steps/s=103.87  prediction: \"tups are hidden in the fog 2 moves ahead\" => \" rnf f ttes    tts                     e\"\n",
      "batch 13423  loss=205.7950  steps/s=104.16  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"79s3 632032n54g 6B5,4w547529416v70540B4\"\"\n",
      "batch 13424  loss=156.8551  steps/s=104.99  prediction: \"e building an army of tiny little robots\" => \" soo       n  n                         \"\n",
      "batch 13425  loss=150.0611  steps/s=104.65  prediction: \"mped billions/decades into w no solution\" => \"ao lomb   d  e ddddeedd idded d    o oo \"\n",
      "batch 13426  loss=142.1133  steps/s=104.87  prediction: \"e usually surrounded with those coloredâ€¦\" => \" dane eeeaer  urruuuluuuuuuu ud     o   \"\n",
      "batch 13427  loss=156.9739  steps/s=102.51  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  +de  eeedeodoee eeeetetttt tttt       \"\n",
      "batch 13428  loss=137.1292  steps/s=103.22  prediction: \"er this applies outside of chess as well\" => \"  elr@ ere tl  t ts  its ss o s s   s  s\"\n",
      "batch 13430  loss=135.4679  steps/s=103.88  prediction: \"d this on there\n",
      "\n",
      "guard your signals boys\" => \" st teadna an n                         \"\n",
      "batch 13431  loss=147.2700  steps/s=104.55  prediction: \"more friction than they need to function\" => \"ereie ah htr   et t tt t tn n     ee e t\"\n",
      "batch 13432  loss=186.3426  steps/s=81.95  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" ig    rriin      tththhttt ee /   co oc\"\n",
      "batch 13433  loss=146.0553  steps/s=105.76  prediction: \"te well is a powerful powerful advantage\" => \" r    eot  tt le            w  w l  l l \"\n",
      "batch 13434  loss=149.8161  steps/s=103.20  prediction: \"e (although Josh only mentioned it once)\" => \" aaia iat ataa  o ho ohooohooo   oo o nn\"\n",
      "batch 13435  loss=151.1693  steps/s=101.90  prediction: \"nsions have a different message, I think\" => \"g ttoe nse nns nsssese   neeee e e  eee \"\n",
      "batch 13436  loss=159.7485  steps/s=100.26  prediction: \"ff has been helping ppl. I love humanity\" => \"oieteam s  f   e   e    e     ppp      l\"\n",
      "batch 13437  loss=147.0464  steps/s=107.39  prediction: \"dering what was on that list, thanks man\" => \"   si aa n w   w    w            ttttt t\"\n",
      "batch 13438  loss=136.2669  steps/s=104.90  prediction: \"will exhaust this reward bc its not real\" => \"ill  ai in  t it                        \"\n",
      "batch 13439  loss=138.7807  steps/s=96.91  prediction: \"ist either way, its all about production\" => \"n  thi httl tt t    a a    a            \"\n",
      "batch 13440  loss=147.4549  steps/s=100.93  prediction: \"worst part, as demonstrated by the graph\" => \"ird e i  h tt t   t     sttt ttt t     t\"\n",
      "batch 13441  loss=156.2914  steps/s=102.97  prediction: \"actually protects me from getting hacked\" => \"ntya    yc c  u   t            t tt tt  \"\n",
      "batch 13442  loss=143.1745  steps/s=103.49  prediction: \"f scummy people getting more money/power\" => \" t haea    c   meeee eeeeee    mmemmeeoe\"\n",
      "batch 13443  loss=166.7528  steps/s=92.48  prediction: \"ly Significant alpha\n",
      "Smart idea to start\" => \"y: @ omm mop iigietit pt a mmm mmet  o o\"\n",
      "batch 13444  loss=145.0752  steps/s=103.86  prediction: \"rally will not trample on your free will\" => \"eiey: ep em bAm *É´***[É´X\"$ðŸ“‰***\"{$A$},$`/\"\n",
      "batch 13446  loss=141.1872  steps/s=101.97  prediction: \"u ship cool things and make ppl have fun\" => \" whnt s  n p  n                         \"\n",
      "batch 13447  loss=143.7584  steps/s=87.78  prediction: \"t only people named dan will have access\" => \"hyo  nlpnn  o  p o n    na        a    a\"\n",
      "batch 13448  loss=150.7039  steps/s=105.30  prediction: \" the db he can just delete all of reddit\" => \"thezezz e s s b       e       eee e e   \"\n",
      "batch 13449  loss=149.5950  steps/s=104.05  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"eael:  on n,nAnekkjj:P(xPPP@@@@HH)H-&@â€;\"\n",
      "batch 13450  loss=158.4180  steps/s=100.12  prediction: \"s if you do both\n",
      "https://t.co/EXEA72MrEm\" => \" auat s p  p          oottottttt/t///EEE\"\n",
      "batch 13451  loss=155.8027  steps/s=97.30  prediction: \"r cool. i wish llms were better with zig\" => \"eply: ebntenhAte(xjj:7(x\"MT)2-&TB)B-wB?;\"\n",
      "batch 13452  loss=143.7397  steps/s=103.27  prediction: \"m, are also used in calculating/thinking\" => \"e s  are   tt     e        a    llllliii\"\n",
      "batch 13453  loss=147.6341  steps/s=103.37  prediction: \"rs a question i've been unable to crackâ€¦\" => \"e  eo no hnr Anqqu1q:A(q1''vq'bIE'E.zb.A\"\n",
      "batch 13455  loss=138.8450  steps/s=95.61  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \"hi  h t ss ee  tnnn  eeeeeeeee   ee   e \"\n",
      "batch 13456  loss=150.7176  steps/s=103.13  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" t ereperterenemmnenn m no t n t  ttntt \"\n",
      "batch 13457  loss=150.5022  steps/s=101.41  prediction: \"_opener oops i misread your comment my b\" => \"pm_aioo_o_oooooo  ooo o o     r    omm  \"\n",
      "batch 13458  loss=161.2635  steps/s=100.24  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \"het pente@en ses ssts stttssstt/////tt//\"\n",
      "batch 13459  loss=138.1479  steps/s=103.94  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \"het oe eem  m e eee    e l      t  rttrt\"\n",
      "batch 13461  loss=133.0661  steps/s=103.56  prediction: \"learning is by doing stuff. For anything\" => \"ya d nt nn t  i                         \"\n",
      "batch 13462  loss=140.2480  steps/s=104.38  prediction: \"eeks but you get back your skill quickly\" => \"     en    ww  e   e        u    k    kk\"\n",
      "batch 13463  loss=141.4359  steps/s=104.84  prediction: \"link, and then pretended to be my server\" => \"yke t ca taat a      n  eeeeeeeee   e ee\"\n",
      "batch 13464  loss=156.3159  steps/s=103.56  prediction: \"makes a comeback they get a large reward\" => \"eres It       a   a    e                \"\n",
      "batch 13465  loss=156.8573  steps/s=102.36  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \" \n",
      "piesiciiliiilillllll   i              \"\n",
      "batch 13466  loss=159.3619  steps/s=105.49  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"te   oo too  o     o           e    eeee\"\n",
      "batch 13467  loss=168.3850  steps/s=103.68  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \" d fe ee  ne   e          t ttt//t//ttHt\"\n",
      "batch 13468  loss=173.2348  steps/s=75.40  prediction: \"nicoara \"The instruction at 0x%p...\"\n",
      "Lol\" => \"gnl  f l  e n  e    ttttt/tt/t///t./Z../\"\n",
      "batch 13469  loss=150.7432  steps/s=104.95  prediction: \"ly got above len=2 for the longest time.\" => \"y: @ iao n  t    o         o     e   e  \"\n",
      "batch 13470  loss=140.3481  steps/s=106.69  prediction: \"ns you get the yellow letters on lichess\" => \"g  t  it o    t    e   e   ee eeeee lee \"\n",
      "batch 13471  loss=152.0787  steps/s=104.12  prediction: \" I'm super down for another one thursday\" => \"@     n!!!s s ds          o    o   o    \"\n",
      "batch 13472  loss=148.1421  steps/s=102.67  prediction: \"s it and im unaware (would love to know)\" => \" a t    ss    n                         \"\n",
      "batch 13473  loss=148.5695  steps/s=104.00  prediction: \"just have to connect/reconnect the wifi'\" => \"ust tg  st  t    o    o  oonoccnnccceeee\"\n",
      "batch 13474  loss=143.0945  steps/s=105.17  prediction: \" (by trusting in ideas) and testing them\" => \"tytte    htt tnt     i                  \"\n",
      "batch 13475  loss=145.8057  steps/s=103.57  prediction: \" the time and not spread important info?\" => \"toa  el lll  e                      tttt\"\n",
      "batch 13476  loss=143.6956  steps/s=102.21  prediction: \"king useful things, so it didnt work out\" => \"el k d   k k                            \"\n",
      "batch 13477  loss=146.8162  steps/s=100.64  prediction: \"hnote uuuh i have a license for thse sir\" => \"aski aseseuuuuuhuu    i      e         s\"\n",
      "batch 13478  loss=146.2574  steps/s=103.80  prediction: \"al, one of the most cracked players ever\" => \"nl nooen  nee o o o    o       e     eee\"\n",
      "batch 13479  loss=261.1561  steps/s=11.65  prediction: \"reply: @amix011 @yupiop12 You were early\" => \"e le  @ Tat,b=5t+&=5@H?VSY.v;?;xv?.y?DDX\"\n",
      "batch 13480  loss=141.9273  steps/s=109.57  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \" e tt  ntt  t  otto ooo o\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaa\n",
      "\n",
      "a\"\n",
      "batch 13481  loss=186.9640  steps/s=66.13  prediction: \"@startupmillyair https://t.co/c3FxqzjmK3\" => \"ltatto t tt   naooo r t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaaaala\"\n",
      "batch 13482  loss=150.9287  steps/s=108.27  prediction: \"sy and they put bugs in the concrete lol\" => \" or   ba n na  n                        \"\n",
      "batch 13483  loss=143.3908  steps/s=103.63  prediction: \"views from space, idk how to describe it\" => \"es  aveeseve eese                       \"\n",
      "batch 13484  loss=142.8087  steps/s=105.38  prediction: \" about it and in 1 weekend jumped up 200\" => \"t de  a  a                   e     eee e\"\n",
      "batch 13485  loss=184.7821  steps/s=73.98  prediction: \"owTiedFox 16hrs every day is crazy,  wow\" => \"r aeo    ae a         eed    d e e  e 00\"\n",
      "batch 13486  loss=168.2865  steps/s=110.76  prediction: \"uff @allgarbled Ah, true, nice inversion\" => \"sfitt@eo ttuul lllll  lll    e   ,    ee\"\n",
      "batch 13487  loss=149.9396  steps/s=106.11  prediction: \"fected, i hope none of my followers were\" => \"ow  re ddaede f e ee e o  e of  oof  ooe\"\n",
      "batch 13488  loss=136.1952  steps/s=103.93  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"ne a    dl  e  leeee eree ereerrrarrraaa\"\n",
      "batch 13489  loss=158.5977  steps/s=100.45  prediction: \"ur enemy when they are making a mistake\"\" => \"n   t eeneer  he y eeey  ey m  me  anma \"\n",
      "batch 13490  loss=158.7622  steps/s=104.92  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"lt t  f le t  el ttttttt/tt//tt////t/ttt\"\n",
      "batch 13491  loss=146.6863  steps/s=106.00  prediction: \"gram faster which made him have more fun\" => \" aeb  m er re r  a  r  h h h  hhmh h mm \"\n",
      "batch 13492  loss=138.3822  steps/s=105.56  prediction: \" the parameters corrrect from the start?\" => \"tha  an naa  a naaarrrerrrrrrrrrrr  rt t\"\n",
      "batch 13493  loss=195.6583  steps/s=98.77  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"taten a peOOOOOc!!OSS!!!e   o     e s  a\"\n",
      "batch 13494  loss=140.1176  steps/s=104.64  prediction: \"n for games (more encouraging?) but canâ€¦\" => \"gw sot     tP r   o     e o ooeoegggg   \"\n",
      "batch 13496  loss=155.9306  steps/s=102.46  prediction: \"eMTB very, very inefficiently, thats how\" => \" TB    ae ner  rrer eererinnnfniin  tt  \"\n",
      "batch 13497  loss=146.3183  steps/s=105.55  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y m tnelntenaa aaaaaaaaatstttttttt//////\"\n",
      "batch 13498  loss=159.0088  steps/s=100.03  prediction: \" more cracked by the day, love to see it\" => \"tet inegnee   eee e    e e  dd d  d   te\"\n",
      "batch 13499  loss=150.8052  steps/s=99.23  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" um0     e g  n   o    ool    t/////////\"\n",
      "batch 13500  loss=139.7717  steps/s=103.64  prediction: \"ion ability. should be trained first tbh\" => \"nn lo c toi lliliiil                   t\"\n",
      "batch 13501  loss=149.4879  steps/s=104.35  prediction: \"r die, and when they swim they find food\" => \"eynyk @ oenSeBttG9,Nqv_Iw2).v,B'zkA1LOTD\"\n",
      "batch 13502  loss=142.2745  steps/s=104.88  prediction: \"a good way to beat addictions in general\" => \"nfoi w  s   ttotooo    a  aa aa   ii    \"\n",
      "batch 13503  loss=142.9652  steps/s=98.35  prediction: \"see more details as you unblur an image.\" => \" etu o o    t e  eee  a    s  s    n nn \"\n",
      "batch 13505  loss=151.4938  steps/s=101.09  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" s ereperterenemmmenn e no t n te ttntt \"\n",
      "batch 13506  loss=142.7439  steps/s=104.57  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng ooon  n (g nn                  uuu   \"\n",
      "batch 13507  loss=153.5447  steps/s=88.04  prediction: \"t only people named dan will have access\" => \" tf   g nn eyegnee o    ee        l    e\"\n",
      "batch 13508  loss=145.8652  steps/s=104.57  prediction: \"ss I need to do keyboard input from it..\" => \"  f .  l lenn une    e  e  e        o   \"\n",
      "batch 13509  loss=145.5712  steps/s=106.81  prediction: \"most rather just.. not have a device tbh\" => \"er  i l o  t   o     tt t   tt   t    ee\"\n",
      "batch 13510  loss=163.4831  steps/s=103.84  prediction: \"norary dan if i can be an honorary denis\" => \" w   ra n an an              n     n  n \"\n",
      "batch 13511  loss=161.8495  steps/s=100.44  prediction: \"s/hacks??????? follow me on linkedin btw\" => \" tr   s////k????????????k   ??o l      n\"\n",
      "batch 13512  loss=168.2264  steps/s=108.38  prediction: \"boards to learn the keys other ppl used)\" => \"eta   aaaa araera       e  e eeee       \"\n",
      "batch 13513  loss=152.3975  steps/s=95.06  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"ya @seaeee te r     e             e e ra\"\n",
      "batch 13514  loss=168.3642  steps/s=100.37  prediction: \"owser gif editor\n",
      "https://t.co/CWUD0xLmZ4\" => \"u ofewi ewfiw f   ii ttrtttrttit/////tC/\"\n",
      "batch 13515  loss=172.4868  steps/s=84.62  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" nen siseOOLO  LOLO\n",
      "\n",
      "\n",
      "ett t// \"\"\"\"rp\"\"4p\"\n",
      "batch 13516  loss=155.8302  steps/s=106.35  prediction: \"tings, and speeding up my workflow, you?\" => \" nf  isceee e  e eeeee  n e      e      \"\n",
      "batch 13517  loss=157.1548  steps/s=102.04  prediction: \"f flipped around https://t.co/tQfmcgFqBM\" => \" sl ut   ff ffeepp pppp  ptttt /t/tt////\"\n",
      "batch 13518  loss=148.2422  steps/s=105.40  prediction: \"r die, and when they swim they find food\" => \"eoo k @ tem eB,tq?,NPvPIP2).v,B#??A1LOTD\"\n",
      "batch 13519  loss=145.2091  steps/s=102.57  prediction: \"te well is a powerful powerful advantage\" => \" r or eot  tt le            w  w l llll \"\n",
      "batch 13520  loss=208.8977  steps/s=99.73  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"eia :  s    iBt á´á´¡Ê€Ê€á´€á´€ÊŸá´á´¡2á´˜á´˜á´€ÉªÉªÊ€á´›á´›Êœá´‡É´É´á´¡á´¡\"\n",
      "batch 13521  loss=139.1889  steps/s=105.41  prediction: \"ything rewarding that follows from that)\" => \":hmaiiiggegeergigrrrrrrg      t  r    o \"\n",
      "batch 13522  loss=152.6717  steps/s=100.89  prediction: \"free could help too if thats the problem\" => \" el eleu  ue   le    e    t  t  ttt  t  \"\n",
      "batch 13523  loss=231.5582  steps/s=98.23  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \"sttToieE GdMGRH WC@MCNGEWO)KINGINGFá´„B:0O\"\n",
      "batch 13524  loss=152.7029  steps/s=98.01  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y y Csasess  ss ss s ssttsttt/t/////////\"\n",
      "batch 13525  loss=166.8079  steps/s=38.59  prediction: \"ly: @andrew_pynch i think about it a ton\" => \"y: @Csss  es ss ss tttst//////////t//t/c\"\n",
      "batch 13526  loss=143.8123  steps/s=109.58  prediction: \"f scummy people getting more money/power\" => \" thhaee    c   meeee eeeeee    mme meeoe\"\n",
      "batch 13527  loss=157.9183  steps/s=104.90  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"the ot otg    e      t  ttttttttt///////\"\n",
      "batch 13528  loss=144.9630  steps/s=104.48  prediction: \"at DAN had. 'get in character' type beat\" => \"n  th\"  s  tstt  t     h  a    '''' ae  \"\n",
      "batch 13529  loss=148.3977  steps/s=103.75  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"tout  t  at                ee e e  egggg\"\n",
      "batch 13531  loss=170.2243  steps/s=29.69  prediction: \"ply: @tszzl no :( 4o is still goated tho\" => \"ly: @o   oo   io      \n",
      "    ee e eggggggg\"\n",
      "batch 13532  loss=150.3634  steps/s=112.47  prediction: \" and can be much more useful to increase\" => \"tndn  ranansana n              e    e  e\"\n",
      "batch 13533  loss=163.8687  steps/s=87.18  prediction: \"rdenis grats btw. site looks amazing too\" => \"eiry: @ketohf_heGk),NG,(?vj.I?vzk??v,kz,\"\n",
      "batch 13534  loss=159.2344  steps/s=102.62  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"tnd ein i   i  n  t   e   oo     o   o  \"\n",
      "batch 13535  loss=156.5061  steps/s=101.68  prediction: \" seems to be doing pretty good with both\" => \"@oe eed  te  er    e  e      o e      oo\"\n",
      "batch 13536  loss=142.9159  steps/s=103.75  prediction: \"e online?\"\n",
      "uuuh, dont be? problem solved\" => \" teyinie eenneeeeee  uu     u    ?   e  \"\n",
      "batch 13537  loss=166.4011  steps/s=46.87  prediction: \"y: @tabtab0x_0 @Brycicle77 never mouse ðŸ«¡\" => \": @menieneee?eiu uuuuuu     ??e    ooe  \"\n",
      "batch 13538  loss=176.5620  steps/s=72.94  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y: @inneene\"0u u uuu uee      e   oooeee\"\n",
      "batch 13539  loss=141.4366  steps/s=108.40  prediction: \"ncing is just how things go in business.\" => \" hw  e enen eien i i  n   i      i  n  i\"\n",
      "batch 13540  loss=169.6200  steps/s=79.04  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eeey:   ts j @t 0#@B?\"v.1YÊœv710kH#10k5zk\"\n",
      "batch 13541  loss=157.2829  steps/s=107.99  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" ae:i     n   n    h      o             \"\n",
      "batch 13542  loss=143.4825  steps/s=101.65  prediction: \"just happen to have sicilian parents lol\" => \"est e el ttt  t  e    e        a  aaa  a\"\n",
      "batch 13543  loss=148.6027  steps/s=105.38  prediction: \"ow readable zig is. how does ak do it???\" => \"n    n  ee n  er      e                 \"\n",
      "batch 13544  loss=166.5653  steps/s=98.40  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"o in oe hrww  w    e e  eesesewe ooe  EE\"\n",
      "batch 13545  loss=175.6363  steps/s=69.37  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \" _n: @nrwhh4nwhehwohoew esssseEe   eTTTT\"\n",
      "batch 13546  loss=140.6974  steps/s=106.12  prediction: \"ies and more insights. Then will release\" => \"nl a t   n nn ee    i i ss s  i i  i    \"\n",
      "batch 13547  loss=137.1617  steps/s=103.27  prediction: \" my weird posts but im happy nonetheless\" => \"tore tr etete  t      t                 \"\n",
      "batch 13548  loss=146.8359  steps/s=103.57  prediction: \"e soda\n",
      "\n",
      "actually nvm this one tastes meh\" => \" iee iteraeaa  ae\n",
      "aa  a aaa aa   tt  ts \"\n",
      "batch 13549  loss=169.9277  steps/s=102.18  prediction: \" that outputs its own weights and biases\" => \"tha etn a te tt tt ott tt  tt ts t s  s \"\n",
      "batch 13550  loss=147.3371  steps/s=99.03  prediction: \"is lol. alright alright, target acquired\" => \"n  t    l  l ihl lil lhil lggggatggt taa\"\n",
      "batch 13552  loss=171.4305  steps/s=73.73  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" ao   l l  l  ullll hthhthttttttt atrrte\"\n",
      "batch 13553  loss=157.5864  steps/s=107.25  prediction: \"s every time I'm getting comfortable lol\" => \" toe r m merr r  ee et e  ete   t tgtt t\"\n",
      "batch 13554  loss=157.5144  steps/s=102.99  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"hmrs t rerr rr  rr aaaeaa aaa a aa aaa  \"\n",
      "batch 13555  loss=143.5519  steps/s=101.96  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" co innnn no o         t  tttttt////////\"\n",
      "batch 13556  loss=138.4677  steps/s=103.55  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \" et  e eerl m e eee    t l      t  rttrt\"\n",
      "batch 13558  loss=142.0481  steps/s=104.23  prediction: \"d to take over the years\n",
      "\n",
      "4 minute miles\" => \" ta etn tttet tee  e ee ee ee ee e      \"\n",
      "batch 13559  loss=182.8801  steps/s=99.52  prediction: \"7AHwatHv6Y was really really really good\" => \"7   t o/c/toHtt HHt6aaaa aaaaaal allllly\"\n",
      "batch 13560  loss=151.8796  steps/s=104.67  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \" aai  t at aaaaaaaaattttt:ttttttt/t////t\"\n",
      "batch 13561  loss=179.1600  steps/s=95.32  prediction: \" was truly L tier. not L tier but L tier\" => \"taaara ta trr rtr  t t L L tLLtt t tLLtL\"\n",
      "batch 13562  loss=233.3015  steps/s=11.67  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"eplo: @se_e b@s .bLY7AL!.?L!6!f\n",
      "YxL7AHLp\"\n",
      "batch 13563  loss=194.1502  steps/s=125.50  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"/.Hc a l////tt/Ht/MMMUUUUDD/t/t ////.t/t\"\n",
      "batch 13564  loss=144.7067  steps/s=104.90  prediction: \" you should waste money\n",
      "&lt;/caveats&gt;\" => \"tou y   sy     o   o      o     o aaaaat\"\n",
      "batch 13566  loss=148.1602  steps/s=105.81  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"u  s o    ss   s  s       a  aaaaaa  a  \"\n",
      "batch 13567  loss=146.0200  steps/s=105.83  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"tor sar   oa  eo r     ss s ss s  m    e\"\n",
      "batch 13568  loss=147.2932  steps/s=98.04  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"hr f r w wwr  gro   o  \n",
      "   o\n",
      "o    o o oo\"\n",
      "batch 13569  loss=141.2392  steps/s=103.67  prediction: \"have become too big and are rotting away\" => \"av sies nemmeecmee                      \"\n",
      "batch 13570  loss=165.4539  steps/s=46.55  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \": @saniee men c ee               o    a \"\n",
      "batch 13571  loss=145.4181  steps/s=137.25  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"ys @beeeee te c  i  i            aa aana\"\n",
      "batch 13572  loss=220.5077  steps/s=102.11  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"yse .ee--))))0))))..).)((({..((...5.5.5.\"\n",
      "batch 13573  loss=170.3246  steps/s=101.78  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"a  ve   si   e   eeeee eee /////////////\"\n",
      "batch 13574  loss=141.6095  steps/s=104.52  prediction: \"lgorithms\n",
      "Get better learning algorithms\" => \"yay g        rettteetttttteeeeeeeeererrr\"\n",
      "batch 13575  loss=165.0044  steps/s=98.08  prediction: \"y brotha ty, nah no zig for this bad boy\" => \":ira_haarh tr   t  t    a n    g   i    \"\n",
      "batch 13576  loss=151.3374  steps/s=104.85  prediction: \"a decision making incongruency somewhere\" => \"rsso   asssassss iiiiiiiinnnnnnnnnnnnnnn\"\n",
      "batch 13577  loss=156.9422  steps/s=98.55  prediction: \"tus Even more bc this doesnt have alaska\" => \" fI   teninele ee     n    e  s    hee e\"\n",
      "batch 13578  loss=140.2418  steps/s=105.68  prediction: \"reevaluating concepts you often overlook\" => \"eple  wwæˆ‘go b[rd|$å§$[.bQðŸ‘Œ||QbðŸ¤¯â€$$}ð—²$â€.ð˜€$\"\n",
      "batch 13579  loss=138.0798  steps/s=103.70  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf ng   ni n   n  i   g      g   o      \"\n",
      "batch 13581  loss=135.3650  steps/s=102.91  prediction: \"stening to the sidetweets podcast at 1am\" => \"   edi   nn   t  t t ttet teee esttetttt\"\n",
      "batch 13583  loss=142.6742  steps/s=103.87  prediction: \"t (for example working when youre tired)\" => \" cou h  oroo ofo o  r r     r       e   \"\n",
      "batch 13584  loss=195.8512  steps/s=105.27  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"  74o/tt9tt\n",
      "\n",
      "\n",
      "s\n",
      "\n",
      "so\n",
      "\n",
      "\n",
      "\n",
      "ss\n",
      "st\n",
      "ss//tp/s//t\"\n",
      "batch 13585  loss=151.0638  steps/s=104.72  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng ia i ww i  w  dd dddd dddod d        \"\n",
      "batch 13586  loss=144.6872  steps/s=102.88  prediction: \"ed for editing videos would be so goated\" => \"  l  rgeodeddeieeeiii i iid d   do  o  o\"\n",
      "batch 13587  loss=148.0584  steps/s=103.78  prediction: \"ingly, doable) youre in for a goood time\" => \"ng    r sryrrri y yryyy o  r  oo o  oo o\"\n",
      "batch 13588  loss=139.2166  steps/s=105.16  prediction: \"got the bit order backwards or something\" => \" n iho   n gb  t      b   r     rrrrrrr \"\n",
      "batch 13589  loss=149.5820  steps/s=104.51  prediction: \"just have to connect/reconnect the wifi'\" => \"ust th  ss       o    o  oonocnnnccceeee\"\n",
      "batch 13590  loss=146.1860  steps/s=104.59  prediction: \"e\n",
      "\n",
      "swapped to mint and never looked back\" => \" \n",
      "th s  p p ppes   p ta t  e e e n   d e\"\n",
      "batch 13591  loss=169.4012  steps/s=103.49  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"ede i elMIfðŸ¤·á´‡á´›f 1$ð—°j__65Mð—²Sð˜‚M6521_â€21cVâ€œ\"\n",
      "batch 13592  loss=163.0257  steps/s=103.73  prediction: \" fit-to-content) https://t.co/kIAe5BVk05\" => \"@iree   e--ot- --ttttttttttttttttt/////t\"\n",
      "batch 13594  loss=155.0122  steps/s=100.63  prediction: \"p. maybe you can figure out how to do it\" => \"l g   o m mdm                         oo\"\n",
      "batch 13595  loss=137.9921  steps/s=104.17  prediction: \"then add audio and make it a vid editor.\" => \" e  duo  dn dddddddddddaa               \"\n",
      "batch 13596  loss=142.4338  steps/s=105.65  prediction: \"it got like 2x fps rendering ocean waves\" => \"n   w w we    i            e  e e  eeeee\"\n",
      "batch 13597  loss=140.4272  steps/s=106.29  prediction: \"l here is better than funny number go up\" => \"ype  no  i                    nnnnnnnnnn\"\n",
      "batch 13599  loss=136.6988  steps/s=105.03  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf ng   ni n   n ii   g      g          \"\n",
      "batch 13600  loss=165.3085  steps/s=99.65  prediction: \"h @tsoding Musializer looked pretty cool\" => \"iag isoishssnsnnssis  ooi ii i e e  eeo \"\n",
      "batch 13601  loss=144.4983  steps/s=94.55  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" in   nhsnh  s taaas  eeeee eeee ee   e \"\n",
      "batch 13602  loss=134.0618  steps/s=102.34  prediction: \"tput something as unexpected as possible\" => \" s  t totoototttt  t o     e   ee eessse\"\n",
      "batch 13603  loss=143.9056  steps/s=101.48  prediction: \"y time back so i can work on what i want\" => \":to aws m  m  a           c             \"\n",
      "batch 13604  loss=164.0962  steps/s=96.20  prediction: \"d 1995 type sites are such a great style\" => \" ogtioa 9 t9   s    s     a   a    a a  \"\n",
      "batch 13605  loss=165.8760  steps/s=98.08  prediction: \"ed\n",
      "Hes just gonna keep goin up from here\" => \"  st  Iydees ees ee  e e  e     n    e  \"\n",
      "batch 13606  loss=180.3714  steps/s=54.12  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" @0xni 0In@IXA5 IbHj_AjHm_zj//kvy/b)vyxj\"\n",
      "batch 13608  loss=158.1928  steps/s=108.55  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"e  t ei r           o   ot            v \"\n",
      "batch 13609  loss=151.0261  steps/s=104.27  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"neio  ioo  k                  t/////////\"\n",
      "batch 13610  loss=147.6732  steps/s=103.48  prediction: \"ces to back him up\n",
      "\n",
      "stand user type shit\" => \"o f  es coec cec                s       \"\n",
      "batch 13611  loss=158.2189  steps/s=100.48  prediction: \"ideally yes. mostly medium sized updates\" => \"ne oei l  eells  le lllyyymymmm mm m ddd\"\n",
      "batch 13612  loss=141.9777  steps/s=102.85  prediction: \" distracting any kind of multitasking is\" => \"too  et  nt t e i           n   i    iii\"\n",
      "batch 13613  loss=169.0890  steps/s=103.80  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"thcootfoo///tt///tXX/ttXXXX/t/tt:///tt//\"\n",
      "batch 13614  loss=143.4516  steps/s=101.81  prediction: \"o make a comeback. would be great to see\" => \" to o e       n                         \"\n",
      "batch 13615  loss=141.7388  steps/s=104.90  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eo ntt t nttnneee e  e e eeeee        \"\n",
      "batch 13616  loss=139.2477  steps/s=105.07  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" ti gne   nnnn nereeeereeeeetitittttoooo\"\n",
      "batch 13617  loss=144.9171  steps/s=104.54  prediction: \" loss (erroneously a vector) as a scalar\" => \"tot wndh  s   sooooooo   e              \"\n",
      "batch 13618  loss=147.2079  steps/s=103.79  prediction: \"about things that have significant value\" => \"noe  tttn   ttett aa tt tth  hat  aiaa a\"\n",
      "batch 13619  loss=150.3708  steps/s=104.60  prediction: \"tbh, i like having control over my tools\" => \"he  e tsf ff  et          i       o   oo\"\n",
      "batch 13620  loss=163.3214  steps/s=100.94  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \"hrn c u sa rta e aatt attttttst/tttc/// \"\n",
      "batch 13621  loss=150.7507  steps/s=99.31  prediction: \"y is nothing like early morning sunlight\" => \" (  erreerrellr e li l il  iiii n  nlnlg\"\n",
      "batch 13622  loss=134.6151  steps/s=102.18  prediction: \"he audiobook content is better than both\" => \"e g t tthttououooooooooooottttttttttt tt\"\n",
      "batch 13623  loss=140.5863  steps/s=103.11  prediction: \" fly everywhere\n",
      "\n",
      "idk how lidar works btw\" => \"torhh  t  ei   veeeeeeeee e      ww   ww\"\n",
      "batch 13624  loss=142.7668  steps/s=103.04  prediction: \"g, or write something else in zig, later\" => \"  ia i  t     i  i     i    ee eee e  e \"\n",
      "batch 13625  loss=156.4046  steps/s=96.91  prediction: \"e go all the blindfold web dev positions\" => \" i      dhe t ett     el lle  l  d d de \"\n",
      "batch 13626  loss=166.1324  steps/s=72.28  prediction: \"ludwigABAP its all slop tier, always was\" => \"ydeng   d gAe tll  lllll lle  ee    oio \"\n",
      "batch 13627  loss=142.9755  steps/s=106.06  prediction: \"it can atrophy if you dont keep doing it\" => \"n    ta h th  at                        \"\n",
      "batch 13628  loss=143.1679  steps/s=103.62  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n ,ne    e                ttt//////////t\"\n",
      "batch 13629  loss=142.0423  steps/s=104.30  prediction: \"think bc they burn through the same fuel\" => \" an io  nh     t       h  h th hh hhhh  \"\n",
      "batch 13630  loss=153.1060  steps/s=101.20  prediction: \"nally get monads\n",
      "https://t.co/lYN3cpV8JV\" => \" uTB o  elel    l      ttttttttttt//////\"\n",
      "batch 13631  loss=148.1409  steps/s=104.78  prediction: \"it anymore. Now she can go get groceries\" => \"n  a  a  n a                         e  \"\n",
      "batch 13632  loss=145.2152  steps/s=102.46  prediction: \"be setting a deadline might help as well\" => \"ett i     nnn  t         e     ie      e\"\n",
      "batch 13633  loss=144.6069  steps/s=104.83  prediction: \"g correct (fingers crossed its this one)\" => \" a e er rt  rrrrrrerr crrerr  ssss ssss \"\n",
      "batch 13634  loss=133.0330  steps/s=103.33  prediction: \"learning is by doing stuff. For anything\" => \"y, hgn  nn n  b                         \"\n",
      "batch 13635  loss=140.0445  steps/s=102.71  prediction: \"marter you get the more the traps change\" => \"eye  amat th  te       t   e   e   e    \"\n",
      "batch 13636  loss=144.5683  steps/s=103.12  prediction: \"i can keep it up https://t.co/aDUupaUfqR\" => \"ntor     ssn   s   e  pp    pp ppttp///U\"\n",
      "batch 13637  loss=149.8255  steps/s=104.71  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \" an   baat t t    t  t  ttt tt  ///xt///\"\n",
      "batch 13638  loss=157.1130  steps/s=102.71  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"eply:  snqMkn/y I?WJMTBQ:ETB.bE;jx:EvzjC\"\n",
      "batch 13639  loss=157.5701  steps/s=103.06  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"es   ne n  00000000                  oo \"\n",
      "batch 13640  loss=139.2843  steps/s=105.18  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"esg    e t nt  t                        \"\n",
      "batch 13641  loss=173.8344  steps/s=78.36  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" ae   n te   omoo  ooo          ..  GGG \"\n",
      "batch 13642  loss=145.4261  steps/s=106.09  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"k re tr h  ''   e    e  e t  ///ttt////t\"\n",
      "batch 13643  loss=155.5434  steps/s=99.67  prediction: \" this long lost treasure of a song, damn\" => \"th  r o   n nohn        o    o          \"\n",
      "batch 13644  loss=181.7205  steps/s=102.79  prediction: \"arning a lot and building a lot\n",
      "\n",
      "love it\" => \"te   l  nen    \n",
      "  ana a a   n    l   llo\"\n",
      "batch 13645  loss=139.8837  steps/s=104.12  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  t   t at t i,         ttttttt//tt////\"\n",
      "batch 13647  loss=150.8144  steps/s=102.17  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tar tee    t  g t  tttt  tttttttttt/////\"\n",
      "batch 13650  loss=143.0188  steps/s=105.08  prediction: \"compress a lifetime into a few sentences\" => \"omprissesnc c    e   iii  i        e eee\"\n",
      "batch 13652  loss=149.0200  steps/s=103.59  prediction: \" is a wild computational rabbithole man.\" => \"tn  psea    aa accc   aa aaa i aaaibaabl\"\n",
      "batch 13653  loss=162.2996  steps/s=73.34  prediction: \"eCachet Consistency is a deadly strategy\" => \" saa cea    c  t si   aa aaa  iball aatt\"\n",
      "batch 13654  loss=173.0096  steps/s=108.57  prediction: \"MTB Yup, totally, would be best actually\" => \"TB @Bryychnin e  y ty ,  tll  o b ttab l\"\n",
      "batch 13655  loss=158.2050  steps/s=98.94  prediction: \" as an information distillery, I like it\" => \"tbam oa    a ao aaaaon  ii i ii i  i lli\"\n",
      "batch 13656  loss=148.8755  steps/s=99.42  prediction: \"ticed this too, its what got me thinking\" => \"hnd ea    n nt tt oi tiit tt t  t   t  t\"\n",
      "batch 13657  loss=158.2185  steps/s=96.22  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"tae cic eit ot t tssttt tott   ttt ttt t\"\n",
      "batch 13658  loss=148.6412  steps/s=99.42  prediction: \"ffects that are extremely hard to notice\" => \"  ie  n ererterte eeetette te  er  e t  \"\n",
      "batch 13659  loss=178.1015  steps/s=105.50  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 7 eis  na  tta   t  tttt  t  ttt  /t/33\"\n",
      "batch 13660  loss=166.0725  steps/s=52.84  prediction: \": @yacineMTB better start skilling up ig\" => \" @tu@i ouee2oMnhD1TMTb,:xD\n",
      "x:uDZ3k5G.:b/\"\n",
      "batch 13661  loss=165.3893  steps/s=108.24  prediction: \"of visualization goes away with practice\" => \"  ot e \n",
      " tof  tii  ioo  aoaaaoo   aaa aa\"\n",
      "batch 13662  loss=143.4022  steps/s=105.21  prediction: \"w. Might do one every mon and every tues\" => \"h o   o rotrrorroo  o  o   o        eee \"\n",
      "batch 13663  loss=149.2490  steps/s=95.92  prediction: \"f you can read graphs youre already ngmi\" => \" tee do  w  n a    r  rrr  r  re r  ree \"\n",
      "batch 13664  loss=180.3565  steps/s=98.16  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" t teueen re ege   h     ttthteatttao///\"\n",
      "batch 13665  loss=149.1585  steps/s=101.29  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"tolw ni    n  nonnooooooooo             \"\n",
      "batch 13666  loss=140.4755  steps/s=105.87  prediction: \" is a no go\n",
      "\n",
      "dang that sounds like a lot\" => \"@n o nb n     n                 n       \"\n",
      "batch 13667  loss=150.9149  steps/s=104.95  prediction: \" drains your energy by paying attentionâ€¦\" => \"tu t ta  nn  igr  n   yyyyyyyy yy y   nn\"\n",
      "batch 13668  loss=141.6562  steps/s=103.18  prediction: \" regarded so take that w a grain of salt\" => \"tese  ii m rrdd      ee aa   aa   aaa  a\"\n",
      "batch 13670  loss=141.0684  steps/s=93.51  prediction: \"irak seems fine to me (i am brainwashed)\" => \"ne ir reees re seee    e     a    aaaa a\"\n",
      "batch 13671  loss=136.9810  steps/s=105.26  prediction: \"our life if you make work look like this\" => \"ur po   rn i  rf        o   o  o k kk kk\"\n",
      "batch 13672  loss=152.9265  steps/s=46.84  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @saoe re e  f         o  oo ookk kk k \"\n",
      "batch 13673  loss=177.8526  steps/s=59.96  prediction: \"ply: @ludwigABAP Oh based it keeps going\" => \"ly: @  oe fef y         o  ookoook kk ii\"\n",
      "batch 13674  loss=143.7292  steps/s=108.87  prediction: \"ut from having 1/3rd the progress per hr\" => \"n ey   u n n  u              r  rr rrrrr\"\n",
      "batch 13675  loss=168.8310  steps/s=102.84  prediction: \"EDM and caffeine\n",
      "https://t.co/xSA2QsenCw\" => \"sS,eliolostrs@g EDM(w/B6BxEDM2w6\n",
      "k,(:C:D\"\n",
      "batch 13676  loss=250.1636  steps/s=10.98  prediction: \"reply: @AaronPeddle Very very good point\" => \"eply  tlostre@s EDMVw/B6B.EDMxwA\n",
      "k,(:C:D\"\n",
      "batch 13677  loss=141.9989  steps/s=109.13  prediction: \"link, and then pretended to be my server\" => \"yn  t ca ta t a      n eeeeeeeeee   e ee\"\n",
      "batch 13678  loss=147.5044  steps/s=104.99  prediction: \"t learning from the things theyre doing.\" => \" ioent l    e  g             t   h      \"\n",
      "batch 13679  loss=148.7304  steps/s=101.13  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" goh  w  n ww       ttttttttttttt///////\"\n",
      "batch 13680  loss=153.8069  steps/s=101.06  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \"uhwl dl bolbb o              ttt////////\"\n",
      "batch 13681  loss=203.1914  steps/s=104.38  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"17 B1AAAA6A1A19191B19B1911131BA13A33333A\"\n",
      "batch 13682  loss=181.2117  steps/s=97.52  prediction: \"nks!! feels good to be doing these again\" => \"  o    x    !!  !     A    oo    B    A1\"\n",
      "batch 13683  loss=173.2436  steps/s=101.81  prediction: \" lol positive feedback loops are awesome\" => \"@esteap oode oo   eo  oe  oe e oe   eeee\"\n",
      "batch 13684  loss=158.7425  steps/s=106.87  prediction: \"nd beyond is such a gargantuan advantage\" => \"g  o vea od n n            a aaaaaaaaana\"\n",
      "batch 13685  loss=140.6864  steps/s=103.67  prediction: \" a lot of chess is abt how to think less\" => \"@no  ot  t o                            \"\n",
      "batch 13686  loss=145.5212  steps/s=96.78  prediction: \"feeling than automating hrs of work away\" => \" e s e o etef ne  a ataata ttt o        \"\n",
      "batch 13687  loss=146.8769  steps/s=103.90  prediction: \"chnical debt kind of effect over time. F\" => \"h in set      nt         e    e ff eeee \"\n",
      "batch 13688  loss=149.4052  steps/s=103.57  prediction: \"l, titan, stable diffusion, a few others\" => \"y  siols ga s asa tat  ati ai ii  i     \"\n",
      "batch 13689  loss=135.3910  steps/s=98.74  prediction: \"tern i fell into\n",
      "\n",
      "Feels goood\n",
      "\n",
      "Your turn\" => \" rm b b a  nttet   teeeeleeelo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "oo\"\n",
      "batch 13690  loss=140.0728  steps/s=103.82  prediction: \" you get stuff done in a quick timeframe\" => \"toua    t  t  t                         \"\n",
      "batch 13691  loss=143.5990  steps/s=102.98  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" at    eeeeemeeeieiiiii                 \"\n",
      "batch 13693  loss=171.3930  steps/s=103.06  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"t.l altt////t/tttzzzztzzzz////tt////t/L/\"\n",
      "batch 13694  loss=150.3345  steps/s=101.67  prediction: \"was making me sleep deprived unknowingly\" => \"hst te I  a        e e  eee  eee eeee ee\"\n",
      "batch 13695  loss=149.4390  steps/s=102.82  prediction: \" and can be much more useful to increase\" => \"t an  ranansana n              e    e  e\"\n",
      "batch 13696  loss=143.9042  steps/s=105.25  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \"     ieee l \n",
      "=s,4)\n",
      ",ApLv=1==B0(/,,0yv3,B\"\n",
      "batch 13697  loss=159.5210  steps/s=100.43  prediction: \"l do bro, never had a french beer before\" => \"yaeej  e b re or   o         r e  r  ere\"\n",
      "batch 13698  loss=148.2184  steps/s=104.31  prediction: \" is structured to add llms pretty easily\" => \"tndi ii  in  et       d dd d   d    t   \"\n",
      "batch 13700  loss=147.2303  steps/s=105.31  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"ec nt e e vveBh wwyy/mjv1!(C((:KY9.0xq35\"\n",
      "batch 13703  loss=142.8397  steps/s=98.98  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"t c inaane na  e        tttttt//////t//t\"\n",
      "batch 13704  loss=145.0385  steps/s=104.96  prediction: \"ouraging way, not stressful for the kid)\" => \"ul   cggnigeegggnnnnnnn                 \"\n",
      "batch 13705  loss=147.5017  steps/s=104.72  prediction: \"re just doin their part to get us to AGI\" => \"e ly  eT sy mMal6M6CkTM)1qCIj3qkY9v0M\n",
      "Th\"\n",
      "batch 13706  loss=167.0938  steps/s=91.96  prediction: \"cle77 arabian mate is a similar good one\" => \"oe n Bnetosn77otaai   t  t t it   to to \"\n",
      "batch 13707  loss=150.5918  steps/s=103.34  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"ani  a  bsen  \n",
      "ooooo ooooooo oooo   o   \"\n",
      "batch 13708  loss=143.0555  steps/s=105.38  prediction: \"tory by far. it continues to surprise me\" => \"   ah  a na naan                        \"\n",
      "batch 13709  loss=136.5558  steps/s=105.83  prediction: \" pays off immensely when I stick to them\" => \"tit  ttf ffeffe ff   m         e        \"\n",
      "batch 13710  loss=145.5715  steps/s=105.67  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" boa tfoess s  s   sss ss ss sssssse  s \"\n",
      "batch 13711  loss=145.1065  steps/s=104.35  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne oomi   i  mieeememoeemeeee eee eeee e\"\n",
      "batch 13712  loss=177.1232  steps/s=85.40  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn i  zmem mee meeeeAee eeee reeeaeere e\"\n",
      "batch 13713  loss=157.8027  steps/s=103.75  prediction: \"n=1)\n",
      "2 their goals are their vidya (n=2)\" => \" re\n",
      "sle  nnin rnee e    er    er   rr   \"\n",
      "batch 13714  loss=152.9627  steps/s=99.81  prediction: \"ting the entire GOL industry as we speak\" => \"hon sm  m t t nt t ee   eei   it        \"\n",
      "batch 13715  loss=146.7236  steps/s=104.03  prediction: \"mething to run from (getting called out)\" => \"a e nvesets tet e    o        g gg g g t\"\n",
      "batch 13716  loss=144.0838  steps/s=102.70  prediction: \"m, are also used in calculating/thinking\" => \"a te are    t     e        a   llallliii\"\n",
      "batch 13717  loss=157.8585  steps/s=105.49  prediction: \"ho. i like it much much better than rome\" => \"eu itso in n oon   i  i    t    th    tt\"\n",
      "batch 13718  loss=139.0310  steps/s=105.32  prediction: \" play instead of making random moves lol\" => \"tott tl   tl  l   a aa aaa aaaa         \"\n",
      "batch 13719  loss=160.6148  steps/s=100.20  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \"  t o   nhe  eh t  ttttt tttt t//////VVV\"\n",
      "batch 13720  loss=164.0901  steps/s=104.19  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"to l  e  s  l il                    nn n\"\n",
      "batch 13721  loss=174.9106  steps/s=99.76  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"hln h u  ht/////  ZZ/HHHHHt......Bpptppp\"\n",
      "batch 13722  loss=160.4842  steps/s=105.86  prediction: \"ge w git commits\n",
      "https://t.co/aMMtiAGLQh\" => \"  s t l  ot       t ttt tttttttttt//t//M\"\n",
      "batch 13723  loss=173.0054  steps/s=102.44  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \"p7r4    n   nowooooollooooloott////////q\"\n",
      "batch 13725  loss=166.1596  steps/s=99.87  prediction: \"the man just liked big words and spirals\" => \"hen rasm r  mmn  ta   t    t  s  d ssdd \"\n",
      "batch 13726  loss=156.6201  steps/s=103.19  prediction: \"igure out how to improve your work ethic\" => \"n   srts t      to  oo tooo  oooo ooo   \"\n",
      "batch 13727  loss=134.7970  steps/s=103.48  prediction: \" will get back to you when this is fixed\" => \"thawe  i l l lw                         \"\n",
      "batch 13728  loss=139.1714  steps/s=105.81  prediction: \"ies and more insights. Then will release\" => \"nl a t   n nn ee    i s ssss  i i  i    \"\n",
      "batch 13729  loss=157.3742  steps/s=104.79  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  d  e;e;ggeeteg;tgttttttttoo oo    oL  \"\n",
      "batch 13730  loss=153.9818  steps/s=100.88  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"n\n",
      " en dee    e     e  e e  e  e         \"\n",
      "batch 13732  loss=161.1382  steps/s=81.49  prediction: \"minus9 This is my new favorite edm track\" => \"agen tnden  s hh     e  ee    t  tt   t \"\n",
      "batch 13733  loss=141.5508  steps/s=107.50  prediction: \"ellite imagery onto the photos they took\" => \" yraltstetes tftee eet   ttotto t   otot\"\n",
      "batch 13734  loss=150.0293  steps/s=80.65  prediction: \"atedro buildin something ppl want lesgoo\" => \"ne el i tte rlmi iottt e ttop o t    oot\"\n",
      "batch 13735  loss=144.5193  steps/s=106.51  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne oomi   im m eeememoee eeee eee eeee e\"\n",
      "batch 13736  loss=254.5490  steps/s=11.12  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"ealuE tbjeurhvtnETbjj~Izvvh'z#ï¸]#S#xxp[z\"\n",
      "batch 13737  loss=157.7324  steps/s=157.88  prediction: \"phones Thanks man! its going well so far\" => \"loo iis em  eeime m me e e    e  ae   ll\"\n",
      "batch 13738  loss=148.3598  steps/s=102.25  prediction: \"ool challenge. amazing its down to 112mb\" => \"rl s hs   l   claaa  aaa aa   a n       \"\n",
      "batch 13739  loss=157.6348  steps/s=105.45  prediction: \"nt ask for almost bricked my work laptop\" => \"  ue a t  d   t                         \"\n",
      "batch 13742  loss=158.0733  steps/s=80.02  prediction: \"minus9 hmm still pixels on my end, weird\" => \"ani  i         t   iiil               o \"\n",
      "batch 13743  loss=143.0449  steps/s=105.57  prediction: \" a lot will impact the rest of your life\" => \"t dtn g na nn  l                        \"\n",
      "batch 13744  loss=134.3874  steps/s=104.15  prediction: \"r this, practice it to get skilled at it\" => \"es to  ga\n",
      "n ljin,x4}Mz,jjjI1xPjIB4/j74BB\"\n",
      "batch 13745  loss=145.0068  steps/s=105.71  prediction: \"e context, like words, strengthen ideas?\" => \" c      e tot  t    e        e  etee eee\"\n",
      "batch 13746  loss=153.0472  steps/s=94.28  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \":do ee  l      dddd ddddddddthtt//t/////\"\n",
      "batch 13747  loss=142.3251  steps/s=99.84  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" wa  ow    ww        tttttttttt///////44\"\n",
      "batch 13748  loss=145.4305  steps/s=103.65  prediction: \"erfect timing actually if thats the case\" => \" e ng tetetteitttitttitittt  t      t t \"\n",
      "batch 13749  loss=200.5201  steps/s=20.47  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @teegtteitttittt ti tt  t t    t t \"\n",
      "batch 13750  loss=142.2634  steps/s=154.57  prediction: \"er this applies outside of chess as well\" => \" etn t ene tt    i s  li ii    fts  e s \"\n",
      "batch 13751  loss=145.9957  steps/s=105.41  prediction: \"n run on my laptop, which I can do w ML?\" => \"gtr H r  e n                            \"\n",
      "batch 13752  loss=184.9208  steps/s=84.68  prediction: \"eigecamry @sunsettler shredded that shit\" => \" r    e  m  n  m   nn n   h    hh  d    \"\n",
      "batch 13753  loss=156.4995  steps/s=104.24  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"                       tttttttt/t//////t\"\n",
      "batch 13755  loss=151.1664  steps/s=104.88  prediction: \"tbh, i like having control over my tools\" => \" on e tsf ff  et          i       o oooo\"\n",
      "batch 13756  loss=144.1776  steps/s=104.42  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"se to wo n no  oooo      ttt  ttttt////s\"\n",
      "batch 13757  loss=147.9795  steps/s=103.84  prediction: \"like there's more of a person there, idk\" => \"ynelpp ee lelereee  ee    e       e   re\"\n",
      "batch 13758  loss=138.6588  steps/s=103.95  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in i n  n     n n    nn n     nn       \"\n",
      "batch 13759  loss=144.3421  steps/s=104.33  prediction: \"ntil finally training on unzoomed images\" => \" eo s om\n",
      "e\n",
      " nnolln l  ln inl nnnnninnnoo\"\n",
      "batch 13760  loss=165.7138  steps/s=96.52  prediction: \"ly @plasmarob you could have a miz mobly\" => \"e: @gom ollt a lllar oo  un o  u  aaoe  \"\n",
      "batch 13761  loss=158.7254  steps/s=37.93  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: @gommtll la@lo   oou  ul    a   mae  \"\n",
      "batch 13762  loss=145.0825  steps/s=114.64  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th  e d nen  n n niiiiiiiiiii           \"\n",
      "batch 13763  loss=196.5756  steps/s=96.42  prediction: \"07 .-.. ..-. --. --. --. --. --. --. --.\" => \" 2Peoa a    r07 w+++bI+++b++zz+zy+++++U+\"\n",
      "batch 13764  loss=174.8252  steps/s=98.57  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" on  ig  li   nii         aa   ..  /// .\"\n",
      "batch 13765  loss=143.7649  steps/s=104.11  prediction: \"ks never knows\n",
      "Or... something like that\" => \"e k n   k  ne wkknn n o...oso.......   e\"\n",
      "batch 13766  loss=168.1027  steps/s=58.24  prediction: \" @llamapuckey never visit sf without jug\" => \"tgo nen keekekknnne.r.....s os.  i e   t\"\n",
      "batch 13767  loss=142.9270  steps/s=108.31  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" t  in   n     w w      i i  ee eeeeeee \"\n",
      "batch 13768  loss=148.3942  steps/s=102.74  prediction: \"gpt-5 powered robot of him into the wild\" => \" re  a a      ege       o     o  o   o  \"\n",
      "batch 13769  loss=151.9641  steps/s=98.94  prediction: \"mcignore feature https://t.co/oLseuf2uxS\" => \"alel t  n  n   r    re eetettt tttttt//t\"\n",
      "batch 13771  loss=150.2694  steps/s=99.60  prediction: \" cs maps btw? would love to see pictures\" => \"toy  n      s               o  o   o    \"\n",
      "batch 13772  loss=139.6701  steps/s=105.33  prediction: \"d into using dishonest middlewit tactics\" => \" ee t teere n n   s snssssi isdsiididiti\"\n",
      "batch 13773  loss=142.4077  steps/s=105.13  prediction: \"he result, its equivalent to convolution\" => \"e   atnr  rr rt  e teeesstt te tt  eet  \"\n",
      "batch 13774  loss=181.7277  steps/s=103.66  prediction: \"his\n",
      "Lets build some cool stuff. So hyped\" => \"es a  e nenL  i i  eese   oo   oo   oo  \"\n",
      "batch 13775  loss=164.6479  steps/s=98.18  prediction: \" your own game engine\n",
      "challenge accepted\" => \"toutwAr tw  e w  e    e ee enegeeneceeee\"\n",
      "batch 13776  loss=146.5177  steps/s=103.75  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" ts ri    s s g     sssss               \"\n",
      "batch 13777  loss=151.8319  steps/s=101.25  prediction: \"inlet like me to test experiments out on\" => \"ngsrtrer  re   le    ee  eee  eeetettett\"\n",
      "batch 13778  loss=214.7477  steps/s=104.98  prediction: \"/t.co/NlzdO0Z2DA https://t.co/qGWUkC7cdS\" => \"tra bret //// ONlt t  t tt ttttte///toot\"\n",
      "batch 13779  loss=167.9836  steps/s=102.02  prediction: \"eople want. Nowâ€ https://t.co/yxXaaiHzQ1\" => \" done ieee    eee      t  t tt///////o//\"\n",
      "batch 13780  loss=162.8471  steps/s=92.56  prediction: \"eMTB very, very inefficiently, thats how\" => \" TBnee Me neM  nee    tetttttttttattttat\"\n",
      "batch 13781  loss=151.2164  steps/s=103.34  prediction: \"ns must magnetically align their protons\" => \" _TB  i  n    nn iilllll  llllllll l    \"\n",
      "batch 13782  loss=135.9368  steps/s=103.51  prediction: \" play instead of making random moves lol\" => \"@ott tl   tt  l     aa   a a            \"\n",
      "batch 13783  loss=134.4445  steps/s=105.55  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia tg  lalt al t   nntttttttttttntttttt\"\n",
      "batch 13784  loss=142.2891  steps/s=103.92  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"    nte ctneeeneeeeeeeeeeettttttt//t////\"\n",
      "batch 13785  loss=161.5136  steps/s=98.77  prediction: \"n @grapplingdev HA i love it, lets do it\" => \" cot e nen@ apanppanna   i v  v v       \"\n",
      "batch 13786  loss=160.6303  steps/s=102.39  prediction: \"meone should make a zig finetune dataset\" => \"ene  a  ln  monoe   o          e     e  \"\n",
      "batch 13787  loss=170.6314  steps/s=98.13  prediction: \"yup totally agree. Very powerful mindset\" => \":pr en  oa lllaa a  a  eee V ee   ee  et\"\n",
      "batch 13788  loss=179.1449  steps/s=69.05  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \":\n",
      "o oy  ty l  et   ee  ee  etee //.. eef\"\n",
      "batch 13789  loss=172.5270  steps/s=106.68  prediction: \"HSVSphere just barely hit max call depth\" => \"o eoa r  y t  g ut t hhee  //e. // KKeff\"\n",
      "batch 13790  loss=145.1962  steps/s=106.22  prediction: \"out efficiency of function approximation\" => \"nl at  aataa aaf    fffffffff c   oooiio\"\n",
      "batch 13791  loss=139.1803  steps/s=103.64  prediction: \"ether they are good or bad on their face\" => \" h d    t tteeteeeee                    \"\n",
      "batch 13792  loss=190.1954  steps/s=85.80  prediction: \"row)\n",
      "\n",
      "deletes 10 lines backwards in nvim\" => \"euly: iBo )\n",
      " A10xP5x110k:)5,:P)!kk\n",
      "/10J,\"\n",
      "batch 13793  loss=147.6970  steps/s=108.37  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   y  hh   s  i  h     i oioiio ooooo oo\"\n",
      "batch 13794  loss=150.5196  steps/s=95.16  prediction: \"enko Could probably do this w ai now lol\" => \"   h c  h   o  o oo o oooobo  o    t o  \"\n",
      "batch 13795  loss=142.2160  steps/s=105.39  prediction: \"ney OR something extremely useful to you\" => \"d  e t  ne            eeeeeeeeeeeeeeeeee\"\n",
      "batch 13796  loss=162.8246  steps/s=102.56  prediction: \"tw (207kb total) https://t.co/nU8w0UL8jm\" => \"hpn e t  ten t 2tt t  tt tttttttt/tt/t/8\"\n",
      "batch 13797  loss=192.0689  steps/s=95.87  prediction: \"____11hz @Collab_Land_ the fuck is this?\" => \"___________1t_l 11lll____t____tt   tt   \"\n",
      "batch 13798  loss=232.1772  steps/s=95.82  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"B WO 7D O IIOOCPEPPPPEEEEEEEtt/t// ///ts\"\n",
      "batch 13799  loss=168.2206  steps/s=98.72  prediction: \"atched this 8 times\n",
      "actually cannot stop\" => \"n    a      t  t  t  s  ttt t  ctccclcct\"\n",
      "batch 13800  loss=153.1104  steps/s=103.79  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"nl rintstttt    p t tptp tptttptttttttt/\"\n",
      "batch 13801  loss=161.6586  steps/s=102.64  prediction: \"norary dan if i can be an honorary denis\" => \"dw t ra n an an              n     n  n \"\n",
      "batch 13802  loss=189.7800  steps/s=21.98  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly: @ba  a na               n n   n  n \"\n",
      "batch 13803  loss=145.3838  steps/s=106.59  prediction: \"discovering new unseen fundamentals, too\" => \" n  ted d\n",
      "en  edn nnennnneenennnneennnen\"\n",
      "batch 13804  loss=148.8664  steps/s=103.36  prediction: \"ple deep q network has achieved insanity\" => \"ly:  o ene e ee e ee   e    e eaaaa  asa\"\n",
      "batch 13805  loss=161.5784  steps/s=99.02  prediction: \"eglide theyre patronizing.\n",
      "trash company\" => \" a n  mde e te dreeee e   rirriiiiiinnni\"\n",
      "batch 13806  loss=155.9843  steps/s=101.16  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e \n",
      "  thRotiot ot oo i  o             s  \"\n",
      "batch 13807  loss=186.2451  steps/s=21.77  prediction: \"eply: @Nominus9 should be out soon   : D\" => \" ly: @itnitot ot o  m                s  \"\n",
      "batch 13808  loss=153.5975  steps/s=131.04  prediction: \" your own game engine\n",
      "challenge accepted\" => \"@ou wtrwiw to w  o    e nnnene eeneeeeee\"\n",
      "batch 13809  loss=138.8828  steps/s=103.79  prediction: \"emely hard to avoid being pressured into\" => \" e h  eee l lele                   e    \"\n",
      "batch 13810  loss=144.2072  steps/s=100.72  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"d oo t   nn n n            ttttttt/////t\"\n",
      "batch 13811  loss=158.7476  steps/s=95.83  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \":hrnea a reell e lllloololtto////ttt////\"\n",
      "batch 13812  loss=150.5460  steps/s=103.27  prediction: \"board wave and its constituent sinusoids\" => \"er y ner  rr  aad   da   t  tst ttssstss\"\n",
      "batch 13813  loss=156.6542  steps/s=39.19  prediction: \"ly: @shurensha Done. Great advice. Ty ty\" => \"y: @ eer      a d   a   ttt tnt ttssstss\"\n",
      "batch 13814  loss=163.3221  steps/s=108.14  prediction: \" going straight there out of highschool)\" => \"teat ea   nn ihg tt t tttttt  t  t hh hh\"\n",
      "batch 13815  loss=137.3413  steps/s=104.20  prediction: \" just be a webpage visit, its in browser\" => \"tu  ll lln  l                     iii   \"\n",
      "batch 13816  loss=139.4278  steps/s=103.01  prediction: \"people skills of almost everyone ive met\" => \"lrol nt e eeeese    ll llllll     eeeeee\"\n",
      "batch 13817  loss=155.0539  steps/s=98.94  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"lo l  t  p es is    \"     eeeooee  eee e\"\n",
      "batch 13818  loss=138.1857  steps/s=103.85  prediction: \"ust store those. skip the whole ML stuff\" => \"st t  stst et  e  ssss      t    e   e  \"\n",
      "batch 13819  loss=148.1468  steps/s=101.92  prediction: \"imative vehicle for personal development\" => \"natte  tit ti  tie ee ee e e lee eee eee\"\n",
      "batch 13820  loss=159.4211  steps/s=99.56  prediction: \"e gets servers/multiplayer working too..\" => \" uhi eiiee ee ge ees rsrseerslrrlerrlror\"\n",
      "batch 13821  loss=144.8355  steps/s=105.54  prediction: \"\n",
      "\n",
      "\"fly over xyz tourist location for $5\"\" => \"\n",
      "y  o @sh\"s  zss!,!x\"z,HHx2zHHxNzN/N$j/k\"\n",
      "batch 13822  loss=146.3974  steps/s=100.82  prediction: \"y time back so i can work on what i want\" => \":to amy m  t  t           o   oo        \"\n",
      "batch 13823  loss=168.7336  steps/s=76.00  prediction: \"izmobly circle gang is TRULY unstoppable\" => \"naat     n    i                n    a t \"\n",
      "batch 13824  loss=145.4145  steps/s=106.40  prediction: \"e tbh\n",
      "My projects arent that big yet tho\" => \" ce  eeenheneeeee ee ee reetettttttttt  \"\n",
      "batch 13825  loss=139.8790  steps/s=104.18  prediction: \"and completely unknown to the other half\" => \"nd o  l  l lllpllllll  nnnnnnn          \"\n",
      "batch 13826  loss=161.7382  steps/s=104.28  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \": @nansyyynyyyyd dd   dd    iiiiiiiiniii\"\n",
      "batch 13827  loss=170.6575  steps/s=101.87  prediction: \"EDM and caffeine\n",
      "https://t.co/xSA2QsenCw\" => \"S ,2lioloutrt0gsEDMxxbBgBTEDMxSA\n",
      "TL,:C:D\"\n",
      "batch 13828  loss=183.8028  steps/s=37.07  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: ttnd     n  n fet e t/tttt////////ts2\"\n",
      "batch 13830  loss=135.0378  steps/s=107.11  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia t   l  t al t   nntttttttttttntttttt\"\n",
      "batch 13831  loss=148.4991  steps/s=90.65  prediction: \"od simclusters chosen principle engineer\" => \"ne   e  g o e t   sss ssss sscs  eeeenne\"\n",
      "batch 13833  loss=148.8298  steps/s=106.34  prediction: \"times and pick up new details every timâ€¦\" => \"hn e  t  t 0  0n        n      d    eeee\"\n",
      "batch 13835  loss=165.6616  steps/s=73.78  prediction: \"ZyMazza what do they call this opening??\" => \"yMy  on  e  n un   d  den  e  eii   eeee\"\n",
      "batch 13836  loss=146.1087  steps/s=110.24  prediction: \"ng that solves a problem you're close to\" => \"   l   iht it tt   s aa         e ooeee \"\n",
      "batch 13838  loss=144.2990  steps/s=104.80  prediction: \"out efficiency of function approximation\" => \"urwat  a tta aaf    fffffffffcc     oiio\"\n",
      "batch 13839  loss=143.4149  steps/s=103.76  prediction: \"t immensely and give you new information\" => \"hing  p neetn  n e  e     e   e   n    n\"\n",
      "batch 13840  loss=144.6593  steps/s=103.96  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" og t   n  n a aaaaaaaanannnnnnnnnnnnnnn\"\n",
      "batch 13841  loss=156.4027  steps/s=103.74  prediction: \"owing that your food supply doesnt scale\" => \"u  i n ttin t  ttt     oo      ooo  o   \"\n",
      "batch 13842  loss=143.7958  steps/s=103.84  prediction: \"ks never knows\n",
      "Or... something like that\" => \"  o n   t nnekwkkkn n o...oso..... e   e\"\n",
      "batch 13843  loss=142.9383  steps/s=103.10  prediction: \"the (fake) claim about compromising info\" => \" i  con n tee te                 mmmmomi\"\n",
      "batch 13844  loss=157.2855  steps/s=101.98  prediction: \"st surgery, without painkillers\n",
      "\n",
      "i kneel\" => \" :se s  s  s s  s     t  i  iiiiitii ii \"\n",
      "batch 13845  loss=157.5638  steps/s=103.14  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly:  ar ppeetpe     o   s   hoo oooh oo \"\n",
      "batch 13846  loss=151.9626  steps/s=100.29  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"e   o te   n            a    aaee   eaae\"\n",
      "batch 13847  loss=139.0543  steps/s=104.27  prediction: \", thank God we can function at all loool\" => \" ind i e r l  te      a   n       an  a \"\n",
      "batch 13848  loss=155.8573  steps/s=97.40  prediction: \" stuff! Thanks, hope yours went well man\" => \"tup  e  oodo   to      n       o    o   \"\n",
      "batch 13849  loss=262.1936  steps/s=11.57  prediction: \"reply: @calbch its the year of the monad\" => \"eply: @b,wmh _isð—ªI#á´v~!GTâ™‚v!$TcGå§kkGGTT1\"\n",
      "batch 13850  loss=190.5211  steps/s=127.35  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"B N AGNALLLAGGIAIGLILL G G   t/////////t\"\n",
      "batch 13851  loss=162.1175  steps/s=105.34  prediction: \" srsly the golden age of building things\" => \"too   no  xss  l  lo  oo     ee  le ggg \"\n",
      "batch 13852  loss=151.6200  steps/s=99.98  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"n  e   eee   d  d  e  e e     e        t\"\n",
      "batch 13853  loss=141.1898  steps/s=105.22  prediction: \"minds me of that old gpt engineer script\" => \"enetide '    en                    ee   \"\n",
      "batch 13854  loss=152.0846  steps/s=104.44  prediction: \"nsions have a different message, I think\" => \"d tto ssne nns nsssese   neeeese e  eee \"\n",
      "batch 13855  loss=155.2677  steps/s=104.40  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" tn tlt nt  t  o  o  tttttt  ttttt////t/\"\n",
      "batch 13857  loss=167.4697  steps/s=103.29  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"toe e   e//eteettttttttttp////hpD//DDp//\"\n",
      "batch 13858  loss=156.2229  steps/s=98.48  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"u    t tecttt ut t  o  oooo o aaoooaabb\n",
      "\"\n",
      "batch 13859  loss=138.0971  steps/s=101.75  prediction: \" put you so far ahead its not even funny\" => \"trulo     llo  u                        \"\n",
      "batch 13860  loss=145.9483  steps/s=102.59  prediction: \"om the distribution of (single response)\" => \"up frnfff e r r ii riitiii iii  ii  i   \"\n",
      "batch 13861  loss=172.4240  steps/s=101.12  prediction: \", no\n",
      "If anyone else does let us know lol\" => \" an     nIon nnn  n n   n e e           \"\n",
      "batch 13862  loss=146.4074  steps/s=105.32  prediction: \"ses to use them, only uses open src ones\" => \"  bss sselse eeese e ee e    e    e   s \"\n",
      "batch 13863  loss=167.4956  steps/s=99.18  prediction: \"end to work, and they pretend to pay us\"\" => \" d  teyrte et te  t    te   t e n e  et \"\n",
      "batch 13864  loss=147.3192  steps/s=104.63  prediction: \"e some exciting long term vision then no\" => \" pr  ote et teet   e    e        ii   nn\"\n",
      "batch 13865  loss=149.5611  steps/s=104.34  prediction: \"rap out of them\n",
      "\n",
      "dont worship complexity\" => \"ec2d nhel_gnsLi @1Lwjk2hb-x80%--u--80%Q-\"\n",
      "batch 13866  loss=146.8560  steps/s=104.84  prediction: \"o make a significant impact on your life\" => \"ugai da   n    i iaiiiiiiiiiiiii        \"\n",
      "batch 13867  loss=156.8802  steps/s=83.24  prediction: \"amebedan @jaivinwylde stochastic success\" => \"ne n ia aa ndiniiiiaiinin t    ttcc  cc \"\n",
      "batch 13868  loss=142.2188  steps/s=103.86  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"n  yoiy yy tle                          \"\n",
      "batch 13870  loss=188.3484  steps/s=93.34  prediction: \"sdavila007 @Nominus9 @mister_shroom Down\" => \"  i  rlalvlla e l      i   s    ro  rro_\"\n",
      "batch 13871  loss=157.7892  steps/s=107.60  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \" se sor  t t   sa    aaaa s    naaaa    \"\n",
      "batch 13872  loss=146.5833  steps/s=104.72  prediction: \"e waves stopped\n",
      "\n",
      "https://t.co/FO1wQxoZRU\" => \" cshese  ed eeeWppppppppppppttt////////t\"\n",
      "batch 13873  loss=139.0553  steps/s=105.06  prediction: \" for most models\n",
      "https://t.co/US1Fvcybrh\" => \"tou    o mot o oomoototttt tttt/t///////\"\n",
      "batch 13874  loss=136.2680  steps/s=101.56  prediction: \"u can build in a week is actually insane\" => \"sc mo  unu uu u                         \"\n",
      "batch 13875  loss=144.1140  steps/s=103.22  prediction: \"best way ive found so far to order tasks\" => \"e    et tt  tett                   o    \"\n",
      "batch 13876  loss=136.3340  steps/s=105.53  prediction: \"will exhaust this reward bc its not real\" => \" lh  ni i     it                        \"\n",
      "batch 13877  loss=157.9708  steps/s=100.96  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" tre  e t  eetg e  gt gtt eee eeee tee  \"\n",
      "batch 13878  loss=142.1439  steps/s=103.51  prediction: \" commonly use amd it works insanely well\" => \"taus tt  m    m                         \"\n",
      "batch 13879  loss=142.0737  steps/s=96.47  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"eyh e iaaaaaaanaaaaaa t  t    ss eesesse\"\n",
      "batch 13880  loss=175.0031  steps/s=70.38  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yve ioaaaaaae   t ttt..  tttssseeeeeeeee\"\n",
      "batch 13881  loss=147.2446  steps/s=122.14  prediction: \"ticed this too, its what got me thinking\" => \"hni     c t ti t  t tttst tt    t   tttt\"\n",
      "batch 13882  loss=175.8478  steps/s=105.16  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"yCnacriii i__ii__@__7777i i7777  7iii i \"\n",
      "batch 13884  loss=169.9583  steps/s=97.79  prediction: \"Koala that would be much appreciated, ty\" => \"aosiaa_aaa aaa   aa   t    b   h    h   \"\n",
      "batch 13885  loss=131.2699  steps/s=99.63  prediction: \"u can build in a week is actually insane\" => \" t mo  mn  uu un                       a\"\n",
      "batch 13886  loss=145.9075  steps/s=104.61  prediction: \"about things that have significant value\" => \"noun t ts   ttttt aa tt tth  hat  aiaa a\"\n",
      "batch 13888  loss=144.4109  steps/s=105.22  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" ts an  s s s g   s sssss               \"\n",
      "batch 13889  loss=147.1778  steps/s=104.93  prediction: \"ng sessions for now for the discord name\" => \"g t ia el ino inssioo  os  oo  oo  oo  o\"\n",
      "batch 13890  loss=142.2577  steps/s=103.84  prediction: \"y clip of polnareff LBJing up the stairs\" => \":a  hig  a l           fffff            \"\n",
      "batch 13891  loss=143.4363  steps/s=105.33  prediction: \"ss\n",
      "\n",
      "p much everything else is midwittery\" => \" i  t  l ppp    e     eeeeeeee e ee  eii\"\n",
      "batch 13892  loss=146.8649  steps/s=109.05  prediction: \"unday is a great sunday to write haskell\" => \" a  aas cn   er    n a  s s     t  t t t\"\n",
      "batch 13893  loss=147.1923  steps/s=105.48  prediction: \"n and id 100% recommend it over The Goal\" => \"ga  oo  d  dd dd  0 00 n            e ee\"\n",
      "batch 13894  loss=203.7409  steps/s=99.52  prediction: \"1 @yacineMTB just dmd you the term sheet\" => \" tA d@no \n",
      " ezT3 j5j47z@34MT@,MTB7jMfB7j@\"\n",
      "batch 13895  loss=174.5955  steps/s=105.34  prediction: \" all that\n",
      "\n",
      "id love to see the source btw\" => \"@n te e  d t  at                      e \"\n",
      "batch 13896  loss=151.4604  steps/s=98.85  prediction: \" gotchu fam\n",
      "sending the link as we speak\" => \"@eln  na t   ada      ee   e            \"\n",
      "batch 13897  loss=144.7440  steps/s=103.52  prediction: \"mind responds to and processes phenomena\" => \"antlr t        n o    o        s sssssss\"\n",
      "batch 13898  loss=167.5257  steps/s=105.03  prediction: \"ich in this case, is their lack of speed\" => \"n as et hshs    h     s  s i  ii        \"\n",
      "batch 13899  loss=148.1251  steps/s=102.85  prediction: \"\n",
      "Learning is the precursor to succeeding\" => \"\n",
      "int  c  @vutYe PLmybPNbOGROGðŸ˜DGLpDZb++8\"\n",
      "batch 13900  loss=155.2943  steps/s=103.03  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"emad iWi @:|\"Wu WL*z^PÊ€vFFvOyWDGLpD[TTâ€¦ðŸ›‘\"\n",
      "batch 13901  loss=151.8025  steps/s=103.57  prediction: \"essing\n",
      "You help cure that if you do this\" => \" se e sesnses rs    e e                 \"\n",
      "batch 13902  loss=175.2427  steps/s=102.96  prediction: \"/t.co/hjQfCWaZxw\n",
      "https://t.co/VFbc29W7Ct\" => \"e.ceeset////ttthttthttttt::tt/tt////ttt/\"\n",
      "batch 13904  loss=141.5380  steps/s=102.90  prediction: \"better generalizer than the classic MLP?\" => \"e t e t  tteteneeeeeeeeeeeeee e ee     e\"\n",
      "batch 13905  loss=151.7657  steps/s=104.70  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"nl r ntstttt    s t tptp t tttptttttttt/\"\n",
      "batch 13907  loss=163.2099  steps/s=65.58  prediction: \"@btwphones thanks! its going well so far\" => \"aanmiotspo   tg â€¦ tptptttt ttt////t tozz\"\n",
      "batch 13908  loss=153.9100  steps/s=106.18  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \"pmeineeee ne e s e s  e  s          er r\"\n",
      "batch 13909  loss=149.4471  steps/s=100.87  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" of ea ae an  re e it  t   ttttt////t///\"\n",
      "batch 13910  loss=141.7455  steps/s=104.39  prediction: \"e the reward dips down below the average\" => \" aeih  hereerrrerer  d dddd   www    e  \"\n",
      "batch 13911  loss=93.5547  steps/s=103.98  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"tou OOO Y\n",
      "  eae    ????  aa?    aa   EE \"\n",
      "batch 13912  loss=146.1995  steps/s=105.24  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"en h i   bbe  hbe  eeeeeoe i  sii i     \"\n",
      "batch 13913  loss=168.8132  steps/s=105.27  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"geet tt e  et  eeede e d dadddadaaaaaaaa\"\n",
      "batch 13914  loss=148.9990  steps/s=104.84  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"es ee @onhio EdaWL-kvT0(v@??MM+?YM)Wv(.L\"\n",
      "batch 13915  loss=144.2840  steps/s=104.13  prediction: \"it seems like using a spoon vs a scalpel\" => \"n   o e  el  es ee s  s      ss  ss    s\"\n",
      "batch 13916  loss=147.8167  steps/s=104.40  prediction: \"y highest elo and post cool results on x\" => \" s  so   st t st    e    o   o   oo   os\"\n",
      "batch 13917  loss=147.7513  steps/s=100.91  prediction: \"e enlightened than me, i need to wake up\" => \" ceer  r rrlele e ee eneeen eeee   e ee \"\n",
      "batch 13918  loss=133.9681  steps/s=106.58  prediction: \" with a small group of people around you\" => \"totto tt i                 oo    op ooo \"\n",
      "batch 13919  loss=160.2670  steps/s=98.51  prediction: \"Koala that would be much appreciated, ty\" => \"assa a aaaaaaaa  aa   u    uu  p pppppaa\"\n",
      "batch 13920  loss=146.4463  steps/s=105.82  prediction: \", how much info could you get from that?\" => \" ao  iiiii m  wm  o     o  oo   o    o  \"\n",
      "batch 13921  loss=145.5463  steps/s=103.89  prediction: \"han automating friction out of your work\" => \"et ne    nenttt  tn  ttttiitti   ot oo o\"\n",
      "batch 13922  loss=143.2067  steps/s=105.40  prediction: \"just point to concepts and arent reality\" => \"ust i  i    n ot   oo  o t  tnn n  nnn t\"\n",
      "batch 13923  loss=150.4740  steps/s=103.22  prediction: \" make work games\n",
      "https://t.co/WVxkHR6btx\" => \"tyr  ma  ek kk    k    a    a///////oo//\"\n",
      "batch 13925  loss=163.0435  steps/s=104.20  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "de d  phd d eda e e    a  sss   ss    \"\n",
      "batch 13926  loss=158.0442  steps/s=105.44  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th tot otg    e      t  tttttttt////////\"\n",
      "batch 13927  loss=153.5450  steps/s=97.72  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \" enr s   t n  n   t  t tt//////////tt/tK\"\n",
      "batch 13928  loss=148.5270  steps/s=102.88  prediction: \"libraries or backend compute or anything\" => \"ykenteneetn rrr rrrrrrr r          r    \"\n",
      "batch 13929  loss=159.6552  steps/s=102.75  prediction: \"he phone seems to make a huge difference\" => \"e  tthg n t e tee  e   ee    e      eeee\"\n",
      "batch 13930  loss=147.5449  steps/s=99.15  prediction: \"to fall back on. build stuff on the side\" => \"  t   s     b        b            f     \"\n",
      "batch 13931  loss=139.8684  steps/s=105.39  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tlea al ell lll lla a aaaaaa      o     \"\n",
      "batch 13933  loss=145.6473  steps/s=105.23  prediction: \"ve to somewhere else\n",
      "\n",
      "idk just a thought\" => \"e  a deoe eeten ee eeeeeeeeeeee e      t\"\n",
      "batch 13934  loss=159.9608  steps/s=91.74  prediction: \"builds mcdonalds just wants to grill man\" => \"et e es   mmmeeeeseesss sss  s  t tt    \"\n",
      "batch 13935  loss=190.7129  steps/s=21.54  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @s mommmdo ds ssss sss  s  t tt    \"\n",
      "batch 13936  loss=144.5704  steps/s=111.20  prediction: \"all a month ago\n",
      "Dang good stuff bro!!!!!\" => \"llyol      tt  x  a aa aa  o oo  o oooo!\"\n",
      "batch 13937  loss=146.8041  steps/s=103.45  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"   tu   ttt  t        p pppppppp        \"\n",
      "batch 13938  loss=144.8955  steps/s=103.64  prediction: \" what? never heard of it lol skill issue\" => \"tome  tamem r  neeae  e re  a  e    lil \"\n",
      "batch 13939  loss=143.8968  steps/s=102.58  prediction: \" been the difference, in your experience\" => \"teedaa  aa n   eeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 13940  loss=137.7793  steps/s=102.88  prediction: \"quote a lot bc it seems to come up a lot\" => \"cistis t      ttt                       \"\n",
      "batch 13941  loss=143.0052  steps/s=102.96  prediction: \"avorite password what would it be?? haha\" => \"te o  i      aa   a a    w  w           \"\n",
      "batch 13942  loss=175.2841  steps/s=104.43  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"t.mei\n",
      "tt:///:t/o/tttttttt:::t/ttz///tt//\"\n",
      "batch 13943  loss=162.5584  steps/s=104.83  prediction: \"ding man! Yeah lmk how it goes next time\" => \" ni  hn oa rnaf naa                     \"\n",
      "batch 13944  loss=142.5998  steps/s=103.85  prediction: \" is better than lots of ppl not starting\" => \"ts  ps ssese eeseeet    t  t  ttt     t \"\n",
      "batch 13945  loss=143.6902  steps/s=102.47  prediction: \"the highest quality music we have so far\" => \" e f a    hhhht hhh                     \"\n",
      "batch 13946  loss=144.3703  steps/s=99.18  prediction: \"lity is really really powerful, actually\" => \"yte uA ii t iii lyllllylllll ellll   lll\"\n",
      "batch 13947  loss=178.8091  steps/s=98.65  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @hieshessser    s   as stttttt////88\"\n",
      "batch 13948  loss=155.8933  steps/s=100.12  prediction: \"ny part of a much bigger long term thing\" => \"    s anaannn n                 g g gg g\"\n",
      "batch 13949  loss=167.0067  steps/s=89.29  prediction: \"c you got it yup https://t.co/6FeXFmJ22C\" => \"oan      y                 g   ///  F FF\"\n",
      "batch 13950  loss=160.7068  steps/s=41.53  prediction: \"ly: @larpertony @kuberdenis my elo is 10\" => \"y: @qxna       t  t t p   /t/  ///FFFmFF\"\n",
      "batch 13951  loss=158.2660  steps/s=129.49  prediction: \"a Meet the new boss\n",
      "Same as the old boss\" => \"nso u  t  t t te    ee  sss  s  eo  e   \"\n",
      "batch 13953  loss=167.2026  steps/s=103.15  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"t.c o ooo///tt////XXtttXXX////ttc///tt//\"\n",
      "batch 13954  loss=160.4428  steps/s=103.53  prediction: \"ameboy emulator) https://t.co/og8bnpdUHw\" => \"ne smaa  b b  e a   a     o   ttttt////o\"\n",
      "batch 13955  loss=153.7966  steps/s=101.98  prediction: \" pieces until you have solved the puzzle\" => \"@o  om  seen   n  e             v   e   \"\n",
      "batch 13956  loss=145.7913  steps/s=103.10  prediction: \"cay principles, and it ended up formingâ€¦\" => \"kl e,ng  n  n  n           d d d  d     \"\n",
      "batch 13957  loss=158.8372  steps/s=103.15  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"n  a   tt t ttt        e eeee reeeeemmem\"\n",
      "batch 13958  loss=145.5478  steps/s=99.37  prediction: \"oo much context switching to twitter idk\" => \"ntt ee     o   m o   tt ttttttittitittit\"\n",
      "batch 13959  loss=164.9527  steps/s=102.93  prediction: \" God for helping us both out\n",
      "it was hell\" => \"@erw  r la              o   oo      t  t\"\n",
      "batch 13960  loss=145.7139  steps/s=104.12  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"the  iti t t         s       a aaa aaaae\"\n",
      "batch 13961  loss=145.3358  steps/s=104.84  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" boe  foess s  s   sss ss ss sssssse  s \"\n",
      "batch 13962  loss=168.0578  steps/s=98.44  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \"pepieri  nln i t  ih tttthnttt  httstt/t\"\n",
      "batch 13963  loss=145.6271  steps/s=103.23  prediction: \"utomatically imagine letters as colored?\" => \"s  o au uoo aaoaaaa aaa aaalaa     l    \"\n",
      "batch 13964  loss=151.2766  steps/s=103.53  prediction: \"y cool implications, seems like it would\" => \" yidces  h n   c iiiiiioo  i ssis i iii \"\n",
      "batch 13966  loss=145.1633  steps/s=104.27  prediction: \"hat easy guys, you learn like way faster\" => \"et ta e l t   a y yyy yyy              a\"\n",
      "batch 13967  loss=139.4009  steps/s=104.62  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" ti gne   nnne ne eeeereeeettititttooooo\"\n",
      "batch 13968  loss=146.2166  steps/s=104.35  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn e te ln  ee e eeeee e eeettttt/////tt\"\n",
      "batch 13969  loss=153.7748  steps/s=104.40  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "it     iwo i)(*z:SzGv2#I1DDz1AV7UB9:)2L\"\n",
      "batch 13970  loss=141.6884  steps/s=103.49  prediction: \"dition, just kpis to optimize right now)\" => \" ne i  n niinnin i   i    o  iiiii iii i\"\n",
      "batch 13971  loss=142.3891  steps/s=103.95  prediction: \"ard to realize. lies are really blinding\" => \"rd  e   nn r   aa         eeeeeeelllllll\"\n",
      "batch 13972  loss=138.8773  steps/s=104.77  prediction: \"ideo of you doing some crazy stuff. damn\" => \"n  a t    t     o ooo ooo    o          \"\n",
      "batch 13973  loss=165.4243  steps/s=97.41  prediction: \" giz tarantinos alt?????? this shit fire\" => \"teo ioz z o yi n ii a a????????? ??   ? \"\n",
      "batch 13974  loss=181.6151  steps/s=91.09  prediction: \"w many GFLOPS? Are these legal in CA????\" => \" pt e y  o ynotn a?  t n  e e e  t    i?\"\n",
      "batch 13975  loss=138.3919  steps/s=104.36  prediction: \"mals have uncanny valley detection genes\" => \"anl r   sss       aaaaaaaaa  aleneeeee e\"\n",
      "batch 13976  loss=143.9831  steps/s=104.97  prediction: \"house? where is your phone charger? etc)\" => \"eue yoyoe   ue re  e e      eo h  h rr  \"\n",
      "batch 13977  loss=176.4034  steps/s=103.33  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e   ieiiei## #n##a#aaasassstat/t////////\"\n",
      "batch 13978  loss=151.0105  steps/s=105.39  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng o   o in   I                         \"\n",
      "batch 13979  loss=167.7472  steps/s=64.06  prediction: \"@IterIntellectus have you brrrytt today?\" => \"ytxi4eioni    n  t             t        \"\n",
      "batch 13981  loss=175.4531  steps/s=78.23  prediction: \": @tunahorse21 Thanks for reading brotha\" => \" @aay m ce   ct 21/,,?F(.vEbjIIw,O(cOk,.\"\n",
      "batch 13983  loss=157.0318  steps/s=108.63  prediction: \" flick of the wrist instead of traveling\" => \"toni ig  f if         t i tt    tt t t  \"\n",
      "batch 13984  loss=138.4404  steps/s=104.12  prediction: \"s of industry water cooler conversations\" => \" aot  t s   os ss       o     oorrrroroe\"\n",
      "batch 13985  loss=170.7021  steps/s=91.44  prediction: \"Veraciety We're goin alright, we're goin\" => \"Spheri n t nn  t   rr   oo    rrrerrooen\"\n",
      "batch 13986  loss=152.0669  steps/s=106.12  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"toer nr    r re ro r  tt   tt s tt s///t\"\n",
      "batch 13987  loss=174.8463  steps/s=97.78  prediction: \"@p0nnnpppppppppp https://t.co/5V1IjMrIYA\" => \"yimloeA pppppppppppppppppp///pp////t/III\"\n",
      "batch 13988  loss=170.9792  steps/s=87.16  prediction: \"e to you brother https://t.co/nLfQJqRwZ9\" => \" iorno ono no   oothttttt/tttttt////t/oc\"\n",
      "batch 13989  loss=159.0347  steps/s=100.33  prediction: \" his story you wont regret it, its crazy\" => \"taasaa aa\n",
      "  sss  sss    o    r r rt   tt\"\n",
      "batch 13991  loss=146.3620  steps/s=103.45  prediction: \"reason...\"\n",
      "Had this actually happen once\" => \"epls  otjuo txw PHBjw;_\"\n",
      "Hm55:jI,,5kUm\"\n",
      "\"\n",
      "batch 13992  loss=148.8586  steps/s=103.15  prediction: \" the past two months and its so worth it\" => \"toe  ot  te t et   tt     t  tt   s  s  \"\n",
      "batch 13993  loss=143.9337  steps/s=101.11  prediction: \"ranoid to install an extension like that\" => \"etle etenfnpe@ne%(@%%%(A,(%%A)(Iv%)x,)wT\"\n",
      "batch 13994  loss=157.0673  steps/s=102.47  prediction: \" now i have this https://t.co/NCsyY5vpWl\" => \"tot  nT n  t  n        ttttttttsttttss//\"\n",
      "batch 13995  loss=157.8450  steps/s=93.22  prediction: \"builds It is factually what plants crave\" => \"ett i bb b    s  t  t tt attt tltt tttp \"\n",
      "batch 13996  loss=140.1743  steps/s=101.78  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"@h e n n t en  ne eee eeeetttttt/////tt/\"\n",
      "batch 13997  loss=139.5695  steps/s=105.61  prediction: \"all the way down https://t.co/uP6ieWqBYQ\" => \"nl titil nll    ll      ttttttttt///////\"\n",
      "batch 13998  loss=260.0418  steps/s=11.06  prediction: \"reply: @graffioh HA thats really awesome\" => \"eply  @dees  @r PN@jINNN,6k66'6kX8U5,xâ€¦:\"\n",
      "batch 13999  loss=149.8373  steps/s=111.25  prediction: \"ective, its significantly more efficient\" => \" tloc   ceecei eiiiiisiiiiiiiii ii ifffi\"\n",
      "batch 14000  loss=150.3223  steps/s=98.80  prediction: \"lsio recursive mind exploding adventures\" => \"y eesi ileelesieeieiieeeiei ee  eii eenn\"\n",
      "batch 14001  loss=172.3632  steps/s=78.24  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"yve sveeesese  e  ee ..   tnn  dedndddee\"\n",
      "batch 14002  loss=144.1148  steps/s=106.07  prediction: \"engthen the habit over reps\n",
      "Cool thought\" => \" tioe tn enneehnthh t hehe e  eeee  o oo\"\n",
      "batch 14004  loss=168.1281  steps/s=50.70  prediction: \": @0arity @bayes_street probably yea lol\" => \" @0toon a@p m0s PA#j_?(?,fk:C?T.?bTvwgv:\"\n",
      "batch 14005  loss=153.5480  steps/s=119.56  prediction: \"th @wordgrammer i love large lean models\" => \"hen hhethete @ t etr ee   rre lelleeelll\"\n",
      "batch 14006  loss=139.8201  steps/s=105.20  prediction: \"thing you do very often, like constantly\" => \"h nf  o si  s n      o                  \"\n",
      "batch 14007  loss=154.2512  steps/s=100.23  prediction: \"eaply making synthetic training data? :)\" => \" li ine  na n   nnn ynn n nnniinntiiitaa\"\n",
      "batch 14008  loss=137.8778  steps/s=104.28  prediction: \"ntelligence\" + related learning concepts\" => \"   s poeiinsni\" ee eeleelee eeeleeennnen\"\n",
      "batch 14009  loss=155.5775  steps/s=96.25  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"leolie_nnnecnn nllIIII l l  e    i   i  \"\n",
      "batch 14010  loss=132.4331  steps/s=104.98  prediction: \"vision how great itll be once youre done\" => \"en  eta nhn   n                        e\"\n",
      "batch 14012  loss=170.0075  steps/s=101.19  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"h m t g gg g gg  gg ggg gttt   ttttt////\"\n",
      "batch 14013  loss=143.6507  steps/s=101.49  prediction: \" a bool so you just become sick again :/\" => \"t te gg     ooo o       o o    o        \"\n",
      "batch 14016  loss=147.6373  steps/s=103.96  prediction: \"nserve the good parts against decay/loss\" => \"   o  a  nn ne d e          a   aaa asaa\"\n",
      "batch 14017  loss=152.1025  steps/s=64.33  prediction: \"@calbch its gonna be a good one for sure\" => \"lazzaee c eneee  oo    aaaa o d aaa asss\"\n",
      "batch 14020  loss=149.5374  steps/s=112.36  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"sdan sasna   n nn     eeee   ee  -------\"\n",
      "batch 14021  loss=141.2941  steps/s=104.68  prediction: \"nk could handle a variable player count)\" => \"  Ior   nend nndd  d a aalalaaaaala laa \"\n",
      "batch 14022  loss=140.6673  steps/s=103.66  prediction: \"setup is going to be a bit different tho\" => \"      ttt tno t                         \"\n",
      "batch 14024  loss=164.6837  steps/s=84.41  prediction: \"rdenis grats btw. site looks amazing too\" => \"e   : @sener whaESEISE.,9(S.3I9zB3(vCOz\n",
      "\"\n",
      "batch 14025  loss=143.9049  steps/s=105.73  prediction: \"u a why/a vision for hard work over time\" => \"sw e  o  w  e h  i     i     o      r   \"\n",
      "batch 14027  loss=139.8286  steps/s=99.35  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" aot  ea  tte  eeeee                   t\"\n",
      "batch 14028  loss=136.5261  steps/s=105.85  prediction: \"he race to steal the eu tech bros begins\" => \"e    ccae    en  tt   e  e    ee   e  e \"\n",
      "batch 14029  loss=140.9929  steps/s=103.62  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"taa  en  eo lo toololll llllllll a   a  \"\n",
      "batch 14030  loss=179.4821  steps/s=101.59  prediction: \"arning a lot and building a lot\n",
      "\n",
      "love it\" => \"ne a 0l len    o  alann n   ni   l   lli\"\n",
      "batch 14031  loss=140.3895  steps/s=104.26  prediction: \"for typos and a list of other dumb stuff\" => \"fr t   c tc                             \"\n",
      "batch 14032  loss=142.3335  steps/s=103.68  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"nt aett ng ic gciiiiiciiaiaaiaaaaaaaap  \"\n",
      "batch 14034  loss=159.7294  steps/s=104.32  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"   ttr  ter tt t rrtr  tt i  stt/tt/t//t\"\n",
      "batch 14035  loss=162.1426  steps/s=95.89  prediction: \"tters job was a good man\n",
      "\n",
      "God is amazing\" => \" r tore tter ttto t    a  a  o oo \n",
      "GG\n",
      "\n",
      "\n",
      "\"\n",
      "batch 14036  loss=136.2280  steps/s=100.58  prediction: \"ge\n",
      "how to generate it is the question...\" => \" tett isvaa  aegeaee e e           t  te\"\n",
      "batch 14037  loss=216.8874  steps/s=91.67  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"t.uaavtt:///KRNtRRRe  tttt  ttttt///t..t\"\n",
      "batch 14038  loss=139.1331  steps/s=104.17  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in   n  n n   n n    nn n     nn       \"\n",
      "batch 14040  loss=137.1889  steps/s=102.42  prediction: \"ch though if i cant fix a particular bug\" => \"hea  t. htththth                       a\"\n",
      "batch 14041  loss=145.5956  steps/s=105.31  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \"ue 00do00000  00 oo 11100000000         \"\n",
      "batch 14042  loss=128.7576  steps/s=104.17  prediction: \"veryone in the past was a caveman/moron\"\" => \"e  je  ene eeeeeee             aaaaaaaaa\"\n",
      "batch 14043  loss=144.1284  steps/s=104.13  prediction: \" deadlines dont really get done the same\" => \"tot   n d d de d  ddd ee e le   e tet ee\"\n",
      "batch 14044  loss=163.8031  steps/s=100.76  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"ue   rniin ni  o  o   t  tst  /// t/tQyy\"\n",
      "batch 14045  loss=153.0934  steps/s=104.45  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "isr  @ ffI. )  ::Y000!:!!!!!j3NN3!NQk63\"\n",
      "batch 14046  loss=208.9613  steps/s=58.47  prediction: \" @458gdb @gizmobly @crypt0x_0 100% agree\" => \"tjoer\n",
      "\n",
      "erâ€™\n",
      "l rli rl   :tst:/t// t//ttt/t\"\n",
      "batch 14047  loss=172.2519  steps/s=111.87  prediction: \"JUST POST so i dropped a draft out there\" => \"uJy      SSSTST T          p           t\"\n",
      "batch 14048  loss=139.3329  steps/s=102.19  prediction: \"category so the rule is to tell everyone\" => \"hnad e  totsoott     ee  e        e  e e\"\n",
      "batch 14049  loss=157.1110  steps/s=103.71  prediction: \" through nevada w my dad as a little kid\" => \"the ir ingnerr n    a    d   a     a a  \"\n",
      "batch 14050  loss=144.8577  steps/s=105.15  prediction: \"did it again w feedback itd be the paper\" => \" fn  dId d  d i                         \"\n",
      "batch 14051  loss=184.5769  steps/s=57.71  prediction: \" @pr0timr @btwphones Will post once done\" => \"tge  ind iia  i     a    i    b    e ee \"\n",
      "batch 14052  loss=153.7428  steps/s=107.34  prediction: \"amount of time, or did you just enjoy it\" => \"ne ia    iin   n  m o      oo       u   \"\n",
      "batch 14053  loss=171.5268  steps/s=101.12  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"   tn neennueteeruututttn tttttttt/////t\"\n",
      "batch 14054  loss=149.5493  steps/s=105.46  prediction: \"ective if that's what you're referencing\" => \" te e b ebhen e ie    tt  tt' '' ' eeree\"\n",
      "batch 14055  loss=182.1171  steps/s=98.78  prediction: \" 4am programming https://t.co/5THAY3txKR\" => \"t0nteei   ca ag  aaa  ttttttttt  tt/te//\"\n",
      "batch 14056  loss=177.5467  steps/s=102.35  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" @r4ni  fonfnofooooolloootloott////////q\"\n",
      "batch 14057  loss=144.3509  steps/s=103.40  prediction: \"he gamer would make for some great games\" => \"e  eof  fhmr  m                   e e e \"\n",
      "batch 14058  loss=163.7937  steps/s=103.73  prediction: \" God for helping us both out\n",
      "it was hell\" => \"@orl  l Gala            o   oo      t  t\"\n",
      "batch 14059  loss=161.1530  steps/s=40.95  prediction: \"ly: @IterIntellectus its white pill week\" => \"y: @loe   l  e n     o  o   ot      t  t\"\n",
      "batch 14060  loss=141.4836  steps/s=107.16  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" to e t  eoen   e     e eeeeeeeieeeieeee\"\n",
      "batch 14061  loss=133.9128  steps/s=103.28  prediction: \"ding up to that over which skill matters\" => \" n  reee ng  t t t  t         h     hh  \"\n",
      "batch 14062  loss=149.4850  steps/s=105.24  prediction: \"just have to connect/reconnect the wifi'\" => \"ust t   st  t    o    o  oonoccnccccncee\"\n",
      "batch 14063  loss=143.3188  steps/s=103.50  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \"g  ta  int  t  otto ooo t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaa\n",
      "\n",
      "a\"\n",
      "batch 14064  loss=191.1115  steps/s=82.95  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"ire    ino  t e\n",
      "o   eel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "laaaaaaaaXX\"\n",
      "batch 14065  loss=154.5102  steps/s=104.92  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e ty:moch_(BmWktBTEk?E:9EL.:9/XR:W/9.qH/\"\n",
      "batch 14067  loss=141.0077  steps/s=104.71  prediction: \" you get stuff done in a quick timeframe\" => \"toua    t at  t                         \"\n",
      "batch 14068  loss=131.7103  steps/s=103.73  prediction: \"en get way too absorbed into one of them\" => \"   o  g t n t tt      ooo oooooooooooooo\"\n",
      "batch 14069  loss=148.7159  steps/s=104.92  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"n  eeeleet ah  raaa r      rer    ee  ee\"\n",
      "batch 14070  loss=157.2216  steps/s=103.35  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"ntaaa aa n ana ammmmmmmmm  rmm          \"\n",
      "batch 14071  loss=166.9082  steps/s=69.67  prediction: \"yacineMTB Its addicting stuff be careful\" => \":c canam am   memm  a   t  r           e\"\n",
      "batch 14072  loss=146.2426  steps/s=107.39  prediction: \"o model_interface.send_to_ai(prompt)\n",
      "\n",
      "ez\" => \"rme  da nden  n ee eeeee________eeeeeooe\"\n",
      "batch 14073  loss=153.4971  steps/s=101.57  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"ao  u  sem emereetttttttttoto osss ssses\"\n",
      "batch 14074  loss=183.8152  steps/s=39.67  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: @ealmeeemtehtettttsttttooo ssss sssaa\"\n",
      "batch 14075  loss=137.3121  steps/s=111.48  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"ne ea  ee     ae  eeeeee     e e   e e  \"\n",
      "batch 14076  loss=150.7267  steps/s=102.47  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" tr s e  t t  f         ff fff  ffff    \"\n",
      "batch 14077  loss=167.7563  steps/s=105.10  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"ree x  x ff            \n",
      "   \n",
      "  ///o///111\"\n",
      "batch 14078  loss=148.8666  steps/s=105.89  prediction: \"n a bit and just work later into the day\" => \" yho     e                        t  t t\"\n",
      "batch 14079  loss=138.2102  steps/s=105.41  prediction: \" in those days will have had it too easy\" => \"an m,  snm\n",
      "n ss    s   ss               \"\n",
      "batch 14080  loss=174.8812  steps/s=102.02  prediction: \"minds me of this https://t.co/Qoy9ykJ35M\" => \"esei i inm   in i    h  s  t ttttto////t\"\n",
      "batch 14081  loss=146.0963  steps/s=102.37  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \" _ndid dididddddddttt t ttttcttcttcccccs\"\n",
      "batch 14082  loss=160.2206  steps/s=101.62  prediction: \"l do bro, never had a french beer before\" => \"yane   e bebe er         r   r e  re ere\"\n",
      "batch 14083  loss=150.4867  steps/s=104.48  prediction: \"ver\n",
      "replace youtube embed with the video\" => \"i \n",
      "aere reree re ee eee eeeeeeeeeeee e  \"\n",
      "batch 14084  loss=204.5636  steps/s=21.66  prediction: \"eply: @rcx86 Thank God\n",
      "I hope nobody did\" => \" ly: @t ee\n",
      "ereer eeeeee eeeeeeeee e  e  \"\n",
      "batch 14086  loss=160.2098  steps/s=111.07  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"teoI lo t u 4o                 e    eeee\"\n",
      "batch 14087  loss=147.2837  steps/s=104.90  prediction: \"ight any pros youd get in the short term\" => \"ne tett thyy   y y               t    t \"\n",
      "batch 14088  loss=144.5416  steps/s=104.59  prediction: \"o model_interface.send_to_ai(prompt)\n",
      "\n",
      "ez\" => \"rmea da dde   n ee eeeee_________eeeeooe\"\n",
      "batch 14089  loss=177.7601  steps/s=37.80  prediction: \"ly: @Purring_Lynx Good addition for sure\" => \"y: a  n  nn d  eeeeee_________oeotottote\"\n",
      "batch 14090  loss=152.1557  steps/s=106.78  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lote o       bb bbb bb babb            o\"\n",
      "batch 14091  loss=174.9828  steps/s=75.65  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"sw w klbib\n",
      "Abb   bbb b  b   l     oo    \"\n",
      "batch 14092  loss=145.6861  steps/s=106.93  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"s  it..it.nit    s ssss s               \"\n",
      "batch 14093  loss=148.5235  steps/s=103.94  prediction: \"rce on github to figure some of this out\" => \"eh h t@enzAj 4 tP64_wp7vI7zzk,/w0kbqjv__\"\n",
      "batch 14094  loss=155.7131  steps/s=101.85  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" o  g   not f 0%%%%%%  %      3         \"\n",
      "batch 14095  loss=149.6468  steps/s=103.29  prediction: \"ven more\n",
      "\n",
      "repeat, positive feedback loop\" => \"eryugnhtt\n",
      "\n",
      "n\n",
      "ene\n",
      "e\n",
      "\n",
      "eeeeeeeeeeeee   eeee\"\n",
      "batch 14096  loss=141.7685  steps/s=104.88  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tist gtt ot  e     t tt tttttott-ttttot\"\n",
      "batch 14097  loss=153.3543  steps/s=98.56  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" cap  w  nwww        ttttttstttt////////\"\n",
      "batch 14098  loss=149.1703  steps/s=105.28  prediction: \"der the hood the better you can innovate\" => \" rnr n   nn n ehhheh  tteeet e e      o \"\n",
      "batch 14099  loss=137.2387  steps/s=102.58  prediction: \"in but u see it everywhere after a while\" => \"ne teet t t          eeeeeeeeeeeeeeeeeee\"\n",
      "batch 14100  loss=143.6311  steps/s=104.43  prediction: \"think bc they burn through the same fuel\" => \" es to uth     t       h hh th hh hhhh  \"\n",
      "batch 14101  loss=150.5988  steps/s=104.86  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"h e  h etl   e e       aaaa :t:t//t/t///\"\n",
      "batch 14102  loss=156.1189  steps/s=101.49  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"ud a geyy l    lloooll   l   l n  d n   \"\n",
      "batch 14103  loss=147.6284  steps/s=103.46  prediction: \"ven more\n",
      "\n",
      "repeat, positive feedback loop\" => \"elyngnhtt\n",
      "\n",
      "n\n",
      "ene\n",
      "e\n",
      "\n",
      "eeeeeeeeeeeeee  eeee\"\n",
      "batch 14104  loss=162.6658  steps/s=105.08  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"neee 0     es es    @    rr rrrrr rrarrr\"\n",
      "batch 14105  loss=146.1152  steps/s=103.68  prediction: \"cuda skills, so its a fun way to do both\" => \"ons n n  e  n ss   s  s   s             \"\n",
      "batch 14106  loss=133.8464  steps/s=99.79  prediction: \"ood at noticing things, would be so kino\" => \"ul ui gt otogo ttttttgggiiii            \"\n",
      "batch 14107  loss=165.8829  steps/s=104.83  prediction: \" blindfolded and win 80% (timur garayev)\" => \"tl     l  l l delddd ddd d d   i   i   i\"\n",
      "batch 14108  loss=145.1306  steps/s=104.65  prediction: \"moves in opening\n",
      "https://t.co/hv5NypSZGV\" => \"eres s ess        e     nttttttt////////\"\n",
      "batch 14109  loss=212.0056  steps/s=20.75  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @t e s s     e     tttttt//////////\"\n",
      "batch 14110  loss=153.4949  steps/s=112.41  prediction: \" make work games\n",
      "https://t.co/WVxkHR6btx\" => \"tar  aa  ak kk    k    a    a //////oo//\"\n",
      "batch 14111  loss=141.8920  steps/s=104.31  prediction: \" resulting in a cool, weird type of game\" => \"tat e e t ftr rte ii l     ii    i      \"\n",
      "batch 14112  loss=148.0657  steps/s=101.35  prediction: \"g i can make some insanely helpful stuff\" => \" ah rae  n  n re         n    e eene    \"\n",
      "batch 14113  loss=181.6673  steps/s=101.86  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \" o.o inS SS@@ @ @@ @@@@           ''''''\"\n",
      "batch 14114  loss=148.4794  steps/s=103.61  prediction: \"ective if that's what you're referencing\" => \" te e b et in e ii    tt tttt  '   eeree\"\n",
      "batch 14115  loss=145.5543  steps/s=103.54  prediction: \"re much lower on time than your opponent\" => \"e lon h \n",
      "fUnaknn}}1â€™},â€™â€™}JJbJJSSjJJfBâ€™â€™â€™\"\n",
      "batch 14116  loss=210.8439  steps/s=58.99  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"taie      oww %o              u    ooono\"\n",
      "batch 14117  loss=141.0963  steps/s=107.35  prediction: \" good at developing your own techniquesâ€¦\" => \"testern toteg t oo  ooo oo  oo  oo o n  \"\n",
      "batch 14118  loss=144.2876  steps/s=102.64  prediction: \"f time and space that can reach in here?\" => \" tie ono         e       a   a a a      \"\n",
      "batch 14119  loss=178.5021  steps/s=97.76  prediction: \"redibly cool ðŸ˜Ž \n",
      "Do lmk when its up on gh\" => \"eplh   ch8@IbAt I_b8vðŸ˜ŽAbDATðŸ˜Žb\n",
      "DpðŸ˜ŽOODOðŸ˜ŽT\n",
      "\"\n",
      "batch 14120  loss=164.6853  steps/s=103.90  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      " e    phd\n",
      "d\n",
      "eda e e    a  sssss ss    \"\n",
      "batch 14122  loss=145.6678  steps/s=103.54  prediction: \"of time has been the problem in the past\" => \"u t fe   f te        e    eee e   e   e \"\n",
      "batch 14123  loss=160.4665  steps/s=99.77  prediction: \" who build cool stuff get followers here\" => \"thme etee ddll d dl   o o o o   olfffll \"\n",
      "batch 14124  loss=141.5808  steps/s=102.83  prediction: \"al hypotheses to search through and test\" => \"tl ao e    oe hptteteteetehh hhhhhhhhh h\"\n",
      "batch 14125  loss=147.1445  steps/s=104.66  prediction: \"al, one of the most cracked players ever\" => \"tl tooeo    e o o o    o       e     eee\"\n",
      "batch 14126  loss=158.1592  steps/s=103.95  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"aT th o        Y     ??????stsst//t////B\"\n",
      "batch 14127  loss=150.2702  steps/s=105.73  prediction: \"lding w ai is gonna get left in the dust\" => \"yi   n  nndl i i                        \"\n",
      "batch 14128  loss=165.3892  steps/s=84.76  prediction: \"wigABAP a friendly virus. one that talks\" => \"hnei lidgi  i i  n     n          t  t t\"\n",
      "batch 14129  loss=146.4276  steps/s=105.62  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n  a ia ihdd   t  i   d   AA d   i   d d\"\n",
      "batch 14131  loss=160.7350  steps/s=105.15  prediction: \"ning curve so I can make cool stuff w it\" => \"gs te ete n n  r e          c        o  \"\n",
      "batch 14132  loss=140.1349  steps/s=101.29  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"epl te swKw wá´¡s æˆ‘â€,$|$|$$$ð—²IQð˜‚*{[ðŸ‘Œ]$ð—²|ðŸ§ ï¸\"\n",
      "batch 14134  loss=167.4311  steps/s=102.86  prediction: \"effJezos Right to learn\n",
      "Right to compute\" => \" fth enefefeeefefeetttttRRRRtRttht ttoto\"\n",
      "batch 14135  loss=148.0826  steps/s=105.10  prediction: \"ill you get better at as you practice it\" => \"nl a lt  s       t  tt   t      t  t  a \"\n",
      "batch 14136  loss=146.4140  steps/s=105.33  prediction: \"m scratch in numpy like i did w backprop\" => \"ete  t   ms s rs                        \"\n",
      "batch 14137  loss=154.0382  steps/s=98.22  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"mob d a uBePe@etP+@3+zk+,T%@bML=b0=f=XMv\"\n",
      "batch 14138  loss=152.3130  steps/s=99.99  prediction: \"tony no but id be down rn for some games\" => \"  tob tb  onn b  o  n   d  d         o  \"\n",
      "batch 14139  loss=167.9274  steps/s=101.31  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \" r    noe n niet t teee e e          e  \"\n",
      "batch 14140  loss=173.1587  steps/s=99.16  prediction: \" its crack bro. be careful. i warned you\" => \"@n  esee_ ri i r  k e  b  e e  ii li l  \"\n",
      "batch 14141  loss=153.2108  steps/s=100.62  prediction: \"rd it means theyre giving you a discount\" => \"e n   ionvkhhcn v1,.$[.,bv*.*ðŸŒ‘$.kI.ðŸ“‰v^Iv\"\n",
      "batch 14142  loss=150.1418  steps/s=102.36  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"lp  @m ee p p pe  ee    e  e eeeyeeaccac\"\n",
      "batch 14143  loss=139.1517  steps/s=103.91  prediction: \"mething. like when youre waiting in line\" => \"enh nno oon   h e  nee   e e  e    ne in\"\n",
      "batch 14145  loss=144.5473  steps/s=104.17  prediction: \"ooks like from someone elses perspective\" => \"nmha  t  a    m    oooooooeeeeeeeeeeeeee\"\n",
      "batch 14146  loss=150.5594  steps/s=101.09  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"tfe  oo l  l  io  lllpllilllllllllll  ll\"\n",
      "batch 14147  loss=156.0585  steps/s=101.46  prediction: \"hdaily how does it compare to 100m leads\" => \"ea  o lllhlol   lo    o  oo  o    t    0\"\n",
      "batch 14148  loss=147.7897  steps/s=102.88  prediction: \"o feel cool writing in an alien language\" => \" wer eg rr roo  e    o       n     l nn \"\n",
      "batch 14149  loss=173.8206  steps/s=98.11  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "o a  @i ALzt/s kLA.l0Lk0,/Ik0@b,jAdxMfB\"\n",
      "batch 14150  loss=238.6571  steps/s=10.90  prediction: \"reply: @0xVonNeumann Love it! Cheers bro\" => \"eply: @iuALzt/rnkLA.l0Lk0,/!kC/b,jAdxMf/\"\n",
      "batch 14151  loss=143.1681  steps/s=109.06  prediction: \" long time. Play a game or two a day idk\" => \"tea    a  al  l      a   a a    a a     \"\n",
      "batch 14152  loss=139.8195  steps/s=103.88  prediction: \"code base to get something super complex\" => \"on nltet tett  e e   e  e      e     ee \"\n",
      "batch 14153  loss=156.1008  steps/s=102.99  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nn totiiintiitiit  ot   t  ssss ss ss  s\"\n",
      "batch 14154  loss=189.5070  steps/s=96.14  prediction: \"Dev i gotchu bro https://t.co/RX6EFjv6Nb\" => \"evin3eiii it i    o ts  rt ssts s/ /  66\"\n",
      "batch 14155  loss=136.3863  steps/s=104.23  prediction: \"to someone on X, its laggy when it plays\" => \"h     o  n n  o                         \"\n",
      "batch 14156  loss=141.4822  steps/s=99.96  prediction: \"ng sedenions for something in your game?\" => \"   o  o nu ennnosnssnsossso    i   i  i \"\n",
      "batch 14157  loss=153.2174  steps/s=104.59  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame  cc   (c t                         \"\n",
      "batch 14158  loss=152.5231  steps/s=103.99  prediction: \"sy and they put bugs in the concrete lol\" => \" ir   ba n na hn                        \"\n",
      "batch 14159  loss=143.1410  steps/s=104.99  prediction: \"e did not seem like the type to work out\" => \" co r  e a d  d     e ee  ee eete e t  t\"\n",
      "batch 14160  loss=132.8261  steps/s=105.64  prediction: \" to ignore such gaps in order to make aâ€¦\" => \"toi s a   n n  r                r  r    \"\n",
      "batch 14161  loss=139.0031  steps/s=105.33  prediction: \" she got into medschool after graduating\" => \"tta o    t  t       oo ooooo oooo o    t\"\n",
      "batch 14162  loss=151.5501  steps/s=105.00  prediction: \"l, titan, stable diffusion, a few others\" => \"y d  als ta s asa tat tati ai ii  i     \"\n",
      "batch 14163  loss=139.6373  steps/s=105.03  prediction: \" you get stuff done in a quick timeframe\" => \"toua    t  t  t                         \"\n",
      "batch 14165  loss=161.8980  steps/s=79.93  prediction: \"edydas @tanayj make one\n",
      "good opportunity\" => \"   o  t  ttt  t        e    o   o    iii\"\n",
      "batch 14166  loss=169.1446  steps/s=105.88  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edori ClMxc tá´˜t 1^ðŸ“‰*á´¡v65M*S|M$521_â€21c|]\"\n",
      "batch 14167  loss=156.8698  steps/s=97.69  prediction: \"pynch we must accelerate snake\n",
      "snake/acc\" => \"lns @a \n",
      "men   n    s  a  aaa aeeaaaeeaaa\"\n",
      "batch 14168  loss=168.6695  steps/s=105.04  prediction: \"ne project\n",
      "- added database/commands toâ€¦\" => \"gr t tt  oeet  eeeee e d dedddadaaaaaaaa\"\n",
      "batch 14169  loss=141.6577  steps/s=104.55  prediction: \"more efficient parameters in the network\" => \"eveim  etott eteeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 14170  loss=149.5676  steps/s=103.99  prediction: \" exactly that for a project a while back\" => \"txiaa axxo t   tta t  t   t t           \"\n",
      "batch 14171  loss=154.4918  steps/s=101.57  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"Ian s ngnBå§P G nPOGM*,â€¦2vÊŸ,$2v~á´jH`Êœ'ð—¯*Ê€\"\n",
      "batch 14172  loss=141.8096  steps/s=104.08  prediction: \"ncing is just how things go in business.\" => \" hw ha enin eien i i  s   i      i  n  i\"\n",
      "batch 14173  loss=166.2906  steps/s=99.02  prediction: \"e yup same did exactly this, worked well\" => \" ce:s  n nw   i e e e        t   i e t  \"\n",
      "batch 14174  loss=142.7572  steps/s=97.42  prediction: \"ko I have no idea why it was working tbh\" => \"e w nena a  n      e       a wwww w www \"\n",
      "batch 14175  loss=155.6310  steps/s=99.94  prediction: \"oodhart that too https://t.co/AKZnb9fRgL\" => \" d  w oo on r rnoohoo tttttttottttt ///K\"\n",
      "batch 14176  loss=150.9357  steps/s=98.57  prediction: \"nds like a super cool premise for a game\" => \"  woret dnn            o p  o ooo   oo  \"\n",
      "batch 14177  loss=144.1588  steps/s=103.35  prediction: \"ach other and spiral deeper into madness\" => \"nk a     a     e            eeeeeee eee \"\n",
      "batch 14178  loss=147.3722  steps/s=103.71  prediction: \"his was a super helpful technique for me\" => \"es   tt tt t                 e    eeeee \"\n",
      "batch 14179  loss=156.6537  steps/s=102.67  prediction: \"at's definitely part of the current meta\" => \"n da    tdre   te t ttett t t  t tt   tt\"\n",
      "batch 14180  loss=182.1704  steps/s=63.29  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"baaeab  teuent eeat  tttt t  t r tt e te\"\n",
      "batch 14181  loss=140.6084  steps/s=106.27  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  a   t tt t i          tttttt///tt////\"\n",
      "batch 14182  loss=138.0678  steps/s=101.17  prediction: \"sts w good content from this perspective\" => \" :t  ns s s s  soooo ooooo            t \"\n",
      "batch 14183  loss=138.3756  steps/s=104.18  prediction: \"n, tons of alpha is already in your head\" => \"   tont tt to at o  a a   aaaa          \"\n",
      "batch 14184  loss=154.3177  steps/s=105.05  prediction: \"freedom fighters. ppl who wanted freedom\" => \"oo        eee ee ee r    e  e       e ee\"\n",
      "batch 14185  loss=161.8152  steps/s=104.81  prediction: \"verfit test btw) https://t.co/qErYnoBOJi\" => \"er b  t t  (oo   tttt tttttttttttt/t////\"\n",
      "batch 14186  loss=146.1034  steps/s=104.56  prediction: \"think you can do cdn type stuff w em btw\" => \" e     ont n   n  o   o     n           \"\n",
      "batch 14188  loss=140.9017  steps/s=104.14  prediction: \"th `sudo service NetworkManager restart`\" => \" e  et an r  r r   e  eeee ee eereeererr\"\n",
      "batch 14189  loss=142.8043  steps/s=105.39  prediction: \"e right things really really does matter\" => \" mo et eeet ett   t      r ll  lllll  le\"\n",
      "batch 14191  loss=140.0559  steps/s=103.42  prediction: \"indirections/abstractions/contexts oh ok\" => \"ng h  illlsiiiiiiiiiiiiissssssssttttttoo\"\n",
      "batch 14192  loss=140.7772  steps/s=105.41  prediction: \"ty programming that in, its over, robotâ€¦\" => \"h xs   iti rtiiii itiitiiiiii     ,    ,\"\n",
      "batch 14193  loss=197.0080  steps/s=37.55  prediction: \"t: RT @angkul07: https://t.co/9PgiahOAE7\" => \"h xs   it iriimi  ttittiti t   ,  ,    o\"\n",
      "batch 14194  loss=150.3748  steps/s=113.09  prediction: \" i was wondering abt yesterday re ceasar\" => \"tt i as  s  e s   n n       e  ee  ee e \"\n",
      "batch 14195  loss=149.4761  steps/s=105.82  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"e y eo  eree   e eeeee ee eeeee eeeeeete\"\n",
      "batch 14196  loss=142.4442  steps/s=102.47  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \"h   tieeeleeeeeneeeeeeeelel ssssssssss  \"\n",
      "batch 14197  loss=167.6195  steps/s=69.68  prediction: \"yacineMTB nooo not a 2d grid of 2d grids\" => \" cscea nememmem no aana  ssss s         \"\n",
      "batch 14198  loss=159.4863  steps/s=117.57  prediction: \" @yotzol prelude in c major from scratch\" => \"tyaei tacooloo noo                 o    \"\n",
      "batch 14199  loss=143.9292  steps/s=104.66  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"emgy w@ k,n nMn Jz@T`:\n",
      "IT```:AO6b3v'AO6V\"\n",
      "batch 14200  loss=143.5478  steps/s=99.60  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"  tr    ii n      lt ttt////t////////ttt\"\n",
      "batch 14201  loss=143.3601  steps/s=102.06  prediction: \" software used that widely is so awesome\" => \"tur a n  af   a                    s    \"\n",
      "batch 14202  loss=126.5015  steps/s=103.92  prediction: \"nd of mental ownership over the codebase\" => \"g i  n     en                    ee eeee\"\n",
      "batch 14203  loss=140.4249  steps/s=101.53  prediction: \"tle robots\n",
      "\n",
      "they remove so much friction\" => \"het tnd    lot ottttttteeeeeeoe         \"\n",
      "batch 14204  loss=169.8095  steps/s=105.34  prediction: \"ich in this case, is their lack of speed\" => \"nhes et hshw    h     s  i i  ii        \"\n",
      "batch 14205  loss=196.7591  steps/s=21.01  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @t s h     s    ss  i i   i        \"\n",
      "batch 14206  loss=158.2655  steps/s=110.16  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tm ii isnniinsie,sssstttttttttt/////////\"\n",
      "batch 14208  loss=176.5219  steps/s=99.64  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"nh i  t e tr te   e t tttttt  ///ctc/ttc\"\n",
      "batch 14209  loss=176.5985  steps/s=94.93  prediction: \"sonnet 3.5v2 its amazing for programming\" => \"  n i tt   tn     t  t  t i iis  z ororg\"\n",
      "batch 14210  loss=147.6893  steps/s=103.19  prediction: \" end of chess, just like everyone feared\" => \"@at at   e    s   s  ss  s   eeeeeeeeeee\"\n",
      "batch 14211  loss=141.5378  steps/s=104.78  prediction: \" way you perceive the world and yourself\" => \"tae  t  waw           eee eeee      e   \"\n",
      "batch 14212  loss=146.6666  steps/s=101.43  prediction: \"o feel cool writing in an alien language\" => \"ufer eg tg loo  e    o       n    ll nn \"\n",
      "batch 14214  loss=157.9599  steps/s=98.68  prediction: \" stuff! Thanks, hope yours went well man\" => \"toe t o oof    ff      n            e e \"\n",
      "batch 14215  loss=144.5851  steps/s=104.67  prediction: \"nd seem more limited in possible results\" => \"  rea   es  m mem mem  e e  i iiii iisee\"\n",
      "batch 14216  loss=141.2291  steps/s=105.15  prediction: \". but idk thats just my weird take on it\" => \" thi.obt t  tt t     t                  \"\n",
      "batch 14217  loss=136.7828  steps/s=104.36  prediction: \" for hrs and hrs and the time just flies\" => \"ton     n   n                           \"\n",
      "batch 14218  loss=158.1012  steps/s=106.44  prediction: \"n confirm this is a very goated strategy\" => \"dtuo  o ea an as    s    s  i    t t  te\"\n",
      "batch 14219  loss=166.0093  steps/s=104.36  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "Ar gtnnnnennneeneepe lllll l          \"\n",
      "batch 14220  loss=170.6193  steps/s=101.65  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tn  r o     r t   \n",
      "     p  p   lll  l   \"\n",
      "batch 14221  loss=146.2123  steps/s=105.35  prediction: \"llows you to better descend the gradient\" => \"y s lw lnw llol o   o   e  ee  e  eeee e\"\n",
      "batch 14223  loss=164.5793  steps/s=97.54  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t n  ne ??n  oo    ttststsstttttt///////\"\n",
      "batch 14224  loss=162.7836  steps/s=105.06  prediction: \" blindfolded and win 80% (timur garayev)\" => \"te     l  lel delddd ddd d d   i   i   i\"\n",
      "batch 14225  loss=145.1562  steps/s=104.91  prediction: \"ain world model) to understand the world\" => \"tncrroo or ro  oorr   o  d do   ddd t td\"\n",
      "batch 14226  loss=147.2817  steps/s=104.53  prediction: \"e a great idea\n",
      "\n",
      "i should do this too tbh\" => \" rli     a    a a     e       d      d  \"\n",
      "batch 14227  loss=158.7940  steps/s=92.10  prediction: \" @yotzol prelude in c major from scratch\" => \"taue   aaa      e    ee d    o    oo o  \"\n",
      "batch 14228  loss=152.4037  steps/s=102.38  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" o   teoor  t  tt          o  o    oo oo\"\n",
      "batch 14229  loss=153.1847  steps/s=97.29  prediction: \"ake with two snakes would be interesting\" => \"li   oh th ttttt   t   o    o o    oe  e\"\n",
      "batch 14230  loss=139.6188  steps/s=101.40  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"th e n n te n ene eee eeet ttttt/////tt/\"\n",
      "batch 14231  loss=176.1327  steps/s=107.59  prediction: \"its how i learned most of my tech skills\" => \"n  oone 0t  00e       eee  e ooooo  mot \"\n",
      "batch 14232  loss=160.8045  steps/s=103.59  prediction: \" but I learned\n",
      "\n",
      "ð—ªð—µð—¶ð—°ð—µ ð—¼ð—»ð—² ð˜€ð—¼ð˜‚ð—»ð—±ð˜€ ð—¯ð—²ð˜ð˜ð—²ð—¿?\" => \"@ui   d  t    I\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "ð—µð—µð—µð—µ  ð—µð—¼ð—¼ð—»ð˜€ð—¼ð—»ð—²ð—²ð—²ð—²\"\n",
      "batch 14233  loss=143.3286  steps/s=105.49  prediction: \"se so i have no idea if this would work)\" => \"  vee n  n s  h    e    e    i  i       \"\n",
      "batch 14234  loss=136.3033  steps/s=104.30  prediction: \", usually because you border more things\" => \" and ne esesees e ee e u uuuuu  e  e e e\"\n",
      "batch 14236  loss=155.1665  steps/s=99.58  prediction: \"I understand what you're saying now yeah\" => \" m t ae amaenaaae a  a  da   a y  r  yyy\"\n",
      "batch 14237  loss=154.0705  steps/s=104.05  prediction: \"while his chess opponents mind went 3fps\" => \"iets t n gi  i s   hssssssss pss snn   n\"\n",
      "batch 14238  loss=146.4674  steps/s=103.07  prediction: \"al, one of the most cracked players ever\" => \"tk   o nn oee o o o    o       e     eee\"\n",
      "batch 14240  loss=144.3225  steps/s=103.79  prediction: \"ooks like from someone elses perspective\" => \"ulha  t  a    o    ooooooooeeeeeeeeeeeee\"\n",
      "batch 14241  loss=166.1842  steps/s=80.48  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" tgAoo  eskoko k oo ooee eeeeeeseeeeseee\"\n",
      "batch 14243  loss=153.6606  steps/s=105.95  prediction: \" tackling client projects, ThreeJS courâ€¦\" => \"@he   n  c  c g lllll lcccccc   eeeeeeee\"\n",
      "batch 14245  loss=141.0668  steps/s=104.49  prediction: \" is better than lots of ppl not starting\" => \"ts  es ss se eeseeet    t  t  ttt     t \"\n",
      "batch 14246  loss=176.5159  steps/s=79.33  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" e   i ener ree  t ttt ttp tttto///ttooo\"\n",
      "batch 14247  loss=156.0317  steps/s=105.89  prediction: \"actually protects me from getting hacked\" => \"ni  u   n  c                   t tt tt  \"\n",
      "batch 14248  loss=161.8864  steps/s=96.08  prediction: \" giz tarantinos alt?????? this shit fire\" => \"ten  yz z atti tttattt?????t???? ??t  ? \"\n",
      "batch 14249  loss=143.9778  steps/s=105.04  prediction: \"house? where is your phone charger? etc)\" => \"ereeyoyoe e ue re  e e      eo h  h rre \"\n",
      "batch 14250  loss=163.5196  steps/s=90.06  prediction: \"ntellectus To beat paranoia, accept risk\" => \"   ae tun nntee ou    o  r o rrar  ee   \"\n",
      "batch 14251  loss=141.4307  steps/s=100.96  prediction: \"ond\n",
      "but a fool with a sword is dangerous\" => \"u ea t b bett b                         \"\n",
      "batch 14252  loss=133.0831  steps/s=103.68  prediction: \"he race to steal the eu tech bros begins\" => \"e se t a  t  e   tt   t  t     e   e  e \"\n",
      "batch 14253  loss=182.2784  steps/s=54.80  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tjac eee h t te   t ttt eet    e   e esb\"\n",
      "batch 14254  loss=144.7002  steps/s=120.27  prediction: \" im pretty screwed when we play sap then\" => \"@s es  ee t   r   eeee e eweewew  we  ee\"\n",
      "batch 14255  loss=138.6943  steps/s=102.89  prediction: \"a wave of weird suspensions going around\" => \"nmet  te be  e s    e  sssssss s so  oso\"\n",
      "batch 14256  loss=209.1854  steps/s=106.49  prediction: \"/t.co/Bl5MfHSU0D https://t.co/y9VjrAaLBP\" => \"t.e   ta////:t/:ts ttttDDD//t/to////tt/t\"\n",
      "batch 14257  loss=147.4147  steps/s=104.37  prediction: \"ys a bad thing just good to keep in mind\" => \": a l s saassaa aaa a              t    \"\n",
      "batch 14258  loss=141.3495  steps/s=98.72  prediction: \" literally can\n",
      "not good for computer tho\" => \"toalyac l lel Bl l  loooooooooo ooo  ooo\"\n",
      "batch 14259  loss=144.7890  steps/s=103.79  prediction: \"ike a combinatoric sized pain in the ass\" => \"ne o noo o  n    i iiiiiii iiiiiiiii i  \"\n",
      "batch 14260  loss=142.6763  steps/s=105.79  prediction: \" component that approximates transformsâ€¦\" => \"toneo  oo ooooono tttttatpatttatttttaaaa\"\n",
      "batch 14262  loss=157.1750  steps/s=99.16  prediction: \"\n",
      "\n",
      "Huh didnt know you could change your @\" => \"\n",
      "Ir :z yaLzr Zr v#IðŸ˜â€™Ix*vH*.â€¦v#H$.á´¡\n",
      "Hz.I\"\n",
      "batch 14264  loss=181.5014  steps/s=105.12  prediction: \"ful to me, like use every day type stuff\" => \" l   \n",
      "l l l lu l e    eee e   eeeee yy y\"\n",
      "batch 14265  loss=137.2241  steps/s=103.44  prediction: \" interesting to see what it hallucinates\" => \"tt  ie   tt tttttttt t   t              \"\n",
      "batch 14266  loss=141.7879  steps/s=102.97  prediction: \"e money now bc you can get 10x more done\" => \" i   e eemene m                         \"\n",
      "batch 14267  loss=144.6299  steps/s=104.06  prediction: \"tournaments, etc\n",
      "https://t.co/JA1SHygLtH\" => \"  iny ie h  nthettettttttttttttt////////\"\n",
      "batch 14268  loss=151.0818  steps/s=95.54  prediction: \"enisnikulin its the lichess of photoshop\" => \" en nneeennnnt tttttttsttttc/csccsssooot\"\n",
      "batch 14269  loss=160.6875  steps/s=101.06  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"yabdee_ne_e analll   IIe e       e   t  \"\n",
      "batch 14270  loss=162.9689  steps/s=101.63  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" ai eibielee  c k    ak   at   t/  ///  \"\n",
      "batch 14271  loss=143.5272  steps/s=104.71  prediction: \"g his own CAD thing and calls it dingcad\" => \" oe  ew  w n  h       n   n         n   \"\n",
      "batch 14272  loss=153.4028  steps/s=103.15  prediction: \" on linkedin will be typing in lowercase\" => \"tn  nneee n nen nnniin  i i  i n  l  i  \"\n",
      "batch 14273  loss=129.2546  steps/s=103.29  prediction: \"veryone in the past was a caveman/moron\"\" => \"e   ed eneeeeeeeee            aaaaaaaaaa\"\n",
      "batch 14275  loss=162.9423  steps/s=95.92  prediction: \"77x im guessing you're super cracked huh\" => \"7 Taneii7   n  7 i     s s     e e rercc\"\n",
      "batch 14276  loss=143.1128  steps/s=102.95  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" te  nw        w        i i   e eeeeeee \"\n",
      "batch 14277  loss=142.7647  steps/s=103.65  prediction: \"video w that id, it starts at that frame\" => \"en  eni  et       i   t  t tttttt t  ttt\"\n",
      "batch 14278  loss=137.8637  steps/s=101.90  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e a at  ra a  eh  e    hthhttttt////t///\"\n",
      "batch 14280  loss=149.9254  steps/s=104.41  prediction: \"r die, and when they swim they find food\" => \"esnek @ o.cSoBtt74,N4v0I72).vSB54'A1LOTD\"\n",
      "batch 14281  loss=141.6555  steps/s=102.79  prediction: \"d size to whatever you want which helps.\" => \" 2o   t  t et      e   ee       w w h hh\"\n",
      "batch 14282  loss=148.8767  steps/s=103.38  prediction: \"ter and more efficient than studying imo\" => \" rt  i r   rtt  tte e t eeeee eeiettttin\"\n",
      "batch 14283  loss=142.5661  steps/s=98.96  prediction: \"oo much context switching to twitter idk\" => \"uo\n",
      " e et  mo   toc  tttc tt tttttitttt t\"\n",
      "batch 14284  loss=150.0459  steps/s=103.27  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \"uao  ht t   t     h        tttc////tt///\"\n",
      "batch 14285  loss=167.9190  steps/s=80.24  prediction: \"drew_pynch Sounds like a good comfy time\" => \" e   o c eccfcc h  t t    tt////ooocccct\"\n",
      "batch 14286  loss=165.3109  steps/s=105.03  prediction: \"t to follow btw\n",
      "\n",
      "https://t.co/HtQ8VvN4bY\" => \"hsr t no n t toooootttttttttt tttt/////t\"\n",
      "batch 14287  loss=171.8886  steps/s=95.91  prediction: \"builds 2012 but yet blunders mate in one\" => \"ut te b ll bl  t22tttt ttt tttt ttttttt \"\n",
      "batch 14288  loss=135.6464  steps/s=100.34  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \" an i   ean n eyteeteeeeeeeeeeeeeeeeeeee\"\n",
      "batch 14289  loss=153.8413  steps/s=105.61  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" ea  e  aneen  d       tttttttttt/tt////\"\n",
      "batch 14291  loss=154.9509  steps/s=85.82  prediction: \"resy you can already talk to one of them\" => \"epld:  ulolwiSeo01,Dx01Sj:LLS.9,5QLS4X59\"\n",
      "batch 14292  loss=203.6727  steps/s=86.81  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/.che rey///KcKRRRRZ Zttt  otttt ///tt o\"\n",
      "batch 14294  loss=168.6691  steps/s=104.58  prediction: \"en helpful!! ah nice addition, good idea\" => \" t s ee ne  lee !!!!  e h  ha  ia oodo i\"\n",
      "batch 14295  loss=152.2395  steps/s=104.85  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"torer  t t et  -o o  \n",
      "ee\n",
      "\n",
      "\n",
      "ttttt/tt/s///\"\n",
      "batch 14296  loss=166.3643  steps/s=105.03  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" ane un  tun  u   t     r    r    r     \"\n",
      "batch 14297  loss=158.1361  steps/s=104.14  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"tene n n   en n               ttttttt///\"\n",
      "batch 14298  loss=146.4365  steps/s=105.55  prediction: \"o make a significant impact on your life\" => \"ulu  la n n    n iaiiiiiiiiiiiii        \"\n",
      "batch 14299  loss=135.7500  steps/s=103.66  prediction: \"years and years\n",
      "\n",
      "https://t.co/XLk8xtcFRc\" => \" rr aan  ae r  aa aaaa  aasssssstttt/t//\"\n",
      "batch 14300  loss=156.6109  steps/s=99.54  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"u a  so ..............       o          \"\n",
      "batch 14301  loss=167.7513  steps/s=97.65  prediction: \"thy I wonder how attention relates to IQ\" => \" en fkhm  m m u  oo    oo   oe   e  e e \"\n",
      "batch 14302  loss=146.8887  steps/s=102.20  prediction: \"error signals, weakening backpropagation\" => \"r enee ee neeewerr   ennennenknkkkknaaaa\"\n",
      "batch 14303  loss=161.3868  steps/s=100.25  prediction: \"azy like that. Cheers my English brother\" => \"n3  he  n  ne t  t     e      e  h      \"\n",
      "batch 14304  loss=146.7618  steps/s=105.84  prediction: \"ces to back him up\n",
      "\n",
      "stand user type shit\" => \"o e c a coec  e                         \"\n",
      "batch 14305  loss=141.3542  steps/s=101.44  prediction: \"l possible golden gate bridge existences\" => \"yf alelp  l llllol  l        ee ee eeeee\"\n",
      "batch 14306  loss=144.6936  steps/s=104.37  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne i mi   i  meeeememoeemeeee eee eeee e\"\n",
      "batch 14307  loss=181.8766  steps/s=98.88  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tf   e ee  h  m     tth     t  t  ttt00/\"\n",
      "batch 14308  loss=139.2949  steps/s=104.70  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \" io o t notnt  nooooooooooo  oo         \"\n",
      "batch 14309  loss=189.3218  steps/s=32.60  prediction: \"ply: @ludwigABAP Oh based it keeps going\" => \"ly: @ tn oton go ooooooo  o  o          \"\n",
      "batch 14310  loss=150.4158  steps/s=107.77  prediction: \"rong tho, my confidence is only like 70%\" => \"egrtli.seIe Ovbevwjx.x.@I?v?v,kw(jfg70Cz\"\n",
      "batch 14311  loss=142.6163  steps/s=101.04  prediction: \"custom extension to watch yt on 4x speed\" => \"oseM t    t   t ttttt t tt   ttt  t     \"\n",
      "batch 14312  loss=147.8301  steps/s=100.56  prediction: \"ly know how many angels fit on a pinhead\" => \"y: t n l n n w  ww    n n               \"\n",
      "batch 14313  loss=128.6700  steps/s=94.65  prediction: \"if you say wala a lot are you a walawala\" => \"neMTy y n     n aaaa aaa   a        aaa \"\n",
      "batch 14314  loss=129.5947  steps/s=104.38  prediction: \"had an eye for it meant maybe its useful\" => \"et  t t       a                         \"\n",
      "batch 14315  loss=180.3225  steps/s=105.13  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \"pmru t  no  nofoooool ooot lotttto///qqq\"\n",
      "batch 14316  loss=168.9204  steps/s=86.87  prediction: \"ettler @gizmobly https://t.co/ZVEh9zCAgb\" => \" han tt erlowooooolotol////////////o//o/\"\n",
      "batch 14317  loss=154.7084  steps/s=103.27  prediction: \"l remember the book much better too. ime\" => \"yoe  ao b b   meebbeemeeb   ee  e  ee   \"\n",
      "batch 14318  loss=154.9206  steps/s=103.42  prediction: \"nism oooh possibly, thats a good thought\" => \" ttei  oommooossooooo    o  ttt    t    \"\n",
      "batch 14319  loss=184.6904  steps/s=85.45  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"04u y   n_n nE_0z@E+LCkkx'Cx+kLI(y,/vpE,\"\n",
      "batch 14320  loss=171.3609  steps/s=102.50  prediction: \"er CERN/physics bros you know what to do\" => \" s o @ tEoe Et sCss ssys ys  soo  oo    \"\n",
      "batch 14321  loss=139.9583  steps/s=101.11  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yr  dod d m m          uu uu uuuuu uuuuu\"\n",
      "batch 14322  loss=139.8562  steps/s=99.94  prediction: \" ive had programming in a long long time\" => \"@s  m s       n                    ggggg\"\n",
      "batch 14323  loss=150.9578  steps/s=106.40  prediction: \"/t.co/dWiO4erSb1 https://t.co/VaQuvIKJWu\" => \"/.. ps t////t/t4oottttt/t1:///tt////t//t\"\n",
      "batch 14324  loss=142.8142  steps/s=105.39  prediction: \"r coding lol. And some chess. Great move\" => \"ea  tmeeyesheAn O4_\"(/KkKK3v3Gbv(J33AA3)\"\n",
      "batch 14325  loss=179.3342  steps/s=104.57  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e itii ofjR_XAg x4/2(7,/EC,z8GI,C88Wj??x\"\n",
      "batch 14326  loss=171.4610  steps/s=29.90  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly: @ e  en t      ee    ee eee  r??   ?\"\n",
      "batch 14327  loss=143.3188  steps/s=113.31  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "et  eelvelleeee eeeeeee ee    e       \"\n",
      "batch 14328  loss=139.4910  steps/s=104.98  prediction: \"s w java and python and studying for fun\" => \" artt   tnn n    a a    n   n      n   n\"\n",
      "batch 14329  loss=148.5866  steps/s=104.37  prediction: \"memory of doing a hard thing in the past\" => \"a i  a   a  m                           \"\n",
      "batch 14330  loss=141.3351  steps/s=104.69  prediction: \" movie theater anywhere\n",
      "\n",
      "or a giant dome\" => \"toga gaa  n aaatata aaeeeeerereeeeera a \"\n",
      "batch 14331  loss=201.5330  steps/s=98.71  prediction: \"1 @yacineMTB just dmd you the term sheet\" => \" hh  @n  a  z5r z5@41z@341TB:jTB.jMTBDj:\"\n",
      "batch 14333  loss=133.0660  steps/s=105.37  prediction: \"they are more than happy to pay for them\" => \"her e et ete e ee   e     h  p   p   p  \"\n",
      "batch 14334  loss=144.4299  steps/s=103.80  prediction: \"f time and space that can reach in here?\" => \" w eronote    e  e       a  aaaa a      \"\n",
      "batch 14335  loss=142.1939  steps/s=102.39  prediction: \"hinks he might pick up in future decades\" => \"en  iei nin hhihh hh h  ii              \"\n",
      "batch 14337  loss=129.7591  steps/s=104.86  prediction: \"endeavors im going to do til ive done it\" => \"  i  t   ttet u                         \"\n",
      "batch 14338  loss=286.5041  steps/s=10.91  prediction: \"reply: @graffioh HA thats really awesome\" => \"eply: @ helrhIr ðŸ’ªAI**[]**$~á´›&&*..$&;Êœ_**\"\n",
      "batch 14339  loss=144.7432  steps/s=126.97  prediction: \"ht them the openscad to make the pulleys\" => \"ets ne b et t  te e   ee  t    e   e   e\"\n",
      "batch 14340  loss=145.5946  steps/s=103.62  prediction: \"al, one of the most cracked players ever\" => \"ni noouo  nee o o o    o       e     eee\"\n",
      "batch 14341  loss=161.2617  steps/s=99.42  prediction: \"re you need to make a sphere version now\" => \"e ly: @ TVSniYt +A=5C'//m////j/..kxz/pj/\"\n",
      "batch 14342  loss=163.6065  steps/s=96.50  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"HaVpne__lee nn na lIII I    e        n  \"\n",
      "batch 14343  loss=157.3318  steps/s=99.74  prediction: \"ve not! Will look tho sounds interesting\" => \"eru e  eeveelel  l    ll  o  o   ooo t t\"\n",
      "batch 14345  loss=129.9057  steps/s=101.01  prediction: \" a cross section now that you mention it\" => \"@ d  k    l    s                        \"\n",
      "batch 14346  loss=147.5466  steps/s=94.78  prediction: \" thanks man! i should uh sleep more yeah\" => \"@he  ao  nsas s nnn   n        u  e e  e\"\n",
      "batch 14347  loss=134.2472  steps/s=103.85  prediction: \"he audiobook content is better than both\" => \"e o t tthutououooooooooooottttttttttt tt\"\n",
      "batch 14349  loss=157.1608  steps/s=99.55  prediction: \"ny part of a much bigger long term thing\" => \"g     aaa ann n                     gg g\"\n",
      "batch 14350  loss=141.9407  steps/s=104.20  prediction: \" movie theater anywhere\n",
      "\n",
      "or a giant dome\" => \"tera gaaa naaaatat  aaeeeeerereeeeera a \"\n",
      "batch 14351  loss=155.0905  steps/s=99.13  prediction: \" your own game engine\n",
      "challenge accepted\" => \"touggAr ew;;o w  e   ne eeneeegeeneeeeee\"\n",
      "batch 14352  loss=185.3213  steps/s=100.40  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \"  e  s iri \"\"\"\"\"i\"\"\"\"\"p=p==ppppiappppatp\"\n",
      "batch 14353  loss=151.6715  steps/s=99.18  prediction: \" market black coffee is super good\n",
      "Slaps\" => \"@annen  eeme eec c  e ee  efe    eo oos \"\n",
      "batch 14354  loss=154.5561  steps/s=102.21  prediction: \"you gotta gamify reporting spam bots lol\" => \":u elg  ntan o     oo   t gg  g      t  \"\n",
      "batch 14355  loss=158.9201  steps/s=103.23  prediction: \" funny i like it https://t.co/gxpcMrRiHL\" => \"@urfs srnen   r  ee       ei ///  i  /t \"\n",
      "batch 14356  loss=139.3894  steps/s=104.55  prediction: \"t, hence why lack of sleep kills my whys\" => \"  , i,  ree r n e     e        e  ll lll\"\n",
      "batch 14357  loss=152.1929  steps/s=101.63  prediction: \"example of lack of speed killing a thing\" => \" p rooret te ee    o  f    k  e     ll  \"\n",
      "batch 14358  loss=150.8663  steps/s=71.38  prediction: \"sunsettler hes locked in to the outdoors\" => \" pes e  neleret l  o eo  e          ii  \"\n",
      "batch 14359  loss=145.3379  steps/s=106.42  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" aoa tcoess s  s   sss ss ss sssssse  sw\"\n",
      "batch 14360  loss=175.7635  steps/s=96.36  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"tt c    cene ti stttts tttp/tt/ss///aaZZ\"\n",
      "batch 14361  loss=174.4319  steps/s=45.04  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \"  @coMi   n tt  httttt/t///////aa/ZZZZZZ\"\n",
      "batch 14362  loss=155.9718  steps/s=105.99  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \" \n",
      "ti sici liiicillllll   i              \"\n",
      "batch 14363  loss=139.4864  steps/s=103.56  prediction: \"f lol. but ppl jump at the local optimas\" => \" tone u uuf   f                         \"\n",
      "batch 14364  loss=148.7652  steps/s=107.73  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"nd uous   a   aa         a  a           \"\n",
      "batch 14366  loss=138.3429  steps/s=105.03  prediction: \"your life (which is what happened to me)\" => \" ur a r lyye le        ii     whhhh   h \"\n",
      "batch 14367  loss=163.0721  steps/s=82.02  prediction: \"zmobly has selo made the circle tool yet\" => \"moblc @nrzcofMn(v_:'v000(w00'Ikj1b0%2\".x\"\n",
      "batch 14368  loss=149.3197  steps/s=107.07  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"reminn   ett  e    ttttttttttttttt//////\"\n",
      "batch 14369  loss=153.4302  steps/s=104.74  prediction: \"while his chess opponents mind went 3fps\" => \"iene t n gi  h s   hssssssss pss snn   n\"\n",
      "batch 14370  loss=150.1033  steps/s=103.95  prediction: \"r time your focus muscle will strengthen\" => \"eoe g thmn   wa Ovxxwkymz,Ov(W00kmu(y,Ov\"\n",
      "batch 14372  loss=151.3385  steps/s=99.95  prediction: \" gotchu fam\n",
      "sending the link as we speak\" => \"tere en  toi  gou   mcs    il     i    e\"\n",
      "batch 14373  loss=148.5903  steps/s=102.05  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"y   i i rit ri r      e  t t  ee  e e   \"\n",
      "batch 14374  loss=139.4100  steps/s=99.04  prediction: \"lves and destroy it all for local optima\" => \"ye  a t s reeeses s  e   s     l l l l  \"\n",
      "batch 14375  loss=142.4397  steps/s=105.05  prediction: \"sively going up\n",
      "But make responsibilityâ€¦\" => \" brl  @ervreveee gggggg g g  ee      e s\"\n",
      "batch 14376  loss=151.1117  steps/s=99.68  prediction: \"uth is the global maxima strat long term\" => \"s itenyse t   ettt          aaaaaaaaataa\"\n",
      "batch 14377  loss=151.7581  steps/s=103.58  prediction: \" pre session lift make a difference btw?\" => \"tro      ss sss ssss               eefee\"\n",
      "batch 14378  loss=147.3374  steps/s=103.91  prediction: \"h4 then 2. h5 every game against him lol\" => \"e          e4             e       e   a \"\n",
      "batch 14379  loss=149.8488  steps/s=103.21  prediction: \" except waaay too short of chunks hahaha\" => \"tvaylleae rraaaaaa aaa    a   o     hh o\"\n",
      "batch 14380  loss=148.2753  steps/s=99.99  prediction: \"an wrong something something bla bla bla\" => \"nde iialn n  non o ogoooo n oogh tn   a \"\n",
      "batch 14381  loss=148.6613  steps/s=103.15  prediction: \" talking drains your energy for building\" => \"@hml md d  nl  n  aa n nn a  rnrrnnr r r\"\n",
      "batch 14382  loss=150.0080  steps/s=99.52  prediction: \" it.\n",
      "Story sounds pretty interesting btw\" => \"@s  i e o r roe   o o t   ttytt ettttett\"\n",
      "batch 14383  loss=135.6351  steps/s=104.08  prediction: \"w the entire thing works when you use it\" => \"hi  en h n  n et                        \"\n",
      "batch 14384  loss=142.1055  steps/s=102.56  prediction: \" have another tweet promoting AB testing\" => \"tae ett to    h    eeeeetettttttt tt ttt\"\n",
      "batch 14385  loss=139.6228  steps/s=104.64  prediction: \"ng and figure out which freqs i care abt\" => \"  u o sa   e  nnn                       \"\n",
      "batch 14386  loss=142.6585  steps/s=103.68  prediction: \"now unless i need to paste in huge files\" => \"gw oo ots   ss s  s          e        ee\"\n",
      "batch 14387  loss=255.6188  steps/s=10.97  prediction: \"reply: @Brycicle77 polnareff could never\" => \"eply: @yygarc_ah7H@)(xH/y/xxIjSxz/z//w/I\"\n",
      "batch 14388  loss=156.9381  steps/s=113.34  prediction: \"igure out how to improve your work ethic\" => \"nA  ss r te     oo  oo tooo  oooo oooo  \"\n",
      "batch 14389  loss=163.3295  steps/s=103.29  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \": rnan yyyyyyyyd      dd    iiiiiiiini i\"\n",
      "batch 14390  loss=194.6169  steps/s=21.18  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @yyyyyyyyy  dd d dd    iiiiiiiiniii\"\n",
      "batch 14391  loss=141.0987  steps/s=111.00  prediction: \"th `sudo service NetworkManager restart`\" => \" e  et tner  rhr   e  eeee ee eereeererr\"\n",
      "batch 14392  loss=169.8139  steps/s=39.18  prediction: \"ly: @Purring_Lynx Good addition for sure\" => \"y: @ser ogr rr     ee eeee eererrererrrr\"\n",
      "batch 14393  loss=219.2716  steps/s=108.88  prediction: \"@0xluffyb LETS FUCKING GOOOOOOOOOOOOOOOO\" => \"sxcires rs nLLL`   eo NNNNGieO rrerarrrr\"\n",
      "batch 14394  loss=153.9923  steps/s=107.24  prediction: \"makes a comeback they get a large reward\" => \"ares w s      a   a    e               e\"\n",
      "batch 14395  loss=154.8491  steps/s=70.33  prediction: \"justalexoki the t has always meant taoki\" => \"ust s   sanseak   ee   e a  a aa   ea  a\"\n",
      "batch 14396  loss=156.1083  steps/s=106.26  prediction: \" through nevada w my dad as a little kid\" => \"@he ir  ngnerrvn    v    d   a     a a  \"\n",
      "batch 14397  loss=151.8491  steps/s=101.54  prediction: \"retty great as well, hes also on youtube\" => \"epln:n grle  }s \n",
      "--Pf-}7LvLffVZcppL,,8J9\"\n",
      "batch 14399  loss=162.8903  steps/s=99.65  prediction: \"wtf\n",
      "Your project sounds very interesting\" => \"iet  gn raarrr   tr    s o  o   o    s e\"\n",
      "batch 14400  loss=150.6848  steps/s=105.06  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  t  k  b bbbbbb bb bb b            o\"\n",
      "batch 14401  loss=140.6403  steps/s=102.03  prediction: \"t. have they found the piece yet or what\" => \"h    i t at t tt  t         eeee eee ee \"\n",
      "batch 14402  loss=217.9873  steps/s=97.04  prediction: \"ch WHOA WHOA YOU WOULDNT DOWNLOAD A LEGO\" => \"o  t o the HnHOOWWOOAOWOUOU DDDLDLDDL LL\"\n",
      "batch 14404  loss=150.5065  steps/s=102.14  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" to     dedd dd d               ????    \"\n",
      "batch 14405  loss=141.3342  steps/s=104.33  prediction: \"cond while avoiding exhausting the first\" => \"oml  tet    h  e       iiiiiiiiiiiii   i\"\n",
      "batch 14406  loss=164.2430  steps/s=103.46  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "n  ht nnnennneepeepe lll   l          \"\n",
      "batch 14407  loss=166.0076  steps/s=99.70  prediction: \"tters job was a good man\n",
      "\n",
      "God is amazing\" => \"he    eeepene s e s    aa a  a oo    a  \"\n",
      "batch 14408  loss=147.8511  steps/s=104.85  prediction: \"up computing 'why' for free all the time\" => \"s   a e   n n          ''''             \"\n",
      "batch 14409  loss=142.6637  steps/s=104.75  prediction: \"erally the divide between autist and npc\" => \"  th lt  rl rrl llllleiee ieieee eeeeeet\"\n",
      "batch 14410  loss=147.1607  steps/s=98.04  prediction: \"per solid learning loop, love it love it\" => \"lrte@o t leilielee i lll    ln        o \"\n",
      "batch 14411  loss=164.5038  steps/s=97.81  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"etteonnoynihtjn vv8v,:v=f.:kHDwu=JD3Y,J;\"\n",
      "batch 14412  loss=142.9415  steps/s=103.03  prediction: \" and realized idk what it actually means\" => \"tbt h    ff   n  d dddd      a     aaaaa\"\n",
      "batch 14413  loss=158.2852  steps/s=100.54  prediction: \"s waking back up https://t.co/0wXM4UadXf\" => \" aual   ni     k    k  p   tp tp ///ttX \"\n",
      "batch 14414  loss=152.4602  steps/s=105.38  prediction: \"r tweet was epictetus's two handles idea\" => \"etd n iriss ixnix0}k}70}b}PP'PfZd.778I/8\"\n",
      "batch 14416  loss=144.5246  steps/s=99.89  prediction: \"to play chess sometime, my li is dnbt777\" => \"h t  b   e            s s   e e       i \"\n",
      "batch 14417  loss=138.7339  steps/s=106.52  prediction: \"ugh the comments and it was pretty funny\" => \"sh th t hthhn hhtttt  tnt          tt  t\"\n",
      "batch 14419  loss=148.6221  steps/s=105.39  prediction: \" approximate it better outcompete others\" => \"tbl l ut r rt  t  tt ett  ttt  ttetttett\"\n",
      "batch 14420  loss=145.3883  steps/s=102.99  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"s  to  ttttt t         ppppppppp   p    \"\n",
      "batch 14421  loss=147.0552  steps/s=101.70  prediction: \"gpt-5 powered robot of him into the wild\" => \" te  a a  e   epe       o     o  o   o  \"\n",
      "batch 14422  loss=147.0596  steps/s=100.04  prediction: \"lity is really really powerful, actually\" => \"yt i A ii i i i  illll lll l rlll   elll\"\n",
      "batch 14423  loss=144.2953  steps/s=99.23  prediction: \"e others (including your past self) with\" => \" ta i o ttt e te e   n   n      u       \"\n",
      "batch 14425  loss=149.4069  steps/s=106.27  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \"hah   iaat t t    t  t  ttt tt  ///xt///\"\n",
      "batch 14426  loss=177.9619  steps/s=100.98  prediction: \"ein @DrBrianKeating yea he made a portal\" => \" ninen iinn iinininnieinnneeeea eaana   \"\n",
      "batch 14427  loss=158.8722  steps/s=104.29  prediction: \"e in milan venice florence.. sorrento rn\" => \" tn nonnn\n",
      "lil n inni nnnnnne  e  eeee.e \"\n",
      "batch 14428  loss=139.1979  steps/s=39.69  prediction: \"t: dingboard is the lichess of photoshop\" => \"  rtlei nliin  iin    nnenee  e  eeeeeen\"\n",
      "batch 14429  loss=160.9702  steps/s=108.83  prediction: \"ke half my followers came from shoutouts\" => \"e 0 0 o e b blyll llll       o fooooomoo\"\n",
      "batch 14430  loss=157.0117  steps/s=100.21  prediction: \" joining man, looking forward to thurs!!\" => \"@uee nwnneno n n ononoonnnnnooooo  o   o\"\n",
      "batch 14431  loss=139.2599  steps/s=105.79  prediction: \"ether they are good or bad on their face\" => \" t  e e t tteeteeeee                    \"\n",
      "batch 14432  loss=238.5026  steps/s=10.83  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"eply: @ Ani ,Ai $[$$$QðŸ¤¯QðŸ°]Ê€QðŸ˜†$$á´›&7&$~ðŸ¤£~$\"\n",
      "batch 14433  loss=150.1169  steps/s=129.27  prediction: \"thats a good one, comparing with experts\" => \"hey  ott tt t gt  o oooooooo   o    n e \"\n",
      "batch 14435  loss=261.5809  steps/s=10.90  prediction: \"reply: @AaronPeddle Very very good point\" => \"eply: @DmfiniAre@,0D%://GS3#/j0MN7UJvJ2`\"\n",
      "batch 14438  loss=145.5856  steps/s=110.98  prediction: \"rally will not trample on your free will\" => \"evuy neim#?ZbAm *]Éª$$á´˜ðŸ˜Ž$\"$ðŸ‘ðŸ°^$?]ð˜/$D,]]/\"\n",
      "batch 14439  loss=228.1880  steps/s=21.61  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly:  t    l llllll llllll   l          \"\n",
      "batch 14440  loss=149.0948  steps/s=111.36  prediction: \"esting example of goodharting the reward\" => \"  iotetteneeettneee eeeee eo oo  g g   r\"\n",
      "batch 14441  loss=164.1697  steps/s=68.96  prediction: \"yacineMTB nooo not a 2d grid of 2d grids\" => \":p/eanetetenn t oo  e o  a g gg  o o  dr\"\n",
      "batch 14442  loss=150.4262  steps/s=106.23  prediction: \" improve a processing unit's ability toâ€¦\" => \"tn caca nrr    r r r  s      ssss i iiii\"\n",
      "batch 14443  loss=144.9545  steps/s=104.60  prediction: \"d it tho, was a change of weather for me\" => \" th e eeejete tte              aa      e\"\n",
      "batch 14444  loss=171.8080  steps/s=72.70  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"nty    htdeww a h  a\n",
      "\n",
      "h      hee      ae\"\n",
      "batch 14445  loss=161.0081  steps/s=107.36  prediction: \"at's definitely part of the current meta\" => \"n aaa   tdrert te t ttett t    t tt   tt\"\n",
      "batch 14446  loss=161.9324  steps/s=103.28  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"trac  \n",
      "s:///ss/ottCCCttCCCC:/ttt:///..//\"\n",
      "batch 14447  loss=144.0311  steps/s=102.50  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"s  t  t th tithrrtttttaaaaaaahhaahahhhhh\"\n",
      "batch 14448  loss=179.7570  steps/s=96.36  prediction: \"an that sounds like such a relaxing time\" => \"n  trz attttaty haa a ht s uu h    hha  \"\n",
      "batch 14449  loss=144.1983  steps/s=104.40  prediction: \"e usually surrounded with those coloredâ€¦\" => \" care eeeaer  urruuuluuuuuuu ud     o  o\"\n",
      "batch 14450  loss=202.7979  steps/s=26.44  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly:  reern  uurruuueuuuuu u ud     o  o\"\n",
      "batch 14451  loss=144.7182  steps/s=108.65  prediction: \"u a why/a vision for hard work over time\" => \" go   o  w  e h  i     o     o      o   \"\n",
      "batch 14452  loss=162.0376  steps/s=100.77  prediction: \"encoded url that leads to discord invite\" => \"  si  eeceeceecee  e  ee d     dd   dd  \"\n",
      "batch 14454  loss=142.2795  steps/s=104.70  prediction: \"ody wake up??\n",
      "Youve killed us all skooks\" => \"neno nennno    n o  ?????e      uu     k\"\n",
      "batch 14455  loss=141.1950  steps/s=101.28  prediction: \"etter but pretty good time bender though\" => \"  oeo  teb  tt etttt  ttttttt    ee  e e\"\n",
      "batch 14456  loss=151.1083  steps/s=102.53  prediction: \"s the error correction mechanism go away\" => \" g   rnr\n",
      "rl e  oeer rrrerrrerreo co oocm\"\n",
      "batch 14457  loss=150.4878  steps/s=94.76  prediction: \" come to your house, and move mario back\" => \"trreeree  t e eo  e  o o   o  oo  o    o\"\n",
      "batch 14458  loss=177.0335  steps/s=103.33  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"ng\n",
      "eerco c,z? yo   OO   OO o mee m  a ba\"\n",
      "batch 14459  loss=146.2629  steps/s=106.61  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"hnle  e an c a c aa      uo    u ou o   \"\n",
      "batch 14460  loss=143.4916  steps/s=103.88  prediction: \", increases both HP and MP significantly\" => \" wo  e  e  reeeeeee ee       PPPPP  i  i\"\n",
      "batch 14461  loss=140.3493  steps/s=103.35  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"e,lat  ss\n",
      "s sðŸ‘s É´[HP$ðŸŒ‘æˆ‘ð—»â€Mð—»Ê€$Êœ_{É´[{ðŸ˜†~]$~\"\n",
      "batch 14462  loss=145.5331  steps/s=105.74  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"t  n  d  nd ddd   aa   aa  a   a     nn \"\n",
      "batch 14463  loss=146.8737  steps/s=104.55  prediction: \"ich is a suuuuper good thing to practice\" => \"n   o ies ssssh uuuu    uuuu    o     o \"\n",
      "batch 14464  loss=174.9612  steps/s=99.43  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" cet   t eedttoettt  hh hhh             \"\n",
      "batch 14465  loss=150.0686  steps/s=105.40  prediction: \"mes often times.\n",
      "anyone can pivot though\" => \"e  % e e s see ese eeeseennnnenn nnnnn  \"\n",
      "batch 14466  loss=145.8613  steps/s=104.79  prediction: \"mething to run from (getting called out)\" => \"etes meeetsetet e    o        g g  g t t\"\n",
      "batch 14467  loss=144.3533  steps/s=105.31  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \"hi     n e  c nn  e     e      e       a\"\n",
      "batch 14468  loss=151.4255  steps/s=99.53  prediction: \"ould get my ass handed to me for suuuure\" => \"    i  iIeeww  g aa   aaaa           e u\"\n",
      "batch 14469  loss=146.4512  steps/s=104.27  prediction: \"about things that have significant value\" => \"loe \n",
      "tktn   ttett aa tt tth  hat  aiaa a\"\n",
      "batch 14470  loss=153.9930  steps/s=104.42  prediction: \"er cool shit bro gl w your phd\n",
      "\n",
      "followed\" => \" s ok aoaas t  tt  h          i    a  ll\"\n",
      "batch 14471  loss=167.7290  steps/s=104.28  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edo t @iMfc t0t 1*ï¸9__65M$Sð—¯M$Êœ21_$M1c$C\"\n",
      "batch 14472  loss=144.0635  steps/s=104.13  prediction: \"ouraging way, not stressful for the kid)\" => \"u   /cgngiggeggggnnnnnn                 \"\n",
      "batch 14473  loss=146.8171  steps/s=103.73  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"lbee ei  yele u  ee e     o      a   a l\"\n",
      "batch 14474  loss=142.1583  steps/s=97.53  prediction: \"ist either way, its all about production\" => \"n  allatieiett t    a     aa   ala ll  o\"\n",
      "batch 14475  loss=154.7660  steps/s=44.71  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \"  @ahlate etettii   a    aaa    l  a o  \"\n",
      "batch 14476  loss=142.6708  steps/s=106.83  prediction: \"re for blundering bc of moving too quick\" => \"eplhi @ ,gsn Mn 'TD'''T''.GBGkUBIBqUBFBq\"\n",
      "batch 14477  loss=148.0883  steps/s=100.39  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \"  eo   o  fffo f  o    oo o  o    oo  oo\"\n",
      "batch 14478  loss=186.0069  steps/s=99.89  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"n_ r oy re nn      ee u  e t to////o/ooo\"\n",
      "batch 14479  loss=141.2723  steps/s=104.00  prediction: \"he gamer would make for some great games\" => \"e  a    nhrr  m              m    e e e \"\n",
      "batch 14480  loss=139.8541  steps/s=103.34  prediction: \"mages looked smoother so it did that lol\" => \"ekh    tte et es  ooeoooooooooo         \"\n",
      "batch 14481  loss=136.1503  steps/s=105.29  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf ni   th n   n  i   g      g          \"\n",
      "batch 14482  loss=144.2793  steps/s=105.27  prediction: \"ession youll do something until its done\" => \"  le  pepp epeul  ooooooooooo      i    \"\n",
      "batch 14483  loss=145.6694  steps/s=104.93  prediction: \", because integrity is incredibly useful\" => \" an acfo a  o       e e i  eeii ii ii ii\"\n",
      "batch 14484  loss=156.2667  steps/s=99.28  prediction: \"ased. Me neither. This is the way to go.\" => \"n    ereBdn ee e eeee i i iii  i    s   \"\n",
      "batch 14485  loss=134.7738  steps/s=99.62  prediction: \"ideo editor I posted earlier\n",
      "took 20mins\" => \"n  e t ee e e ed    e     e  ee eoeeoooo\"\n",
      "batch 14487  loss=150.9524  steps/s=105.37  prediction: \"xample losslessâ€¦ https://t.co/1abTqawnLU\" => \"tmatottot  o   F seesssssssssssts/t/////\"\n",
      "batch 14488  loss=144.1589  steps/s=103.89  prediction: \", how do WE figure out where things are?\" => \" ao  ii no n                   e   e    \"\n",
      "batch 14489  loss=146.6782  steps/s=104.26  prediction: \" even the ones i disagreed with the most\" => \"tv e te ntn  etn          e ee          \"\n",
      "batch 14492  loss=173.4505  steps/s=102.45  prediction: \"ng jai??? Instantly 10x more interesting\" => \"g  ne  igi ? ?n??????n               t  \"\n",
      "batch 14494  loss=138.1415  steps/s=104.73  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \" soq st       ms            t        e  \"\n",
      "batch 14495  loss=146.8789  steps/s=99.31  prediction: \"TB strategy is an abstraction of tactics\" => \"h s i   seett tts   t       at tnt  ttt \"\n",
      "batch 14496  loss=148.6402  steps/s=104.69  prediction: \"ew_pynch join often, good guys to follow\" => \"  i a ean@nndnn n   nnnnnooooon  o   o o\"\n",
      "batch 14497  loss=175.7983  steps/s=74.15  prediction: \"yMazza my favorite systems administrator\" => \":i naMwa w n n nfno o    oo ooo  oo  o o\"\n",
      "batch 14498  loss=139.8645  steps/s=106.09  prediction: \"ing this with terms masters commonly use\" => \"ng li n ni    ht            s  ssmmsmmmm\"\n",
      "batch 14499  loss=129.4674  steps/s=103.41  prediction: \"to use resumes if lying becomes the meta\" => \"  i imi   sessssessss     e  e     ee ee\"\n",
      "batch 14500  loss=158.2305  steps/s=80.20  prediction: \"arcyan now you can make pokemon real too\" => \"ne o e eseses se  u        meee eeee  ee\"\n",
      "batch 14501  loss=189.3423  steps/s=26.75  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @ie esse us  u        meee eeee    \"\n",
      "batch 14502  loss=183.4042  steps/s=137.89  prediction: \"@IterIntellectus https://t.co/7QXmzFoC4o\" => \"atirierrnoes  s    u  m   omee ooeem   ðŸ›‘\"\n",
      "batch 14503  loss=152.3216  steps/s=106.01  prediction: \"l remember the book much better too. ime\" => \"ysi mco o\n",
      "be  beebbeebeeeeb ee     ee   \"\n",
      "batch 14504  loss=132.4065  steps/s=103.95  prediction: \"sire, and if it sounds good to them\n",
      "\n",
      "idk\" => \" ce  et et  t hi  i           d  o     o\"\n",
      "batch 14505  loss=137.6711  steps/s=104.51  prediction: \"ful for learning https://t.co/B7rPa9oFnr\" => \" n l    u l l l lrrrrer   p    /// ///rt\"\n",
      "batch 14506  loss=175.2213  steps/s=64.55  prediction: \"@HSVSphere im appropriating your culture\" => \"aaoiior llrlr n    ppprpptttt ////r/rort\"\n",
      "batch 14507  loss=163.2591  steps/s=121.13  prediction: \"ere @jesx64 never stop having fun either\" => \"  euS@VSVe 4e e e errpr ntt t no uut unn\"\n",
      "batch 14508  loss=173.6966  steps/s=103.52  prediction: \"/t.co/cU8TdGmOOe https://t.co/wR9o8NrNIm\" => \"/.ucs:o  ////TT/TOOOOttOOO//t/ttt////t//\"\n",
      "batch 14509  loss=151.0611  steps/s=105.81  prediction: \"ugh or is it just whatever comes to mind\" => \"sh  o o  rr o  o  r     t tt   t t  t   \"\n",
      "batch 14510  loss=152.0505  steps/s=101.84  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"ng eor rnri   aa      a  aaooeooaoott dd\"\n",
      "batch 14511  loss=179.9686  steps/s=75.79  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" iierr wwain  a  c  ooa  otao ootoitoedd\"\n",
      "batch 14513  loss=145.5825  steps/s=106.62  prediction: \"es success, but there is a causal factor\" => \"  \n",
      "ut   e es  utsssseessse es    a  a a \"\n",
      "batch 14514  loss=172.6543  steps/s=98.94  prediction: \"e77 @0xdiicell turkish coffee is amazing\" => \" 7 ut cecsece7c  eee i e   cu ss  a afe \"\n",
      "batch 14515  loss=138.4279  steps/s=104.73  prediction: \"and i think that helped me a ton in life\" => \"nd o tr nn n  n    t t   h              \"\n",
      "batch 14516  loss=138.0198  steps/s=104.21  prediction: \"gh, regardless it needs a lot of work xD\" => \" t oe  re hrerhre  eeeeee  e s e      o \"\n",
      "batch 14517  loss=145.9314  steps/s=102.88  prediction: \"d posted some CRAZY progress\n",
      "LETS GET IT\" => \" ioi    ddt sdd d          o  sssssssssE\"\n",
      "batch 14518  loss=156.8695  steps/s=106.66  prediction: \"TB you can just do things bro just do it\" => \"h s sso  d o   s        o so ssss s     \"\n",
      "batch 14519  loss=151.1076  steps/s=103.82  prediction: \"n getting rid of the phone really is key\" => \"gae  a e ten tti t   t          e   e   \"\n",
      "batch 14520  loss=150.5685  steps/s=104.21  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"tu   vt mw mJ a  a       t  tt  ttt/////\"\n",
      "batch 14522  loss=153.3916  steps/s=99.83  prediction: \"tbh, about 1/3rd of the way through them\" => \" en  ettt tbt e t    t     t      t   th\"\n",
      "batch 14523  loss=144.6945  steps/s=100.00  prediction: \"just happen to have sicilian parents lol\" => \"ust eeele  t  t  e    e        a  aaaa a\"\n",
      "batch 14524  loss=150.4782  steps/s=104.65  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" an fofn)) on a      e  ee  e  t t   ts \"\n",
      "batch 14525  loss=159.3049  steps/s=102.90  prediction: \" wonder what else you could fast-preview\" => \"taea  a  en d e  ee   e    e         e  \"\n",
      "batch 14526  loss=141.2578  steps/s=100.11  prediction: \"s and sugar and i dont get tired anymore\" => \" an  uu    sa  aa a  a         d     t  \"\n",
      "batch 14527  loss=147.5334  steps/s=98.64  prediction: \"ng that solves a problem you're close to\" => \"  ay t ist it tt             e   eooe e \"\n",
      "batch 14528  loss=139.4398  steps/s=105.16  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h      o org  ogooo ooo oo o   o o    o \"\n",
      "batch 14529  loss=155.3817  steps/s=99.38  prediction: \"el editor and gameplay, that sounds cool\" => \" eao  ee l     l      a aaaa aaaa aaa   \"\n",
      "batch 14530  loss=147.0970  steps/s=105.22  prediction: \"ective if that's what you're referencing\" => \" te e b eb en e ii    tt tttt  '   ee ee\"\n",
      "batch 14531  loss=137.8051  steps/s=104.75  prediction: \"ffect has it had on you? im very curious\" => \" \n",
      " ie    ff f f                         \"\n",
      "batch 14532  loss=147.2647  steps/s=102.10  prediction: \"right words can change entire industries\" => \"eton  e_eee eÊœllðŸ˜Ž@$*ð—¿m@|á´›$jGj$ð—¶jG*$ð˜‚j]ð—¯èµ°\"\n",
      "batch 14534  loss=137.8223  steps/s=102.48  prediction: \"en hook it up to a domain and everything\" => \" tr  c eco n eo    o  o o          a a  \"\n",
      "batch 14535  loss=204.1280  steps/s=70.34  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"tNojoo eot _% o    o  o o      a   e nn \"\n",
      "batch 14537  loss=150.6912  steps/s=114.96  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tnd hnp n  nn            t ttttttt//////\"\n",
      "batch 14538  loss=143.2277  steps/s=103.91  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"  ncnte ctneeeneeeeeeeeeee::::::t//t////\"\n",
      "batch 14539  loss=150.3913  steps/s=98.83  prediction: \" im pretty screwed when we play sap then\" => \"ts ts  ee tee s  seeee e eweewewewwe eee\"\n",
      "batch 14540  loss=139.1128  steps/s=100.52  prediction: \"the replies here\n",
      "https://t.co/9TNeUoLw5k\" => \" enn i     ie e eeeeeeeteeehtttttt//////\"\n",
      "batch 14542  loss=152.0498  steps/s=105.81  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"e i   e  ll le leeeeeee    e            \"\n",
      "batch 14543  loss=180.8966  steps/s=101.84  prediction: \".03$ a day you can help a webdev in need\" => \" . strr       0          a    a a      e\"\n",
      "batch 14544  loss=158.6170  steps/s=100.59  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \"th  t  e ccl   e ......   .......ct////t\"\n",
      "batch 14545  loss=171.5440  steps/s=102.27  prediction: \"king stuff part of twitter is so fun wtf\" => \"ena ce s  n0s   f t sf tf ft ottt tfwsws\"\n",
      "batch 14546  loss=146.2575  steps/s=102.43  prediction: \" linux like it hallucinated csgo or doom\" => \"@el aaill lllli i lllllilll illi      c \"\n",
      "batch 14548  loss=157.4047  steps/s=104.73  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u  ent no ttte                     0   \"\n",
      "batch 14549  loss=147.9238  steps/s=104.07  prediction: \"t 200hrs in around the same time you did\" => \" woo    tt  t un                        \"\n",
      "batch 14550  loss=155.2767  steps/s=103.51  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n  t   i\n",
      "i m    i    ga     tthhttttt//O\"\n",
      "batch 14551  loss=135.7873  steps/s=104.62  prediction: \" adding the context into the computation\" => \"and e   oe r   ee ooe e  t nt e te ttttt\"\n",
      "batch 14552  loss=147.9345  steps/s=102.81  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"nfy lei  aele u  ee e     o      a   a l\"\n",
      "batch 14553  loss=149.7261  steps/s=104.04  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" t peeperterenemmmenn e ee n n t  ttntt \"\n",
      "batch 14554  loss=165.8801  steps/s=104.21  prediction: \"n and are kindaâ€¦ https://t.co/zyjcsUAF4i\" => \" m   a   ain nnn a   a         tt/t/////\"\n",
      "batch 14555  loss=144.6331  steps/s=104.55  prediction: \" (by trusting in ideas) and testing them\" => \"ayetee   htt tnt     i                  \"\n",
      "batch 14557  loss=165.7614  steps/s=100.35  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"i b a a  ck e2 k0z@AmxzxLvvPIUf.-\"~zQk?u\"\n",
      "batch 14558  loss=152.4640  steps/s=101.07  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" ringtl iii  cc c ccccccscccctccc///////\"\n",
      "batch 14559  loss=148.2077  steps/s=103.94  prediction: \"s. im betting on that. but i am not sure\" => \"  y\n",
      "y at htt  tn t    t ttt tt          \"\n",
      "batch 14560  loss=153.2299  steps/s=80.88  prediction: \"atedro buildin something ppl want lesgoo\" => \"n   yma ttt t b   ttt   ttt          t  \"\n",
      "batch 14562  loss=163.4196  steps/s=102.19  prediction: \"xplain this then https://t.co/WO0ul2kmNe\" => \"pe zepbe  ll i n  th thhth ttttthtt/tt//\"\n",
      "batch 14563  loss=156.0961  steps/s=103.81  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"@m iihisnniinshesssssttttttttttt////t///\"\n",
      "batch 14564  loss=170.4166  steps/s=75.94  prediction: \"xqc unironically how much I was drinking\" => \"pm iitnin ninieeitttttt/tttt//cIIIIt6666\"\n",
      "batch 14565  loss=175.3531  steps/s=106.35  prediction: \"h i dont remember getting much out of it\" => \"es  a d d    ee  ee eeme eememt  et     \"\n",
      "batch 14566  loss=155.7870  steps/s=104.46  prediction: \"nce\n",
      "\n",
      "5 depends on not missing ANY of 1-4\" => \" elo a al t   \n",
      "n    nnnn nnnnnnnn       \"\n",
      "batch 14567  loss=148.0334  steps/s=101.68  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"aat u l  wt s                sss        \"\n",
      "batch 14568  loss=150.9862  steps/s=104.29  prediction: \"d virus that makes ppl cracked at scale?\" => \" w   e i e  n n              a   a   aa \"\n",
      "batch 14569  loss=154.2042  steps/s=103.24  prediction: \"orn to make cash forced to consooolidate\" => \"r tt ttttttt               c   o ooooooo\"\n",
      "batch 14570  loss=167.8114  steps/s=103.24  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edo i @iMnh t0t 1[á´jX#65MXSð—µMv521_*M1&V/\"\n",
      "batch 14572  loss=256.7278  steps/s=12.03  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @5Mlc t0t 17Dj##65M*Sð—ªMv521_ÊŸM1&V/\"\n",
      "batch 14573  loss=147.8504  steps/s=124.15  prediction: \" billion zimbabwe dollars of labor hours\" => \"@u e bvbbab  bi bbbbllllll l  lllo llooo\"\n",
      "batch 14574  loss=143.1749  steps/s=103.51  prediction: \"t immensely and give you new information\" => \" ing  e teenn  n    e     e   e   n    n\"\n",
      "batch 14575  loss=147.6003  steps/s=100.98  prediction: \" of your day your brain will work better\" => \"tnp r f t  et rr   yy  rr y r       r   \"\n",
      "batch 14576  loss=173.2954  steps/s=104.09  prediction: \" at 5:10 or something I just go til 9:10\" => \"@nd t  tnn t   t                t  t   t\"\n",
      "batch 14577  loss=170.5933  steps/s=44.35  prediction: \"y: @tabtab0x_0 @Brycicle77 never mouse ðŸ«¡\" => \": @:tn  ta  0 00                t  t   t\"\n",
      "batch 14578  loss=145.8102  steps/s=116.54  prediction: \"nt true they wouldnt put it in the title\" => \"g t   it i ttttt tt  t t t  t tt ttt ttt\"\n",
      "batch 14579  loss=135.1702  steps/s=105.37  prediction: \"oncept but also show you how to apply it\" => \"n c  ee  ecc cn  c    o    oo ooo ooo o \"\n",
      "batch 14580  loss=291.3586  steps/s=11.14  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"esly: @r\n",
      "rertL uYjZZZZZZZZZZZZZJJJDDDD~~\"\n",
      "batch 14581  loss=170.9798  steps/s=110.10  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"ttittlG ///ss///th thtZZZt  Z  t a..x  x\"\n",
      "batch 14582  loss=170.5521  steps/s=95.26  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nAs o  AhgggAgo gggyhhht otott//////p //\"\n",
      "batch 14583  loss=188.3922  steps/s=57.78  prediction: \" @0xluffyb Deserved\n",
      "You build cool stuff\" => \"tlhlgp  iiygggyy yyyotot/ttt///////oqqsX\"\n",
      "batch 14584  loss=163.8019  steps/s=117.59  prediction: \"ger and crazier, more ambitious programs\" => \"  s  1 g  ggg    rrr r   rr ari   oorrro\"\n",
      "batch 14585  loss=170.8089  steps/s=53.03  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @0ucuetee 7tBtt7/B.YxcT(zxLy,T5ð—¯T*1z5T)\"\n",
      "batch 14586  loss=146.2726  steps/s=106.97  prediction: \"ng them as irrational, then assigning 0â€¦\" => \"   th itg gg ig  ii iiiiiaaaa aiaaaninin\"\n",
      "batch 14587  loss=144.4470  steps/s=103.34  prediction: \" company dgaf and you can contact those?\" => \"torea a n en ana a    a   n a a n c c cc\"\n",
      "batch 14588  loss=154.3945  steps/s=104.60  prediction: \"t habit of reaching for my phone is gone\" => \" to    at t tthh     h  h               \"\n",
      "batch 14589  loss=144.8753  steps/s=104.19  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" meo ee mde meem eue tttte t t  ttmttttt\"\n",
      "batch 14590  loss=145.3970  steps/s=106.55  prediction: \"ew pieces\n",
      "repeat\n",
      "https://t.co/C9USHdvyzA\" => \"  lns e e e eeseeeeeeeeepetetttt/t//////\"\n",
      "batch 14591  loss=154.9155  steps/s=101.78  prediction: \"durr. the kings gambit. crazy mf opening\" => \" f iere rr rr  rr  r                 z  \"\n",
      "batch 14592  loss=155.8157  steps/s=99.66  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \" yhdr n hh d dnd d iidd d d n     i     \"\n",
      "batch 14593  loss=193.8782  steps/s=22.88  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly:  nddh dndd dd iidd   d n     i     \"\n",
      "batch 14595  loss=144.7361  steps/s=111.84  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"tld  iht  tth  t htttttsstttttttt///////\"\n",
      "batch 14596  loss=139.5364  steps/s=104.30  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"epl e erodl n@t x_kD(7%B8%k8b)QC3SJ8VbG)\"\n",
      "batch 14597  loss=157.8452  steps/s=102.24  prediction: \"nrot swe competition\n",
      "Gm level strategery\" => \"do M  erton    totot tttotttit eeetee ee\"\n",
      "batch 14598  loss=135.9004  steps/s=103.34  prediction: \"lots of stuff you learn way way way more\" => \"yw  os   o     sff ff               yy y\"\n",
      "batch 14600  loss=139.6317  steps/s=104.15  prediction: \"se? seems like death spiral potential no\" => \"  eo e eeseseeeeeeeeee    e    s     a  \"\n",
      "batch 14601  loss=147.7304  steps/s=104.19  prediction: \" of how i debug and catch inefficiencies\" => \"tf e  ormpo  a           a   a i   icfic\"\n",
      "batch 14603  loss=137.8705  steps/s=105.36  prediction: \"tic paper searches\n",
      "at this rate it willâ€¦\" => \" ns s  p p pnpe areaeaaa aasaea aaatt tt\"\n",
      "batch 14604  loss=141.7596  steps/s=101.59  prediction: \"m like the future too\n",
      "is this mujoco btw\" => \"ana s pee   tete e e   t   tt t  t   t  \"\n",
      "batch 14605  loss=145.9379  steps/s=103.76  prediction: \"een enough to find mentorable candidates\" => \" d e  t ee e  en           n    nn nnnen\"\n",
      "batch 14606  loss=170.5068  steps/s=105.04  prediction: \"our gpt api key\n",
      "\n",
      "https://t.co/qBtIejDpHA\" => \"nsd i   dadd      p   p ppptpttt///tt///\"\n",
      "batch 14607  loss=137.2620  steps/s=105.36  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sinn isnnneeiginniiinntnteitttccttttKKK\"\n",
      "batch 14608  loss=142.8201  steps/s=105.66  prediction: \"10mins on a puzzle just try ur best gues\" => \"  fpyes0 cd. Qd 4Qjqq10&kjQ&f&&Q44&:QQkQ\"\n",
      "batch 14609  loss=146.8885  steps/s=103.83  prediction: \"an get immense alpha if you keep zooming\" => \"nd ooe   e   mmm e                      \"\n",
      "batch 14610  loss=147.1579  steps/s=104.12  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t s  r rsr r  Ir     r   o   o  o    t  \"\n",
      "batch 14611  loss=147.3133  steps/s=105.53  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"y    e   edde     e  t   ttttt t//t//tt/\"\n",
      "batch 14612  loss=147.6046  steps/s=104.76  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \" aa tat   tte   t    t ee    e    e  o  \"\n",
      "batch 14614  loss=144.5022  steps/s=103.43  prediction: \"i can keep it up https://t.co/aDUupaUfqR\" => \"ns  s  srrsn       e   p    p  pptpp///p\"\n",
      "batch 14615  loss=175.4634  steps/s=85.05  prediction: \"mobly @amix011 May do this in the future\" => \"ont e ni n n  @    t   t  t /  //ttUUUtt\"\n",
      "batch 14616  loss=172.2547  steps/s=104.39  prediction: \"wigABAP why a few years\n",
      "\n",
      "do it this week\" => \"itA @e   e lw A    w   y     a   ee   tt\"\n",
      "batch 14617  loss=145.7064  steps/s=102.67  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"  p id dididddddddttt t tttttttcttccccct\"\n",
      "batch 14618  loss=140.2063  steps/s=103.94  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"eraoea   venv r       o  o  oo  o       \"\n",
      "batch 14619  loss=144.7286  steps/s=104.32  prediction: \"all a month ago\n",
      "Dang good stuff bro!!!!!\" => \"nlyol      tt  a  a aa aa oo oo oo oooo!\"\n",
      "batch 14620  loss=168.1046  steps/s=104.70  prediction: \"ger, LETS GET IT\n",
      "https://t.co/ZIDQZp9Vp6\" => \" t ia  aaf nE  ETTTTTTTT       t////ZZZZ\"\n",
      "batch 14621  loss=155.1167  steps/s=102.48  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"ther nr    r r  ro r  tt   tt s tt 7/7/t\"\n",
      "batch 14622  loss=140.3696  steps/s=103.73  prediction: \" eu would lose half its talent overnight\" => \"tvee  m ele   l  l  l  l    l    l   t  \"\n",
      "batch 14623  loss=159.7630  steps/s=97.59  prediction: \"ts like how prisoners get JACKED in jail\" => \"h i  e l lo   li   io  os   s  see   Ji \"\n",
      "batch 14625  loss=150.5779  steps/s=100.02  prediction: \" like this too? They come in pairs often\" => \"tos  no   r s  s         o    e    o    \"\n",
      "batch 14626  loss=159.1180  steps/s=95.70  prediction: \"yb is this founder mode or manager mode?\" => \":e  xleis t    i  o  o eo e    o  oo  ea\"\n",
      "batch 14627  loss=143.3497  steps/s=105.36  prediction: \" cliff in one go. like, good luck w that\" => \"top  ot  ff    f                        \"\n",
      "batch 14628  loss=175.7679  steps/s=44.97  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \": @sef  fo f  e          oo   oo        \"\n",
      "batch 14629  loss=159.9393  steps/s=113.78  prediction: \"nvm then, enjoy your rain water counting\" => \"geeot h  ttttt tn n n  n  n   n     r   \"\n",
      "batch 14630  loss=155.5688  steps/s=102.87  prediction: \"bly helps that they have a faster ai now\" => \"ey o  hlyb  bbb  hhlh h h hh h h  aaa   \"\n",
      "batch 14631  loss=152.1855  steps/s=104.50  prediction: \"se and 'magically' econ makes more sense\" => \" d le thetet   eaaaaaaa  a   aaa      ee\"\n",
      "batch 14632  loss=167.6971  steps/s=81.49  prediction: \"calbach_ thanks! hope its useful for you\" => \"ol o le ahhca  aaa     c     m  e e   ee\"\n",
      "batch 14633  loss=171.7753  steps/s=105.37  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/.. s:/  ////TTtTtOOOttOOOO/t/ttt////t//\"\n",
      "batch 14634  loss=152.4779  steps/s=106.62  prediction: \"d virus that makes ppl cracked at scale?\" => \" w   e i e  n n              a   a   aa \"\n",
      "batch 14635  loss=148.3940  steps/s=101.37  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"   r t t tttt ut a aa a aoo a  a  a aaa\n",
      "\"\n",
      "batch 14636  loss=140.4709  steps/s=103.17  prediction: \"\n",
      "\n",
      "good potential source of cool projects\" => \"\n",
      "lo dx@enhn evl 8T)GR11f,=1.RR:zD8wvvxzD\"\n",
      "batch 14637  loss=142.6065  steps/s=96.83  prediction: \"feeling than automating hrs of work away\" => \" yo   e oet tnneatanataatt  a o   o o o \"\n",
      "batch 14638  loss=183.6813  steps/s=21.37  prediction: \"eply: @tunahorse21 its really that good?\" => \" ly:  getetetn natanataatt  a oo  o o o \"\n",
      "batch 14639  loss=143.2384  steps/s=119.03  prediction: \"n to achieve an awesome long term vision\" => \" xr teeaa  ale a  aae  e   e e ee eee   \"\n",
      "batch 14640  loss=167.4638  steps/s=104.44  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/..l    ///ss///th t/ZZZZW  a  n aaxx  .\"\n",
      "batch 14641  loss=144.5252  steps/s=101.53  prediction: \"onster company\n",
      "i believe you could do it\" => \" g o eneme m  mmm      eeeeeeee ee      \"\n",
      "batch 14642  loss=155.8834  steps/s=103.97  prediction: \"is phrase and you will see it everywhere\" => \"n Mb   emrmrere s rrse ess   s  eii   ee\"\n",
      "batch 14643  loss=145.2079  steps/s=100.37  prediction: \"s. let the people decide. for danmocracy\" => \"  leerteest te  ee  ee eeee ee eeeddeddd\"\n",
      "batch 14644  loss=143.8723  steps/s=102.42  prediction: \"the highest quality music we have so far\" => \"he   e    h hhtthhht t tt               \"\n",
      "batch 14646  loss=139.4079  steps/s=104.19  prediction: \"e seen it from all possible perspectives\" => \" quh    ehee  i                 sssssees\"\n",
      "batch 14647  loss=158.4972  steps/s=94.92  prediction: \"ure Beautiful, and great choice of music\" => \"s  eeeeeeseu ea   a     l   ee  eeee eee\"\n",
      "batch 14648  loss=170.6323  steps/s=98.28  prediction: \" grows ur skills\n",
      "https://t.co/9ZBc4ushgS\" => \"toot  t  t  t     ss sssststtststts/////\"\n",
      "batch 14649  loss=146.9575  steps/s=105.24  prediction: \"lled by the day\n",
      "\n",
      "https://t.co/AFoPj5e1Mt\" => \"yer  d   edde     e  t   ttttt t//tt/tt/\"\n",
      "batch 14650  loss=153.3780  steps/s=99.51  prediction: \"keep that in mind\n",
      "idk what brypto is btw\" => \"el  l e  tl   n             i    t  i t \"\n",
      "batch 14651  loss=146.6696  steps/s=104.39  prediction: \"like there's more of a person there, idk\" => \"ykeia eee leleleee  ee    e       e   re\"\n",
      "batch 14652  loss=141.8072  steps/s=104.23  prediction: \" try to figure out why your brain worksâ€¦\" => \"th    oo t t tyt t  u      u   y   r rr \"\n",
      "batch 14654  loss=258.4777  steps/s=104.70  prediction: \": CHECK\n",
      "DELTA TIME: CHECK\n",
      "GRAVITY: CHECK\" => \" @HacIeTeeenHLT :DCHS:KCHELKARHLMKYGRAVI\"\n",
      "batch 14655  loss=143.5405  steps/s=104.16  prediction: \"oser and closer until you can putt it in\" => \"utti t  ti l   l                        \"\n",
      "batch 14657  loss=174.9199  steps/s=90.19  prediction: \"UBalis welcome to circle tool gang, king\" => \"pSPoce@JKmeU (t ::MME),KHGKmG),YVTkYECK(\"\n",
      "batch 14658  loss=148.1003  steps/s=105.72  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t e see eeeeeeeeer eeaaa  aa   a  a \"\n",
      "batch 14660  loss=155.9209  steps/s=101.05  prediction: \"tremely good at using ai to build things\" => \" a soexeemtemeet  et                 i  \"\n",
      "batch 14661  loss=140.0948  steps/s=105.38  prediction: \"evelopment speed\n",
      "https://t.co/YNvpK7QsyT\" => \" eee   tt n   neeeeeeeepeepttttttt//////\"\n",
      "batch 14662  loss=153.5002  steps/s=98.43  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t d  nente  pto   ttsststtst////t//////t\"\n",
      "batch 14663  loss=146.9994  steps/s=100.96  prediction: \" ways to take advantage of small nuances\" => \"tor  ro r te  t  a t aa aa aaaaaaaaaaaea\"\n",
      "batch 14664  loss=176.0655  steps/s=105.43  prediction: \"/t.co/hjQfCWaZxw\n",
      "https://t.co/VFbc29W7Ct\" => \"/.coesht////ttth/tthttttth/t//tt////ttt/\"\n",
      "batch 14665  loss=150.1103  steps/s=104.40  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \" rle    tg tetettttt   ee eeee e   e ee \"\n",
      "batch 14666  loss=158.1832  steps/s=104.97  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"ei   eb r           o   ot            v \"\n",
      "batch 14668  loss=166.9661  steps/s=97.55  prediction: \"a little weirder https://t.co/dcbD9IdKyf\" => \"ngt t.t ti lil     ttrttteetttt  /tttt//\"\n",
      "batch 14669  loss=147.1347  steps/s=104.04  prediction: \"ng and converged to guessing really well\" => \"d aeedennd n  nen      e e gggggg    g e\"\n",
      "batch 14670  loss=147.5284  steps/s=99.99  prediction: \" process does feel good when err go down\" => \"teierneer rnee sese see eee   o e  oeo o\"\n",
      "batch 14671  loss=144.6564  steps/s=108.00  prediction: \"cking it was kobe posting the whole time\" => \"o  M@in dot s s      o o    o       o   \"\n",
      "batch 14672  loss=148.1616  steps/s=101.52  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"@n e n     o  un      t  ttttttto ttttUU\"\n",
      "batch 14673  loss=158.8498  steps/s=100.15  prediction: \"ent in pygame and the network in pytorch\" => \" tnne tne n nnnnn     e ee e    e       \"\n",
      "batch 14674  loss=153.3202  steps/s=106.26  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" d e \n",
      "R\n",
      "RReeee eeeseesesesseeessesss eee\"\n",
      "batch 14675  loss=185.4151  steps/s=53.32  prediction: \": @AyNio2 see you on monday ma brotha! ðŸ«¡\" => \" @tam cA@Nhngv lB9j4kxI;AERqpBEkmKAvRIAb\"\n",
      "batch 14676  loss=172.5721  steps/s=116.71  prediction: \"e77 build things people want/ need maybe\" => \" 7oee@ci777777  i  i i  e   e     ee n  \"\n",
      "batch 14677  loss=139.5868  steps/s=102.49  prediction: \"to save this for later in case I forget\"\" => \"  e to   e    s                         \"\n",
      "batch 14678  loss=167.0107  steps/s=47.43  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \": @s     e    n                         \"\n",
      "batch 14679  loss=156.3986  steps/s=141.07  prediction: \"builds It is factually what plants crave\" => \"eins ibb_bd sis  t tf f  attaaa    aaata\"\n",
      "batch 14680  loss=145.6651  steps/s=101.27  prediction: \"nt true they wouldnt put it in the title\" => \"     e t it t tt t   t t    t    t t  tt\"\n",
      "batch 14681  loss=174.6290  steps/s=102.12  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" @ 4 t \n",
      "fo  nowloooolloootllottttoo/////\"\n",
      "batch 14683  loss=192.8229  steps/s=79.24  prediction: \"eativeBuilds @yacineMTB bro lets connect\" => \"pr o @ rfw  woololoo oootttt/////t//qqqo\"\n",
      "batch 14684  loss=140.9400  steps/s=105.65  prediction: \"cially long term stuff,  makes it harder\" => \"ocl  et stele ee                        \"\n",
      "batch 14686  loss=163.8647  steps/s=105.49  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"npe ee ereneeeieeiiii   pppptttttptttt//\"\n",
      "batch 14687  loss=151.2176  steps/s=105.21  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" r   tnee t  a \n",
      "aa\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tttttttt////\"\n",
      "batch 14688  loss=137.1375  steps/s=103.98  prediction: \"learning is by doing stuff. For anything\" => \"y,   nt nn n  t                         \"\n",
      "batch 14689  loss=163.4677  steps/s=102.37  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"tude  n ne n                 /t//////tt/\"\n",
      "batch 14690  loss=173.3609  steps/s=104.65  prediction: \"nthwave channel: https://t.co/0b7orVHqb3\" => \"g    t teedtnndennehhnhnnnnhttt:::t/tt//\"\n",
      "batch 14691  loss=165.9318  steps/s=85.24  prediction: \"phere its \"Hi\" (i removed all the noise)\" => \"leh @tteha nn atn   t  ee/ee//tt   tVltt\"\n",
      "batch 14692  loss=148.7290  steps/s=102.77  prediction: \"g i can make some insanely helpful stuff\" => \" ho even n  n he         n    e eene    \"\n",
      "batch 14693  loss=142.6014  steps/s=106.06  prediction: \"tiary structures. spirals within spirals\" => \"hne  y ryrrrrytrrrtrrrstrrsssrrssiisiii \"\n",
      "batch 14694  loss=152.1709  steps/s=86.39  prediction: \"enisnikulin its the lichess of photoshop\" => \" dntteaieninrt uustitiststsssisispssiii \"\n",
      "batch 14695  loss=143.2410  steps/s=103.75  prediction: \" regarded so take that w a grain of salt\" => \"tenem \n",
      "i m rmed      ee aa   aa   aaa  a\"\n",
      "batch 14696  loss=145.1475  steps/s=102.79  prediction: \" to call in the big guns (aka @gizmobly)\" => \"the     an     l                        \"\n",
      "batch 14697  loss=149.0232  steps/s=101.58  prediction: \"s after monads.. https://t.co/V7s73DqEAF\" => \" aos  os ssn s  s   s....tts.ttt...ttttt\"\n",
      "batch 14698  loss=152.4490  steps/s=100.90  prediction: \"an wrong something something bla bla bla\" => \"ndei  aln n  nen n nn  ommnnooog toh  b \"\n",
      "batch 14699  loss=150.0697  steps/s=104.26  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"tue   netdetdeoe     e eCCCICCCIIIIn nnn\"\n",
      "batch 14700  loss=140.6275  steps/s=103.11  prediction: \"change it up a bit from the ol .txt file\" => \"aeded n  tt t a                         \"\n",
      "batch 14701  loss=158.3139  steps/s=104.55  prediction: \" still use the ideas several times a day\" => \"tei   y  s    iss   s s   eessse seee  e\"\n",
      "batch 14702  loss=168.8281  steps/s=89.04  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \"r st lr s  ot h ee  seseeaeesiieeii  l  \"\n",
      "batch 14703  loss=169.8162  steps/s=98.78  prediction: \"nch @yacineMTB let the a b testing BEGIN\" => \" hes   ory O% y  eeetteeeet  t t  t  t t\"\n",
      "batch 14704  loss=145.5963  steps/s=101.34  prediction: \"all of the theories that we could invent\" => \"nle o o    o   e o     hh t et  e     e \"\n",
      "batch 14705  loss=150.3757  steps/s=101.68  prediction: \"unctional adults that they interact with\" => \"sd hf ifsfn d    u    t t  t  ttttt tttt\"\n",
      "batch 14706  loss=157.7335  steps/s=102.94  prediction: \"d LLMs to get boilerplate and stuff done\" => \" d tteAnLLLn LLt  t   e    t   t  t  tt \"\n",
      "batch 14707  loss=152.0941  steps/s=100.19  prediction: \"retty great as well, hes also on youtube\" => \"eply:n A@wen Mw pc,Nx.NbNxvJNJJwwJJ,,JJJ\"\n",
      "batch 14708  loss=203.2079  steps/s=20.45  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" ly: @t   t t t       ee   ll  l        \"\n",
      "batch 14709  loss=147.6797  steps/s=111.61  prediction: \"r taxes and splitting with other winners\" => \"ethy  fÊŸ)gere^iy\n",
      "^,X)ï¸Éª@@ÊŸ*@(ðŸ°**kx|\n",
      "ð—±]:(\"\n",
      "batch 14710  loss=168.4936  steps/s=98.58  prediction: \"uper loudly but yea. it helps w thinking\" => \"n   otct eon  uu t  lu  t t it  tt   ih \"\n",
      "batch 14711  loss=144.6664  steps/s=101.77  prediction: \" possible, at least quote and add a take\" => \"@ree s ss ss se l l               a aaaa\"\n",
      "batch 14712  loss=146.0397  steps/s=99.68  prediction: \"ng that solves a problem you're close to\" => \"    ot iot et tt     a       o   o oe e \"\n",
      "batch 14713  loss=147.2731  steps/s=104.48  prediction: \"eakens your life-problem solving ability\" => \" r   ng nn n          e   eoeellllll lll\"\n",
      "batch 14714  loss=152.0905  steps/s=105.55  prediction: \"ull potential. That would be surprising.\" => \"sd  t     tt tt  t   ttttt t ll        u\"\n",
      "batch 14715  loss=146.2466  steps/s=104.44  prediction: \"g\n",
      "Especially the more complex things get\" => \"   o o nniieniillllll     o   ee e e    \"\n",
      "batch 14717  loss=143.4553  steps/s=105.57  prediction: \" away looks smoother than a bowling ball\" => \"tnd  faaaeaa  ffoo ao a oaao   o ooao  a\"\n",
      "batch 14718  loss=157.6238  steps/s=98.84  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \" kha tw w lbb            t  tt t////////\"\n",
      "batch 14719  loss=154.7408  steps/s=105.56  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" tn  nt nt nt  o  o  tttttt  ttttt////t/\"\n",
      "batch 14720  loss=140.1614  steps/s=106.26  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tistnitn  t        t tt tttttott-ttttot\"\n",
      "batch 14721  loss=140.0066  steps/s=104.19  prediction: \"r, it felt a little linkediny over there\" => \"e uiineJ,hsm 6n .88OY8O8888@I7888IO!==v.\"\n",
      "batch 14722  loss=169.1491  steps/s=80.16  prediction: \"ey sandwich has been achieved internally\" => \"   it  trr t   da   ee   aheeee  eieee e\"\n",
      "batch 14723  loss=142.5751  steps/s=107.11  prediction: \"ould color their pill white for the lolz\" => \"n eu  ltc th  l h     llll i l    ih    \"\n",
      "batch 14724  loss=138.5111  steps/s=103.71  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "An n y88beh 'u ','','KK',vKV3,3NNNXXXXX\"\n",
      "batch 14725  loss=147.1001  steps/s=103.35  prediction: \"om the distribution of (single response)\" => \"neoferfff e r t i  riitiii iti  ii  i   \"\n",
      "batch 14726  loss=146.5073  steps/s=105.52  prediction: \"de you hate work\n",
      "https://t.co/2jmiAqT1C6\" => \"  iti t th t  a       ttttttt///////////\"\n",
      "batch 14727  loss=142.1396  steps/s=101.17  prediction: \"mes? maybe you could make a mod you want\" => \"ate tou   m mya   y    m                \"\n",
      "batch 14728  loss=212.4276  steps/s=21.03  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly: @naaa mmye        m                \"\n",
      "batch 14729  loss=141.5349  steps/s=108.63  prediction: \" get to master idk depends on your goals\" => \"te oee  en e  tt      t   d dd d  d  o  \"\n",
      "batch 14730  loss=150.0114  steps/s=101.14  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"tok  ni    n nnonnooooooooooo           \"\n",
      "batch 14732  loss=174.8705  steps/s=102.92  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" tett rt eed t etth  hh  hh             \"\n",
      "batch 14733  loss=159.5378  steps/s=106.16  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \" d  tttseeseteteeetettttttttttttttt/////\"\n",
      "batch 14734  loss=161.8100  steps/s=96.63  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u@ e   7ce e   o t ttptt//p:///pt//.333\"\n",
      "batch 14735  loss=161.0611  steps/s=102.41  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" aso e o   s  s  ooo oool onnnn   nn    \"\n",
      "batch 14737  loss=150.7428  steps/s=102.99  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"eplyy ,M$OeU @f X[@Oá´„[X*$$X~{*â€™[[$á´˜ðŸ«¡Éªâ˜ ]ðŸ¤·\"\n",
      "batch 14738  loss=140.5948  steps/s=104.05  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h ar   o ong  ogooo ooo oo o   o o    o \"\n",
      "batch 14739  loss=138.9058  steps/s=104.45  prediction: \" from that channel/vid to that x account\" => \"trr  lo lol   d   a a      tttttt    tt \"\n",
      "batch 14740  loss=141.5158  steps/s=101.40  prediction: \"etter but pretty good time bender though\" => \"   oot t p  tt etttt  ttttttt    ee ee e\"\n",
      "batch 14741  loss=131.6823  steps/s=104.13  prediction: \"d so i felt the need to post the way out\" => \" in isiini                              \"\n",
      "batch 14742  loss=140.9059  steps/s=104.06  prediction: \"tal clarity and less of a need for sleep\" => \" ns    eneenn  laal ll    a             \"\n",
      "batch 14744  loss=145.7445  steps/s=104.04  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei   n    n iiiiii ii     i         uu \"\n",
      "batch 14745  loss=155.0482  steps/s=101.63  prediction: \"u actually did the work so youre chillin\" => \"tcfattta  t t a                        o\"\n",
      "batch 14746  loss=141.8785  steps/s=104.75  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"g    aa aa gg  g   a         e ee eeeee \"\n",
      "batch 14747  loss=145.0204  steps/s=104.19  prediction: \" if you come across any useful stuff tho\" => \"tt  o n   o  o   oo   o      s   usuuusf\"\n",
      "batch 14749  loss=134.2998  steps/s=103.62  prediction: \"and run it in the front end of a browser\" => \"td o e                                  \"\n",
      "batch 14750  loss=164.2938  steps/s=105.93  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne e l    sss es    @@@@rrr rrrrr rrarrr\"\n",
      "batch 14751  loss=155.8084  steps/s=103.04  prediction: \"h, that explanation/example makes sense'\" => \"e  h hh hh ha thaaaaaaaaxxxaaaaaaaeeeeee\"\n",
      "batch 14752  loss=146.4357  steps/s=104.46  prediction: \" to animate a NN https://t.co/JdnKMowlAa\" => \"titeetttt ttttaa       NNNt ttt/////////\"\n",
      "batch 14753  loss=172.4868  steps/s=105.28  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"Eaitaao)ji n ~ilbj5EK_Kð—¯~=/xX()~bÊ€â€¦ðŸ˜¤_/1%\"\n",
      "batch 14754  loss=166.4127  steps/s=98.80  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t g tnett n  to    tos tttstptttt////o//\"\n",
      "batch 14755  loss=168.3639  steps/s=35.05  prediction: \"ly: @morew4rd Gettin there, yup\n",
      "Soooooon\" => \"y: @Nont+    toststtsststtst////t////oGn\"\n",
      "batch 14756  loss=152.4943  steps/s=110.35  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"tepeee ern ele lee   ee                 \"\n",
      "batch 14757  loss=148.4388  steps/s=104.99  prediction: \"nts also on the nm level, but, 3d not 2d\" => \" il  e snnnnoonnn                       \"\n",
      "batch 14758  loss=143.2946  steps/s=103.20  prediction: \"ally have to put in 10k hrs of work, itâ€¦\" => \"n  t ae  y  te                          \"\n",
      "batch 14759  loss=194.1806  steps/s=35.40  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly  t  e ll e e                         \"\n",
      "batch 14760  loss=136.6043  steps/s=106.67  prediction: \"w the entire thing works when you use it\" => \"ht  hn h n  n et                        \"\n",
      "batch 14761  loss=152.0388  steps/s=104.70  prediction: \"them depth wise, learning â€œon demandâ€ (â€¦\" => \"hieecte  ep t m e    e e  ee    n n nnnn\"\n",
      "batch 14762  loss=146.7898  steps/s=105.26  prediction: \"quickly that require a variety of skills\" => \"ui\n",
      "e   i at r  qqq rqq  r rrrar   r  r  \"\n",
      "batch 14763  loss=184.1546  steps/s=101.01  prediction: \"7AHwatHv6Y was really really really good\" => \"0  @t o///ttttt HHHHaaaa aaalall allllly\"\n",
      "batch 14764  loss=227.1675  steps/s=11.17  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"eplv: @7Axe  @r Y)0q7AH\",%%v6YC.:j/7.,Q/\"\n",
      "batch 14765  loss=148.3667  steps/s=110.22  prediction: \" set at 5mins by default when unblocking\" => \"tti dti tit  t                     n   n\"\n",
      "batch 14766  loss=163.2217  steps/s=107.15  prediction: \"a exactly\n",
      "\n",
      "just mon and thurs every week\" => \"nl  utkk  e aa t   aaa  a   n n  nu   e \"\n",
      "batch 14767  loss=149.6553  steps/s=103.50  prediction: \"rflowsucks and never went on there again\" => \"eao    Cx  h Ugejf12b9Q12Q12JjO1FFQUWWWW\"\n",
      "batch 14769  loss=147.2824  steps/s=104.95  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" in lo aae l af\n",
      "a\n",
      "ababb   aaaa a aaaaaaa\"\n",
      "batch 14770  loss=143.4161  steps/s=104.39  prediction: \"ard to realize. lies are really blinding\" => \"np  o r  n a   aa          eeeeeelllllll\"\n",
      "batch 14771  loss=138.9970  steps/s=104.05  prediction: \"to a prompt, auto copied to my clipboard\" => \"     t t        t t       oooo o      o \"\n",
      "batch 14772  loss=167.6359  steps/s=93.42  prediction: \"Gotta make one and learn that skill then\" => \"o:   t r  tta ato o  ae  o    a    ta  l\"\n",
      "batch 14773  loss=158.6454  steps/s=44.97  prediction: \"y: @thevalidcode Was just gonna say this\" => \"  @ni  arato   tt  o ae  n  taa  l tl tl\"\n",
      "batch 14774  loss=192.6859  steps/s=42.11  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly: @oaraaot ae   o ae  n  taa  latl tðŸ›‘\"\n",
      "batch 14775  loss=144.5437  steps/s=110.62  prediction: \"do all of those\n",
      "\n",
      "https://t.co/C4hXOs7hck\" => \" mb   i  f o   f   o ooo o otott////////\"\n",
      "batch 14776  loss=165.8378  steps/s=76.59  prediction: \"hones Hype, solid 4hr block, lets get it\" => \"eu  ao    of    ooo ssshtttt//ttttssssht\"\n",
      "batch 14777  loss=153.0069  steps/s=107.11  prediction: \"usly gives API access, can also finetune\" => \"      nmsssmesssses essssesss c ss  css \"\n",
      "batch 14778  loss=159.4666  steps/s=99.32  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"m b de@jnB u @etzv@2WzAIIbbAPI(,,xqâ™‚á´¡k))\"\n",
      "batch 14779  loss=153.8128  steps/s=99.87  prediction: \"ke getting flashbanged by your teammates\" => \"e gi ieil ti i   g  gnggg e ae  a      a\"\n",
      "batch 14781  loss=149.0975  steps/s=103.94  prediction: \" except waaay too short of chunks hahaha\" => \"tad laelelrlea aa  aaa    oo  o     hh o\"\n",
      "batch 14782  loss=151.1411  steps/s=104.69  prediction: \"e we figure out that sleeping is a thing\" => \" ionacneneccce      e   e    e        i \"\n",
      "batch 14783  loss=141.3859  steps/s=103.96  prediction: \"t progress/mistakes made/lessons learned\" => \" in eo o  srtrrsrrssssssseesssseessessse\"\n",
      "batch 14784  loss=202.9946  steps/s=88.16  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"e, y: iL1~4|zL mbbL1k00xmD..BI(N,k0N\n",
      ".))\"\n",
      "batch 14785  loss=142.7323  steps/s=105.70  prediction: \"igh quality outputs with infinite tokens\" => \"nh b  n  hhuu   uu uu  uuttitttiitititii\"\n",
      "batch 14786  loss=191.3634  steps/s=60.07  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tLah  h gh t t uuututtttiitiittiitititii\"\n",
      "batch 14787  loss=147.6188  steps/s=108.31  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"  fo t   rn n n            ttt//t/ ////t\"\n",
      "batch 14788  loss=155.0143  steps/s=94.36  prediction: \"TB you can just do things bro just do it\" => \"B th p  nine   n    t   ttttotttt s   oo\"\n",
      "batch 14789  loss=142.2659  steps/s=105.27  prediction: \"etter, all in your head\n",
      "Can explain more\" => \"    e t  etn   l                   aa aa\"\n",
      "batch 14790  loss=142.7670  steps/s=102.19  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \"g ehate  nanaaan a    a          t/tt///\"\n",
      "batch 14791  loss=144.8069  steps/s=103.56  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \"uent i an\n",
      "nnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nww\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "onnnoooo\"\n",
      "batch 14792  loss=151.3269  steps/s=101.83  prediction: \" personally wasted many years bc of this\" => \"tant teeeaelee  eaeaa aaaaaaaaa aa      \"\n",
      "batch 14793  loss=148.5574  steps/s=104.29  prediction: \" of how i debug and catch inefficiencies\" => \"tf e iormpo  a           a   a i   icfic\"\n",
      "batch 14794  loss=148.5158  steps/s=101.67  prediction: \" surprised at how clean of a read it was\" => \"tta een Y ss  as          a             \"\n",
      "batch 14795  loss=135.3082  steps/s=103.29  prediction: \" you called it. may as well draft it now\" => \"tou  on    y                            \"\n",
      "batch 14796  loss=151.8772  steps/s=99.87  prediction: \"nsettler 1min in, its pretty good so far\" => \"g yo  etss nsstt t    i i i  itt t   t  \"\n",
      "batch 14797  loss=153.7750  steps/s=103.95  prediction: \" tackling client projects, ThreeJS courâ€¦\" => \"@he   n  bi c g llll  llccccc e eeeeeeee\"\n",
      "batch 14798  loss=150.7701  steps/s=104.74  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"an   +n   tpt      ttt  ttttttttttt/////\"\n",
      "batch 14799  loss=141.5159  steps/s=104.94  prediction: \"cond while avoiding exhausting the first\" => \"on i yet   s  ne       iiiiiiiiiiiii   i\"\n",
      "batch 14801  loss=179.6684  steps/s=56.01  prediction: \" @Yosef_Frost vision: pro\n",
      "execution: slo\" => \"tBt ose ee  ooediiii i    iiiixieitii  t\"\n",
      "batch 14802  loss=154.1995  steps/s=112.05  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" oo   n   n   n    h      o             \"\n",
      "batch 14804  loss=146.9926  steps/s=105.23  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"\n",
      "Iooe e_xfw  Ê€  á´›($U:zâ€™/N')$XAX$*,25(ðŸ¤£â€¦[\"\n",
      "batch 14805  loss=159.3051  steps/s=100.64  prediction: \"y the paper i thought it was a neat read\" => \" iil M    h t hhppp  h   hhhht   t t   a\"\n",
      "batch 14806  loss=161.6810  steps/s=75.50  prediction: \"yotzol its not a meme, its a way of life\" => \" u t ep a   tttptha     e   at   t a   a\"\n",
      "batch 14808  loss=154.5736  steps/s=105.04  prediction: \" this long lost treasure of a song, damn\" => \"toe rro   n no n   o    o s  o o        \"\n",
      "batch 14809  loss=147.5793  steps/s=104.12  prediction: \" sum bros.. pivot, its worth it trust me\" => \"teu  eo e  r o...... oo      o ot   ttt \"\n",
      "batch 14811  loss=158.9827  steps/s=95.94  prediction: \"tters job was a good man\n",
      "\n",
      "God is amazing\" => \"hi e   sst ro sts       o o  i oo     i \"\n",
      "batch 14812  loss=176.9932  steps/s=56.58  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tlumeeser__ms   s  o   a  oo   oo  si ii\"\n",
      "batch 14813  loss=141.7607  steps/s=109.28  prediction: \" software used that widely is so awesome\" => \"tei   n  a    f                         \"\n",
      "batch 14814  loss=132.6823  steps/s=102.37  prediction: \"tput something as unexpected as possible\" => \"hs  t   tootottt            ee eeeeeesss\"\n",
      "batch 14815  loss=142.0544  steps/s=103.85  prediction: \"bank account evaporate like a black hole\" => \"el y t   r    o    a o oa a a aae a     \"\n",
      "batch 14816  loss=169.4249  steps/s=105.35  prediction: \"his ~10yrs ago w py\n",
      "Learn by doing WORKS\" => \"en  st ~ttr~  1s s   ys   r      y      \"\n",
      "batch 14817  loss=197.7764  steps/s=88.51  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"g p c s  s M  ~=    ECC   ttt o///  LoLS\"\n",
      "batch 14818  loss=149.8627  steps/s=105.16  prediction: \"caveman do xyz?\"\n",
      "https://t.co/TlhgHoICNd\" => \"anlc d        a?           tt t/t//t////\"\n",
      "batch 14819  loss=146.6362  steps/s=103.34  prediction: \", increases both HP and MP significantly\" => \" wn ee  er reeeeeee ee     PPPPPP   i  i\"\n",
      "batch 14820  loss=144.3527  steps/s=104.03  prediction: \"c, just separated by some amount of time\" => \"h nk t t,r,t   s ta  teee  e        t   \"\n",
      "batch 14821  loss=138.1028  steps/s=101.92  prediction: \"etter but pretty good time bender though\" => \"   oot oeb ett etttt  ttttttt    ee ee e\"\n",
      "batch 14822  loss=154.1296  steps/s=99.12  prediction: \"yeah, tunisia... carthage would be nice\"\" => \":arnsn ..t nni........a.a a aaa       a \"\n",
      "batch 14823  loss=148.3657  steps/s=104.59  prediction: \"e a dog\n",
      "\n",
      "thats how i feel abt it anyways\" => \" ana  o k  k  a    o                    \"\n",
      "batch 14824  loss=137.2706  steps/s=101.69  prediction: \" least its not opengl like this poor kid\" => \"tik  at e ttttatt t t   t            i i\"\n",
      "batch 14825  loss=158.1636  steps/s=104.75  prediction: \"you like hearing about progress updates!\" => \":u denolnil  ig l ii      ioor  or  r u \"\n",
      "batch 14826  loss=149.7490  steps/s=105.42  prediction: \"having kids, etc) may be only palliative\" => \"en   a(       h i   i                   \"\n",
      "batch 14827  loss=171.7420  steps/s=101.99  prediction: \"le77 Good stuff brotha\n",
      "\n",
      "looks productive\" => \"yt  cr iic  77 d o    tf f  o al a llo i\"\n",
      "batch 14829  loss=152.1705  steps/s=45.77  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \"  @Bci icg  77ff o f  tfoo oo aooa liovi\"\n",
      "batch 14830  loss=141.7894  steps/s=128.62  prediction: \"tler where would you say you are on this\" => \" e  aaree telee  ooz    o  yyooooa   oe \"\n",
      "batch 14831  loss=152.8085  steps/s=100.79  prediction: \"el you save\n",
      "\n",
      "hmm interesting interesting\" => \" lie  i  eee ehe    e me\n",
      "mmeme  eeeetent\"\n",
      "batch 14832  loss=155.0375  steps/s=103.42  prediction: \"er cool shit bro gl w your phd\n",
      "\n",
      "followed\" => \"  ie  ooeoso   mo    r        t rre\n",
      "r\n",
      "\n",
      "e\"\n",
      "batch 14833  loss=179.4169  steps/s=103.89  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns      n   n      o  tttt  tttttt////t/\"\n",
      "batch 14834  loss=143.5989  steps/s=102.51  prediction: \"marter you get the more the traps change\" => \"eke  am trt   te       t   e   e   e    \"\n",
      "batch 14835  loss=164.2713  steps/s=86.30  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"e l in aenf I5no1I5M1Sb,MjC5!Y!:1JTJ!1J2\"\n",
      "batch 14836  loss=138.5448  steps/s=105.53  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y\n",
      " eileiei lll p                 a     a\"\n",
      "batch 14837  loss=131.3791  steps/s=103.31  prediction: \"ntext into a computation to make it pure\" => \"   s ta  nnnn n    ttttttttttttttttt    \"\n",
      "batch 14838  loss=144.7570  steps/s=103.68  prediction: \"e some exciting long term vision then no\" => \" fnooete et teet   e    e        ii   nn\"\n",
      "batch 14839  loss=167.6476  steps/s=104.62  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"ebt i eoMlc tð—±  1pX9jZ65MðŸ¤·SXM6â™‚21_[21cVC\"\n",
      "batch 14840  loss=178.4106  steps/s=103.16  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"ngm_ier ra PP ee TT   X E EEETERLRLILLII\"\n",
      "batch 14841  loss=168.6338  steps/s=80.93  prediction: \"nsettler cant spell family without AI :D\" => \"g! oa a rette    EE t   I L   GG  I  I  \"\n",
      "batch 14842  loss=166.6061  steps/s=103.97  prediction: \"G SUB 30 BABYYYY https://t.co/E87r3E6tgg\" => \"oN      F     eBBBYYYYYYYYY/ // //////t3\"\n",
      "batch 14843  loss=149.9759  steps/s=105.44  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"ei ee iwn oo Eda1LYkxPY(vY??MMY?UM)Wv(6L\"\n",
      "batch 14845  loss=145.9193  steps/s=103.42  prediction: \"ttin you do all that stuff, drop out etc\" => \" eteo ltthu tt t    t t    ttt t  t t  t\"\n",
      "batch 14846  loss=153.9652  steps/s=103.22  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nnieot iintiitiit  ot   g  s  s ss ss  s\"\n",
      "batch 14847  loss=139.5048  steps/s=103.12  prediction: \"cond while avoiding exhausting the first\" => \"omei yee    h ne       iiiiiiiiiiiii   i\"\n",
      "batch 14848  loss=172.6250  steps/s=30.58  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly:  yie         ii  i iiiiiiiiii iii  t\"\n",
      "batch 14849  loss=160.6462  steps/s=110.61  prediction: \"nonstop about that compression challenge\" => \"gt o  o nonn nh ttttttttttttooooooooo   \"\n",
      "batch 14851  loss=183.8926  steps/s=64.85  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"BnnsUeno oon tt tttotttttssottooooc c ee\"\n",
      "batch 14852  loss=151.9678  steps/s=109.42  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e  t:souods cY t,T,II[T:_L@.:Y/4.NUT4DNA\"\n",
      "batch 14854  loss=151.1409  steps/s=102.09  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame  ic   ct t                         \"\n",
      "batch 14855  loss=155.2171  steps/s=101.10  prediction: \"\n",
      "\n",
      "Huh didnt know you could change your @\" => \"\n",
      "s wezeyagzr _r ,Tf_LKT:vH@b:v/H.((/HDNU\"\n",
      "batch 14856  loss=138.2627  steps/s=99.73  prediction: \"e\n",
      "\n",
      "i need to try your coffee shop tactic\" => \" \n",
      "t  @ uef ddeee                  e  o  \"\n",
      "batch 14857  loss=150.8805  steps/s=102.28  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"eku  a  t     booooo ooooooo ooooo  o   \"\n",
      "batch 14858  loss=179.8792  steps/s=103.62  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" t t kcoc cd cedccocom   to ooootto///co\"\n",
      "batch 14859  loss=145.3747  steps/s=103.19  prediction: \" far dang the format looks so much nicer\" => \"torb  fr b     f   f   o    o oo  ooo  o\"\n",
      "batch 14860  loss=143.1447  steps/s=105.07  prediction: \"ney OR something extremely useful to you\" => \"d to on ne            eeeeeeeeeeeeeeeeee\"\n",
      "batch 14861  loss=162.8450  steps/s=105.70  prediction: \"t to follow btw\n",
      "\n",
      "https://t.co/HtQ8VvN4bY\" => \"hso t no n tot  oootttttttttt tttttt/t/t\"\n",
      "batch 14862  loss=182.9140  steps/s=53.49  prediction: \": @AyNio2 see you on monday ma brotha! ðŸ«¡\" => \" @lEterAebirsNinSTMLxUSY)MLLbUv{fFzb!w:f\"\n",
      "batch 14863  loss=153.5740  steps/s=112.04  prediction: \" rivals\n",
      "\n",
      "but idk, i dont know the theory\" => \"teo i  ololol  \n",
      "     i   d i      t    t\"\n",
      "batch 14864  loss=177.7223  steps/s=29.24  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: @ooolholl id    id     k      t    t\"\n",
      "batch 14865  loss=154.9573  steps/s=111.50  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"tenaae a l paaapaaappaatttttttotttt/////\"\n",
      "batch 14866  loss=149.4066  steps/s=105.15  prediction: \" relationship where you never lie to her\" => \"tere \n",
      "m a enaao  a a a  ee     eeee     \"\n",
      "batch 14868  loss=155.7996  steps/s=101.55  prediction: \"though who knows\n",
      "https://t.co/YpddagC5uf\" => \"hes i raa     hh hhhhhhhhthhttottott/o//\"\n",
      "batch 14869  loss=147.0493  steps/s=104.03  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" co    d  dd dd d dd     t              \"\n",
      "batch 14870  loss=165.1283  steps/s=99.93  prediction: \"wigABAP why a few years\n",
      "\n",
      "do it this week\" => \"itke e w e wwA wAw w   w         e  t t \"\n",
      "batch 14871  loss=161.1424  steps/s=104.80  prediction: \"ng up every word you hear more than once\" => \"t  worw roor  o  r    o   o    r    r   \"\n",
      "batch 14872  loss=143.0263  steps/s=101.23  prediction: \" bricked my laptop\n",
      "patronizing bloatware\" => \"tee  e  deer          ppappppppppppiiaat\"\n",
      "batch 14873  loss=146.0984  steps/s=102.81  prediction: \" the code in my head like an interpreter\" => \"thini n ntn n                e    e  e e\"\n",
      "batch 14874  loss=135.6793  steps/s=103.60  prediction: \"ort of like a spike strip but for boats)\" => \"u tho t ne  n                           \"\n",
      "batch 14875  loss=200.7932  steps/s=78.42  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"yanaiono i       i    i  p          ttt \"\n",
      "batch 14876  loss=151.5788  steps/s=105.06  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt  eoeeef ff rf ff      s   t /tt///tt/\"\n",
      "batch 14877  loss=141.3588  steps/s=104.12  prediction: \"ol\n",
      "gonna crack one open rn over some ice\" => \"r  h to loolooalo oooooonnnnnnnn        \"\n",
      "batch 14878  loss=152.9164  steps/s=98.94  prediction: \" stuff! Thanks, hope yours went well man\" => \"totwooonoono   nn              e    e   \"\n",
      "batch 14879  loss=197.6871  steps/s=20.16  prediction: \"eply: @djcows you need attention, is all\" => \" ly: @n ohno   nn                   e   \"\n",
      "batch 14880  loss=156.8861  steps/s=108.85  prediction: \" it can be! Nice https://t.co/7gl6yX5jXL\" => \"tf  era....c ae  ce  e    t   ttttt////t\"\n",
      "batch 14881  loss=145.1812  steps/s=105.39  prediction: \"e online?\"\n",
      "uuuh, dont be? problem solved\" => \" wet nie eenneeeeeen uu  ?????   e   e  \"\n",
      "batch 14882  loss=164.1968  steps/s=95.35  prediction: \"e to you brother https://t.co/nLfQJqRwZ9\" => \" sot o  oe uou  oo o t t    tttt ///t/oo\"\n",
      "batch 14883  loss=143.3234  steps/s=105.43  prediction: \"rids\n",
      "gpus are 2d grids of 2d grids so 4d\" => \"ede oe 6amnte_9eLPjj!xNL2mL3-:j,\n",
      ".w)?4jI\"\n",
      "batch 14884  loss=165.3792  steps/s=92.30  prediction: \"bly same, llms are so much faster though\" => \"ey ddd ioia   ssa    s ss        d s  s \"\n",
      "batch 14885  loss=156.7277  steps/s=102.03  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"tt   e elle nee i e   i  e       d dd   \"\n",
      "batch 14886  loss=147.0928  steps/s=98.73  prediction: \"whoa thats wild, old twitter could never\" => \" et @s  e t n    a    dt d  ttt  t t    \"\n",
      "batch 14887  loss=140.4995  steps/s=104.47  prediction: \"n an addiction\n",
      "Really curious what it is\" => \" ma le ataanaaianannanan aiii iiii    i \"\n",
      "batch 14888  loss=148.3540  steps/s=96.55  prediction: \"ould get my ass handed to me for suuuure\" => \"r    o  n o t    al a    a    s   o  uuu\"\n",
      "batch 14889  loss=164.6890  steps/s=100.28  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"nt  ee e he 2   22 2  t ttt ttttttt///t/\"\n",
      "batch 14890  loss=179.1314  steps/s=87.01  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \"  oh2  e2h   lh h haahthttt tt/tttt//tVt\"\n",
      "batch 14891  loss=143.6089  steps/s=106.33  prediction: \"tle robots\n",
      "\n",
      "they remove so much friction\" => \" er se     l t ottttttteooe eoee   o    \"\n",
      "batch 14892  loss=153.7690  steps/s=103.92  prediction: \"lf of that was way off. all good tho nbd\" => \"y   m   l   t t           af            \"\n",
      "batch 14893  loss=173.2443  steps/s=82.15  prediction: \"edydas @tanayj make one\n",
      "good opportunity\" => \"  ah  h  ttaa aaaaaa   aa   o ooooo  o o\"\n",
      "batch 14894  loss=152.1724  steps/s=103.32  prediction: \"important piece of advice here by a mile\" => \"ne aanca t n t n   t     e  eee    e    \"\n",
      "batch 14896  loss=146.0962  steps/s=104.71  prediction: \"ike a combinatoric sized pain in the ass\" => \"neor  oo o  n    o  iiiiii iiiiiiiii i  \"\n",
      "batch 14897  loss=190.8573  steps/s=87.05  prediction: \"ruck is this you https://t.co/TaMoSJicnx\" => \"enty:dezeegrsDt ?jST@Gjv1:;k:1MT.:JMTSM,\"\n",
      "batch 14898  loss=153.7933  steps/s=105.48  prediction: \"tremely good at using ai to build things\" => \" a  oe  emmemeet  eo                    \"\n",
      "batch 14899  loss=141.3970  steps/s=104.72  prediction: \"nk could handle a variable player count)\" => \"   oro  nend nndd  d a aala aaaaala laa \"\n",
      "batch 14900  loss=146.9167  steps/s=104.81  prediction: \"it anymore. Now she can go get groceries\" => \"n  a  aa n                           g  \"\n",
      "batch 14901  loss=140.1744  steps/s=105.17  prediction: \"ing this with terms masters commonly use\" => \"ng f  n ni     t            s  smmmmmmmm\"\n",
      "batch 14902  loss=135.3607  steps/s=103.62  prediction: \"oncept but also show you how to apply it\" => \"u e  ee cecc cc       o    o  ooo oo  o \"\n",
      "batch 14903  loss=165.2331  steps/s=91.65  prediction: \"eMTB very, very inefficiently, thats how\" => \" TBpicnce  e     e    o    o   o   t t  \"\n",
      "batch 14904  loss=159.4595  steps/s=100.61  prediction: \"ircle tool gang) https://t.co/eWviZR2Y3N\" => \"ne e   ccll lo ol   ool  tttt  ttttt////\"\n",
      "batch 14906  loss=175.1991  steps/s=96.47  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" t elAeAoA  @ n eee_______ _see   e l  e\"\n",
      "batch 14907  loss=156.5929  steps/s=104.74  prediction: \"ort (effort is proportional to time butâ€¦\" => \"ne te t te ttff fffrrroooooooo otooo to \"\n",
      "batch 14908  loss=135.4776  steps/s=98.79  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"taib  d t gg      ppppppp               \"\n",
      "batch 14909  loss=149.8233  steps/s=104.43  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"t e  na n  nn            t ttttttt/tt///\"\n",
      "batch 14910  loss=160.4998  steps/s=102.80  prediction: \" wonder what else you could fast-preview\" => \"taea  ai ed   e  ee   e    e         e  \"\n",
      "batch 14912  loss=168.2686  steps/s=88.92  prediction: \"ates Hear me out https://t.co/M8bURSdiT1\" => \"c  d a eeaet e  e  e  out   ttso///toeeo\"\n",
      "batch 14913  loss=145.1540  steps/s=104.28  prediction: \"g correct (fingers crossed its this one)\" => \" a e er et  rrrrrrerr  rrerr  ssss ssss \"\n",
      "batch 14914  loss=142.6050  steps/s=102.66  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eeeint n  neeseseesseeeeeemeeeeiii i i i\"\n",
      "batch 14915  loss=167.9838  steps/s=100.30  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" to@eea e     u   oo  o    oolttto/tVVVV\"\n",
      "batch 14916  loss=172.6032  steps/s=73.75  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"u n  sa  n  noo  ooo  o lotto////VV//ool\"\n",
      "batch 14917  loss=157.0898  steps/s=105.03  prediction: \" flick of the wrist instead of traveling\" => \"@oui Pw  f of         i i tt    tt t t  \"\n",
      "batch 14918  loss=141.1423  steps/s=105.45  prediction: \"hing that could ruin their brand idk tho\" => \"eve e eeem ttt t  t              i      \"\n",
      "batch 14919  loss=144.3074  steps/s=104.73  prediction: \"tiny advantages?\n",
      "\n",
      "Confusion and insanity\" => \" on th     n a aaaaaaaanannnnnnnnnnnnnnn\"\n",
      "batch 14920  loss=147.5299  steps/s=104.43  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"eie    mmer LL rCD'GB.&bz;kA^!H===&;;;^^\"\n",
      "batch 14921  loss=163.3652  steps/s=100.29  prediction: \" stuff! Thanks, hope yours went well man\" => \"too  eos ono   to      h            e ee\"\n",
      "batch 14922  loss=156.4295  steps/s=67.78  prediction: \"justalexoki the t has always meant taoki\" => \"ust ootts nn s thh     hh   w w     e   \"\n",
      "batch 14923  loss=155.6262  steps/s=107.84  prediction: \"y the paper i thought it was a neat read\" => \":tiein    h n hhppp  h   hhhht   t     a\"\n",
      "batch 14924  loss=166.6720  steps/s=104.64  prediction: \"tiquing the zoomers that jump in his dms\" => \" on  heaeeineitie iii  t tto    tt   t  \"\n",
      "batch 14925  loss=170.2500  steps/s=85.23  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"nn  i ttu2 2 i toA AA  thth  mt hmm  e  \"\n",
      "batch 14926  loss=161.4552  steps/s=104.95  prediction: \"ongrats on finishing the moon easter egg\" => \" e 2i arngtan ti  inni in  nin  enne e e\"\n",
      "batch 14927  loss=173.7076  steps/s=100.76  prediction: \"h i dont remember getting much out of it\" => \"epe   ddde       ee eee eeememt  et     \"\n",
      "batch 14928  loss=207.8865  steps/s=100.86  prediction: \"NITE RIEMANN MAP https://t.co/ehwwY6cUAf\" => \"oTU eI NIIEETNNMMMNNNMAMA   N   //   // \"\n",
      "batch 14929  loss=149.6981  steps/s=106.36  prediction: \" what fever dream anime your pfp is from\" => \"@itt n t   t   f    a    e   e          \"\n",
      "batch 14930  loss=148.0740  steps/s=101.42  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"n an  aearra  aaar   aa   aoo ooooo   dd\"\n",
      "batch 14931  loss=158.0206  steps/s=99.81  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"mobude@luneP @ tzR@MAzNEbRP::/N.sv//bv.Y\"\n",
      "batch 14932  loss=157.7591  steps/s=103.76  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee  emeneneeeeee nnentt tttttttt/////\"\n",
      "batch 14933  loss=147.1699  steps/s=105.29  prediction: \".. would love to be proven wrong on this\" => \"  o lea w.w.w..l o   o     o    oo o  o \"\n",
      "batch 14934  loss=166.2431  steps/s=95.39  prediction: \"sha Keep grinding ig\n",
      "\n",
      "Ppl love to see it\" => \" are o  n en  l e       ne    o oo    o \"\n",
      "batch 14935  loss=158.4864  steps/s=76.24  prediction: \"minus9 This is my new favorite edm track\" => \"ene   d  ne s ii i   n i e v  ooooeee te\"\n",
      "batch 14936  loss=157.2955  steps/s=105.40  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \"hr a atsshseteteeetetttttttttttttttt////\"\n",
      "batch 14937  loss=159.2991  steps/s=105.32  prediction: \" /GPU in my repo https://t.co/E0y7ZskhYs\" => \"@nde  n ne n              / //t//////tt/\"\n",
      "batch 14938  loss=167.2570  steps/s=102.36  prediction: \"ta point\n",
      "how hard/often were you lifting\" => \"hl  zes aen aan   oottt    teeoooo    oo\"\n",
      "batch 14939  loss=155.7386  steps/s=97.18  prediction: \"B GPT isnt wrong, just ahead of its time\" => \" C edana  n       o tnt  w e    e     ii\"\n",
      "batch 14940  loss=146.0748  steps/s=76.26  prediction: \"amebedan since ports dont allow weapons.\" => \"ne eMT Tn nn nwn   nn   oo    o    ai w \"\n",
      "batch 14942  loss=211.3242  steps/s=109.81  prediction: \"ETURNS\n",
      "Wb wb. Great zig project idea btw\" => \"  Ny q@eyHeSeWS WD.@ETDGNEzURzS,WjG/j.lG\"\n",
      "batch 14943  loss=148.6660  steps/s=104.02  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" rede    l       r rrrrrrrrrrrrrrrr   h \"\n",
      "batch 14944  loss=146.5304  steps/s=103.03  prediction: \"aster i u know its just abt authenticity\" => \"n  toetttt  t tt  t        t    ttt ttt \"\n",
      "batch 14947  loss=159.9012  steps/s=97.78  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \" toa ea   eet net    e   t   a  e e ee  \"\n",
      "batch 14948  loss=148.1151  steps/s=103.05  prediction: \"d xD but maybe its trying to communicate\" => \" tay ll leb   ybb         t   t  t  m  t\"\n",
      "batch 14949  loss=147.3604  steps/s=103.94  prediction: \"ed, its worth at least giving a shot tho\" => \"  n      s    t   t      t   t        t \"\n",
      "batch 14951  loss=154.0423  steps/s=101.93  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" poo  el ttit tl    ttt tttttttttttt////\"\n",
      "batch 14952  loss=150.7259  steps/s=103.18  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e canboch_s mC tBTI}L6T6,LBx66w6JCCCTHBx\"\n",
      "batch 14953  loss=161.6612  steps/s=101.72  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"n e aio  n     n     d        r     TTTT\"\n",
      "batch 14955  loss=159.5867  steps/s=99.61  prediction: \"ircle tool gang) https://t.co/eWviZR2Y3N\" => \"ne a c ccololo oo   oo    ttt  tt/ t////\"\n",
      "batch 14956  loss=138.8499  steps/s=104.72  prediction: \" from that channel/vid to that x account\" => \"trr  lo lol       a a      t tttt    tt \"\n",
      "batch 14957  loss=248.8997  steps/s=11.20  prediction: \"reply: @yacineMTB google necessary being\" => \"eply: @c,neneMTe@#MTB(xMTB)THE#G]:[##.,`\"\n",
      "batch 14958  loss=155.3486  steps/s=112.57  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \"  isaa aanasasa sss                     \"\n",
      "batch 14959  loss=154.8710  steps/s=103.92  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r litpe tt ttnttr      ss rr rrr rr r r\"\n",
      "batch 14960  loss=160.9806  steps/s=104.27  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" Ch     pod d eda e e    a  sssss ss    \"\n",
      "batch 14961  loss=173.4493  steps/s=53.84  prediction: \": @iliekcomputers Just steal it back bro\" => \" @srerngeme nCr gJVV=UJPUUVPU44JmKXpXðŸ˜ðŸ«¡d\"\n",
      "batch 14962  loss=147.0982  steps/s=113.30  prediction: \"nd stop you from seeking rewards in life\" => \"g eh  r  u n  u   o   o                 \"\n",
      "batch 14963  loss=144.0717  steps/s=104.88  prediction: \" extreme levels of being acoustic though\" => \"tautus isi ese ses ee   ee     ee ee    \"\n",
      "batch 14964  loss=142.2582  steps/s=102.17  prediction: \" Post it in the disc it helps us all out\" => \"tos lll s                               \"\n",
      "batch 14966  loss=156.7008  steps/s=93.49  prediction: \"builds It is factually what plants crave\" => \"atio eb  i  t t  s  i    ttt  l    l    \"\n",
      "batch 14967  loss=146.3966  steps/s=99.14  prediction: \"ood direction to get more good direction\" => \"ul benie edd dedeoooto  oo  t to  ooo oo\"\n",
      "batch 14969  loss=166.3758  steps/s=101.01  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"  g o g  g g gg  gg ggg  ttt   ttt t////\"\n",
      "batch 14970  loss=155.6958  steps/s=100.14  prediction: \"conclusion that the zig code IS the docs\" => \"omt 0i tncc o  to tth  t   t    t      h\"\n",
      "batch 14971  loss=149.5191  steps/s=101.33  prediction: \"e unbelievably interesting and beautiful\" => \" go n  e ege ebb bebbeeeeeeeeninnnneeenn\"\n",
      "batch 14972  loss=148.1574  steps/s=100.12  prediction: \"ting the entire GOL industry as we speak\" => \" nn  m  m   t nn e ee e   i             \"\n",
      "batch 14973  loss=145.3594  steps/s=104.49  prediction: \"ar mongering gets attention (clicks etc)\" => \"n s  e  esren nee  ee eeettttntttnttt  t\"\n",
      "batch 14974  loss=141.7296  steps/s=103.11  prediction: \" which uses a superset of c. so not sure\" => \"thi  hcc c cn  c     s    s s           \"\n",
      "batch 14975  loss=152.7107  steps/s=100.33  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" \n",
      "l y i mmbmmemey e   e l ll  al       e\"\n",
      "batch 14976  loss=147.8877  steps/s=105.16  prediction: \" the past two months and its so worth it\" => \"the  ot  te t et   tt     t  tt   s  s  \"\n",
      "batch 14977  loss=157.2541  steps/s=103.96  prediction: \"tem\n",
      "- SPHERE GUN https://t.co/tqM3ZpJCkN\" => \"hr  iedee  -ns-EEEEEEEE t tt//////////t/\"\n",
      "batch 14978  loss=163.3793  steps/s=46.14  prediction: \"y: @mayfer easy, just ask it what to ask\" => \"  @tas  n nEnE  EE t  t//t///////tt pttN\"\n",
      "batch 14979  loss=149.8941  steps/s=106.92  prediction: \"s of useful packages python would be ded\" => \" aa d    n s  o      s              o   \"\n",
      "batch 14980  loss=144.9314  steps/s=105.15  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yt tat  t  t tt    t   tttttttttttt////Y\"\n",
      "batch 14982  loss=141.1918  steps/s=103.74  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hln pelisiiitiiiiiitttittttttttttttt////\"\n",
      "batch 14983  loss=158.8836  steps/s=105.52  prediction: \"ay simpler, but also much more effective\" => \"n  ot e    p   p                       e\"\n",
      "batch 14984  loss=147.8172  steps/s=104.48  prediction: \"ut what it meant https://t.co/XYAZfowlv5\" => \"s    o  t t  t   tttt tt tttttttt/////tt\"\n",
      "batch 14985  loss=138.2407  steps/s=104.65  prediction: \"ideo of you doing some crazy stuff. damn\" => \"ne i t    t     o ooo ooo    o    o     \"\n",
      "batch 14986  loss=155.7555  steps/s=100.61  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"t  t    et e7  n  oo  o   e          y  \"\n",
      "batch 14987  loss=137.6160  steps/s=105.85  prediction: \"robably dont ask 'will you be my mentor'\" => \"emi is ban   9  'A'I_A'A@__M,vMZ7x7_7:z9\"\n",
      "batch 14988  loss=197.7325  steps/s=93.57  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \" vime rrb y  bd br   t tl  l tty  /  o o\"\n",
      "batch 14989  loss=163.0024  steps/s=62.50  prediction: \" @pilpulon will release v1 at some point\" => \"tgrk irrbyg r  g ht tttts  o/tts // Qo o\"\n",
      "batch 14990  loss=166.7149  steps/s=87.86  prediction: \"@djcows but yet my 5s gifs come out 50MB\" => \"seyrellrer b b l lt stssss o/ttcomeo o 0\"\n",
      "batch 14991  loss=155.5901  steps/s=109.96  prediction: \"ut you neeeeeed execution skill yourself\" => \"   w  arrrrrrr re  eee eeeeeeeeeeeee uou\"\n",
      "batch 14992  loss=143.1871  steps/s=105.48  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"   h, tenenennenennnnnnnnnnennnnonoooooo\"\n",
      "batch 14993  loss=134.5301  steps/s=104.55  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"euly b coin nMnn-IvY/&;Y!!;&-&T&-Tx//x(;\"\n",
      "batch 14994  loss=158.4823  steps/s=102.10  prediction: \"r him, thanks! Sounds useful potentially\" => \"eany  @Kan'diðŸ‘_ I'v_}I'##ðŸ‘€á´€#[#[â˜ ÊŸ[â€//,(ðŸ›‘\"\n",
      "batch 14995  loss=150.7279  steps/s=100.74  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" nina l tiin ic c ccccccscccctcccc/tt///\"\n",
      "batch 14996  loss=161.2119  steps/s=103.09  prediction: \"inful to stfu but it works suuuuper well\" => \"ng l   ls   s it    u   t ut   uuuu    u\"\n",
      "batch 14997  loss=143.9173  steps/s=102.62  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"nk ttte  agagagaaaaaaaaa aaaa a  a    LL\"\n",
      "batch 14998  loss=184.7428  steps/s=104.64  prediction: \"10^10^10^10^10^10^10^10^10\n",
      "so maybe 2064\" => \"0^10^101f ^0^^T^^10^10^v,^g0^,ygv\n",
      ",mw\n",
      "2,\"\n",
      "batch 14999  loss=220.7016  steps/s=101.68  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"B P I NANGALLAIAIILILI L S    //////////\"\n",
      "batch 15000  loss=169.5379  steps/s=104.75  prediction: \"a fckton of time https://t.co/HOKGcS3zKn\" => \"np    ttnt    a t o    t   tttt ttt c///\"\n",
      "batch 15001  loss=174.1348  steps/s=56.23  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @ses @gegcreveo^10^10^10^10::0^..MyHOOT\"\n",
      "batch 15002  loss=164.8458  steps/s=114.83  prediction: \"te wow\n",
      "\n",
      "followed https://t.co/riXL2UlhdY\" => \"hd rin   twol  owowwwwowotttttt/////////\"\n",
      "batch 15003  loss=144.1117  steps/s=105.07  prediction: \"w. Might do one every mon and every tues\" => \"i o   o rotrrortoo  o  o   o     e  eee \"\n",
      "batch 15005  loss=159.9586  steps/s=99.67  prediction: \"ace to your list https://t.co/dwHsPF5vJC\" => \"nkotooe d  t        t  tttt  ttt ttttt//\"\n",
      "batch 15006  loss=153.0270  steps/s=101.02  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"aepaae a n paaapaaappaatttttttttttt/////\"\n",
      "batch 15007  loss=141.5399  steps/s=104.94  prediction: \"his, and even then you might get mislead\" => \"es pto t      h    e   e             e  \"\n",
      "batch 15008  loss=143.1453  steps/s=102.77  prediction: \"nt and then generate a new one each time\" => \"  t  ee e nnenennneneee eeee eeee e eeee\"\n",
      "batch 15009  loss=167.4294  steps/s=105.05  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \" rk    tonnonogo o         t  tt////t///\"\n",
      "batch 15010  loss=144.5043  steps/s=100.85  prediction: \"ce for an american traveling there soon?\" => \"o p itdi an a n aaaa aaaaaaaaaa a re eee\"\n",
      "batch 15011  loss=133.9952  steps/s=105.14  prediction: \"to someone on X, its laggy when it plays\" => \"h  s  o tnnn  V                         \"\n",
      "batch 15013  loss=181.4361  steps/s=103.17  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e iiul\n",
      "=#^CCJPl xP.7.7P/ECGG8\n",
      "I\n",
      "C8KW.?Bx\"\n",
      "batch 15014  loss=145.7534  steps/s=105.14  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" yh  c  tnan a i    t ttth hhtttststttt/\"\n",
      "batch 15015  loss=150.8661  steps/s=104.03  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \" tiyt it \n",
      "it t iiittt  ts  sa s s  aa   \"\n",
      "batch 15016  loss=144.9647  steps/s=105.27  prediction: \"y abt compression, which is intelligence\" => \" bi ar   aat  tt   t   i   iii issiiiii \"\n",
      "batch 15017  loss=159.1162  steps/s=104.56  prediction: \"ying/whatever, every monday and thursday\" => \":n oioo/in/gingggnneveeevereeeeeeey ddd \"\n",
      "batch 15018  loss=172.0431  steps/s=96.30  prediction: \"nus9 Thats super useful to know actually\" => \"g/aodgnnh Tisu eeess e euu u uu   u  u  \"\n",
      "batch 15019  loss=157.6808  steps/s=104.31  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"tonn leeere  l   uuuu ur   ttttt/tt/////\"\n",
      "batch 15020  loss=170.2621  steps/s=72.90  prediction: \"yacineMTB Its addicting stuff be careful\" => \":ncnecicelu  rr     t tittttt////////qZZ\"\n",
      "batch 15021  loss=184.7985  steps/s=116.50  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"ene iorn I r    ot..ddtttt..//ttc/:ZZc/Z\"\n",
      "batch 15023  loss=174.1985  steps/s=104.87  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OOOO\n",
      "f   n nn          d   tttttt///////\"\n",
      "batch 15024  loss=155.6625  steps/s=102.03  prediction: \"h, that explanation/example makes sense'\" => \"e    hh     a taaaaaaaaaxxxaaaeaaaeeeeee\"\n",
      "batch 15025  loss=150.1256  steps/s=101.07  prediction: \" im pretty screwed when we play sap then\" => \"ts es  ee t   s   eeee e eeee ee  w    e\"\n",
      "batch 15026  loss=154.1634  steps/s=104.57  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"n boo   kkktV VV  t  tt ttttttttt//tt/tt\"\n",
      "batch 15027  loss=152.2373  steps/s=102.42  prediction: \"ted to see how cracked you get long term\" => \" r p oeer teteeee  e eeeee     e e e    \"\n",
      "batch 15028  loss=162.8472  steps/s=102.58  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n  ittttmgmimmmimiiiiiiizznzziiiziiiiii \"\n",
      "batch 15030  loss=150.0835  steps/s=105.44  prediction: \"ve gradient it lives in? Something else?\" => \"er  tt  ttenniiiiieiiiiiiiii i      e ee\"\n",
      "batch 15031  loss=138.1559  steps/s=105.13  prediction: \" different distribution of training data\" => \"iov eveeeh  n eeeeeeetttiititiiiiiiinini\"\n",
      "batch 15032  loss=139.5630  steps/s=100.11  prediction: \"ot a lot of sleep last night, feels good\" => \"u  se t  t  oo    o l   l        t  eee \"\n",
      "batch 15033  loss=146.7861  steps/s=102.42  prediction: \"pany uses it often for researching stuff\" => \"lep  yonommom  oo o    o o   e  r   r  r\"\n",
      "batch 15034  loss=160.0324  steps/s=81.23  prediction: \"calbach_ thanks! hope its useful for you\" => \"olp  y  s an   eo nf   ooee ses r e rfff\"\n",
      "batch 15035  loss=146.9826  steps/s=110.96  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"a cy@ on   noono oooo oooottoooto o     \"\n",
      "batch 15036  loss=143.4762  steps/s=104.68  prediction: \"the most useful? https://t.co/w0tVqarS34\" => \"hes  r  tre    e  tte t tttstttttt//tttt\"\n",
      "batch 15037  loss=154.3580  steps/s=103.99  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \"pmriEs eeenene s ess  es s          er r\"\n",
      "batch 15038  loss=141.6471  steps/s=99.27  prediction: \"ews on the internet\n",
      "id say it worked lol\" => \"   e @i   nn   n  n n  ee  e e tt   i   \"\n",
      "batch 15039  loss=177.5678  steps/s=103.83  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..co  ooo//o/oo///ototttt/ttttt////t///\"\n",
      "batch 15040  loss=146.3406  steps/s=105.77  prediction: \"ool\n",
      "\n",
      "Maybe youll be the dude to crack it\" => \"nl  holoo cooooooooo                    \"\n",
      "batch 15041  loss=137.0275  steps/s=100.92  prediction: \"he race to steal the eu tech bros begins\" => \"e  o c ae c  en       e  e e eee   e  e \"\n",
      "batch 15042  loss=153.0037  steps/s=103.97  prediction: \"would be insanely useful to do this with\" => \"hrkne   rn eu   ee ie eeuu uul      e   \"\n",
      "batch 15043  loss=138.8486  steps/s=100.67  prediction: \"ot a lot of sleep last night, feels good\" => \"n  se t  tttoo    o l   l  l     t   ee \"\n",
      "batch 15044  loss=164.4493  steps/s=105.11  prediction: \"ynch Its official im naming my kid movie\" => \":c dade nn@nn nt  f  f ii ii iiiiimim mi\"\n",
      "batch 15045  loss=145.6974  steps/s=106.20  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n    i   hdd   t  i   d  AAA d   i   d d\"\n",
      "batch 15046  loss=161.9791  steps/s=93.02  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"hlng   dtt o   t MMM  o   od  d  t   O e\"\n",
      "batch 15047  loss=188.8250  steps/s=23.77  prediction: \"eply: @bozo10n you can just build things\" => \" ly: @s nertt t  MM   o   oo  d  t e e e\"\n",
      "batch 15048  loss=144.0039  steps/s=108.45  prediction: \"y abt compression, which is intelligence\" => \":ai ta   aat  tt   a   i   iii issiiiii \"\n",
      "batch 15049  loss=162.5627  steps/s=103.56  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"n    e eneieeeieeiiii   pp ptttttptttt//\"\n",
      "batch 15050  loss=144.9671  steps/s=104.37  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" t   nw  n     w        i i  ee eeeeeee \"\n",
      "batch 15051  loss=149.7861  steps/s=103.35  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"efw u   t ntto\n",
      "too                  t  t\"\n",
      "batch 15052  loss=139.0810  steps/s=104.94  prediction: \"et back up and get back at it eventually\" => \" t it   tawt  a                         \"\n",
      "batch 15053  loss=144.2999  steps/s=103.87  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"ywes nt slne e  e eeleeee eeeelllll\n",
      "\n",
      "\n",
      "ll\"\n",
      "batch 15054  loss=149.4563  steps/s=104.58  prediction: \"s it and im unaware (would love to know)\" => \" a  .t  tnhn  n                      o  \"\n",
      "batch 15055  loss=138.9904  steps/s=104.06  prediction: \"e forever with a simple 5min interaction\" => \"rsinsee efefeeffe               iiiiiiii\"\n",
      "batch 15056  loss=164.4241  steps/s=84.48  prediction: \"y_builds i wouldrather shootmyself loool\" => \"  o eeeennf i i    i e      i    m tttnl\"\n",
      "batch 15057  loss=173.1568  steps/s=106.16  prediction: \"/t.co/gufhF6ZVD6 https://t.co/0ldvn5Oi6t\" => \"/.c  t t :///t///66/666t6t////ttt////t//\"\n",
      "batch 15059  loss=169.6035  steps/s=100.08  prediction: \"? nah, blocktard https://t.co/bYxFfo7Sue\" => \" Dorw tooh oaoa to otttth  tttt////t////\"\n",
      "batch 15060  loss=172.4254  steps/s=82.07  prediction: \"dwigABAP Big win, love it, great job man\" => \" its trat g a t ht   ttt, tt/tt/t/t7toto\"\n",
      "batch 15061  loss=145.8887  steps/s=105.93  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng it i nwiid w  dd dddd dddod d        \"\n",
      "batch 15062  loss=138.4704  steps/s=100.62  prediction: \" least its not opengl like this poor kid\" => \"tiac  T   ttt ttt t t   t            i e\"\n",
      "batch 15063  loss=145.4454  steps/s=104.83  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"ype  t  t it tt    t   tttttttttttttttto\"\n",
      "batch 15064  loss=158.9643  steps/s=21.11  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"nt:     t t tt     t   ttttttttttooootYo\"\n",
      "batch 15065  loss=145.5830  steps/s=107.84  prediction: \" and the professor thought it was a typo\" => \"t  a ii \"iid                            \"\n",
      "batch 15066  loss=158.6120  steps/s=103.81  prediction: \" I gotta make the disc announcement oops\" => \"t  t  h totht h tt   to   ta  ae    e   \"\n",
      "batch 15067  loss=159.4091  steps/s=102.88  prediction: \"ly bc i want one https://t.co/AySfEijpuc\" => \"y: @ sd  ti t         t   ttttt//t/t//t/\"\n",
      "batch 15068  loss=145.9999  steps/s=102.87  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"tlda iht  tth    tttttttstttttttt/t/////\"\n",
      "batch 15069  loss=153.7672  steps/s=102.61  prediction: \"enjoyable is such a gargantuan advantage\" => \" ti  hagngg nnn      s aaaaaaaaanaa aaaa\"\n",
      "batch 15070  loss=150.2201  steps/s=104.31  prediction: \"mped billions/decades into w no solution\" => \"arii er  d  ee ddddeedd idded d    o oo \"\n",
      "batch 15071  loss=175.1675  steps/s=51.73  prediction: \": @pindjouf @thomasbocquet7 ayyy lets go\" => \" @tabi otn@jd,ea@@WW0,/WWcqW\",7kQO/kkcSf\"\n",
      "batch 15072  loss=147.6488  steps/s=106.54  prediction: \"ng, dunno why this flew over my head lol\" => \"g ools nni   nu nt  n n n               \"\n",
      "batch 15073  loss=141.9775  steps/s=101.43  prediction: \"gonna code to one song and one song only\" => \" o   iin n  nonn o    ooo o nn  oon nnn \"\n",
      "batch 15074  loss=138.6523  steps/s=103.58  prediction: \"useful directions to take the project in\" => \" 9   ffefefeeeueee   e tt t tt tttt  tt \"\n",
      "batch 15075  loss=136.3743  steps/s=103.95  prediction: \"works for the first time is the most fun\" => \"irk @ et t  r  r  r     r    t  t   t   \"\n",
      "batch 15076  loss=156.9777  steps/s=94.27  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"h  tore tor tt r  tt   tt s  stt tt/tt/t\"\n",
      "batch 15077  loss=150.7287  steps/s=110.12  prediction: \"TB elon lived in leafland for a bit iirc\" => \"h  tore enee elli e  iie l l lf   o    i\"\n",
      "batch 15078  loss=159.6242  steps/s=80.90  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \"   re@nnlinili  i e l ee foo of      i  \"\n",
      "batch 15079  loss=136.2213  steps/s=106.78  prediction: \"useful directions to take the project in\" => \" e   ffefefeeeueee   e tt t tt ttt   tt \"\n",
      "batch 15080  loss=148.8055  steps/s=105.01  prediction: \"ve gradient it lives in? Something else?\" => \"er  tn  ttenniiiiieiiiii iii i      e ee\"\n",
      "batch 15081  loss=181.5518  steps/s=95.04  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" iee  enereeeeejjeee     tt  tttt ///eee\"\n",
      "batch 15082  loss=151.1418  steps/s=101.53  prediction: \"uth is the global maxima strat long term\" => \"   centi ttt t tt        a    aaaaaaaaaa\"\n",
      "batch 15083  loss=154.1077  steps/s=106.12  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"eplou @ kkJ  &  ;kPPPj@xPPjPPP,:G-v&0;;9\"\n",
      "batch 15084  loss=147.3122  steps/s=102.90  prediction: \"f this song and never listen to it again\" => \" mouri et   s  s  s    n   n     n      \"\n",
      "batch 15085  loss=135.3716  steps/s=105.60  prediction: \"this is the same as the place where theâ€¦\" => \"hi   t t i    e                  eeeeeee\"\n",
      "batch 15086  loss=170.8020  steps/s=100.10  prediction: \"e77 build things people want/ need maybe\" => \" 7ie @cie777777      i  l   ppp eeee   e\"\n",
      "batch 15087  loss=159.8161  steps/s=103.75  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"iekd od  n  n)n ))                    ff\"\n",
      "batch 15088  loss=144.6504  steps/s=104.71  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng fo no no(( ng                 uuuuuu \"\n",
      "batch 15089  loss=182.9817  steps/s=52.33  prediction: \": @yacineMTB better start skilling up ig\" => \" @palan a\n",
      "(jtM  jRRRRvR_@@@@@â™‚v@XXXXXXXX\"\n",
      "batch 15090  loss=144.7818  steps/s=108.42  prediction: \"of time has been the problem in the past\" => \"u ttfe   t           e    eee ee  e   e \"\n",
      "batch 15091  loss=145.8252  steps/s=104.46  prediction: \"ight radius\n",
      "Hmm 5px or 5%? Maybe 4.9%...\" => \"nA at thnthtt it   t     555555      %%%\"\n",
      "batch 15092  loss=150.2362  steps/s=104.10  prediction: \"rflowsucks and never went on there again\" => \"eao   n i Cn Rge2R12RRQ12Q12RRR12RQGGGGG\"\n",
      "batch 15093  loss=146.5785  steps/s=103.98  prediction: \"ingly, doable) youre in for a goood time\" => \"ng  e assryrrri y yryyy o  r  oo o  oo o\"\n",
      "batch 15094  loss=152.4514  steps/s=104.92  prediction: \"amount of time, or did you just enjoy it\" => \"ne       i n   n  o o      oo        jj \"\n",
      "batch 15095  loss=143.5546  steps/s=104.05  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"81 ia       t         hhhttttt//////////\"\n",
      "batch 15096  loss=164.0918  steps/s=81.56  prediction: \"phones Thanks man! its going well so far\" => \"le: @an hn    hkhht tt ///ttttggtttV  UU\"\n",
      "batch 15097  loss=156.6509  steps/s=106.22  prediction: \"otten most of my follows from Yacine lol\" => \"u e etee etttte     t  o   o  ooo   f  o\"\n",
      "batch 15098  loss=168.2041  steps/s=59.16  prediction: \" @Wooltard me too\n",
      "Im the lowercase wojak\" => \"aBr oeot  tet  m   om  o f o oof       l\"\n",
      "batch 15099  loss=141.7596  steps/s=108.74  prediction: \" to get tons of llms to output good code\" => \"theet et tgttt tt  o       o     ooo  oo\"\n",
      "batch 15100  loss=171.1529  steps/s=69.60  prediction: \"ludwigABAP its all slop tier, always was\" => \"ydgith tt gto tttt   o  oo ot  oooo   oo\"\n",
      "batch 15101  loss=153.2619  steps/s=109.11  prediction: \"ogan?? was he on sidetweets or something\" => \"  wowig   ?o ?s          e e eeee ssseee\"\n",
      "batch 15104  loss=218.0664  steps/s=10.96  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"eply: @taBvPn*tAPTIj$*TIj}ðŸ¤”|#á´„,}k#?,[jQk\"\n",
      "batch 15105  loss=162.8500  steps/s=163.49  prediction: \"yan I have fun. does that make me a CEO?\" => \":celna?a  n a    h    e   eee s t  e ee \"\n",
      "batch 15106  loss=156.6725  steps/s=104.20  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"eply   inqMknRaoIRfRMTB/@ETB/@ExRRjqUCEO\"\n",
      "batch 15107  loss=141.2424  steps/s=100.10  prediction: \"ood and helps you not waste future years\" => \"  ro      o          o       o         u\"\n",
      "batch 15108  loss=139.3775  steps/s=99.94  prediction: \"lves and destroy it all for local optima\" => \"ye iece s sreeses s  e   l l   l l l l  \"\n",
      "batch 15109  loss=186.4603  steps/s=46.09  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"y: @ee   esree  r s  s   l l   lll l l  \"\n",
      "batch 15110  loss=160.5988  steps/s=126.02  prediction: \"n just do things https://t.co/909bTHzmml\" => \" lii so st  n   t t  ttt s tt/tt/t//9/9/\"\n",
      "batch 15111  loss=188.4886  steps/s=21.29  prediction: \"eply: @Nominus9 should be out soon   : D\" => \" ly: @s nettn jtt ttsttt/sstt/tt////9/9/\"\n",
      "batch 15112  loss=175.4176  steps/s=119.52  prediction: \": @pindjouf @thomasbocquet7 ayyy lets go\" => \" @tudsa inBâ€™_Fee@\n",
      "f,Mjmb@7qm.:7/f.jO490D\"\n",
      "batch 15113  loss=149.8484  steps/s=106.85  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"toe e  endetdeoe     e eCCCICCCIIIIn nnn\"\n",
      "batch 15114  loss=148.7783  steps/s=102.25  prediction: \"x reddit is the strange people attractor\" => \" et@eetexxxxee teee   e ee    eeteee tte\"\n",
      "batch 15115  loss=221.7452  steps/s=101.61  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOEr OOOOOOOOOOOOOOOOOOOOOtt pt/tttJJ\"\n",
      "batch 15116  loss=212.6769  steps/s=21.81  prediction: \"eply: @ludwigsonneck Did you learn/grow?\" => \" ly: @ OOOOOOOOOOOOOOOOGGOppett tt//tJJJ\"\n",
      "batch 15117  loss=162.0494  steps/s=125.78  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"neMTB e dedd  d    d    ttt ////t////t/t\"\n",
      "batch 15118  loss=154.2507  steps/s=97.50  prediction: \" pieces until you have solved the puzzle\" => \"@o   oee ee e  n  e            vv   e   \"\n",
      "batch 15119  loss=192.4410  steps/s=98.53  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"ere  eyz@o oz @Wo 72277727777ot tt/z///t\"\n",
      "batch 15120  loss=157.3649  steps/s=102.62  prediction: \"illed w AI tools https://t.co/AIn5typg7l\" => \"nl  nt  n l t            ttttttttttttt//\"\n",
      "batch 15122  loss=153.3222  steps/s=99.55  prediction: \"oure italian too\n",
      "and youre based\n",
      "\n",
      "basado\" => \"uttu ne   ttt ut o  oo ooooooo aooo\n",
      "\n",
      "\n",
      " \n",
      "\"\n",
      "batch 15123  loss=144.7066  steps/s=105.36  prediction: \"u a why/a vision for hard work over time\" => \"sgoe  e  w    h  i     i     o      rr  \"\n",
      "batch 15125  loss=155.1612  steps/s=103.88  prediction: \"plex projects in it but it was super fun\" => \"ly:  p e   ee cce  e                    \"\n",
      "batch 15126  loss=138.9390  steps/s=105.94  prediction: \"ad a concept of \"I\" they would probablyâ€¦\" => \"no          c  c                        \"\n",
      "batch 15127  loss=142.8674  steps/s=103.49  prediction: \"nces contains homotopies (find them idk)\" => \" e stat esnseeeneennonoooooooooooiiiii i\"\n",
      "batch 15128  loss=149.4113  steps/s=104.92  prediction: \"mped billions/decades into w no solution\" => \"el\n",
      "ioeb  dd ee ddddeedd idde  d    o oo \"\n",
      "batch 15129  loss=166.8353  steps/s=94.19  prediction: \"uff @allgarbled Ah, true, nice inversion\" => \"tf meutuilllllllaall  lll        ,   iii\"\n",
      "batch 15130  loss=150.3866  steps/s=100.09  prediction: \"inlet like me to test experiments out on\" => \"nkc   er  re    e    ee  eee  e etettett\"\n",
      "batch 15131  loss=143.4135  steps/s=105.69  prediction: \" about it and in 1 weekend jumped up 200\" => \"t de  a  a                   e      e  e\"\n",
      "batch 15132  loss=149.9193  steps/s=104.46  prediction: \"amount of time, or did you just enjoy it\" => \"ne i i   iin   n  o o      oo       u   \"\n",
      "batch 15133  loss=158.5143  steps/s=103.70  prediction: \"tively\n",
      "100k ppl? 1mil? 100mil?\n",
      "98% of X?\" => \"hnn i  otlilili0ll l1l1?1110???0?0000 0 \"\n",
      "batch 15134  loss=155.8960  steps/s=104.51  prediction: \"rs automatically slap that down to 10fps\" => \"e eer n bhn s2e @jO?Ij\n",
      "cI:5jvIO,50x98,'1\"\n",
      "batch 15135  loss=194.2880  steps/s=21.15  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @sr gss attosssa  saa atatat tt tt \"\n",
      "batch 15136  loss=169.3954  steps/s=145.83  prediction: \"2wlearning Great stuff man, keep pushing\" => \"5 i5s ersortiat rsssa  saa a at t tt   p\"\n",
      "batch 15137  loss=151.0465  steps/s=108.24  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \".dh co leld.d r  e          ttt///////PP\"\n",
      "batch 15138  loss=154.5184  steps/s=98.05  prediction: \"eadphones dead gonna recharge real quick\" => \" rale heehhhd deeddd  nn   o arrrnararrc\"\n",
      "batch 15139  loss=138.1610  steps/s=105.40  prediction: \"sfully improved their lives tremendously\" => \"  buestf uese  seeeeeee ee eeee eeeeee e\"\n",
      "batch 15140  loss=152.3958  steps/s=101.14  prediction: \"an esopost to english translator service\" => \"ng r  e ee o e  e  e ee s  s st t st ssr\"\n",
      "batch 15141  loss=146.7615  steps/s=104.07  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \".hh cr le d.deh  e          ttttt///////\"\n",
      "batch 15142  loss=145.7058  steps/s=104.04  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t le  s  r            o  t t:t:/tt/tt///\"\n",
      "batch 15143  loss=149.7314  steps/s=105.22  prediction: \"nt properties. huts dont have penthouses\" => \"g  h etrernnerteeereeett ett   t  t t   \"\n",
      "batch 15144  loss=160.2596  steps/s=80.65  prediction: \"cows a truly great ideasguy will execute\" => \"oune preortetretre   ett  se   e    e   \"\n",
      "batch 15145  loss=157.3371  steps/s=82.19  prediction: \"love spending 30mins debugging a typo :D\" => \"yne e   e t  r. r    ees  see  g    e e \"\n",
      "batch 15146  loss=151.9194  steps/s=107.63  prediction: \"i know bedrock api has a chat window too\" => \"nh na t t ob  bbk          a   a a    a \"\n",
      "batch 15148  loss=160.1307  steps/s=74.63  prediction: \"izmobly @juweeism i can try to help haha\" => \"n  nt   b n k no    i a   aa   a a    oo\"\n",
      "batch 15149  loss=143.3023  steps/s=106.43  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \" ead in n\n",
      "nnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nnw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ogggoono\"\n",
      "batch 15150  loss=135.5459  steps/s=105.20  prediction: \"en clusters into single tokens like this\" => \" t te eeteetn  tt    s      s      kkk k\"\n",
      "batch 15151  loss=144.4315  steps/s=106.49  prediction: \" not super out of alignment with reality\" => \"toe  sn n nnn uu  u     o   e  n     t  \"\n",
      "batch 15152  loss=140.7862  steps/s=104.48  prediction: \"ard to realize. lies are really blinding\" => \"np  o r nn a   aa         eeeeeeelllllll\"\n",
      "batch 15153  loss=166.3280  steps/s=76.85  prediction: \"paeoh do it man!! making games is so fun\" => \"lrn  h ra    ie i  aa!!  eaeee  lll i il\"\n",
      "batch 15154  loss=137.6491  steps/s=106.79  prediction: \"my efficiency. But overall cause its fun\" => \"e t  ot s  ee fee                       \"\n",
      "batch 15155  loss=142.9589  steps/s=104.09  prediction: \"ite complexity? If not, what is the max?\" => \"niin  ii niniiitiii i                   \"\n",
      "batch 15156  loss=160.6774  steps/s=100.75  prediction: \"ot even... this? https://t.co/vAkhEpFVm1\" => \"u t nctne n et . ....tttt tttt tt///////\"\n",
      "batch 15157  loss=174.1650  steps/s=35.86  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @ccnnenn...nn..tt ttttttt///t//////hh\"\n",
      "batch 15158  loss=139.4453  steps/s=111.71  prediction: \"mals have uncanny valley detection genes\" => \"ent e   sas        aaaaaaaa  aa  ee enne\"\n",
      "batch 15159  loss=156.4123  steps/s=103.14  prediction: \"aftinginterpreters\n",
      "- got back into 3d pâ€¦\" => \"nten    erteeterertrrrerertrrrtttttt    \"\n",
      "batch 15160  loss=156.7263  steps/s=103.24  prediction: \" I gotta make the disc announcement oops\" => \"t ot  h totht h tt   to   ta  at    e   \"\n",
      "batch 15161  loss=138.2783  steps/s=102.11  prediction: \"lgorithms\n",
      "Get better learning algorithms\" => \"yareyo   g   iet teetttttteeeeeeeeererrr\"\n",
      "batch 15162  loss=160.4610  steps/s=103.61  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "e     dhd s eda e e       sssss ss    \"\n",
      "batch 15163  loss=143.2421  steps/s=104.71  prediction: \"ht. i feel like i barely understand them\" => \"es e n      l              e   ee ee e e\"\n",
      "batch 15164  loss=149.4934  steps/s=104.99  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng e   o in   I                         \"\n",
      "batch 15165  loss=165.3877  steps/s=39.42  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y  @ o ondn   Id    I                   \"\n",
      "batch 15166  loss=150.0725  steps/s=109.24  prediction: \"tebooks with 45 cells each, 4 docker imâ€¦\" => \"hd se  oenoonoon  o         e       ce  \"\n",
      "batch 15167  loss=160.9248  steps/s=66.96  prediction: \"justalexoki its tpot, all lowercase only\" => \"ust o nonotnno k  t   t    l    cec ce  \"\n",
      "batch 15168  loss=151.2435  steps/s=105.23  prediction: \" drains your energy by paying attentionâ€¦\" => \"auat yh  nn n gr      y yyyyyy yyyy   nn\"\n",
      "batch 15169  loss=141.7608  steps/s=102.49  prediction: \"ould color their pill white for the lolz\" => \"uttn ynll to  l oo    ll     l     t    \"\n",
      "batch 15170  loss=137.4499  steps/s=105.39  prediction: \" does blade+motor=tablesaw or battlebot?\" => \"ten erhrretteeeseeoeoooooeoaeoaotbabbtbb\"\n",
      "batch 15171  loss=143.2043  steps/s=105.57  prediction: \"learn and have fun building baller stuff\" => \" ae  ln owon  p  n   n       n  nn  llll\"\n",
      "batch 15172  loss=143.0974  steps/s=104.41  prediction: \"otential for small - very small things.â€¦\" => \"u  o tnot tot  t                llllll  \"\n",
      "batch 15173  loss=150.5287  steps/s=102.31  prediction: \"p. maybe you can figure out how to do it\" => \"l     aim m m m                         \"\n",
      "batch 15174  loss=227.3202  steps/s=11.23  prediction: \"reply: @dwbypass https://t.co/k3grlVSm53\" => \"eply: @beheu D  PD@X:2/@22DD\"2jD.2V\"Q536\"\n",
      "batch 15175  loss=144.2747  steps/s=152.05  prediction: \"cking it was kobe posting the whole time\" => \"heaa@in lod c          oo   oo  o  tt   \"\n",
      "batch 15176  loss=177.2821  steps/s=104.39  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tte  edeeddeeeee        t  ttttttt////SS\"\n",
      "batch 15177  loss=179.6724  steps/s=103.58  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \"NSOTGADTNDAAT AA A    CC  A     / t/t//t\"\n",
      "batch 15178  loss=147.9800  steps/s=104.67  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"h re tr     n   e    e  e t  //tttt////t\"\n",
      "batch 15179  loss=162.9115  steps/s=103.40  prediction: \"??\n",
      "\n",
      "oh wow it is https://t.co/dShiVDjfFr\" => \"\n",
      "\n",
      "\n",
      "en w ?h?? wn ww w   o   t  ttt///////\"\n",
      "batch 15180  loss=134.9088  steps/s=102.11  prediction: \"d so i felt the need to post the way out\" => \" bn  siddi                              \"\n",
      "batch 15181  loss=147.9641  steps/s=101.45  prediction: \"lex code across multiple (simple!) Files\" => \"ym o no cn  co ccccc c   lll lll lll lll\"\n",
      "batch 15182  loss=143.4242  steps/s=105.26  prediction: \" and the professor thought it was a typo\" => \"t ta ii\"\"i d                         t  \"\n",
      "batch 15183  loss=164.7647  steps/s=46.90  prediction: \"y: @sebby_builds Japan sounds way better\" => \": @l ni    dd            h t        ttt \"\n",
      "batch 15185  loss=188.3379  steps/s=79.46  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \": @d ni       d s   o   ssot        ttt \"\n",
      "batch 15186  loss=143.7326  steps/s=105.85  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"h g\n",
      " is  s f                            \"\n",
      "batch 15188  loss=193.1133  steps/s=64.05  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" li ii   off     lll              n  nnn\"\n",
      "batch 15189  loss=150.0894  steps/s=104.84  prediction: \"high quality patches they send to FFmpeg\" => \"esk t nh ghhth h hh    hhh    t    t  e \"\n",
      "batch 15190  loss=145.4641  steps/s=105.03  prediction: \"did it again w feedback itd be the paper\" => \" ff  icd dt d i                         \"\n",
      "batch 15191  loss=210.1113  steps/s=20.88  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: d ddi d                            \"\n",
      "batch 15193  loss=203.1038  steps/s=36.36  prediction: \"reply: @helscom OF NOTHING\n",
      "IN PARTICULAR\" => \"ep y: @okr%;oRerv__&,L@%&xI&yP/5RI%/&55J\"\n",
      "batch 15194  loss=146.0742  steps/s=111.41  prediction: \" :D to the world\n",
      "https://t.co/um6G18Q1N8\" => \"t le  s  l            o  t t t::ttttt///\"\n",
      "batch 15195  loss=144.4379  steps/s=104.75  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tarn t i r    e         t ttttttt///////\"\n",
      "batch 15196  loss=179.5936  steps/s=51.68  prediction: \": @Noahpinion lack of speed/growth kills\" => \" @supve lyv# Ren7XNOTLINGwIN4zARTv44GAR:\"\n",
      "batch 15197  loss=144.5507  steps/s=106.49  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng  oo o n ng nn                 uuuuuu \"\n",
      "batch 15198  loss=162.8755  steps/s=45.96  prediction: \"y: @mayfer easy, just ask it what to ask\" => \"  @los  negnge    uu    u   o   uuu o   \"\n",
      "batch 15199  loss=143.8079  steps/s=110.74  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"et2y eiery^2k*@ ð—¿1,[j$á´›Êœå€‘á´ÊŸ]É´}#$#}*ð—¶]$å§#\"\n",
      "batch 15200  loss=159.0096  steps/s=68.20  prediction: \"love spending 30mins debugging a typo :D\" => \"ywa n  aa naen\n",
      "\n",
      "n n  rrr rrrre   tt     \"\n",
      "batch 15201  loss=153.9357  steps/s=116.60  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \"hln  o letagneg in   odd d nnnn  tno  o \"\n",
      "batch 15202  loss=192.2525  steps/s=45.04  prediction: \"y: @EsotericCofe https://t.co/qJ19YldyDK\" => \": @aae enenoo ooio    ddnd nnnn    o  o \"\n",
      "batch 15203  loss=149.8309  steps/s=121.98  prediction: \"x reddit is the strange people attractor\" => \"aea@xetexteTee teet t e  t    ee   e ete\"\n",
      "batch 15204  loss=150.8543  steps/s=102.76  prediction: \"would be insanely useful to do this with\" => \" rl     uuueu   ee ie ee u ull      e   \"\n",
      "batch 15206  loss=165.6204  steps/s=98.35  prediction: \"B the layers must go up\n",
      "RAISE THE LAYERS\" => \" @gidne   een s eesseuu  u uu       EE E\"\n",
      "batch 15207  loss=150.7211  steps/s=103.14  prediction: \"d of just putting in more and more hours\" => \" on  ini t t  ttt tttt t                \"\n",
      "batch 15208  loss=146.1369  steps/s=101.56  prediction: \"ng and converged to guessing really well\" => \"g  ee ennd n  nen      e ggggggggg   g e\"\n",
      "batch 15209  loss=202.2952  steps/s=21.34  prediction: \"eply: @Nominus9 should be out soon   : D\" => \" ly: @n nen nn nn      e ggggggggg  e el\"\n",
      "batch 15211  loss=148.7842  steps/s=154.94  prediction: \"xoki How do I know this isnt a lie tho ðŸ¤”\" => \"akoike an n  o   o    o  n t s  i    lll\"\n",
      "batch 15212  loss=150.6774  steps/s=103.15  prediction: \" it that one RL phd keeps talking abt it\" => \"ts t  tttttttttt                        \"\n",
      "batch 15213  loss=132.0424  steps/s=103.10  prediction: \"sire, and if it sounds good to them\n",
      "\n",
      "idk\" => \" cl  en ett t  i  i           o  o  oooo\"\n",
      "batch 15214  loss=148.0993  steps/s=104.48  prediction: \"up computing 'why' for free all the time\" => \"s    ae   n n        '''''              \"\n",
      "batch 15215  loss=135.2463  steps/s=103.87  prediction: \"oncept but also show you how to apply it\" => \"n e  eb cecc cn       o    o  ooo oo  o \"\n",
      "batch 15216  loss=142.9776  steps/s=104.11  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"  btn e ccneee eeeeeeeeeeettt:t/t//t////\"\n",
      "batch 15217  loss=147.8280  steps/s=101.66  prediction: \"king useful things, so it didnt work out\" => \"el   e   k k  n                         \"\n",
      "batch 15218  loss=141.0357  steps/s=104.23  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \" ce pbliiiiitiiiiiitttitttttttttttt/////\"\n",
      "batch 15219  loss=142.9483  steps/s=105.97  prediction: \" (by trusting in ideas) and testing them\" => \"ty te    htt tnt     i                  \"\n",
      "batch 15220  loss=139.5544  steps/s=104.99  prediction: \"r the picture\" for any industry or niche\" => \"etee  eeehs eá´¡aekv][,W$$TÊŸ\"W,X$v#I'Tâ€v$_\"\n",
      "batch 15221  loss=144.2314  steps/s=102.53  prediction: \"ven a bit is a huge anti pattern i think\" => \"emo tveeebn n beii            a    tt   \"\n",
      "batch 15222  loss=145.0639  steps/s=104.74  prediction: \"interested to hear how well it works our\" => \"ng  e   n d t ete eeee e     e          \"\n",
      "batch 15223  loss=142.4106  steps/s=104.52  prediction: \"10mins on a puzzle just try ur best gues\" => \"  0 1e@0 cds 6d 66j66106kj66f6**YPPPP5kâ€¦\"\n",
      "batch 15224  loss=162.0685  steps/s=103.48  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "w\n",
      " a  phd d\n",
      "eda e e    a  ssss  ss    \"\n",
      "batch 15225  loss=143.9209  steps/s=105.36  prediction: \"e info produced by exploring new options\" => \" iaaniin n n   nn        d  e         o \"\n",
      "batch 15226  loss=155.0946  steps/s=100.25  prediction: \" thought they became ugly when they fell\" => \"the   e dhh   ht    e e       e    e  ee\"\n",
      "batch 15227  loss=142.0466  steps/s=105.15  prediction: \"r coding lol. And some chess. Great move\" => \"est tmeeeewheAne79â€¦+(+â€¦kâ€¦Bâ€¦vâ€¦@xv(Z..AA+%\"\n",
      "batch 15228  loss=164.7668  steps/s=103.87  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"t.Ve  :.. .: X:XtX PP3Ptt3:///:t:ttt./Qt\"\n",
      "batch 15229  loss=141.0417  steps/s=104.36  prediction: \"orthless. you find the gold when you dig\" => \" edeslee semss sss                      \"\n",
      "batch 15230  loss=145.6968  steps/s=103.23  prediction: \"om the distribution of (single response)\" => \"np frrf fee r r ii riitiii iii  ii  i   \"\n",
      "batch 15231  loss=143.1718  steps/s=102.97  prediction: \"e money now bc you can get 10x more done\" => \" i n e eenene me                        \"\n",
      "batch 15232  loss=162.1105  steps/s=92.81  prediction: \"yan I have fun. does that make me a CEO?\" => \":c n m e  nen  n o    n    e    a    m  \"\n",
      "batch 15235  loss=149.4969  steps/s=104.70  prediction: \"nt properties. huts dont have penthouses\" => \"  fh ttrernnerpeeereeett ett   t  t t   \"\n",
      "batch 15236  loss=157.0199  steps/s=103.38  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \"st e       l     ... ..   ....../ct////t\"\n",
      "batch 15237  loss=143.2110  steps/s=104.41  prediction: \"per curious to see what youre working on\" => \"lrd  sa rn    io                   o    \"\n",
      "batch 15238  loss=144.5484  steps/s=104.24  prediction: \"hat easy guys, you learn like way faster\" => \"et t ae lht   a y yyy yyy              a\"\n",
      "batch 15239  loss=152.3514  steps/s=100.10  prediction: \"ressure either turns to dust or to a gem\" => \"eply:  Bini  zt JIz,F70Mj7IBRbBFPkbBjP1)\"\n",
      "batch 15240  loss=186.5120  steps/s=82.12  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"ese or  rer seeeereeett  utttss tt  o X \"\n",
      "batch 15241  loss=145.7178  steps/s=110.06  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \"ha  h n snee k th nnseteeheseeee ee   u \"\n",
      "batch 15242  loss=144.8475  steps/s=102.80  prediction: \"m, are also used in calculating/thinking\" => \"o se sre    t         e    a    lallliii\"\n",
      "batch 15243  loss=145.4159  steps/s=108.88  prediction: \"ely the case for chess and debugging imo\" => \" l ete eene se e     e        s   dn ggg\"\n",
      "batch 15245  loss=170.8094  steps/s=83.32  prediction: \"io2 @ludwigABAP the nightmare never ends\" => \"n2 elytii e2 e f    A   hh   nggenggg  e\"\n",
      "batch 15247  loss=155.2679  steps/s=108.21  prediction: \"file llm editing stuff is the future imo\" => \" nl t  lllefellilllliiiiii if fe fft    \"\n",
      "batch 15248  loss=152.2242  steps/s=100.37  prediction: \" it.\n",
      "Story sounds pretty interesting btw\" => \"@m  i e o r ro   ro o r    tytt rttttett\"\n",
      "batch 15249  loss=142.6792  steps/s=105.17  prediction: \"w. Might do one every mon and every tues\" => \"h oe  o rotrrortoo  o  o   o        ee  \"\n",
      "batch 15250  loss=155.7509  steps/s=103.45  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \" \n",
      "pi sisi liiicillllll   i              \"\n",
      "batch 15251  loss=136.8498  steps/s=105.12  prediction: \" already doing, faster. you are the user\" => \"t ge n   e nee de       e               \"\n",
      "batch 15252  loss=148.8443  steps/s=99.12  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e ot boconbocM tBT\"vL\"T.XLUjjUjVUUVjj)Ub\"\n",
      "batch 15253  loss=145.2230  steps/s=102.82  prediction: \"ding up the drive thru for 1000 episodes\" => \" ne Bei  e    n                   000000\"\n",
      "batch 15254  loss=144.3538  steps/s=103.71  prediction: \"o much suffering for the DUMBEST reasons\" => \"nfnieiiin e e e   fi fffff f            \"\n",
      "batch 15255  loss=154.7713  steps/s=104.76  prediction: \"of learning is learning from the past ig\" => \"n aeedaaneannnaennn n nan nnn n         \"\n",
      "batch 15256  loss=148.7503  steps/s=100.67  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"@tt uteut teeeeeeeeeceeeeeeeeeeeeeeeeee \"\n",
      "batch 15257  loss=144.6070  steps/s=106.46  prediction: \"re use at my job instead of adobes stuff\" => \"eplyr @hesehw_seqMjB@LMjB'LDUMMOSS888A8w\"\n",
      "batch 15258  loss=145.7409  steps/s=104.23  prediction: \"l amazing, do what you like least, first\" => \"yaeno nae nea a aa  a    a       l      \"\n",
      "batch 15259  loss=164.1153  steps/s=103.06  prediction: \"on\n",
      "Also doesnt apple allow emulators now\" => \"   ce\n",
      "r\n",
      "inn oos nos  oplo llelll  llo ll\"\n",
      "batch 15260  loss=142.6598  steps/s=104.56  prediction: \"s, but eventually this catches up to you\" => \"  n  lb  nl n  lllllllll t ttttt        \"\n",
      "batch 15261  loss=160.4672  steps/s=100.81  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \" da e  eeegeg eeee e   e   ttttt////t///\"\n",
      "batch 15262  loss=191.1432  steps/s=79.85  prediction: \"eativeBuilds @yacineMTB bro lets connect\" => \" da  eeeggeega     c aa///////tt/t ccKKK\"\n",
      "batch 15264  loss=157.9893  steps/s=105.59  prediction: \"you have ffmpeg installed on your system\" => \":u  ene t  a   t    a        e      e   \"\n",
      "batch 15265  loss=151.6164  steps/s=102.95  prediction: \"re advanced in the art of shape rotating\" => \"eplyt 55hnittxtIIqbw]ySUbÊ€zSðŸ“ˆx#ð˜‚k^Cgð—µkL,\"\n",
      "batch 15266  loss=158.6199  steps/s=102.04  prediction: \"f flipped around https://t.co/tQfmcgFqBM\" => \" bl stn  pf fpeepp pppppppttttttt/tt////\"\n",
      "batch 15267  loss=140.9225  steps/s=101.98  prediction: \"us things that make your life easier ig?\" => \" t b ibiiiiitit tttttt                  \"\n",
      "batch 15268  loss=146.2386  steps/s=105.28  prediction: \"uq?\n",
      "\n",
      "this freaked me out, didnt know ifâ€¦\" => \" urde e  c   aer  e  eee eee  e   d dd  \"\n",
      "batch 15269  loss=170.4398  steps/s=52.01  prediction: \": @IterIntellectus here have another one\" => \" @t.d he enh 0  9Hq?@9xI9wISw,\"Iq?PPPh99\"\n",
      "batch 15270  loss=135.8330  steps/s=110.44  prediction: \"ark a bit so i felt like writing this up\" => \"nd ?  s  t    t              i iiiiiiiii\"\n",
      "batch 15271  loss=190.3426  steps/s=95.11  prediction: \"072 im super glad man! love to hear that\" => \"  o a @e7ecn07enUUvx!!vIUv.S!,\"Iv!V\n",
      "bvOO\"\n",
      "batch 15272  loss=155.5605  steps/s=46.60  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \": @lha  0 s iii    l    al   lt   to t h\"\n",
      "batch 15273  loss=168.4641  steps/s=122.68  prediction: \"king one open rn just cause of this post\" => \"en07hraacrnn   r   een  n    n  ooe  ts \"\n",
      "batch 15274  loss=160.0742  steps/s=36.41  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @Oraaiine   en  n    n    n  to   ts \"\n",
      "batch 15275  loss=148.9648  steps/s=111.52  prediction: \"olve for the entire past week was a typo\" => \" v\n",
      " te e    t e  e e e    e eeeeee    e \"\n",
      "batch 15276  loss=148.9027  steps/s=103.29  prediction: \"my camera by accident so maybe thats why\" => \"e t   i mme   e     aa      a a  a     a\"\n",
      "batch 15277  loss=169.3810  steps/s=97.85  prediction: \"king stuff part of twitter is so fun wtf\" => \"eng  e m  m a aca t  t tff t ettt tt   s\"\n",
      "batch 15278  loss=159.1886  steps/s=103.11  prediction: \"nonstop about that compression challenge\" => \" t o sonnenn nh tttttttttttttoooooooo   \"\n",
      "batch 15279  loss=146.1821  steps/s=104.52  prediction: \"o make a significant impact on your life\" => \" muin i   n    i iaiiiiiiiiiiiii        \"\n",
      "batch 15280  loss=161.7741  steps/s=97.81  prediction: \"pmillyair lichess is like 200 elo higher\" => \"los @saa l mill iii  iii s ii    0   000\"\n",
      "batch 15281  loss=139.4271  steps/s=105.26  prediction: \"d into using dishonest middlewit tactics\" => \" ve s teere n n   sssnssssiiisssiididiti\"\n",
      "batch 15282  loss=147.4907  steps/s=105.23  prediction: \"a decision making incongruency somewhere\" => \"lsns   asssassss i iiiiiinnnnnnnnnnnnnnn\"\n",
      "batch 15283  loss=165.8106  steps/s=105.34  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"ite @ru u @ @ nAB@BBB B a B        a a a\"\n",
      "batch 15284  loss=146.8174  steps/s=105.03  prediction: \" your brain insanely bad in the long run\" => \"@ou     rrrbrr r     aa   aa     n    n \"\n",
      "batch 15285  loss=161.8699  steps/s=75.71  prediction: \"paeoh do it man!! making games is so fun\" => \"lny ur brb r iaii aaan!  aan n   n    nn\"\n",
      "batch 15286  loss=154.6907  steps/s=101.99  prediction: \"builds mcdonalds just wants to grill man\" => \"etpbs bbi dd io n  annn      s   s    s \"\n",
      "batch 15287  loss=146.5221  steps/s=104.77  prediction: \"kind of just whatever I want to pivot to\" => \"in,  r  ir  tti t    e     t ett  t  e t\"\n",
      "batch 15288  loss=133.9863  steps/s=103.57  prediction: \"learning is by doing stuff. For anything\" => \"y   gnt nn n  b                         \"\n",
      "batch 15289  loss=169.5255  steps/s=96.90  prediction: \"tney00 thanks brotha\n",
      "\n",
      "glad you liked it!\" => \"    t t enn      0    t s    oo      y  \"\n",
      "batch 15290  loss=152.2619  steps/s=104.69  prediction: \"ught it was a cool idea so i speedran it\" => \" hit\n",
      "to\n",
      "et\n",
      "tttht t        o             \"\n",
      "batch 15291  loss=167.3847  steps/s=99.04  prediction: \"wigABAP why a few years\n",
      "\n",
      "do it this week\" => \"itte@H t e gAA wAw w   a        ee  s i \"\n",
      "batch 15292  loss=146.3612  steps/s=103.41  prediction: \" 5am to 9pm, keeps sleep schedule intact\" => \"trlo  seo  em ntmmeeee pep  epp p  eee  \"\n",
      "batch 15293  loss=147.3404  steps/s=105.45  prediction: \"im definitely not an expert in it though\" => \"t  o u  ihiiiieniiiii                   \"\n",
      "batch 15294  loss=149.6062  steps/s=96.60  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \" n  esjiiniooon ooo  ooonnn    t t    l \"\n",
      "batch 15295  loss=154.6115  steps/s=102.01  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf   re e   n n     e ttttsstt/ss//ttstt\"\n",
      "batch 15296  loss=153.6440  steps/s=99.52  prediction: \"s every time I'm getting comfortable lol\" => \" cfe m eemerr r eee ee e  tmt  etmtgtt t\"\n",
      "batch 15297  loss=147.1357  steps/s=97.04  prediction: \"hnote uuuh i have a license for thse sir\" => \"eo e ysttemt    h     i    e o e  e ee o\"\n",
      "batch 15299  loss=145.7654  steps/s=103.44  prediction: \"ining data. The loss went down over time\" => \"t to eanen tannnanaa a    a         n   \"\n",
      "batch 15300  loss=148.3991  steps/s=103.81  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"ein   h  er ?LurvW.XT=wbIM4P^w8===&;;;^^\"\n",
      "batch 15301  loss=166.1483  steps/s=103.33  prediction: \" post your progress as you go through it\" => \"tra utyou  oo  oo  ooo    ss   oo   o   \"\n",
      "batch 15302  loss=140.1398  steps/s=104.01  prediction: \"ol\n",
      "gonna crack one open rn over some ice\" => \"ul i eo loonoocco ooooooonnn nn         \"\n",
      "batch 15303  loss=144.1461  steps/s=100.08  prediction: \"have you seen the walmart aura points ad\" => \"eve aln n nn e  e e ee e   e   aa aara a\"\n",
      "batch 15304  loss=146.3345  steps/s=101.59  prediction: \"ple deep q network has achieved insanity\" => \"ly: @ha le e ee e ee   e a  a aa a   iii\"\n",
      "batch 15305  loss=155.2026  steps/s=104.18  prediction: \"rs automatically slap that down to 10fps\" => \"ein r n nhn s2e 3j33.:v.q:y0!qC,5b/!.,I1\"\n",
      "batch 15306  loss=140.6798  steps/s=104.71  prediction: \"n an addiction\n",
      "Really curious what it is\" => \" ma ie ataanaaiaaanaanan aiii iiii    i \"\n",
      "batch 15309  loss=145.3120  steps/s=104.06  prediction: \"cay principles, and it ended up formingâ€¦\" => \"or g,ng  n  n  n           d d d dd     \"\n",
      "batch 15310  loss=147.3751  steps/s=99.13  prediction: \"cking it was kobe posting the whole time\" => \"oi g@in cinin r i           e       e   \"\n",
      "batch 15311  loss=141.4477  steps/s=102.27  prediction: \"nt true they wouldnt put it in the title\" => \"g,  i    it tttt tt t  t tt t   tttt ttt\"\n",
      "batch 15312  loss=158.7546  steps/s=100.47  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \" gi e eeeeg g eeee e   e   ttttt////t///\"\n",
      "batch 15313  loss=189.6916  steps/s=45.45  prediction: \"y: @BenjaminDEKR https://t.co/XKzK1sR0d2\" => \": @jtctegeg g FF   t   tt/ct//tt////tcKK\"\n",
      "batch 15314  loss=146.9809  steps/s=106.70  prediction: \" done in 1s, lol https://t.co/d2QCy0zBel\" => \"tonsinntnnt n nn         t tttttt///////\"\n",
      "batch 15315  loss=154.4855  steps/s=99.31  prediction: \"esome trend of advice sharing, i love it\" => \"   oli om oll ol    oo       d i  iisi  \"\n",
      "batch 15316  loss=159.7452  steps/s=102.76  prediction: \"inful to stfu but it works suuuuper well\" => \"ns a   \n",
      "s   s ttu   u   t ut  uuutu    u\"\n",
      "batch 15317  loss=152.9891  steps/s=105.79  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o   n   ne e ee ee r    e  e       e ee\"\n",
      "batch 15318  loss=136.6569  steps/s=105.17  prediction: \"ence in the hypothesis continues to grow\" => \" t r  eeee ne h   hhhhh hh hh nnnnntt   \"\n",
      "batch 15319  loss=155.1187  steps/s=99.52  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" d  e aea aaaaewalwll lle  lle   l liili\"\n",
      "batch 15320  loss=137.0227  steps/s=104.67  prediction: \" the time. personally i havent done this\" => \"the   t t    t t   e          l l      e\"\n",
      "batch 15321  loss=145.4205  steps/s=105.99  prediction: \"us example like this for numerous toolsâ€¦\" => \" t t  eeermeremmleeelile  ele ee e   r r\"\n",
      "batch 15322  loss=147.7474  steps/s=104.33  prediction: \"mer.js to make it cost $0. took too long\" => \"e se emsss rormr    o   t   t   o  tooo \"\n",
      "batch 15323  loss=144.7602  steps/s=104.39  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \" it  I   e  n nn  e     e      e       a\"\n",
      "batch 15324  loss=139.4332  steps/s=104.37  prediction: \"you can control the models, and its free\" => \" ur ccccocco cocoo   o   o              \"\n",
      "batch 15325  loss=148.4070  steps/s=100.82  prediction: \"ll send you a link to it around the 25th\" => \"yy e e y nnnn                          t\"\n",
      "batch 15326  loss=136.4093  steps/s=103.83  prediction: \"t, bc you can edit/delete prompt history\" => \"  r   a ta t tn  c    t  et eee  e   ptt\"\n",
      "batch 15327  loss=142.7130  steps/s=101.65  prediction: \"e transformer architecture works so well\" => \" aoo    n     n rr rrrrrrrrrrrrrrrrrr   \"\n",
      "batch 15328  loss=173.2713  steps/s=69.06  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"yd @    n nAn  rrrarrrereererre eo o  e \"\n",
      "batch 15329  loss=263.1964  steps/s=16.96  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @l Bv  @ APEM_RjSyWRK77v/777v/7j/7\"\n",
      "batch 15330  loss=142.2725  steps/s=107.28  prediction: \"t theres probably better stuff out there\" => \" on  e esees eeebbb bbbbbbbeettttttt  tt\"\n",
      "batch 15331  loss=155.8016  steps/s=103.05  prediction: \"eed\n",
      "Raise series A\n",
      "Raise series b\n",
      "Ez $6B\" => \" d es@R\n",
      "RReeee eeeseesesessesessesessee \"\n",
      "batch 15332  loss=144.8160  steps/s=104.52  prediction: \"al of life that pays some huge dividends\" => \"n         f    f                        \"\n",
      "batch 15333  loss=164.0481  steps/s=70.85  prediction: \"kul07 Nothing beats the classic todo.txt\" => \"esnh naf ef    ttta    tt   ee   isssdd \"\n",
      "batch 15334  loss=147.2404  steps/s=106.13  prediction: \"a recent nvim noob Tutor is super useful\" => \"nfoa       v   n              o     u  u\"\n",
      "batch 15335  loss=156.6296  steps/s=97.36  prediction: \"bootloader fast and frictionless is king\" => \"eoid tnot borooooo   at   a    i s ssi s\"\n",
      "batch 15336  loss=142.6896  steps/s=104.82  prediction: \"be helpful, so I recommend taking a look\" => \"e te   lbl l  b   l    e         e      \"\n",
      "batch 15337  loss=147.6797  steps/s=103.35  prediction: \"ely one-shot by breakfast (i was hungry)\" => \"    g n iinono n  o                    a\"\n",
      "batch 15338  loss=154.3763  steps/s=104.02  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"hmaeci c concee e re ee   ht  t////t/ttp\"\n",
      "batch 15339  loss=168.8725  steps/s=96.25  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"e 0rse h !h  !h hte ett  .tt  .tt    uuu\"\n",
      "batch 15340  loss=144.7876  steps/s=104.56  prediction: \"n clarity from practicing visualizationâ€¦\" => \" the s eeme n m  rrrirrrriii  iciiiiaiii\"\n",
      "batch 15341  loss=155.0389  steps/s=104.73  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"   /nth h////tthtttthhttttth///ttt////PP\"\n",
      "batch 15343  loss=149.1315  steps/s=101.62  prediction: \"ews on the internet\n",
      "id say it worked lol\" => \" _insngi  nn      n n  tte n t tt   t   \"\n",
      "batch 15345  loss=143.1558  steps/s=100.25  prediction: \"e latent space of \"make things ppl want\"\" => \" win  ttn  n tat et     e  e  e  e     p\"\n",
      "batch 15346  loss=144.2323  steps/s=105.85  prediction: \" breadth, right now the latter is bigger\" => \"tet   ed mem  hrr   h   hh   t ttttt   t\"\n",
      "batch 15347  loss=133.4004  steps/s=105.00  prediction: \"you can get a stronger 'muscle' for this\" => \" u henth  ott o   t   t t       '' '''  \"\n",
      "batch 15348  loss=138.6386  steps/s=105.50  prediction: \" from that channel/vid to that x account\" => \"to o lo lol    a  a a      t tttt    tt \"\n",
      "batch 15349  loss=149.1375  steps/s=98.12  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"eplitni ixigiMk @1'TBIx'TB.7\"M$TB4'_TM,\n",
      "\"\n",
      "batch 15351  loss=165.6985  steps/s=65.11  prediction: \"@IterIntellectus have you brrrytt today?\" => \"atxqie  n eneeneen    le  o       yy    \"\n",
      "batch 15352  loss=138.9484  steps/s=106.17  prediction: \"s w java and python and studying for fun\" => \" artti  tnn n    a a    a   n      n   n\"\n",
      "batch 15353  loss=145.3946  steps/s=104.83  prediction: \"em all the cool ML stuff out there thatâ€¦\" => \"  e   t   l l  ll    l            t  tt \"\n",
      "batch 15354  loss=147.2923  steps/s=102.84  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" bo  t  t tt th tttttt ttt  t   t       \"\n",
      "batch 15355  loss=145.7456  steps/s=103.79  prediction: \"I figure if we just do it, ppl will join\" => \" uhldbiidlidiiii                        \"\n",
      "batch 15356  loss=141.5585  steps/s=103.98  prediction: \"ich is a great way to find opportunities\" => \"ni    i c icc w                        t\"\n",
      "batch 15357  loss=143.4725  steps/s=102.23  prediction: \"d it tho, was a change of weather for me\" => \" th theeejeje ttt              aa      e\"\n",
      "batch 15358  loss=133.5403  steps/s=104.19  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" f      e e eee ee              ot t  t \"\n",
      "batch 15360  loss=148.3765  steps/s=100.49  prediction: \"sed to sound like the opposite of curses\" => \" e lelt lsd s s           o      ooo  o \"\n",
      "batch 15361  loss=145.1026  steps/s=105.51  prediction: \"l amazing, do what you like least, first\" => \"ywend nae  ea a aa  a    a       l      \"\n",
      "batch 15362  loss=164.6017  steps/s=63.03  prediction: \"@codyaims 113 bots liked this one so far\" => \"Naeeiooeeie   eaaa ao   li        e     \"\n",
      "batch 15363  loss=165.0501  steps/s=111.91  prediction: \" the 16 hour coding session, lets get it\" => \"th nt7    no       oo      s  ssssssssss\"\n",
      "batch 15364  loss=147.4439  steps/s=103.76  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"eie   h  er LL rvY3Y@w&b7;6^^6_===&;;;^^\"\n",
      "batch 15365  loss=148.4081  steps/s=104.43  prediction: \"lding w ai is gonna get left in the dust\" => \"e    i  nnll i i                        \"\n",
      "batch 15366  loss=275.8241  steps/s=11.04  prediction: \"reply: @5handilya See you thurs brotha ðŸ«¡\" => \"e ei: @heerhhðŸ˜ee}}#KðŸ˜‰vâ€¦*á´›Q}#æˆ‘ð—µá´€#ðŸ‘Œá´˜#kðŸ˜‰ðŸ§ ðŸ«¡k\"\n",
      "batch 15367  loss=142.6671  steps/s=108.35  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sah en   s   e         ttt ttt/////////\"\n",
      "batch 15368  loss=155.1906  steps/s=104.71  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne le llllllll         t  tttttt//////HH\"\n",
      "batch 15369  loss=175.8441  steps/s=100.03  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"hl  hta  ir////â€¦ HHHHHHHHH.......tpptppp\"\n",
      "batch 15370  loss=160.4615  steps/s=107.17  prediction: \"unches, then good luck ever finding them\" => \"   he    e  l nn  e    e    e    e e   e\"\n",
      "batch 15371  loss=135.5996  steps/s=103.75  prediction: \"f, and also not lying about small things\" => \"   e gn   nn  ol  l     o           a   \"\n",
      "batch 15372  loss=172.8931  steps/s=99.76  prediction: \"inpeace I gotchu https://t.co/l34MQvLmOd\" => \"ng  o  ae@ n  e   t  g ttt tt ttt////h44\"\n",
      "batch 15373  loss=153.7968  steps/s=100.06  prediction: \"p was the ultimate signal the whole time\" => \"li: @tettp   tet  t tt  tts t t tl l tth\"\n",
      "batch 15374  loss=152.8454  steps/s=104.01  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf arme e   n       e t ttssttsss//tts//\"\n",
      "batch 15375  loss=143.4202  steps/s=105.76  prediction: \"ht. i feel like i barely understand them\" => \"ete  ne ne  l              e   ee ee e e\"\n",
      "batch 15376  loss=147.3333  steps/s=101.28  prediction: \"ld love to hear if you dont mind sharing\" => \"y  st    ll lo l          o             \"\n",
      "batch 15377  loss=209.4290  steps/s=95.96  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"g see ?a  eka a e    NINNIININIOO  OOOO \"\n",
      "batch 15378  loss=180.0459  steps/s=38.08  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: @Per teek    IN  ININ TIOINIOO EESOON\"\n",
      "batch 15379  loss=149.0233  steps/s=110.08  prediction: \" inference than gpus\n",
      "\n",
      "but what do i know\" => \"tm     nerne nennnnnennnnne e  t        \"\n",
      "batch 15380  loss=142.3616  steps/s=105.00  prediction: \"erfect timing actually if thats the case\" => \" ein ntttetteitttitttitit t  t      t t \"\n",
      "batch 15381  loss=149.2382  steps/s=100.44  prediction: \"ind groups of ppl who love what you love\" => \"ng  ets   tt                o  o   o   o\"\n",
      "batch 15382  loss=154.2334  steps/s=104.07  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"eet n  bem br ree  e eeoooo   t  s      \"\n",
      "batch 15384  loss=246.3059  steps/s=10.70  prediction: \"reply: @crackeddl its hard. but worth it\" => \"eply: @  en  q  PZ@0T,7HOE,bAMDqCIDbqGII\"\n",
      "batch 15385  loss=162.2427  steps/s=121.55  prediction: \"here you go mate\n",
      "https://t.co/oR4fVr3TMW\" => \"e h ay  uh      e         tttttttt/tt///\"\n",
      "batch 15386  loss=134.7982  steps/s=103.44  prediction: \"r this, practice it to get skilled at it\" => \"estio   aen lqin,@W2â€¦v,HMTIHAMTILI/â€¦x6II\"\n",
      "batch 15387  loss=133.4656  steps/s=104.46  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"thi   b t gg       ppppppp              \"\n",
      "batch 15388  loss=146.2284  steps/s=104.40  prediction: \"dering what was on that list, thanks man\" => \"  a s ae n n w www  w             tttt t\"\n",
      "batch 15389  loss=145.8811  steps/s=99.25  prediction: \"gh Ive been wanting to do a wasm project\" => \"  tithnwg l   ge        n        a      \"\n",
      "batch 15390  loss=138.5307  steps/s=100.75  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"ttdool ggag nagaaaaaaaaa a a           L\"\n",
      "batch 15391  loss=276.1967  steps/s=11.09  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @  sc  q eNDk0Pj,xMIv+xMIvÉ´W/ðŸ¤”]ðŸ’ªI+\"\n",
      "batch 15392  loss=136.6509  steps/s=106.53  prediction: \"knesses and imbalances, using space, etc\" => \"i o ttinngenneeneaaaaaaassssaas ssssssss\"\n",
      "batch 15393  loss=136.8613  steps/s=102.62  prediction: \"better generalizer than the classic MLP?\" => \"u   e t  eteteneeeeeeeeeereee e        a\"\n",
      "batch 15394  loss=139.3710  steps/s=103.24  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"thet t  t  ttttt                        \"\n",
      "batch 15395  loss=146.1338  steps/s=99.03  prediction: \"he second one Unison (Knife Party Remix)\" => \"e     n ean n Ae n   onnnnnnnn nnn     e\"\n",
      "batch 15396  loss=146.8129  steps/s=104.65  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"n  eeelhen hh  raaa r      rer    ee  ee\"\n",
      "batch 15397  loss=147.5932  steps/s=104.60  prediction: \"w zooming forward on an electric scooter\" => \"ibu     ewowoon oo ooo  o  on      nc  c\"\n",
      "batch 15398  loss=163.9968  steps/s=98.21  prediction: \"is is great goal\n",
      "https://t.co/pYjm7zBOfa\" => \"n o  menin s  r  g  gaa  gattt tc/////oc\"\n",
      "batch 15399  loss=157.1708  steps/s=100.09  prediction: \" joining man, looking forward to thurs!!\" => \"tues nenneno non ononoononnnooooo      o\"\n",
      "batch 15400  loss=148.9870  steps/s=101.82  prediction: \"l ideas\n",
      "\n",
      "say if youre trying to learn ML\" => \"ywffeneeneneneel       y eyyy y   y     \"\n",
      "batch 15402  loss=138.4890  steps/s=104.61  prediction: \"o make a comeback. would be great to see\" => \"nte o e  e                              \"\n",
      "batch 15403  loss=145.8122  steps/s=104.21  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" boa tcoess s  s   sss ss ss sssssse  s \"\n",
      "batch 15404  loss=164.1412  steps/s=59.45  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tyoc   eees t rs sesee ss p eess ewwwasa\"\n",
      "batch 15405  loss=201.5250  steps/s=110.56  prediction: \"nly read a bit so far but its super good\" => \" o / rt t7n n a  i a o a    b i         \"\n",
      "batch 15406  loss=201.0803  steps/s=102.19  prediction: \" audio too\n",
      "\n",
      "I really felt that beat drop\" => \"@ pOO p pr p    o  \n",
      "   oo o l lt lt t a \"\n",
      "batch 15407  loss=167.4829  steps/s=103.92  prediction: \"ich in this case, is their lack of speed\" => \"nh stes hnhh    h     s  s i  ii        \"\n",
      "batch 15408  loss=158.2892  steps/s=102.83  prediction: \"l do bro, never had a french beer before\" => \"ysepr  e b be  d         r   e e   eeere\"\n",
      "batch 15410  loss=148.3618  steps/s=104.02  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"nmass  ss\n",
      "\"\n",
      " \"m mmmmm\n",
      "\n",
      "mm\n",
      "&&&;;;;\n",
      "tttttu\"\n",
      "batch 15411  loss=147.0796  steps/s=104.30  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"   pro r erererereeereeeee e se ee    i \"\n",
      "batch 15412  loss=148.2231  steps/s=98.75  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"epl nna axag Yd bE';;/W'LPbWv\"&&f;;ð—ªAvf/\"\n",
      "batch 15413  loss=146.0281  steps/s=104.31  prediction: \"e component is the key to crazy stuff...\" => \" pons  ooeonnnt nn  e     e  ee  t   t  \"\n",
      "batch 15414  loss=167.7765  steps/s=104.80  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"eso i eiMlc t0t 1#å§j_v6CM#S]M6[21_ðŸ‘21cVC\"\n",
      "batch 15415  loss=140.3149  steps/s=101.74  prediction: \"ood and helps you not waste future years\" => \"nkio    o      n             o     u   u\"\n",
      "batch 15416  loss=146.0004  steps/s=98.66  prediction: \"t really is a long term + hard work game\" => \"han a   id  n  l  l   l       t r    rrr\"\n",
      "batch 15417  loss=165.8743  steps/s=103.81  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"@on  t   gt t!!!!!!!!!!ttttttttt//////tt\"\n",
      "batch 15418  loss=184.8371  steps/s=100.07  prediction: \"u helped a ton, hugely appreciate it bro\" => \"tdt__t_11n1 1  t     e     eo    pptp pp\"\n",
      "batch 15419  loss=159.1538  steps/s=99.95  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"@ut pezeii  iiiii ililiit  ttttt////c///\"\n",
      "batch 15420  loss=171.6551  steps/s=59.72  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"@_r pinii b llebi htt t/t/////tt////cccc\"\n",
      "batch 15421  loss=151.6709  steps/s=106.58  prediction: \"itor as I was with 2 screens and a mouse\" => \"n  tn a  tan                 s  s   s s \"\n",
      "batch 15422  loss=152.4487  steps/s=101.15  prediction: \"allenge\n",
      "however: https://t.co/TzbAuUlGIG\" => \"n aa  pu       e  h heheeee::::::///////\"\n",
      "batch 15423  loss=144.2236  steps/s=100.02  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"  e o o  i  i h  i  t tt tttttttt//////t\"\n",
      "batch 15424  loss=152.5083  steps/s=103.98  prediction: \" and mc write n\n",
      "\n",
      "https://t.co/7R6F8ZlLFS\" => \"and       n n d         tttttttttttt////\"\n",
      "batch 15425  loss=140.5405  steps/s=104.13  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"a  t  t            hhttttttttttttttttoo/\"\n",
      "batch 15426  loss=140.2435  steps/s=104.74  prediction: \" bc random twitter guy said itd be funny\" => \"temmsma mem         t      t       d    \"\n",
      "batch 15427  loss=141.7170  steps/s=104.71  prediction: \"epts end up just being 'oh its just xyz'\" => \" lyan c nn n                            \"\n",
      "batch 15428  loss=152.6672  steps/s=102.30  prediction: \" like this too? They come in pairs often\" => \"tone no   r s  s         o    e    i  i \"\n",
      "batch 15429  loss=145.1957  steps/s=103.99  prediction: \"seconds to go to jail and ruin your life\" => \" s   ea  rs t  t  o  o  o         o   o \"\n",
      "batch 15430  loss=149.6230  steps/s=93.78  prediction: \"oulda made stock cert flags instead, rip\" => \"uncand    s o oo ot    a    tt    a   ii\"\n",
      "batch 15431  loss=165.1115  steps/s=104.34  prediction: \"obably been undervaluing its utility tbh\" => \"ul  tet t tntb bebbbbeeeeeeuunun u uuiui\"\n",
      "batch 15432  loss=172.7668  steps/s=79.33  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eploa @a  n s7a Gv.vvqv,?.42,).694j(69!2\"\n",
      "batch 15433  loss=152.6056  steps/s=106.33  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"eee bearememm   ettt ee ttu sut  s s   s\"\n",
      "batch 15434  loss=158.3162  steps/s=100.45  prediction: \"Building scratch from scratch in scratch\" => \"   immiem u r e i s  r s r    cr cc   rr\"\n",
      "batch 15435  loss=144.8563  steps/s=102.74  prediction: \"inds the shortest path to get everything\" => \"ng rn   t  n      tssttttttt ttttt ttttt\"\n",
      "batch 15436  loss=169.8016  steps/s=97.47  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"oars i tennwh thh  ts so e e eeeeeee  eE\"\n",
      "batch 15437  loss=158.9179  steps/s=101.62  prediction: \"C $ they raisedâ€¦ https://t.co/8AMjPz3k5K\" => \"owyw: riiisniâ™‚oo:kW^@]k^VC#$%k%%%Êœ%uðŸ˜†èµ°K%\"\n",
      "batch 15438  loss=145.8611  steps/s=104.20  prediction: \" the time and not spread important info?\" => \"toe  el lll  e                      tttt\"\n",
      "batch 15439  loss=135.6211  steps/s=102.75  prediction: \" play instead of making random moves lol\" => \"to t tl   tt  l     aa     aa           \"\n",
      "batch 15441  loss=143.2434  steps/s=103.49  prediction: \"cay principles, and it ended up formingâ€¦\" => \"olng,ng  n  n  n           d d d dd     \"\n",
      "batch 15442  loss=179.7245  steps/s=38.52  prediction: \"ly: @anish0209 No problem I gotchu man ðŸ«¡\" => \"y  @ ri  e cn ca          dd d d        \"\n",
      "batch 15443  loss=149.6792  steps/s=106.50  prediction: \"k the same amount but on their own stuff\" => \" ag  n e  wwe   e    e      t   t  o   t\"\n",
      "batch 15444  loss=156.7738  steps/s=101.05  prediction: \"ressive overload\n",
      "https://t.co/q7aR3FUGAr\" => \"e   e n ue   2n qá´›j8#:}m:k8##b7xq7FR3FUG\"\n",
      "batch 15445  loss=151.2239  steps/s=102.68  prediction: \"mpactful on actual success for me though\" => \"elhi  t vn tt ht     a    ccccccc   c   \"\n",
      "batch 15446  loss=173.8330  steps/s=102.61  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \" fo e  t mt m   m  mt tttttttttttttt////\"\n",
      "batch 15447  loss=166.9510  steps/s=101.04  prediction: \" the 16 hour coding session, lets get it\" => \"to ni  7 nn         n      os ssssssssss\"\n",
      "batch 15448  loss=163.1013  steps/s=102.85  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"ea er ngyn:nbjn w0j(@7:!71.K16bYCTDqY6JI\"\n",
      "batch 15449  loss=141.8054  steps/s=102.79  prediction: \" if I decide to read em ill do a summary\" => \"tn aet   s  n d    d e                  \"\n",
      "batch 15450  loss=147.6921  steps/s=104.27  prediction: \" muscle for mentally doing them will get\" => \"tett errenrre e rr   e   ll   le  l mll \"\n",
      "batch 15451  loss=174.1066  steps/s=104.30  prediction: \"           5.26e-13\n",
      "Running validation:â€¦\" => \"t   200012\n",
      "1 2 2  2         363333-33 \n",
      " \"\n",
      "batch 15452  loss=153.1533  steps/s=104.41  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"e chsd@tck@#s.ee8:(.1R)vm`kÉªâ™‚wqÉªk]xðŸ˜:F8#\"\n",
      "batch 15453  loss=133.8337  steps/s=103.81  prediction: \"ntext into a computation to make it pure\" => \"g an t t  tnt n     ttttttttttttttt     \"\n",
      "batch 15454  loss=148.5895  steps/s=103.40  prediction: \"ng, dunno why this flew over my head lol\" => \"g aols tnie  ne nt  n n n               \"\n",
      "batch 15455  loss=134.8477  steps/s=102.93  prediction: \"future features\n",
      "\n",
      "thanks for the idea bro\" => \" noi ntetteteteeeetteteeeettttet        \"\n",
      "batch 15456  loss=140.3140  steps/s=104.22  prediction: \"es your data instead of storing the data\" => \" eiinae etettt  aaaa aaa a       t   t  \"\n",
      "batch 15457  loss=137.5827  steps/s=103.60  prediction: \"ether they are good or bad on their face\" => \" t ue e t tteeheeeee                    \"\n",
      "batch 15459  loss=138.7563  steps/s=105.55  prediction: \"miliar with a place and the things in jt\" => \"eni a i miiimiiiii a a  aaa  a     h h  \"\n",
      "batch 15460  loss=138.9449  steps/s=105.17  prediction: \"can help guide them towards better stuff\" => \"hn let  t   e pe   e   ee   e   ttt  ttt\"\n",
      "batch 15462  loss=142.9693  steps/s=105.00  prediction: \" component that approximates transformsâ€¦\" => \"ton o  oo noooono t tttattatttatttttaaaa\"\n",
      "batch 15463  loss=142.5408  steps/s=104.88  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"nt se t ng  c gciiiciciiaiaaiaaaaaaaap  \"\n",
      "batch 15464  loss=145.4735  steps/s=104.72  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"ne na e  nd ddd   aa   aa  a   a     nn \"\n",
      "batch 15465  loss=165.7577  steps/s=82.65  prediction: \"by_builds another $20 trillion to ludwig\" => \"e  ddnb  ad aii   aa       n   i  otnnn \"\n",
      "batch 15466  loss=133.9471  steps/s=104.41  prediction: \"future features\n",
      "\n",
      "thanks for the idea bro\" => \" noientett tet eeetteteteetttte e       \"\n",
      "batch 15468  loss=178.6852  steps/s=86.11  prediction: \"yon Super hyped to see what youre cookin\" => \":u  ute efeeuueret eee ses eee  t    rr \"\n",
      "batch 15469  loss=145.3855  steps/s=105.29  prediction: \"isten to remixes of the ost all the time\" => \"n  oe   s s s                        t  \"\n",
      "batch 15470  loss=147.3294  steps/s=104.89  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"tot sar   or  eo r     ss s ss s  s    e\"\n",
      "batch 15471  loss=149.3132  steps/s=101.06  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r   nt t e   n         tstttt//////////\"\n",
      "batch 15472  loss=150.7849  steps/s=102.98  prediction: \"velsio im hyped to see what youre cookin\" => \"e evvllee@e  eel           e    ee  o oo\"\n",
      "batch 15473  loss=136.7066  steps/s=105.18  prediction: \"l tools for myself and they save me time\" => \"yp  u  u u loo l      f                 \"\n",
      "batch 15474  loss=161.5752  steps/s=103.39  prediction: \" it was all tactice, but this is the way\" => \"tn innein  t  a at ttt ta     ttttt ii  \"\n",
      "batch 15475  loss=168.8903  steps/s=81.67  prediction: \"cicle77 welcome aboard the zig train bro\" => \"hcee@er il  l7 wll  c  a t t   ti i ii  \"\n",
      "batch 15476  loss=146.5926  steps/s=109.75  prediction: \" thanks man! i should uh sleep more yeah\" => \"@h ncahaantat t ae    a    h   u  e    e\"\n",
      "batch 15477  loss=139.3222  steps/s=102.59  prediction: \"nomena that i used to not have words for\" => \"gta t nn nenn n                         \"\n",
      "batch 15478  loss=210.6246  steps/s=98.97  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" ea t nnet M  BU    E tt  ttt  oo/ o oo \"\n",
      "batch 15479  loss=140.8759  steps/s=104.44  prediction: \" a funny glowing rock will make billions\" => \"ts  he     n      n     w       l  lllll\"\n",
      "batch 15480  loss=193.7936  steps/s=20.33  prediction: \"eply: @andreiacribeir Thoughts on Scala?\" => \" ly: @t    nn     n     w       l llllll\"\n",
      "batch 15482  loss=151.3258  steps/s=110.80  prediction: \"e we figure out that sleeping is a thing\" => \" ion en n cccee     e   e    e        i \"\n",
      "batch 15483  loss=157.1020  steps/s=103.06  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"nda os  ..............       o          \"\n",
      "batch 15484  loss=159.9734  steps/s=104.04  prediction: \"yo grand children at 85. gps kids r busy\" => \" u  pn1  5en  ed     d   d           d  \"\n",
      "batch 15485  loss=141.9095  steps/s=104.63  prediction: \"ding blocks that make it up, recursively\" => \" n iiyii i l  l      t    t    t      e \"\n",
      "batch 15486  loss=147.3872  steps/s=105.21  prediction: \" by talking abt half done projects. BOOM\" => \"aede l  ng  n  n                        \"\n",
      "batch 15487  loss=182.9205  steps/s=31.30  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly:      en nnb  a    a                 \"\n",
      "batch 15488  loss=156.3698  steps/s=111.89  prediction: \" curriculum work https://t.co/5pG7qkZKyY\" => \"ahd  leeer r r   ruruurr   ttt//////////\"\n",
      "batch 15489  loss=141.5188  steps/s=104.34  prediction: \"mpeg tho but not if i rely heavily on it\" => \"ere me  tif t f                         \"\n",
      "batch 15491  loss=136.4275  steps/s=101.62  prediction: \"s of industry water cooler conversations\" => \" ios  t s o os ss       o     oorrrroror\"\n",
      "batch 15493  loss=130.9802  steps/s=105.65  prediction: \"vision how great itll be once youre done\" => \"eo  ena nhn   n                        e\"\n",
      "batch 15494  loss=134.8039  steps/s=104.21  prediction: \" is it some kind of info storage system?\" => \"tt ts ittissi gi  i    i       o    o s \"\n",
      "batch 15495  loss=145.7129  steps/s=99.31  prediction: \"whoa thats wild, old twitter could never\" => \"hat @s n  t t    w     o    ttt  t tt e \"\n",
      "batch 15496  loss=156.8010  steps/s=102.00  prediction: \" making anifusion in the first place btw\" => \"te a    t   t nnaiiniinnniiniiiii       \"\n",
      "batch 15497  loss=157.4278  steps/s=45.47  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @wu   n a a in inniiiiniini  i        \"\n",
      "batch 15498  loss=157.2533  steps/s=122.11  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"ecly: o  lg  ble,5@b@BzTBy55,B00G,Y:j0v.\"\n",
      "batch 15499  loss=183.1417  steps/s=85.43  prediction: \"dup QUICK do something that doesnt scale\" => \" n  o  â€™db ns so  s  ttstttth/tt tttsccl\"\n",
      "batch 15500  loss=168.0072  steps/s=58.79  prediction: \": @IterIntellectus here have another one\" => \" @aek oui C  Ch UICK@:/cb.c5,BvwGLY:jIv.\"\n",
      "batch 15501  loss=137.5899  steps/s=111.07  prediction: \"als and make smaller and smaller circles\" => \"tletae aenanmaenaamaaaa aaaaalaallllllll\"\n",
      "batch 15502  loss=144.0366  steps/s=104.82  prediction: \"has any non-json, ask for json in prompt\" => \"et  o.        n nnn nnnn                \"\n",
      "batch 15503  loss=145.3829  steps/s=104.34  prediction: \"g correct (fingers crossed its this one)\" => \" a e e eet  rrrrrrcrrccrrerr   sse s ss \"\n",
      "batch 15504  loss=151.7999  steps/s=105.98  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \"5   a    n na aaaaana    ooo   cc cc ccs\"\n",
      "batch 15506  loss=146.2868  steps/s=101.89  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"hate yr ettet rl      o       i i  i   i\"\n",
      "batch 15507  loss=182.5307  steps/s=99.58  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"ty e  a a  ` ``` `     `n t ttn/////tt//\"\n",
      "batch 15508  loss=147.2830  steps/s=100.98  prediction: \" process does feel good when err go down\" => \"taaeineer gnee sese see eee   oee  oeo o\"\n",
      "batch 15509  loss=162.1683  steps/s=72.29  prediction: \"@Aryvyo use the api\n",
      "anthropic or bedrock\" => \"yrcineM s r es sese oee  ee   o e  or do\"\n",
      "batch 15510  loss=138.9534  steps/s=106.45  prediction: \"robably dont ask 'will you be my mentor'\" => \"emu i   a    Z  'Z'ZZJ'c$+`z,vCJSVR:JVx.\"\n",
      "batch 15511  loss=205.4227  steps/s=99.47  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"tL l       A+LLLLLLLDDEEEEEEEEETTTTT  \n",
      "\n",
      "\"\n",
      "batch 15512  loss=153.8533  steps/s=102.85  prediction: \"ld almost suspect God is on their side..\" => \"y s  osu dossss sssss s   s             \"\n",
      "batch 15513  loss=154.1456  steps/s=100.39  prediction: \"nt get too random with high stakes stuff\" => \"t  e ss tt  t  tt  oot  ot   h hhhhhh  h\"\n",
      "batch 15515  loss=165.3415  steps/s=96.22  prediction: \"tiquing the zoomers that jump in his dms\" => \" on sh r eitriri  iii  t tto    tt   m  \"\n",
      "batch 15516  loss=150.5722  steps/s=106.40  prediction: \"concept, yes\n",
      "\n",
      "2/3 depends on the concept\" => \"oot @ oon tet ccee  eeeeeee e e ee ee e \"\n",
      "batch 15518  loss=143.7928  steps/s=97.09  prediction: \"isten to remixes of the ost all the time\" => \"n  ts   ses s                        t  \"\n",
      "batch 15519  loss=145.0173  steps/s=105.20  prediction: \"mul, transitions from one derivative toâ€¦\" => \"ent m el  mamigittitiinin  nn   n io   i\"\n",
      "batch 15520  loss=145.4143  steps/s=104.88  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" entu t rtt r  trr   r o oroo opooo o oo\"\n",
      "batch 15521  loss=146.3556  steps/s=104.74  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" ha     s...s..s  o                     \"\n",
      "batch 15522  loss=144.1311  steps/s=102.53  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"el o  e an c a c aa      ou      ou ooo \"\n",
      "batch 15523  loss=161.5962  steps/s=101.60  prediction: \"? i actually dont know anything abt groq\" => \" I\n",
      "uit ????i                   nnnnnnn  \"\n",
      "batch 15524  loss=134.2324  steps/s=102.00  prediction: \" feel to be a tier above elon @teodor_io\" => \"tow  ie  e  t e              eee    eeoo\"\n",
      "batch 15525  loss=142.6375  steps/s=105.02  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yat mm aemm m m llllel llsllllss////t///\"\n",
      "batch 15526  loss=159.8823  steps/s=103.18  prediction: \" fit-to-content) https://t.co/kIAe5BVk05\" => \"toree   ettot- o-ttttttttttttt/tt//////t\"\n",
      "batch 15527  loss=140.3456  steps/s=99.97  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" ait  eaa tte  eeeee                   t\"\n",
      "batch 15529  loss=137.4418  steps/s=105.75  prediction: \"r, it felt a little linkediny over there\" => \"e ly:ner hsB Zno!Z(?YZ(!J(y@IRR)RI-RRJ:R\"\n",
      "batch 15530  loss=139.1906  steps/s=105.68  prediction: \"o halt with a general halting function?\"\" => \"nwn temtn  t t t  t t       aa a  a nnn \"\n",
      "batch 15531  loss=137.1121  steps/s=103.24  prediction: \"yself infinite runway to build fun stuff\" => \"   d mn en neifiiiiiin  n     i      u  \"\n",
      "batch 15532  loss=143.0645  steps/s=103.11  prediction: \"re use at my job instead of adobes stuff\" => \"ep yu @hewe  Rse?MTBRLMjB@L@@R?BA/â€™â€™â€™vâ€™8\"\n",
      "batch 15533  loss=172.9024  steps/s=88.01  prediction: \"npaul_ai Improves irl ppls responses too\" => \"go  i      a  a    r r e     a  esss ses\"\n",
      "batch 15534  loss=148.2045  steps/s=105.35  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e ny  h mer  L rvUj_IU_jUU_88_7===&;;;^^\"\n",
      "batch 15535  loss=154.0283  steps/s=102.40  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et  t   ttooo tooo  ooooo oso sss uussuu\"\n",
      "batch 15536  loss=143.9563  steps/s=105.92  prediction: \"s changing how I think abt models a lot.\" => \" a   n ta n tnt  n  hhhn  h  hh n       \"\n",
      "batch 15537  loss=167.6342  steps/s=102.53  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yz\n",
      "s es t     u       e  e ff eeeee ooee\"\n",
      "batch 15538  loss=140.8026  steps/s=103.71  prediction: \"hing that could ruin their brand idk tho\" => \"as  a ee m ttt t  t              i      \"\n",
      "batch 15539  loss=203.5002  steps/s=104.42  prediction: \"needed to dl this. meme delivery service\" => \"g no     d    ed       e d  de eeeeeeeee\"\n",
      "batch 15540  loss=153.5355  steps/s=100.24  prediction: \"coder trust me bro im high iq, see above\" => \"am     at  teet    e     m  i           \"\n",
      "batch 15543  loss=141.5564  steps/s=102.19  prediction: \"one\n",
      "\n",
      "steamrollers do this but with water\" => \"   m \n",
      " \n",
      "teeneene  eeee oe            tt \"\n",
      "batch 15544  loss=185.6602  steps/s=22.08  prediction: \"eply: @tunahorse21 its really that good?\" => \" ly\n",
      " @t\n",
      "teneneeee eeeeoo             ttt\"\n",
      "batch 15545  loss=140.7196  steps/s=108.30  prediction: \"for typos and a list of other dumb stuff\" => \" rct afc cc                             \"\n",
      "batch 15546  loss=148.6506  steps/s=99.45  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" io uo   d el  l           e    m s ssus\"\n",
      "batch 15547  loss=162.9064  steps/s=89.66  prediction: \"ler i wish it tasted as good as it looks\" => \"ymo 1w l oll   w  h      ssad  sss  so s\"\n",
      "batch 15548  loss=153.4615  steps/s=103.04  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"@oo ae!nnen n e      nn nnnnnnnnn \n",
      " \n",
      "   \"\n",
      "batch 15549  loss=167.4997  steps/s=105.06  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"soc   e  //eteet/ttttttttp////hpD//DDp//\"\n",
      "batch 15550  loss=172.5842  steps/s=78.26  prediction: \"drew_pynch Sounds like a good comfy time\" => \" et  e eeetttyy hhthptt/t //tDDcooOOtOtt\"\n",
      "batch 15551  loss=158.2476  steps/s=107.95  prediction: \"file llm editing stuff is the future imo\" => \" l tt .elllfellilllliii iiiif ff fft    \"\n",
      "batch 15552  loss=138.3981  steps/s=102.24  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"@ne e         a a   ss ssssssstt////t///\"\n",
      "batch 15553  loss=143.4270  steps/s=104.30  prediction: \"w. Might do one every mon and every tues\" => \"h o   o rotrrorroo  o  o   o        eee \"\n",
      "batch 15554  loss=150.5817  steps/s=101.94  prediction: \"e algo show you a lot more similar posts\" => \" aa  ot    o    oo  o     o    o    o   \"\n",
      "batch 15555  loss=162.9124  steps/s=70.04  prediction: \"gizmobly @juweeism duude this is awesome\" => \" nbokem mgo               o    i  s s  s\"\n",
      "batch 15556  loss=133.4632  steps/s=108.96  prediction: \"tput something as unexpected as possible\" => \" st t t toototttt    u     eee eeeee sss\"\n",
      "batch 15557  loss=179.1146  steps/s=29.14  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: @  tt too t      u    eeee eeessssss\"\n",
      "batch 15558  loss=159.7128  steps/s=149.23  prediction: \"ucoder Any cracked accts you wanna list?\" => \"te t ttoo toee        e ccee  as  s s   \"\n",
      "batch 15559  loss=142.3531  steps/s=105.06  prediction: \"r coding lol. And some chess. Great move\" => \"elt  mpeneaheP@ 7___(_P:D/PvPD/v(S..AA`F\"\n",
      "batch 15560  loss=193.6609  steps/s=21.75  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly  @dgnoooooono   o                  e\"\n",
      "batch 15561  loss=146.4557  steps/s=107.04  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" eoese,esodedeeeeeedeeeseeetsts///////tt\"\n",
      "batch 15562  loss=156.9493  steps/s=99.56  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  + eooeeedeldoee eeett tttt tttt       \"\n",
      "batch 15563  loss=148.2632  steps/s=105.11  prediction: \" talking drains your energy for building\" => \"toir  d d  na  n  aa n nn a  rnrryyr r r\"\n",
      "batch 15565  loss=146.9723  steps/s=99.50  prediction: \"p. maybe you can figure out how to do it\" => \"l   @gomm mdm    y          u   u     o \"\n",
      "batch 15566  loss=151.7587  steps/s=97.16  prediction: \"xoki How do I know this isnt a lie tho ðŸ¤”\" => \" kpi italo   o   o         io   i    i  \"\n",
      "batch 15567  loss=146.5718  steps/s=98.95  prediction: \"ng that solves a problem you're close to\" => \"g  oot  ot et tt     t    s  o   o ee e \"\n",
      "batch 15568  loss=141.4040  steps/s=104.78  prediction: \"ing ive wanted in life lol, complete 180\" => \"ng tve  ennen in i  i    i    l lll llll\"\n",
      "batch 15569  loss=154.8061  steps/s=95.91  prediction: \"nks!! feels good to be doing these again\" => \"gi l   enaete n e   e e     o    eee   e\"\n",
      "batch 15570  loss=141.6806  steps/s=103.80  prediction: \"video w that id, it starts at that frame\" => \"ed  e ie et       i   t    tttttt t  ttt\"\n",
      "batch 15571  loss=141.9202  steps/s=102.85  prediction: \"requency domain?\n",
      "https://t.co/hEnW40pyZ4\" => \"e   t ess s s}s å€‘#[[#èµ°#[á´˜[â™‚XÉ´á´„,]]4}ðŸ˜¤â€ð—¿#,\"\n",
      "batch 15573  loss=137.2020  steps/s=104.38  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  ttteett tbe be       i   i       d  d \"\n",
      "batch 15574  loss=147.4922  steps/s=103.93  prediction: \"about things that have significant value\" => \"toe  ttts   ttett aa tt tth  hat  aiaa a\"\n",
      "batch 15575  loss=180.7987  steps/s=86.10  prediction: \"xluffyb Its almost side project saturday\" => \" e t   ta  2t ttt aa t st i  iiai aata a\"\n",
      "batch 15577  loss=164.0618  steps/s=108.84  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" aas ehllss h l  l lle p peepepttttt////\"\n",
      "batch 15578  loss=148.2894  steps/s=99.78  prediction: \"s and sugar and i dont get tired anymore\" => \" ahl  u    as  aa    a     d   d     t  \"\n",
      "batch 15579  loss=156.5666  steps/s=103.64  prediction: \" and functional, genius place for a blog\" => \"tnd   nm  mn  e  n  ninn n nn n  n  a   \"\n",
      "batch 15580  loss=146.8623  steps/s=104.15  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"eal    on n,nVteâ€™__8:I(x888vI8_8_)_-&â€™â€™;\"\n",
      "batch 15581  loss=145.5557  steps/s=104.37  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y tttnelngenaa aaaaaaaaatttttttttt//////\"\n",
      "batch 15582  loss=154.1298  steps/s=94.81  prediction: \"[listen to tpod] https://t.co/T4E8ws1uTP\" => \"lo   tll st    t tt ttt ttttttt///////tT\"\n",
      "batch 15583  loss=154.4604  steps/s=103.45  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \"g\n",
      "tiesici liiiiilllll    i              \"\n",
      "batch 15584  loss=167.5603  steps/s=98.12  prediction: \"by_builds another $20 trillion to ludwig\" => \"e isiclllllillihhh  h r        rrl d  d \"\n",
      "batch 15585  loss=137.0036  steps/s=106.27  prediction: \" pays off immensely when I stick to them\" => \"tit  ttf ff  f  ff   m         e        \"\n",
      "batch 15586  loss=148.0398  steps/s=103.29  prediction: \"tbh, i like having control over my tools\" => \"hoe e tsf ff  et          i       o  ooo\"\n",
      "batch 15587  loss=138.1796  steps/s=104.60  prediction: \"l? I guess maybe low level memory stuff?\" => \"y  n an     s a         llllllleeeeeeeee\"\n",
      "batch 15588  loss=143.0589  steps/s=104.83  prediction: \"house? where is your phone charger? etc)\" => \"er  yoyoe e  e re  e e      eo h  h rrer\"\n",
      "batch 15589  loss=148.7364  steps/s=104.53  prediction: \"memory of doing a hard thing in the past\" => \"eteoelt  a                              \"\n",
      "batch 15590  loss=139.3733  steps/s=104.16  prediction: \"on\n",
      "\n",
      "im guessing you do that a lot to huh\" => \"ue t  tatt es   s ss               t    \"\n",
      "batch 15591  loss=148.7254  steps/s=103.44  prediction: \"anything else would kneecap learning no?\" => \"nd  ih tt th ihni     nn n  e ee ennennn\"\n",
      "batch 15592  loss=170.0307  steps/s=98.82  prediction: \"king stuff part of twitter is so fun wtf\" => \"eng  i n  n g   f    f tff  ee ti it   i\"\n",
      "batch 15593  loss=157.8276  steps/s=99.21  prediction: \"t just means youre on par with a supergm\" => \"hte ter scs sssmts   o                  \"\n",
      "batch 15594  loss=139.6727  steps/s=103.15  prediction: \"ollowers type shit) he shouted me out\n",
      "\n",
      "g\" => \"uli l lll   ll  e    e     e  e       e \"\n",
      "batch 15595  loss=145.3113  steps/s=103.34  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" medhee mde meem eoe tttte t t  ttmttttt\"\n",
      "batch 15596  loss=159.1190  steps/s=108.07  prediction: \"re you need to make a sphere version now\" => \"eple t@HnV   wp Tjbxx:@2vTkx2p.kj/I..CC/\"\n",
      "batch 15597  loss=178.3780  steps/s=30.26  prediction: \"ply: @sunsettler https://t.co/VV0NoHhCJz\" => \"ly: @H ooedeee   t  e    e  a ee e eree \"\n",
      "batch 15599  loss=177.2951  steps/s=109.59  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e g  di#eii# ## #a#aaaaasaststs/////////\"\n",
      "batch 15600  loss=148.5757  steps/s=104.41  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"tor sar   or  er r     ss s ss s  s    e\"\n",
      "batch 15601  loss=160.5190  steps/s=85.29  prediction: \" square gang wont let this happen &gt;:(\" => \"tur garrers s rg g  e ge   ee  e e  n ee\"\n",
      "batch 15603  loss=183.6092  steps/s=26.81  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: @grs eg   g g  e ge    e  e e  n ee\"\n",
      "batch 15604  loss=163.9517  steps/s=147.58  prediction: \"nis @startupmillyair pretty solid rating\" => \" snoo    es esga aa   ti  i tp p    t  ðŸ›‘\"\n",
      "batch 15605  loss=139.5401  steps/s=105.85  prediction: \"oast. silencio until youve made progress\" => \"u  ett   ts s is tiii iiiii  i    o     \"\n",
      "batch 15606  loss=141.8930  steps/s=104.15  prediction: \"ommittal move like going on a sabbatical\" => \"ueme e  mam am t m    e    o          aa\"\n",
      "batch 15607  loss=142.8224  steps/s=105.55  prediction: \"ht. i feel like i barely understand them\" => \"etem ne  e  l             ee   ee ee e e\"\n",
      "batch 15608  loss=159.6245  steps/s=100.91  prediction: \"[listen to tpod] https://t.co/T4E8ws1uTP\" => \"lo   i l st t  t tt ttt ttttttttt/////tt\"\n",
      "batch 15609  loss=170.4490  steps/s=95.46  prediction: \"y childhood was nuketown 2025 and python\" => \":Oosue utntt o t  hot ootttot  222 25o2 \"\n",
      "batch 15610  loss=161.5993  steps/s=81.54  prediction: \"igABAP np bro, you should write more man\" => \"nhs nil ofo nodo    oo ooo 2 o n w  ton \"\n",
      "batch 15611  loss=236.2477  steps/s=15.22  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"eply: @aeewceAeePx@,/b#\",vOPx#kx[#2k#50v\"\n",
      "batch 15612  loss=141.8646  steps/s=110.62  prediction: \"think bc they burn through the same fuel\" => \" an io ekh     t       h  h th hh hhhh  \"\n",
      "batch 15613  loss=162.1638  steps/s=100.58  prediction: \"p in the readme\n",
      "\n",
      "https://t.co/dWiO4erSb1\" => \"lie @   t\n",
      " tet  ee\n",
      "tet\n",
      "e\n",
      "tttteettttt////\"\n",
      "batch 15614  loss=152.2211  steps/s=98.01  prediction: \"re even now then lol\n",
      "yea my disc has one\" => \"eplytp@naxhh á´¡raIG'%*I}'.c::vð—¶..j:/WWO44\"\n",
      "batch 15615  loss=130.4332  steps/s=103.80  prediction: \"ments as opposed to making the user wait\" => \"e ye  t  n  nesesssss   s  o            \"\n",
      "batch 15616  loss=144.7872  steps/s=104.31  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \" r  ((eg =l t=stI)@,AI\"\"B1=1B0(/,10WW.,â€¦\"\n",
      "batch 15617  loss=137.9551  steps/s=102.98  prediction: \"the material itself or a battery\n",
      "\n",
      "right?\" => \"he  se eer  me  eee    l l      t  rrtrt\"\n",
      "batch 15618  loss=154.3778  steps/s=98.13  prediction: \"new following you was the right decision\" => \"  gt e rthr    llw w w  ww   t      h t \"\n",
      "batch 15619  loss=147.2460  steps/s=103.66  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tt teiiiiinniiiiiiiiiiiiiiiiiii         \"\n",
      "batch 15620  loss=154.8497  steps/s=104.57  prediction: \"l. but really, I have absolutely no clue\" => \"y  ng g pn   pp            al   a lll ll\"\n",
      "batch 15621  loss=144.9532  steps/s=103.16  prediction: \"der the hood the better you can innovate\" => \" rnt t   nn n e h e   tteeet e e      o \"\n",
      "batch 15622  loss=172.4106  steps/s=103.10  prediction: \" 4min miles, need to know whats possible\" => \"tnt ia m  i mm m        e          w   o\"\n",
      "batch 15623  loss=141.7496  steps/s=104.41  prediction: \"hitectures. it only finds different MLPs\" => \"esc nenet ectetttet       i  i    i ffff\"\n",
      "batch 15624  loss=165.1093  steps/s=103.85  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" mo    anf nt  ata aa t a t / /// t//tto\"\n",
      "batch 15625  loss=148.7281  steps/s=103.56  prediction: \"potential. then one day, it all explodes\" => \"lsn  nttt teettttttt nt               l \"\n",
      "batch 15626  loss=142.1961  steps/s=105.10  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"nt s tt fg  c gciccciciiaiaaiaaaaaaaap  \"\n",
      "batch 15627  loss=155.5581  steps/s=104.53  prediction: \"/t.co/zlto3SBYwd https://t.co/Izzdx8c2HJ\" => \"/.crs d/or////o///ttttt/tt/::/t/tt/zzzzz\"\n",
      "batch 15628  loss=143.6753  steps/s=105.08  prediction: \" component that approximates transformsâ€¦\" => \"toneo co  noooono t tttatpatttaattttaaaa\"\n",
      "batch 15629  loss=142.3088  steps/s=99.88  prediction: \"Some Tal games are real art masterpieces\" => \" mehoenmm nom maama aaaaaaaa aaaar rrtar\"\n",
      "batch 15632  loss=162.5822  steps/s=73.45  prediction: \"minus9 hmm still pixels on my end, weird\" => \"eno   mm am     m  eell  a r    e   eeee\"\n",
      "batch 15633  loss=173.4762  steps/s=106.61  prediction: \" ITTTTTTTTTTTTT\n",
      "\n",
      "https://t.co/7uhSNn1VI6\" => \"t ryT1 LTTTTTTTT TT\n",
      "\n",
      "\n",
      "EEt  \n",
      "\n",
      "/t\n",
      "\n",
      ":S/7S7S\"\n",
      "batch 15634  loss=163.9715  steps/s=104.84  prediction: \" blindfolded and win 80% (timur garayev)\" => \"tu     l  lll dedddd ddd d d   i   i   i\"\n",
      "batch 15636  loss=147.0383  steps/s=103.73  prediction: \", how much info could you get from that?\" => \" so   iiii n  wm  o     o  oo   o    o  \"\n",
      "batch 15637  loss=145.1841  steps/s=104.05  prediction: \"t\n",
      "so.. hopefully i can get it to do that\" => \" \n",
      "j i t   pepeeee e                     \"\n",
      "batch 15639  loss=150.4158  steps/s=97.44  prediction: \"imated stills have finally been defeated\" => \"ne  t aa na alell  ll    lll   e e   eee\"\n",
      "batch 15640  loss=161.1287  steps/s=41.89  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \"  @ane anean.la l  li l aall   e ee  eee\"\n",
      "batch 15641  loss=153.9085  steps/s=107.48  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \"pm irs ee ne e s e s  es s          er r\"\n",
      "batch 15642  loss=142.8052  steps/s=101.59  prediction: \"u ship cool things and make ppl have fun\" => \" whee s nn p  n                         \"\n",
      "batch 15643  loss=199.6284  steps/s=87.69  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"  wu sh  p M  RR    E      tppp///      \"\n",
      "batch 15644  loss=155.3317  steps/s=98.76  prediction: \" to make it better before (if) I release\" => \"thed c  cn    e   tt tt t  ee ee  eeere \"\n",
      "batch 15645  loss=174.1545  steps/s=33.09  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: ea  ee  UeEett e tteee ee e   eeeree\"\n",
      "batch 15646  loss=130.0653  steps/s=72.28  prediction: \"st: caffeine is steroids but for posting\" => \" :hen e dn   e ttt ettteee ee e   eeeree\"\n",
      "batch 15647  loss=141.1819  steps/s=110.37  prediction: \"t progress/mistakes made/lessons learned\" => \" ro  o t  s tresrrssssssseesssseessessse\"\n",
      "batch 15648  loss=163.3731  steps/s=68.50  prediction: \"2wlearning Great stuff man, keep pushing\" => \"5  rrarerrsrers eesessesaeesseseeeeeeese\"\n",
      "batch 15649  loss=140.1333  steps/s=105.99  prediction: \" keep doing it for more and more phrases\" => \"tnn ngenneeeneee  e                 r   \"\n",
      "batch 15650  loss=145.8624  steps/s=100.93  prediction: \"nd stop you from seeking rewards in life\" => \"  eee  d n    u  oo   o             r   \"\n",
      "batch 15651  loss=145.9050  steps/s=102.92  prediction: \"r taxes and splitting with other winners\" => \"etss tfd)de?eviyá´„I|ðŸ“‰)bIÉ´T|á´›$(â™‚$bbx|ðŸŽ‰$É´((\"\n",
      "batch 15652  loss=148.6605  steps/s=102.09  prediction: \"e but it really is super flawed probably\" => \" lio  teletle  llll lll e     eeeeee   l\"\n",
      "batch 15654  loss=152.8038  steps/s=101.69  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \"  e   i i f fi  iiii s    s sts s t ss t\"\n",
      "batch 15655  loss=144.1434  steps/s=96.93  prediction: \"Some Tal games are real art masterpieces\" => \"  Em inim n n m  e   aa   ea   aereaatae\"\n",
      "batch 15656  loss=150.2999  steps/s=95.96  prediction: \"P get him toys, play w him, lasts longer\" => \" Rhi toA A  e        a    a    a a  l ss\"\n",
      "batch 15657  loss=140.7104  steps/s=103.90  prediction: \"mindset that kills the call to adventure\" => \"en i tit et ttttttt t tt t     l   l    \"\n",
      "batch 15658  loss=151.3012  steps/s=96.76  prediction: \"nes thanks brother!! its good to be free\" => \" rete tt  te  h t t s  t !  !        o e\"\n",
      "batch 15659  loss=144.6479  steps/s=99.99  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tn . h ..n.eeenteen   nn                \"\n",
      "batch 15660  loss=152.4502  steps/s=104.50  prediction: \"mentals can be really really hard to see\" => \"e t mo monss na  n aaa  aaalall  alll   \"\n",
      "batch 15661  loss=193.1007  steps/s=39.03  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"y: @u\n",
      "nuenss nas neaaa ealllall   ll    \"\n",
      "batch 15662  loss=142.3356  steps/s=109.07  prediction: \" pool (at least once seems cold tho ngl)\" => \"tott ooooto t ht        e e e e eee  e  \"\n",
      "batch 15663  loss=182.8065  steps/s=28.74  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly:  bot ot t e        eee  e e         \"\n",
      "batch 15664  loss=146.4840  steps/s=108.97  prediction: \"t the procedure for doing this is on mac\" => \" ros  e tht  e t  trr eer  o o   o   o  \"\n",
      "batch 15665  loss=162.1533  steps/s=104.99  prediction: \" so this helped\n",
      "\n",
      "Are you gonna continue?\" => \"tuat  ns i   s       s           e   nn \"\n",
      "batch 15666  loss=146.0876  steps/s=102.78  prediction: \"you could just make move that looks good\" => \":u s nny y n  w         u         oo  oo\"\n",
      "batch 15667  loss=146.6198  steps/s=104.12  prediction: \" have to reprompt it like 1/3rd the time\" => \"tad           e                         \"\n",
      "batch 15668  loss=144.7126  steps/s=104.10  prediction: \"mul, transitions from one derivative toâ€¦\" => \"ect m en  mamigittitiinin  nn   n io   i\"\n",
      "batch 15669  loss=175.4637  steps/s=51.03  prediction: \": @djcows you can make the jungle levels\" => \" @-tme   co  Tan\n",
      "ï¸.W)UWzâ€x,Iâ™‚((j)',(ðŸ¤¦PO5\"\n",
      "batch 15670  loss=141.1407  steps/s=107.44  prediction: \" onto it forever and never reevaluate it\" => \"tn e rnon n t  o  o       n eerevvereeee\"\n",
      "batch 15671  loss=144.5187  steps/s=100.51  prediction: \"plate btw if u wanna make ur own version\" => \"ly: el eebt tet  t  t a   a             \"\n",
      "batch 15672  loss=149.4281  steps/s=105.14  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"t  o o   y      y   y  tttttttt/////////\"\n",
      "batch 15673  loss=171.4418  steps/s=82.54  prediction: \"koslib Also just saw the Eu/acc, respect\" => \" stooos   sy y    ttttssttt//t////ccbbbb\"\n",
      "batch 15674  loss=149.6301  steps/s=109.95  prediction: \"ate? i mean i can guess, but.. nice work\" => \"t so 2     aa  c                  ... . \"\n",
      "batch 15675  loss=192.1548  steps/s=96.38  prediction: \"@___________11hz helped me out with mine\" => \"lonah21e _______________1_e eee e    e  \"\n",
      "batch 15676  loss=147.0041  steps/s=103.05  prediction: \"seconds to go to jail and ruin your life\" => \" 2   e   rs t  t  o  o  o    a    o   o \"\n",
      "batch 15677  loss=172.0993  steps/s=102.55  prediction: \"as irl but the ppl here are way higher x\" => \"n i      o    b                      e  \"\n",
      "batch 15678  loss=152.6980  steps/s=103.79  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o   me  ne e ee ee r    e  e       e ee\"\n",
      "batch 15679  loss=145.7392  steps/s=95.55  prediction: \"see more details as you unblur an image.\" => \" 2eedseo e e eee eee  e       a      u  \"\n",
      "batch 15680  loss=159.7682  steps/s=101.43  prediction: \" at like 8pm\n",
      "\n",
      "Every restaurant offers it\" => \"tn e ne f eeeee   8e  eeee eeee rrrr rr \"\n",
      "batch 15681  loss=152.0078  steps/s=101.20  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf arre e   n n     e ttttssttsst//tts//\"\n",
      "batch 15683  loss=136.8136  steps/s=102.91  prediction: \" to use. code is linked in another reply\" => \"toe  e epet tosee   esee se iie    ee en\"\n",
      "batch 15685  loss=180.8433  steps/s=36.99  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly eer eset   eee   es e    iin    ee en\"\n",
      "batch 15686  loss=151.7678  steps/s=147.04  prediction: \"wphones Love the plan, sounds meaningful\" => \"eh  @r t soo  e e   se   n nnnne nn eeeðŸ›‘\"\n",
      "batch 15687  loss=141.6345  steps/s=104.62  prediction: \"eful/true)\n",
      "\n",
      "sometimes thisll take months\" => \" ust  esseeseueuueeeeeeeeeeesttttttttttt\"\n",
      "batch 15688  loss=143.6791  steps/s=102.77  prediction: \" deadlines dont really get done the same\" => \"tot   nodedede d  ddd ee e le   e tet ee\"\n",
      "batch 15689  loss=147.5874  steps/s=102.98  prediction: \"om the distribution of (single response)\" => \"u  ferfff e r t ii riitiii iii  ii  i   \"\n",
      "batch 15690  loss=179.2232  steps/s=30.06  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @t  ter e riii riitiio iiio  i  s ne\"\n",
      "batch 15691  loss=145.3590  steps/s=111.72  prediction: \"avorite password what would it be?? haha\" => \"te e  c      aa   a aa   wwww  w        \"\n",
      "batch 15692  loss=170.3438  steps/s=96.55  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" t   aoknkakksa  a a   rzz z          ah\"\n",
      "batch 15693  loss=145.0177  steps/s=105.73  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  hne  n    ttt    ttttttttttttt//t//t\"\n",
      "batch 15694  loss=152.9285  steps/s=102.76  prediction: \"re advanced in the art of shape rotating\" => \"eplo  n5onAtt,tII)Tâ€@yS(%~@Sá´€:@z5.WRH95,\"\n",
      "batch 15695  loss=142.0612  steps/s=105.85  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" re t lilnlnnlnnnnn n nn  ttt ttttt/////\"\n",
      "batch 15696  loss=155.0758  steps/s=103.02  prediction: \"d you man. Yea whenever you can do join!\" => \" ins ie       i         eeeeeeeee  e    \"\n",
      "batch 15698  loss=143.2484  steps/s=104.93  prediction: \"ouraging way, not stressful for the kid)\" => \"     cgggaggegggnnnnnnn                 \"\n",
      "batch 15699  loss=149.6730  steps/s=100.86  prediction: \"am and it doesnt mess your sleep up much\" => \"teen hn  a n  d              sssss      \"\n",
      "batch 15700  loss=148.6279  steps/s=104.72  prediction: \" but its worth it\n",
      "\n",
      "just make stuff thatâ€¦\" => \"tudeer tnhg   ttt th ttt tttt tttttt ut \"\n",
      "batch 15701  loss=167.1490  steps/s=106.16  prediction: \"m tools for speedy development (et al):â€¦\" => \"eho g t ooom o sososo  o  ee e  eee eeee\"\n",
      "batch 15702  loss=136.2081  steps/s=103.17  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \"  e  eoeee e e n    e     e     e  e   e\"\n",
      "batch 15703  loss=147.8663  steps/s=105.02  prediction: \" things other people arent\n",
      "Do new things\" => \"thene r th n thn   t teee tee  ee eee  e\"\n",
      "batch 15704  loss=151.7928  steps/s=101.02  prediction: \"lped me too yrs ago. very inspiring dude\" => \"ysrneeseesssee  e   o             rr i  \"\n",
      "batch 15705  loss=137.8084  steps/s=104.29  prediction: \"oser and closer until you can putt it in\" => \"ut:i tt t  l   l                        \"\n",
      "batch 15706  loss=155.1554  steps/s=94.01  prediction: \"phones Thanks man! its going well so far\" => \"lo:e@ t  nno s  n nn   o              t \"\n",
      "batch 15707  loss=148.6516  steps/s=107.14  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" to  one nlel  l  a        a    sss ss o\"\n",
      "batch 15708  loss=174.1871  steps/s=73.27  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"   t s hlahl  al  oh     s s  susss eooo\"\n",
      "batch 15709  loss=151.4945  steps/s=105.08  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \" g t sttwor rpeespssspssssstsssst//t/t//\"\n",
      "batch 15710  loss=138.2569  steps/s=105.01  prediction: \"to a prompt, auto copied to my clipboard\" => \"     t t      n t t       o    o      o \"\n",
      "batch 15711  loss=147.4118  steps/s=102.23  prediction: \"e a great idea\n",
      "\n",
      "i should do this too tbh\" => \" rly     a    a a     e       d         \"\n",
      "batch 15712  loss=173.8617  steps/s=83.88  prediction: \"yon Super hyped to see what youre cookin\" => \":u   r  ea e aede   e dd d      t  oooo \"\n",
      "batch 15713  loss=179.4349  steps/s=70.70  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"lewpanp eaee eede\n",
      "  ee  e    o  t  ootoo\"\n",
      "batch 15714  loss=145.1117  steps/s=110.36  prediction: \"interested to hear how well it works our\" => \"n   a   n   t ee  ee e e  e  e       w  \"\n",
      "batch 15715  loss=148.8518  steps/s=102.08  prediction: \"important piece of advice here by a mile\" => \"npna aca a n t n   t     e  eeee e e    \"\n",
      "batch 15717  loss=148.4792  steps/s=94.02  prediction: \"MTB a dollar flowing through the economy\" => \"TB iiaea anana  o ool    o  e    h  e   \"\n",
      "batch 15718  loss=153.0400  steps/s=104.53  prediction: \"ncy, and bitcoin was invented by midwits\" => \" e m= eccit   nn           nnnn  nn     \"\n",
      "batch 15719  loss=146.6274  steps/s=102.74  prediction: \" is actually happening behind the scenes\" => \"@n e     e    l  aaaa aaa    n  nh   eee\"\n",
      "batch 15720  loss=199.2536  steps/s=91.75  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"/.o  t tolltltoolltln   hthh ttt   eeeee\"\n",
      "batch 15721  loss=168.0435  steps/s=103.54  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"  s//stxp n naaa taaaad nd aadd  ladlddl\"\n",
      "batch 15722  loss=146.6430  steps/s=105.01  prediction: \"uq?\n",
      "\n",
      "this freaked me out, didnt know ifâ€¦\" => \"nurd  e  a  raer  ee eee eee  e   d dd  \"\n",
      "batch 15723  loss=153.9651  steps/s=104.52  prediction: \"st? I believe Jesus gave us the playbook\" => \"t io mi  mt t e   ee eeeeeeesee e   e   \"\n",
      "batch 15724  loss=146.9596  steps/s=105.27  prediction: \"k in college it worked for me super well\" => \"eib   b    cc  l                      ee\"\n",
      "batch 15725  loss=137.9158  steps/s=106.68  prediction: \"able for whoever owns the algorithm/site\" => \" to2  e te tr    ee e  ee ee e  o oe o o\"\n",
      "batch 15726  loss=144.4188  steps/s=104.30  prediction: \"icians and is a net negative for society\" => \"t    dcci tti nii         a             \"\n",
      "batch 15727  loss=142.5621  steps/s=104.64  prediction: \"s is pretty cool https://t.co/2VR6GTbI3d\" => \" coa   iih    t  t t    tttttttoot//tt//\"\n",
      "batch 15728  loss=191.7449  steps/s=20.89  prediction: \"eply: @yacineMTB https://t.co/H0UMjZbPTA\" => \" ly: @t thn t S  tttt  tttttttt/////tt//\"\n",
      "batch 15729  loss=161.3035  steps/s=118.43  prediction: \"s way\"\n",
      "\n",
      "Thats good, will remember that ðŸ§ \" => \" aon  onoin    g                        \"\n",
      "batch 15730  loss=145.6680  steps/s=100.90  prediction: \"ood direction to get more good direction\" => \" deregieoegd oodeooo o   o  eoeo  ooo  o\"\n",
      "batch 15731  loss=141.1495  steps/s=104.93  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e aoan e t n tnneee e  e e eeeee        \"\n",
      "batch 15732  loss=168.0630  steps/s=50.73  prediction: \"y: @yotzol @Laz4rz dj lazars on the beat\" => \"  @dan tttnnnetleee      e   e          \"\n",
      "batch 15733  loss=131.9288  steps/s=109.41  prediction: \"to it so you can share with your friends\" => \"  t n  tt ttt s                         \"\n",
      "batch 15734  loss=156.4360  steps/s=107.52  prediction: \"new following you was the right decision\" => \" s t   tthn    w o   o  ww  o       h   \"\n",
      "batch 15735  loss=137.7018  steps/s=105.48  prediction: \"ed around the data that flows through it\" => \"    ean ea  d  d d   d  aa  a t  t tt tt\"\n",
      "batch 15736  loss=217.5136  steps/s=102.01  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"  N s_  _yo e_lo?@'RxGINEBUPNGIVEvUAVE0U\"\n",
      "batch 15737  loss=172.2548  steps/s=67.48  prediction: \"@nlevnet that's a great thought actually\" => \"yexinre n  V   P!!!!!!!! t  hh  tt   ttt\"\n",
      "batch 15739  loss=165.2034  steps/s=112.22  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \":taneaeaeneelene  ooloololttoo///ttt////\"\n",
      "batch 15740  loss=140.9034  steps/s=104.96  prediction: \"se? seems like death spiral potential no\" => \"  eo rreeseseeseeeeeee  e e    s     a  \"\n",
      "batch 15741  loss=188.9479  steps/s=104.55  prediction: \"dnt acct for maintenance/electricity tho\" => \" t\n",
      "  ee c c d cd       nnancnaaacneeeeec\"\n",
      "batch 15743  loss=149.8586  steps/s=105.19  prediction: \" into an age with a lot of visual beauty\" => \"tn eg nenne t n n                       \"\n",
      "batch 15744  loss=154.6513  steps/s=103.62  prediction: \"d first..still a bit cloudy but got theâ€¦\" => \" tha   a  ht  tt            t t   t     \"\n",
      "batch 15745  loss=160.8140  steps/s=100.50  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \"  lh    aot  lli  t tttt tttttt /t//ty//\"\n",
      "batch 15746  loss=139.2441  steps/s=98.23  prediction: \"ure the first man on mars thats so crazy\" => \"ne ee  eeneee et   e               s  s \"\n",
      "batch 15747  loss=138.5857  steps/s=104.19  prediction: \"ness should get\n",
      "otherwise skill issue ig\" => \"dM  oee rees suuss sss eseeeeseessssssii\"\n",
      "batch 15748  loss=160.8938  steps/s=102.08  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n eit t&&gtimimimiiiiiiizznzziii\n",
      "ii     \"\n",
      "batch 15749  loss=151.5231  steps/s=101.01  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"@hae tt  e  a  naaaa aa a aa   a a  a   \"\n",
      "batch 15750  loss=148.4912  steps/s=101.58  prediction: \"o feel cool writing in an alien language\" => \"rde teg rr ooo  e    o       n  lnll nn \"\n",
      "batch 15751  loss=133.7343  steps/s=103.77  prediction: \" for  processing info and learning stuff\" => \"@oa  t   o    g               nnnnnnnnnn\"\n",
      "batch 15752  loss=226.7803  steps/s=102.32  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOEUOOOOOOOOOOOOOOOOOOOOOOOtns //ttEE\"\n",
      "batch 15753  loss=246.1595  steps/s=11.62  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"eply: @N^e T _  EINGkETIFU4KIN::/I.:;/DR\"\n",
      "batch 15754  loss=176.0044  steps/s=113.20  prediction: \"/t.co/2Uz4rraAzL https://t.co/n1Ai0LXyJh\" => \"d.caalat////t/////tzzttzzzzt//tt////t///\"\n",
      "batch 15755  loss=140.1462  steps/s=103.21  prediction: \"ont like tech leave\n",
      "\n",
      "bulking and cutting\" => \"rt t lt t t   tt   eeeeeeeeeeeee      nn\"\n",
      "batch 15756  loss=137.4243  steps/s=104.39  prediction: \"if you have enough courage to go for it.\" => \"n  oa t  i                        oooo o\"\n",
      "batch 15757  loss=139.9675  steps/s=101.76  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" Ilt  eaa txe  eeeeee                  r\"\n",
      "batch 15758  loss=154.5944  steps/s=106.22  prediction: \"... and 4\n",
      "\n",
      "idk about other spaces though\" => \"  i    b.......d                        \"\n",
      "batch 15759  loss=148.5913  steps/s=105.32  prediction: \"s. im betting on that. but i am not sure\" => \"  y t at htt  nn t      ttt tt          \"\n",
      "batch 15760  loss=151.7845  steps/s=103.52  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "ie   @pafoâ€™ O â€™:JYOOOO:OOO:,OxON3XNQk93\"\n",
      "batch 15761  loss=146.7384  steps/s=105.01  prediction: \"ss I need to do keyboard input from it..\" => \" i  t  l lenn nne    e  e  o        o   \"\n",
      "batch 15762  loss=153.5723  steps/s=105.47  prediction: \"k checked him out, followed, thanks mate\" => \"ewe \n",
      " o  chk ckc            ooo     o,  \"\n",
      "batch 15763  loss=182.6943  steps/s=31.81  prediction: \"ply: @ns123abc mad growth, what happened\" => \"ly:  t    kkkckh   oo       ooo     o,  \"\n",
      "batch 15764  loss=177.9264  steps/s=108.11  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \" lue cu tit///â€™/  HHHHHHHHQQQ....Dpptppp\"\n",
      "batch 15765  loss=142.5002  steps/s=107.19  prediction: \"ch though if i cant fix a particular bug\" => \"h ih t. htththth                      aa\"\n",
      "batch 15766  loss=142.8515  steps/s=103.52  prediction: \"e did not seem like the type to work out\" => \" lo r  e a e  f    ee ee  ee eete e t  t\"\n",
      "batch 15767  loss=164.6969  steps/s=104.17  prediction: \"orks but is mvp\n",
      "\n",
      "https://t.co/0jdbSxKeVi\" => \"  mamemmmme    \n",
      "     \n",
      "\n",
      " \n",
      " s ttt/////////\"\n",
      "batch 15768  loss=145.3083  steps/s=104.26  prediction: \"mple py script manages building/updating\" => \"eet ts rooolpps pp psp pessp    iiieii a\"\n",
      "batch 15769  loss=157.5915  steps/s=104.30  prediction: \"you like hearing about progress updates!\" => \" u  inollill ig l ii      ioor  or  r u \"\n",
      "batch 15770  loss=170.9230  steps/s=99.10  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"t     oo0w0000000000   tttt tttssttt////\"\n",
      "batch 15771  loss=184.1290  steps/s=60.54  prediction: \" @AI_Solzhenitsyn it's an acquired taste\" => \"tba   00000000   t  tttttttttt/e////333t\"\n",
      "batch 15772  loss=137.5634  steps/s=106.20  prediction: \"lots of stuff you learn way way way more\" => \"yw  dt   o      ff ff            yy yy y\"\n",
      "batch 15773  loss=144.8801  steps/s=101.83  prediction: \"a monoid in the category of endofunctors\" => \"ntoco sos mm o        o  o o      o onon\"\n",
      "batch 15775  loss=140.7995  steps/s=104.62  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"   y   aaalaeaaaa aaaa  a               \"\n",
      "batch 15776  loss=184.3238  steps/s=62.27  prediction: \"@ludwigABAP ever thought of moving here?\" => \"juaer)a yyaaba a e  a                aa \"\n",
      "batch 15777  loss=146.1055  steps/s=107.58  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" i\" oo aae l af\n",
      "a abab    aaaa a aaa aaa\"\n",
      "batch 15779  loss=145.5962  steps/s=104.61  prediction: \" breadth, right now the latter is bigger\" => \"te e  ed mem  hrr   h   hh   t ttttt   t\"\n",
      "batch 15780  loss=146.6395  steps/s=102.29  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \" e ore    n    nn nn nnnnnnnneneeeenenee\"\n",
      "batch 15781  loss=140.1076  steps/s=104.62  prediction: \"d work that into my current program haha\" => \" to   a  n  w                   rrr  rrr\"\n",
      "batch 15782  loss=147.5710  steps/s=105.30  prediction: \" log(distance) to things instead of theâ€¦\" => \"tiset s  tt t t   t tttt tt tttt t      \"\n",
      "batch 15783  loss=187.5871  steps/s=99.96  prediction: \"ARA \"dont talk to me or my retard again\"\" => \"BAP @ nA b A  b A                      r\"\n",
      "batch 15784  loss=137.2445  steps/s=105.00  prediction: \"sts w good content from this perspective\" => \"  e  no s s soosoooo ooooo t          t \"\n",
      "batch 15785  loss=153.8738  steps/s=104.13  prediction: \"roblem by introducing an extra level ofâ€¦\" => \"emEe  Wi cw  Wt v@0j%A)vFFv}yWjðŸ‘ðŸ“‰[kjFT/d\"\n",
      "batch 15786  loss=144.2580  steps/s=104.25  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"ne to w on no  oooo      ttt  ttttt///ss\"\n",
      "batch 15787  loss=160.1412  steps/s=100.26  prediction: \"i it does look super nice, was gonna say\" => \"n@ on n itittii i o     o    e    o  s  \"\n",
      "batch 15788  loss=211.2893  steps/s=11.70  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eply: @a dcerWgev40IjATvF@vIk,@2:TD\n",
      "4@â€¦@\"\n",
      "batch 15789  loss=145.0745  steps/s=107.97  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"\n",
      "Iue  ed  w  ðŸ‘Œ  [(!Qjz[/Ê€')á´›kA@2F,ðŸŒ‘](Râ€¦ð˜\"\n",
      "batch 15790  loss=148.1409  steps/s=99.71  prediction: \" v. move forward/backward is layer stuff\" => \"tev  c    v             rrrrrraraaaarraa\"\n",
      "batch 15791  loss=157.3446  steps/s=104.78  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \" eth   cenownocr   oraaaar  aaa   a  y  \"\n",
      "batch 15792  loss=160.6378  steps/s=100.48  prediction: \" @btwphones whoa https://t.co/dCCbEgrV7b\" => \"@_a_aehatttthswwhh oww h  s t////////CCC\"\n",
      "batch 15793  loss=159.8722  steps/s=96.91  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":ur aa  77  e   a o ttp tt///t//t.//.../\"\n",
      "batch 15795  loss=141.7219  steps/s=103.66  prediction: \"d luck to step on worms and they stopped\" => \" i  t d  t    tt            o        t  \"\n",
      "batch 15797  loss=153.1086  steps/s=102.57  prediction: \"\n",
      "pull up and crack open a celcius brudda\" => \"\n",
      "u e  nrnrrrt_em@(,$jWGMMj)Z$MMQ,MQB(\n",
      "DD\"\n",
      "batch 15798  loss=151.9494  steps/s=104.34  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nnst t t t  t      t  \" \"               \"\n",
      "batch 15799  loss=179.9741  steps/s=74.13  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"yt aini t t nt  \" ttt  tttt   t to o    \"\n",
      "batch 15800  loss=158.2617  steps/s=109.94  prediction: \"l do bro, never had a french beer before\" => \"yte@l  e b be ed   d         r a  re ere\"\n",
      "batch 15801  loss=145.4206  steps/s=101.93  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"@h    d nen  n niniiiiiiiiiii           \"\n",
      "batch 15802  loss=142.2034  steps/s=103.97  prediction: \"ard to realize. lies are really blinding\" => \"nd  e r nn      a          eeeeeelllllll\"\n",
      "batch 15803  loss=145.3389  steps/s=99.58  prediction: \"ings will continue until morale improves\" => \"n  Ah n ewegl nliii  ninnn    i        i\"\n",
      "batch 15804  loss=150.0941  steps/s=101.97  prediction: \" never rule things out as impossible tbh\" => \"tete  essetneett  eee  t       s sss iss\"\n",
      "batch 15805  loss=135.6263  steps/s=103.12  prediction: \"he end result could look like\n",
      "\n",
      "followed!\" => \"e e   t t teee t e   e     llllloloollll\"\n",
      "batch 15806  loss=155.8060  steps/s=37.25  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y:     eteteeent t      ll llllooloollll\"\n",
      "batch 15807  loss=150.7575  steps/s=124.36  prediction: \"gh Ive been wanting to do a wasm project\" => \" t  tdn   l e  eee                      \"\n",
      "batch 15809  loss=166.3955  steps/s=47.58  prediction: \"y: @yacineMTB ty @elonmusk for the dL/dW\" => \"  @HaN    e    ee                       \"\n",
      "batch 15810  loss=146.6430  steps/s=108.97  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" tnd   d  dd dd d dd     t              \"\n",
      "batch 15811  loss=161.6978  steps/s=103.82  prediction: \"iday\n",
      "Welcome aboard the zig train brotha\" => \"ne   d a feWW aneeae   eaa       a      \"\n",
      "batch 15812  loss=181.1686  steps/s=59.47  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tLnd e do fWW eaeaaea  e eea     b     r\"\n",
      "batch 15813  loss=160.9311  steps/s=107.35  prediction: \" will lose to one w more accurate values\" => \"thah =ii  s l  l                        \"\n",
      "batch 15814  loss=169.1999  steps/s=96.87  prediction: \"s like crack man https://t.co/cRBmHJXUF6\" => \" ts  iil l      e     k   cacctttcc///cc\"\n",
      "batch 15815  loss=136.7893  steps/s=104.42  prediction: \"i is a smart idea to pitch to the public\" => \"nh so  o                    t   tt tttt \"\n",
      "batch 15816  loss=155.3784  steps/s=103.99  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"tocnneet//otg/t/ttttthhtthpt//pt//ttp///\"\n",
      "batch 15818  loss=149.6765  steps/s=104.36  prediction: \"t 200hrs in around the same time you did\" => \"hfeo    tt  t un                        \"\n",
      "batch 15820  loss=134.0568  steps/s=105.52  prediction: \"w if you know they answered w/o thinking\" => \"iw   l b e   o               www  ww    \"\n",
      "batch 15821  loss=151.4964  steps/s=103.72  prediction: \"r tweet was epictetus's two handles idea\" => \"etetn irssstixngx0v,'80Y+Y+I'2f++++II2+v\"\n",
      "batch 15822  loss=147.2794  steps/s=101.61  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n     is  ss siss                       \"\n",
      "batch 15823  loss=148.9508  steps/s=106.61  prediction: \"nce I did one in django I perma switched\" => \"ge \n",
      "tr   cd   c     d           n       \"\n",
      "batch 15824  loss=145.7818  steps/s=100.52  prediction: \"plate btw if u wanna make ur own version\" => \"ly:  t  ebtettm  t  t a   a             \"\n",
      "batch 15825  loss=138.9919  steps/s=103.85  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"thae n n t  n  ne eee eeettttttts////tt/\"\n",
      "batch 15826  loss=149.3830  steps/s=104.07  prediction: \"new super super early on she was the one\" => \" t en  e te   er    eee r er    es e   s\"\n",
      "batch 15827  loss=142.0712  steps/s=104.97  prediction: \"r coding lol. And some chess. Great move\" => \"esd mmpe eshewn 7ZZZ(Z?k???v7G?v(7..AAZÊŸ\"\n",
      "batch 15829  loss=168.4765  steps/s=112.23  prediction: \" @btwphones whoa https://t.co/dCCbEgrV7b\" => \"t_aoa aatn sh hn    oo  hhosss tt/////Ce\"\n",
      "batch 15830  loss=172.3311  steps/s=67.73  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \"swana ahhws h   hhn ht  hhtt///CCCCCCCCC\"\n",
      "batch 15831  loss=136.7327  steps/s=110.34  prediction: \"change it up a bit from the ol .txt file\" => \"ee eo nn t  t t                         \"\n",
      "batch 15832  loss=158.1338  steps/s=105.00  prediction: \"saas #developers https://t.co/GmrQaIKpLs\" => \" kne   #e#ssaeeeseeessssesseess/s///////\"\n",
      "batch 15833  loss=178.5372  steps/s=45.70  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \": @Bssi#easesese seesssse/ss////t///////\"\n",
      "batch 15834  loss=152.5384  steps/s=111.03  prediction: \"uch working tomorrow, key is consistency\" => \"shi o   t otooor oo oooooro    o   o   s\"\n",
      "batch 15835  loss=154.0881  steps/s=75.41  prediction: \"unsettler Ive made a few, its fun indeed\" => \"sci o ooott r orooor r r    w   isssnnin\"\n",
      "batch 15836  loss=205.8130  steps/s=73.57  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"@sutsu rrt tr # mo   m ,  , ,    issnnen\"\n",
      "batch 15837  loss=149.3094  steps/s=105.84  prediction: \"st insights -&gt; spread insights -&gt;â€¦\" => \" -sgt n t; tst  ttsssttsss  s sssssss   \"\n",
      "batch 15838  loss=141.2402  steps/s=100.99  prediction: \" talking to more med school students lol\" => \"@oe e e   t                     o     o \"\n",
      "batch 15840  loss=225.5531  steps/s=11.32  prediction: \"reply: @pixqc ok https://t.co/7zZszIGt52\" => \"eply: @brrrr xruð—¯_z`I/ð—µ`zI[f}7/Z[wwvxx|\n",
      "\"\n",
      "batch 15841  loss=141.1708  steps/s=122.60  prediction: \"ely definitely worth messing around with\" => \" y iniieinineifeiiiiiieeeeiii i     n   \"\n",
      "batch 15842  loss=152.9770  steps/s=96.67  prediction: \"pynch we must accelerate snake\n",
      "snake/acc\" => \"lny @aynnenee n  t t  teee e eesnnnsnnnn\"\n",
      "batch 15844  loss=137.5738  steps/s=102.23  prediction: \" is it some kind of info storage system?\" => \"@t t  ittissi ii  i    i       o    o   \"\n",
      "batch 15845  loss=155.1493  steps/s=104.42  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"hihe w t etene    e  e\n",
      "\n",
      "ee:::::ttt:///OO\"\n",
      "batch 15846  loss=171.8618  steps/s=65.39  prediction: \"@scheminglunatic https://t.co/9wvijoocgK\" => \"aubiegepeememen\n",
      "\n",
      "\n",
      "t\n",
      " ttt:::///./ttOUOOOO\"\n",
      "batch 15847  loss=150.9705  steps/s=106.96  prediction: \"sicily, i hope to see the island one day\" => \" nor    mmimiii ii      e      e  ee   e\"\n",
      "batch 15848  loss=176.2283  steps/s=104.40  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \" acti      t   t                        \"\n",
      "batch 15849  loss=172.8122  steps/s=91.91  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAti  wlwtAA A      l          a    aa \"\n",
      "batch 15850  loss=241.6224  steps/s=11.31  prediction: \"reply: @cachecrab ah, the french defense\" => \"eply: @eurePnhepPC2#/3#4k,5,WSSDDBE)?\n",
      "Bx\"\n",
      "batch 15852  loss=157.5074  steps/s=120.33  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"swii BlA AB BP       o rr ?    ssssseese\"\n",
      "batch 15853  loss=147.8125  steps/s=112.11  prediction: \"er this applies outside of chess as well\" => \" iiit@ uwi  n  s s  s llo e     ss se ss\"\n",
      "batch 15854  loss=144.7115  steps/s=103.17  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to li  s s s g     sssss               \"\n",
      "batch 15855  loss=151.4263  steps/s=100.66  prediction: \"ed me understand https://t.co/LHjT6ITtSs\" => \"p ih  s    eeeeeeee edd dtttt tttt//////\"\n",
      "batch 15856  loss=139.5846  steps/s=46.34  prediction: \"y: @sunsettler write a will just in case\" => \": @salsedheeded  d tt  t tttt/tt/t///TTT\"\n",
      "batch 15857  loss=146.6246  steps/s=121.75  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"Ay @BABee teeeteeee e ee s  sssss   sss \"\n",
      "batch 15858  loss=142.8257  steps/s=101.65  prediction: \" android OS inside of a virtual machine?\" => \"@nd ann d   n  n dd          i       i  \"\n",
      "batch 15859  loss=137.9537  steps/s=103.89  prediction: \"ny depressions ripple to other countries\" => \"  ae  eoe sss messsrsssss  p  e  o ooo o\"\n",
      "batch 15860  loss=156.5776  steps/s=93.32  prediction: \"ex Only if you get a lobotomy afterwards\" => \"ptmaed  neden y  p e e   oooo o ootttrrr\"\n",
      "batch 15861  loss=135.2379  steps/s=104.21  prediction: \"asily, and they compound with each other\" => \"nt eeeallel  l l     y                 h\"\n",
      "batch 15862  loss=144.5124  steps/s=104.93  prediction: \"dless memory related errors (impossible)\" => \" y  mn   mm mmmsee eeerrerrrrrerrrrrrrrs\"\n",
      "batch 15863  loss=147.6744  steps/s=104.77  prediction: \"w zooming forward on an electric scooter\" => \"hbu   n  wowoon oo ooo  o  on      nc  c\"\n",
      "batch 15864  loss=144.9828  steps/s=103.62  prediction: \"I figure if we just do it, ppl will join\" => \" dildbiidliuiii                         \"\n",
      "batch 15865  loss=164.7905  steps/s=105.33  prediction: \"is i second this https://t.co/3JrtWEMXgK\" => \"n  bui irdene n    is st tttttttttt/////\"\n",
      "batch 15866  loss=142.4644  steps/s=104.83  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"nt eet  fg  c gciccciciiaiaaiaaaaaaaap h\"\n",
      "batch 15867  loss=150.2262  steps/s=100.65  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"nt ces twor rre srssspssssstsssstt/t////\"\n",
      "batch 15868  loss=147.7597  steps/s=106.03  prediction: \"esting example of goodharting the reward\" => \"  bt ttteneeettneee eeeee eoooo  o o   r\"\n",
      "batch 15869  loss=204.6454  steps/s=21.15  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @tteeeeeteeeee ee oo  o oo  o o   r\"\n",
      "batch 15870  loss=137.2679  steps/s=111.13  prediction: \"my efficiency. But overall cause its fun\" => \"a e  pte   ee fee                       \"\n",
      "batch 15871  loss=180.7945  steps/s=104.56  prediction: \"ful to me, like use every day type stuff\" => \" l    l   l ll l e    eee e   eeeee yy y\"\n",
      "batch 15872  loss=157.7266  steps/s=102.93  prediction: \"ying/whatever, every monday and thursday\" => \":ngoioo/inogingggnneneeerereeeeeeyy ddd \"\n",
      "batch 15873  loss=148.0649  steps/s=100.32  prediction: \"am and it doesnt mess your sleep up much\" => \"ti   h   a n  d                         \"\n",
      "batch 15874  loss=138.8863  steps/s=103.62  prediction: \"doing stuff their mind doesnt want to do\" => \" n         n  nd                        \"\n",
      "batch 15875  loss=158.7330  steps/s=96.22  prediction: \"nvm then, enjoy your rain water counting\" => \"ga o oyt tttt  tn n n  n      n r   r   \"\n",
      "batch 15876  loss=151.3876  steps/s=106.92  prediction: \"x reddit is the strange people attractor\" => \" ya@reTTTdxxeexteee   e  e    eeteee ete\"\n",
      "batch 15877  loss=146.7817  steps/s=102.60  prediction: \"is such a great productivity improvement\" => \"n s s   ua                    t itttiiti\"\n",
      "batch 15878  loss=132.7137  steps/s=99.41  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"tai   b ttgg      pppp pp               \"\n",
      "batch 15879  loss=211.3251  steps/s=66.39  prediction: \" @458gdb @gizmobly @crypt0x_0 100% agree\" => \"taab   ggg g gppppppp  o   p xx        p\"\n",
      "batch 15880  loss=143.8150  steps/s=106.27  prediction: \"w. Might do one every mon and every tues\" => \"h oe io rotrrortoo  o  o   o        eee \"\n",
      "batch 15881  loss=141.7493  steps/s=103.52  prediction: \"think bc they burn through the same fuel\" => \" a   o  nh n   t       h  h th hh hhhh  \"\n",
      "batch 15882  loss=156.2459  steps/s=103.74  prediction: \"r\"\n",
      "\"uhh no i cant tell you trust me bro\"\" => \"e ro\" iatnnnn.rdIWvv)IL@!A)LAx1))c0100f/\"\n",
      "batch 15883  loss=146.7961  steps/s=102.43  prediction: \" sum bros.. pivot, its worth it trust me\" => \"tem  eo e  r oor.... oo      o ot   ttt \"\n",
      "batch 15884  loss=159.7687  steps/s=101.53  prediction: \"ylde lowkey cant believe zompy said that\" => \":e n ero   w oe    o     tt  e  ti    tt\"\n",
      "batch 15885  loss=166.5573  steps/s=105.42  prediction: \"m tools for speedy development (et al):â€¦\" => \"es   ettomom o sososo  o eee e  eee eeee\"\n",
      "batch 15886  loss=141.1263  steps/s=105.21  prediction: \" to recover from if it becomes a problem\" => \"toe otoo ro   r rorrr r               e \"\n",
      "batch 15887  loss=147.1073  steps/s=101.65  prediction: \"ly beautiful\n",
      "Love seeing stuff like this\" => \"y: aansanaaaaaaeaeeleee eeeeeeeeeefff ff\"\n",
      "batch 15888  loss=171.0979  steps/s=85.58  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" ns  u aeslene ve e eev  e ef  iie    ll\"\n",
      "batch 15889  loss=161.5415  steps/s=105.16  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"n o ol   n     n    dd        r   TTTTTT\"\n",
      "batch 15890  loss=140.0563  steps/s=104.84  prediction: \" keep doing it for more and more phrases\" => \"tnn n enneegneee                    r   \"\n",
      "batch 15891  loss=139.9689  steps/s=104.36  prediction: \"ecurity bots monitoring my whole network\" => \" i     a re   tt oooot oioto o o   o  oo\"\n",
      "batch 15892  loss=137.4793  steps/s=99.19  prediction: \"lves and destroy it all for local optima\" => \"yerra t s seeeses s  e   l     lll l l  \"\n",
      "batch 15893  loss=213.0368  steps/s=110.04  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"t.cssae se//KRNnRRR  t  tt  tttl  oottoo\"\n",
      "batch 15894  loss=188.8699  steps/s=70.35  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ydr aet d///7Rd ZZt nttptt  //t  //NttNN\"\n",
      "batch 15895  loss=140.6307  steps/s=104.23  prediction: \"nomena that i used to not have words for\" => \" ta t nn nenn n                         \"\n",
      "batch 15896  loss=143.0888  steps/s=105.31  prediction: \"h\n",
      "Also good to know abt the muting thing\" => \"eI is d ssodooooooooooooo            ttt\"\n",
      "batch 15897  loss=152.9649  steps/s=102.97  prediction: \"ncy, and bitcoin was invented by midwits\" => \" eali n tit   nn           nnnn  nn     \"\n",
      "batch 15898  loss=155.7888  steps/s=69.27  prediction: \"justalexoki the t has always meant taoki\" => \"est iae nenc inn        na nn n    di tt\"\n",
      "batch 15899  loss=140.1442  steps/s=104.29  prediction: \"y want to use something feeling-relatedâ€¦\" => \" co   bbbbbob     o         ee  eeeeeeee\"\n",
      "batch 15900  loss=134.2277  steps/s=104.47  prediction: \" not their fault imo. that used to be me\" => \"to     tt t t               tt          \"\n",
      "batch 15901  loss=155.4593  steps/s=104.66  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e e  riengenexdo'@U'z:/KUJKvU9JqQCUU%DB\n",
      "\"\n",
      "batch 15902  loss=163.3978  steps/s=92.86  prediction: \"Thanks for joining! You guys are awesome\" => \"hin oti s f s sn  nnnn nonngggoooou ssaa\"\n",
      "batch 15903  loss=166.8684  steps/s=71.95  prediction: \"yMazza my favorite systems administrator\" => \":a  isas a f  on oooin ggssy g sa a esss\"\n",
      "batch 15904  loss=167.6828  steps/s=51.75  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @asa  n f  inioooit t ssy a ss a esas\"\n",
      "batch 15905  loss=213.1459  steps/s=123.58  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"B S ri   OGOOOOGOOOOOOOOO ttta ///ss///t\"\n",
      "batch 15906  loss=169.8639  steps/s=103.29  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"/t.tIl\n",
      "\n",
      "/t/ss///tQQt/ttttt  Z  t axxxx x\"\n",
      "batch 15907  loss=138.3955  steps/s=103.83  prediction: \"and solving their problems/communicating\" => \"nd  lo  nd to nn   n   r   rrrroommmmmmm\"\n",
      "batch 15908  loss=159.9815  steps/s=96.16  prediction: \"7 make money so you can make video games\" => \" I ersc 7g  7en  o e  eo  o mmmo maaimim\"\n",
      "batch 15910  loss=156.5197  steps/s=98.23  prediction: \"n confirm this is a very goated strategy\" => \"goooesn ea annis    o    s  v a  e a  sa\"\n",
      "batch 15911  loss=168.1225  steps/s=100.10  prediction: \" that outputs its own weights and biases\" => \"tha etn   ta tt tt t t tto tt  ts  s  s \"\n",
      "batch 15912  loss=129.0566  steps/s=104.46  prediction: \"ot at the same time/in the same geometry\" => \"uhr  t t t t  t tt  t  t   e  e e ee eee\"\n",
      "batch 15913  loss=155.4631  steps/s=99.16  prediction: \"ssir\n",
      "\n",
      "ill dm you on the 25th with a link\" => \" inis nees   sss    i             hhh  t\"\n",
      "batch 15915  loss=153.0590  steps/s=104.72  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o   n n ne e ee ee r    e  e       e ee\"\n",
      "batch 15916  loss=138.9793  steps/s=105.67  prediction: \", thank God we can function at all loool\" => \" iae l   r    te      a   n       an  a \"\n",
      "batch 15917  loss=251.1779  steps/s=11.47  prediction: \"reply: @cachecrab ah, the french defense\" => \"e ly: a ,naut_esGI2)Tk.GI\"v,,k-GzkkGGNVN\"\n",
      "batch 15919  loss=146.0031  steps/s=110.63  prediction: \"t learning from the things theyre doing.\" => \" ioentels   e ig             t   h      \"\n",
      "batch 15920  loss=145.1479  steps/s=103.06  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"yyt@  n  uee           ttttsttttt///////\"\n",
      "batch 15921  loss=163.1318  steps/s=87.53  prediction: \"upmillyair microsoft is a faulty company\" => \"s r  t tl lisliliittssstttssttt ttttt4qt\"\n",
      "batch 15922  loss=140.9093  steps/s=104.30  prediction: \"es)\n",
      "\n",
      "yea back pain is, well, a pain haha\" => \"  ny   aaelaeaaaa aaaa  a               \"\n",
      "batch 15923  loss=176.8417  steps/s=101.69  prediction: \", no\n",
      "If anyone else does let us know lol\" => \" aa  n  n  n nIn  non   eeoeee       oe \"\n",
      "batch 15924  loss=156.0421  steps/s=101.06  prediction: \" could you tell\" https://t.co/968GsOvdfW\" => \"toy   d       e\"         ltlttttttt/////\"\n",
      "batch 15925  loss=148.8254  steps/s=102.52  prediction: \"g\n",
      "Especially the more complex things get\" => \" \n",
      "go o oggieniilillll     o   ee e e    \"\n",
      "batch 15926  loss=144.2851  steps/s=103.59  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yies nt ss e ea e eeleeeeleeeelle\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ll\"\n",
      "batch 15927  loss=146.2135  steps/s=103.60  prediction: \" company dgaf and you can contact those?\" => \"toree a n en anaaaaa  a   n a a c a c cc\"\n",
      "batch 15928  loss=148.6210  steps/s=104.04  prediction: \"n and id 100% recommend it over The Goal\" => \" a loon d  dd dd     0              e ee\"\n",
      "batch 15929  loss=163.1989  steps/s=48.06  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @ved  dd %d ad  0 00              e eo\"\n",
      "batch 15930  loss=148.9684  steps/s=107.25  prediction: \"or as long as you can\n",
      "\n",
      "thats what he did\" => \"r  s o    ss   s  s       a  aaaaaa  a  \"\n",
      "batch 15931  loss=141.3288  steps/s=104.11  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"r    ot nonn  o  oo    t tt   t   t   ss\"\n",
      "batch 15932  loss=176.7917  steps/s=83.31  prediction: \"wlearning \"Pricing it in\" now 15% faster\" => \" eh  tn otnne  t e   t   tt  t    s s s \"\n",
      "batch 15933  loss=145.2433  steps/s=105.16  prediction: \" something rudimentary could be possible\" => \"tpiine  n n ttn   iin in           e    \"\n",
      "batch 15934  loss=166.4981  steps/s=99.24  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t p tnett n   h    tts tttstttt/t///////\"\n",
      "batch 15935  loss=158.3142  steps/s=101.63  prediction: \"ly easy actually https://t.co/H2M3XYMGwC\" => \"y: oje  aeesaaa aaalya lllllltt/ ///////\"\n",
      "batch 15936  loss=193.4273  steps/s=21.37  prediction: \"eply: @mynamebedan head completely empty\" => \" ly: ea  eseaal aally  llttt/t// /////M/\"\n",
      "batch 15937  loss=148.3934  steps/s=111.12  prediction: \"mes there are 10x rewards for doing this\" => \"a t  oatmmteteeee  eee rreere  r   rr   \"\n",
      "batch 15938  loss=131.5606  steps/s=104.02  prediction: \"sire, and if it sounds good to them\n",
      "\n",
      "idk\" => \" mot et et en hi  i           d  o   ooo\"\n",
      "batch 15939  loss=140.1186  steps/s=99.97  prediction: \"ive sum game players\n",
      "tautologically true\" => \"ne eyei  s  s es        e aaeaatalllllal\"\n",
      "batch 15940  loss=177.8560  steps/s=107.65  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"tbti ni  s a a aaa  tttattttttotttoo///9\"\n",
      "batch 15941  loss=148.1371  steps/s=104.26  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t ak t   o r  Ir     r   o   o  o    t  \"\n",
      "batch 15942  loss=156.2743  steps/s=101.35  prediction: \"ne that sends the html/js/etc files over\" => \" sse   t  tee he  t et thhh ttst tt   e \"\n",
      "batch 15943  loss=162.1331  steps/s=105.88  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tn eol olo sgosi   \"\"iiiiiiiiiiiii i    \"\n",
      "batch 15944  loss=147.0010  steps/s=104.13  prediction: \"al, one of the most cracked players ever\" => \"nl  ooei onee o o o    o       e     eee\"\n",
      "batch 15945  loss=137.0522  steps/s=104.57  prediction: \"n sheeps clothing is probably enough tbh\" => \" aalo s shene ss   s      i         o   \"\n",
      "batch 15946  loss=144.8977  steps/s=105.18  prediction: \"lly using those)\n",
      "https://t.co/igTzLP504q\" => \"y  @den  ue            ttttstttttttt////\"\n",
      "batch 15948  loss=159.2765  steps/s=97.83  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"te  cicleile eetssts\n",
      "\n",
      "thtttttottttittt t\"\n",
      "batch 15949  loss=150.7816  steps/s=101.84  prediction: \"p. maybe you can figure out how to do it\" => \"l   @ omm mdm m  y          u   u     o \"\n",
      "batch 15950  loss=136.8885  steps/s=98.20  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"rn  ppp  o    en     ee ee eeee         \"\n",
      "batch 15952  loss=148.2162  steps/s=99.29  prediction: \"enko Could probably do this w ai now lol\" => \"   p n oo n e el llll  l   h       t    \"\n",
      "batch 15953  loss=162.5719  steps/s=101.24  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"@oaYmmY shs  s        t h      s  sss s!\"\n",
      "batch 15954  loss=145.5293  steps/s=106.00  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"t   s  o    n  iiiiiiinitsttttttttt/////\"\n",
      "batch 15955  loss=154.3358  steps/s=98.52  prediction: \" I got a creality one, works well so far\" => \"t d s b si  n n     tttt atttooo    o   \"\n",
      "batch 15956  loss=189.5878  steps/s=100.33  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"ev   ora@@l@z zWo77o27772222 o ////o///x\"\n",
      "batch 15957  loss=141.1098  steps/s=104.81  prediction: \"tal clarity and less of a need for sleep\" => \" ns  sn neenn  l a  ll    a             \"\n",
      "batch 15958  loss=147.8913  steps/s=104.07  prediction: \"ally fun/challenging/interesting for ppl\" => \"tl m  maaa n a llllllllnnnnnnnnnnnnnnnnn\"\n",
      "batch 15959  loss=178.6955  steps/s=39.65  prediction: \"ly: @pepegawitch https://t.co/SATxjQ6nk5\" => \"y: @ eu a aalla llll//nn/nnnnnnnnnngnnni\"\n",
      "batch 15960  loss=154.1248  steps/s=142.15  prediction: \"tard Interesting can you elaborate more?\" => \" n  t  eletaeltentnngnnnnecceneieeeenrrr\"\n",
      "batch 15961  loss=150.2916  steps/s=106.32  prediction: \"would be insanely useful to do this with\" => \"ark     rnuou   ee ie eeuu uul      e   \"\n",
      "batch 15962  loss=154.9800  steps/s=104.72  prediction: \"aftinginterpreters\n",
      "- got back into 3d pâ€¦\" => \"nter    er eeterertrrrerertrrrtttttt    \"\n",
      "batch 15963  loss=137.3165  steps/s=103.92  prediction: \"but for now ill run whatever ppl ask for\" => \"ut e n   u nn  n                        \"\n",
      "batch 15964  loss=158.1100  steps/s=102.20  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e o s @ t r  S oSkO-x6@OO-q@HABX@MGBxPyâ€¦\"\n",
      "batch 15965  loss=140.2570  steps/s=104.87  prediction: \"anifold, like on the surface of a sphere\" => \"nt on o no    nf   o  o                e\"\n",
      "batch 15966  loss=139.9460  steps/s=104.83  prediction: \"ink in part bc you have more to remember\" => \"ng e etin     i                       e \"\n",
      "batch 15967  loss=133.9017  steps/s=101.15  prediction: \" the atmosphere, such a great experience\" => \"the   e t  e   eeeeheee           eeeeee\"\n",
      "batch 15968  loss=176.0784  steps/s=88.32  prediction: \"ettler @crypt0x_0 @EsotericCofe thanks!!\" => \" i eaeteeetteee, eeh 0 0    e eeeere eee\"\n",
      "batch 15969  loss=137.3565  steps/s=105.14  prediction: \"in places where i found better solutions\" => \"ng to o  o     l        e     e e  ee ee\"\n",
      "batch 15970  loss=140.9375  steps/s=102.88  prediction: \" ig i still dont understand comonads yet\" => \"t  hic   i   i  i       t    d dnndddndn\"\n",
      "batch 15971  loss=179.0456  steps/s=38.53  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @gmn  h   i    t     ttd ddddnndddndn\"\n",
      "batch 15972  loss=138.7327  steps/s=126.91  prediction: \" ill dm you a link to it around the 25th\" => \"tn i eeeellll  l   l            o    t  \"\n",
      "batch 15973  loss=227.0145  steps/s=99.25  prediction: \"ETURNS\n",
      "Wb wb. Great zig project idea btw\" => \"NLNGET@ iteS\n",
      "WSeWD.RGTUGzEzWRzSj.jG)j.RG\"\n",
      "batch 15974  loss=162.9232  steps/s=102.58  prediction: \" thought they became ugly when they fell\" => \"@oe  deddhht  et    e e       e    e  ee\"\n",
      "batch 15975  loss=148.1488  steps/s=104.09  prediction: \"his was a super helpful technique for me\" => \"ene tt  tt t           p     e    eeeee \"\n",
      "batch 15976  loss=149.9329  steps/s=105.80  prediction: \"d of just putting in more and more hours\" => \" io  ini t n  ttt tttt t                \"\n",
      "batch 15977  loss=139.6904  steps/s=105.67  prediction: \" bc random twitter guy said itd be funny\" => \"ty a ma mem         t      t       t    \"\n",
      "batch 15978  loss=167.7825  steps/s=56.58  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tjmm ana    m et  t t t    i            \"\n",
      "batch 15979  loss=142.0196  steps/s=107.20  prediction: \"h yes it is? I would literally sit on aâ€¦\" => \"ei  ututnn  t s                 lllll  l\"\n",
      "batch 15980  loss=147.7266  steps/s=103.62  prediction: \" apart and send each one off to an agent\" => \"tnde  a   a a  aa a  e  a  e      n     \"\n",
      "batch 15981  loss=155.9052  steps/s=95.72  prediction: \"n confirm this is a very goated strategy\" => \" oo rtn ea an tsn   n    s  t    a a  t \"\n",
      "batch 15982  loss=139.9155  steps/s=103.21  prediction: \"ollowers type shit) he shouted me out\n",
      "\n",
      "g\" => \"u i lllll   l   e    e     e  h       e \"\n",
      "batch 15983  loss=147.6039  steps/s=104.32  prediction: \"tuff goes for you\n",
      "gpu stuff is super fun\" => \" ra a s  t f   f     o   uuuuf uuuuu uuu\"\n",
      "batch 15984  loss=206.9975  steps/s=21.30  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly: @t       ofo o      uuuff uuuus uuu\"\n",
      "batch 15985  loss=148.4805  steps/s=138.90  prediction: \"s the magic of doing things from scratch\" => \" o c s  hs ts t t o     o ggg g     s   \"\n",
      "batch 15986  loss=138.7451  steps/s=104.71  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" to e e etetr me    e                   \"\n",
      "batch 15988  loss=136.9015  steps/s=105.23  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y\n",
      " ril lei lll p                 a a   a\"\n",
      "batch 15989  loss=149.4272  steps/s=72.84  prediction: \"almost as bad as jan blocking his bishop\" => \"nlieie l s l ss asa aa  a   a        ni \"\n",
      "batch 15990  loss=150.1671  steps/s=109.94  prediction: \"e (although Josh only mentioned it once)\" => \" faiaiiat ataao hhho hhohohooo   oooo nn\"\n",
      "batch 15991  loss=139.5389  steps/s=105.27  prediction: \"s a natively written zig matmul function\" => \" ae         v  s     i     ttttt    t tt\"\n",
      "batch 15992  loss=152.8576  steps/s=104.01  prediction: \"ways but in many cases it holds you back\" => \" se  al lnl a y    a   a  a             \"\n",
      "batch 15993  loss=142.8364  steps/s=103.03  prediction: \"our mind\n",
      "\n",
      "It helps a lot, did it w chess\" => \" ria iiii  in   n                       \"\n",
      "batch 15994  loss=144.9279  steps/s=103.71  prediction: \"ntries\n",
      "\n",
      "where is singapore on this list?\" => \"  c ro   erererereeereeeee e se ee    i \"\n",
      "batch 15995  loss=147.6620  steps/s=101.91  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" yr s tf f n  fn   n    ff f f   ffff   \"\n",
      "batch 15996  loss=146.3732  steps/s=103.30  prediction: \" been some adventure man. God bless him.\" => \"te    eee snee eeeeeeeeeeeee            \"\n",
      "batch 15997  loss=174.1710  steps/s=99.74  prediction: \"0x_0 how is crypto this good at replying\" => \"x_  oor0xne  @  Y4@Gx_p-Gx_0/-Iz2@-IkMC/\"\n",
      "batch 15998  loss=160.7588  steps/s=97.16  prediction: \"end to work, and they pretend to pay us\"\" => \"   eprptw  ew te  o  to  t  t ttd e tet \"\n",
      "batch 15999  loss=137.3515  steps/s=103.73  prediction: \" my weird posts but im happy nonetheless\" => \"tore en etete  t      t                 \"\n",
      "batch 16000  loss=138.6436  steps/s=103.80  prediction: \"o halt with a general halting function?\"\" => \"uatetontt  t t t  t t      aaa a  a nnn \"\n",
      "batch 16001  loss=138.6371  steps/s=104.83  prediction: \" she got into medschool after graduating\" => \"tta   t  tt t       oo ooooo oooo o    t\"\n",
      "batch 16003  loss=198.9658  steps/s=45.01  prediction: \"y: @Laz4rz based https://t.co/Hykbbb2PTu\" => \"  @  nt   t t      ooo ooooo oo    aaaaa\"\n",
      "batch 16004  loss=147.5508  steps/s=118.87  prediction: \"ool challenge. amazing its down to 112mb\" => \" d a  s   c   acc   aaaa aaaa a a       \"\n",
      "batch 16006  loss=144.6210  steps/s=103.62  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"n  ia i nw id w  dd dddd ddd d d        \"\n",
      "batch 16007  loss=146.6614  steps/s=104.91  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"ni eeeleenahh hraaa r      rer    ee  ee\"\n",
      "batch 16008  loss=164.8669  steps/s=104.56  prediction: \" blindfolded and win 80% (timur garayev)\" => \"tle       l l delddd ddd d d   n   i   i\"\n",
      "batch 16009  loss=177.5041  steps/s=102.35  prediction: \" know some ppl this would help immensely\" => \"tnrl n n!!!   m            o   p   pm   \"\n",
      "batch 16012  loss=141.3500  steps/s=104.62  prediction: \"your post, your app has been declined :(\" => \" u ca n   n n  r     p            e     \"\n",
      "batch 16013  loss=137.2327  steps/s=102.69  prediction: \"better generalizer than the classic MLP?\" => \"lt  e t  tteteteeeeeeeeeeeeee          a\"\n",
      "batch 16014  loss=224.9266  steps/s=98.35  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"w.cttt t//Q:e//QZrZZZhZZZhhtt/ t//tcc///\"\n",
      "batch 16015  loss=202.8418  steps/s=21.38  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @st//:tr/t/ZrZZZhZtthhtt/ t//tcc/KK\"\n",
      "batch 16016  loss=188.5123  steps/s=108.05  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"taatte tvZotvZhvhhtChhttth//// t/cKK9KKðŸ›‘\"\n",
      "batch 16017  loss=168.5495  steps/s=133.16  prediction: \"cle77 arabian mate is a similar good one\" => \"he  @at citc77a aa aaat tsa   s  i siolðŸ›‘\"\n",
      "batch 16018  loss=149.3750  steps/s=102.92  prediction: \"sicily, i hope to see the island one day\" => \" n r m  mmimiii ii             e  ee   e\"\n",
      "batch 16019  loss=148.7140  steps/s=105.37  prediction: \" focus/attention to a negative direction\" => \"tort  us utt ttuottoottt tttttttt  t t  \"\n",
      "batch 16020  loss=184.3107  steps/s=95.12  prediction: \"Dev i gotchu bro https://t.co/RX6EFjv6Nb\" => \" fi ewtuouotto  ootott   t//tt/  e /it66\"\n",
      "batch 16022  loss=162.6583  steps/s=63.05  prediction: \"@scheminglunatic https://t.co/9wvijoocgK\" => \"Budpeu oo ttgun ottottt//////tRX//666jjj\"\n",
      "batch 16023  loss=151.6238  steps/s=106.53  prediction: \"concept, yes\n",
      "\n",
      "2/3 depends on the concept\" => \"hm e@ oan tet ncee  e eeeee e e eeeee   \"\n",
      "batch 16024  loss=152.9659  steps/s=103.78  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et   t ttto o tooo  ooooo ooossssssusuuu\"\n",
      "batch 16025  loss=151.9209  steps/s=104.32  prediction: \"se and 'magically' econ makes more sense\" => \" t le thete    eaaaaaaa  a   aaa      ee\"\n",
      "batch 16026  loss=139.1968  steps/s=107.38  prediction: \"ood and helps you not waste future years\" => \" l i           d     o       o         e\"\n",
      "batch 16027  loss=157.0413  steps/s=104.47  prediction: \"sidering going down a very similar route\" => \" co t isthnsngg iggggggnn    n    ii r  \"\n",
      "batch 16028  loss=171.8285  steps/s=102.80  prediction: \"ebsite https://t.co/fKvh5jFnKh somewhere\" => \" eso         ss t t tt /////tKKKKKKKKhhh\"\n",
      "batch 16029  loss=160.5323  steps/s=101.11  prediction: \"is the platonic form of a platonic form?\" => \"n  y nteene ithte   tt    ofoo   of no o\"\n",
      "batch 16030  loss=173.1228  steps/s=39.51  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: @in een  nthe  ttoo    ofoo   of co o\"\n",
      "batch 16031  loss=161.3521  steps/s=109.99  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"np i e eneneeeieeiiii   t  pttttt////t//\"\n",
      "batch 16032  loss=164.7006  steps/s=100.03  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"ert  n ahhap !na!  a a    aa    dydddddd\"\n",
      "batch 16034  loss=141.4224  steps/s=105.13  prediction: \"lgos to live by, and the art of learning\" => \"yoe  e  er lt  e  l  ,  ,               \"\n",
      "batch 16035  loss=139.0254  steps/s=101.54  prediction: \"finite strings, such as the digits of pi\" => \" n h  o   n  i niiiiiss ssss s          \"\n",
      "batch 16036  loss=159.8072  steps/s=102.84  prediction: \"ice didnt know they made it that low, ty\" => \"ne n na  iii  n i  n       e   tt  tttt \"\n",
      "batch 16038  loss=210.7067  steps/s=95.04  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/.cc dnc:///cRKcRRR   t tt tttttt tttt t\"\n",
      "batch 16039  loss=154.5069  steps/s=103.45  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"ne A  o   o  oo   e e eeee  eeeeeeeeeeee\"\n",
      "batch 16040  loss=176.9023  steps/s=30.47  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly:  b    oo o    eeeeeeee  eeeeeeeeeeee\"\n",
      "batch 16041  loss=147.2883  steps/s=109.96  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"tren aa  n                    o     ooo \"\n",
      "batch 16043  loss=152.6218  steps/s=103.08  prediction: \"ok me a second but damn thats a good one\" => \"ui aepn    m  m o          to   tt a aa \"\n",
      "batch 16045  loss=152.9885  steps/s=103.35  prediction: \"l. but really, I have absolutely no clue\" => \"y  ng g pn   pp            ll l a lll ll\"\n",
      "batch 16046  loss=145.9016  steps/s=101.42  prediction: \" long long time\n",
      "\n",
      "https://t.co/svmrGr008p\" => \"@ot a     g g no ggg    t  tttttottttt//\"\n",
      "batch 16047  loss=147.3604  steps/s=102.65  prediction: \" in the post, only read the abstract tho\" => \"@n       n    nt                       t\"\n",
      "batch 16048  loss=198.1989  steps/s=99.85  prediction: \"07 .-.. ..-. --. --. --. --. --. --. --.\" => \"x   i  o   ur0a 7TYBxPI@7QIw@:JBwPkJBIPk\"\n",
      "batch 16050  loss=191.2527  steps/s=70.63  prediction: \"ZyMazza what do they call this opening??\" => \"yMn  in  .....--   -. -- .-- .--t -- .--\"\n",
      "batch 16051  loss=145.1964  steps/s=108.03  prediction: \"ng and converged to guessing really well\" => \"g aea n nd n  nen      e e ggggggg g gee\"\n",
      "batch 16052  loss=191.1914  steps/s=22.18  prediction: \"eply: @Nominus9 should be out soon   : D\" => \"ply: @a nen nn nn      e egggggggg  e el\"\n",
      "batch 16053  loss=145.2947  steps/s=113.41  prediction: \"ely one-shot by breakfast (i was hungry)\" => \"p itg rgiinono n  o                    a\"\n",
      "batch 16054  loss=271.7039  steps/s=10.22  prediction: \"reply: @IterIntellectus no i forgot srry\" => \"eali: @  hs  É´  $|#$.#{ð—ªðŸ“ˆjv*cð—°$$ÊŸ[-.[:[D\"\n",
      "batch 16055  loss=145.6754  steps/s=107.56  prediction: \"the behavior, forming a habit eventually\" => \"he   h nern e  r re ri  oii i  ah ii a a\"\n",
      "batch 16056  loss=156.9095  steps/s=101.60  prediction: \"e irl. i dare u. https://t.co/NEk2CLBwti\" => \" mot  t t                  t tttt.tt////\"\n",
      "batch 16057  loss=172.4388  steps/s=103.94  prediction: \"ou get like 5 seconds to shoot your shot\" => \"ur R eH n                     ooo  o  s \"\n",
      "batch 16058  loss=148.8007  steps/s=91.54  prediction: \" quarter is another kinda similar banger\" => \"@ud ee elne n n   n  tn      i   i ai ia\"\n",
      "batch 16059  loss=142.7046  steps/s=107.16  prediction: \"re for blundering bc of moving too quick\" => \"eplia @g nss \"nsQT8zYQT%%%qCZkUq%%qU%9â€¦q\"\n",
      "batch 16060  loss=186.5657  steps/s=104.12  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"n    e  n   n  ,   t ttttt  tttttt/t//t/\"\n",
      "batch 16061  loss=181.9747  steps/s=94.28  prediction: \"ly @covix2772 â˜ ï¸ https://t.co/2A3p3rDVtF\" => \"y    n oo o , 2â˜ 2722727ttt::///22/3/3233\"\n",
      "batch 16062  loss=165.5065  steps/s=99.56  prediction: \" know any easy way to work with cuda btw\" => \"tip   nu u    a o y y  a y wwy  w wo    \"\n",
      "batch 16063  loss=144.8686  steps/s=104.97  prediction: \"ve to somewhere else\n",
      "\n",
      "idk just a thought\" => \"e eendeoe eo ennee eeeeeeeeeeee e      t\"\n",
      "batch 16065  loss=149.3226  steps/s=94.81  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" pr  mo  seneeree e  eo     s   ss  \n",
      "ht\n",
      "\"\n",
      "batch 16067  loss=147.7853  steps/s=104.93  prediction: \"e algo show you a lot more similar posts\" => \" aae ot    h    oo  o     o    o    o   \"\n",
      "batch 16068  loss=147.3891  steps/s=98.14  prediction: \"ogan?? was he on sidetweets or something\" => \"uhaoa j n    ?s            eeee eese eee\"\n",
      "batch 16069  loss=147.5289  steps/s=103.56  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \":thyhhit \n",
      "it t iiittt  ts  sa s s  aa   \"\n",
      "batch 16070  loss=146.7789  steps/s=104.58  prediction: \"recommended to device 2, sending one bit\" => \"eply  rT  o oVa JJJJJJJJJJJJ:JJJJJJJJpp+\"\n",
      "batch 16072  loss=141.0425  steps/s=104.57  prediction: \"good idea but whatever, i wanna have fun\" => \" r tnno no  o o    t        aa   aaaa aa\"\n",
      "batch 16073  loss=145.1426  steps/s=103.34  prediction: \"s, have back and forth conversations etc\" => \"  hr  h    ec g a   a                   \"\n",
      "batch 16074  loss=150.3599  steps/s=99.71  prediction: \"nsettler 1min in, its pretty good so far\" => \" \n",
      " or tese ns nn n  n t   n  ttttto  tt \"\n",
      "batch 16075  loss=147.5918  steps/s=103.68  prediction: \" focus/attention to a negative direction\" => \"tort  fs utt ttuottoottt  ttttttt  t t  \"\n",
      "batch 16076  loss=139.8434  steps/s=102.08  prediction: \"he gamer would make for some great games\" => \"e  e o   hrr  m              m    e e e \"\n",
      "batch 16077  loss=150.6027  steps/s=101.03  prediction: \"ressure either turns to dust or to a gem\" => \"eplys  B n  tzt J@zklR,Sw-Flp,1Fkp-'Nx(z\"\n",
      "batch 16078  loss=143.3818  steps/s=104.92  prediction: \"evant documents\n",
      "\n",
      "https://t.co/oLuRW4NPNs\" => \" elrt    ne  o \n",
      "eeeteetttteettttt////t//\"\n",
      "batch 16079  loss=137.4488  steps/s=105.12  prediction: \" or not so i dont have much data on that\" => \"tf   po                                 \"\n",
      "batch 16080  loss=191.6685  steps/s=30.79  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"lyt u  oo                              a\"\n",
      "batch 16081  loss=142.9350  steps/s=107.82  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" r  . ..  n n e      nnnntttttttt///////\"\n",
      "batch 16082  loss=147.3794  steps/s=97.65  prediction: \"ist either way, its all about production\" => \"n .thi itiieti nit  ttt    tt  tttaaooto\"\n",
      "batch 16083  loss=142.9234  steps/s=104.60  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \"neitw nangnnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ww\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nnnoono\"\n",
      "batch 16084  loss=163.0967  steps/s=105.03  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nkpudo\n",
      "ll lll            N t::://t//////\"\n",
      "batch 16085  loss=174.0335  steps/s=104.24  prediction: \" know some ppl this would help immensely\" => \"tnel n !  n   me    p      o   l   lll  \"\n",
      "batch 16086  loss=144.2840  steps/s=104.72  prediction: \"If are not one, you stand out like crazy\" => \"   ee ne e     ne             o         \"\n",
      "batch 16087  loss=155.1518  steps/s=102.89  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y ae aas ss  ss ss s ssttsttttttttt/////\"\n",
      "batch 16088  loss=138.7457  steps/s=104.77  prediction: \"ast 3 weeks so development has been slow\" => \"n  nee   e    s  e  e  e eeee eeeeeeee  \"\n",
      "batch 16089  loss=153.5625  steps/s=98.50  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e l nc _  icw@ icx@88zâ˜ 21O8q21BqBOGGGGz:\"\n",
      "batch 16090  loss=140.9218  steps/s=103.85  prediction: \"nto those traps\n",
      "\n",
      "overall\n",
      "\n",
      "idk maaaan lol\" => \" o ta nett  t  \n",
      "tt  ooo t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "aaaaa\n",
      "\n",
      "a\"\n",
      "batch 16091  loss=146.9213  steps/s=99.07  prediction: \" takes a lot of work and years of it tho\" => \"to  iatanetea  too oo oo\n",
      "oa    a aaa    \"\n",
      "batch 16093  loss=148.7516  steps/s=98.02  prediction: \"ne was right the rates arent high enough\" => \" MTBa s l  aaii       r   aaa  ree   hhe\"\n",
      "batch 16095  loss=230.2813  steps/s=96.02  prediction: \"UR BROBLEM GREEN https://t.co/mstazBvsCM\" => \"IiRWAA WHAYYUU YBUcLLMOGGEMNGRbbNz::/C.:\"\n",
      "batch 16096  loss=138.1722  steps/s=103.18  prediction: \"ment it with all the details that pop up\" => \"e e pe iene         t  tttttttttttttttt \"\n",
      "batch 16097  loss=188.7176  steps/s=96.80  prediction: \"ti @jack Amen. Thanks for posting this ðŸ‘\" => \" ne et ott n ti    h     ee   a t   p p \"\n",
      "batch 16098  loss=143.5201  steps/s=100.67  prediction: \"ant believe I havent been napping before\" => \"nd nt  e e  e e ee eee eeeeeeeeeneenenne\"\n",
      "batch 16099  loss=148.3493  steps/s=103.91  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \" tse ae  e                    s/////p///\"\n",
      "batch 16100  loss=144.4722  steps/s=104.43  prediction: \" the game loop in zig, rendering in cuda\" => \"to te thta t  a                  ie ii  \"\n",
      "batch 16101  loss=158.5168  steps/s=99.69  prediction: \"oesnt matter if its not live.. but still\" => \" s h te   t t  t t     ttt it i    i    \"\n",
      "batch 16102  loss=161.5589  steps/s=104.18  prediction: \"f us have jobs)\n",
      "\n",
      "https://t.co/qTcrhcfjBM\" => \" y  e n  t t   j      sssstttttttt//////\"\n",
      "batch 16103  loss=147.1114  steps/s=103.97  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"nh teelhen hh hraaa r      rer    ee  ee\"\n",
      "batch 16104  loss=151.8214  steps/s=104.27  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"tore   t t et  -e e  eeet\n",
      "\n",
      "ttttt/tt/s///\"\n",
      "batch 16106  loss=147.9109  steps/s=101.99  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" y ti  giinono n  o                    s\"\n",
      "batch 16107  loss=172.4369  steps/s=52.97  prediction: \": @gizmobly beautiful. pioneer type shit\" => \" @niV  a e . =rrK;C=.p=:=jvðŸ¤£c:/=X8-v&;%=\"\n",
      "batch 16108  loss=145.5155  steps/s=110.24  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"g to in  nn n n            ttttttt/////t\"\n",
      "batch 16109  loss=134.2966  steps/s=106.00  prediction: \"do 16hrs tmrw, test this and report back\" => \"  i t   nh    t           t             \"\n",
      "batch 16110  loss=197.1098  steps/s=28.72  prediction: \"ply: @dgant wild https://t.co/0HTLsAprAT\" => \"ly:  t  n  n         ttttt              \"\n",
      "batch 16111  loss=175.5265  steps/s=133.97  prediction: \"wigABAP why a few years\n",
      "\n",
      "do it this week\" => \"atk  d V e wwA wAwww   w     e   e  t   \"\n",
      "batch 16112  loss=152.6640  steps/s=102.16  prediction: \"ttempt to appeal to ipad kid generation?\" => \"her  e eptta apppt tptpp  p  p pi  i i  \"\n",
      "batch 16113  loss=147.3742  steps/s=103.51  prediction: \"r type, i.e. g : (x, context) -&gt; x\n",
      "\n",
      "?\" => \"emi    on n nKtoðŸ¤£@K4)4(x4/4444ðŸ¤£ðŸ¤£ðŸ¤£)@ðŸ¤£&ðŸ¤£ðŸ¤£;\"\n",
      "batch 16114  loss=145.5185  steps/s=105.58  prediction: \"w, weve been going for a few weeks or so\" => \"a t   tt      w   ee    e          e   e\"\n",
      "batch 16115  loss=141.8042  steps/s=102.99  prediction: \" the dark forest from the 3 body problem\" => \"the t de te ee e e r  f r           o o \"\n",
      "batch 16116  loss=151.9486  steps/s=99.67  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"n        ed  d  d  e  e e     e         \"\n",
      "batch 16117  loss=190.2492  steps/s=61.90  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"t td  e ee m ed e    ee e     o       tt\"\n",
      "batch 16118  loss=143.6799  steps/s=107.14  prediction: \" far dang the format looks so much nicer\" => \"tor   nr t     f       o    o oo  ooo  o\"\n",
      "batch 16119  loss=169.9973  steps/s=103.16  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/.awILGGG//ss///tQCCCCt/ t  a  n aa.x   \"\n",
      "batch 16120  loss=169.0922  steps/s=77.44  prediction: \"izmobly you have 3 days or youre blocked\" => \"nm\n",
      "   \n",
      " httQ  ht h h     a  o  5  xoe   \"\n",
      "batch 16121  loss=153.5566  steps/s=105.14  prediction: \"out desktop ðŸ¤·â€â™‚ï¸ https://t.co/dIobkjujRZ\" => \"n  oo  kkkktk k   t  tt ttttttttt/////tt\"\n",
      "batch 16122  loss=145.2615  steps/s=103.75  prediction: \"ploring become really clear to your mind\" => \"ly:o oae r  e be  eee ee leele  ll e   r\"\n",
      "batch 16123  loss=147.5895  steps/s=104.15  prediction: \" focus/attention to a negative direction\" => \"torts  s utt ttuottoottt  ttttttt  t t  \"\n",
      "batch 16124  loss=146.3246  steps/s=104.12  prediction: \"e exposure therapy and learn more abt it\" => \" aooroot  toooet erere e eerere  r    rr\"\n",
      "batch 16125  loss=142.6724  steps/s=95.44  prediction: \"king spheres are infinitely many circles\" => \"en   oiotet seeree e e ee ennnie in   iy\"\n",
      "batch 16126  loss=150.3601  steps/s=105.30  prediction: \"s and $billions\n",
      "\n",
      "https://t.co/JAfCka4QWD\" => \" af ede ddeddd      sss ssssssttt/t/////\"\n",
      "batch 16127  loss=210.2848  steps/s=103.88  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"7913s6t2039A54056B5/4954v5A9313570B40B48\"\n",
      "batch 16128  loss=137.3107  steps/s=103.19  prediction: \" into local files when you need to build\" => \"tn ond t n t   t                        \"\n",
      "batch 16129  loss=143.9752  steps/s=104.81  prediction: \"e, i would also have liked to be yacine\"\" => \"    a  n   n                            \"\n",
      "batch 16130  loss=149.3985  steps/s=103.82  prediction: \"n is a great way to beat some addictions\" => \" two  n   titst tttt    t  t  ta   aaa  \"\n",
      "batch 16131  loss=156.5973  steps/s=107.03  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \"nky  gyyyyll l lo   o        a          \"\n",
      "batch 16132  loss=172.4031  steps/s=101.76  prediction: \"EDM and caffeine\n",
      "https://t.co/xSA2QsenCw\" => \"To e iouo7B{t0e MDM33:BAB.EDMxS,,Q5k:B:D\"\n",
      "batch 16133  loss=145.9860  steps/s=104.61  prediction: \"our sword and over time makes you deadly\" => \"n in  ll wn   r   r    r              e \"\n",
      "batch 16134  loss=232.6645  steps/s=11.67  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"eptyo @bez~.t8eeU8/UU:UUU.UbPP//PPPqU/U~\"\n",
      "batch 16135  loss=147.7295  steps/s=108.09  prediction: \"kind of just whatever I want to pivot to\" => \"in   r  ir  tti t    e     t ett  t  e t\"\n",
      "batch 16136  loss=143.8784  steps/s=103.68  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"  \n",
      "g iss s                              \"\n",
      "batch 16137  loss=155.7048  steps/s=103.22  prediction: \"darin and english which they are meh at)\" => \" n  aem  anne n nn nn        h hh hh h  \"\n",
      "batch 16138  loss=176.8749  steps/s=92.10  prediction: \"ller accurate. really useful distinction\" => \"y pe c ar nenaaeacra h  hhh hl   e e    \"\n",
      "batch 16139  loss=145.8529  steps/s=105.34  prediction: \" the time and not spread important info?\" => \"to   el lll  e                      tttt\"\n",
      "batch 16140  loss=197.6825  steps/s=89.73  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"e dae eL =4|zMss5LA1N.0)Lk110G,x.)Lyb.jW\"\n",
      "batch 16141  loss=141.0684  steps/s=103.54  prediction: \" a lot will impact the rest of your life\" => \"t ltn g n  nn  l                        \"\n",
      "batch 16142  loss=141.0889  steps/s=103.99  prediction: \"minds me of that old gpt engineer script\" => \"ane ipe e  'een                    ee e \"\n",
      "batch 16144  loss=153.4139  steps/s=104.21  prediction: \" right now its just learning on the side\" => \"ter r a r nn  t         t   t    nn     \"\n",
      "batch 16145  loss=171.2917  steps/s=94.63  prediction: \" its crack bro. be careful. i warned you\" => \"tf  ri    r    c    b  br n e   n    i  \"\n",
      "batch 16146  loss=208.7966  steps/s=100.45  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"TI  @  0sik e_io|@ARxGINE,UPNGIVE9UAVE9U\"\n",
      "batch 16147  loss=149.8644  steps/s=101.46  prediction: \"in there for sure\n",
      "Those guys are awesome\" => \"ng e re pep r ree    r  ee ee e     e  e\"\n",
      "batch 16148  loss=152.5833  steps/s=97.22  prediction: \"ki i have an idea but it will cost $1600\" => \" n   ele a     i    ee e    u           \"\n",
      "batch 16149  loss=148.6779  steps/s=101.13  prediction: \" cs maps btw? would love to see pictures\" => \"@oy   a  o  s  s       o    o  o   o    \"\n",
      "batch 16150  loss=170.5482  steps/s=105.31  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"/.k othoo///tt//ttXXCttXXXX:ttttc///tt//\"\n",
      "batch 16151  loss=166.9798  steps/s=104.55  prediction: \" post your progress as you go through it\" => \"arwtttyou  oo  oo  ooo    ss   oo   o   \"\n",
      "batch 16152  loss=141.7776  steps/s=105.38  prediction: \"s of thought, and your ability to thinkâ€¦\" => \" ye  e  n hh  n   hh        a       t ti\"\n",
      "batch 16153  loss=137.6168  steps/s=103.63  prediction: \"e firework chair https://t.co/J6w6odDBx3\" => \" thn n    ne en      rrrrrr rt  ttttt///\"\n",
      "batch 16154  loss=140.7840  steps/s=103.98  prediction: \"t progress/mistakes made/lessons learned\" => \" ro  o o  s tresrrssssssseesssseessessse\"\n",
      "batch 16155  loss=140.8433  steps/s=104.01  prediction: \"oud to yourself, or in your imagination)\" => \"urh ostotnooo oo o ooo  o  o  o    r i i\"\n",
      "batch 16156  loss=148.6801  steps/s=83.55  prediction: \"er cool shit bro gl w your phd\n",
      "\n",
      "followed\" => \"  e oloooo ol   o             r    ioioo\"\n",
      "batch 16158  loss=141.1050  steps/s=105.35  prediction: \"ing and shipping is gonna grow immensely\" => \"ngooe    en  pp nippiiiiinnngg g   g    \"\n",
      "batch 16159  loss=175.4509  steps/s=85.56  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \"   t nt niniii  isss snnsss      /// ooo\"\n",
      "batch 16160  loss=143.7356  steps/s=105.10  prediction: \" and realized idk what it actually means\" => \"tb  s  f f    n    dddd      a   a aaaaa\"\n",
      "batch 16161  loss=160.1188  steps/s=103.73  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"/.dssasts///t/eet/t/ttttt:/t//tt////t/tt\"\n",
      "batch 16162  loss=200.5648  steps/s=94.39  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"4tz z @L .O nTWLAP.!LTF:,WTFmv7C7755zM7j\"\n",
      "batch 16163  loss=193.0811  steps/s=96.77  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/..z4z4::///.KoKRRRZ  tttpp/ttto.///ttGD\"\n",
      "batch 16164  loss=160.7098  steps/s=102.26  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"tn eieva  in edi    ee   t  eeee eeee ee\"\n",
      "batch 16165  loss=171.7546  steps/s=72.39  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"ust r  en e    e e ee   ee eeeee eeeee e\"\n",
      "batch 16167  loss=144.6673  steps/s=105.70  prediction: \"e Bible has treasure but you have to dig\" => \" phrt  i n  etnt    e e e e e   uu   u  \"\n",
      "batch 16168  loss=141.6179  steps/s=105.34  prediction: \"ginal returns idea seems to pop up a lot\" => \" nl  e e raa  n   raa  eee es   ee      \"\n",
      "batch 16169  loss=149.9778  steps/s=105.17  prediction: \"essing\n",
      "You help cure that if you do this\" => \"    essesns s rs    s e                 \"\n",
      "batch 16170  loss=148.2552  steps/s=104.30  prediction: \"unctional adults that they interact with\" => \" s rf s dfn d    u    t t  t  ttttt attt\"\n",
      "batch 16171  loss=148.3200  steps/s=102.95  prediction: \"res a reason they dont but i dont see it\" => \"eply  ayn n t-enHI-k,H-H--HH-----HH-vH--\"\n",
      "batch 16172  loss=153.3416  steps/s=103.46  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"taci  cc   c  c                         \"\n",
      "batch 16173  loss=178.1362  steps/s=84.83  prediction: \"dwigABAP Big win, love it, great job man\" => \" icst cct t t ss     l    o         o   \"\n",
      "batch 16174  loss=144.7928  steps/s=106.11  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \"0 (  eeg  l  =s,P)\n",
      ",Ap.TB1==Bk,/,10:vj,B\"\n",
      "batch 16175  loss=186.0614  steps/s=104.35  prediction: \"YYYYYYYYYYYYYYY\n",
      "\n",
      "https://t.co/xt0RP3tmNR\" => \"pY YYYYYYYYYYYYYYYYYYYBB\n",
      "\n",
      "\n",
      "B BYY\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tR\"\n",
      "batch 16176  loss=154.4887  steps/s=100.08  prediction: \" then yes please https://t.co/kmo21P7CqI\" => \"th   n n teen ene eee eeeetttttt/////tt/\"\n",
      "batch 16177  loss=144.9406  steps/s=105.24  prediction: \"feels better than giving to the homeless\" => \" rcn hh ehneneeteettttt    ttt   ttt    \"\n",
      "batch 16178  loss=150.6617  steps/s=100.14  prediction: \"visualize 5d and if so whats your method\" => \"irt non ui9       i                     \"\n",
      "batch 16180  loss=170.7994  steps/s=103.43  prediction: \"an just do this: https://t.co/1xgV5Vs635\" => \"n yo  _\n",
      "ott  t   t    t tts  :ttt s/t/VV\"\n",
      "batch 16181  loss=158.8699  steps/s=68.19  prediction: \"justalexoki the t has always meant taoki\" => \"ust_ u tt  t t   tth  t:tts ////tsVVVV55\"\n",
      "batch 16182  loss=150.4354  steps/s=108.57  prediction: \"so much better than ppl who dont anyways\" => \"  s  o        t                         \"\n",
      "batch 16184  loss=162.2586  steps/s=90.22  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"etn e eo rdn20n Y@_YYfj_YYYYYbMYkYY..Yb\n",
      "\"\n",
      "batch 16185  loss=149.7107  steps/s=107.16  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ng o   o in   I                         \"\n",
      "batch 16186  loss=142.6021  steps/s=99.74  prediction: \" the scaling laws for language models...\" => \"the t e  tt t t   t    l   l  g g aggggg\"\n",
      "batch 16187  loss=141.7619  steps/s=53.26  prediction: \"y: @sunsettler write a will just in case\" => \"  @Nort the   t   l    a l lg ga   la aa\"\n",
      "batch 16188  loss=143.6095  steps/s=108.51  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"s ti....t tit      s                    \"\n",
      "batch 16189  loss=196.8657  steps/s=53.50  prediction: \": @angkul07 Super awesome\n",
      "Haha over 9000\" => \" Ja    fe ( ðŸ‘€9erSH-HHH-H-H---yH-,-H9)-rb\"\n",
      "batch 16190  loss=152.6378  steps/s=119.38  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"Ai @ Ag   meeeteeee eeee    sssssss s   \"\n",
      "batch 16191  loss=161.4627  steps/s=38.10  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @BAB eneeeeteeee eeeeess sss s     s \"\n",
      "batch 16192  loss=146.0030  steps/s=106.51  prediction: \"s principle imo\n",
      "\n",
      "https://t.co/VzXUJ8r5oL\" => \" op )     nnniii  iiiiiiittttttttt//////\"\n",
      "batch 16193  loss=195.9377  steps/s=89.25  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"poz\"ðŸ’ªQÊ€ðŸ˜ŽðŸ‘Œâ€¦ðŸ’ªðŸ’ª 0 aA%w3@ABM@\")BMwH@kBW4@4MT\"\n",
      "batch 16194  loss=160.4934  steps/s=104.09  prediction: \"ea c and JS and compiled with emscripten\" => \" r it ac a   n     n  ca  c a ii  iei ii\"\n",
      "batch 16195  loss=152.7682  steps/s=87.67  prediction: \"phones Thanks man! its going well so far\" => \"lot @sn    a a  nnan   a  ii  miiiil  ee\"\n",
      "batch 16196  loss=132.9907  steps/s=103.34  prediction: \"d so i felt the need to post the way out\" => \" on ididdd                              \"\n",
      "batch 16197  loss=165.4622  steps/s=99.05  prediction: \"nus9 Thats super useful to know actually\" => \" msoti f  T s     s  e ee  s  u      o  \"\n",
      "batch 16198  loss=138.8943  steps/s=104.56  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"eplyeg@codl n@n x9kT(??DT?k?b)???????b$)\"\n",
      "batch 16199  loss=170.3639  steps/s=99.64  prediction: \"e gets servers/multiplayer working too..\" => \" ary  gigg ee fesseiees slelllrrlerrerot\"\n",
      "batch 16200  loss=145.1437  steps/s=103.55  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"g e een  nnn                    //t///t/\"\n",
      "batch 16201  loss=149.4722  steps/s=98.55  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"AT @BAaee ne eeeeee eeee  sssssssssssss \"\n",
      "batch 16202  loss=179.5103  steps/s=68.36  prediction: \"@IterIntellectus https://t.co/7QXmzFoC4o\" => \"atdineMBBeeneeneet ss essss ss  s     so\"\n",
      "batch 16203  loss=145.1147  steps/s=105.89  prediction: \"\n",
      "\n",
      "\"fly over xyz tourist location for $5\"\" => \"\n",
      "i he @shs l zis%,@x\"z,:9xvz:9x7zX9)$!gk\"\n",
      "batch 16204  loss=265.0865  steps/s=12.08  prediction: \"reply: @AaronPeddle Very very good point\" => \"eply: @shs l z  7,@x\"z,:2xvz:!x7zcN)$5gk\"\n",
      "batch 16205  loss=159.7570  steps/s=109.21  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nm o re OCCS  Se   e    e               \"\n",
      "batch 16206  loss=143.9352  steps/s=102.91  prediction: \"ike the programming skillset example is.\" => \"ne tg  uhgth  e                   llllll\"\n",
      "batch 16207  loss=147.2501  steps/s=105.38  prediction: \"re use at my job instead of adobes stuff\" => \"eplye fFese s2se%MTBPLMjB3L999N9.99W!!!!\"\n",
      "batch 16208  loss=184.2961  steps/s=98.35  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \" y n ioeeo @@ OW@@ @@@@      '  ''''''''\"\n",
      "batch 16209  loss=155.0856  steps/s=103.57  prediction: \"ut you neeeeeed execution skill yourself\" => \"s  wr arrrrrrr re  eee eeeeeeeeeeeee uou\"\n",
      "batch 16210  loss=163.4116  steps/s=96.70  prediction: \"eeping does that https://t.co/uYNTCCWe87\" => \" \n",
      " ro ten e   nee  ett t  t tt ttt/tt///\"\n",
      "batch 16211  loss=141.9540  steps/s=105.44  prediction: \"cies and come up w better ways to learn'\" => \"on   n ininenenc      e                 \"\n",
      "batch 16212  loss=171.3641  steps/s=98.48  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" tiit eAcAceAe eeee_______ _      e e  e\"\n",
      "batch 16213  loss=150.0600  steps/s=103.23  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" ihP o n  dd dd d dd     t              \"\n",
      "batch 16214  loss=141.0851  steps/s=104.94  prediction: \"you can control the models, and its free\" => \" u  ccoc cco cocoo   o   o              \"\n",
      "batch 16215  loss=133.8182  steps/s=102.58  prediction: \"ta but those with a data engine: iteratâ€¦\" => \" re  ot  t tttt ttt           a         \"\n",
      "batch 16216  loss=139.6854  steps/s=104.28  prediction: \"se? seems like death spiral potential no\" => \"  eo rn eseseeseeeeeee  e e    s     a  \"\n",
      "batch 16217  loss=164.8523  steps/s=96.97  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \"  t a e ns s  tl te t   ee   ee too te t\"\n",
      "batch 16218  loss=184.7949  steps/s=21.45  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly: @nsnon s o  te t  oee   ee too tett\"\n",
      "batch 16219  loss=153.9046  steps/s=112.32  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"ed    a   l le leeeeeee                 \"\n",
      "batch 16220  loss=155.7301  steps/s=104.72  prediction: \"sunami\n",
      "- job stuff\n",
      "\n",
      "Mistakes/to improveâ€¦\" => \" neR catn n   on    o f\n",
      "\n",
      "\n",
      "\n",
      "fs\n",
      "sssstsstst\"\n",
      "batch 16221  loss=150.8349  steps/s=98.17  prediction: \"c high entropy stuff that fits the curve\" => \"oTpe taaaoan  m     ts tt fttfttfttt ttt\"\n",
      "batch 16222  loss=145.0887  steps/s=98.53  prediction: \"if you say wala a lot are you a walawala\" => \"ne iacian   n s   a  aaa  ta         aa \"\n",
      "batch 16223  loss=160.5747  steps/s=101.59  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \" d  t msshseteteeeeettttttttttt//t//////\"\n",
      "batch 16224  loss=151.0636  steps/s=100.94  prediction: \"ike a combinatoric sized pain in the ass\" => \"neld noo e  n n  i  iiiiii iiiiiiiii    \"\n",
      "batch 16225  loss=169.1048  steps/s=55.46  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \"  @gu  o e   on i  iiiiiiiiiiiii i      \"\n",
      "batch 16226  loss=149.4493  steps/s=109.93  prediction: \"ter and more efficient than studying imo\" => \" s   i r r rtt  tre e tteeeee eeiettttin\"\n",
      "batch 16227  loss=168.5049  steps/s=98.81  prediction: \"gonna humble him\n",
      "https://t.co/HUMAzXB4rm\" => \" o h tuneo nn    h   n hh h tth////Ht//t\"\n",
      "batch 16229  loss=144.2194  steps/s=102.50  prediction: \"your brain doesnt have weird hooks in it\" => \":u  ee  r r ro    n     e      e    e   \"\n",
      "batch 16230  loss=173.4656  steps/s=95.95  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nA ig  Aigg ig   gyyh hhyt ttto/////oi//\"\n",
      "batch 16231  loss=161.6442  steps/s=101.54  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"@x lo   m mooooooollll  l  l e        e \"\n",
      "batch 16232  loss=157.2178  steps/s=98.31  prediction: \"nis @startupmillyair pretty solid rating\" => \" s    hr en e e  tlllll p l  e     oo l \"\n",
      "batch 16233  loss=187.0589  steps/s=105.14  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"w.c uu ::///t:/tttttOt1111/Ot/tttt//tt//\"\n",
      "batch 16234  loss=162.7023  steps/s=102.42  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"nd   sasna  nn n n     tee  t e nn------\"\n",
      "batch 16235  loss=141.6902  steps/s=104.63  prediction: \"s aside though, why wouldn't that work?)\" => \" (oo   keeskes gs   h hh  hh  h   h w w \"\n",
      "batch 16236  loss=156.4722  steps/s=80.92  prediction: \"minglunatic @kuberdenis im also catholic\" => \"onn   (teninggu hi    uuu dd      t tooo\"\n",
      "batch 16237  loss=148.7633  steps/s=110.73  prediction: \"erIntellectus the italians have returned\" => \" ins Ienth Ittueeteeteleii   iaa  a aaa \"\n",
      "batch 16238  loss=146.2071  steps/s=104.35  prediction: \"tll program all my ML experiments for me\" => \" e  tea on tn  ta  l   ll  ml mm mm     \"\n",
      "batch 16239  loss=152.7717  steps/s=102.23  prediction: \"el editor and gameplay, that sounds cool\" => \" la   ee l     d      a aaaa aaaa aaa   \"\n",
      "batch 16240  loss=150.2046  steps/s=105.46  prediction: \"ger projects the smaller ones get faster\" => \" ts ens roeeroeree  re ee  lelee s eee  \"\n",
      "batch 16241  loss=141.1836  steps/s=104.41  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "i e eelnelle\n",
      "ee eeeeeee ee    e       \"\n",
      "batch 16242  loss=154.5862  steps/s=99.88  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"@e e oe or a  a      or ao    rs rss    \"\n",
      "batch 16243  loss=153.5439  steps/s=98.80  prediction: \"n confirm this is a very goated strategy\" => \" soletm ea oc tr    si s s  i    a    r \"\n",
      "batch 16244  loss=171.9369  steps/s=42.43  prediction: \": @0arity @bayes_street probably yea lol\" => \" @tnesnh C t _s fCjf_FCLfAxuufkvAPy,bbjg\"\n",
      "batch 16245  loss=141.5449  steps/s=106.24  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" to ing lie nll llllllllll,,,, ,,,,     \"\n",
      "batch 16246  loss=162.0044  steps/s=104.42  prediction: \"copy ... etc\n",
      "\n",
      "my bottleneck is LLM speed\" => \"odei    c   ,.e...   .      te          \"\n",
      "batch 16247  loss=159.7333  steps/s=104.10  prediction: \"amming you can make bigger leaps though.\" => \"n       nnn r m  m m   m   gggg    g  g \"\n",
      "batch 16248  loss=144.4001  steps/s=102.84  prediction: \"ers too! dunno\n",
      "\n",
      "love the experiment idea\" => \" s e olelollootoooooooooo oooeeeeeeeeeee\"\n",
      "batch 16249  loss=172.4923  steps/s=97.01  prediction: \" Update it works https://t.co/8M8be8RA4E\" => \"t2twoo td non   oot  tt t ttt  tttt88888\"\n",
      "batch 16251  loss=160.0340  steps/s=99.19  prediction: \" is better though, I should check it out\" => \"tt bemeebeeee te   e hh hh   hh  hh     \"\n",
      "batch 16252  loss=142.0562  steps/s=100.59  prediction: \"nds like a super cool premise for a game\" => \"   ohe  ss es s        u      eo    o   \"\n",
      "batch 16253  loss=180.4545  steps/s=18.87  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @bes  e  h u      e e    eo    o   \"\n",
      "batch 16254  loss=157.8624  steps/s=107.61  prediction: \"yo grand children at 85. gps kids r busy\" => \" u  nn1  5en  ed     d   d           d  \"\n",
      "batch 16255  loss=146.5681  steps/s=104.63  prediction: \"e component is the key to crazy stuff...\" => \" 1ons  ooeonnnt nn  e     e  ee  t   t  \"\n",
      "batch 16256  loss=168.7363  steps/s=99.57  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tst  so     rir\n",
      "  \n",
      "     a  p   lll  l   \"\n",
      "batch 16257  loss=182.1090  steps/s=107.63  prediction: \"ackwards buttons https://t.co/JO2nBFplUJ\" => \"te- o srmaroard raab bstast /tt t//tt//J\"\n",
      "batch 16258  loss=149.8924  steps/s=104.71  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tutu t a atn  t uututttttttttttttttt////\"\n",
      "batch 16259  loss=140.0995  steps/s=106.02  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l n  wa   nn oo   o    ttt  ttttttttttet\"\n",
      "batch 16260  loss=152.9953  steps/s=100.01  prediction: \"l remember the book much better too. ime\" => \"yyo  do b\n",
      "be  beebbeebeebb  be     ee   \"\n",
      "batch 16261  loss=179.6404  steps/s=100.64  prediction: \"ubed making gpt2 from scratch in c(obol)\" => \"te oeemmbeere  eeoom  mm   tet  c tto   \"\n",
      "batch 16263  loss=158.8162  steps/s=106.29  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"   t et ttt h b r o  y   o    to  t  t r\"\n",
      "batch 16264  loss=162.8810  steps/s=102.73  prediction: \"y did my idea :(\n",
      "https://t.co/wC1KdndUrR\" => \":bona e dd dd  ddddd         ::::///////\"\n",
      "batch 16265  loss=157.8191  steps/s=89.80  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"tir   d ii   iii  i   hh  has   ososoo  \"\n",
      "batch 16266  loss=144.7385  steps/s=102.11  prediction: \" time on their hands + survivorship bias\" => \"thet tn     t t                   r ri i\"\n",
      "batch 16267  loss=134.6353  steps/s=106.07  prediction: \"system is non being at the limit of time\" => \"   i  os sss ssssnnn nnn         i   i  \"\n",
      "batch 16269  loss=151.6643  steps/s=104.74  prediction: \"usly gives API access, can also finetune\" => \"n     nmsssmesssses essssesss c ss  css \"\n",
      "batch 16270  loss=164.6483  steps/s=73.66  prediction: \"calbach_ thanks! hope its useful for you\" => \"onerumoul en   a  s se ssc ss   ss   nnn\"\n",
      "batch 16271  loss=177.3787  steps/s=116.43  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" tosncau  a   eujeeee  e s sstu foo// oo\"\n",
      "batch 16272  loss=175.5002  steps/s=103.21  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \"  ec teset ts too  t o ooooosooooooooooo\"\n",
      "batch 16273  loss=141.3118  steps/s=104.51  prediction: \"did something similar w his site i think\" => \" n    ii ani   mim  ii   mi isii  ii  ii\"\n",
      "batch 16274  loss=150.4167  steps/s=105.92  prediction: \"\n",
      "The main idea is to be super productive\" => \"\n",
      "hos  nunllolNtlPYNTONxNONvOS,,:YYYp:w,w\"\n",
      "batch 16275  loss=148.4189  steps/s=98.36  prediction: \"credibly cool to see this project evolve\" => \"oa  @   nonn ion    ooo   o ee   eee  tv\"\n",
      "batch 16276  loss=139.7016  steps/s=97.91  prediction: \"for getting me to read this btw, its fun\" => \" r c  e t  n  t        t     tt  t    t \"\n",
      "batch 16279  loss=137.8650  steps/s=101.93  prediction: \" the parameters corrrect from the start?\" => \"tha nannnaaa a naaarrrerrrrrrrrrrr  rr t\"\n",
      "batch 16280  loss=153.7417  steps/s=104.00  prediction: \"darin and english which they are meh at)\" => \" yn  em  anne n nn nn n      h hh hh h  \"\n",
      "batch 16281  loss=152.3671  steps/s=99.68  prediction: \"atched this 8 times\n",
      "actually cannot stop\" => \"n  eae aan d ihd    ii    t a  aaaa aaat\"\n",
      "batch 16282  loss=149.2000  steps/s=99.17  prediction: \"e IRL, its fundamentals all the way down\" => \" cea ad i s s  di    t aaaaallllllll  t \"\n",
      "batch 16283  loss=162.1727  steps/s=98.60  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" sos sl sss hl   eeell e petteettttt////\"\n",
      "batch 16284  loss=139.9199  steps/s=104.33  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tl a allell  ll lla a aaaaaa      a     \"\n",
      "batch 16285  loss=158.7940  steps/s=104.59  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"  lt o;e;ggee&;g;tgttttttttoo oo    oL  \"\n",
      "batch 16286  loss=140.9640  steps/s=103.45  prediction: \" are no forests where 2+2 truly equals 5\" => \"t  awt         re   e eeeeee e222222    \"\n",
      "batch 16287  loss=144.4705  steps/s=104.76  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"et   i i rbe  hte  eeeeeoe i  sii i     \"\n",
      "batch 16288  loss=156.2083  steps/s=104.33  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"r                      tttttttt/t//////t\"\n",
      "batch 16289  loss=146.3202  steps/s=103.88  prediction: \"discovering new unseen fundamentals, too\" => \" meme   deen   dn nnennnneenennnneennnen\"\n",
      "batch 16290  loss=165.8499  steps/s=106.73  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"thc d  t////t/6//tttttttt:/t//tt////t///\"\n",
      "batch 16291  loss=190.4599  steps/s=69.04  prediction: \"HSVSphere just barely hit max call depth\" => \"aV p  it/tttett ttttNtt/tt/t/ttt/tttcNNt\"\n",
      "batch 16292  loss=139.5902  steps/s=107.83  prediction: \"better generalizer than the classic MLP?\" => \"e   n t   tetereeeeeeeeeereee e e      a\"\n",
      "batch 16293  loss=142.4550  steps/s=99.64  prediction: \"o actually understand the program better\" => \"nte  sn e tl     a aaaa     t   r     rr\"\n",
      "batch 16294  loss=170.3944  steps/s=105.99  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"/.cepso r///ot/t//5/ttttt:/tt/t:////tt//\"\n",
      "batch 16295  loss=164.1898  steps/s=83.36  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \" rotoobuco c cotoit itt/ttptttppittptoqs\"\n",
      "batch 16296  loss=173.1008  steps/s=105.26  prediction: \" ITTTTTTTTTTTTT\n",
      "\n",
      "https://t.co/7uhSNn1VI6\" => \"t deT  yETTTTTTT TTTTTTETTTT\n",
      "Tt\n",
      "\n",
      "TS/7StS\"\n",
      "batch 16297  loss=158.6877  steps/s=102.26  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nn ootiti tiitiit  ot  og  s  g s  gs   \"\n",
      "batch 16298  loss=135.7604  steps/s=88.49  prediction: \"ideo editor I posted earlier\n",
      "took 20mins\" => \"net    ee     e     e   eeee eeeeeeeoooo\"\n",
      "batch 16299  loss=138.3680  steps/s=110.25  prediction: \"r, it felt a little linkediny over there\" => \"e l :neg, sB @som*BVYmB*Y**VV******yN!I!\"\n",
      "batch 16300  loss=153.4957  steps/s=104.99  prediction: \"/t.co/bGCVZbuoNU https://t.co/CPaVjqg1AU\" => \"/.ccbsats\n",
      "t/tt/V////btt/tb////ttC///Ct//\"\n",
      "batch 16301  loss=175.0899  steps/s=105.13  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"ordtttteno ooo   ooo sht ssh tts://tts//\"\n",
      "batch 16302  loss=173.7642  steps/s=29.86  prediction: \"ply: @andrew_pynch fundamentals compound\" => \"ly: ttnwe  owo   ooo sht sst tt////tts//\"\n",
      "batch 16303  loss=157.1823  steps/s=114.31  prediction: \" of all time itd be sebby and his 9 alts\" => \"tf  o    l ll   o   ll  l   b    bb  b  \"\n",
      "batch 16304  loss=152.0363  steps/s=103.11  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "AT   @.apIn _  :%Y+++!:______31G3_EQkv3\"\n",
      "batch 16305  loss=168.5374  steps/s=101.13  prediction: \"e yup same did exactly this, worked well\" => \"rber \n",
      " yi l   y i i e   yt  tt   t e tw \"\n",
      "batch 16306  loss=143.1143  steps/s=103.74  prediction: \"e did not seem like the type to work out\" => \" rorr te a d  f     e ee  ee eete e t  t\"\n",
      "batch 16307  loss=152.5594  steps/s=95.73  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"g l  d  ndnoem mee  eee        t  t t   \"\n",
      "batch 16309  loss=159.0115  steps/s=97.38  prediction: \"n just do things https://t.co/909bTHzmml\" => \"dah  du nt  n   n      t t tt tt tttt/9/\"\n",
      "batch 16311  loss=139.9711  steps/s=100.37  prediction: \"t. have they found the piece yet or what\" => \"  ha in  it t tt            eeee eee  e \"\n",
      "batch 16312  loss=151.0086  steps/s=103.49  prediction: \"mentals can be really really hard to see\" => \"e taio tonss na  n aaa  aaalall  alll   \"\n",
      "batch 16313  loss=152.2813  steps/s=101.17  prediction: \" people who find their work fun win more\" => \"tron e eee p   oo e   e  o       w  w w \"\n",
      "batch 16315  loss=147.5121  steps/s=100.03  prediction: \"o beta testers, and the world soon after\" => \" se   te eet e t  te  ttt  e    t   o  o\"\n",
      "batch 16317  loss=139.5643  steps/s=103.96  prediction: \"d from 15 relevant studies in 10 seconds\" => \" toupumuumem eere       ee  e       e  s\"\n",
      "batch 16318  loss=148.3314  steps/s=104.44  prediction: \"ve gradient it lives in? Something else?\" => \"er  tni teenniiiiiiiiiiiiiii i      e ee\"\n",
      "batch 16319  loss=148.4834  steps/s=104.09  prediction: \"ked bc i could make cool fun stuff in it\" => \"e f  hot h  ooooooo    oo   oo          \"\n",
      "batch 16320  loss=160.5625  steps/s=103.62  prediction: \"o projects, kinda like how momentum does\" => \" dea2 re o t  go eeet    k    o   ooe mm\"\n",
      "batch 16321  loss=152.2556  steps/s=104.89  prediction: \"freedom fighters. ppl who wanted freedom\" => \" on  m t ne e ee ee r    e  e       e ee\"\n",
      "batch 16322  loss=154.0403  steps/s=45.89  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \"  @reree  e   neeee p  p e  e   w  eeeee\"\n",
      "batch 16323  loss=151.8842  steps/s=121.55  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" 1) d w  n ww        t  ttttttttttt///44\"\n",
      "batch 16324  loss=150.4357  steps/s=102.66  prediction: \"f children will build my programs for me\" => \" ioe    mdm   y      ll ll ll l      r r\"\n",
      "batch 16325  loss=157.7428  steps/s=99.51  prediction: \" but also, probably, very poorly sampled\" => \"aed  l lr lo  obob b b, bb,,   py yyyyy \"\n",
      "batch 16327  loss=134.5497  steps/s=102.16  prediction: \"op over and over is the opposite of slop\" => \"nl n r ss   n                    o   o o\"\n",
      "batch 16328  loss=160.2127  steps/s=87.53  prediction: \"igABAP np bro, you should write more man\" => \"nA   oa  p  n o     o   ooo  ooo     oo \"\n",
      "batch 16330  loss=174.6776  steps/s=33.15  prediction: \"ply: @Nominus9 u should raise a series b\" => \"ly: @    nnno on o  oo  ooo  oeoe    ooe\"\n",
      "batch 16331  loss=141.8015  steps/s=108.66  prediction: \"did something similar w his site i think\" => \" d    ii ann   mim  ii   mi ssii  ii  ii\"\n",
      "batch 16333  loss=145.5555  steps/s=102.29  prediction: \" like i can do so much more in python :(\" => \"tikl l l      i                         \"\n",
      "batch 16334  loss=153.7306  steps/s=102.74  prediction: \"d some stuff!!!!\n",
      "https://t.co/160qafZKAk\" => \" ti   is ss !s!!!!!!!!!!ttttttssttttt//t\"\n",
      "batch 16335  loss=181.1339  steps/s=91.18  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \":\n",
      "i s ests f !es tttuttt/tt////////.KK/K\"\n",
      "batch 16336  loss=171.3682  steps/s=34.59  prediction: \"y: @radbackwards God invented it\n",
      "Idk lol\" => \": @tss sde ofs e tttsht//tt////./t/.KKff\"\n",
      "batch 16337  loss=165.8781  steps/s=116.53  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @ a e ee     e    o      o         o\"\n",
      "batch 16338  loss=146.3813  steps/s=102.59  prediction: \"inds the shortest path to get everything\" => \"ng  n   t  t     tt sttttttt ttttt ttttt\"\n",
      "batch 16339  loss=147.5246  steps/s=104.42  prediction: \"us example like this for numerous toolsâ€¦\" => \"rt t neeenmenemmleeelile  e e ee e   e r\"\n",
      "batch 16340  loss=145.4662  steps/s=102.07  prediction: \"hinks he might pick up in future decades\" => \"en  ani nin hhhhh  h h  ii          u   \"\n",
      "batch 16341  loss=144.1590  steps/s=104.07  prediction: \"us example like this for numerous toolsâ€¦\" => \"tt t leeenmenemmleeelile  e e ee e   e r\"\n",
      "batch 16342  loss=149.8526  steps/s=102.85  prediction: \"so much better than ppl who dont anyways\" => \"  so o   n    t                         \"\n",
      "batch 16343  loss=146.0991  steps/s=98.15  prediction: \"so much to develop it? regulatory maybe?\" => \"  s  o   ss c       o         t  t    ee\"\n",
      "batch 16344  loss=240.3432  steps/s=85.58  prediction: \"ST LIKE ME FR FR https://t.co/WZzG9ilSEu\" => \"  mF    t t  E  E  RR R   tttotetttyyy?y\"\n",
      "batch 16345  loss=190.8249  steps/s=24.98  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @t o tE EE E  RR R   tttot/t/tyyyoðŸ›‘\"\n",
      "batch 16346  loss=152.6083  steps/s=107.33  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" e  tyt m           ttttt ttt\n",
      "ittttt////\"\n",
      "batch 16347  loss=140.9911  steps/s=104.49  prediction: \"minds me of that old gpt engineer script\" => \"ene ide e   een                    ee   \"\n",
      "batch 16348  loss=157.2114  steps/s=104.59  prediction: \"you have ffmpeg installed on your system\" => \" u ennent      t    a        e      n   \"\n",
      "batch 16349  loss=174.7460  steps/s=103.30  prediction: \"kers #math #saas https://t.co/mBSvpFLQvZ\" => \"e  pbei#eii# ## #aaaaaaasastststt///////\"\n",
      "batch 16350  loss=148.3992  steps/s=102.92  prediction: \" in terms of your thoughts in each \"era\"\" => \"tt e me  ir   rm        o  o   ot t     \"\n",
      "batch 16351  loss=160.2166  steps/s=99.19  prediction: \"uote tweets work https://t.co/CCGxweEQQ8\" => \"rn  nooeto  ewe ettt tt ttttttttt tCCCCC\"\n",
      "batch 16352  loss=182.6817  steps/s=63.51  prediction: \"@rohitfrx @pixqc https://t.co/qeqtRljvgG\" => \"yidwnooo wteww e ttttttttt///tCCC//C/QQQ\"\n",
      "batch 16353  loss=155.9897  steps/s=115.49  prediction: \" it sucked but couldve been 1000x worse.\" => \"tn t k  t s n t         u  u eee e000000\"\n",
      "batch 16354  loss=133.8122  steps/s=103.88  prediction: \" with a small group of people around you\" => \"to to tt i                 oo    op ooo \"\n",
      "batch 16355  loss=142.0890  steps/s=104.81  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "/cl levveeveeee eeeeeee ee    e       \"\n",
      "batch 16357  loss=147.1046  steps/s=101.70  prediction: \"ly beautiful\n",
      "Love seeing stuff like this\" => \"y: @Nnaanaaeaaae aelee eeeeeeeeeeeeeefff\"\n",
      "batch 16358  loss=256.1862  steps/s=11.63  prediction: \"reply: @esiarpze its good to be back man\" => \"eply: @Nt t@ M9 @*yÊœ*FT.**xTÉ´$0$ðŸ’ª]ÊœRkjqðŸ’ª\"\n",
      "batch 16359  loss=167.0525  steps/s=112.06  prediction: \"/t.co/3niiW6u2N4 https://t.co/AMiuse1VEj\" => \"t.ads t/tc///////ttWWtWtttt///tt////////\"\n",
      "batch 16360  loss=164.5266  steps/s=104.94  prediction: \"us @BasedBeffJezos Some are on the money\" => \"st@l@sese seBeneBBBeBeeeseeeeeee ee  e  \"\n",
      "batch 16361  loss=144.1715  steps/s=104.85  prediction: \"have the opposite happen, do more stuff?\" => \"etpsSe  t oo  te o pp pppp   pppp po   o\"\n",
      "batch 16362  loss=151.6147  steps/s=98.71  prediction: \"a single man who can bench more than 400\" => \"n@eeei_ene  n in     n    nn     nn     \"\n",
      "batch 16363  loss=159.0747  steps/s=84.07  prediction: \"kul07 Nothing beats the classic todo.txt\" => \"elw nn   en    n  n    nn   he  cca n   \"\n",
      "batch 16364  loss=171.0643  steps/s=45.82  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y: @nen  nin   n an    ec   chc cca co0t\"\n",
      "batch 16365  loss=147.1461  steps/s=107.83  prediction: \"to fill them in fast, like you mentioned\" => \"h   ys t it t                           \"\n",
      "batch 16366  loss=163.9112  steps/s=101.58  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"s  yorissen nneononnnnontnnntttttotttt//\"\n",
      "batch 16367  loss=134.7140  steps/s=104.78  prediction: \"se\n",
      "\"sunsettler is the first man on mars\"\" => \" s ts sssheesssssseeee ee ee            \"\n",
      "batch 16368  loss=148.3572  steps/s=105.26  prediction: \"ern of multiplied KPIs pop up semi-often\" => \"  iot t t en  nn   i  ii pipppp  pp  p  \"\n",
      "batch 16369  loss=150.4755  steps/s=93.70  prediction: \"s9 and of course, its subscription based\" => \"   tt i  to t  d o     sss   ssss sppiio\"\n",
      "batch 16370  loss=153.3182  steps/s=104.41  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "ot ar yiio ^)k z:SzGv2&I1;&z,AV7UB?:)2L\"\n",
      "batch 16371  loss=151.6036  steps/s=102.86  prediction: \"anything else would kneecap learning no?\" => \"lg tig ttrthtieni      n n  e ee ennennn\"\n",
      "batch 16372  loss=174.4442  steps/s=100.70  prediction: \"rackpad &gt;&gt; 3 monitors + pc + mouse\" => \"ecly: obweo  +hoP!+z!:/+I.T;z&ju!3Bj:)3L\"\n",
      "batch 16373  loss=141.7387  steps/s=101.90  prediction: \" just need to learn the secret shortcuts\" => \"tud  ki s ses e     e   ee    eeeee eeee\"\n",
      "batch 16374  loss=153.5161  steps/s=101.35  prediction: \"u come up with. Forgetfulness is a bitch\" => \"sc io t  t t   w    o    t  e     ss    \"\n",
      "batch 16375  loss=133.3229  steps/s=102.33  prediction: \"uture w her, and what that would be like\" => \"s  intet    t ge             w          \"\n",
      "batch 16376  loss=211.0217  steps/s=21.38  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly: @tttue    e        h    w     t    \"\n",
      "batch 16377  loss=175.9589  steps/s=101.24  prediction: \"ly: @anish0209 No problem I gotchu man ðŸ«¡\" => \"y: @gtuteee   w    r    h    wt    t    \"\n",
      "batch 16379  loss=182.4917  steps/s=123.34  prediction: \"redibly cool ðŸ˜Ž \n",
      "Do lmk when its up on gh\" => \"eply   c z se2i Iy!8!ðŸ˜Ž/bDy\n",
      "DI\n",
      "D!ðŸ˜Ž.\n",
      "DbðŸ˜Žv\n",
      "\"\n",
      "batch 16380  loss=147.3484  steps/s=104.23  prediction: \"nd then vcs give u money for some reason\" => \"g   fy n   n  en                        \"\n",
      "batch 16381  loss=141.2272  steps/s=104.89  prediction: \"tremendously\n",
      "gets meta gains on learning\" => \"hat    tt eemeneeeeeeeeeteeeeeeeee  n nn\"\n",
      "batch 16382  loss=159.0456  steps/s=96.64  prediction: \"y based. how do you compile zig to wasm?\" => \":ti mneobobedersde d  o    o o   e  i g \"\n",
      "batch 16383  loss=137.4929  steps/s=104.20  prediction: \"f you could 1.2x all the engineers there\" => \" toanga u u uu  uu  d  l   l  l   eeeeee\"\n",
      "batch 16384  loss=148.2297  steps/s=105.78  prediction: \"h hub, only been there once and loved it\" => \"eb e ot           e eeee    eee e eeee e\"\n",
      "batch 16385  loss=146.4931  steps/s=98.92  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" e   en aaseseaee      nnnn nn   n     t\"\n",
      "batch 16386  loss=139.8493  steps/s=104.49  prediction: \"and completely unknown to the other half\" => \"n  o     l l lpllllll  nn nnnn          \"\n",
      "batch 16387  loss=141.8674  steps/s=105.24  prediction: \"compress a lifetime into a few sentences\" => \"ompsissecnc c    e   iii  i        e eee\"\n",
      "batch 16389  loss=140.3613  steps/s=102.14  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"taemt  o   mmmm mmmmm m  mttt tttttppppp\"\n",
      "batch 16390  loss=136.5060  steps/s=105.45  prediction: \"ment it with all the details that pop up\" => \"ene iu tene     ttttt tttttttttttttttt  \"\n",
      "batch 16391  loss=150.0286  steps/s=102.68  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"tblt     tete ane\"\"\"\"\"\"\" e   e   e   so \"\n",
      "batch 16392  loss=164.5479  steps/s=105.50  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \": r eesyyyyyyyyd      dd    iiiiiiiiniii\"\n",
      "batch 16393  loss=178.0303  steps/s=103.73  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OO\n",
      "\n",
      "\n",
      "f   n  n          d   ttt//////////\"\n",
      "batch 16394  loss=147.2112  steps/s=104.51  prediction: \"c too much attention + hasnt been solved\" => \"odeie  a itt  ttt  tt t tttt     t    n \"\n",
      "batch 16395  loss=172.6027  steps/s=75.78  prediction: \"udwigABAP Thanks bro Ill keep em comin ðŸ«¡\" => \"nw litl  t  tt  to t     o t   een   en \"\n",
      "batch 16396  loss=144.1961  steps/s=106.22  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"lcahw  t rse  hte  eeeeeoe i  sii i     \"\n",
      "batch 16398  loss=149.2739  steps/s=103.51  prediction: \" different on your OS. you can google em\" => \"ton tte  hfffe n  e o         y   o   oo\"\n",
      "batch 16399  loss=160.5613  steps/s=101.15  prediction: \"encoded url that leads to discord invite\" => \"   e reeceeceenee  e   e       ddd  dddd\"\n",
      "batch 16400  loss=142.4771  steps/s=104.18  prediction: \"re for blundering bc of moving too quick\" => \"epl n @g ns  #ns9TKKK@TKKKxKKkUOW.q2K66q\"\n",
      "batch 16401  loss=224.8083  steps/s=92.80  prediction: \"/t.co/NlzdO0Z2DA https://t.co/qGWUkC7cdS\" => \"t..e toðŸ¤¦+///+rAZr  b Z  A  o to  ///qqoc\"\n",
      "batch 16402  loss=144.9174  steps/s=105.39  prediction: \" the ladder on what strats are possible.\" => \"thet ot    tt t          t   t  a   a s \"\n",
      "batch 16403  loss=141.4626  steps/s=104.93  prediction: \"than \"heres a tool to solve problem xyz\"\" => \"hen  ie h hrrhhr   r             o o oo \"\n",
      "batch 16404  loss=144.5784  steps/s=105.08  prediction: \" and the professor thought it was a typo\" => \"t d  iii\"i d                            \"\n",
      "batch 16405  loss=137.5519  steps/s=103.51  prediction: \"f a nix rollback could fix their problem\" => \" tmsti i r  i   i  l l     l   l        \"\n",
      "batch 16406  loss=159.0539  steps/s=103.90  prediction: \"m 800 to 2100 in 7 months on chessdotcom\" => \"aaii i w   0 00 0000                  o \"\n",
      "batch 16407  loss=151.4571  steps/s=98.94  prediction: \"h\n",
      "Also good to know abt the muting thing\" => \"e\n",
      " \n",
      "odd dsodooooooooooooo            tt \"\n",
      "batch 16408  loss=138.4917  steps/s=104.99  prediction: \"n stuff that just sounds nice in my head\" => \"daerat s,ettrtt t tt utt ss s s  n      \"\n",
      "batch 16409  loss=152.3127  steps/s=94.71  prediction: \"per solid learning loop, love it love it\" => \"lr  @ us s ll   ss   nnnn n l    o    e \"\n",
      "batch 16410  loss=174.9425  steps/s=92.27  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \"dso ut nuueeejenjeeennn  o e  ttoo/// oo\"\n",
      "batch 16411  loss=157.3795  steps/s=103.81  prediction: \" them for yourself initially? im curious\" => \"thi  n   m m             i i  iiiiliiiii\"\n",
      "batch 16412  loss=146.7702  steps/s=102.19  prediction: \" instead of main https://t.co/K187NvFlSA\" => \"ts m ss tn s snt     t  t tt t /////tt//\"\n",
      "batch 16414  loss=136.5663  steps/s=105.14  prediction: \"et good at the ones youre not so good at\" => \"  ansmeanht   tt                  oooooo\"\n",
      "batch 16415  loss=181.9996  steps/s=99.68  prediction: \"@p0nnnpppppppppp https://t.co/5V1IjMrIYA\" => \"lidwigA  ppppppppppppppppppptpt  t//oo//\"\n",
      "batch 16416  loss=147.4323  steps/s=102.72  prediction: \"etter but pretty good time bender though\" => \"  teotooee ett etttt  ttttttt    ee ee e\"\n",
      "batch 16417  loss=148.0579  steps/s=104.56  prediction: \" muscle for mentally doing them will get\" => \"tort errenrre e rr   e   ll   le    mll \"\n",
      "batch 16419  loss=150.4079  steps/s=103.26  prediction: \"nt do that\n",
      "now it doesnt do that\n",
      "\n",
      "repeat\" => \"d\n",
      "oiht  t  tt tt tt tt oot o tt tt ttttt\"\n",
      "batch 16421  loss=149.3641  steps/s=104.91  prediction: \"nd super useful: https://t.co/i2lqZZ1GQR\" => \"g oo   o u u usuu  uuu  sss:t:::////t //\"\n",
      "batch 16422  loss=161.0516  steps/s=102.76  prediction: \"he making a dingboard clone or something\" => \"er d  g igg  ig     gi   g       oo    o\"\n",
      "batch 16423  loss=144.9557  steps/s=104.78  prediction: \"imize model performance (we are talkingâ€¦\" => \"ne o mi   im e eeeeemoee eeee eee eeee e\"\n",
      "batch 16424  loss=144.6552  steps/s=104.47  prediction: \" that is not working out for some reason\" => \"thee rt t te  r t  t t ot   oo   o  o  o\"\n",
      "batch 16425  loss=181.7109  steps/s=66.16  prediction: \"@startupmillyair https://t.co/c3FxqzjmK3\" => \"guz4ob tett   t i  iotooo   oo o o ro  o\"\n",
      "batch 16426  loss=137.1434  steps/s=107.45  prediction: \"got the bit order backwards or something\" => \" o  ne bgn gt  t      b   r     rrr rr  \"\n",
      "batch 16427  loss=137.9226  steps/s=104.09  prediction: \"cially long term stuff,  makes it harder\" => \"one  et fg le ee                        \"\n",
      "batch 16428  loss=155.8961  steps/s=106.68  prediction: \"s message is NOT approved by square gang\" => \" oa iolssms s 8esss  s            a  r e\"\n",
      "batch 16429  loss=137.9624  steps/s=104.60  prediction: \" a long line? aight imma work on bug xyz\" => \"t  tn a  nn   nnnn  iin iiii   i        \"\n",
      "batch 16430  loss=142.1988  steps/s=102.50  prediction: \"he actual serious dangers of being smart\" => \"ere de   a    ua        e  s   s      s \"\n",
      "batch 16431  loss=140.9280  steps/s=103.87  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tase rn  nrn  n        o      o   o   ii\"\n",
      "batch 16432  loss=147.1264  steps/s=101.85  prediction: \" busy so i havent been posting much my b\" => \"tes  se  ss s s      e   e  e n  n t en \"\n",
      "batch 16433  loss=145.3304  steps/s=104.69  prediction: \", because integrity is incredibly useful\" => \" ao  cfo a  o       e i i ieeii ii ii ii\"\n",
      "batch 16435  loss=167.5464  steps/s=105.86  prediction: \"ger, LETS GET IT\n",
      "https://t.co/ZIDQZp9Vp6\" => \" t ia tonf      TTTTTTTTT    / tIII////Z\"\n",
      "batch 16436  loss=158.9718  steps/s=104.48  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee  e eneneeeeee nnentt ttttttttt////\"\n",
      "batch 16437  loss=213.0664  steps/s=66.23  prediction: \" @Laz4rz IM FREE https://t.co/6zRFYN5bNS\" => \"tNa e een en eâ€¦ n  ttttttt//tt////t///BB\"\n",
      "batch 16438  loss=143.1855  steps/s=105.99  prediction: \"ys end up thinking \"nah they would justâ€¦\" => \"  is  I  a    e         nn  nn n        \"\n",
      "batch 16439  loss=151.6803  steps/s=104.05  prediction: \"2) calculation\n",
      "Works w coding, chess etc\" => \" 9d  t a n na aaaaana    ooo   cc cc ccs\"\n",
      "batch 16440  loss=176.4239  steps/s=102.64  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \"  us tet t ts t o  t o ooooooooooooooooo\"\n",
      "batch 16441  loss=141.8121  steps/s=104.06  prediction: \"ur goal is to obliterate them with ideas\" => \"s eaom hr r   r      o o to t tt  tte  i\"\n",
      "batch 16442  loss=138.5511  steps/s=104.51  prediction: \" of the best habits of all time for sure\" => \"tf  t  t   ettt   t t  b      t      f  \"\n",
      "batch 16443  loss=174.4796  steps/s=102.48  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \" p 4    ni  nofooooollooot ootttto/////q\"\n",
      "batch 16444  loss=147.1284  steps/s=102.29  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \" n f fu  e u  y u  uuu hhhh hhhhhhhhu  p\"\n",
      "batch 16445  loss=163.6815  steps/s=99.50  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tt eol ol   gosi i i\"iiiiiiiiiiiii i i  \"\n",
      "batch 16446  loss=143.7729  steps/s=105.14  prediction: \"g his own CAD thing and calls it dingcad\" => \" irs  w  i n  h       n   nn    n   n   \"\n",
      "batch 16447  loss=144.9502  steps/s=102.84  prediction: \" distracting any kind of multitasking is\" => \"tote et ott t i i           n   i   iiii\"\n",
      "batch 16448  loss=178.0904  steps/s=102.99  prediction: \", no\n",
      "If anyone else does let us know lol\" => \" ion    na n nIn  n y    oe      s    e \"\n",
      "batch 16449  loss=143.5849  steps/s=104.75  prediction: \"s of thought, and your ability to thinkâ€¦\" => \" oe   h n hh  n   hh        a       t ti\"\n",
      "batch 16450  loss=152.2127  steps/s=101.50  prediction: \"he building -&gt; increase skillset loop\" => \"e g in  iiinii  iiii i    i    ii ss s l\"\n",
      "batch 16451  loss=137.5079  steps/s=105.23  prediction: \" does blade+motor=tablesaw or battlebot?\" => \"ten erarr tteeeseeoeoooooeoaeoaotbabbtbb\"\n",
      "batch 16452  loss=168.8790  steps/s=82.88  prediction: \"ebsirak @yacineMTB alexander could never\" => \" per reab b ratdeoaaoeaaaeaaeea to eottl\"\n",
      "batch 16453  loss=171.1690  steps/s=78.53  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"uit ch aeb aaan eeaaeeaadeaae e ee e eer\"\n",
      "batch 16454  loss=146.6281  steps/s=110.04  prediction: \"ly using the word prior kinda wrong here\" => \"y:   bl b  bb b a    r     r  rrrrr  r r\"\n",
      "batch 16455  loss=137.1602  steps/s=104.80  prediction: \"to a prompt, auto copied to my clipboard\" => \"  a  t t        t t       o    o      o \"\n",
      "batch 16456  loss=140.6470  steps/s=104.86  prediction: \"ecurity bots monitoring my whole network\" => \" tao   o re   tt oooot oooto o o   o  oo\"\n",
      "batch 16457  loss=155.0444  steps/s=104.79  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"  cotth h////tthtttthhttttth/ttttt////P/\"\n",
      "batch 16458  loss=152.7742  steps/s=102.85  prediction: \"forming around AI or aroumd a fear of AI\" => \" r s g  n nnn tn      o      r     r    \"\n",
      "batch 16459  loss=153.5464  steps/s=104.10  prediction: \"rings out there that would just ruin ppl\" => \"en l:n atiie k tz)OL11\"?k(jv\"kAIxkjjjw6B\"\n",
      "batch 16461  loss=158.4805  steps/s=99.74  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "iau   tðŸ’ª$|P G tPð—¼GMw[QðŸ§ vðŸ“ˆj[{v$ðŸ’ª[$jjj|É´ðŸ›‘\"\n",
      "batch 16462  loss=146.0969  steps/s=103.74  prediction: \" works when I ask it for complex changes\" => \"towew ww wwwww                          \"\n",
      "batch 16463  loss=170.7245  steps/s=67.71  prediction: \"seatedro c-&gt;wasm and js, all frontend\" => \" ree ee wh w  &                   l   eo\"\n",
      "batch 16464  loss=144.4639  steps/s=109.44  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" h y c  d dd  d                  ???    \"\n",
      "batch 16465  loss=164.5022  steps/s=104.94  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"/..E  gt.t n X /tX PP/P/t3:://:t:ttt./Qt\"\n",
      "batch 16466  loss=151.4189  steps/s=103.31  prediction: \"rings out there that would just ruin ppl\" => \"en l n ltiie k t&&M;110PkPTvMkQQIPjjjEkA\"\n",
      "batch 16467  loss=141.2957  steps/s=104.84  prediction: \"mindset that kills the call to adventure\" => \"eddi   t ettttttttt t tt t     l   l    \"\n",
      "batch 16468  loss=176.5426  steps/s=68.84  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"yd die it tttttt ltll    lll       t  ae\"\n",
      "batch 16471  loss=183.1550  steps/s=111.66  prediction: \"elsio @SWTOR @Upwork It's fun isn't it??\" => \" y   ng@eSS@@ @ @@R@@@@              '''\"\n",
      "batch 16472  loss=141.5487  steps/s=103.89  prediction: \" try to figure out why your brain worksâ€¦\" => \"th ttht  n t tyt t  u      u   y   r  r \"\n",
      "batch 16473  loss=144.5820  steps/s=104.69  prediction: \"g\n",
      "Especially the more complex things get\" => \" \n",
      "in o tngioniillllll     o   ee e e    \"\n",
      "batch 16474  loss=181.4065  steps/s=57.36  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tlo gn oeninllelllell    lee  ee     g t\"\n",
      "batch 16476  loss=146.9908  steps/s=109.80  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r   nt t e             tststtstt/t/////\"\n",
      "batch 16478  loss=151.8740  steps/s=104.74  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"ns  intstttt    s t tptp t tttptttttttt/\"\n",
      "batch 16479  loss=154.1736  steps/s=98.98  prediction: \"! wanted to do something a bit different\" => \"\n",
      "joh@ s nont ta t    t o  o to t  i   ii\"\n",
      "batch 16480  loss=143.6234  steps/s=104.18  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \"ninnwinan\n",
      "nnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nnw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "onnnoooo\"\n",
      "batch 16481  loss=203.9956  steps/s=96.98  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \" @j  m e ierez s41vSBBvRBRBWRLRLOWONSRSP\"\n",
      "batch 16482  loss=141.9026  steps/s=105.17  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e  o t t t n tnneee e  e e eeeee        \"\n",
      "batch 16483  loss=256.5923  steps/s=11.11  prediction: \"reply: @btwphones Thanks! we'll see haha\" => \"ealieIIs h, izd,$Tá´›w$$|,,RL'OOTTOzTPPUSP\"\n",
      "batch 16484  loss=169.9974  steps/s=149.25  prediction: \"@yacineMTB You want us to find our moms?\" => \"yacone ne nuc ceeee e    e     e        \"\n",
      "batch 16485  loss=147.3369  steps/s=107.13  prediction: \"tll program all my ML experiments for me\" => \" et  ea  n tr ata  l   ll  ml mm mm     \"\n",
      "batch 16486  loss=164.3968  steps/s=104.89  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"/... GRV.t.X / /PX XPXPttt:://:t:ttt./Qt\"\n",
      "batch 16487  loss=193.2757  steps/s=99.45  prediction: \"dgrammer best languages in your opinion?\" => \" it  er@r r  remrtt  t s sgsggggagee   s\"\n",
      "batch 16488  loss=151.1452  steps/s=103.30  prediction: \"cipe for less funny + fake feeling posts\" => \"oneotss\n",
      " ereee s    e          fffffee  \"\n",
      "batch 16489  loss=166.3548  steps/s=100.07  prediction: \"g it\n",
      "When I figure out privacy stuff lol\" => \" intr  riW n n  ine i   iiue     uui  ff\"\n",
      "batch 16490  loss=174.7355  steps/s=100.54  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \" tonc n na    a L   LLLLLtt atsttts/////\"\n",
      "batch 16491  loss=163.7535  steps/s=100.46  prediction: \"ho. i like it much much better than rome\" => \"ereinso i  n oon   i            th    tt\"\n",
      "batch 16492  loss=149.0012  steps/s=104.14  prediction: \"ly pretending to give unsolicited advice\" => \"y   rze   rteeht ee       ee e  ii niii \"\n",
      "batch 16493  loss=149.4028  steps/s=104.77  prediction: \" is \"given the context, how relevant isâ€¦\" => \"ts  o k \"\"    \"                eeeeeeeee\"\n",
      "batch 16494  loss=154.3291  steps/s=100.21  prediction: \"eepfake the adobe CEO's face onto Yezhov\" => \" dt d  eee ddehee  eeee e   e           \"\n",
      "batch 16495  loss=144.0017  steps/s=103.40  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" oo  onnn no oo        t  ttttttt/tt////\"\n",
      "batch 16496  loss=160.5123  steps/s=78.96  prediction: \"xqc unironically how much I was drinking\" => \" cinnonoc noni   c  t   ttt ///// ///fs8\"\n",
      "batch 16497  loss=172.0485  steps/s=105.65  prediction: \"eres so little time to things in the day\" => \" I  ee  eleeeet e    t  ttttttt ttt     \"\n",
      "batch 16498  loss=195.3654  steps/s=29.11  prediction: \"ply: @calbch do it\n",
      "i double dog dare you\" => \"ly: @n i eeelelttt t tttttttttt t t     \"\n",
      "batch 16499  loss=142.2383  steps/s=107.71  prediction: \"d into using dishonest middlewit tactics\" => \" be s teene n n   sssnssssiiisdsiididiti\"\n",
      "batch 16500  loss=164.7587  steps/s=91.73  prediction: \"ntellectus little italy?? nah. big italy\" => \"  oa r en neteu isiss iit ii?it ???t it \"\n",
      "batch 16501  loss=162.8653  steps/s=88.67  prediction: \"kul07 Nothing beats the classic todo.txt\" => \" lg  n teini littti    tt l ht lia ititt\"\n",
      "batch 16502  loss=153.8303  steps/s=104.64  prediction: \"e. I can teach you a bit too if you want\" => \"  t s n   an  a     a             o  o  \"\n",
      "batch 16503  loss=137.3931  steps/s=105.81  prediction: \"verything that happens to everyone else'\" => \"eryteete teettt tttttthtt t     e eeeeee\"\n",
      "batch 16504  loss=152.8350  steps/s=100.17  prediction: \"ly got above len=2 for the longest time.\" => \"y: a iat   tt    o         e     e e e  \"\n",
      "batch 16506  loss=140.4046  steps/s=105.24  prediction: \"gh, regardless it needs a lot of work xD\" => \" oune  r   re tr   eeeeees e s e      o \"\n",
      "batch 16507  loss=155.5477  steps/s=104.57  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf   r    de  ri  i  i                  \"\n",
      "batch 16508  loss=140.6850  steps/s=105.28  prediction: \"nd mental storage/organization efficient\" => \"   ee  nnf entt tttt taaaaaataaaaaaiiaii\"\n",
      "batch 16509  loss=150.6373  steps/s=101.39  prediction: \"ice awareness and reading ppl/situations\" => \"nifottptttaaaa aaeaaeaaeeaeen en   aa i \"\n",
      "batch 16510  loss=140.8391  steps/s=103.93  prediction: \"ling down on stuff I initially dismissed\" => \"ykeo  no mnnn   on n     nnn   i iiiiii \"\n",
      "batch 16511  loss=138.7627  steps/s=104.02  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"eaec el n sss f                   y     \"\n",
      "batch 16512  loss=149.1925  steps/s=104.48  prediction: \"y highest elo and post cool results on x\" => \" peloe   st t st    e    o   o   oo   os\"\n",
      "batch 16514  loss=162.7960  steps/s=84.11  prediction: \"by_builds another $20 trillion to ludwig\" => \"e  hothb bl b en    o t  o  lo llllo  t \"\n",
      "batch 16515  loss=150.5076  steps/s=104.89  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"neio  io                     tt/////////\"\n",
      "batch 16516  loss=143.0059  steps/s=104.92  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"eagy  @ie   n\"n JzF97:\n",
      "I0D|7:AO6b,v'AO6V\"\n",
      "batch 16517  loss=146.4175  steps/s=102.31  prediction: \"pen theatre stairs door and ruin the run\" => \"lr: @  nee tetttte t    to     rr      r\"\n",
      "batch 16518  loss=141.7586  steps/s=104.06  prediction: \"r coding lol. And some chess. Great move\" => \"eld tmeeres eA@ 7;;&(&&k&&bv;Gbv(@&&AA&)\"\n",
      "batch 16519  loss=157.0601  steps/s=96.44  prediction: \"nis @sunsettler sun yearns for the mines\" => \"gt oo io    e inln   e  n   ss  eeer   e\"\n",
      "batch 16520  loss=142.5145  steps/s=99.51  prediction: \"credibly cool to see this project evolve\" => \"hel @ nonintel l l   o    e e    ee   ee\"\n",
      "batch 16522  loss=157.3539  steps/s=101.18  prediction: \"ly easy actually https://t.co/H2M3XYMGwC\" => \"y: oje  aee aaa aaal a lltttltt  t//////\"\n",
      "batch 16523  loss=149.7862  steps/s=103.45  prediction: \"ally understand the problem and the goal\" => \"nl   a  l  el  l    e e     ee  e       \"\n",
      "batch 16525  loss=157.0644  steps/s=101.27  prediction: \"ly bc i want one https://t.co/AySfEijpuc\" => \"y: @ vt or  t g       t   ttttt//t/t//t/\"\n",
      "batch 16526  loss=158.2119  steps/s=102.86  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"nlye  oo oo  oo   e e  eee  eeeeeeeeeeee\"\n",
      "batch 16527  loss=132.9426  steps/s=102.02  prediction: \"d so i felt the need to post the way out\" => \" to idiini                              \"\n",
      "batch 16528  loss=149.2231  steps/s=103.70  prediction: \"s. im betting on that. but i am not sure\" => \"  y tnat htt  nn t    t ttt tt          \"\n",
      "batch 16529  loss=141.3245  steps/s=103.48  prediction: \" the most important parts of improvement\" => \"to  t  oetto  oo   ottt t  t ott   tp mm\"\n",
      "batch 16530  loss=142.3350  steps/s=104.57  prediction: \"ite complexity? If not, what is the max?\" => \"n ii diiininiiitiii i                   \"\n",
      "batch 16532  loss=177.5430  steps/s=68.28  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"ydbi i id iAt et i  t                   \"\n",
      "batch 16533  loss=144.9385  steps/s=119.61  prediction: \"cking it was kobe posting the whole time\" => \"o i @ln lit n   a      o    o    t tt   \"\n",
      "batch 16534  loss=154.3622  steps/s=48.09  prediction: \"y: @Nominus9 So no chess players, got it\" => \": @inninin  n  k   o o ss   o    h  t e \"\n",
      "batch 16536  loss=144.6591  steps/s=108.24  prediction: \"c, just separated by some amount of time\" => \"h n  t t,r t   s ta  teee  e        t   \"\n",
      "batch 16537  loss=140.6265  steps/s=104.49  prediction: \"etting up a fake verification system etc\" => \" tent tttttt  e            i iiii iiii e\"\n",
      "batch 16538  loss=138.7533  steps/s=104.52  prediction: \"oast. silencio until youve made progress\" => \"ud yit  tts s is tiii iiiii  i    o     \"\n",
      "batch 16539  loss=138.2727  steps/s=104.38  prediction: \"file editing program, will show vid soon\" => \" neit  ni ien itiiiii i iiii l l   i    \"\n",
      "batch 16540  loss=195.9282  steps/s=96.68  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"ew   tnnei nee  ent     t  .    o/ sso/ \"\n",
      "batch 16541  loss=143.6807  steps/s=98.83  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"ene  ann aoney. yn..  t//../// t:/ZZXXX2\"\n",
      "batch 16542  loss=227.5838  steps/s=10.60  prediction: \"reply: @CreativeBuilds drop playlist son\" => \"eply:MMhhod yAedPkjhj..\":hypp::/Z..XbZZ5\"\n",
      "batch 16544  loss=187.5990  steps/s=145.63  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tCorMa n  ynn..tytt p:t/t..:/ZZtXX2255st\"\n",
      "batch 16545  loss=176.2511  steps/s=92.77  prediction: \" @Yosef_Frost vision: pro\n",
      "execution: slo\" => \"tCor ned  y e0ot0et @:::t@poo.soocsfyoss\"\n",
      "batch 16546  loss=144.2127  steps/s=106.35  prediction: \"a good way to beat addictions in general\" => \"nfei w is s ttooooo    a  aa aa   ii    \"\n",
      "batch 16547  loss=146.6054  steps/s=102.72  prediction: \"ld love to hear if you dont mind sharing\" => \"yir t    ll l  l          o             \"\n",
      "batch 16548  loss=141.3079  steps/s=105.58  prediction: \" random people you dont really know well\" => \"tem i  . nn   p   o ooooooooo         ll\"\n",
      "batch 16549  loss=152.7523  steps/s=103.34  prediction: \"id you practice practice practice today?\" => \"ne cotccidiid  tiiiciicciccicccccicc ccc\"\n",
      "batch 16550  loss=151.4597  steps/s=100.04  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"itg t s t tttootooo                 a  t\"\n",
      "batch 16551  loss=148.6977  steps/s=104.11  prediction: \" but its worth it\n",
      "\n",
      "just make stuff thatâ€¦\" => \"tuteer tnhg   ttt th ttt tttt tttttt ut \"\n",
      "batch 16552  loss=140.4589  steps/s=104.55  prediction: \"ollowers type shit) he shouted me out\n",
      "\n",
      "g\" => \"uvill lll  lll  e    e     e  h       e \"\n",
      "batch 16553  loss=165.4184  steps/s=102.73  prediction: \"norary dan if i can be an honorary denis\" => \"gw   rn n nn an              n  a   n nn\"\n",
      "batch 16554  loss=170.6023  steps/s=29.20  prediction: \"ply: @jaivinwylde top tier game for sure\" => \"lyx 0 a nan  ae            n n  a   n nn\"\n",
      "batch 16555  loss=174.8466  steps/s=150.41  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"x_00x ecbes tEelDCE@,Cyd@cC,f..xBc,f(bD/\"\n",
      "batch 16556  loss=162.7769  steps/s=75.25  prediction: \"wphones Love the plan, sounds meaningful\" => \"ihx_@ an norn i L e  e   anan oo  n   oe\"\n",
      "batch 16557  loss=138.0334  steps/s=104.89  prediction: \"he loss function https://t.co/3Dutny5gPl\" => \"e g o  tet   es       tt  ttttt/t//t////\"\n",
      "batch 16558  loss=140.4886  steps/s=100.60  prediction: \" a bool so you just become sick again :/\" => \"t ttttg   lo ooooo      o o    s        \"\n",
      "batch 16559  loss=159.9508  steps/s=100.39  prediction: \"uote tweets work https://t.co/CCGxweEQQ8\" => \"nut  ooo o  e e  ttt tt tttttt/t//////CC\"\n",
      "batch 16560  loss=174.0312  steps/s=92.58  prediction: \"ere @jesx64 never stop having fun either\" => \"       SVe seee eeete e ttt tttto tt n t\"\n",
      "batch 16561  loss=149.2113  steps/s=103.41  prediction: \"ut what it meant https://t.co/XYAZfowlv5\" => \"n    n  t t  t   tttt tt tttttttt/////tt\"\n",
      "batch 16562  loss=181.4204  steps/s=102.64  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"lmo  Pt    sm CATT TTTTA A    ////I/EEE/\"\n",
      "batch 16563  loss=148.6728  steps/s=105.02  prediction: \"rs a question i've been unable to crackâ€¦\" => \"e aeo nn ano Ansqujq,A?q?''vq'bIL'E.3b'A\"\n",
      "batch 16564  loss=144.5524  steps/s=103.36  prediction: \"just start working, and it doesnt matter\" => \"usta         t r   r  t   t rt  t  nttt \"\n",
      "batch 16566  loss=144.5780  steps/s=105.15  prediction: \"es success, but there is a causal factor\" => \"  int   e es  utsssseessse es    a  a a \"\n",
      "batch 16567  loss=143.2175  steps/s=104.98  prediction: \"nd seem more limited in possible results\" => \"  rr  i es mm nem mem  e e  i iiie iesee\"\n",
      "batch 16568  loss=140.4127  steps/s=104.15  prediction: \" us safe from undetectable Dyson spheres\" => \"tp t ne ne f   ff    eeee e eeeee eeeeee\"\n",
      "batch 16569  loss=165.9580  steps/s=97.83  prediction: \"ly @plasmarob you could have a miz mobly\" => \"y: @nps  mof   ma   ou   uu   oo    eee \"\n",
      "batch 16570  loss=137.4543  steps/s=104.46  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "tne  y ll   &  @,&;,&&&&,JJwH,6H;HHzHHH\"\n",
      "batch 16572  loss=169.4962  steps/s=102.94  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"t.rhotooo///ttt/ttXXtttXXXX///ttc///tt//\"\n",
      "batch 16573  loss=180.6423  steps/s=97.04  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" to  ao ak nks   htazz tzz z ttto ttt tt\"\n",
      "batch 16575  loss=169.5337  steps/s=99.60  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly:  ntanh sssen s  s  ttt ttttt///////8\"\n",
      "batch 16576  loss=155.1166  steps/s=100.79  prediction: \" of why i used to get work sniped looool\" => \"tf eh e ffg   w           t             \"\n",
      "batch 16577  loss=152.7000  steps/s=105.09  prediction: \"hristians believe this is the case w God\" => \"eo  tl i mis s iiiiesiiiiiseie ii  se   \"\n",
      "batch 16578  loss=147.3329  steps/s=104.70  prediction: \" but vanilla obsidian seems very mid imo\" => \"aedewereruuul e u laall    ia aa    ei i\"\n",
      "batch 16579  loss=143.3273  steps/s=104.77  prediction: \"y, gpt 4o was bad at the first iteration\" => \"  r aet na    a   a      a       t  t tt\"\n",
      "batch 16580  loss=126.7524  steps/s=103.86  prediction: \"veryone in the past was a caveman/moron\"\" => \"e y o ne eeeeeeeee             aaaaaaaaa\"\n",
      "batch 16582  loss=134.3141  steps/s=104.33  prediction: \"en clusters into single tokens like this\" => \" t oen oteetn  tt    s      n      k   k\"\n",
      "batch 16583  loss=191.8134  steps/s=91.73  prediction: \"dup QUICK do something that doesnt scale\" => \" en e  e t  n noo s ss sttetn n  t t ees\"\n",
      "batch 16584  loss=158.0663  steps/s=105.87  prediction: \"h's run are: samplesize=64, epochs=100,â€¦\" => \"e gahta r r   n   r   assaseessees==e=e=\"\n",
      "batch 16585  loss=136.6844  steps/s=99.50  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"tae   d gggg       ppppppp              \"\n",
      "batch 16587  loss=139.1948  steps/s=106.27  prediction: \"gger stuff, maybe thatll make me faster?\" => \" e  to    ig     g      t  t  t   a  a  \"\n",
      "batch 16588  loss=158.2281  steps/s=97.65  prediction: \"AP wow\n",
      "\n",
      "i need to pivot from using print\" => \"B o wrlKww ww w  e e    t  t     m    r \"\n",
      "batch 16589  loss=160.5533  steps/s=87.64  prediction: \"cle77 arabian mate is a similar good one\" => \"hel @t  ciwwa7e aa aii  to    i  i  i rr\"\n",
      "batch 16590  loss=151.9800  steps/s=99.38  prediction: \"ple deep q network has achieved insanity\" => \"ly:  t  ei e ee e ee   e    a a  a   aia\"\n",
      "batch 16591  loss=148.9933  steps/s=102.62  prediction: \"kes a lot of sacrifice and energy though\" => \"e   tget ttetst  o  aa aa  a  e   e     \"\n",
      "batch 16592  loss=145.2729  steps/s=103.46  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" oi f  a e laaf a ababb   aaaa a aaaaaaa\"\n",
      "batch 16593  loss=170.9195  steps/s=104.31  prediction: \"ng jai??? Instantly 10x more interesting\" => \"g8 @ l  wi   ? ??????                  t\"\n",
      "batch 16594  loss=144.3050  steps/s=104.51  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \" ei wlnan\n",
      "pnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nnw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "onnnoooo\"\n",
      "batch 16595  loss=154.2602  steps/s=103.65  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"e  cor cn the8w T4v\"P,xju\"6=x8E\"L1xCMZ:6\"\n",
      "batch 16597  loss=150.3675  steps/s=104.75  prediction: \"ead to insanity\n",
      "\n",
      "https://t.co/FLccrhEiEd\" => \" rxoiso   s na \" ai \n",
      "\n",
      "t\n",
      "tt\n",
      "\n",
      "\n",
      "ttt/////ttc\"\n",
      "batch 16598  loss=156.1428  steps/s=99.96  prediction: \"gpu accelerated cnn from scratch?\n",
      "\n",
      "based\" => \" t  an ee  ceeetattcceecc ee ccc ccccccc\"\n",
      "batch 16599  loss=159.5796  steps/s=86.72  prediction: \"hag_ its good to be on the outside again\" => \"et t g a  ct   t t  to    o oc o \n",
      "tha s\n",
      "\"\n",
      "batch 16600  loss=145.4729  steps/s=104.90  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yies ltssl e e  e eeleeeeleeeelllll\n",
      "\n",
      "\n",
      "ll\"\n",
      "batch 16601  loss=168.6651  steps/s=64.37  prediction: \"opaeoh Duuuude lets go this is awesome!!\" => \"n (s e esnnn eu eele ee e e lelll\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  \"\n",
      "batch 16602  loss=163.5860  steps/s=107.38  prediction: \" line number + G https://t.co/iiOczSXHEe\" => \"tene n n e  n n                tt///////\"\n",
      "batch 16603  loss=139.5468  steps/s=104.79  prediction: \"d from 15 relevant studies in 10 seconds\" => \" to mumumm m eere       ee  e       e  s\"\n",
      "batch 16605  loss=165.3130  steps/s=103.86  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "A  gt nnnennnee eene lll              \"\n",
      "batch 16606  loss=159.5248  steps/s=101.19  prediction: \"rusted with this https://t.co/78lPrhtd11\" => \"es fe iavoyf :' jWW'VjVWWVVgw7AWn'ZAAAAA\"\n",
      "batch 16607  loss=140.8359  steps/s=99.76  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" Iit  xa  axe  eeeee                    \"\n",
      "batch 16608  loss=143.5759  steps/s=102.62  prediction: \"to play chess sometime, my li is dnbt777\" => \"  t  be  o            s s   m e         \"\n",
      "batch 16610  loss=262.4220  steps/s=106.46  prediction: \": CHECK\n",
      "DELTA TIME: CHECK\n",
      "GRAVITY: CHECK\" => \" PHoaE TYKBJHLT :DCLE:KCHMLKGGHLVKYGRAVI\"\n",
      "batch 16611  loss=169.1242  steps/s=100.05  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"tn t i  int e  n \n",
      "t\n",
      "  \n",
      "          \n",
      "   y  \"\n",
      "batch 16612  loss=143.8197  steps/s=104.37  prediction: \"tups are hidden in the fog 2 moves ahead\" => \" anf f stes    tts                     e\"\n",
      "batch 16613  loss=160.6769  steps/s=104.75  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"t..tttSt////t/t/tttttttttY:t//tt////t///\"\n",
      "batch 16614  loss=161.0889  steps/s=102.17  prediction: \"free could help too if thats the problem\" => \" o  setr  u u  l    oo o  o    ttt   t  \"\n",
      "batch 16615  loss=165.9796  steps/s=105.31  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" an tut ufun  u   t     r    r    e     \"\n",
      "batch 16616  loss=150.9198  steps/s=104.00  prediction: \"ger projects the smaller ones get faster\" => \" t  ynt rreeroeree  re ee  lelee s eee  \"\n",
      "batch 16617  loss=141.4538  steps/s=101.88  prediction: \"tony learns domain expansion in season 5\" => \"h t oot   on nonnn nn nnn  nnnnnnnnnnns \"\n",
      "batch 16618  loss=137.9109  steps/s=105.71  prediction: \" from that channel/vid to that x account\" => \"tiao lo lol    a  a a      tttttt    tt \"\n",
      "batch 16619  loss=132.8597  steps/s=104.87  prediction: \"vision how great itll be once youre done\" => \"edt enh nhn   n                        e\"\n",
      "batch 16620  loss=172.9154  steps/s=74.47  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"nh rheh n  nn i    t          o  ee   ee\"\n",
      "batch 16621  loss=154.3131  steps/s=106.25  prediction: \"ai car tire\n",
      "\n",
      "may not get smart money tho\" => \"n oo ea a\n",
      "aaa  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a    aa  aa  t     t\"\n",
      "batch 16622  loss=138.9006  steps/s=104.25  prediction: \"to someone on X, its laggy when it plays\" => \"  l   s  n n                            \"\n",
      "batch 16623  loss=138.9204  steps/s=104.25  prediction: \"stead of just knowing what they were, Iâ€¦\" => \" aa mt e en e e    n           t        \"\n",
      "batch 16624  loss=151.2154  steps/s=103.46  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" r iost f      U    ttttt tttiittttt////\"\n",
      "batch 16625  loss=155.4347  steps/s=107.46  prediction: \"own to play more. was a pleasure as well\" => \"u  e nm  n     m                a    aa \"\n",
      "batch 16626  loss=145.0316  steps/s=103.49  prediction: \"us example like this for numerous toolsâ€¦\" => \"st t n eermeremmleeelile  eie ee e   r r\"\n",
      "batch 16627  loss=141.0467  steps/s=104.60  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eoonit t n tnneee e  e e eeeee        \"\n",
      "batch 16628  loss=144.5248  steps/s=98.35  prediction: \", even my llm is on 3 cups of coffee bro\" => \" iot  ln a e  n e                   f f \"\n",
      "batch 16629  loss=159.3640  steps/s=97.81  prediction: \"n @grapplingdev HA i love it, lets do it\" => \" m   eanen@eenanannn       i  i i       \"\n",
      "batch 16630  loss=134.5568  steps/s=103.27  prediction: \"he end result could look like\n",
      "\n",
      "followed!\" => \"e f  o  t teeeet e   e     lllllollollll\"\n",
      "batch 16632  loss=150.7408  steps/s=103.43  prediction: \"t some point ill probably make it public\" => \" io   r tm  m            ll bll    l  b \"\n",
      "batch 16633  loss=139.0353  steps/s=104.34  prediction: \"too, its good to break your priors intoâ€¦\" => \"  t     t ttoootooooooooo o      o    rr\"\n",
      "batch 16634  loss=157.7584  steps/s=106.45  prediction: \"re you need to make a sphere version now\" => \"eply: @HfrS h_aeWvT&Lz;KIKITCCCkT&PR;RvP\"\n",
      "batch 16635  loss=176.2730  steps/s=28.77  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly: @    etet ot    e       r errrrerroo\"\n",
      "batch 16636  loss=170.9192  steps/s=107.19  prediction: \"o\n",
      "Learn by doing, get compounding skills\" => \"u\n",
      "yrs e   r sry      y  e  og go gg  gon\"\n",
      "batch 16637  loss=178.2477  steps/s=28.40  prediction: \"ply: @sunsettler https://t.co/2ERTWsJiwS\" => \"lyj o   s r  rr         eo no  o gg  gon\"\n",
      "batch 16638  loss=146.8530  steps/s=107.93  prediction: \"ed, its worth at least giving a shot tho\" => \"  ni     s    t   t      t   t        t \"\n",
      "batch 16639  loss=147.0545  steps/s=103.64  prediction: \"d xD but maybe its trying to communicate\" => \" ttyl l beb   ybb     y   t   t  t  i  t\"\n",
      "batch 16640  loss=155.2036  steps/s=103.84  prediction: \"matching pixels\n",
      "Reward for clearing rows\" => \"ent for n n m  R n   i    e   a  errrr e\"\n",
      "batch 16641  loss=150.9703  steps/s=103.91  prediction: \"r tweet was epictetus's two handles idea\" => \"etltn eg sstiNng$0____0_x___'x__ZZRZxI__\"\n",
      "batch 16642  loss=154.6199  steps/s=102.75  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"tyrt neem m   d    ee             e     \"\n",
      "batch 16643  loss=144.1382  steps/s=105.40  prediction: \"moves in opening\n",
      "https://t.co/hv5NypSZGV\" => \"eves s ws  ss     e     nnttttttt///////\"\n",
      "batch 16644  loss=155.5208  steps/s=95.04  prediction: \"s I love zig\n",
      "Are you doing the ziglings?\" => \" ao  we    e e  e eeee ii to ooohh iiigg\"\n",
      "batch 16645  loss=181.8497  steps/s=50.18  prediction: \": @AyNio2 see you on monday ma brotha! ðŸ«¡\" => \" @bo pngtwy tx sPI'z,v0Az&5@Ax&;;;P&JYðŸ«¡A\"\n",
      "batch 16646  loss=171.0735  steps/s=125.99  prediction: \"ein_sh LOOL\n",
      "\n",
      "we need a \"bruh\" paper STAT\" => \" n  l@isNi nOO  OOOe \n",
      "  n n    \"\"\"ihhh  \"\n",
      "batch 16647  loss=145.8219  steps/s=105.66  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"se wo w on no  oooo      ttt  ttttt////s\"\n",
      "batch 16649  loss=154.4256  steps/s=101.50  prediction: \"wesome looking pieces though, im jealous\" => \"h t  onillelllieeeeee  eeeeoeee o    o  \"\n",
      "batch 16650  loss=146.4134  steps/s=104.35  prediction: \"o make a significant impact on your life\" => \"uia ndi   n   ai iaiiiiiiiiiiiii        \"\n",
      "batch 16651  loss=172.5513  steps/s=104.45  prediction: \"/t.co/cU8TdGmOOe https://t.co/wR9o8NrNIm\" => \"/..csto  :///TT/Tt/OOttOOO//t/ttt////t//\"\n",
      "batch 16652  loss=166.4469  steps/s=55.47  prediction: \"y: @sunsettler write a will just in case\" => \"  @ ucg t///tTT OOOOOtt/tt////ttt///888N\"\n",
      "batch 16653  loss=145.5683  steps/s=109.67  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "n   eeeneeeeeee eeeeeee ee    e       \"\n",
      "batch 16654  loss=166.7648  steps/s=104.07  prediction: \"his ~10yrs ago w py\n",
      "Learn by doing WORKS\" => \"es  rt ~ttr~  1s s   ys   r      y  y  o\"\n",
      "batch 16655  loss=143.9715  steps/s=103.98  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" rt       n n g     nnnnntttttttttttt///\"\n",
      "batch 16656  loss=168.7345  steps/s=100.00  prediction: \"e yup same did exactly this, worked well\" => \" bnin@i   d n yddddddd dtd e t   t t dd \"\n",
      "batch 16657  loss=155.3028  steps/s=101.58  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \" sn ean  t t  asa    aaaa s    aaaaa    \"\n",
      "batch 16658  loss=131.3379  steps/s=105.16  prediction: \" feel to be a tier above elon @teodor_io\" => \"toa  we  e                   eee  e eeoo\"\n",
      "batch 16659  loss=154.7575  steps/s=103.44  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omceci c co cee e re ee   ht  te  /ttttp\"\n",
      "batch 16660  loss=146.0910  steps/s=104.87  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" ao   coess s  s   sss ss ss sssssse  s \"\n",
      "batch 16661  loss=138.7178  steps/s=104.01  prediction: \"o him) and he begged to pay me to use it\" => \"nal i t n n n  n                        \"\n",
      "batch 16662  loss=143.1331  steps/s=104.74  prediction: \"nomic than discord id switch immediately\" => \" th     nemom omo   o   d  d id iii diii\"\n",
      "batch 16663  loss=144.9857  steps/s=104.09  prediction: \"dibly efficient and powerful compression\" => \" tt ir  in nf ifi ifiniiin   f e ee  e e\"\n",
      "batch 16664  loss=151.6048  steps/s=102.87  prediction: \" it that one RL phd keeps talking abt it\" => \"ts t  t ttttt  t                        \"\n",
      "batch 16665  loss=173.9294  steps/s=99.45  prediction: \"end to work, and they pretend to pay us\"\" => \" t tttttt  ete e  t   ed  d t enen  tet \"\n",
      "batch 16666  loss=147.5387  steps/s=105.73  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes   t    l  l  thttttttttttttttt//////\"\n",
      "batch 16667  loss=150.5574  steps/s=100.57  prediction: \"kes a lot of sacrifice and energy though\" => \"i   tnetetteset  s  aa aa  aa a   e     \"\n",
      "batch 16669  loss=145.4797  steps/s=104.06  prediction: \"al, one of the most cracked players ever\" => \"nk   o e ooee o o o    o       e     eee\"\n",
      "batch 16670  loss=153.9447  steps/s=104.91  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "ot ar yiio o)( z:SzGv2JI1xJz1AV7UBJ:)2L\"\n",
      "batch 16672  loss=147.3700  steps/s=103.80  prediction: \"n just build cool fun stuff all the time\" => \"gt te t tn  u nn  u    uu uu   u l   ll \"\n",
      "batch 16673  loss=150.5404  steps/s=102.64  prediction: \"nkedin phase\n",
      "\n",
      "we'll teach them hopefully\" => \"g th     nhnnih ieieeeee eeeleehee ee hh\"\n",
      "batch 16674  loss=151.0251  steps/s=95.20  prediction: \"a Meet the new boss\n",
      "Same as the old boss\" => \"npotn  n  te etee  eeee  e  ae   e    l \"\n",
      "batch 16676  loss=166.7195  steps/s=104.53  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "Ao gt nnnennneeneene lll              \"\n",
      "batch 16677  loss=166.8914  steps/s=103.23  prediction: \" so this helped\n",
      "\n",
      "Are you gonna continue?\" => \"ttaas t  e   s G     s           e   nn \"\n",
      "batch 16678  loss=146.1298  steps/s=98.94  prediction: \"credibly cool to see this project evolve\" => \"oepinao thnl   llo   oo   o      eee oee\"\n",
      "batch 16679  loss=172.1373  steps/s=96.17  prediction: \"nch @yacineMTB let the a b testing BEGIN\" => \"gre i y cyccyyc c  ee etee   e t tee te \"\n",
      "batch 16680  loss=137.2852  steps/s=97.33  prediction: \"he race to steal the eu tech bros begins\" => \"e r aia enn  en t tet e  e e ete   e  e \"\n",
      "batch 16681  loss=152.3779  steps/s=104.22  prediction: \"/t.co/dWiO4erSb1 https://t.co/VaQuvIKJWu\" => \"t.copp s////t/oooottttttt::t//tt////t//.\"\n",
      "batch 16682  loss=157.7403  steps/s=99.50  prediction: \"nism oooh possibly, thats a good thought\" => \" stho nsomomoos ooooss hosssttsssttt t  \"\n",
      "batch 16683  loss=156.7500  steps/s=103.81  prediction: \"Logit transform: https://t.co/MtjBY3y5n5\" => \"ogoo        t oL   ttttt ttt:tttttt/tt/t\"\n",
      "batch 16684  loss=197.7624  steps/s=96.50  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"/..-opps/t..o///ZhZZZhZZth////tt//tBB///\"\n",
      "batch 16685  loss=139.8723  steps/s=104.73  prediction: \"m the previous day\n",
      "\n",
      "i try to only writeâ€¦\" => \"ate  e    sss f                   y     \"\n",
      "batch 16686  loss=178.7029  steps/s=103.26  prediction: \"oing the deadline thing\n",
      "Works super well\" => \"nn tt   t  t tnt   dddd eeiiini n e ee e\"\n",
      "batch 16687  loss=142.5126  steps/s=105.32  prediction: \" random people you dont really know well\" => \"tem in   nn   m   o ooooooooo         ll\"\n",
      "batch 16688  loss=154.0504  steps/s=97.62  prediction: \"s every time I'm getting comfortable lol\" => \" y ipr e  err r eee ee e  tme   t tett  \"\n",
      "batch 16689  loss=131.7276  steps/s=104.43  prediction: \"d so i felt the need to post the way out\" => \" it ididdi                              \"\n",
      "batch 16690  loss=182.7814  steps/s=30.95  prediction: \"ply: @10x_er he saw food and came runnin\" => \"ly: t   nd                   tt   t     \"\n",
      "batch 16691  loss=135.4502  steps/s=108.69  prediction: \"got the bit order backwards or something\" => \" n  ho ogn gt  t      b   r  rr rrr rrr \"\n",
      "batch 16692  loss=182.6971  steps/s=85.17  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"ng octce t t  t    eO   rOr    ooo    bo\"\n",
      "batch 16693  loss=151.5944  steps/s=103.97  prediction: \" like this too? They come in pairs often\" => \"ton opae  r s ss         o    o    i    \"\n",
      "batch 16694  loss=149.1060  steps/s=104.10  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"eiine @onooo E a!L!kx!!(v!??MMP?IM)Wv(!L\"\n",
      "batch 16695  loss=187.3274  steps/s=84.83  prediction: \"wigABAP bro what https://t.co/v7f0VyuaHE\" => \"itk evede rA         h    dsss///cc ce  \"\n",
      "batch 16696  loss=151.3470  steps/s=94.25  prediction: \" version control https://t.co/syhjjWL8M6\" => \"tedi rlvr v   rso t ttt///////////t/c//W\"\n",
      "batch 16699  loss=146.9559  steps/s=104.57  prediction: \"c too much attention + hasnt been solved\" => \"obli   a  tt  ttt  tt t tttt     n    n \"\n",
      "batch 16700  loss=217.9327  steps/s=11.75  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eplim @uedennke k--vJJJ.J,+-HW-2FgD,4RðŸ«¡ðŸ«¡\"\n",
      "batch 16701  loss=148.4370  steps/s=108.20  prediction: \" but back in the day thats how I learned\" => \"tuc   cc tc t e                t        \"\n",
      "batch 16702  loss=195.2990  steps/s=20.76  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly: @ic ec   u                t        \"\n",
      "batch 16704  loss=146.8646  steps/s=108.19  prediction: \"ng i correctly understood what you meant\" => \"  b  it  s    in    rr         oooo oo  \"\n",
      "batch 16705  loss=140.7190  steps/s=98.94  prediction: \"ust linux mints built in text editor lol\" => \"st gi t  t t   t    ii i  ii    tttt  tt\"\n",
      "batch 16706  loss=163.7811  steps/s=101.29  prediction: \"y did my idea :(\n",
      "https://t.co/wC1KdndUrR\" => \" 'icaMe dd dd d ddd         :::::://////\"\n",
      "batch 16707  loss=206.0801  steps/s=93.06  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"oS E oEaEEEEEOOOOOOOOOOtOtht/wtw twwd d \"\n",
      "batch 16708  loss=147.7267  steps/s=104.12  prediction: \"you find God, the truth, and help people\" => \" u  anwew nee  ee        t      h  hh   \"\n",
      "batch 16709  loss=146.1218  steps/s=100.27  prediction: \"ld love to hear if you dont mind sharing\" => \"y  sw    ll l  l          o             \"\n",
      "batch 16710  loss=153.3976  steps/s=101.99  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e ly: hemyen .doO!^^,v;b^;Qx!9J^?Cw;Éª?_\n",
      "\"\n",
      "batch 16711  loss=142.7352  steps/s=103.54  prediction: \"the most useful? https://t.co/w0tVqarS34\" => \"hes     tre   te  tte t tttstttttt/////t\"\n",
      "batch 16713  loss=171.1760  steps/s=55.95  prediction: \": @IterIntellectus here have another one\" => \" @s y  c  l  Oa O?bIETwI',(x.'b?w0LVqD:S\"\n",
      "batch 16714  loss=151.0146  steps/s=107.27  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \"hr    nee t  t \n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttttttt/////\"\n",
      "batch 16715  loss=137.6574  steps/s=102.19  prediction: \"als and make smaller and smaller circles\" => \"nset t   nanmaemaamaaaa aaaaalaallllllll\"\n",
      "batch 16716  loss=142.7888  steps/s=105.30  prediction: \"erally the divide between autist and npc\" => \"  thl t  rl rrllllllleiee ieieee eeeeeee\"\n",
      "batch 16717  loss=160.1509  steps/s=45.87  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \": @rali  r+++il l  ite ee ieieee eeet en\"\n",
      "batch 16718  loss=142.1482  steps/s=110.04  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"tuu t    m mmmm mmmmm    mttt ttttttpppp\"\n",
      "batch 16719  loss=152.8614  steps/s=103.85  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"to.sssst////s//st/ttttttts////tt////P//t\"\n",
      "batch 16720  loss=164.6536  steps/s=100.58  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @ toe ee  n  e    o      oo    o    \"\n",
      "batch 16721  loss=149.6908  steps/s=104.75  prediction: \"efitted from tracking sleep and whatnot?\" => \" f youeeeeteteete  te         ee   e    \"\n",
      "batch 16722  loss=135.8169  steps/s=104.09  prediction: \"ve to or weak squares/pieces etc etc etc\" => \"e e esn  e   e       e  e  eeeeeeeeeeeee\"\n",
      "batch 16723  loss=193.4300  steps/s=58.69  prediction: \" @jjohnpotter ga https://t.co/GIOxuvZsb1\" => \"tNa  eo           a  eeeee/eeeeeeeeeeecc\"\n",
      "batch 16724  loss=145.3377  steps/s=106.56  prediction: \"onder if he stuck w onnx or went w tf.js\" => \"u/  elle e                         w    \"\n",
      "batch 16726  loss=172.9448  steps/s=99.20  prediction: \" know some ppl this would help immensely\" => \"tine n  !!!   I            o   p   l    \"\n",
      "batch 16727  loss=142.4795  steps/s=102.63  prediction: \"d useful stuff better with the new tools\" => \" uu u luf  luuu ffuffu f   ette t tt  tt\"\n",
      "batch 16728  loss=144.2141  steps/s=101.41  prediction: \"eft\n",
      "right looks right\n",
      "its a miracle init\" => \" u llo\n",
      "\n",
      " lofll loooooo ttttt   i   i iii\"\n",
      "batch 16729  loss=136.3418  steps/s=102.60  prediction: \" already doing, faster. you are the user\" => \"t ge n   ennee de       e   a           \"\n",
      "batch 16730  loss=155.6349  steps/s=54.51  prediction: \"y: @gizmobly nooooooooo my plans, foiled\" => \"  @eent deeed rdo       e   ar  r   e e \"\n",
      "batch 16731  loss=137.1176  steps/s=111.40  prediction: \"mals have uncanny valley detection genes\" => \"enl oete ss     aaaaaaaaaaan nn  eeeeene\"\n",
      "batch 16732  loss=181.2163  steps/s=94.48  prediction: \"ates Hear me out https://t.co/M8bURSdiT1\" => \"ni  a  e aaasan a    l     etteeee/eeeee\"\n",
      "batch 16733  loss=145.5020  steps/s=104.57  prediction: \"learn thing -&gt; compress thing, repeat\" => \"yxr )nennd nrn engng ngg gtg t   g gg   \"\n",
      "batch 16735  loss=165.4835  steps/s=97.79  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"u    sminn ni    to  t    ts  stsst/trtJ\"\n",
      "batch 16737  loss=144.2853  steps/s=102.53  prediction: \"best way ive found so far to order tasks\" => \"e lt@et tt ttett                   o    \"\n",
      "batch 16738  loss=185.5174  steps/s=103.35  prediction: \"MTB Yup, totally, would be best actually\" => \"TB @yry ro  t y ay a uo  oo   o   tael l\"\n",
      "batch 16739  loss=145.6002  steps/s=103.83  prediction: \" what to do next. i want to do my own tâ€¦\" => \"toa            o  o        t t       o  \"\n",
      "batch 16740  loss=149.7946  steps/s=96.97  prediction: \"f you can read graphs youre already ngmi\" => \" yo  s n o    a    aaa  a      o     o  \"\n",
      "batch 16741  loss=141.2635  steps/s=104.76  prediction: \" get to master idk depends on your goals\" => \"te oee  en    tt      t   d dd d  d  o  \"\n",
      "batch 16742  loss=137.5442  steps/s=105.21  prediction: \"sfully improved their lives tremendously\" => \" octest  h se  seeeeeee ee eeee eeeeee e\"\n",
      "batch 16743  loss=158.6279  steps/s=104.22  prediction: \"orking feels a bit more stale without it\" => \"ne  eegefnfefew    e e        e         \"\n",
      "batch 16744  loss=138.4495  steps/s=104.40  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"epl e ecod  n@t x%@D(BYLMTkOL).\"WG\"A5\"R)\"\n",
      "batch 16745  loss=144.3391  steps/s=104.14  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"tu    e  n    ttt    ttttttttttt/t//t//t\"\n",
      "batch 16747  loss=138.2410  steps/s=103.89  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sin tisnnneeieinniiinntnteittt//t//tt//\"\n",
      "batch 16748  loss=252.8330  steps/s=11.76  prediction: \"reply: @cachecrab ah, the french defense\" => \"esso: @    o O sO.@O.O'OOOOOO'TOOIv:''x.\"\n",
      "batch 16749  loss=148.9914  steps/s=108.74  prediction: \"it anymore. Now she can go get groceries\" => \"n  ai aa n                           e  \"\n",
      "batch 16751  loss=139.8923  steps/s=100.21  prediction: \"ould color their pill white for the lolz\" => \"  ehn  tl tooolooo    llll  ll     l    \"\n",
      "batch 16752  loss=145.4838  steps/s=100.50  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"tren aa  n     f              o     ooo \"\n",
      "batch 16753  loss=142.6500  steps/s=105.91  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" t  ena  n n   w w      i i  ee eeeeeee \"\n",
      "batch 16754  loss=156.1678  steps/s=101.68  prediction: \"very instructive zig raylib example/code\" => \"e   t t   n   iri ii i ri iiii i ii  i e\"\n",
      "batch 16755  loss=141.5538  steps/s=104.65  prediction: \"hink about a post before responding lool\" => \"en  o      nn u              o oo  oe oo\"\n",
      "batch 16756  loss=184.7442  steps/s=60.16  prediction: \" @0xluffyb unfunded? then do it unfunded\" => \"tyo h  u   b   t    o    ee oooo e  oooo\"\n",
      "batch 16757  loss=196.7147  steps/s=36.78  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly: @tut b b  u    o    ee oooo e  oooo\"\n",
      "batch 16758  loss=149.0321  steps/s=110.39  prediction: \"ally fun/challenging/interesting for ppl\" => \"nl t    aa n a llllnl/lnnnnnnnnnnnnnnnng\"\n",
      "batch 16760  loss=154.0659  steps/s=99.09  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"eply   t en dvdivH_?AkjT?y.kOE:vTN.QITEY\"\n",
      "batch 16762  loss=141.0619  steps/s=103.73  prediction: \"ed hard at improving, mostly by studying\" => \"  wo    rhrr  dd   r r    o  o         y\"\n",
      "batch 16763  loss=172.6753  steps/s=95.28  prediction: \"Rohit @archived_videos @discord its fake\" => \"answ rk ah r r v  vvivvv oi  ooss ddsist\"\n",
      "batch 16764  loss=138.5190  steps/s=102.55  prediction: \" the first alien on earth thats so crazy\" => \"thie  neee t e t e e           tt  t t  \"\n",
      "batch 16765  loss=157.6962  steps/s=89.99  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAPie dti eA a  l   l    r  ? as?ssssss\"\n",
      "batch 16767  loss=156.0408  steps/s=102.35  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf   ri   d   ri  i  i                  \"\n",
      "batch 16768  loss=146.1750  steps/s=100.90  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"tren aa  n                    o     ooo \"\n",
      "batch 16769  loss=139.5938  steps/s=106.16  prediction: \"etter but pretty good time bender though\" => \" t  ototeg  tt etttt  ttttttt    ee    e\"\n",
      "batch 16770  loss=154.3678  steps/s=47.72  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \": @iorotl  eettettt   tt    e ee e     e\"\n",
      "batch 16771  loss=137.8828  steps/s=109.11  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"thet   tt  tt tt                        \"\n",
      "batch 16772  loss=164.9414  steps/s=104.49  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \":monos a t t   ata aa t a t   t// t//LLL\"\n",
      "batch 16773  loss=183.0522  steps/s=94.24  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"/.choQfa //   oo tttttt/tt////tt/////bbb\"\n",
      "batch 16774  loss=145.8514  steps/s=104.10  prediction: \" this era where breaches happen so often\" => \"toe  snenieeein  ei  eee  hhheh he  heee\"\n",
      "batch 16775  loss=135.6628  steps/s=105.47  prediction: \" you have a podcast on in the bg or smth\" => \"touss n  i                              \"\n",
      "batch 16776  loss=169.5715  steps/s=88.64  prediction: \"npaul_ai Improves irl ppls responses too\" => \" lt  saa   a  aaa  aa           p    s o\"\n",
      "batch 16777  loss=141.3832  steps/s=104.55  prediction: \" up and down\n",
      "\n",
      "Youre always in the middle\" => \"ts a   a       n          w             \"\n",
      "batch 16778  loss=143.3122  steps/s=105.74  prediction: \"a good way to beat addictions in general\" => \"ngni i  s   ttooooo    a  aa aa   ii    \"\n",
      "batch 16779  loss=154.3672  steps/s=102.75  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \" wi iai  t t  asa    aaaa s   nnaaaa    \"\n",
      "batch 16780  loss=161.1447  steps/s=105.26  prediction: \"verfit test btw) https://t.co/qErYnoBOJi\" => \"er o  s t  (ooo  tttt tttttttttttttt////\"\n",
      "batch 16781  loss=236.8636  steps/s=95.24  prediction: \"____11hz @Collab_Land_ the fuck is this?\" => \"______t1111n z hC_@L___L:_/).._L.EE_YE?k\"\n",
      "batch 16782  loss=160.1757  steps/s=102.05  prediction: \"channels\n",
      "\n",
      "works for individuals, anyways\" => \"o t u o ooonon nonn ononnoi i  iriii aia\"\n",
      "batch 16783  loss=154.1243  steps/s=100.39  prediction: \"resy you can already talk to one of them\" => \"eplyn  htm  tlee__byk__f\"Mm%\"kMvZcmkMm,?\"\n",
      "batch 16784  loss=141.6483  steps/s=105.18  prediction: \"rtionately likely to show up on your FYP\" => \"eitidt y    n~  Z~FFFF.ZT^#X#Éª~#W%^Éª==P%\"\n",
      "batch 16785  loss=168.1539  steps/s=104.48  prediction: \" of utility in my life (more like 97/10)\" => \"tf ee n     n t        i  i  i    i     \"\n",
      "batch 16786  loss=150.5325  steps/s=104.97  prediction: \" drains your energy by paying attentionâ€¦\" => \"tu t th   n n gr  n   yyyyyyyy yy y   nn\"\n",
      "batch 16787  loss=202.4433  steps/s=102.39  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"tLalf         L LLLLLEEEEEEEEEEETTTT  tt\"\n",
      "batch 16788  loss=145.5140  steps/s=105.38  prediction: \" not super out of alignment with reality\" => \"toe aen n nnn uu  o     o   e  n     t  \"\n",
      "batch 16790  loss=148.2861  steps/s=103.90  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" r t t oeee        rrrrrrrrrrrrrrrhh  h \"\n",
      "batch 16791  loss=152.0639  steps/s=102.96  prediction: \"otten most of my follows from Yacine lol\" => \"u r etee ett te     t  o   o oooo   f  o\"\n",
      "batch 16793  loss=147.9802  steps/s=102.61  prediction: \"king useful things, so it didnt work out\" => \"en  kdi  k k                            \"\n",
      "batch 16794  loss=135.3552  steps/s=103.98  prediction: \" you have a podcast on in the bg or smth\" => \"iou s n  i                              \"\n",
      "batch 16795  loss=195.4398  steps/s=21.87  prediction: \"eply: @visakanv The attack of the clowns\" => \" ly  @i       e a a       o             \"\n",
      "batch 16796  loss=149.1672  steps/s=114.49  prediction: \" into an age with a lot of visual beauty\" => \"in ee nennen  n                         \"\n",
      "batch 16797  loss=142.3029  steps/s=103.53  prediction: \", how do WE figure out where things are?\" => \" io  n  no                     e   e    \"\n",
      "batch 16798  loss=146.0940  steps/s=103.75  prediction: \"n and id 100% recommend it over The Goal\" => \" au oot    d  dd    00              e ee\"\n",
      "batch 16799  loss=144.4946  steps/s=105.54  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"em no aae e rehee ea a  aa  a aa aaaa   \"\n",
      "batch 16800  loss=142.6878  steps/s=104.78  prediction: \"ommittal move like going on a sabbatical\" => \"uememe  mam am t      e    o          aa\"\n",
      "batch 16801  loss=142.8891  steps/s=104.29  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"   cntt ceneee eeeeeeeeeee:::://t//t////\"\n",
      "batch 16802  loss=157.4203  steps/s=102.69  prediction: \"minds me of this https://t.co/bGCVZbuoNU\" => \"ent  p se emeen   t    tttsttttt////////\"\n",
      "batch 16804  loss=147.9990  steps/s=104.63  prediction: \"\n",
      "\n",
      "the command runit runs the last output\" => \"\n",
      "it rnof obl \"o TBÉªM#gv:44ÊŸv\"á´˜#4á´˜#VðŸ˜†Êœ]`ðŸ˜†\"\n",
      "batch 16805  loss=134.0968  steps/s=102.24  prediction: \" new meta\n",
      "dont think too hard about that\" => \"@ot i  tn  n  t  tttttttttttt          t\"\n",
      "batch 16806  loss=158.0366  steps/s=99.55  prediction: \"grammer unfortunately you are correct xD\" => \" astet mmdrmemrrrnrrnrtrr r   ao o r  r \"\n",
      "batch 16807  loss=167.6766  steps/s=31.47  prediction: \"ply: @Wooltard @eigenrobot Poor things ðŸ˜¢\" => \"ly: @  mmmerrmmrrnrrnror  ur  u r  r  rr\"\n",
      "batch 16808  loss=259.4457  steps/s=33.02  prediction: \"reply: @djcows leveraged short positions\" => \"eply: @S     Mi TBL@MTvN44HvP)84GCVZETIx\"\n",
      "batch 16809  loss=146.2585  steps/s=108.53  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \" //  nuet nn  s  i  i  i+ +++++xxx      \"\n",
      "batch 16810  loss=219.6938  steps/s=101.15  prediction: \"DE\n",
      "14hrs is wild\n",
      "also james is a gooooat\" => \"oesSp0\n",
      " DD E ED    i  iss s     ss s  s \"\n",
      "batch 16811  loss=139.4638  steps/s=105.05  prediction: \", usually because you border more things\" => \" sot ni  sesees e ee e   uuuu   e  e err\"\n",
      "batch 16812  loss=153.2167  steps/s=105.08  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"te.cittt.///tt8=//ttS4tSS444tttt:///tt//\"\n",
      "batch 16813  loss=189.6011  steps/s=84.88  prediction: \"eigecamry @sunsettler shredded that shit\" => \" r c netaaiacS  S4tSst:ttt////hh3Xt5httK\"\n",
      "batch 16814  loss=173.9448  steps/s=105.22  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"t.cepho c //ot/t//5/5ttttt/tt/t:////tt//\"\n",
      "batch 16815  loss=219.0598  steps/s=100.24  prediction: \"Y DONT KNOW ME SON\n",
      "THEY DONT KNOW ME SON\" => \"emh_a DcaaONONT ON ENNONHE  ENET NOKWOEE\"\n",
      "batch 16816  loss=155.2014  steps/s=104.60  prediction: \"freedom fighters. ppl who wanted freedom\" => \" o   m n fe efee ee r    e  e       e ee\"\n",
      "batch 16817  loss=129.8544  steps/s=105.31  prediction: \"endeavors im going to do til ive done it\" => \" ti      tt t u                         \"\n",
      "batch 16818  loss=156.6271  steps/s=105.52  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tn ii issniinshesssssttttttttttt////////\"\n",
      "batch 16819  loss=137.6828  steps/s=104.44  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e a ah  ra r  eh  e   ththhttttth/ttt///\"\n",
      "batch 16820  loss=141.5968  steps/s=104.48  prediction: \"laces in my mind https://t.co/M8BGGgHnSS\" => \"icenesn ta n         n    t   ttttt////G\"\n",
      "batch 16821  loss=143.2128  steps/s=99.96  prediction: \"ed me understand https://t.co/LHjT6ITtSs\" => \"   h ls    ee eeedddd dtdtttt/t/////////\"\n",
      "batch 16822  loss=192.8678  steps/s=98.37  prediction: \" QUICK delete this before sphere sees it\" => \"terw wwedeletee dtt ttetttte ts seesrres\"\n",
      "batch 16823  loss=147.4364  steps/s=105.25  prediction: \"more friction than they need to function\" => \"ereie an  tn   ot t tt t tn n     ee e t\"\n",
      "batch 16824  loss=176.9286  steps/s=86.62  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"_unol   BQK_ebldA0vv@AjMIEjbMIb@.zxb@5MT\"\n",
      "batch 16825  loss=144.8698  steps/s=103.59  prediction: \" works when I ask it for complex changes\" => \"aowe  w   ww                            \"\n",
      "batch 16826  loss=145.6327  steps/s=100.85  prediction: \" sensors lol thats much less complicated\" => \"ior ssu nss ssosssssss  ss ssss  lsssccc\"\n",
      "batch 16827  loss=149.5541  steps/s=105.23  prediction: \"fected, i hope none of my followers were\" => \" e  ae d c de f e ee   o  e of  oof  ooe\"\n",
      "batch 16828  loss=157.9465  steps/s=103.49  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nta  re\n",
      " me\n",
      "  Se   e    e               \"\n",
      "batch 16829  loss=156.2176  steps/s=103.37  prediction: \"000000000000000000000001% of the new one\" => \"00 oho brJ  t2Io---I*.kk1%-II5I-TGO//,g5\"\n",
      "batch 16830  loss=183.2868  steps/s=102.42  prediction: \"kedin slop\n",
      "you vill post engagement bait\" => \"e   io   ii n io loo  o l loop    enenee\"\n",
      "batch 16831  loss=136.8381  steps/s=102.16  prediction: \"op over and over is the opposite of slop\" => \"ul t s ss  ss                    o   o o\"\n",
      "batch 16832  loss=156.8429  steps/s=96.24  prediction: \"s message is NOT approved by square gang\" => \" ooe ims ms s eess   s   pp   pp     s e\"\n",
      "batch 16833  loss=138.7079  steps/s=103.43  prediction: \"on + analysis, considering posting on gh\" => \"u ta nona anaaa aanniniinniiiiiiisininin\"\n",
      "batch 16834  loss=168.7475  steps/s=101.43  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \"Ezk     t   t  e   t ttttttttttttttst///\"\n",
      "batch 16835  loss=208.5819  steps/s=101.79  prediction: \"luffyb Xorswap, what a username, love it\" => \"ydw@17_0x 0 11 fXX XXXXs wXswwaa ,  u s \"\n",
      "batch 16836  loss=149.1674  steps/s=104.75  prediction: \"fected, i hope none of my followers were\" => \" e  ae d c de e e ee   o  e of  oof  ooe\"\n",
      "batch 16837  loss=169.0443  steps/s=103.06  prediction: \"of work every monday and thursday brotha\" => \"u  oh  orh oo or  or rr  oy   y y   y dd\"\n",
      "batch 16838  loss=144.4908  steps/s=102.49  prediction: \"hinks he might pick up in future decades\" => \"es  ini nhn hhihh  h h  iii         u   \"\n",
      "batch 16839  loss=171.9955  steps/s=104.81  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"t.cN\n",
      "Ne::////teoNttttttttt//t/ttc////ttc\"\n",
      "batch 16840  loss=150.9203  steps/s=104.52  prediction: \"sed\n",
      "\n",
      "Try it asap\n",
      "https://t.co/ZK8YpKEtoP\" => \" ln a o fn rf r \n",
      "a \n",
      "\n",
      "\n",
      "t\n",
      "\n",
      "sttttt s/ttttt/\"\n",
      "batch 16841  loss=151.0554  steps/s=99.88  prediction: \"inlet like me to test experiments out on\" => \"n lrtree  re    e    ee  eee  e etettett\"\n",
      "batch 16842  loss=138.3624  steps/s=104.46  prediction: \"to a few people its a gargantuan problem\" => \"  t is   t t   t              aaa aa aa \"\n",
      "batch 16843  loss=149.1794  steps/s=103.88  prediction: \"r die, and when they swim they find food\" => \"eoi k @st   oBtt_@,N.vSIx2).v,B3@kD1LOTD\"\n",
      "batch 16844  loss=139.4300  steps/s=103.70  prediction: \"f lol. but ppl jump at the local optimas\" => \" ti   g   f   f                         \"\n",
      "batch 16845  loss=185.1371  steps/s=69.43  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tsufue u el llul u    tpp          ll   \"\n",
      "batch 16846  loss=142.5464  steps/s=108.77  prediction: \"ces for speed and it makes the game wild\" => \"h si   s  cce seeee   e   e  e     e   e\"\n",
      "batch 16847  loss=158.4071  steps/s=103.73  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"Tmpoet rerr rr   r aaaaaa aaa a aaaa a  \"\n",
      "batch 16848  loss=143.2054  steps/s=104.51  prediction: \"cool ML/studying/building posts are gone\" => \"hniiti    t    ooooo///iiiiiiiiiiiiigggg\"\n",
      "batch 16849  loss=163.6548  steps/s=83.83  prediction: \" square gang wont let this happen &gt;:(\" => \"tto  o o ll l ug g gg nnn iitt ss   s n \"\n",
      "batch 16850  loss=146.2949  steps/s=103.98  prediction: \"t lately\n",
      "\n",
      "Your RPA loop is pretty useful\" => \" io hel l  llll\n",
      "l                       \"\n",
      "batch 16851  loss=130.6824  steps/s=105.61  prediction: \" local optima solution they got stuck in\" => \"tiset t   t t  t   oooooooooooooottttttt\"\n",
      "batch 16852  loss=143.3252  steps/s=100.33  prediction: \"i have a few libraries in there sadly :9\" => \"nto  tt a a a                  ee eeee  \"\n",
      "batch 16853  loss=149.0195  steps/s=103.71  prediction: \"rap out of them\n",
      "\n",
      "dont worship complexity\" => \"ecif nhen on xo N1???k2???280%??u??80%:?\"\n",
      "batch 16855  loss=154.0389  steps/s=87.89  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \"  a   ntto   t tt\n",
      "  \n",
      " w\n",
      "\n",
      "ooo\n",
      "\n",
      " oooopoppo\"\n",
      "batch 16858  loss=150.4612  steps/s=104.74  prediction: \" like this too? They come in pairs often\" => \"toc  nar  r s  s         o    e    i  i \"\n",
      "batch 16859  loss=140.9107  steps/s=105.60  prediction: \"usually good metrics, good feedback, etc\" => \"st t u   ss l lo ooo    o oooooooooddd  \"\n",
      "batch 16861  loss=152.2363  steps/s=103.78  prediction: \"he pot of gold at the end of the rainbow\" => \"er  t t  tet  t   o      t              \"\n",
      "batch 16862  loss=135.3042  steps/s=104.14  prediction: \" you have a podcast on in the bg or smth\" => \"touss n  i                              \"\n",
      "batch 16863  loss=159.7263  steps/s=98.69  prediction: \"ded something to edit gifs/clips quickly\" => \"   e noeeeneededdedee e   it tgi i   iii\"\n",
      "batch 16864  loss=138.3811  steps/s=104.14  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taiegstnn iiniet        lll ll  e   ee e\"\n",
      "batch 16865  loss=142.1836  steps/s=102.99  prediction: \"views from space, idk how to describe it\" => \"ede aneeseveeeese      s                \"\n",
      "batch 16866  loss=143.3467  steps/s=100.87  prediction: \"ust linux mints built in text editor lol\" => \"stite i  t t   t    i  i iiitt  ittt  tt\"\n",
      "batch 16867  loss=140.9447  steps/s=100.66  prediction: \" ig i still dont understand comonads yet\" => \"tt  ih h i   i          t    dddnddddddn\"\n",
      "batch 16868  loss=142.4085  steps/s=100.29  prediction: \"e or desire to practice for other things\" => \" ioo  rct  r  t r rrr  e    c r rr    r \"\n",
      "batch 16869  loss=151.4029  steps/s=95.72  prediction: \"t only people named dan will have access\" => \" ae iot nr  e  pee oee  e         e   ce\"\n",
      "batch 16870  loss=182.4233  steps/s=42.11  prediction: \"t: RT @AI_Solzhenitsyn: Live Not by Lies\" => \"  s  nt  e pe epee iee   a        e   ce\"\n",
      "batch 16871  loss=154.5236  steps/s=111.97  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \":eisaa aasas sa sss                     \"\n",
      "batch 16872  loss=185.1867  steps/s=92.15  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"    l @oxem @E_nw@EwwCwkxkCX.qxq,.+,,v,H\"\n",
      "batch 16873  loss=147.6999  steps/s=104.06  prediction: \"esting example of goodharting the reward\" => \"  bttetteneeettneee eeee  eoooo  o o   r\"\n",
      "batch 16874  loss=161.1384  steps/s=90.35  prediction: \"ucoder Any cracked accts you wanna list?\" => \"nh taea e r eree e  e coac   ooo t na ar\"\n",
      "batch 16875  loss=139.9657  steps/s=102.40  prediction: \"ces for speed and it makes the game wild\" => \"h ps cec ecce seeee   e   e  e     e   e\"\n",
      "batch 16876  loss=196.6398  steps/s=20.97  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly: sc c  ce eseee   e   e  e     e   e\"\n",
      "batch 16877  loss=168.2759  steps/s=149.92  prediction: \"ure Beautiful, and great choice of music\" => \"ne i sA  seu ease e   i a   aa  eeee   e\"\n",
      "batch 16878  loss=187.0866  steps/s=101.35  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"nBeasps////ssB tBBBB o    oo oo o  o   l\"\n",
      "batch 16879  loss=156.6235  steps/s=102.95  prediction: \"ught it was a cool idea so i speedran it\" => \"neitnto\n",
      "et\n",
      "tttht t        o             \"\n",
      "batch 16881  loss=156.0049  steps/s=104.29  prediction: \" I'm super down for another one thursday\" => \"@   ! n!! s s ds          o    o   o    \"\n",
      "batch 16882  loss=142.6660  steps/s=104.82  prediction: \"just point to concepts and arent reality\" => \"ust    i hs n ot   oo  o t  tnn n  nnn t\"\n",
      "batch 16883  loss=138.7767  steps/s=104.72  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \"  e  ew ee e ehn    e     e     e  e   e\"\n",
      "batch 16884  loss=143.2650  steps/s=103.71  prediction: \" this era where breaches happen so often\" => \"toe  s enie ein  ei  eee  hhheh he  heee\"\n",
      "batch 16885  loss=145.0090  steps/s=105.28  prediction: \"e component is the key to crazy stuff...\" => \" pons  ooe nnnt nn  e     e  ee  t   t  \"\n",
      "batch 16886  loss=153.8810  steps/s=105.92  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  ag  t  ne   r     e             r   r \"\n",
      "batch 16887  loss=131.3496  steps/s=94.83  prediction: \" just do what i tell them the first time\" => \"tus  t t h     t      t  t tt t e  t t t\"\n",
      "batch 16888  loss=148.7022  steps/s=103.97  prediction: \"cipe for less funny + fake feeling posts\" => \"onles m\n",
      "sereee s    e        +   fffee  \"\n",
      "batch 16890  loss=160.1471  steps/s=104.12  prediction: \"ning curve so I can make cool stuff w it\" => \"gm te  he n n  r e          c        c  \"\n",
      "batch 16891  loss=140.3289  steps/s=104.67  prediction: \"y want to use something feeling-relatedâ€¦\" => \" co eobbbbbob     o         e   eeeeeeee\"\n",
      "batch 16892  loss=180.0467  steps/s=102.02  prediction: \"ellectus @gfodor https://t.co/Emux6iPInC\" => \" le nertlt el l  tto  o ttteetttee///ete\"\n",
      "batch 16893  loss=143.1864  steps/s=104.17  prediction: \"it seems like using a spoon vs a scalpel\" => \"n o o e te   es e     s      ss  ss    s\"\n",
      "batch 16894  loss=170.4255  steps/s=100.78  prediction: \"n.. animate it bros. that's 60fps almost\" => \"  gtec enhtnmnt  t. .. .att. t.   t st  \"\n",
      "batch 16895  loss=146.9270  steps/s=103.24  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"tn e  o       u          ttttttto////tSS\"\n",
      "batch 16896  loss=153.9832  steps/s=103.87  prediction: \" i found it really hard for some things.\" => \"tn  ist in    n                         \"\n",
      "batch 16897  loss=140.3418  steps/s=105.60  prediction: \" hold onto the ones not worth finishing.\" => \"tot on  ontooottooooooo oo oo  o      nn\"\n",
      "batch 16898  loss=161.2746  steps/s=102.23  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \"sh     e c     e    .    s.........////t\"\n",
      "batch 16900  loss=147.7889  steps/s=101.30  prediction: \"ticed this too, its what got me thinking\" => \"ho o  e c n ii t  totttst tt  t t   tttt\"\n",
      "batch 16901  loss=143.4239  steps/s=103.24  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"se o  t fhitat rrttattaaaaaaahhhahhhhhhh\"\n",
      "batch 16902  loss=147.3163  steps/s=103.78  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"td tt  daaaaannaaanaaeeeeee eeeeeeee eee\"\n",
      "batch 16903  loss=153.5610  steps/s=96.98  prediction: \"its cause you hit her w the ah jEEz dude\" => \"n  tPdlAna ss e ss    e       h         \"\n",
      "batch 16904  loss=148.0731  steps/s=103.93  prediction: \"ill you get better at as you practice it\" => \"nl t tt  l l     t  tt   t      t  t  a \"\n",
      "batch 16905  loss=139.3663  steps/s=104.50  prediction: \"s a natively written zig matmul function\" => \" ae s       v  s     i      tttt   tt tt\"\n",
      "batch 16906  loss=155.4956  steps/s=102.77  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"  ig   eveseeeeeeittttitttttntttttt////C\"\n",
      "batch 16907  loss=165.8725  steps/s=102.76  prediction: \" God for helping us both out\n",
      "it was hell\" => \"tErll r lo              oo  oo      t  t\"\n",
      "batch 16908  loss=149.6714  steps/s=104.10  prediction: \"r time your focus muscle will strengthen\" => \"eoerg thnn   wenOk.7wkym.bOf(jCCkmj(yGOv\"\n",
      "batch 16909  loss=197.9351  steps/s=23.06  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly: @erttre e er   rur  uuu us uul s  e\"\n",
      "batch 16910  loss=155.4187  steps/s=108.51  prediction: \" lets you debug your own problems easily\" => \"tose t ttt t t t  u    u   u    oo    oe\"\n",
      "batch 16911  loss=139.9681  steps/s=104.35  prediction: \" only improve by improving their skills)\" => \"tfe  nnnn n n i  o   o    i   iiiiiiii i\"\n",
      "batch 16912  loss=167.5799  steps/s=95.21  prediction: \"sonnet 3.5v2 its amazing for programming\" => \" mn t t    nn     i    mi i ii   rr rrrg\"\n",
      "batch 16913  loss=195.0979  steps/s=20.97  prediction: \"eply: @BuxdahMo its not the real discord\" => \" ly: @t n  n  v   i    mi i ii   rr rrrg\"\n",
      "batch 16914  loss=142.7840  steps/s=111.99  prediction: \"als and make smaller and smaller circles\" => \"nl sa    nanaaeaaa aaaa aaaa   allll lll\"\n",
      "batch 16915  loss=158.0088  steps/s=104.40  prediction: \" super awesome, wait why multiple chats?\" => \"toa   a ar sa  s   a ,    w w w w w    e\"\n",
      "batch 16916  loss=149.6091  steps/s=104.23  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \"hanr  ete tete   \n",
      "ee\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ttt/////tt//\"\n",
      "batch 16918  loss=150.8575  steps/s=103.10  prediction: \"memory of doing a hard thing in the past\" => \"e hieinr d mm                           \"\n",
      "batch 16919  loss=136.7255  steps/s=107.24  prediction: \" my weird posts but im happy nonetheless\" => \"tore en  tete  t      t            p    \"\n",
      "batch 16920  loss=146.6457  steps/s=88.41  prediction: \"t only people named dan will have access\" => \" lhr  len   o yp p       p     n  h ee e\"\n",
      "batch 16921  loss=146.9429  steps/s=103.89  prediction: \"engagement-bait generating llm finetunes\" => \" d    eaeeeeneenaeeeenenetgeggeggnnnennt\"\n",
      "batch 16922  loss=142.3634  steps/s=104.93  prediction: \"he result, its equivalent to convolution\" => \"e   a nr  rr rt  e teeesstt te tt  oet  \"\n",
      "batch 16923  loss=179.6505  steps/s=102.43  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \"o m  rettir\"i\"\"\"i\"\"\"\"\"pppttppppitppopppi\"\n",
      "batch 16924  loss=179.8118  steps/s=82.84  prediction: \"yon Super hyped to see what youre cookin\" => \":u e citop  ppepe=ppep pptiieetaoaao&o;;\"\n",
      "batch 16925  loss=164.4800  steps/s=72.39  prediction: \"@vorpal_strikes Does it replicate tho???\" => \"liaine Sr  t pypee  ep ietiteetioaco inðŸ›‘\"\n",
      "batch 16926  loss=159.3250  steps/s=105.72  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nl tol  f  t  el ttttttt/tt//tt////t///t\"\n",
      "batch 16927  loss=140.1692  steps/s=101.78  prediction: \"ot a lot of sleep last night, feels good\" => \"u  he r  t  oo    o     l        t   ee \"\n",
      "batch 16928  loss=177.7663  steps/s=61.45  prediction: \": @yacineMTB Action produces information\" => \" @pa  nst icnM ey/vG8B298P2_:,AO.cOOB3HH\"\n",
      "batch 16929  loss=141.9672  steps/s=107.84  prediction: \"bank account evaporate like a black hole\" => \"eb uto   r    a    a oaoa a a aae a a   \"\n",
      "batch 16930  loss=140.0408  steps/s=105.46  prediction: \"ant to make many measurements per second\" => \"n u nt  to           m mmmmameeemme eeee\"\n",
      "batch 16931  loss=146.7756  steps/s=99.13  prediction: \"lity is really really powerful, actually\" => \"yk  uA ii i i y    yllyyyeye elll   rlll\"\n",
      "batch 16932  loss=159.7872  steps/s=70.22  prediction: \"paeoh do it man!! making games is so fun\" => \"lnl @o mi  l  yP  lll!!lllar l ala  slll\"\n",
      "batch 16933  loss=149.7395  steps/s=105.85  prediction: \"n doing on a method of learning faster)â€¦\" => \" t we   nnnnn n     n    o      n  n    \"\n",
      "batch 16934  loss=146.2500  steps/s=100.36  prediction: \"just happen to have sicilian parents lol\" => \"ust l e l  t  t  e             i  ii   a\"\n",
      "batch 16936  loss=130.5247  steps/s=101.64  prediction: \"hine now. unless anybody has a spare one\" => \"enke  n  mn  n  n nnnnnn                \"\n",
      "batch 16938  loss=191.0114  steps/s=59.59  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @lacw@lrer  [erVZ[(@QkVÊ€V:j/]^(j/M45X,T\"\n",
      "batch 16939  loss=156.9676  steps/s=106.73  prediction: \" joining man, looking forward to thurs!!\" => \"tues naeneno n n ononoonnnnnooooo      o\"\n",
      "batch 16940  loss=149.1464  steps/s=102.50  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"trea  a  n                          oo  \"\n",
      "batch 16941  loss=154.4959  steps/s=105.02  prediction: \"n\n",
      "Took me from c to a student in college\" => \" \n",
      " \n",
      "aateroo rooo oo    t oo o  t o    t \"\n",
      "batch 16942  loss=212.8363  steps/s=96.52  prediction: \"ch WHOA WHOA YOU WOULDNT DOWNLOAD A LEGO\" => \"oiatTo nee  mHOOWWOO WWUUOUWODDWDNDNDOAO\"\n",
      "batch 16943  loss=151.8264  steps/s=105.05  prediction: \"everything is simple after you learn it\"\" => \" eren  nn gni  g  ii  i     e           \"\n",
      "batch 16944  loss=183.6098  steps/s=31.67  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly  o  n  g i  ii ii  i     e   e       \"\n",
      "batch 16945  loss=138.9464  steps/s=107.28  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"t  o t    t  t ,  tttttttttttttt/tt////p\"\n",
      "batch 16946  loss=158.1614  steps/s=101.23  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \" e  snoon k n e    t            o0000000\"\n",
      "batch 16947  loss=158.4608  steps/s=102.11  prediction: \" is better though, I should check it out\" => \"tt bem ebebee  e eee  h hhh hhh hhh     \"\n",
      "batch 16948  loss=152.6284  steps/s=104.28  prediction: \"ncy, and bitcoin was invented by midwits\" => \" e wt nitht   nn           nnnn  nn     \"\n",
      "batch 16949  loss=148.4335  steps/s=104.71  prediction: \"rflowsucks and never went on there again\" => \"eao     i    UieFf12WFQb2Q12H,p12VQSVSSS\"\n",
      "batch 16950  loss=151.7844  steps/s=101.42  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"t st e s e s        ssssstsssstttt//////\"\n",
      "batch 16951  loss=145.9514  steps/s=103.66  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"s  ie  ttttt t        pp ppppppp  p     \"\n",
      "batch 16952  loss=148.0973  steps/s=104.13  prediction: \"er useful building block to get good at.\" => \"       s u uuueu uuu  l ll              \"\n",
      "batch 16953  loss=158.8724  steps/s=95.26  prediction: \"e @sunsettler youre in the nix dimension\" => \" ao e eS huseleles ee  l     e          \"\n",
      "batch 16954  loss=147.0884  steps/s=81.29  prediction: \"phere @gizmobly giz inc will change this\" => \"let  eSusee@e@ @@l e ii   ni in   i    i\"\n",
      "batch 16955  loss=137.2326  steps/s=106.01  prediction: \"but for now ill run whatever ppl ask for\" => \"et  en   n nn  n                        \"\n",
      "batch 16956  loss=149.1872  steps/s=104.76  prediction: \"s. im betting on that. but i am not sure\" => \"  y t at htt  nn t  t t ttt tt          \"\n",
      "batch 16957  loss=152.9651  steps/s=99.30  prediction: \"oger @sunsettler @tunient baller name xD\" => \"ueytub t  t  tnettttt@tttt ntnnttnn    n\"\n",
      "batch 16958  loss=170.3043  steps/s=29.09  prediction: \"ply: @calbch do it\n",
      "i double dog dare you\" => \"ly: @txtu@e ntn@ttt@t@@ttt ntnntnnne   e\"\n",
      "batch 16959  loss=164.6811  steps/s=108.61  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"@oaamma shs  s        t h      s  sss s!\"\n",
      "batch 16960  loss=148.8639  steps/s=101.39  prediction: \"pany uses it often for researching stuff\" => \"lr   yonymnom  oo o    o o  ee  r   r   \"\n",
      "batch 16962  loss=164.0866  steps/s=108.36  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BA  yy sgAs Attssst  r eeeeoe          \"\n",
      "batch 16963  loss=143.4778  steps/s=104.06  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"0/ w  i     0         h  ttttt//////////\"\n",
      "batch 16965  loss=139.6308  steps/s=103.95  prediction: \"dition, just kpis to optimize right now)\" => \" n  i  nnniinnin i   i    t  iiiii iii i\"\n",
      "batch 16966  loss=149.9596  steps/s=100.76  prediction: \"f many useful things i can build for ppl\" => \" y o ant   f     f      s           i   \"\n",
      "batch 16967  loss=131.2220  steps/s=103.27  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"u  t  b ttt tt t  t     o      eeeeeeeee\"\n",
      "batch 16968  loss=154.0815  steps/s=103.88  prediction: \"ndow its just :q when inside that window\" => \" o\n",
      "\n",
      "oo  sito      t          si   i  i  \"\n",
      "batch 16969  loss=148.9097  steps/s=102.38  prediction: \"rappers around statistical distributions\" => \"ent c e   t  xo á´‡]Zkj[&k~ym::;x,â€jx:+;xx\"\n",
      "batch 16970  loss=144.0606  steps/s=44.74  prediction: \"y: @sunsettler write a will just in case\" => \": @jawtesr  rrp  r asatstaatastsii titii\"\n",
      "batch 16971  loss=169.1595  steps/s=92.70  prediction: \": @yacineMTB better start skilling up ig\" => \" @jac @  o  tMne7]0kj[&k;ym::;xjbjx:+;xx\"\n",
      "batch 16972  loss=148.0087  steps/s=121.32  prediction: \"almost as bad as jan blocking his bishop\" => \"nl n rel t l as tsa aa aaa    a  n   ii \"\n",
      "batch 16973  loss=145.2971  steps/s=100.18  prediction: \" wanted to include infinite programs too\" => \"@in  nen nnt  en n n    niniii iiiiiii  \"\n",
      "batch 16976  loss=139.5277  steps/s=99.82  prediction: \" play instead of making random moves lol\" => \"@rtt tn   tta l  aa a aaaaa aaa         \"\n",
      "batch 16977  loss=150.0424  steps/s=102.38  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" we ni    lll  l           a    m s ssss\"\n",
      "batch 16978  loss=141.9022  steps/s=103.83  prediction: \"nces contains homotopies (find them idk)\" => \" e saatserseeeeneennonoooooooooooiii i i\"\n",
      "batch 16979  loss=165.6987  steps/s=107.21  prediction: \"uote tweets work https://t.co/CCGxweEQQ8\" => \"sfd  oont   e eeottt tt tttttttt///////C\"\n",
      "batch 16980  loss=191.8809  steps/s=100.20  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"erb  elz o @l @ o77227772222ttt////.///t\"\n",
      "batch 16981  loss=194.4712  steps/s=101.30  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"topek  myymmmm  l l h htt:::t:/t////////\"\n",
      "batch 16982  loss=146.5502  steps/s=104.63  prediction: \"es success, but there is a causal factor\" => \"  int   eees  utsssseessse es    a  a a \"\n",
      "batch 16983  loss=142.7721  steps/s=104.94  prediction: \"d its helped man. i shpuld sleep too lol\" => \" thn n   hd d nn d              lplp    \"\n",
      "batch 16984  loss=150.9439  steps/s=104.38  prediction: \" pre session lift make a difference btw?\" => \"tro      ss sssssss                eefee\"\n",
      "batch 16985  loss=154.0488  steps/s=45.93  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  @    s ese s              fffffeee eee\"\n",
      "batch 16986  loss=223.1107  steps/s=131.70  prediction: \"icCapital COMMENCE OPERATION BRAIN DRAIN\" => \"nl   rasiiets [[e  CCEE E E eORReeeIN  R\"\n",
      "batch 16987  loss=141.9057  steps/s=103.70  prediction: \" like 1hr ago lol\n",
      "\n",
      "also is that your dog\" => \"teaw nh  i           lllllllll          \"\n",
      "batch 16989  loss=144.2675  steps/s=104.83  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"n  aee   a    e          tttttttttt/////\"\n",
      "batch 16990  loss=158.4019  steps/s=105.17  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \"ter,  o nn nt gn   o    t    ttgggg gg g\"\n",
      "batch 16992  loss=150.1481  steps/s=103.44  prediction: \"ts one of the fundamentals of everything\" => \"; g    t bo  o n     e  tee e e  ee e e \"\n",
      "batch 16993  loss=152.6428  steps/s=104.61  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"taci  ac   c  t                         \"\n",
      "batch 16994  loss=145.1547  steps/s=105.19  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"&Mte  e   w  _  $(888zÊ€/$')~$Axvá´›,`ð˜(ÊŸâ€¦^\"\n",
      "batch 16995  loss=145.4584  steps/s=97.14  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"yd nsesr ettt n  i  s s        aaaee ara\"\n",
      "batch 16996  loss=142.8731  steps/s=103.86  prediction: \"ommittal move like going on a sabbatical\" => \"n m  e  momeam t m    e    o    o     aa\"\n",
      "batch 16997  loss=156.7872  steps/s=102.82  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"n   oso  .............       o          \"\n",
      "batch 16998  loss=214.5369  steps/s=87.71  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"  h  aa .m MP uU                 /  o o \"\n",
      "batch 16999  loss=155.0547  steps/s=106.54  prediction: \"free could help too if thats the problem\" => \" oe mtcm                  o     tt   t  \"\n",
      "batch 17000  loss=142.1016  steps/s=105.36  prediction: \"d its helped man. i shpuld sleep too lol\" => \" tai n  ahd d nn d              pppp    \"\n",
      "batch 17001  loss=179.1321  steps/s=99.83  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"hpn i    htn////  ZZ/HHHHH.....DDDpp=pp=\"\n",
      "batch 17002  loss=145.2286  steps/s=105.68  prediction: \"dates/incentives to fund ai safety stuff\" => \" ye  anaannetenenneeeeneenn nn  n    t  \"\n",
      "batch 17004  loss=151.8827  steps/s=103.79  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"ta m nee  m  ed    ee                   \"\n",
      "batch 17005  loss=168.5032  steps/s=57.68  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"tsim eree e   I    ee        e    s   t \"\n",
      "batch 17006  loss=150.2257  steps/s=112.08  prediction: \"ler\n",
      "\n",
      "the more you talk the less you walk\" => \"yr  ioi ritirr r r    o  t t  ee  e e   \"\n",
      "batch 17007  loss=142.3954  steps/s=105.46  prediction: \"e right things really really does matter\" => \" mo  e eeet ett   t      r  l  lllll  ll\"\n",
      "batch 17009  loss=165.4826  steps/s=103.96  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"re  x nxxf   x 5f      \n",
      "   \n",
      "\n",
      " ///o///111\"\n",
      "batch 17010  loss=152.1098  steps/s=99.69  prediction: \"e ive been thinking the exact same thing\" => \" snivf  ve e eee ienn nntntthttt  tttht \"\n",
      "batch 17011  loss=167.6830  steps/s=104.05  prediction: \"ger, LETS GET IT\n",
      "https://t.co/ZIDQZp9Vp6\" => \" t iaetsff aE   TTTTTTTT       tII////ZZ\"\n",
      "batch 17012  loss=163.8811  steps/s=104.50  prediction: \"the community give me energy to do these\" => \"he  esto  t    t    e    ee e e eeee  ee\"\n",
      "batch 17013  loss=156.6921  steps/s=100.86  prediction: \"Tex prob huge dollars in anti drone bots\" => \"h ntoha TeTeee re e      r         n    \"\n",
      "batch 17014  loss=145.3942  steps/s=103.69  prediction: \"al, one of the most cracked players ever\" => \"nl neo o  nee o o o    o       e     eee\"\n",
      "batch 17015  loss=147.9792  steps/s=101.50  prediction: \"r switching if mint doesnt serve me well\" => \"etIel   ne  mvaeI'vá´€ðŸ˜.$Wx^ÊŸðŸ‘ŒÉª`*$.$WÊ€á´›å§ÊŸå€‘\"\n",
      "batch 17016  loss=130.8359  steps/s=103.94  prediction: \"ink thats gonna be a massive rabbit hole\" => \"ng i  tt t tttntt            aaaaaaabbbb\"\n",
      "batch 17017  loss=151.4363  steps/s=105.21  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"tore   t t eo  -e e  \n",
      "ee\n",
      "\n",
      "\n",
      "ttttt/t//s///\"\n",
      "batch 17018  loss=137.1143  steps/s=105.04  prediction: \"f, and also not lying about small things\" => \"o    gmgty  l ol  l     o           l   \"\n",
      "batch 17019  loss=137.0768  steps/s=103.27  prediction: \" to use. code is linked in another reply\" => \"toep e epet tosee   esee se   e    ee en\"\n",
      "batch 17020  loss=161.1796  steps/s=103.07  prediction: \"/t.co/KAmykVYFyw https://t.co/Fg3PbzaDJZ\" => \"t..htpep //tK////t//Kt//t::///F:///FF///\"\n",
      "batch 17021  loss=146.3028  steps/s=102.95  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot int ni  n n               ttttt/t///\"\n",
      "batch 17023  loss=144.1610  steps/s=104.73  prediction: \"a good way to beat addictions in general\" => \"ngni w ss   ttooooo    a  aa aa   ii    \"\n",
      "batch 17025  loss=185.8829  steps/s=83.70  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"ero     w      e    ttt  ttt ii   nnnXXX\"\n",
      "batch 17026  loss=138.7624  steps/s=102.90  prediction: \"s of industry water cooler conversations\" => \"tftt tt s o ososs       o     orrrrroror\"\n",
      "batch 17027  loss=137.4298  steps/s=105.63  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sin lisnnneeiginniiinntnteitttccttttt/c\"\n",
      "batch 17028  loss=148.4143  steps/s=104.93  prediction: \" by talking abt half done projects. BOOM\" => \"ted  ti ng  n  n                        \"\n",
      "batch 17029  loss=140.4322  steps/s=102.65  prediction: \"ich is a great way to find opportunities\" => \"ni f  ici icc w                        t\"\n",
      "batch 17030  loss=183.3573  steps/s=93.34  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"tceii n ia  rre   th    tttthptttop///tt\"\n",
      "batch 17031  loss=175.2359  steps/s=97.03  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tn i  rnwn hntth h ttt:::tht::/t.:t//.0c\"\n",
      "batch 17032  loss=162.5622  steps/s=101.76  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"ton oFeooooolleoo ll  o o   o   oo oo  u\"\n",
      "batch 17033  loss=156.7045  steps/s=102.62  prediction: \"you get used to it and overcome the fear\" => \":u a ra   g   ut t t t   tt  o  o   e e \"\n",
      "batch 17034  loss=147.5558  steps/s=97.49  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tnb in  n   a            ttttttttttttt//\"\n",
      "batch 17035  loss=141.4901  steps/s=103.95  prediction: \"stead of just knowing what they were, Iâ€¦\" => \" in mvni mn e e    n           t        \"\n",
      "batch 17036  loss=140.2253  steps/s=103.98  prediction: \"dnt mention anything related to caffeine\" => \" tnlo tetntttt   tnntn nnttnntnnnt te te\"\n",
      "batch 17037  loss=154.7197  steps/s=83.61  prediction: \"ochenko curious, can you elaborate more?\" => \"ne  de e nenno   inn n    ee t   aaaeeae\"\n",
      "batch 17038  loss=169.9984  steps/s=105.37  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"t.c it t////9///9999899ttpp//ttt////t///\"\n",
      "batch 17039  loss=154.3156  steps/s=101.80  prediction: \"ding up the drive thru for 1000 episodes\" => \" vn Bne  enn  n                    00000\"\n",
      "batch 17040  loss=188.2729  steps/s=63.71  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \"on sts en     ee e    h     000000000 ee\"\n",
      "batch 17041  loss=138.9133  steps/s=107.19  prediction: \" know its doable\n",
      "https://t.co/DZCdUoVn6w\" => \"tit  n   t  noo   ooootttotttttoottttt//\"\n",
      "batch 17042  loss=165.3873  steps/s=104.74  prediction: \"orks but is mvp\n",
      "\n",
      "https://t.co/0jdbSxKeVi\" => \"ukmam mmmmes         \n",
      "\n",
      " \n",
      " t\n",
      "tt ttt//////\"\n",
      "batch 17043  loss=166.1002  steps/s=98.59  prediction: \"gonna humble him\n",
      "https://t.co/HUMAzXB4rm\" => \" n t eus o nn    h  hh hhthhtt/////ht//t\"\n",
      "batch 17044  loss=138.2026  steps/s=103.51  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"  t  eett tb  be       i   i       d  d \"\n",
      "batch 17045  loss=140.6454  steps/s=105.57  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e eoat t t n tnneee e  e e eeeee        \"\n",
      "batch 17046  loss=136.9097  steps/s=103.75  prediction: \" to install\n",
      "\n",
      "so im making one for myself\" => \"thettt  t  vtttt                        \"\n",
      "batch 17047  loss=148.1004  steps/s=103.82  prediction: \"on the manager/grifter/sociopath problem\" => \"u  ee o oe e eaee errr ererrrgerrrrrtrrr\"\n",
      "batch 17048  loss=144.1386  steps/s=99.28  prediction: \"t really is a long term + hard work game\" => \"hih   ron   r  l    a l  i o  a r r  rrr\"\n",
      "batch 17049  loss=142.9313  steps/s=105.89  prediction: \" the zero quine: https://t.co/qt0qAp9ZYk\" => \"thett  tttttt            t ttttttqqtqqqq\"\n",
      "batch 17050  loss=140.7068  steps/s=105.45  prediction: \" you get stuff done in a quick timeframe\" => \"toul    t  t  t                         \"\n",
      "batch 17051  loss=148.5708  steps/s=100.40  prediction: \" off with a basic template and modify it\" => \"tu ttatf fftf  t           a aataa a aa \"\n",
      "batch 17052  loss=166.0795  steps/s=72.90  prediction: \"Brycicle77 its a 'being' kinda day today\" => \" y t rtffffta i   t  a tt aa  ataa a da \"\n",
      "batch 17054  loss=158.3180  steps/s=110.11  prediction: \"r model architecture not based on tokens\" => \"ewoy  ayri er_no7NA'@jpA.'Nk,IrNIIIIIII,\"\n",
      "batch 17055  loss=155.4897  steps/s=100.63  prediction: \" this long lost treasure of a song, damn\" => \"to    o f n no n        o    o s      s \"\n",
      "batch 17056  loss=159.2063  steps/s=106.23  prediction: \"re. Turns out it actually had a solution\" => \"epletce  mg  O  OyO\"vOvv(v(()(5zk\n",
      "\"v\"\"\n",
      "\"\"\n",
      "batch 17057  loss=161.5753  steps/s=96.43  prediction: \" a friend that did this for a CS project\" => \"t t   r ea 2r a   t  t tt th  a     a  o\"\n",
      "batch 17058  loss=139.2726  steps/s=104.63  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taiegstnn\n",
      "iiniet        lll ll  e   ee e\"\n",
      "batch 17059  loss=162.9610  steps/s=103.54  prediction: \" funny i like it https://t.co/gxpcMrRiHL\" => \"tun   s fen d r  ee     k ei i    i  /t \"\n",
      "batch 17060  loss=135.6263  steps/s=104.24  prediction: \"p infested regions of their latent space\" => \"li  @o  t te enteeeeeeeeeee       e     \"\n",
      "batch 17062  loss=183.5768  steps/s=29.28  prediction: \"ply: @10x_er he saw food and came runnin\" => \"ly: @o   otetenteeeee  e e   e ee e   t \"\n",
      "batch 17063  loss=149.3188  steps/s=107.17  prediction: \"n doing on a method of learning faster)â€¦\" => \" m we   nennn e     n    o      n  n    \"\n",
      "batch 17064  loss=156.5704  steps/s=104.18  prediction: \"morrow, hope it goes well for you brotha\" => \"ede oi fodrtmoorroo  ooo   oo eo   oo   \"\n",
      "batch 17065  loss=152.5453  steps/s=100.86  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"nd   ts m      a  a      a         a    \"\n",
      "batch 17066  loss=154.6680  steps/s=104.46  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"ei t et       o     o    t            v \"\n",
      "batch 17067  loss=178.8579  steps/s=88.57  prediction: \"ettler @gizmobly https://t.co/3UPliJk8JG\" => \"  en  s  t  r    o  o ttl  tt v       o \"\n",
      "batch 17068  loss=146.4483  steps/s=104.16  prediction: \"o beta testers, and the world soon after\" => \"nse  nte eet e t  te  ttt  e    t   o   \"\n",
      "batch 17069  loss=149.2936  steps/s=103.86  prediction: \"sed to sound like the opposite of curses\" => \"   lelb e d s s           e      ooo  o \"\n",
      "batch 17070  loss=147.3094  steps/s=103.70  prediction: \"w, weve been going for a few weeks or so\" => \"o te  ot      w         e          e   e\"\n",
      "batch 17071  loss=147.3269  steps/s=104.69  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \"   o  u  e u uy u  uu  hh h hhhhhhhuu   \"\n",
      "batch 17072  loss=142.8512  steps/s=104.89  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"te s  o g gg   e eee ooee eeeeee  o  o s\"\n",
      "batch 17073  loss=179.5699  steps/s=65.93  prediction: \"@startupmillyair https://t.co/QgfnCndCQA\" => \"suoitot erg eeneieo   oeeee e ooo s  sss\"\n",
      "batch 17074  loss=156.4039  steps/s=114.23  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"g m ts  mnmmem  mo   em  e e        a   \"\n",
      "batch 17075  loss=151.3858  steps/s=98.93  prediction: \"ieved internally https://t.co/tbnU75n8eA\" => \"ns  etnee n  eeeeelellllt  tttt////t////\"\n",
      "batch 17076  loss=173.7346  steps/s=96.92  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"egtyl  D     _  0W@j!A1@jx66Iz480Iz4Q0_T\"\n",
      "batch 17077  loss=144.1276  steps/s=100.37  prediction: \" if I decide to read em ill do a summary\" => \"tt eet   s  n        e                  \"\n",
      "batch 17078  loss=172.6465  steps/s=100.88  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"ss    r eruu tyeruutuuttt tttotttt//tt/t\"\n",
      "batch 17079  loss=145.8927  steps/s=103.72  prediction: \"r something as small as starting on boot\" => \"ew_y  awr   c_py6PkPMP:P6P:PYP.yYTL87T:U\"\n",
      "batch 17080  loss=147.6878  steps/s=97.46  prediction: \"hnote uuuh i have a license for thse sir\" => \"eoeesnmetennnu   u    a      a e  n   os\"\n",
      "batch 17081  loss=151.3151  steps/s=103.15  prediction: \"hinks he might pick up in future decades\" => \"en  aniiten  hihh  h h   i     i        \"\n",
      "batch 17082  loss=146.1397  steps/s=105.28  prediction: \" the time and not spread important info?\" => \"to   el lll  e                      tttt\"\n",
      "batch 17083  loss=138.7137  steps/s=105.81  prediction: \"y can approximate any func. they all can\" => \" aoaenn     n n aa aaaaaaaaaa   n       \"\n",
      "batch 17084  loss=142.1486  steps/s=104.18  prediction: \"link, and then pretended to be my server\" => \"yne trct t  t a      n  eeeeeeeee   e ee\"\n",
      "batch 17085  loss=143.7740  steps/s=101.34  prediction: \" android OS inside of a virtual machine?\" => \"t d ann da nn  n dd          i       i  \"\n",
      "batch 17086  loss=201.4007  steps/s=21.09  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: nd d  n     d         i i       i  \"\n",
      "batch 17087  loss=145.7668  steps/s=107.14  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"h re tew   ''   e    e  e t  ///ttt////t\"\n",
      "batch 17088  loss=183.3333  steps/s=37.74  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y: @een  e e' e e    e  ttt /////tt//s/c\"\n",
      "batch 17089  loss=160.1462  steps/s=117.23  prediction: \"i it does look super nice, was gonna say\" => \"nsainrnnitittii   io    o    s    o  s  \"\n",
      "batch 17091  loss=150.3414  steps/s=100.73  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \":co ee  ln l   d ddd d dddddddd/////////\"\n",
      "batch 17092  loss=133.9028  steps/s=99.11  prediction: \"ood at noticing things, would be so kino\" => \" d ut gtgototo ttttttgiigii             \"\n",
      "batch 17093  loss=154.8794  steps/s=105.86  prediction: \" right now its just learning on the side\" => \"tet a a r nn  t         t   t    nn     \"\n",
      "batch 17094  loss=141.6700  steps/s=103.67  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"tal pen  ooolo toololll llllllll a   a  \"\n",
      "batch 17095  loss=151.6213  steps/s=97.37  prediction: \"rd it means theyre giving you a discount\" => \"e 21 nionse o. rv1RLxx,.wb`,Ij!!'II8vF'v\"\n",
      "batch 17097  loss=134.0758  steps/s=102.53  prediction: \"future features\n",
      "\n",
      "thanks for the idea bro\" => \" clienaoftet t eettteteeeettttttt ee    \"\n",
      "batch 17098  loss=144.9747  steps/s=103.53  prediction: \"e real for this\n",
      "\n",
      "https://t.co/XuMxlWAwBE\" => \" be a aalaa  a a lr\n",
      "\n",
      "\n",
      "  t\n",
      "\n",
      "\n",
      "tttt\n",
      "/ttttt/\"\n",
      "batch 17099  loss=153.4491  steps/s=96.22  prediction: \"ollowed you on li\n",
      "my lichess is @dnbt777\" => \"   hloooolllloooooo     ll           ss \"\n",
      "batch 17100  loss=145.8043  steps/s=101.21  prediction: \" time on their hands + survivorship bias\" => \"@het t  to  t t                   r ri i\"\n",
      "batch 17101  loss=142.8008  steps/s=105.12  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tar at i r n            t ttttttt///////\"\n",
      "batch 17102  loss=151.7008  steps/s=104.06  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt    geef ff rf ff      s   t /tt///tt/\"\n",
      "batch 17103  loss=186.5274  steps/s=67.86  prediction: \" @brianf3rnandez @crungulism Like 20mins\" => \"tyaerni feffr n  en  snntt s// /tt//ttKt\"\n",
      "batch 17104  loss=171.6701  steps/s=90.83  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tbaere e ef rnnnooo  tnn:s///to/HHHJJ00t\"\n",
      "batch 17105  loss=146.6993  steps/s=106.81  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"the  ttt t  i  t  t tthhtttthtthtttttoot\"\n",
      "batch 17106  loss=137.2119  steps/s=104.30  prediction: \"w the entire thing works when you use it\" => \"ist en h n  n et                        \"\n",
      "batch 17107  loss=273.4169  steps/s=13.28  prediction: \"reply: @yacineMTB google necessary being\" => \"e, y: aael neMb EE@8b8x8IEEx4.?B,?::/:NQ\"\n",
      "batch 17108  loss=156.6795  steps/s=111.05  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tn iihissniinshesssssttttttttttt////////\"\n",
      "batch 17109  loss=141.6621  steps/s=103.16  prediction: \"rtionately likely to show up on your FYP\" => \"ei ydt y    n/  666G66.GTWWWWWGYYYYGYYP=\"\n",
      "batch 17110  loss=153.9069  steps/s=105.64  prediction: \"new following you was the right decision\" => \"gwai   orhr  l l o w o  ww              \"\n",
      "batch 17111  loss=145.0352  steps/s=103.47  prediction: \"d posted some CRAZY progress\n",
      "LETS GET IT\" => \" to     dd  sdd d          o ssssssssssT\"\n",
      "batch 17112  loss=131.0959  steps/s=105.26  prediction: \" a cross section now that you mention it\" => \"t dd k  k     ss                        \"\n",
      "batch 17113  loss=145.0613  steps/s=104.27  prediction: \"n clarity from practicing visualizationâ€¦\" => \" t e sneeme n m  rrrirrrriii  iciiiiaiii\"\n",
      "batch 17114  loss=152.8440  steps/s=97.58  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"  ie ima in        c t ttttttottttt//t//\"\n",
      "batch 17115  loss=139.6133  steps/s=105.09  prediction: \"st powerful learning techniques there is\" => \"  s t   o  t  no    e    e eeeeneneeeeee\"\n",
      "batch 17116  loss=159.8165  steps/s=101.99  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e ly:m _  @t @ iT_@.21-21IIx21!xxIvmA\"A:\"\n",
      "batch 17117  loss=142.9710  steps/s=104.03  prediction: \"deviating\n",
      "and it lets you do that faster\" => \" ns a d edn  nnennnii i     t  t    t  t\"\n",
      "batch 17118  loss=144.0245  steps/s=102.39  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"ea y nt      @  k3@&b;3;333A33b333,bPP9_\"\n",
      "batch 17119  loss=151.7881  steps/s=96.93  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \"hloso taa\n",
      "ssa h tt     rrtt euun  ny a  \"\n",
      "batch 17120  loss=177.7607  steps/s=50.35  prediction: \": @minamisatokun https://t.co/7cpKcX83WN\" => \" @m o n\n",
      "n lns@nnkS@.b:S.p.:A/7.LK/783KOX\"\n",
      "batch 17121  loss=183.2623  steps/s=123.33  prediction: \"losdavila007 yeea\n",
      "started abt a week ago\" => \"ywae anars aa0tn000 tseesttstret  a     \"\n",
      "batch 17122  loss=147.1802  steps/s=103.71  prediction: \"up computing 'why' for free all the time\" => \"  i   e   n n        '''''              \"\n",
      "batch 17123  loss=168.9829  steps/s=39.60  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y: @een  uun  en  '''''                 \"\n",
      "batch 17124  loss=166.2889  steps/s=106.03  prediction: \"/t.co/YpddagC5uf https://t.co/GdftPhw7eI\" => \"/..c:30t:YYtppt//ttYptttttp///ppt./ttdtt\"\n",
      "batch 17125  loss=144.9126  steps/s=103.65  prediction: \"onna get wiiiild man like reeeeally wild\" => \"    ors gosngig n gn  i iiiiii e l  l   \"\n",
      "batch 17126  loss=159.3200  steps/s=94.94  prediction: \" stuff! Thanks, hope yours went well man\" => \"toe  e s of    ff           eeee    w   \"\n",
      "batch 17127  loss=148.1854  steps/s=103.37  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e\n",
      " y     er LLLrvGDDw_!bTmD!DT,===&;;;^^\"\n",
      "batch 17128  loss=159.2392  steps/s=101.45  prediction: \"here for the funny symbols and recursion\" => \"e sk er rr  rrr      e    e        n   n\"\n",
      "batch 17129  loss=151.2437  steps/s=96.53  prediction: \"resy you can already talk to one of them\" => \"eplym ntninsjA_ovGY3wwf:TB7!mxju&&y,b'vx\"\n",
      "batch 17130  loss=176.1465  steps/s=71.75  prediction: \"xluffyb Its almost side project saturday\" => \"pejmehee hy   en aan y al se   o oo  o o\"\n",
      "batch 17131  loss=150.4994  steps/s=109.51  prediction: \"eepfake the adobe CEO's face onto Yezhov\" => \" l nd  dee  deuee  eee  e e e     e     \"\n",
      "batch 17132  loss=152.0948  steps/s=101.75  prediction: \" like this too? They come in pairs often\" => \"@or opa n r s  s         o    o    o  i \"\n",
      "batch 17133  loss=186.7917  steps/s=97.75  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"eue  nrn a te  hoe  ee etoe.    t os t/t\"\n",
      "batch 17134  loss=142.6291  steps/s=105.01  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r  tior g  i  . siiississssttsttttt////\"\n",
      "batch 17135  loss=141.2037  steps/s=105.98  prediction: \"hing that could ruin their brand idk tho\" => \"es    e  t ttt t  t              i      \"\n",
      "batch 17136  loss=160.6115  steps/s=76.08  prediction: \"paeoh do it man!! making games is so fun\" => \"lro  g sn  t  g t          i    ii      \"\n",
      "batch 17137  loss=158.5295  steps/s=106.23  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"aow  n aama n e  massssssss   ttttt/////\"\n",
      "batch 17138  loss=155.9944  steps/s=100.95  prediction: \"though who knows\n",
      "https://t.co/YpddagC5uf\" => \" es c y  cc   hh hohhhhhhthhttttt////o//\"\n",
      "batch 17139  loss=158.8356  steps/s=103.42  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nt to   l  t  el tttttttitttttt////t////\"\n",
      "batch 17141  loss=154.0181  steps/s=104.56  prediction: \"s\n",
      "\n",
      "been doing this over half my life now\" => \" \n",
      "e   peess eeeee  e  e i  i     h      \"\n",
      "batch 17142  loss=136.7505  steps/s=104.45  prediction: \"stuff in general\n",
      "https://t.co/hPNi1j1Eaw\" => \" of   n i nff nf nn    nttnttttttttt//tt\"\n",
      "batch 17143  loss=158.6762  steps/s=104.85  prediction: \"amming you can make bigger leaps though.\" => \"ne p    nnn r m  m m   m    ggg    g  g \"\n",
      "batch 17145  loss=147.9624  steps/s=104.81  prediction: \" so I invested my time into that instead\" => \"tkrterno     oIe   ee e i    t  t tttt t\"\n",
      "batch 17146  loss=160.5690  steps/s=38.71  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y  @eo o r    I e  ee e t    t  t tttt t\"\n",
      "batch 17147  loss=157.1301  steps/s=129.12  prediction: \"ea c and JS and compiled with emscripten\" => \" l oe@aeree d          dd d   ii    itei\"\n",
      "batch 17148  loss=192.9425  steps/s=100.77  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"tha aa e    TTT OOOOO O   t   tt////////\"\n",
      "batch 17149  loss=140.0891  steps/s=103.89  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he moe n  n   in                        \"\n",
      "batch 17150  loss=127.9368  steps/s=102.35  prediction: \"veryone in the past was a caveman/moron\"\" => \"e  h   e eneeeeeee            aaaaaaaaaa\"\n",
      "batch 17151  loss=155.8973  steps/s=99.77  prediction: \"oulda made stock cert flags instead, rip\" => \"r eane e  n a h  da    t    cc    s    n\"\n",
      "batch 17152  loss=154.3921  steps/s=105.01  prediction: \"know what it is\n",
      "\n",
      "https://t.co/wJ5n1H6JUK\" => \"eo)on    t  t     tt t ttttttttttt/////J\"\n",
      "batch 17153  loss=143.1185  steps/s=103.91  prediction: \", how do WE figure out where things are?\" => \" aou    no                     e   e    \"\n",
      "batch 17154  loss=138.8230  steps/s=103.98  prediction: \"code base to get something super complex\" => \"omio tet tett  e e   e  e      e     ee \"\n",
      "batch 17155  loss=130.7066  steps/s=100.84  prediction: \"o the door the instant she hears it open\" => \"nyop t ntgn  ttt  t t t       h   h    e\"\n",
      "batch 17156  loss=155.7265  steps/s=102.05  prediction: \"yeah, tunisia... carthage would be nice\"\" => \" a suui..t nn...........a a aaa aa    e \"\n",
      "batch 17157  loss=137.3061  steps/s=105.04  prediction: \"verything that happens to everyone else'\" => \"eryteev  teettt tttttthtt t     e eeeeee\"\n",
      "batch 17158  loss=139.7530  steps/s=104.53  prediction: \"r the picture\" for any industry or niche\" => \"ethe teceesse_sekðŸ°^â€,W[]T^\"W[Ê€#|{I'T`W$`\"\n",
      "batch 17159  loss=138.4933  steps/s=105.49  prediction: \"tw, my b, but ill hop in on the next one\" => \"h    ite t m  mm  t   b                 \"\n",
      "batch 17160  loss=156.4154  steps/s=101.67  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"ns    r eyd  e     e dd d  e  e   t   tt\"\n",
      "batch 17161  loss=149.3276  steps/s=105.08  prediction: \"000000000000000000000001% of the new one\" => \"0  ohh  tre tAt kv7IL=.%1%CCI79vTIvXQjgx\"\n",
      "batch 17162  loss=156.6987  steps/s=103.46  prediction: \"now unless i need to paste in huge files\" => \" t f o  o   ssss  s                   ee\"\n",
      "batch 17163  loss=162.2353  steps/s=86.39  prediction: \"amebedan @jaivinwylde stochastic success\" => \"nen\n",
      "   onse  nnn  i     e ee   tt    ees\"\n",
      "batch 17164  loss=143.3239  steps/s=104.97  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" no  onnn no o         t tttttttt///////\"\n",
      "batch 17165  loss=148.1015  steps/s=105.43  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"ep hlr@tcitis0ge0000000000k00000k000:000\"\n",
      "batch 17166  loss=139.9829  steps/s=105.49  prediction: \"ational ones it might actually be useful\" => \"ne   nr f ronoonoooi  i     ttta  tt al \"\n",
      "batch 17168  loss=152.1644  steps/s=102.36  prediction: \"enjoyable is such a gargantuan advantage\" => \" ti  tagngg nnn        sa aaaaaanaa aaaa\"\n",
      "batch 17169  loss=148.8887  steps/s=99.74  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lon   ein\n",
      "r rre raorr\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IIIooI   tt  \"\n",
      "batch 17170  loss=191.1177  steps/s=105.70  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \":tosr rrsrt  tt n tI  tto  ttttof// tt  \"\n",
      "batch 17171  loss=141.6501  steps/s=103.40  prediction: \"ding blocks that make it up, recursively\" => \" nhyi ii i l  l      t    t    t      e \"\n",
      "batch 17172  loss=152.2031  steps/s=99.13  prediction: \" this long lost treasure of a song, damn\" => \"the fro f n no n        o t  o o        \"\n",
      "batch 17173  loss=142.9280  steps/s=104.65  prediction: \"utomatically imagine letters as colored?\" => \"  d  ououoo aaoaaaa aaa aaatl e    e    \"\n",
      "batch 17174  loss=143.4413  steps/s=101.91  prediction: \" is a no go\n",
      "\n",
      "dang that sounds like a lot\" => \"tn e ie b  n  n          o      n       \"\n",
      "batch 17175  loss=157.3476  steps/s=94.19  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"to  c e ei \n",
      "\n",
      "\n",
      "hn\n",
      "\n",
      "  tat  ntt  ottt  tt t\"\n",
      "batch 17176  loss=140.3127  steps/s=105.00  prediction: \"dual input vector or a set of input data\" => \" cgi do n iiiiinii  i                  t\"\n",
      "batch 17177  loss=137.5964  steps/s=100.39  prediction: \"ndustries\n",
      "Currently building semi public\" => \"  roeoedii iiinnirrrrrriurriiiiii iiuiii\"\n",
      "batch 17178  loss=180.1897  steps/s=91.47  prediction: \"bin_Valk ChatGPT and tons of reprompting\" => \"lndsiniisieCerCCCCrtuu  nni  ns i i  iii\"\n",
      "batch 17179  loss=165.0113  steps/s=53.13  prediction: \"y: @amix011 but you cant buy an audience\" => \": @noeriiCCCerer rt u  nnn   nn   p pppi\"\n",
      "batch 17180  loss=161.5045  steps/s=121.82  prediction: \"a exactly\n",
      "\n",
      "just mon and thurs every week\" => \"ntonaeaaae  aa t y at t n   t     u  ne \"\n",
      "batch 17182  loss=141.9552  steps/s=105.06  prediction: \"y fundamentals are hidden in plain sight\" => \" mana namaan amnaaannaaa   nn  nn     in\"\n",
      "batch 17183  loss=168.4362  steps/s=96.18  prediction: \"y childhood was nuketown 2025 and python\" => \" man ayyfnyn   n    dd en  n    22  n 2 \"\n",
      "batch 17184  loss=145.7760  steps/s=105.40  prediction: \"be allocate some time to do fun projects\" => \"u  io   n     e                   o    o\"\n",
      "batch 17185  loss=145.7222  steps/s=97.80  prediction: \"but openai is cringe so obviously sonnet\" => \"ut t   ann b   e    i i  i    oooo o oos\"\n",
      "batch 17186  loss=131.5602  steps/s=104.04  prediction: \"sire, and if it sounds good to them\n",
      "\n",
      "idk\" => \" meee n ei  t hi  i           d  o    oo\"\n",
      "batch 17187  loss=158.0688  steps/s=98.63  prediction: \" stuff! Thanks, hope yours went well man\" => \"tee  iotoofo   ff      ooo  o  o    o   \"\n",
      "batch 17188  loss=146.1952  steps/s=105.12  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"hmeed  seteter ettt.........t..ttt//////\"\n",
      "batch 17189  loss=182.6116  steps/s=105.34  prediction: \"STAND A CHAAANCE https://t.co/8TM7PIKwvr\" => \"TSHT\n",
      "ADTADAAT AA A CC CC  A     / t/t//t\"\n",
      "batch 17190  loss=168.6910  steps/s=107.37  prediction: \"ice awareness and reading ppl/situations\" => \"ne tt c caaaaaraa aaeaa  aa a a    as  a\"\n",
      "batch 17192  loss=137.9188  steps/s=102.76  prediction: \" is it some kind of info storage system?\" => \"tt t  itti si gi  i    i            o   \"\n",
      "batch 17193  loss=160.9702  steps/s=100.44  prediction: \"ng an os in zig\n",
      "\n",
      "schizo giz arc when????\" => \"g iw tt in n   in  n izzizizz zz    ig? \"\n",
      "batch 17194  loss=174.6693  steps/s=83.25  prediction: \"cicle77 welcome aboard the zig train bro\" => \"onee B  i   n 7n   iioi  iio   i   z?? ?\"\n",
      "batch 17196  loss=154.9023  steps/s=105.39  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"  s/tthit////tthhttthhhtttt////ttt////tt\"\n",
      "batch 17197  loss=250.3405  steps/s=11.33  prediction: \"reply: @5handilya See you thurs brotha ðŸ«¡\" => \"epli: :  er  W  z4OLWP\"?)(44\"?\n",
      "(vJJV3k19\"\n",
      "batch 17198  loss=152.5206  steps/s=121.56  prediction: \" sensors lol thats much less complicated\" => \"ttm sse sssss osssssss  ll   s    ss    \"\n",
      "batch 17199  loss=144.5244  steps/s=103.50  prediction: \"have become too big and are rotting away\" => \"et\n",
      " ies nemmeesmee                      \"\n",
      "batch 17201  loss=148.4948  steps/s=101.19  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"tnstme sse s        ssssst sssttttttt///\"\n",
      "batch 17202  loss=149.6992  steps/s=103.01  prediction: \"losoft and make the circle tool yourself\" => \"yckeeotsooseso s  e   e      e    e     \"\n",
      "batch 17203  loss=181.6102  steps/s=94.22  prediction: \"a @teodor_io teo mercy killed anime pfps\" => \"n(ose taeezdte too  e ceee   llll olllee\"\n",
      "batch 17204  loss=145.0574  steps/s=104.44  prediction: \" extreme levels of being acoustic though\" => \"ta t nessi ese ses ee   ee     ee ee    \"\n",
      "batch 17205  loss=152.1939  steps/s=103.75  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf arme e   n n     e ttttssttsss/ttts//\"\n",
      "batch 17206  loss=167.8606  steps/s=100.72  prediction: \"eglide theyre patronizing.\n",
      "trash company\" => \"  r t@toert rehdheehetteet trzzrzziitioi\"\n",
      "batch 17207  loss=141.1274  steps/s=103.49  prediction: \"e are, so it has a ton of ripple effects\" => \" tro  t ww  t                          f\"\n",
      "batch 17208  loss=138.5043  steps/s=102.69  prediction: \"a wave of weird suspensions going around\" => \"nme  tte se    s    e  sssssss s so ooso\"\n",
      "batch 17209  loss=147.9970  steps/s=104.02  prediction: \"on the manager/grifter/sociopath problem\" => \"u  le o o  e  tee eeer ererrraerrrrrtrrr\"\n",
      "batch 17210  loss=167.0049  steps/s=94.12  prediction: \"ntly using aws\n",
      "\n",
      "whats the pitch for gcp?\" => \" e o t lr rrerg g annntas ss ah ptthhht \"\n",
      "batch 17211  loss=180.8603  steps/s=101.48  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \"stast  tptsoo\n",
      "eessiuiiieeiieeeeeeeese'ee\"\n",
      "batch 17212  loss=141.7891  steps/s=104.12  prediction: \"our phone constantly. i had this problem\" => \"ulel  n  oon  hcooononn  n   n h        \"\n",
      "batch 17213  loss=151.2467  steps/s=103.28  prediction: \"round PNGs in powerpoint xDDDDDDDDDDDDDD\" => \"em inw ar tte6ttGJJJJJJJwJJx*****j****j*\"\n",
      "batch 17214  loss=151.3240  steps/s=104.44  prediction: \"ion==intelligence is wild rabbithole man\" => \"nn ensioniine=ei=ieniiiineeiieeiiiiiieli\"\n",
      "batch 17215  loss=184.4764  steps/s=90.95  prediction: \"eativeBuilds @yacineMTB bro lets connect\" => \" sinntCtniiine nieesiciiieeii biillll  e\"\n",
      "batch 17216  loss=182.6312  steps/s=24.02  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly: tConiiineiiieesiciiie li biill l  e\"\n",
      "batch 17217  loss=152.3466  steps/s=120.79  prediction: \"p. maybe you can figure out how to do it\" => \"l : @ooim m mym             u    o     o\"\n",
      "batch 17218  loss=154.0524  steps/s=101.80  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"tarmmmedm m  ed    ee                   \"\n",
      "batch 17219  loss=144.2393  steps/s=100.15  prediction: \"uters. i dont like those tbh. weird shit\" => \"n  i it l     et   t      t    t        \"\n",
      "batch 17220  loss=168.7081  steps/s=77.91  prediction: \"@jamstack_guru Speed of launches as well\" => \"lentel  e  c  i     eee   t    h e  s   \"\n",
      "batch 17221  loss=149.2292  steps/s=113.79  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"e t tsrna    ono oooo oooooooootoo      \"\n",
      "batch 17222  loss=151.8894  steps/s=97.19  prediction: \"AP wow\n",
      "\n",
      "i need to pivot from using print\" => \"B o 2ono w \n",
      "o\n",
      "w  o \n",
      "    o  o o   oo   i \"\n",
      "batch 17223  loss=145.7504  steps/s=104.54  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yces ltesnse ea e eeleeeeleeeellll\n",
      "\n",
      "\n",
      "\n",
      "ll\"\n",
      "batch 17224  loss=138.1131  steps/s=104.50  prediction: \"assume that had a large effect back then\" => \"ns s  s  s s   s  aaaaaaaaaa            \"\n",
      "batch 17225  loss=171.6637  steps/s=99.39  prediction: \"z and ctrl+y now https://t.co/1AII6b45hG\" => \"egg l io \n",
      "_egyn v888+z88:8+z815+16446+45\"\n",
      "batch 17226  loss=147.2598  steps/s=103.04  prediction: \"verything app\n",
      "may take like a decade tho\" => \"ere eeneetne eetee  e a a  a  a   aa a  \"\n",
      "batch 17228  loss=167.6575  steps/s=100.70  prediction: \"prob 2.5M tokens\n",
      "https://t.co/6FbmJG4MmF\" => \"let @.2  s              ttttttt/t///////\"\n",
      "batch 17229  loss=160.8191  steps/s=107.23  prediction: \"Tex prob huge dollars in anti drone bots\" => \"B Tlont @exe x xe eo     o    o    n    \"\n",
      "batch 17230  loss=157.0939  steps/s=100.60  prediction: \"new following you was the right decision\" => \" MTB o  th     l oow w  ow   i          \"\n",
      "batch 17231  loss=141.7653  steps/s=102.91  prediction: \"ed for editing videos would be so goated\" => \"p e   goeneddeieieeiidi iiddd   do  o  o\"\n",
      "batch 17232  loss=165.2509  steps/s=100.86  prediction: \"thy's highlights https://t.co/axnc6zqI4E\" => \" es  e   ean  highh hshthhtssstt/th////t\"\n",
      "batch 17233  loss=183.0960  steps/s=74.63  prediction: \"0nnnpppppppppp hilarious bait, i love it\" => \"x sy ie 0 e  'm PI/ckzK':f/T.x'I:xw?6zqI\"\n",
      "batch 17234  loss=163.4305  steps/s=117.15  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \"hris p napiggpp  pi   oo  usat a tooo c \"\n",
      "batch 17236  loss=149.5154  steps/s=102.42  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \" eso  iIsd n o onnonnottttt\n",
      "\n",
      "ttttt////t/\"\n",
      "batch 17237  loss=174.3492  steps/s=102.02  prediction: \"mk if you have any questions about usage\" => \"e t  tonmme   m  e              e   u  u\"\n",
      "batch 17238  loss=147.2427  steps/s=100.63  prediction: \"nt know if you were wrong abt everything\" => \" e ifetuu now wo     w w              e \"\n",
      "batch 17240  loss=142.7016  steps/s=105.72  prediction: \"tention/effort with no results. Not easy\" => \" r  ist teenettettttttttt t    t  o t  t\"\n",
      "batch 17242  loss=170.4016  steps/s=102.91  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"t.ct sr ////ot/tt444tttttt/tt/t:////tt//\"\n",
      "batch 17243  loss=144.3478  steps/s=105.47  prediction: \"i) youd have to store infinite bits forâ€¦\" => \"n  i di  n    o                iiiiiiiii\"\n",
      "batch 17244  loss=154.5293  steps/s=103.55  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \"  inaa aan s ss sss                     \"\n",
      "batch 17245  loss=147.1096  steps/s=104.69  prediction: \" by talking abt half done projects. BOOM\" => \"tede  ieng  n  n      a                 \"\n",
      "batch 17246  loss=137.2306  steps/s=103.96  prediction: \"e forever with a simple 5min interaction\" => \" si  oe eeefeeffe                iiiiiii\"\n",
      "batch 17247  loss=144.6816  steps/s=105.10  prediction: \"out efficiency of function approximation\" => \"ul at    ta  aaf    fffffffffcc     oiio\"\n",
      "batch 17248  loss=141.5760  steps/s=103.22  prediction: \"now unless i need to paste in huge files\" => \" t l   t    ssss  s          e        ee\"\n",
      "batch 17249  loss=135.8871  steps/s=104.79  prediction: \" yrs. ur brain will figure it out, trust\" => \"tou  it r  rrrr rrr r    ii iiii  i    u\"\n",
      "batch 17250  loss=160.4384  steps/s=99.94  prediction: \"the man just liked big words and spirals\" => \" en   n hn  mmn  aa   i              dd \"\n",
      "batch 17251  loss=162.3656  steps/s=100.04  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"epoernnsonistku ()j():/j.k:/(bkj),D3YQJ\"\"\n",
      "batch 17253  loss=191.8929  steps/s=103.82  prediction: \"he phone seems to make a huge difference\" => \"e  thtg n t e te   ee  ee    e a  eeeeee\"\n",
      "batch 17254  loss=90.1304  steps/s=104.55  prediction: \" your plans man??? thats AWESOME LETS GO\" => \"touOOOO\n",
      "w\n",
      "         ????  aa?    aEE  EES\"\n",
      "batch 17255  loss=151.5593  steps/s=104.57  prediction: \"f undulation. You probably already knowâ€¦\" => \" yotr  t nn   ou   uuoouoo ooooaaalaaaaa\"\n",
      "batch 17256  loss=143.9785  steps/s=103.47  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" an  s e eeemeeeieiiiii                 \"\n",
      "batch 17257  loss=165.9783  steps/s=104.19  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" ss fe el el            s   ttttt////c//\"\n",
      "batch 17258  loss=139.9709  steps/s=105.94  prediction: \"ly  small gif editing, it should be fine\" => \"e: @lone l l  n llll   l   i   i    i  i\"\n",
      "batch 17259  loss=164.6276  steps/s=100.29  prediction: \"kedin slop\n",
      "you vill post engagement bait\" => \"    ilo  iYin iooloo l  llllop     nenee\"\n",
      "batch 17261  loss=159.0368  steps/s=102.31  prediction: \"conclusion that the zig code IS the docs\" => \"ome 0  ln c e  to tt  tt   th   e      e\"\n",
      "batch 17262  loss=174.7098  steps/s=76.49  prediction: \"h1xabc king shit https://t.co/UJrAexS6FM\" => \"e mec mcn on  nihthhht   tt           SS\"\n",
      "batch 17263  loss=155.4472  steps/s=106.82  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \": acaa aasas ss sss                     \"\n",
      "batch 17265  loss=153.4990  steps/s=80.87  prediction: \"arcyan now you can make pokemon real too\" => \"tt s asaniy n y   yy       e    e  e  !!\"\n",
      "batch 17266  loss=150.9265  steps/s=104.57  prediction: \"ready having better days from this stuff\" => \"eply gid ct twn ::DSw2w2vv26Ubk:m/qk,z,x\"\n",
      "batch 17267  loss=163.0604  steps/s=67.36  prediction: \"@squirtle_says yacine what have you done\" => \"lueriy aaaag ay ay  eaee   ra   ha  t t \"\n",
      "batch 17268  loss=150.6293  steps/s=105.65  prediction: \" this long lost treasure of a song, damn\" => \"@o  rro   n no n        o t  o o        \"\n",
      "batch 17269  loss=199.5798  steps/s=104.94  prediction: \"2CFQvJH\n",
      "\n",
      "Worakis\n",
      "https://t.co/ep4sOiNnzk\" => \"6 f42h\n",
      "t\n",
      "\n",
      "t\n",
      "n\n",
      "s\n",
      "\n",
      "sos\n",
      "\n",
      "\n",
      "ts\n",
      "/s\n",
      "sst/tpss//t\"\n",
      "batch 17270  loss=170.2154  steps/s=96.26  prediction: \" its a sign you should make react in zig\" => \"@t o/FQAsi sAssnsssossosothoossooooa izz\"\n",
      "batch 17271  loss=170.8329  steps/s=88.01  prediction: \"builds mcdonalds just wants to grill man\" => \"etys  biii  s   so o s uas u aatt ta  ii\"\n",
      "batch 17272  loss=155.8944  steps/s=104.14  prediction: \"matching pixels\n",
      "Reward for clearing rows\" => \"entoror f m     im   i    e   a rerrrr e\"\n",
      "batch 17273  loss=151.7841  steps/s=104.14  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"/..asistsss t//st////stttsc///tt////P//P\"\n",
      "batch 17274  loss=155.3130  steps/s=101.14  prediction: \"a single man who can bench more than 400\" => \"npset_tnn n n an     n    n      nnn    \"\n",
      "batch 17275  loss=139.6108  steps/s=104.11  prediction: \"cond while avoiding exhausting the first\" => \"o/en yrt   t   e       iiiiiiiiiiiii   i\"\n",
      "batch 17276  loss=143.1653  steps/s=103.75  prediction: \"e online?\"\n",
      "uuuh, dont be? problem solved\" => \" tey nye eenneeeeee  uu   ?????  e   e  \"\n",
      "batch 17277  loss=152.9428  steps/s=102.91  prediction: \"he building -&gt; increase skillset loop\" => \"e ges   itinii iiiii i  i i    iis   sll\"\n",
      "batch 17278  loss=148.8621  steps/s=103.67  prediction: \"'ll see models get good at outputting it\" => \"slnner  en leeweeeeeeeee         oo  ott\"\n",
      "batch 17279  loss=142.0724  steps/s=102.52  prediction: \" onto it forever and never reevaluate it\" => \"tn e rnon n t no  o       n eerevveveeee\"\n",
      "batch 17280  loss=173.6522  steps/s=105.03  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"ird tou\n",
      "bo ooo   oww sht ssh tts://tts//\"\n",
      "batch 17281  loss=142.8496  steps/s=105.30  prediction: \"to the planning phase with more momentum\" => \"hpa ead     n  nn nnnnnn                \"\n",
      "batch 17282  loss=172.8992  steps/s=104.89  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"t.ct so //ttot/t//t///tttt/tt/tp////tt//\"\n",
      "batch 17283  loss=156.6502  steps/s=103.22  prediction: \"ve you ever worked for a fast food chain\" => \"eryaull e e e e  ee            o        \"\n",
      "batch 17285  loss=150.6189  steps/s=102.88  prediction: \"would check for? https://t.co/QU5rK4r0Kj\" => \"iul  y othht              ttttttttttt///\"\n",
      "batch 17286  loss=147.3215  steps/s=104.92  prediction: \"e context, like words, strengthen ideas?\" => \" soo    e t t  t    e        e tetee eee\"\n",
      "batch 17287  loss=158.9461  steps/s=101.42  prediction: \"ve not! Will look tho sounds interesting\" => \"e  ee  eer elel  l    loo oolo   o o s  \"\n",
      "batch 17288  loss=154.1353  steps/s=99.60  prediction: \"tand on the shoulders of retarded giants\" => \"hleta st i n  nt  h   ooo  o   erereerdd\"\n",
      "batch 17289  loss=147.3854  steps/s=105.31  prediction: \"e session, just wake up without an alarm\" => \" to  en e nen es  ss                    \"\n",
      "batch 17290  loss=150.5172  steps/s=103.53  prediction: \" from scratch, and a bit of transformers\" => \"tonp m p r    ccrccca a   a             \"\n",
      "batch 17291  loss=202.6036  steps/s=21.03  prediction: \"eply: @yacineMTB https://t.co/4muNOoCpeC\" => \" ly  @Lpprcrc c rca a a                r\"\n",
      "batch 17292  loss=147.2059  steps/s=108.01  prediction: \" IP, imo\n",
      "\n",
      "vpns are not security products\" => \"t  e n  ng  i in     n             r   r\"\n",
      "batch 17294  loss=142.8436  steps/s=104.66  prediction: \"xample\n",
      "Do this and then train them on it\" => \" mfto o ft em tt    t    t   t t  t t  t\"\n",
      "batch 17295  loss=152.8763  steps/s=105.79  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "Te   @.at n ,  :FDP,86:8,/vv83TN3TNQk93\"\n",
      "batch 17296  loss=172.1059  steps/s=97.72  prediction: \"n pick your own time though its flexible\" => \" whtl t on    o   ot   o t  ot  toth iit\"\n",
      "batch 17297  loss=154.8815  steps/s=100.37  prediction: \" them for yourself initially? im curious\" => \"the  m   a  m  m         eii iiiiiiiiiii\"\n",
      "batch 17298  loss=142.5885  steps/s=104.06  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sh  en e s   e         ttt ttttttt/////\"\n",
      "batch 17299  loss=149.0989  steps/s=95.84  prediction: \"t really is a long term + hard work game\" => \"hca t e ss ns  l    a l  t t  t r    r r\"\n",
      "batch 17300  loss=163.0421  steps/s=95.06  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nAi:iieAigg i i gggyo t  t ttt////// o//\"\n",
      "batch 17301  loss=151.7784  steps/s=100.55  prediction: \" a while before I add it to the site tho\" => \"tl yy y lil    l        e         t     \"\n",
      "batch 17302  loss=150.3873  steps/s=105.07  prediction: \" is \"given the context, how relevant isâ€¦\" => \"ts    k \"\"    \"                eeeeeeeee\"\n",
      "batch 17303  loss=162.3510  steps/s=102.69  prediction: \"ors let you get to the meat of it faster\" => \"n  a c  e tteeot t    ttt  t tt      t  \"\n",
      "batch 17304  loss=149.2758  steps/s=102.96  prediction: \" stamina by ~3hr https://t.co/87qPs0f0gq\" => \"@oe  at mw mmaa  a       t  tt  ttt/////\"\n",
      "batch 17305  loss=142.4122  steps/s=104.92  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  o  i  t t  t t  t tt    llle l  ll ll\"\n",
      "batch 17306  loss=175.4161  steps/s=83.84  prediction: \"yon Super hyped to see what youre cookin\" => \" u c tu ey      e   ee le  lee  l  l  e \"\n",
      "batch 17307  loss=145.5008  steps/s=105.39  prediction: \"seconds to go to jail and ruin your life\" => \" s  ae n rs t  t  o  o  o    a    o   o \"\n",
      "batch 17308  loss=169.4272  steps/s=100.02  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \" e    seet t ses sstses ttt stt ss /tt/9\"\n",
      "batch 17309  loss=151.9233  steps/s=103.81  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \" eai  t at aaaaaaaaattttttt:ttttt///////\"\n",
      "batch 17310  loss=161.6662  steps/s=101.11  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"n   om1l n     d     d        r     T TT\"\n",
      "batch 17311  loss=148.3236  steps/s=104.66  prediction: \"memory of doing a hard thing in the past\" => \"e hoehtn a  n                           \"\n",
      "batch 17312  loss=138.2939  steps/s=104.44  prediction: \"s w java and python and studying for fun\" => \" asttr ttnn n    a a    n   n      n   n\"\n",
      "batch 17313  loss=162.1791  steps/s=102.23  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "! oea e seseseeeeee ee ees sss s  s  s\"\n",
      "batch 17314  loss=148.0934  steps/s=103.08  prediction: \"my camera by accident so maybe thats why\" => \"e taa   mmee  e   a aa c   ca a  a     a\"\n",
      "batch 17315  loss=148.3483  steps/s=104.41  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e\n",
      "ebr h  er LLur.TRRR.&bR;kj7!Q===&;;;^^\"\n",
      "batch 17317  loss=152.4829  steps/s=91.73  prediction: \"izo with that soundtrack its hard not to\" => \"ne\n",
      "toteeth t h t  tt t  aat  ta         \"\n",
      "batch 17318  loss=151.1100  steps/s=105.83  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  o     b bbbbbb bb bb b            o\"\n",
      "batch 17319  loss=142.5317  steps/s=104.51  prediction: \"etter, all in your head\n",
      "Can explain more\" => \"   ve tn ett   l                   aa aa\"\n",
      "batch 17320  loss=175.9879  steps/s=99.40  prediction: \"ecursive thread\n",
      "\n",
      "https://t.co/sc1GSL4fJx\" => \" tenrr lchee rrRrehhhehe\n",
      "ett\n",
      "tt/t//t//ot\"\n",
      "batch 17321  loss=163.6187  steps/s=81.61  prediction: \"by_builds another $20 trillion to ludwig\" => \"e  brrie brebrerehhthttrrrt$/tt//lltoJJt\"\n",
      "batch 17322  loss=173.9955  steps/s=108.71  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"n  in   s  ` `h` `   tttttt/ttt/////tt//\"\n",
      "batch 17323  loss=158.2107  steps/s=100.42  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" ae oo  rdor  o    oo  ooooo  o         \"\n",
      "batch 17324  loss=155.8737  steps/s=97.42  prediction: \"is i second this https://t.co/3JrtWEMXgK\" => \"nt  ae ind nesn s  isss ttst tstttt/////\"\n",
      "batch 17325  loss=146.7655  steps/s=96.69  prediction: \"farming simulator but with a circle tool\" => \" l a  erinin iisi ttti ttttt ttt   tct  \"\n",
      "batch 17326  loss=167.9901  steps/s=29.04  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @besnnin iim  tt m ttttt ttt   cct  \"\n",
      "batch 17327  loss=156.9630  steps/s=110.02  prediction: \"ying/whatever, every monday and thursday\" => \":n /ooo/in/gingggnnereeerereeeeeeee ydd \"\n",
      "batch 17328  loss=158.0132  steps/s=103.76  prediction: \"sted this first)\n",
      "https://t.co/7AHwatHv6Y\" => \" rp  o   t s  h s stttststttstt/ttt/t//H\"\n",
      "batch 17329  loss=141.5143  steps/s=103.66  prediction: \"t on bad apple vs python library anyways\" => \"hsi tttho     a    p  pp    pp p     yyy\"\n",
      "batch 17330  loss=145.5631  steps/s=91.03  prediction: \"ttler experimentation games are the best\" => \"hpi nt  e  te e  pppttn  tt na  aaa aaaa\"\n",
      "batch 17331  loss=143.6869  steps/s=101.85  prediction: \"es courage\n",
      "lack of courage is a weakness\" => \" toetnen  eeteeaaaaa    ao            a \"\n",
      "batch 17332  loss=166.4590  steps/s=100.31  prediction: \"de!!! Huge achievement\n",
      "\n",
      "What did u study\" => \" n  onad  g!  d!!!  e e eueee eeeeee  t \"\n",
      "batch 17333  loss=166.6529  steps/s=94.41  prediction: \"builds mcdonalds just wants to grill man\" => \"et e !bb  gdc   d edeee e t  tt   tt  d \"\n",
      "batch 17334  loss=149.4272  steps/s=98.34  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"t e inain   n           tttt ttttttttttt\"\n",
      "batch 17335  loss=139.2816  steps/s=104.30  prediction: \"oast. silencio until youve made progress\" => \"ul tit    s s is tiii iiiii  i    o     \"\n",
      "batch 17336  loss=149.3255  steps/s=104.52  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \"al ld dellldllo ll o\"\"  oo   ooo oo    !\"\n",
      "batch 17337  loss=212.0178  steps/s=10.70  prediction: \"reply: @calbach_ https://t.co/Gyx4pLqxKX\" => \"e gy: @ en  tse +X'+v+(_@X7:vvQv'kvqZKXx\"\n",
      "batch 17338  loss=177.3053  steps/s=151.40  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ydelled!\" l\"l    oonnnpppppppppp  ee!! !\"\n",
      "batch 17339  loss=153.0206  steps/s=105.66  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  ao  r   e   re    e             r   re\"\n",
      "batch 17340  loss=158.7446  steps/s=100.23  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"eil y yound iysi^É´lquf/ÉªðŸ¤£.uKd#Mð—µk,'á´„â€:|Éª\"\n",
      "batch 17341  loss=184.5565  steps/s=101.47  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \"BDm-H eeRR Rs Hn s   ssssss sss s sso oo\"\n",
      "batch 17342  loss=177.2279  steps/s=99.65  prediction: \"77 oh whoa i didnt know abt tabs, thanks\" => \"  T0eae s7scc  oi     ooon   d   tn  n n\"\n",
      "batch 17343  loss=169.5434  steps/s=30.87  prediction: \"ply: @pixqc @ludwigABAP i like it\n",
      "boolin\" => \"ly: @s @eh  c  ii      oon   o   bb  nkn\"\n",
      "batch 17344  loss=144.6136  steps/s=108.29  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"tupdoni ggg giigiiiiii########e#SSSSeeee\"\n",
      "batch 17345  loss=154.7812  steps/s=97.34  prediction: \"nism oooh possibly, thats a good thought\" => \"gnto metomomoonsoooosss oo    s    a    \"\n",
      "batch 17346  loss=169.2653  steps/s=99.02  prediction: \"er CERN/physics bros you know what to do\" => \" s   @ otoo ss s si ss s ys   oo   ooo o\"\n",
      "batch 17347  loss=166.4014  steps/s=30.77  prediction: \"ply: @tszzl no :( 4o is still goated tho\" => \"ly: @motto psssN sb ssys ys   oo   ooo o\"\n",
      "batch 17348  loss=160.6673  steps/s=122.79  prediction: \"em man, I had to share, its a crazy tool\" => \" s eno ppm m              a   a a     a \"\n",
      "batch 17349  loss=151.9127  steps/s=100.04  prediction: \"r full potential https://t.co/jR1cEbfQlo\" => \"ebl   @anar  g  :(/CNbI/fIð˜‚|_fÉªI_w_fzy_,\"\n",
      "batch 17350  loss=150.7565  steps/s=104.36  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to en  s s s g     sssss               \"\n",
      "batch 17351  loss=205.6528  steps/s=21.31  prediction: \"eply: @Laz4rz glad you brought the stuff\" => \" ly: @i si      s s ssss                \"\n",
      "batch 17352  loss=157.9295  steps/s=130.80  prediction: \"is the platonic form of a platonic form?\" => \"n  t ngien  ithte  at       oo   o  oofo\"\n",
      "batch 17353  loss=230.2057  steps/s=11.80  prediction: \"reply: @yacineMTB google necessary being\" => \"eply: @r zhn pi Wh/C,b//N.y!RjRSmmwkz!!,\"\n",
      "batch 17354  loss=175.1490  steps/s=114.79  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"epl t CegcApMCð—µBð—ª^vÊœðŸ‘M/^^ÊœMLMMá´€R__wMâ€|_Ê€\"\n",
      "batch 17355  loss=186.0043  steps/s=104.38  prediction: \"h, global frames\n",
      "https://t.co/cXzSAmjmet\" => \"e    c t t  llne eletllt attts///ttt////\"\n",
      "batch 17356  loss=148.9127  steps/s=105.12  prediction: \"ot good results: https://t.co/KAmykVYFyw\" => \"nhei      o  o oo   t   tttststtttt/ttt/\"\n",
      "batch 17357  loss=170.7834  steps/s=29.80  prediction: \"ply: @Myrefly destroyer of square apples\" => \"ly: ind on o   go   tttstttststtttt/////\"\n",
      "batch 17358  loss=173.3118  steps/s=112.12  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @sran@ty cieke S?RLRL?-.g``1qkbX}M45X1T\"\n",
      "batch 17359  loss=150.6197  steps/s=109.76  prediction: \"ld almost suspect God is on their side..\" => \"y s  o u sos ss sssssss   s             \"\n",
      "batch 17360  loss=152.9460  steps/s=100.06  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng   nstteee tneettiti tttattaaa aa aa  \"\n",
      "batch 17361  loss=151.8685  steps/s=104.93  prediction: \"freedom fighters. ppl who wanted freedom\" => \" om    n ne e ee ee r    e  e       e ee\"\n",
      "batch 17362  loss=146.5195  steps/s=101.96  prediction: \"rner u can actually set them to 2x speed\" => \"eea in@anesbevtl)m2)\"gá´b^\"ð—±.bk_bx1.\"1.â™‚2\"\n",
      "batch 17363  loss=132.9965  steps/s=102.65  prediction: \"he audiobook content is better than both\" => \"e o thnthutooouooooooooooottttttttttt tt\"\n",
      "batch 17364  loss=142.2377  steps/s=103.97  prediction: \"ed for editing videos would be so goated\" => \"  ei  gdoneddeieieeii i iii d   do  o  o\"\n",
      "batch 17365  loss=147.0286  steps/s=103.13  prediction: \"isten to remixes of the ost all the time\" => \"n assa ls s s                        t  \"\n",
      "batch 17366  loss=158.4518  steps/s=99.81  prediction: \"rs? and the keychain is for a parachute?\" => \"e lol hwhal  w a@up?WzÉªðŸ˜‰'?!.Gk|y!?wká´„y,!\"\n",
      "batch 17367  loss=144.0401  steps/s=104.87  prediction: \"\n",
      "Learning is the precursor to succeeding\" => \"\n",
      "oea  cs tt twe GLIzWP$4'G/.wkD4L?Dk&.?!\"\n",
      "batch 17368  loss=144.7731  steps/s=104.61  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"n s\n",
      "ntnen inititttttttittttttttttt//////\"\n",
      "batch 17369  loss=177.3063  steps/s=92.15  prediction: \"verflow they shoulda forked this instead\" => \"eryztthiiin n athttttaaatttt/////Psskssi\"\n",
      "batch 17370  loss=177.9475  steps/s=71.70  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yleetozvhwn ehoo aa ttaakhh h6 h4iksiss \"\n",
      "batch 17371  loss=144.7401  steps/s=107.40  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"u e o o  i  i h  i  t tt ittttttt//////t\"\n",
      "batch 17372  loss=146.6295  steps/s=101.89  prediction: \"pen theatre stairs door and ruin the run\" => \"lrg @ tree tttttte t    to     rr      r\"\n",
      "batch 17373  loss=170.3097  steps/s=60.27  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"ten  on e eet  tte   o  aa r   rr   n  r\"\n",
      "batch 17374  loss=143.7453  steps/s=110.56  prediction: \" Post it in the disc it helps us all out\" => \"too lll s                               \"\n",
      "batch 17375  loss=132.8735  steps/s=103.09  prediction: \"s and had strong knowledge of the course\" => \" wh  d d d   dd         n               \"\n",
      "batch 17376  loss=144.8754  steps/s=102.52  prediction: \"the canvas match the white tetris shapes\" => \"he \n",
      "tes   n n a            h htttttttttt\"\n",
      "batch 17377  loss=144.2320  steps/s=102.85  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e   to\n",
      "etnett tthh t tt tt       t   e d\"\n",
      "batch 17378  loss=165.0804  steps/s=100.04  prediction: \"0x_0 how is crypto this good at replying\" => \"0    p snne  @ eSb@0x_pP05_0.OxxffpO5u\n",
      "P\"\n",
      "batch 17380  loss=145.7151  steps/s=103.83  prediction: \"l release results soonish #buildinpublic\" => \"ys   Wd  telele le lelesssessssss ssssis\"\n",
      "batch 17381  loss=146.8642  steps/s=101.49  prediction: \"be setting a deadline might help as well\" => \"ettii     nnn  t    a    e             e\"\n",
      "batch 17382  loss=198.5323  steps/s=21.24  prediction: \"eply: @angkul07 YOOO HAPPY 2 DECADES MAN\" => \" ly: @t    n   t    a   ei             l\"\n",
      "batch 17383  loss=158.4403  steps/s=109.80  prediction: \"ay simpler, but also much more effective\" => \"n, nt e    m  ol                       e\"\n",
      "batch 17384  loss=149.4393  steps/s=97.02  prediction: \"ake with two snakes would be interesting\" => \"ne i  e si nwwtt   w   s      e   eeeeee\"\n",
      "batch 17385  loss=162.7630  steps/s=82.18  prediction: \"Veraciety We're goin alright, we're goin\" => \"alh,r n ewetwttt   so  o o    eeeeeeteei\"\n",
      "batch 17386  loss=147.2746  steps/s=105.72  prediction: \" but vanilla obsidian seems very mid imo\" => \"tud wener uul e u laall    sa aa    ei i\"\n",
      "batch 17387  loss=149.6651  steps/s=104.95  prediction: \"o you get more data) or hit a \"dampener\"\" => \"us m  o o(o  oo                         \"\n",
      "batch 17388  loss=150.1503  steps/s=100.76  prediction: \"ding stuff for fun also helped immensely\" => \" snib  ti fif ii fff fff f  u           \"\n",
      "batch 17389  loss=157.6336  steps/s=106.16  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"ts w  t  l l li      t  t tt t//////////\"\n",
      "batch 17390  loss=148.6200  steps/s=99.29  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \" ts tts t teettettetttttttttttttt///////\"\n",
      "batch 17391  loss=158.9665  steps/s=106.14  prediction: \" making anifusion in the first place btw\" => \"@ertt e n   a nn iininnnniiniiiii       \"\n",
      "batch 17392  loss=140.2334  steps/s=104.88  prediction: \"minds me of that old gpt engineer script\" => \"ene 'he '' 'een                    ee   \"\n",
      "batch 17393  loss=150.5737  steps/s=102.81  prediction: \" make work games\n",
      "https://t.co/WVxkHR6btx\" => \"tar  aa   k kk    k    a    a  oo///oo//\"\n",
      "batch 17394  loss=221.7944  steps/s=104.50  prediction: \"ST BACKPROPAGATE https://t.co/eFVShlRgdK\" => \"TMUTTSBMOSOBOOAOPAAAAATP  AtA ////tt:///\"\n",
      "batch 17395  loss=157.7010  steps/s=100.57  prediction: \"ffects that are extremely hard to notice\" => \"     in erepte te eeetette te  ere e t  \"\n",
      "batch 17396  loss=148.2068  steps/s=105.96  prediction: \"tuff goes for you\n",
      "gpu stuff is super fun\" => \" fa   se f s   f  o  o   uuuuf uuuuu uu \"\n",
      "batch 17397  loss=141.1358  steps/s=102.44  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"neie eeee eeehgeee heeheeeeeeeee eeeeeee\"\n",
      "batch 17398  loss=139.0209  steps/s=105.23  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  oe ni n   in                        \"\n",
      "batch 17399  loss=143.6679  steps/s=97.85  prediction: \"izo with that soundtrack its hard not to\" => \"ne t thithith  t   t t ataat s  tt a   t\"\n",
      "batch 17400  loss=143.6648  steps/s=105.02  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"n  hee   a    e           tttttttttt////\"\n",
      "batch 17401  loss=143.1720  steps/s=101.96  prediction: \"ns\n",
      "you me and andrew, that was super fun\" => \"de      soss ons   e  n   n       a    a\"\n",
      "batch 17402  loss=148.3567  steps/s=103.64  prediction: \"k the same amount but on their own stuff\" => \"eyn  w n  tre   e    e      t   t  o   t\"\n",
      "batch 17403  loss=144.6759  steps/s=104.18  prediction: \"discovering new unseen fundamentals, too\" => \" n tt   d\n",
      "en   dn nnennnneenennnneennnen\"\n",
      "batch 17404  loss=160.6141  steps/s=64.59  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"t0un e ieeninnninneeeennnnenennneee sasa\"\n",
      "batch 17405  loss=144.0595  steps/s=109.04  prediction: \"stion, why do they cluster where they do\" => \" e ,  ouu t too       yy      e   eheee \"\n",
      "batch 17406  loss=148.2947  steps/s=103.61  prediction: \" monday\n",
      "\n",
      "5am (your timezone) is best imo\" => \"ton  n asss n  yyyyyy y yo oo      o  i \"\n",
      "batch 17407  loss=148.0058  steps/s=103.81  prediction: \"and notice way more over time\n",
      "I suspectâ€¦\" => \"nt ne ee r  ntt     e   e   e  e e e  e \"\n",
      "batch 17408  loss=157.4839  steps/s=105.04  prediction: \" to have it work https://t.co/c0Jpg2NlZl\" => \"th t    t            t  tttttttt////////\"\n",
      "batch 17409  loss=146.1487  steps/s=104.13  prediction: \" sessions with you and everyone else man\" => \"the t n eses ss   s s s        e eee eee\"\n",
      "batch 17410  loss=148.0859  steps/s=103.85  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" toh w n  dd dd d dd     t              \"\n",
      "batch 17411  loss=146.0686  steps/s=102.24  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"tn e n        u           tttttt/////tt/\"\n",
      "batch 17412  loss=182.1024  steps/s=99.92  prediction: \"yacineMTB Interesting can you elaborate?\" => \":ce enee f    i n tteettt ntttety y   yo\"\n",
      "batch 17413  loss=149.0909  steps/s=105.55  prediction: \" is \"given the context, how relevant isâ€¦\" => \"ts  k\"k \"     \"                eeeeeeeee\"\n",
      "batch 17414  loss=170.5470  steps/s=74.11  prediction: \"oppflightkid That could be helpful yeah!\" => \"u a\"\"\"i  et g et    tt t oo   eeeeee e  \"\n",
      "batch 17415  loss=160.9272  steps/s=61.63  prediction: \"bly same, llms are so much faster though\" => \"ee  ifiieii   ata   ll    o h    lhe eth\"\n",
      "batch 17417  loss=168.8930  steps/s=160.84  prediction: \"fsimo Lets goo!!!! Incredibly impressive\" => \" et    i  l ss  e !!!! oo!! c  r r e ihh\"\n",
      "batch 17418  loss=142.7856  steps/s=105.38  prediction: \"ing ive wanted in life lol, complete 180\" => \"ng tven ennen in i  i    i    lllll llll\"\n",
      "batch 17419  loss=145.6835  steps/s=103.93  prediction: \"n is a great way to beat some addictions\" => \"gaio  n  st tst tttt    a  t  aa   aaa  \"\n",
      "batch 17420  loss=133.2491  steps/s=105.73  prediction: \"learning is by doing stuff. For anything\" => \"y  oeng nn n  t                         \"\n",
      "batch 17421  loss=159.8827  steps/s=98.79  prediction: \"7 make money so you can make video games\" => \"7peiengengne7en  o    oo  y       aa   a\"\n",
      "batch 17422  loss=145.1884  steps/s=102.02  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"toutmamo oo    o           e  e eegggggg\"\n",
      "batch 17423  loss=140.1421  steps/s=104.93  prediction: \"ike the programming skillset example is.\" => \"ne ig  uggth  e                  lllllll\"\n",
      "batch 17424  loss=140.2979  steps/s=105.39  prediction: \"ncing is just how things go in business.\" => \"ghe  a e eneeien e i  s   i      i  n  i\"\n",
      "batch 17425  loss=145.4909  steps/s=103.52  prediction: \"o my head\n",
      "\n",
      "empirical blog posts are king\" => \"ude le l d  eeneeee  e ei il    oo    o \"\n",
      "batch 17426  loss=161.0973  steps/s=104.85  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nesooe\n",
      "\n",
      "u lll              :::///t//////\"\n",
      "batch 17427  loss=141.0989  steps/s=105.35  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"oe einenenn n nc ni      ee  t   tette t\"\n",
      "batch 17428  loss=167.6655  steps/s=66.77  prediction: \"@codyaims 113 bots liked this one so far\" => \"yrzcncntlie   e  ooo    eee  tt   ette t\"\n",
      "batch 17429  loss=155.3689  steps/s=106.07  prediction: \"is a gamechanger https://t.co/hOly3JQOWD\" => \"n     nini m  n i    ea     tthht/ttt//O\"\n",
      "batch 17430  loss=170.8539  steps/s=102.83  prediction: \"n.. animate it bros. that's 60fps almost\" => \"g rte  e6ennn t. tn... .attt ts   t ss  \"\n",
      "batch 17431  loss=174.3024  steps/s=95.54  prediction: \"ry looking thing https://t.co/aHe3A0jd1d\" => \"e 6 s@ n   a lee!0buk!b!b16k'xH60f'6:6/y\"\n",
      "batch 17432  loss=173.7891  steps/s=99.46  prediction: \"\n",
      "we'll see how things really play out ig\" => \"\n",
      "it seY_  thnwo !'bfY:/wb'Fwx'H:3f0j:f'y\"\n",
      "batch 17433  loss=139.9853  steps/s=103.74  prediction: \"have primitives if you look close enough\" => \"etr v iveviiii iviviiiiii  i   o    ooo \"\n",
      "batch 17434  loss=236.2767  steps/s=11.70  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"eply: @s nan l  8B8;k:B8b%_w8#&:%;;k##/ðŸ›‘\"\n",
      "batch 17435  loss=141.6610  steps/s=107.80  prediction: \"ys end up thinking \"nah they would justâ€¦\" => \"  ita e  a              nn  nn n        \"\n",
      "batch 17436  loss=175.5869  steps/s=60.90  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"taa        t   n   nnn  nn   h h       u\"\n",
      "batch 17437  loss=144.2789  steps/s=108.96  prediction: \" possible, at least quote and add a take\" => \"trl  t  s ss sesl l                 aaaa\"\n",
      "batch 17438  loss=138.3221  steps/s=104.14  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "t en y uley uueI@j.28&2.;v448?2IC777777\"\n",
      "batch 17439  loss=147.1299  steps/s=104.59  prediction: \"ate, but I think about this all the time\" => \"tibn   in t  tt tt    t   tttt t        \"\n",
      "batch 17441  loss=156.4184  steps/s=100.42  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \"  i on ot e   h tt tttttttttt ttt////VVV\"\n",
      "batch 17442  loss=140.7069  steps/s=104.74  prediction: \"anifold, like on the surface of a sphere\" => \"t fon bono    n    o  o                e\"\n",
      "batch 17443  loss=137.9191  steps/s=104.19  prediction: \" interesting to see what it hallucinates\" => \"tt eie   tt tttttttt t   t              \"\n",
      "batch 17444  loss=154.3966  steps/s=104.41  prediction: \" backpropagation https://t.co/1T0eIBgpz9\" => \"tetaae c l paarpaaapppatttttttotttt/////\"\n",
      "batch 17445  loss=173.6412  steps/s=103.70  prediction: \" at 5:10 or something I just go til 9:10\" => \"@n 5t utnr t   t         t      t  t   t\"\n",
      "batch 17446  loss=157.2758  steps/s=97.64  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \"   : ma oo  o goo tggg t tttttt /t//  //\"\n",
      "batch 17447  loss=170.3744  steps/s=73.43  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \" i   t  ng gon   hhththh///t/////.//xxxx\"\n",
      "batch 17448  loss=144.8932  steps/s=105.06  prediction: \"o actually understand the program better\" => \" teo sn e t      aaa aaaa   t   a     rr\"\n",
      "batch 17449  loss=140.0074  steps/s=105.91  prediction: \"d will be free. so far, thats everything\" => \" ra i tntt ene n    eee    e      r    t\"\n",
      "batch 17450  loss=151.1688  steps/s=83.12  prediction: \"nsettler cant spell family without AI :D\" => \"  n  ir nettel         ll   f     ttthht\"\n",
      "batch 17451  loss=164.5931  steps/s=62.81  prediction: \": @teodor_io funny number go up type shi\" => \" @soys wigs bctnPN@.\"\"ywk\"I,b510bb\".vY\"A\"\n",
      "batch 17452  loss=153.8183  steps/s=113.71  prediction: \" could you tell\" https://t.co/968GsOvdfW\" => \"thu   d       e,         llttttttttt////\"\n",
      "batch 17453  loss=155.2497  steps/s=46.35  prediction: \"y: @mayfer easy, just ask it what to ask\" => \": @s ue            lll  ttttttttttt/////\"\n",
      "batch 17454  loss=162.2076  steps/s=106.50  prediction: \"azy like that. Cheers my English brother\" => \"n4   e  n  ne t  t     e      e  e      \"\n",
      "batch 17455  loss=150.1149  steps/s=110.70  prediction: \" literally can\n",
      "not good for computer tho\" => \"@eacyer e lel llalllle   n    o ooo  ooo\"\n",
      "batch 17456  loss=138.1875  steps/s=104.55  prediction: \"file editing program, will show vid soon\" => \" n it  di iii itiiiii i iii  l l   i    \"\n",
      "batch 17457  loss=140.6297  steps/s=104.24  prediction: \" pool (at least once seems cold tho ngl)\" => \"tro  o  oto t ht        e e e e eee  e  \"\n",
      "batch 17458  loss=174.1329  steps/s=102.91  prediction: \"mk if you have any questions about usage\" => \"e e  c   mem  m                        u\"\n",
      "batch 17459  loss=154.9847  steps/s=103.64  prediction: \" i.e. p(death in car | not risky driver)\" => \"tf   r    d   ri  i  i                  \"\n",
      "batch 17460  loss=149.7770  steps/s=103.88  prediction: \", welcome to circle gang @ineedtolocking\" => \" whd onenoong noo c cc c  c  e e ee eeee\"\n",
      "batch 17461  loss=151.1758  steps/s=84.91  prediction: \"amebedan since ports dont allow weapons.\" => \"ne o   on e  ec c cc    oo   enoneeooone\"\n",
      "batch 17462  loss=135.7006  steps/s=104.54  prediction: \" of the tier lists of all time, for sure\" => \"@f e e     e e              ll    lol   \"\n",
      "batch 17463  loss=147.5249  steps/s=102.37  prediction: \"nal golf, really https://t.co/XJ8ijD0rEK\" => \" lie lso iennne llllllllllllltttt///////\"\n",
      "batch 17464  loss=164.4962  steps/s=99.19  prediction: \"wigABAP thats why they call him zigmobly\" => \"onl @l z il     AA tt thtt th   hh   i  \"\n",
      "batch 17466  loss=170.6533  steps/s=41.80  prediction: \"y: @tabtab0x_0 @Brycicle77 never mouse ðŸ«¡\" => \": @lgdgigaAtAP@t Bhthhth   hh   hh   ll \"\n",
      "batch 17467  loss=148.4321  steps/s=106.07  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"ts tiiitiinniiiiiiiiiiiiiiiiiii         \"\n",
      "batch 17468  loss=136.4089  steps/s=105.47  prediction: \"but for now ill run whatever ppl ask for\" => \"lt   n   n nn  n                        \"\n",
      "batch 17469  loss=275.3323  steps/s=11.04  prediction: \"reply: @gizmobly youre under 25??? muted\" => \"eply: @Aerirryee[@**É´â€œ@]JJBá´€]ðŸ‘ð—¿B$Má´€$á´„á´˜ÊœÉª\"\n",
      "batch 17470  loss=169.9273  steps/s=157.36  prediction: \"tters job was a good man\n",
      "\n",
      "God is amazing\" => \" i  t  not r  nto    a a  a    oo a     \"\n",
      "batch 17471  loss=164.6724  steps/s=103.16  prediction: \"of visualization goes away with practice\" => \"n \n",
      "the \n",
      " t f   ii  ioo  aaaaaao   aaa aa\"\n",
      "batch 17472  loss=152.6324  steps/s=47.86  prediction: \"y: @_diginova i served my time in x jail\" => \"  @ttecfi\n",
      "iof  iioaooo aaa  ai    aaa aa\"\n",
      "batch 17473  loss=141.4220  steps/s=106.31  prediction: \"h yes it is? I would literally sit on aâ€¦\" => \"ei  otthnu  t s                 lllll  l\"\n",
      "batch 17474  loss=143.6765  steps/s=103.68  prediction: \"ploring become really clear to your mind\" => \"ly: eoane   e be  eee ee leele  ll e  lr\"\n",
      "batch 17475  loss=142.9751  steps/s=104.62  prediction: \"ojang\n",
      "openai\n",
      "windows\n",
      "\n",
      "all going downhill\" => \"uuit an a\n",
      "pnnann\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nn\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "onnnoono\"\n",
      "batch 17476  loss=176.7259  steps/s=104.03  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..co  soo//o/oo/ttototttt/ttttt////t///\"\n",
      "batch 17477  loss=170.2398  steps/s=43.15  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y  @oa o/s//t/coottotttttt/t//tt////t//F\"\n",
      "batch 17478  loss=147.5327  steps/s=107.52  prediction: \"o make a significant impact on your life\" => \"ufu   t  a     n  aiiiiiiiiiiiii        \"\n",
      "batch 17479  loss=143.3643  steps/s=100.06  prediction: \" in the post, only read the abstract tho\" => \"tn   a   n    t                      ttt\"\n",
      "batch 17480  loss=163.8850  steps/s=60.81  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"tMa   n  et t n              e   et tttt\"\n",
      "batch 17481  loss=147.3563  steps/s=113.56  prediction: \"o feel cool writing in an alien language\" => \"uLertet tm ooo  o    o       n    ll nn \"\n",
      "batch 17484  loss=164.1336  steps/s=99.98  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl r flI53ZZ% t/.ÊŸBÊ€/â€**kÉ´wð—¿$**$*$*ð—ª*æˆ‘1\"\n",
      "batch 17485  loss=159.0169  steps/s=107.02  prediction: \"new following you was the right decision\" => \"  ead  enhn    n o   w  ow  o           \"\n",
      "batch 17486  loss=177.2133  steps/s=31.38  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @i e eorn n  w w w  ww              \"\n",
      "batch 17487  loss=134.4255  steps/s=111.69  prediction: \"d hire my friends to do research with me\" => \" to  tto t  m              e        r   \"\n",
      "batch 17488  loss=171.8144  steps/s=100.38  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" hott  t eedtthetth  hh  hh             \"\n",
      "batch 17489  loss=143.8920  steps/s=106.28  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"n  ae    a    e         tttttttttttttt//\"\n",
      "batch 17490  loss=180.5739  steps/s=101.01  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"tongsgbss innng  s    t  t  tt tt/t/////\"\n",
      "batch 17491  loss=147.3666  steps/s=105.22  prediction: \"it playable on lichess and post the link\" => \"n  e     elllllel llll  l  l           s\"\n",
      "batch 17492  loss=138.5149  steps/s=103.87  prediction: \"ntelligence\" + related learning concepts\" => \" l se oriinsni\"eee eeleeeee eeeleeennnen\"\n",
      "batch 17493  loss=152.6541  steps/s=104.31  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" rt tst m      \n",
      "    ttttt ttt\n",
      "ittttt/i//\"\n",
      "batch 17494  loss=177.5489  steps/s=107.05  prediction: \"builds 2012 but yet blunders mate in one\" => \"ut b  bb   b iit22 ttt ttt tt/iititiiiii\"\n",
      "batch 17496  loss=157.0885  steps/s=96.88  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"hen  it  t n   e   u b tnt /tt/////tt/tU\"\n",
      "batch 17497  loss=162.5252  steps/s=83.37  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ng  e  e   en nue eettttntnttttUUee o  =\"\n",
      "batch 17499  loss=145.4660  steps/s=105.81  prediction: \"learn thing -&gt; compress thing, repeat\" => \"yx  mneendenrn ennn  nng gtg t   g gg   \"\n",
      "batch 17500  loss=152.3643  steps/s=100.79  prediction: \" or so more to go. Lookin forward t o it\" => \"tn b !oo o oo oooooooooooooooooo   o    \"\n",
      "batch 17501  loss=142.6103  steps/s=105.65  prediction: \"sions of significantly stronger models,â€¦\" => \" o eisrotoooso nsissisiiiiisiiinn nnnn n\"\n",
      "batch 17502  loss=138.2412  steps/s=104.26  prediction: \" for most models\n",
      "https://t.co/US1Fvcybrh\" => \"toutt co mot o oomootottttstttt/t///////\"\n",
      "batch 17503  loss=146.7400  steps/s=104.58  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t eosee eee\n",
      "eeeeeraeeaaa  aa  aa  a \"\n",
      "batch 17504  loss=140.0683  steps/s=103.86  prediction: \"fficulty level, progressive overload etc\" => \" i  e eutef fl llllllelleeeeevvvvvveveve\"\n",
      "batch 17506  loss=243.5777  steps/s=101.70  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"IaGe i  SSSSRSSEG GGGGGGGN   N   ////33/\"\n",
      "batch 17507  loss=169.2355  steps/s=70.26  prediction: \" miss the good old completion model days\" => \"teH ET I I G  I S   \n",
      "   tt  //3/o//3dd37\"\n",
      "batch 17508  loss=167.1425  steps/s=105.68  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" ss fe e  el.           s  sttttt////c//\"\n",
      "batch 17509  loss=201.4736  steps/s=103.84  prediction: \" audio too\n",
      "\n",
      "I really felt that beat drop\" => \"tnd OOp pp Oi  ro  \n",
      "    o   l  t tt t a \"\n",
      "batch 17510  loss=145.3866  steps/s=102.23  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"neietee e eeehgeeehheeheeeee eee eeeeeee\"\n",
      "batch 17511  loss=165.2153  steps/s=45.81  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \"  @e thee tcthgteeheeeeeeeeeeeee eee eee\"\n",
      "batch 17512  loss=142.2544  steps/s=107.21  prediction: \"tw, my b, but ill hop in on the next one\" => \" pae ite t m  mm  t   b                 \"\n",
      "batch 17513  loss=146.8419  steps/s=100.56  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"lldn iath t h  h tttttttstttttttttt/////\"\n",
      "batch 17514  loss=156.6082  steps/s=105.96  prediction: \" tackling client projects, ThreeJS courâ€¦\" => \"th    n  biil g llll  llccccc e  eeeeeee\"\n",
      "batch 17515  loss=152.9797  steps/s=103.81  prediction: \"see this everywhere when you look for it\" => \"tta/  se  e eeee eeeeeeeeeeeeeeh  e    o\"\n",
      "batch 17516  loss=141.8572  steps/s=101.86  prediction: \"my efficiency. But overall cause its fun\" => \"a e rdtas  ee fee                       \"\n",
      "batch 17517  loss=144.2387  steps/s=103.80  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"  nton tn f finf iiiioiiiiooooroooorrror\"\n",
      "batch 17519  loss=124.6362  steps/s=30.95  prediction: \"st: caffeine is steroids but for posting\" => \"tua t   ffnnfiin iiiioii  oooorooooorror\"\n",
      "batch 17520  loss=164.7964  steps/s=142.83  prediction: \"e @sunsettler youre in the nix dimension\" => \" tooeten e ner sttrrrrir  r r     i iin \"\n",
      "batch 17521  loss=153.6352  steps/s=103.09  prediction: \"xperience that will make me live longer)\" => \"plf@f  i eeeneeeeeeeeee              l  \"\n",
      "batch 17522  loss=174.5574  steps/s=100.81  prediction: \"/t.co/i4ntqAK26E https://t.co/vE1KPjEGtm\" => \"t.ci  z /it/t//t/ttitttttt/t//tt/tEEE//E\"\n",
      "batch 17523  loss=149.4969  steps/s=103.25  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e  ttotetrhtt tthh t tt tt       t   e d\"\n",
      "batch 17524  loss=160.9838  steps/s=91.97  prediction: \" version control https://t.co/syhjjWL8M6\" => \"tee   erth t  roo    tttt   dttd\n",
      "//\n",
      "t...\"\n",
      "batch 17525  loss=153.1027  steps/s=102.16  prediction: \"TB you can just do things bro just do it\" => \"B ylu  ec non  n    tt  ttttotossjjjjjjo\"\n",
      "batch 17526  loss=144.2715  steps/s=102.91  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" te  nw  n n   w w      i i  ee eeeeeee \"\n",
      "batch 17527  loss=192.1689  steps/s=30.67  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly: @   nan  wa  w      i e eeeeeeeeeee \"\n",
      "batch 17528  loss=162.8168  steps/s=123.28  prediction: \"pounds over time vs disappears instantly\" => \"lst @tnnonenoooo oooo ev     ss  ss  sss\"\n",
      "batch 17529  loss=159.1353  steps/s=102.17  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n zi itimgtimimimiiiiiiizztzziiizi ii   \"\n",
      "batch 17530  loss=147.7971  steps/s=99.38  prediction: \" said it was his last email, he meant it\" => \"@terhrt nhn  e  h    s  aa   s      a  e\"\n",
      "batch 17531  loss=191.0918  steps/s=99.17  prediction: \"honey and yet... https://t.co/ZuyXf2t5os\" => \"ew h nnn a aai he    s  ts . h  eee et/t\"\n",
      "batch 17532  loss=146.6912  steps/s=104.03  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \" e 00do 0000   0 oo 11100000000         \"\n",
      "batch 17533  loss=218.3394  steps/s=99.99  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"P P0ii  mGGOOOOGOOOOOOOOOO O    ttoV///V\"\n",
      "batch 17534  loss=148.3404  steps/s=100.38  prediction: \"ich is a great way to find opportunities\" => \"ni ff i iiicc w                        t\"\n",
      "batch 17535  loss=221.8045  steps/s=100.04  prediction: \"UR BROBLEM GREEN https://t.co/mstazBvsCM\" => \"UN\n",
      "HAG ItAYYUUxlxU0LLMMGLEMNNRUkNz::OCM:\"\n",
      "batch 17536  loss=148.3498  steps/s=100.21  prediction: \" have to reprompt it like 1/3rd the time\" => \"tad      a    e                         \"\n",
      "batch 17537  loss=140.8350  steps/s=103.72  prediction: \"pick any domain/topic there are usuallyâ€¦\" => \"lxt  o     o  dk     i  iio i i   e   a \"\n",
      "batch 17538  loss=163.7838  steps/s=99.74  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \" u Bei  ca  o   o o  t  tt p//t/ t// rr/\"\n",
      "batch 17539  loss=164.1616  steps/s=71.80  prediction: \"minus9 This is my new favorite edm track\" => \"ece  nny    s a   t tt /tt////t/Ct333rrr\"\n",
      "batch 17540  loss=175.6901  steps/s=106.88  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OOOO\n",
      "J  an  n          d   tttttt/t/////\"\n",
      "batch 17541  loss=165.1135  steps/s=104.58  prediction: \" will lose to one w more accurate values\" => \"tha  =ii  n l nl                        \"\n",
      "batch 17542  loss=154.2080  steps/s=105.04  prediction: \"/t.co/bGCVZbuoNU https://t.co/CPaVjqg1AU\" => \"/.cb sats///tt////ttbtt/tb////ttC///Ct//\"\n",
      "batch 17543  loss=148.1209  steps/s=102.65  prediction: \"works for the first time is the most fun\" => \"hrk   en to    r  r     r    t  t   t   \"\n",
      "batch 17544  loss=138.4481  steps/s=105.29  prediction: \"endeavors im going to do til ive done it\" => \" ti      tt t ut                        \"\n",
      "batch 17545  loss=172.4064  steps/s=38.87  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"e: oten  etvR a o      o                \"\n",
      "batch 17546  loss=157.2679  steps/s=120.20  prediction: \"cking a computable number from the reals\" => \"o vt@   in   inn a          m m m  e eee\"\n",
      "batch 17547  loss=153.8550  steps/s=103.32  prediction: \" you can do the second without the first\" => \"tou e nnn      n              o      t  \"\n",
      "batch 17548  loss=153.8904  steps/s=103.84  prediction: \"learning models\n",
      "\n",
      "https://t.co/KAmykVYFyw\" => \"yvri ni nin re =neeoeeeennetetts////ttot\"\n",
      "batch 17549  loss=196.3189  steps/s=98.86  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \" =nas ss////ssssBBBBBBBBB  oooo oool   l\"\n",
      "batch 17550  loss=147.0666  steps/s=103.48  prediction: \" unsurvivable, when in fact, youd manage\" => \"tse s enens nvsevvvvv nnnnn             \"\n",
      "batch 17551  loss=154.2610  steps/s=103.38  prediction: \" apart and send each one off to an agent\" => \"tndrr a   t a  aa a  d  a  e      o     \"\n",
      "batch 17552  loss=140.6382  steps/s=102.45  prediction: \" the parameters corrrect from the start?\" => \"tha nannaaa ta taaarrreerrrrrrrrrr  rt t\"\n",
      "batch 17553  loss=174.5927  steps/s=100.13  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"yemin_A  ka ath  atta s  e e  e e se ess\"\n",
      "batch 17554  loss=163.2162  steps/s=104.35  prediction: \"yo grand children at 85. gps kids r busy\" => \" u  en1  5e   ed     d   d           d  \"\n",
      "batch 17555  loss=173.9522  steps/s=80.13  prediction: \"dwigABAP Big win, love it, great job man\" => \" i  5    An d nn     n         s    r   \"\n",
      "batch 17556  loss=145.5309  steps/s=104.63  prediction: \"re in the zone), and 2) psychologicallyâ€¦\" => \"eplfm(aarmmn =ðŸš€ ð—»â€#~Ê€Ê€á´›#X(#â€¦}â€{(ðŸ¤”ð—¯#Ê€ð—²(~%\"\n",
      "batch 17557  loss=137.7018  steps/s=101.49  prediction: \"t channel you found that effing exploded\" => \" ai   t  t nn  n                        \"\n",
      "batch 17558  loss=192.8502  steps/s=57.14  prediction: \" @pr0timr @btwphones Will post once done\" => \"tbaehenn tn   h n nnn         f    o edd\"\n",
      "batch 17559  loss=157.2244  steps/s=34.95  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"utthta eLLn n honon n    t    f    o edd\"\n",
      "batch 17560  loss=165.8233  steps/s=151.03  prediction: \"minus9 This is my new favorite edm track\" => \"ene   t  n t  ton n n    a f  o    eeedd\"\n",
      "batch 17561  loss=142.5524  steps/s=105.46  prediction: \"s are your own, and i need to prove that\" => \" tot t ee ====br                        \"\n",
      "batch 17562  loss=158.0355  steps/s=102.77  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"lte  enaspls olps sooookoooonoononnono  \"\n",
      "batch 17564  loss=163.2147  steps/s=101.30  prediction: \"s every time I'm getting comfortable lol\" => \" tp  r pr 55==ðŸš€ eee e  e  emeg  t tett  \"\n",
      "batch 17565  loss=150.6305  steps/s=104.00  prediction: \"ful if youre a complete beginner like me\" => \" l  t tei  uu f     u e    e e ee eeee e\"\n",
      "batch 17566  loss=143.0683  steps/s=104.06  prediction: \"people skills of almost everyone ive met\" => \"lr lent es eees     ll llllll     eeeeee\"\n",
      "batch 17567  loss=173.1200  steps/s=57.93  prediction: \" @sunsettler @namingbe_ damn thats crazy\" => \"tHo  e eeetss el lllll l e  o e  eee eee\"\n",
      "batch 17568  loss=179.4466  steps/s=77.28  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" @Hu@ i uVSr =BePF@&_V_FV.U_;bzPI,X:..z'\"\n",
      "batch 17569  loss=144.9610  steps/s=107.31  prediction: \"did something similar w his site i think\" => \" n   t n eni   dim  ii   mi ssii  ii  ii\"\n",
      "batch 17570  loss=171.1646  steps/s=101.31  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \"hps  is  ten sis sstsee tt   tt/////tt/t\"\n",
      "batch 17571  loss=170.2030  steps/s=103.35  prediction: \"/t.co/qfQB6dDiXN https://t.co/RAr3VgwrNk\" => \"thcgha t////t///ttttttttt:/t//tt////t///\"\n",
      "batch 17572  loss=143.5963  steps/s=104.48  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"epl egeo dl n=` N6kD(KN4AAk4b)4RA43VWbA)\"\n",
      "batch 17573  loss=264.8340  steps/s=11.09  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"eply: @o d no=ZQN6kD(INA&JkJb)JRAU3w&bA)\"\n",
      "batch 17574  loss=151.6009  steps/s=115.40  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et  tt ttt  o tooo  ooooo oosssssssuuuuu\"\n",
      "batch 17575  loss=144.8963  steps/s=103.91  prediction: \"he result, its equivalent to convolution\" => \"e  erenr  rr ra  e teeesstt te tt  oet  \"\n",
      "batch 17576  loss=173.4832  steps/s=104.04  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/.citust////Wtoottttttttt::tt/tt////t///\"\n",
      "batch 17577  loss=147.1590  steps/s=104.92  prediction: \"avorite password what would it be?? haha\" => \"neno ii      aa   a aa   wwwwwww      ??\"\n",
      "batch 17578  loss=205.2042  steps/s=87.15  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"e s i eLlT4==M1l?kS1Yf0v?Gb.E:/LSG2I3.6W\"\n",
      "batch 17579  loss=188.0794  steps/s=64.07  prediction: \" @anish0209 And now hes making it run js\" => \"tLaz iarz4 sðŸ˜­0 d d00   os   t    ee   ee\"\n",
      "batch 17580  loss=153.4807  steps/s=106.83  prediction: \" different on your OS. you can google em\" => \"tor tne  et ee n  e o         y   o   oo\"\n",
      "batch 17581  loss=143.0317  steps/s=104.29  prediction: \"of those bc there are uncountably many c\" => \"u  abn nna n  n               e     a  a\"\n",
      "batch 17582  loss=176.2549  steps/s=100.29  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" tett  t oedothettt  hh  hh             \"\n",
      "batch 17583  loss=141.7097  steps/s=104.20  prediction: \", or that would be fun/interesting to me\" => \" iuu ee  t  t                  ttttttttt\"\n",
      "batch 17584  loss=159.3997  steps/s=80.02  prediction: \"minus9 This is my new favorite edm track\" => \"an    te  ou  th         eee eteettttete\"\n",
      "batch 17585  loss=158.3003  steps/s=104.53  prediction: \"ting the entire GOL industry as we speak\" => \"hng oe em   s ttt   e e  eii  it        \"\n",
      "batch 17586  loss=172.3256  steps/s=65.65  prediction: \"@ludwigABAP ever thought of moving here?\" => \"Budin_u    nn  eee in i  it t  r  s     \"\n",
      "batch 17587  loss=185.6041  steps/s=32.46  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @gtn  nr  eee t  i  it t  s  s     \"\n",
      "batch 17588  loss=151.9341  steps/s=118.98  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lpe @e mm  n         a          a  aaaaa\"\n",
      "batch 17589  loss=163.3264  steps/s=101.48  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  n  c ceegeg eeee g   e   ttttt////t/t/\"\n",
      "batch 17590  loss=146.3506  steps/s=105.19  prediction: \"r coding lol. And some chess. Great move\" => \"epd tmfe@B@[e5@ @j;;(&;kx;qvR:Zv(Z.,AAj@\"\n",
      "batch 17591  loss=165.1394  steps/s=100.64  prediction: \"i wonder what the 3rd+ order effects are\" => \"ngo     n ine   d    d   eee  dre eeee r\"\n",
      "batch 17592  loss=151.9143  steps/s=105.45  prediction: \"strategies like this. Gets way more data\" => \"    st tt EMUEUse ts teeee es    s      \"\n",
      "batch 17593  loss=159.7394  steps/s=99.57  prediction: \" your own game engine\n",
      "challenge accepted\" => \"tou tArAeg re w  g    e ee eeegeeneeeeee\"\n",
      "batch 17594  loss=172.9179  steps/s=70.70  prediction: \"2wlearning Great stuff man, keep pushing\" => \"  wh; rwe gre n  ene  e eneeneeee eeeece\"\n",
      "batch 17595  loss=152.4025  steps/s=115.19  prediction: \"! wanted to do something a bit different\" => \"!!!! en n  n aw   t  t t  o  e    i  iin\"\n",
      "batch 17596  loss=141.0041  steps/s=103.50  prediction: \"useful directions to take the project in\" => \" efg eeefefeeeueee   e tt tttt ttttt tt \"\n",
      "batch 17597  loss=140.9659  steps/s=106.06  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taoegstnt iiniet     l  lll lll l   ee o\"\n",
      "batch 17598  loss=204.8787  steps/s=100.75  prediction: \"________11hz togglesite is super helpful\" => \"i_x____.111zizX 1@zz!bb!!p!!!!zkz!yz_j1y\"\n",
      "batch 17599  loss=157.5933  steps/s=102.62  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "sar  @  1 â€™ zIâ€™:_Y81??:??@:p=3/N3=NQk_3\"\n",
      "batch 17600  loss=154.9900  steps/s=104.85  prediction: \"ed something about that, not sure though\" => \"    e rees e heshe    t   h ttt ttttttu \"\n",
      "batch 17601  loss=134.5034  steps/s=105.49  prediction: \" to other areas where you make decisions\" => \"theeneeeette   te   eee   e e   e  e ee \"\n",
      "batch 17603  loss=151.1134  steps/s=97.07  prediction: \"nks!! feels good to be doing these again\" => \"  el ti se tees s    eoo  ooo   oe e  si\"\n",
      "batch 17604  loss=140.8188  steps/s=102.05  prediction: \"nd me tracks and ill render them for you\" => \"   eeia ne  n                           \"\n",
      "batch 17605  loss=143.5591  steps/s=105.39  prediction: \"e a data pipeline that scrapes data. Orâ€¦\" => \" ioe     aa a   aa   a   a  a e aeaaaaa \"\n",
      "batch 17606  loss=162.9231  steps/s=73.33  prediction: \"izmobly @juweeism i can try to help haha\" => \"ne  a  aaaa    eieeei    aaat ea t t  a \"\n",
      "batch 17607  loss=170.6525  steps/s=110.39  prediction: \"0x_0 how is crypto this good at replying\" => \"x3 txsc xne  Aw /j@/x_pvvx_0A!_w_\n",
      "S/b:::\"\n",
      "batch 17608  loss=143.7780  steps/s=104.43  prediction: \"If are not one, you stand out like crazy\" => \"  aee te h     ne             o         \"\n",
      "batch 17609  loss=143.6868  steps/s=105.65  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yat  m a mmellmmllllel llslll ss////t///\"\n",
      "batch 17610  loss=146.5594  steps/s=102.95  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"s  o  t ti tith rttattaaaaaaahhhahhhhhhh\"\n",
      "batch 17611  loss=175.1196  steps/s=84.56  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" mee satuttere ta aaa va aoo   ha     ll\"\n",
      "batch 17612  loss=204.7653  steps/s=100.70  prediction: \"07 .-.. ..-. --. --. --. --. --. --. --.\" => \"x_ef@    7dGn07 HCADxH!!!)__/:_kkFv3x\n",
      "F3\"\n",
      "batch 17613  loss=143.9712  steps/s=105.42  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sa  en   s e eD        ttt ttttt///////\"\n",
      "batch 17614  loss=159.9610  steps/s=100.35  prediction: \"ho. i like it much much better than rome\" => \"ene.tno i  n  en   i  i         th    tt\"\n",
      "batch 17615  loss=184.3308  steps/s=13.34  prediction: \"reply: @helscom OF NOTHING\n",
      "IN PARTICULAR\" => \"eply: @w leaeC_lFCk-T)I8GwIb-wARTbb8-\n",
      "R-\"\n",
      "batch 17616  loss=145.8986  steps/s=107.58  prediction: \"em all the cool ML stuff out there thatâ€¦\" => \"  h  ot   tht  ll    l            t  tt \"\n",
      "batch 17618  loss=149.3450  steps/s=104.17  prediction: \" but back in the day thats how I learned\" => \"tuc pacc tc t e                t        \"\n",
      "batch 17619  loss=141.1644  steps/s=105.02  prediction: \"time\n",
      "Then you stack lots of reps of this\" => \"ho   e   t mm  e ee                  o  \"\n",
      "batch 17620  loss=136.8294  steps/s=103.29  prediction: \" already doing, faster. you are the user\" => \"t ge n     dde de       e               \"\n",
      "batch 17621  loss=152.1138  steps/s=105.17  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nl t t   t  t    \"\"\"\"\"\"\"                \"\n",
      "batch 17622  loss=164.3510  steps/s=97.61  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \" s l l  l t  t  n   tttt ttttht ////oo//\"\n",
      "batch 17623  loss=186.9629  steps/s=49.35  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" 3oy ohe d\"m AB P9@-_CD@)_@I@4A@@-O:DvBâ€¦\"\n",
      "batch 17624  loss=169.7774  steps/s=60.83  prediction: \"@liljuuliet this https://t.co/MmuaB56dUP\" => \"yudputl n iAiin  ttoott/::////t////yyyyy\"\n",
      "batch 17625  loss=137.0937  steps/s=107.23  prediction: \" out why things are good. ex: i used toâ€¦\" => \"tf cg eini nt  n  i   g      g          \"\n",
      "batch 17626  loss=171.1174  steps/s=100.31  prediction: \"houlda stuck to planting apple trees smh\" => \"ing anta z   suu  s o to  ta    pe e tee\"\n",
      "batch 17627  loss=143.3958  steps/s=102.45  prediction: \"ers too! dunno\n",
      "\n",
      "love the experiment idea\" => \" s e tlelollootoooooooooo oooeeeeeeeeeee\"\n",
      "batch 17628  loss=142.7428  steps/s=105.09  prediction: \"y do what sounds more interesting to you\" => \" th uoo  b bb        o    o           t \"\n",
      "batch 17629  loss=147.0710  steps/s=105.17  prediction: \"problems im overlooking, then solve them\" => \"lob  t onn mm        ooooooi ooooe oo   \"\n",
      "batch 17630  loss=145.8180  steps/s=104.78  prediction: \"n clarity from practicing visualizationâ€¦\" => \" the s eeme n m  rrrirrrriii  iciiiiaiii\"\n",
      "batch 17631  loss=144.1653  steps/s=104.93  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng oo n  n gg nn                  uuuu  \"\n",
      "batch 17632  loss=207.5648  steps/s=100.90  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"thadcaee O %T TT OOOO OOOOO    /////////\"\n",
      "batch 17634  loss=189.1656  steps/s=97.65  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"tOddrddnEOO  OOSSS S !!!t   t    os s  o\"\n",
      "batch 17635  loss=170.0116  steps/s=105.20  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"tocl ttto///RttotttotttttSSStttt:/t/tt//\"\n",
      "batch 17637  loss=169.8453  steps/s=47.66  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \"  @coh tolttttc tttwStttt::://ttc/t/ttcc\"\n",
      "batch 17638  loss=142.7837  steps/s=114.47  prediction: \" for  processing info and learning stuff\" => \"ton  o        g                    nn nn\"\n",
      "batch 17639  loss=193.1182  steps/s=73.08  prediction: \"EsotericCofe i think i could add that in\" => \"REGI@:@eRUQâ€™nMRh1Tv999x:99u66::79E94â€™RWE\"\n",
      "batch 17640  loss=147.0673  steps/s=107.37  prediction: \"eMTB How long until dingbots can do this\" => \" TBo oricefro ng   noni niii  ndn  at  t\"\n",
      "batch 17641  loss=160.3677  steps/s=101.10  prediction: \"l do bro, never had a french beer before\" => \"ysd H  e b le  l             r e     ere\"\n",
      "batch 17642  loss=162.2606  steps/s=104.18  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e lrm  om wi kg bH,LEXACEXACTACTI,k\n",
      "XAwT\"\n",
      "batch 17643  loss=148.4315  steps/s=105.31  prediction: \"nts also on the nm level, but, 3d not 2d\" => \"  tu e tnnnnonnnn                       \"\n",
      "batch 17644  loss=150.6443  steps/s=103.62  prediction: \"ably already figured out some of my plan\" => \"nl miee oh  y lyyyyy  arr u    oe       \"\n",
      "batch 17645  loss=171.2457  steps/s=97.12  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"ebttl  D i   E,Tkk@jE.A@j:UEXz480fT480kT\"\n",
      "batch 17646  loss=146.7634  steps/s=104.39  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y m tn ingenaa Xaaaaaaaatttttttttttt////\"\n",
      "batch 17647  loss=155.1765  steps/s=103.90  prediction: \"ic cases)\n",
      "dump into claude automatically\" => \"ne e   eeeececccsssss    i       aaa aaa\"\n",
      "batch 17649  loss=179.8007  steps/s=99.48  prediction: \"its how i learned most of my tech skills\" => \"n ceomeis0  s i       e e  e ooom    tt \"\n",
      "batch 17650  loss=147.7342  steps/s=101.36  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" @oox  f f n  fn        f       fffffo  \"\n",
      "batch 17651  loss=141.2175  steps/s=104.67  prediction: \"t on bad apple vs python library anyways\" => \"hmi ttth      a    p  pp    pp       yyy\"\n",
      "batch 17652  loss=139.6297  steps/s=103.97  prediction: \"indirections/abstractions/contexts oh ok\" => \"ngo lciellliiiiiiiiiiiiissssssssstttttto\"\n",
      "batch 17653  loss=142.5160  steps/s=102.06  prediction: \"ce for an american traveling there soon?\" => \"o s it i aa  an aaaaaaaaaaaaaaa  eeeeeee\"\n",
      "batch 17655  loss=136.6316  steps/s=105.35  prediction: \" yrs. ur brain will figure it out, trust\" => \"tou  innr  rrrr rrr r    ii iiii  i    u\"\n",
      "batch 17656  loss=148.8210  steps/s=103.72  prediction: \" anyways\n",
      "might as well switch in advance\" => \"tltr teo ewe awm aaa  aa wwaw    w   a  \"\n",
      "batch 17657  loss=136.4821  steps/s=103.50  prediction: \" the time. personally i havent done this\" => \"the l t t    t t   e          l l      e\"\n",
      "batch 17660  loss=174.1844  steps/s=92.40  prediction: \"cicle77 welcome aboard the zig train bro\" => \"oni    be  ele7tellle    a a   te    i n\"\n",
      "batch 17661  loss=147.0186  steps/s=105.88  prediction: \" I could print out 1pg of relevant textâ€¦\" => \"t  a t  so r  Ir     p   o   o  o    t  \"\n",
      "batch 17662  loss=165.6512  steps/s=103.96  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"tondbt    t t ! !!!!!!!!!tttttttt/////tt\"\n",
      "batch 17663  loss=175.0776  steps/s=78.36  prediction: \"drew_pynch Sounds like a good comfy time\" => \" a  b  ne!!!t  !   tt   ttt // /ooo   GG\"\n",
      "batch 17664  loss=191.6060  steps/s=103.87  prediction: \"ez5341 Will do brother. Much appreciated\" => \"     uaite    3   i  d    ooo cc o cccmðŸ›‘\"\n",
      "batch 17665  loss=142.3996  steps/s=106.23  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"he ei e  nnen nc ii      ee  e   tette t\"\n",
      "batch 17666  loss=151.1589  steps/s=103.99  prediction: \"dable and makes debugging not so bad tbh\" => \" yg  isr a ne  aada aeee edadggn    g b \"\n",
      "batch 17667  loss=152.0727  steps/s=105.40  prediction: \"ed something about that, not sure though\" => \"   s   eesrenseshe    t   h ttt ttttttt \"\n",
      "batch 17669  loss=155.1356  steps/s=104.36  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"  t/tth h////tthtttthhttttth///ttL////tt\"\n",
      "batch 17670  loss=160.0379  steps/s=100.28  prediction: \"onna gm post w this video I guarantee it\" => \" e no eJSn  n m          s           t  \"\n",
      "batch 17671  loss=150.5274  steps/s=102.71  prediction: \"my ability to make things I want to make\" => \"a e ai ii i   i                         \"\n",
      "batch 17672  loss=144.4908  steps/s=102.19  prediction: \"his wtf\n",
      "\n",
      "ill dm u a link around the 25th\" => \"eng t  h$gt t it       l  l             \"\n",
      "batch 17673  loss=139.6962  steps/s=104.71  prediction: \"ly  small gif editing, it should be fine\" => \"y: o onn l l  n lll    l   i   i    i  i\"\n",
      "batch 17674  loss=168.7672  steps/s=69.79  prediction: \"2wlearning Great stuff man, keep pushing\" => \"3 Fo  lnl ll  n  ii    gi  i i,   e    n\"\n",
      "batch 17675  loss=164.3493  steps/s=113.18  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"eko    lahanaana  aa a  a  a y ddydddddd\"\n",
      "batch 17676  loss=169.3109  steps/s=101.42  prediction: \" a https://t.co/OmDwKUEq4p for gpt5, rip\" => \"t s   e   s  tsj t//tt////t////t pp 4ppp\"\n",
      "batch 17677  loss=147.7690  steps/s=104.91  prediction: \"tial art and he generalizes between them\" => \"hoo  or mra aa aaa   a  a  e  eeee eee e\"\n",
      "batch 17678  loss=152.4718  steps/s=99.95  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"epli   t en ly-iPj;:duv.z!!kxE:!Uz.!\n",
      "!EY\"\n",
      "batch 17679  loss=139.3889  steps/s=105.30  prediction: \"tw, my b, but ill hop in on the next one\" => \"  a  ite t m  tt  ,                     \"\n",
      "batch 17680  loss=157.9257  steps/s=45.26  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \"  @dim  m m,m tt  t                    n\"\n",
      "batch 17681  loss=150.7160  steps/s=111.30  prediction: \" it that one RL phd keeps talking abt it\" => \"ts h ht ttttt tt                        \"\n",
      "batch 17682  loss=144.2313  steps/s=100.44  prediction: \"ers had a username but idk his name name\" => \"   itt es@  r ere   e a                a\"\n",
      "batch 17683  loss=134.3507  steps/s=104.08  prediction: \"r this, practice it to get skilled at it\" => \"es ie  a et lvBn,2@.3G,GMSIFGBSIvJ/vLJJx\"\n",
      "batch 17684  loss=139.0388  steps/s=105.11  prediction: \"ty programming that in, its over, robotâ€¦\" => \"       iti rtiiii itiitiiiiii     ,    ,\"\n",
      "batch 17685  loss=168.3537  steps/s=103.59  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \" f am ke tes00ee000   000 //tt s///tt/t/\"\n",
      "batch 17686  loss=152.2626  steps/s=103.92  prediction: \"ting should not be taking customer calls\" => \" oo  i fmo cooou oo    on  nn n   t  t  \"\n",
      "batch 17687  loss=145.4242  steps/s=105.28  prediction: \"eet you can do some crazy things in life\" => \"   egnt  n    y      o                  \"\n",
      "batch 17688  loss=156.1456  steps/s=99.79  prediction: \"yeah, tunisia... carthage would be nice\"\" => \" r  une..t nti..........a a aaa       e \"\n",
      "batch 17689  loss=169.9682  steps/s=105.06  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "o h p n i  hs@l$jâ€¦3â€¦_â€¦[~`/á´¡ðŸ°()~ff##_/1%\"\n",
      "batch 17690  loss=170.6524  steps/s=67.57  prediction: \"koslib Also just saw the Eu/acc, respect\" => \"ilg  este tttce eee         ee ccccc eec\"\n",
      "batch 17691  loss=166.7913  steps/s=92.15  prediction: \"opaeoh Duuuude lets go this is awesome!!\" => \"ultr es sr   uu eet  t    g  c c  c  eet\"\n",
      "batch 17692  loss=139.6016  steps/s=106.74  prediction: \"etc\n",
      "\n",
      "i dont completely understand it tbh\" => \"  i itgetg t  e           t  tteeetdtttt\"\n",
      "batch 17693  loss=152.4352  steps/s=102.67  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne l  ll lllll         t tttttttttt//HHH\"\n",
      "batch 17694  loss=146.5014  steps/s=102.77  prediction: \"you could just make move that looks good\" => \" ug ntn hy n  y   u     u         oo  oo\"\n",
      "batch 17695  loss=143.8524  steps/s=103.88  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"t d linded dd n  d     rrrrr rrrrrr r   \"\n",
      "batch 17696  loss=178.3075  steps/s=69.94  prediction: \"jipe_dev Product\n",
      "Everything else follows\" => \"est eae   dd    rcrrc rrrrr  r    e h  h\"\n",
      "batch 17697  loss=135.0348  steps/s=105.46  prediction: \"en clusters into single tokens like this\" => \" t oeneoteetn  tt    s      n      n    \"\n",
      "batch 17698  loss=197.3289  steps/s=105.17  prediction: \"layzXD @ludwigABAP Based\n",
      "Python/zig gang\" => \"yn  eeteezeelllil   AAAAAABBPPPP PPe  ii\"\n",
      "batch 17699  loss=144.7228  steps/s=104.81  prediction: \" breadth, right now the latter is bigger\" => \"ter   ee dem  hrr   h   hh   t htttt   t\"\n",
      "batch 17700  loss=168.8816  steps/s=102.05  prediction: \"of work every monday and thursday brotha\" => \"   oo  hri  o or  or ro  or      d    dd\"\n",
      "batch 17701  loss=142.0665  steps/s=104.77  prediction: \"dering doing another one of these monday\" => \" l    s nnn n gnnnonnnnnnnonoooo        \"\n",
      "batch 17702  loss=143.9046  steps/s=105.13  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \"hit  I n e  n nn  e     e      e       a\"\n",
      "batch 17703  loss=152.6526  steps/s=101.93  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"ne I roo oo  oy   e   eeee  eeeeeeeeeeee\"\n",
      "batch 17704  loss=139.8751  steps/s=104.09  prediction: \"s but I strongly believe in it long term\" => \" an  tnn s ss g                         \"\n",
      "batch 17705  loss=144.9003  steps/s=104.25  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"the  att t     t  t tthhttttttt////ttoot\"\n",
      "batch 17706  loss=150.8110  steps/s=98.35  prediction: \"t your iq has to be under 70 or over 170\" => \" th s rsrt t  ut        e         o o7 7\"\n",
      "batch 17707  loss=168.1042  steps/s=96.44  prediction: \"e77 build things people want/ need maybe\" => \" 7ooy@c ii  777 i       e   p    eee  ee\"\n",
      "batch 17708  loss=146.0726  steps/s=105.49  prediction: \"ate, but I think about this all the time\" => \"t bn   ib t  tt tt    t   tttt t        \"\n",
      "batch 17709  loss=149.9385  steps/s=100.92  prediction: \"ot wrong, youve just seen enough 'demos'\" => \" hyi noo wonnornoooo   ou   e e  e ee  e\"\n",
      "batch 17710  loss=139.0456  steps/s=101.36  prediction: \"he actual serious dangers of being smart\" => \"ea  d n  a     a    a  aa      s      s \"\n",
      "batch 17711  loss=140.5466  steps/s=104.52  prediction: \"ng at C. The spacetine waves interact wâ€¦\" => \"g i  at pa  t  g   a         e ee eeeee \"\n",
      "batch 17712  loss=143.2508  steps/s=102.02  prediction: \"ody wake up??\n",
      "Youve killed us all skooks\" => \"nuno nennno    n ????????e      uu   k k\"\n",
      "batch 17713  loss=137.2101  steps/s=102.61  prediction: \"d segments of the godfather and seinfeld\" => \" oo ee ne nn eee e     e  e   e         \"\n",
      "batch 17714  loss=173.2906  steps/s=103.99  prediction: \"/t.co/cU8TdGmOOe https://t.co/wR9o8NrNIm\" => \"/.. s:/: :///T/tTOOOOttOOtO/t/ttt////t//\"\n",
      "batch 17715  loss=174.4223  steps/s=102.59  prediction: \"bly same, llms are so much faster though\" => \"ee   c t To  Osmmmt  t tst/ctcctcctthott\"\n",
      "batch 17716  loss=165.5190  steps/s=82.00  prediction: \"y_builds i wouldrather shootmyself loool\" => \":oi sy ebdl s   d    l sh h hhs  sto  ho\"\n",
      "batch 17717  loss=145.7997  steps/s=107.11  prediction: \"nt and then generate a new one each time\" => \"  m   n ennnendneneneee neeeneeee e eeee\"\n",
      "batch 17718  loss=166.3145  steps/s=93.84  prediction: \"ed_videos Thanks!! Yea I took like 0.3mg\" => \" _rie  d aeenn eeae   !!a !   e e    tee\"\n",
      "batch 17719  loss=144.5366  steps/s=101.95  prediction: \"ng and converged to guessing really well\" => \"  aea w nd n   en      e e ggggggg   g e\"\n",
      "batch 17721  loss=162.1844  steps/s=98.80  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BAPa D ngAA Ae@At   ees   e      o     \"\n",
      "batch 17722  loss=173.5394  steps/s=103.12  prediction: \"/t.co/zlto3SBYwd https://t.co/zSwD6up50u\" => \"/.yci\n",
      " t\n",
      "///tt///ttttttttt///tttz///tt//\"\n",
      "batch 17723  loss=139.8293  steps/s=105.58  prediction: \"your time for fruitful endeavors instead\" => \" u  o u nuon    o    ffffff fff   r   ee\"\n",
      "batch 17724  loss=181.3560  steps/s=90.37  prediction: \"ettler @gizmobly https://t.co/3UPliJk8JG\" => \" tny  suett r e iiiit u   tttee    ieeee\"\n",
      "batch 17725  loss=145.8647  steps/s=101.32  prediction: \"ait to see what you cook up with giz inc\" => \"nn oo t t t    t  t t t    oo  oo   oi i\"\n",
      "batch 17726  loss=142.5524  steps/s=104.09  prediction: \"sy but its a path to super strong skills\" => \"   y  yt  stt                          s\"\n",
      "batch 17727  loss=176.8659  steps/s=95.43  prediction: \"ez5341 based, i respect the grind brotha\" => \" yiy ua t t  a      s p    tt t   r  rrr\"\n",
      "batch 17728  loss=140.0461  steps/s=104.64  prediction: \"fficulty level, progressive overload etc\" => \" i  e a tef fl llllllllleeeeeeeeevveveve\"\n",
      "batch 17729  loss=158.7903  steps/s=103.44  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"/.. ttStS///o////////tt/tt:t//tt////t///\"\n",
      "batch 17730  loss=180.8724  steps/s=47.00  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \"  @tohSto/t/o/t tttottt/tt/t//tt////YYpY\"\n",
      "batch 17731  loss=156.4784  steps/s=107.71  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" poo  tl tt t  l    ttt tttttttttt//////\"\n",
      "batch 17732  loss=140.4194  steps/s=104.45  prediction: \"t them as axioms, and it screws you over\" => \" tn   t ettttaa  a a   a       s s      \"\n",
      "batch 17733  loss=142.6118  steps/s=103.09  prediction: \" and realized idk what it actually means\" => \"t t s    f f  n  d dddd      a     aaaaa\"\n",
      "batch 17734  loss=157.7494  steps/s=100.28  prediction: \"r him, thanks! Sounds useful potentially\" => \"ean : @Kans|á´\n",
      "_YI'ðŸ“‰_*I'$v|ð˜€Éªæˆ‘[#I}xbzI,Éª#\"\n",
      "batch 17735  loss=151.5895  steps/s=104.94  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"enlor o   i mpS EKRj@-I-MbyI-M-j-1b.I,Rv\"\n",
      "batch 17736  loss=139.5381  steps/s=103.25  prediction: \"he actual serious dangers of being smart\" => \"er  o n  a    na        a      s      s \"\n",
      "batch 17737  loss=170.6573  steps/s=97.18  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \"dtoo  on uueeeeuuueeaaes ss   tts ///aoa\"\n",
      "batch 17738  loss=146.2962  steps/s=95.74  prediction: \"TB strategy is an abstraction of tactics\" => \" e@\n",
      " @fan erteasataat  s tt atatoooottta\"\n",
      "batch 17739  loss=130.3681  steps/s=101.58  prediction: \" for  processing info and learning stuff\" => \"@on ia   o    go               nnnnnnnnn\"\n",
      "batch 17741  loss=191.8876  steps/s=91.92  prediction: \"gABAP @yacineMTB https://t.co/NDBKphrBEW\" => \" BAP  f dog ssi  nii  ns    tnnn///  nff\"\n",
      "batch 17742  loss=184.6145  steps/s=47.38  prediction: \"y: @tunahorse21 wasm babyyyyyyyyyyyyyyyy\" => \": @gudgA    sPi  nin   s   t//nn/// BBBðŸ›‘\"\n",
      "batch 17743  loss=155.3860  steps/s=106.89  prediction: \" up to do multiple iterations of editing\" => \"tste tt tt             t  t tt titiiiii \"\n",
      "batch 17744  loss=138.2341  steps/s=103.24  prediction: \" eu would lose half its talent overnight\" => \"tvee  m ele   l  l  l  l    l    l   t  \"\n",
      "batch 17745  loss=143.0132  steps/s=103.17  prediction: \"d building things with skills new to you\" => \" ao  e nn n  idiiiiiiiiiiiiiiii         \"\n",
      "batch 17746  loss=177.9657  steps/s=100.85  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tn   cint   t    t   ttt ttttttttttttt//\"\n",
      "batch 17747  loss=158.3451  steps/s=71.07  prediction: \"love spending 30mins debugging a typo :D\" => \"ynk c  n  n  60000t000ttttttttt/////  ot\"\n",
      "batch 17748  loss=142.9344  steps/s=105.56  prediction: \"be helpful, so I recommend taking a look\" => \"e  d  llbe l lb   l    e         e      \"\n",
      "batch 17749  loss=150.4733  steps/s=102.18  prediction: \"ficantly off lol https://t.co/SgwnmEaXdF\" => \" l te otsniininffffff      t ttttttt////\"\n",
      "batch 17750  loss=146.6226  steps/s=100.44  prediction: \"pany uses it often for researching stuff\" => \"lrp etonommom  oo o    o     e  r   r   \"\n",
      "batch 17751  loss=143.1975  steps/s=106.06  prediction: \"ill consider leaning into it more though\" => \"nl  d t w   w  l     iiiinniiini        \"\n",
      "batch 17752  loss=154.1591  steps/s=102.70  prediction: \"ught it was a cool idea so i speedran it\" => \"thitntooet tttit t        o             \"\n",
      "batch 17753  loss=152.4399  steps/s=96.44  prediction: \"tus Even more bc this doesnt have alaska\" => \" f gen inetet o o     e    o ss    sa   \"\n",
      "batch 17754  loss=166.4395  steps/s=98.29  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"o Ineae ennc bb    sseooesse ese e ea ee\"\n",
      "batch 17756  loss=171.0225  steps/s=103.82  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"/.cp Net:/o//NeNNttttttttt////ttc////ttc\"\n",
      "batch 17758  loss=148.1226  steps/s=102.83  prediction: \" possible, at least quote and add a take\" => \"trsn t  s ss sesl l               a aaaa\"\n",
      "batch 17759  loss=263.9288  steps/s=11.50  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"epli: @OJ49|ru/ .@jNO4TPBNN4TTX350=R::3K\"\n",
      "batch 17760  loss=145.4734  steps/s=106.99  prediction: \"out efficiency of function approximation\" => \"nlaat  a  a  aff    fffffffffcc   oooiio\"\n",
      "batch 17761  loss=147.1835  steps/s=102.26  prediction: \"g down other hard but unproductive paths\" => \" in   rn e on n  o    o   r r    ru uu u\"\n",
      "batch 17762  loss=149.0129  steps/s=103.70  prediction: \"potential. then one day, it all explodes\" => \"lst  ntla teettttttt nt               l \"\n",
      "batch 17763  loss=157.0361  steps/s=102.19  prediction: \"HY this works???\n",
      "https://t.co/QBkB6XfKTg\" => \"a ee  e        H    s??????sssstttttttt/\"\n",
      "batch 17764  loss=146.7414  steps/s=99.88  prediction: \"dness there are some juicy tactics there\" => \" a   m ssssss  sseseeee   ree  ttccccccc\"\n",
      "batch 17765  loss=154.4918  steps/s=104.49  prediction: \"ely matters when the post is this useful\" => \"  lr tiate t rttett ee    t t  s s ss ts\"\n",
      "batch 17766  loss=138.2200  steps/s=104.12  prediction: \"t, hence why lack of sleep kills my whys\" => \"  n i,  reeer r e     e        e  l  l  \"\n",
      "batch 17767  loss=262.5554  steps/s=11.46  prediction: \"reply: @kubeden Id be down in the future\" => \"epley @t n i d_uFFQQQ5Q5555''''''''m''''\"\n",
      "batch 17768  loss=135.8264  steps/s=110.65  prediction: \"assume that had a large effect back then\" => \"nk c  o  s s   s  aaaaaaaaaaa           \"\n",
      "batch 17769  loss=135.4660  steps/s=105.13  prediction: \"w the entire thing works when you use it\" => \"it  en o n  n et                        \"\n",
      "batch 17770  loss=136.0220  steps/s=105.86  prediction: \"ve to or weak squares/pieces etc etc etc\" => \"e eoecn  e   e       e  e  eeeeeeeeeeeee\"\n",
      "batch 17771  loss=149.9755  steps/s=103.44  prediction: \"stone cpus in it https://t.co/UsFG7LjU6T\" => \"  a  b vnuoonnsen  e      t t t ///t/t//\"\n",
      "batch 17772  loss=150.5590  steps/s=101.19  prediction: \"o feel cool writing in an alien language\" => \"niar  getm toog e    o       n     l nn \"\n",
      "batch 17773  loss=151.1007  steps/s=104.55  prediction: \"no work on my part? ok lol thanks @sama\"\" => \"gwr ei sn r  o wo       oo  o   ok     a\"\n",
      "batch 17775  loss=144.8988  steps/s=103.70  prediction: \"ions you choose, like oregon or whatever\" => \"nn ro nnnoetnon  ooo  ooooooooo o o  o o\"\n",
      "batch 17776  loss=167.2595  steps/s=101.41  prediction: \"w! I love hearing what works/what doesnt\" => \"i A na o l   e   e e  e e h    wwaw wwaw\"\n",
      "batch 17777  loss=137.7714  steps/s=104.02  prediction: \"able for whoever owns the algorithm/site\" => \"nt r  e te tt  e ee e  ee ee e  o oe o o\"\n",
      "batch 17778  loss=164.1096  steps/s=45.23  prediction: \"y: @astroButter @karpathy @MagnusCarlsen\" => \"  @tt eetetee er  e e  ee    e  ohhr tet\"\n",
      "batch 17779  loss=172.5730  steps/s=93.03  prediction: \": @yacineMTB jak creep is a real problem\" => \" @lub nys i nMTtxjI@b!q21pbIu@MqIBw2CpyB\"\n",
      "batch 17780  loss=146.4894  steps/s=106.76  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \" nt  eibt n n  3  nn nnnnnnnneneeeeienee\"\n",
      "batch 17781  loss=145.1376  steps/s=105.82  prediction: \"pen theatre stairs door and ruin the run\" => \"lrg @  ne\n",
      " tttttte tt   ta     rr r    r\"\n",
      "batch 17782  loss=185.1860  steps/s=76.18  prediction: \"dwigABAP @calbch https://t.co/oUmYmyc5qx\" => \"ei  totett ttaa aa  t   tt   //ot   o  u\"\n",
      "batch 17783  loss=158.5785  steps/s=103.23  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \"  a tc ceeggt eeee e   e   ttttt/t//t/t/\"\n",
      "batch 17784  loss=158.4419  steps/s=104.52  prediction: \"igABAP has selo made the circle tool yet\" => \"nAeblod@@ g g Al                 e      \"\n",
      "batch 17785  loss=156.9053  steps/s=102.82  prediction: \"ht to modify my own 1s and 0s\n",
      "What else?\" => \"e g  Rithttot ot oo o  o                \"\n",
      "batch 17786  loss=159.9794  steps/s=100.55  prediction: \"uces combined... https://t.co/TfckZAwse7\" => \"tht A  e ccl   e   ....   ........t////t\"\n",
      "batch 17787  loss=145.1757  steps/s=103.75  prediction: \" sessions with you and everyone else man\" => \"the t n eses ss   s s s        e eee e e\"\n",
      "batch 17788  loss=144.3661  steps/s=104.76  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"t iit..it ti t   ssssss s               \"\n",
      "batch 17789  loss=141.0441  steps/s=102.60  prediction: \"ols is kinda like cookie clicker but irl\" => \"rl ii t niiitinii  i  i  i  iikkkkckki i\"\n",
      "batch 17790  loss=143.2310  steps/s=100.53  prediction: \"e drew your whole country as the soyjack\" => \" sair iorn    r  r  r  ro   o  o      o \"\n",
      "batch 17791  loss=143.4447  steps/s=104.11  prediction: \"g correct (fingers crossed its this one)\" => \" toe e ert  rrrrrrerr  rrerr  ssss s ss \"\n",
      "batch 17792  loss=141.5045  steps/s=100.91  prediction: \" time on their hands + survivorship bias\" => \"th o tn     t t                     ri i\"\n",
      "batch 17793  loss=145.7744  steps/s=106.01  prediction: \"mes there are 10x rewards for doing this\" => \"ent eooemmtetee\n",
      "e  eee rreere  r   rr   \"\n",
      "batch 17794  loss=132.5868  steps/s=103.03  prediction: \" and the quote tweet is the reply itself\" => \"t   tee tttte tetteetteeteeeeee eeee  ee\"\n",
      "batch 17795  loss=157.8945  steps/s=100.99  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"neMTB e d ddd d           tt tttt/t/////\"\n",
      "batch 17796  loss=184.3593  steps/s=64.42  prediction: \"@HSVSphere im appropriating your culture\" => \"yacineMT   n  n    p  tttttt///////////t\"\n",
      "batch 17797  loss=154.9637  steps/s=120.16  prediction: \"eminglunatic we know\n",
      "\n",
      "you forgot scp btw\" => \" e    Hnneni   n a pr t\n",
      "\n",
      "nt\n",
      "\n",
      "\n",
      "yo uotoutðŸ›‘\"\n",
      "batch 17798  loss=140.2330  steps/s=105.36  prediction: \"nd mental storage/organization efficient\" => \"d  ee on t  n t tttt ttnaaaataaaaaaniaii\"\n",
      "batch 17799  loss=163.2643  steps/s=61.03  prediction: \" @sunsettler @iliekcomputers he was anon\" => \"@fo  ene entn tttt eeeaaaaaanaaaaiaiiaii\"\n",
      "batch 17800  loss=143.7241  steps/s=112.00  prediction: \"nna steal that\n",
      "\n",
      "sharpening the axe, nice\" => \"do ee  i a  naaaa aaaataaaaatnthaatne e \"\n",
      "batch 17801  loss=146.4275  steps/s=103.48  prediction: \"cise or anything else prevent this loss?\" => \"ino h arsee eeee  e      e eeeeeeeeee  e\"\n",
      "batch 17802  loss=154.9492  steps/s=104.02  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"e  h ei             o   ot            v \"\n",
      "batch 17803  loss=138.6383  steps/s=99.99  prediction: \", Heaven and hell are both one step away\" => \" ih  a  a a n  n aa ee  e  e            \"\n",
      "batch 17804  loss=146.8388  steps/s=103.60  prediction: \"n is a great way to beat some addictions\" => \"gaid nn   titst tttt    a  t  aa   aaa  \"\n",
      "batch 17805  loss=159.8797  steps/s=102.17  prediction: \"\n",
      "\n",
      "and give it slightly higher privileges\" => \"\n",
      "serizinettn s, BBvjvk13.1k13f1,vyAxA1xz\"\n",
      "batch 17806  loss=153.4592  steps/s=103.50  prediction: \"high quality patches they send to FFmpeg\" => \"en  o nn nhhth h t     h h  h t    t  t \"\n",
      "batch 17807  loss=139.8736  steps/s=105.78  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  i  n  n   in                        \"\n",
      "batch 17808  loss=161.6756  steps/s=102.41  prediction: \"enter eggman arc https://t.co/tjWAcTKg2K\" => \" t  tc c et g  eee e   t   ttttt//t/t///\"\n",
      "batch 17809  loss=149.4789  steps/s=102.51  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tin teem e t  g t   ttt  ttttt////t/////\"\n",
      "batch 17811  loss=139.5082  steps/s=103.33  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"eriilntlli               e   ii iiiiiiii\"\n",
      "batch 17812  loss=152.4700  steps/s=102.38  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et ot  ott  ootooo  ooooooos  sssuuuuuuu\"\n",
      "batch 17813  loss=184.9942  steps/s=59.41  prediction: \" @eyeofenceladus https://t.co/dIPbA0GNsC\" => \"tk4 tt ttotototoo soooos ssssuusuuuuuuuu\"\n",
      "batch 17814  loss=154.6998  steps/s=108.16  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"t er   e  ro dt         o      o       s\"\n",
      "batch 17815  loss=157.8124  steps/s=102.25  prediction: \"al route for a speedrun?\n",
      "\n",
      "maximize trust\" => \"n ist eot t t t          eee   emeeemmem\"\n",
      "batch 17816  loss=149.0862  steps/s=101.01  prediction: \" is actually happening behind the scenes\" => \"ts e  ett   a l  aaaa aaa    n   nn    e\"\n",
      "batch 17817  loss=159.4839  steps/s=103.83  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"to e oeeen)nn)n ))                    ff\"\n",
      "batch 17818  loss=156.7119  steps/s=105.34  prediction: \" is better though, I should check it out\" => \"td bemeamebee te eee  h  h   hh h       \"\n",
      "batch 17819  loss=163.1741  steps/s=103.59  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" mon V ant nt nata aa t a t   t// t//ttL\"\n",
      "batch 17820  loss=169.9107  steps/s=29.57  prediction: \"ply: @realityarb https://t.co/n5R65RI54L\" => \"ly::tRaon a    a ataattttttt//t// t//LLL\"\n",
      "batch 17821  loss=144.0462  steps/s=107.65  prediction: \" breadth, right now the latter is bigger\" => \"tet   ea mer  hrr   h   he   t htttt   t\"\n",
      "batch 17822  loss=150.1268  steps/s=98.72  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" ao   e  t n  fnn  n    ff o f  fffff   \"\n",
      "batch 17823  loss=135.5056  steps/s=103.04  prediction: \"t channel you found that effing exploded\" => \" oe   e  t nn hn                        \"\n",
      "batch 17824  loss=151.5856  steps/s=104.69  prediction: \"mentals can be really really hard to see\" => \"e tane tunss na  n aaa  aallall  alll   \"\n",
      "batch 17825  loss=152.7972  steps/s=102.97  prediction: \" tackling client projects, ThreeJS courâ€¦\" => \"thee ann bi lll lllll lcccccc   eeeeeeee\"\n",
      "batch 17826  loss=140.0324  steps/s=105.18  prediction: \"more efficient parameters in the network\" => \"eneid  sptttteteeeeeeeeeeeeeeeeeeeeeeeee\"\n",
      "batch 17827  loss=159.2338  steps/s=91.85  prediction: \"here zoomer problems, cant relate /shrug\" => \"e  oo nSe ene   ooreereeree t    etttee \"\n",
      "batch 17828  loss=150.4250  steps/s=105.04  prediction: \" make work games\n",
      "https://t.co/WVxkHR6btx\" => \"tare aa  ak kk    k    a    a  s////oo//\"\n",
      "batch 17829  loss=137.0436  steps/s=105.08  prediction: \"knesses and imbalances, using space, etc\" => \"ioo t  ingenneeneaaaaaaasassaas ssssssss\"\n",
      "batch 17830  loss=141.7789  steps/s=104.85  prediction: \"thing you do very often, like constantly\" => \" anea o si ts n   o                     \"\n",
      "batch 17831  loss=136.5548  steps/s=103.14  prediction: \"entation, the cooler everything will get\" => \"  to  m  mo tthttttooooeeeeeeeee eeeee e\"\n",
      "batch 17832  loss=169.6141  steps/s=102.85  prediction: \"uper loudly but yea. it helps w thinking\" => \"n nomenn   u   uleu eu  y y ye  et   i  \"\n",
      "batch 17833  loss=140.4801  steps/s=104.63  prediction: \"r) instead of giving you an easy way out\" => \"e e   ins iahw)aP@PG9RV9p.R3.4CG.(99)A\n",
      "(\"\n",
      "batch 17834  loss=150.6597  steps/s=105.54  prediction: \"rong tho, my confidence is only like 70%\" => \"egrtlie ese Oubevw@x.x.@IMvEv,bw(wfF70CðŸ›‘\"\n",
      "batch 17836  loss=150.4742  steps/s=102.44  prediction: \"many roadblocks trying to automate stuff\" => \"enehiecI t t   b  ooo oo    oo tttt tttt\"\n",
      "batch 17837  loss=151.9727  steps/s=103.40  prediction: \"ng to caffeine+building/studying for fun\" => \"  er c n  ngiigniii+iiniiiingnininiininn\"\n",
      "batch 17839  loss=138.4790  steps/s=103.70  prediction: \"cies and come up w better ways to learn'\" => \"hn g nniiinenenc      e                 \"\n",
      "batch 17840  loss=156.8233  steps/s=100.38  prediction: \"ock does to a mf https://t.co/xHio7RLUnV\" => \"rhwa dw w     oo          tttttt//t/////\"\n",
      "batch 17841  loss=146.7040  steps/s=104.55  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n ttt iosee eee;eeeeer eeaaa  aa   a  a \"\n",
      "batch 17843  loss=171.7053  steps/s=64.55  prediction: \"@HSVSphere im appropriating your culture\" => \"lSaheget ppreem eapprar  aaa  a    e  e \"\n",
      "batch 17844  loss=139.4356  steps/s=107.13  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tiitnitn  t        t tt tttttott-ttttot\"\n",
      "batch 17845  loss=147.0152  steps/s=104.79  prediction: \" is structured to add llms pretty easily\" => \"tndi  id in tet       d dd d   d    t   \"\n",
      "batch 17846  loss=157.7918  steps/s=100.03  prediction: \" super awesome, wait why multiple chats?\" => \"ttr   sra  sa  s a a a w ww w w w w    t\"\n",
      "batch 17847  loss=153.1967  steps/s=104.32  prediction: \"d some stuff!!!!\n",
      "https://t.co/160qafZKAk\" => \" tu  ste ss Jst!!!!!!!!!tttttts/t//tt///\"\n",
      "batch 17848  loss=148.1405  steps/s=101.23  prediction: \"ns the returns are high on more of it :)\" => \"  f   i  hsh  ttes  re      hh  rr      \"\n",
      "batch 17849  loss=150.5535  steps/s=105.28  prediction: \". we're done for https://t.co/PlqWP4Xc4H\" => \" dh ci led  d n  e           ttt///////P\"\n",
      "batch 17850  loss=155.0071  steps/s=101.59  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" i! oo nrd n  o    o   ooo o  o         \"\n",
      "batch 17851  loss=134.7527  steps/s=104.02  prediction: \" than ever to be get skilled at building\" => \"thee t ttet t  t e e e   ee      e  e   \"\n",
      "batch 17852  loss=150.3229  steps/s=104.12  prediction: \", write one sentence after another, andâ€¦\" => \" and a odd  o d ee ee  e eeeeneeeee enee\"\n",
      "batch 17853  loss=145.9778  steps/s=104.43  prediction: \" the time and not spread important info?\" => \"toe tel lll  e                    t tttt\"\n",
      "batch 17854  loss=140.3051  steps/s=104.96  prediction: \"think bc they burn through the same fuel\" => \" a   o enh     t       h hh th hh hhhh  \"\n",
      "batch 17855  loss=149.5840  steps/s=104.01  prediction: \"l, titan, stable diffusion, a few others\" => \"y  s  ns aa s asa aat  ati ai ii  i     \"\n",
      "batch 17856  loss=148.2379  steps/s=104.16  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \" tse wen e    e               //////////\"\n",
      "batch 17857  loss=142.4441  steps/s=106.67  prediction: \"so i havent used anything like webgl yet\" => \"  se  n    ss           n    n        e \"\n",
      "batch 17858  loss=158.9875  steps/s=96.84  prediction: \"i wonder what the 3rd+ order effects are\" => \"nas i   n   eeh      hh  hhr  tee eeeeer\"\n",
      "batch 17859  loss=176.9080  steps/s=30.72  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: @ ess   ee       hh  drr  dee eeeeer\"\n",
      "batch 17860  loss=150.0198  steps/s=110.06  prediction: \"cipe for less funny + fake feeling posts\" => \"hplesesose eee s    e            fffee  \"\n",
      "batch 17861  loss=179.9073  steps/s=51.02  prediction: \" @0xluffyb Deserved\n",
      "You build cool stuff\" => \"alre leeeef  e ee   e      fel    eee  s\"\n",
      "batch 17862  loss=150.4573  steps/s=111.87  prediction: \"ld almost suspect God is on their side..\" => \"y s  osu uos ss sssss s   s             \"\n",
      "batch 17863  loss=150.6568  steps/s=100.61  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"as aaela  in  dt    e       eeee eeeeeee\"\n",
      "batch 17864  loss=135.4200  steps/s=102.07  prediction: \"y noticed the last time i was there, lol\" => \":oa tneniiiitiettettttttt               \"\n",
      "batch 17865  loss=137.9613  steps/s=104.29  prediction: \"ntelligence\" + related learning concepts\" => \"   s norninsni\"eee eeleeleeleeeleeennnen\"\n",
      "batch 17866  loss=194.9547  steps/s=29.54  prediction: \"ply: @cto_junior https://t.co/BLe9cxo4Bp\" => \"ly:rep eniesnineee eeleeleeleee enennncn\"\n",
      "batch 17867  loss=154.6155  steps/s=114.62  prediction: \"ally really cool https://t.co/5a5Tuej93U\" => \"n  a  a s  lallllllllllll   t/tttt////55\"\n",
      "batch 17868  loss=138.0188  steps/s=104.35  prediction: \"but for now ill run whatever ppl ask for\" => \"ut   u   n nn  n                        \"\n",
      "batch 17869  loss=173.0538  steps/s=105.01  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"p0cc~N~N:////OeN/ttttttttt////ttc////ttc\"\n",
      "batch 17870  loss=167.1120  steps/s=103.84  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"to  ndin  tgt!!!!!!!!!!!!tttttttt /t/ttt\"\n",
      "batch 17871  loss=145.6427  steps/s=104.88  prediction: \"did it again w feedback itd be the paper\" => \" f   esd dt d i                         \"\n",
      "batch 17872  loss=146.4528  steps/s=103.67  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"ycm tneaneenaa aaaaaaaaattttttttttttt///\"\n",
      "batch 17873  loss=148.1651  steps/s=100.49  prediction: \"like there's more of a person there, idk\" => \"yteoa enelleleleee  ee    e       e   re\"\n",
      "batch 17874  loss=154.4400  steps/s=104.36  prediction: \" 10% is figuring out a fix + applying it\" => \"t0teerii  e  ig ii       ii  i       i  \"\n",
      "batch 17875  loss=139.8226  steps/s=102.74  prediction: \"have primitives if you look close enough\" => \"ere p iveviiii vvieiiiiii  i   o    o o \"\n",
      "batch 17876  loss=139.0299  steps/s=104.77  prediction: \" hold onto the ones not worth finishing.\" => \"tot on nonnooottooooooo  o oo  o      nn\"\n",
      "batch 17877  loss=193.9831  steps/s=96.79  prediction: \"____11hz @Collab_Land_ the fuck is this?\" => \"___________th_n o1   on__ ____ n   iiiii\"\n",
      "batch 17878  loss=158.6263  steps/s=104.18  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" oooa  t   te  eee eee e l ffffff f     \"\n",
      "batch 17879  loss=164.7800  steps/s=101.35  prediction: \"an!\n",
      "Gpt 4o came in clutch for the images\" => \"td n  e   n n  t  a        c  c       e \"\n",
      "batch 17880  loss=138.5085  steps/s=102.85  prediction: \"te well is a powerful powerful advantage\" => \"  tor eo   tt  e          www ww l  l la\"\n",
      "batch 17881  loss=159.3097  steps/s=101.41  prediction: \" but I learned\n",
      "\n",
      "ð—ªð—µð—¶ð—°ð—µ ð—¼ð—»ð—² ð˜€ð—¼ð˜‚ð—»ð—±ð˜€ ð—¯ð—²ð˜ð˜ð—²ð—¿?\" => \"tud I didd    I\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "ð—µð—µð—µð—µ  ð—µð—¼ð—¼ð—»ð˜€ð—¼ð—»ð—²ð—²ð—²ð—²\"\n",
      "batch 17882  loss=146.9440  steps/s=103.44  prediction: \"d take a bite of a giant company's lunch\" => \" th h s  e           a     a   a     a  \"\n",
      "batch 17883  loss=149.5493  steps/s=101.78  prediction: \"imative vehicle for personal development\" => \"nebht ee   ti  tie ee ee e e ree ele eee\"\n",
      "batch 17884  loss=157.3817  steps/s=100.79  prediction: \" seems to be doing pretty good with both\" => \"@t  eeta @e  em    e  e      o       oot\"\n",
      "batch 17885  loss=139.7902  steps/s=103.89  prediction: \" just need to learn the secret shortcuts\" => \"tud  tics sen es    e   ee    eeee  eeee\"\n",
      "batch 17886  loss=169.6266  steps/s=104.79  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"3.csNN/=:////teoNtttNttttt//t/tt.////ttc\"\n",
      "batch 17887  loss=157.9892  steps/s=103.82  prediction: \"that there were pink cubes at some point\" => \"he  l  re t te re eee    e    e e ee   t\"\n",
      "batch 17888  loss=139.8709  steps/s=104.63  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" tingie   nnne ne eeeereeeeetitittttoooo\"\n",
      "batch 17889  loss=167.6622  steps/s=103.70  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu c lc geg  g 2  22222277  ttt  tt/tt//\"\n",
      "batch 17890  loss=177.4375  steps/s=29.48  prediction: \"ply: @sunsettler https://t.co/gCxzVkTiTl\" => \"ly: @  n  g  u  222227777t tt/t/////tt//\"\n",
      "batch 17891  loss=155.3440  steps/s=121.97  prediction: \" it sucked but couldve been 1000x worse.\" => \"tn a na n n n u    u    u  u b    e 0000\"\n",
      "batch 17892  loss=136.8053  steps/s=105.10  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" tingne   enne ne eeeereeeeetititttooooo\"\n",
      "batch 17895  loss=151.2426  steps/s=103.24  prediction: \"them depth wise, learning â€œon demandâ€ (â€¦\" => \"hi nc e  em t t h    e e  ee    e    nnn\"\n",
      "batch 17896  loss=150.8010  steps/s=98.67  prediction: \"an esopost to english translator service\" => \"nd r te ee e e  e  e ee s  s sn t st  r \"\n",
      "batch 17897  loss=144.9072  steps/s=103.38  prediction: \"less advantages\n",
      "\n",
      "https://t.co/dcdLpaNQKE\" => \"y t tneaneanaa aaaaaaaaattttttttttt/////\"\n",
      "batch 17898  loss=153.7432  steps/s=103.96  prediction: \"/t.co/zlto3SBYwd https://t.co/joIt9EpsFP\" => \"/..kkh ttn//.///tttttttttt/t//tt////t//t\"\n",
      "batch 17899  loss=133.6977  steps/s=104.81  prediction: \"en get way too absorbed into one of them\" => \"      g n   t tt     ooooooooooooooooooo\"\n",
      "batch 17900  loss=150.4078  steps/s=101.00  prediction: \"there like this?\n",
      "https://t.co/ZF2p1Q4n6L\" => \"he    tt  tee   eeetttttehtttttstttt/t//\"\n",
      "batch 17901  loss=140.4180  steps/s=103.31  prediction: \"eres so little time to things in the day\" => \" s oeet eseeeet    ttt tttttttt tt      \"\n",
      "batch 17902  loss=139.6006  steps/s=103.13  prediction: \"nd mental storage/organization efficient\" => \"go e   ftt en t tttt ttaanaataaaaaaiiaii\"\n",
      "batch 17903  loss=151.4825  steps/s=99.46  prediction: \"new super super early on she was the one\" => \"g, etn i te   er    eee   er    es e   s\"\n",
      "batch 17904  loss=150.5188  steps/s=104.16  prediction: \" btw? or does onnx just work well enough\" => \"tute vntn ttt nn    o    o    w    w    \"\n",
      "batch 17905  loss=140.8041  steps/s=104.04  prediction: \" a lot of chess is abt how to think less\" => \"tnd  ot  t                              \"\n",
      "batch 17906  loss=141.3071  steps/s=99.44  prediction: \"ont need sleep, your mind goes wide open\" => \"u e ynu  ee    ne   eee  e e    e    e  \"\n",
      "batch 17908  loss=146.0862  steps/s=105.32  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t t see eee;eeeeeraeeaaa  aa  aa  a \"\n",
      "batch 17909  loss=147.3519  steps/s=99.02  prediction: \", welcome to circle gang @ineedtolocking\" => \" ao gonewwongenooee cc c  c  e   ee eeee\"\n",
      "batch 17910  loss=152.9538  steps/s=103.51  prediction: \" kache who made dingboard w llms (afaik)\" => \"tnn  iu \n",
      "nfen  a e   e  aaa       aaada \"\n",
      "batch 17912  loss=142.7110  steps/s=103.02  prediction: \"s changing how I think abt models a lot.\" => \" t   n  a n  nt  n  nh n     hn n       \"\n",
      "batch 17913  loss=142.3419  steps/s=103.89  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n se es  e    u           tttt//////////\"\n",
      "batch 17914  loss=150.3776  steps/s=104.58  prediction: \"f undulation. You probably already knowâ€¦\" => \" I tey tee    od u uooouoo ooooaaalaaaaa\"\n",
      "batch 17915  loss=158.4939  steps/s=102.10  prediction: \" thought they became ugly when they fell\" => \"the  oiodhh   ht    e e       e    e  ee\"\n",
      "batch 17916  loss=187.3120  steps/s=30.26  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly: a  dh th     tt e e       e e  ee ee\"\n",
      "batch 17917  loss=149.5560  steps/s=137.76  prediction: \"whoa thats wild, old twitter could never\" => \" a  @s nh tht    t    ll    wlt tt tt e \"\n",
      "batch 17918  loss=141.4307  steps/s=105.14  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"te   ebeg  g   e eee ooee eeeeee  o  o s\"\n",
      "batch 17919  loss=175.0717  steps/s=104.57  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"tn rt tSeaneeaaena  nnnnn tnnnst//tt////\"\n",
      "batch 17920  loss=152.3115  steps/s=102.51  prediction: \" the db he can just delete all of reddit\" => \"thezzei e  es b       e       ee    e   \"\n",
      "batch 17921  loss=137.6881  steps/s=102.68  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"un  ppp  o oo gn    eeeeee eee          \"\n",
      "batch 17922  loss=144.1603  steps/s=105.09  prediction: \"it can atrophy if you dont keep doing it\" => \"n tihot h thh at                        \"\n",
      "batch 17923  loss=143.7015  steps/s=96.04  prediction: \"ler its always an :x day here on twitter\" => \"yr ott ana ta a a    a y              ee\"\n",
      "batch 17924  loss=156.9674  steps/s=104.13  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"tsaaa al nna anammmmmmmmm  rmm          \"\n",
      "batch 17925  loss=141.8348  steps/s=99.88  prediction: \"e\n",
      "\n",
      "i need to try your coffee shop tactic\" => \" T     defeddeee                o o  o  \"\n",
      "batch 17926  loss=142.1841  steps/s=104.55  prediction: \"rger abstractions which eventually haveâ€¦\" => \"eeainnchiin  mbnDD++++P+++jCCC+RRv++j+â€¦+\"\n",
      "batch 17927  loss=149.3939  steps/s=103.07  prediction: \"ective, its significantly more efficient\" => \" h tct  ceecei eiiiiisiiiiiiiii ii iffff\"\n",
      "batch 17928  loss=209.4318  steps/s=95.85  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/.cosapip///KRccRRRiRtttZt sttt f///cect\"\n",
      "batch 17930  loss=160.1244  steps/s=103.49  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"u e  e    t                         o oo\"\n",
      "batch 17931  loss=146.7810  steps/s=102.84  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" ooe a  ggan n Kennae eeneettsst//tt/t//\"\n",
      "batch 17932  loss=172.6682  steps/s=105.48  prediction: \"t in a position to help you at all loool\" => \" c  ala n b  igotttt nt t pt ppitt oo ll\"\n",
      "batch 17933  loss=152.1660  steps/s=100.30  prediction: \" this long lost treasure of a song, damn\" => \"tho rro   n no n        o t  o o        \"\n",
      "batch 17934  loss=159.4292  steps/s=99.45  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \"gMee  f ni lll silll ssse   a  a et    n\"\n",
      "batch 17935  loss=152.7010  steps/s=104.04  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "ti  e@ addâ€™ MIâ€™:SYS6AN:666:6Z3GN36NQkB3\"\n",
      "batch 17936  loss=169.5037  steps/s=95.41  prediction: \"Koala that would be much appreciated, ty\" => \"anoKea\n",
      "asaloaag  aa   t     t    p  tcet\"\n",
      "batch 17937  loss=133.6708  steps/s=104.89  prediction: \"uscle and you get better as you practice\" => \"tt it n  t       u       te  ee     t tt\"\n",
      "batch 17938  loss=142.5318  steps/s=100.22  prediction: \" im pretty screwed when we play sap then\" => \"tt es  ee t   s   eeee e eeee ee  w   ee\"\n",
      "batch 17939  loss=197.6404  steps/s=20.54  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly: @teeete  ree eeee e eeeewee  w   ep\"\n",
      "batch 17940  loss=157.4210  steps/s=125.92  prediction: \"mewhat relevant:\n",
      "https://t.co/USV0L8wnT8\" => \"e n e g de emeeKeeeeetettttttttt:ttt////\"\n",
      "batch 17941  loss=236.4598  steps/s=11.13  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"eply: @TxnAonxY {æˆ‘$kèµ°8[^/}$mèµ°$ZxLjH$2Éªv]\"\n",
      "batch 17942  loss=148.9649  steps/s=111.78  prediction: \" anyways\n",
      "might as well switch in advance\" => \"tstr mee eme aam aaa  aa w aw    ww  a  \"\n",
      "batch 17943  loss=145.6706  steps/s=103.49  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"nh\n",
      "nin  t ininittttittitttttttttttt/////\"\n",
      "batch 17944  loss=138.4675  steps/s=104.92  prediction: \"ovate too and come up w cool experiments\" => \"uen  ne nonoo onooo         o        e e\"\n",
      "batch 17946  loss=148.7515  steps/s=105.70  prediction: \"k the same amount but on their own stuff\" => \"ewp  t s  wwe   e    e      t   t  o   t\"\n",
      "batch 17947  loss=175.2383  steps/s=101.47  prediction: \"ost valuable RESOURCE\n",
      "\n",
      "damn i need sleep\" => \"ut ootosto  suuu   a EREEEREERaa  a    n\"\n",
      "batch 17948  loss=168.1236  steps/s=104.20  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \" d reren  nen  e          t ttt/ tt/ttHt\"\n",
      "batch 17950  loss=151.9784  steps/s=106.02  prediction: \"es in claude does the page size decrease\" => \"    co  cn cn u   e   ee e e  e eee  ee \"\n",
      "batch 17951  loss=142.5501  steps/s=101.41  prediction: \"all of the theories that we could invent\" => \"tl  o   e      o o     hh    t  t     e \"\n",
      "batch 17952  loss=147.7603  steps/s=105.18  prediction: \"BOIII zombies i fucking love zombies bro\" => \" T y ntn emIIII   III       ii   oi i   \"\n",
      "batch 17953  loss=147.4964  steps/s=105.06  prediction: \" but vanilla obsidian seems very mid imo\" => \"tedepen ruuul eeu laall    ia aa    ei i\"\n",
      "batch 17954  loss=154.9876  steps/s=103.40  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" ea  a   neev  d       tttttttttttttt///\"\n",
      "batch 17955  loss=154.6243  steps/s=96.58  prediction: \"nes @micsolana same for my history class\" => \" v te t  nnc  @ a tta aa   t   tttt stss\"\n",
      "batch 17956  loss=155.7209  steps/s=105.70  prediction: \"\n",
      "\"runit\"\n",
      "\n",
      "almost never have to modify it\" => \"\n",
      "asseni51els b:e5@*$5_ÊŸ$x..å€‘$,j.D^*,Êœ$Êœ{\"\n",
      "batch 17957  loss=156.6160  steps/s=100.77  prediction: \"hdaily how does it compare to 100m leads\" => \"ei udegini olh lloooo o  oo  o    o     \"\n",
      "batch 17958  loss=152.4703  steps/s=101.23  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"@m tci iin     n  t   o    o     p   p  \"\n",
      "batch 17960  loss=157.8930  steps/s=104.59  prediction: \"st tab\n",
      "\n",
      "other than that, not much so far\" => \"  to tltn o tth t tttt tththtt  tt hh   \"\n",
      "batch 17962  loss=147.1268  steps/s=104.56  prediction: \"h4 then 2. h5 every game against him lol\" => \"e    s                    e       e   a \"\n",
      "batch 17963  loss=142.9296  steps/s=101.80  prediction: \" got chicken bone broth from walmart lol\" => \"to  uo        u              o o        \"\n",
      "batch 17964  loss=147.1079  steps/s=104.66  prediction: \" exercise days, and just work a bit less\" => \"txe eemenaene  s                        \"\n",
      "batch 17965  loss=148.7482  steps/s=105.92  prediction: \" talking drains your energy for building\" => \"toil mdod  naain  aa a nn a  rnrrnnr r r\"\n",
      "batch 17966  loss=142.8446  steps/s=100.54  prediction: \"ant believe I havent been napping before\" => \"nd  oleuue ne e ee  eeeeeee eeeen nnnnne\"\n",
      "batch 17967  loss=142.3537  steps/s=103.89  prediction: \"re for blundering bc of moving too quick\" => \"eplhn c  ns  gngYT'??MT?M???#kU333qUDxDq\"\n",
      "batch 17969  loss=137.6915  steps/s=105.43  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sim rionnneeieinniiinttntehtttc/t//tKKK\"\n",
      "batch 17970  loss=159.8526  steps/s=94.22  prediction: \"ublic Refining my problem finder program\" => \" l gnlilinnnnniiiin ininn  t pc pceeoooo\"\n",
      "batch 17971  loss=147.3814  steps/s=102.09  prediction: \"y visualize fundamentals is super useful\" => \":t  avtililliiiili l ia aaa sssss ssssss\"\n",
      "batch 17972  loss=145.3334  steps/s=105.04  prediction: \" works if you did it right, or it doesnt\" => \"that ewo w                              \"\n",
      "batch 17973  loss=139.7375  steps/s=104.64  prediction: \"nomena that i used to not have words for\" => \"gt  t n  nenn n                         \"\n",
      "batch 17974  loss=155.0862  steps/s=103.65  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \" lf  eenetatt teoo    oo   nnn o oooo oo\"\n",
      "batch 17975  loss=136.1625  steps/s=105.25  prediction: \"l tools for myself and they save me time\" => \"ype u iouulloo l      f                e\"\n",
      "batch 17977  loss=137.7901  steps/s=103.50  prediction: \"s using techniques right under our noses\" => \" put o  o  o  us n          u   uuu     \"\n",
      "batch 17978  loss=143.0584  steps/s=102.41  prediction: \"w. Might do one every mon and every tues\" => \"h o     rotrrortoo  o  o   o        eee \"\n",
      "batch 17979  loss=146.1364  steps/s=103.23  prediction: \"e code a bit in /ai-tools/multicoder lol\" => \" ia tot tot t g             iiiiiiiiiooo\"\n",
      "batch 17980  loss=143.5117  steps/s=104.71  prediction: \"per curious to see what youre working on\" => \"lrt  s  in    io                   o    \"\n",
      "batch 17981  loss=146.7257  steps/s=103.20  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"nbyegeiy yele u  ee e     o      a   a l\"\n",
      "batch 17982  loss=174.0441  steps/s=101.72  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"epl t @egeA?MsðŸš€e^Vèµ°$$MX`^.MLMMðŸ›‘$I}VM}`ðŸ°*\"\n",
      "batch 17983  loss=149.0173  steps/s=104.35  prediction: \"ot good results: https://t.co/KAmykVYFyw\" => \"n  agd       o Ro   t   ttt:::ttttt/////\"\n",
      "batch 17984  loss=146.7081  steps/s=101.22  prediction: \" to call in the big guns (aka @gizmobly)\" => \"the    aa      l                        \"\n",
      "batch 17985  loss=237.4240  steps/s=101.62  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"B @  s l O EOVPPEPPPPMP EEEEtt/t// ///co\"\n",
      "batch 17986  loss=136.7870  steps/s=104.18  prediction: \"w the entire thing works when you use it\" => \"it  en thn  n et                        \"\n",
      "batch 17987  loss=135.7933  steps/s=99.78  prediction: \"tart over again with a new hard problem?\" => \"hln  nht tt t  tt    a    a             \"\n",
      "batch 17988  loss=149.6208  steps/s=105.68  prediction: \"nt properties. huts dont have penthouses\" => \"  fh srr rtnerpeeereeett ett   t  t t   \"\n",
      "batch 17989  loss=142.7357  steps/s=101.26  prediction: \" ill dm you a link to it around the 25th\" => \"tn  leeeent   e           o    o     t  \"\n",
      "batch 17990  loss=156.2531  steps/s=100.79  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"etny:f@aenv  fge0Lfb.:/7bb;L~v;=yxv:k0~f\"\n",
      "batch 17991  loss=150.3107  steps/s=95.86  prediction: \"visualize 5d and if so whats your method\" => \"en iuouiuiu   d                       o \"\n",
      "batch 17992  loss=134.4012  steps/s=105.32  prediction: \"through hoops\n",
      "\n",
      "its harder, until its not\" => \" enveu n nthhotthohhhhhhhhhhh           \"\n",
      "batch 17993  loss=173.1477  steps/s=69.11  prediction: \"koslib Also just saw the Eu/acc, respect\" => \"  1  ot h go o oo hh  hh   h   u  ,    t\"\n",
      "batch 17994  loss=131.9041  steps/s=104.31  prediction: \"to it so you can share with your friends\" => \"  t m  tt tst s                         \"\n",
      "batch 17995  loss=136.8477  steps/s=104.74  prediction: \"en hook it up to a domain and everything\" => \" ti  c econn eo    o  o o          a a  \"\n",
      "batch 17996  loss=162.5353  steps/s=105.19  prediction: \"us @BasedBeffJezos Some are on the money\" => \"s @n ses  s eeseBBBeBeeeseeeeeee ee  e  \"\n",
      "batch 17997  loss=146.8491  steps/s=103.40  prediction: \" us safe from undetectable Dyson spheres\" => \"@s e nok@hen  nff    eeee e eeeee eeeeee\"\n",
      "batch 17998  loss=139.1593  steps/s=104.49  prediction: \"and solving their problems/communicating\" => \"nd  le ene to  n   n   r    rrroommmmmmm\"\n",
      "batch 17999  loss=142.8621  steps/s=104.33  prediction: \"nts of time. its like skilling up almost\" => \"gh o  temeten e  t     s   i  iiiii  ill\"\n",
      "batch 18000  loss=143.2756  steps/s=105.36  prediction: \"ike the programming skillset example is.\" => \"ne ouo uthth  e         g         llllll\"\n",
      "batch 18001  loss=211.3600  steps/s=104.19  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"77 B1A6AABA1A12B11B19B19A11B1BA13A3AA33A\"\n",
      "batch 18002  loss=147.1976  steps/s=105.30  prediction: \"every useful thing I do the cooler it is\" => \" e eemnem rereer eeee              o    \"\n",
      "batch 18003  loss=163.4606  steps/s=91.03  prediction: \"ler i wish it tasted as good as it looks\" => \"yae  mwne llee t  i    tt t d  d o oo  t\"\n",
      "batch 18004  loss=145.8172  steps/s=103.94  prediction: \"best way ive found so far to order tasks\" => \"e \n",
      "es ltss  tett                   o    \"\n",
      "batch 18005  loss=153.3860  steps/s=102.86  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"thee nr  t r re ro r  tt  ttt s/// s///t\"\n",
      "batch 18006  loss=145.9815  steps/s=104.21  prediction: \"llows you to better descend the gradient\" => \"yms  wolnw llol o   o   e eee ee  eeee e\"\n",
      "batch 18007  loss=138.5232  steps/s=105.07  prediction: \" sets? that sounds right but im not sure\" => \"teoostta n t ttttstsssss s t    t     t \"\n",
      "batch 18008  loss=146.4014  steps/s=103.61  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"ne iaate \n",
      "m\n",
      " \"\n",
      " mmm\n",
      "\n",
      "\n",
      "\n",
      "mm\n",
      "\n",
      "\n",
      "\n",
      "&;;;&t;ttt;\"\n",
      "batch 18009  loss=149.5121  steps/s=104.34  prediction: \"nt properties. huts dont have penthouses\" => \"  nh ter ennerpeeereeett ett   t  t t   \"\n",
      "batch 18010  loss=140.3361  steps/s=102.98  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot ini nt  n n              tt////////K\"\n",
      "batch 18011  loss=152.1394  steps/s=104.40  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"ne t  ene      k              tt////////\"\n",
      "batch 18012  loss=157.8271  steps/s=104.10  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nl t    l  t  el tttttttitttttt////t////\"\n",
      "batch 18013  loss=140.6984  steps/s=104.31  prediction: \"ns you get the yellow letters on lichess\" => \"  tttni mot   t    e   e   ee eeeee   e \"\n",
      "batch 18014  loss=139.9486  steps/s=105.29  prediction: \"your post and are considering followingâ€¦\" => \" u  e p  pp             o    o   ooooooi\"\n",
      "batch 18015  loss=138.0674  steps/s=102.35  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"e iilnwl i               e   ii iiiiiiii\"\n",
      "batch 18016  loss=138.6997  steps/s=105.51  prediction: \"code base to get something super complex\" => \"om   ts  eett  e e   e  e      e     e  \"\n",
      "batch 18017  loss=158.8899  steps/s=82.14  prediction: \"kul07 Time limits on tasks are so useful\" => \"e g eba   t   te e  otttts s ses    oee \"\n",
      "batch 18018  loss=153.4833  steps/s=104.56  prediction: \"gpu accelerated cnn from scratch?\n",
      "\n",
      "based\" => \" tla t   cecee c c cceecccn   rc cccc sc\"\n",
      "batch 18020  loss=146.2318  steps/s=101.79  prediction: \"interested to hear how well it works our\" => \"n  n  n n d d ete eee  e     e          \"\n",
      "batch 18021  loss=157.1626  steps/s=101.39  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"ts a  r  a l iil     t    tt tttt/t/////\"\n",
      "batch 18022  loss=144.0409  steps/s=104.60  prediction: \"sy but its a path to super strong skills\" => \"  fn  fte sst s                        s\"\n",
      "batch 18023  loss=275.8786  steps/s=11.18  prediction: \"reply: @calbch its the year of the monad\" => \"eple: @@eneeedBd15B831TBJðŸ‘€ð—°TO$$JbJðŸ¤£PbROP\"\n",
      "batch 18024  loss=143.9979  steps/s=111.44  prediction: \"ably do this for all future projects tbh\" => \"nl   t i ol b l   l   l           r   rr\"\n",
      "batch 18025  loss=168.6860  steps/s=105.05  prediction: \"fyb is there a SWE equivalent of goggins\" => \" b    @h is   fP      e  e e e eee  eet \"\n",
      "batch 18027  loss=152.7116  steps/s=99.48  prediction: \"iplying cells literally changed my life.\" => \"nli P  s lle llli lllelllllll  lle ggll \"\n",
      "batch 18028  loss=137.0439  steps/s=101.63  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \"et  ua   f n                            \"\n",
      "batch 18029  loss=187.8493  steps/s=97.41  prediction: \"lEnergel @jesx64 https://t.co/gyECG7Z8jB\" => \"yf  tennngeneeeEee eeee ettttts ttt  ///\"\n",
      "batch 18030  loss=181.5240  steps/s=103.46  prediction: \"per useful to me https://t.co/VnY1ZfLz4C\" => \"lrh  s  s s suu u           tttt////////\"\n",
      "batch 18031  loss=170.5203  steps/s=104.22  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"ttdtIlGE=ðŸ¤£/QG///tQQthtZZZtZ Z  t axxxx x\"\n",
      "batch 18032  loss=170.9078  steps/s=104.18  prediction: \"ich in this case, is their lack of speed\" => \"nh hessees s    h     s  i i  ii        \"\n",
      "batch 18033  loss=151.8168  steps/s=104.47  prediction: \" of how i debug and catch inefficiencies\" => \"tf e iormpo  a           a   a i   icfic\"\n",
      "batch 18034  loss=148.3275  steps/s=103.24  prediction: \"al, one of the most cracked players ever\" => \"tl  oo i o ee o o o    o       e     eee\"\n",
      "batch 18035  loss=135.6965  steps/s=99.86  prediction: \"hine now. unless anybody has a spare one\" => \"en   tn emnn n  nnnnnnnn          aa aa \"\n",
      "batch 18037  loss=151.3225  steps/s=103.13  prediction: \"eed you on my side during the robot wars\" => \" d o stongnoe  n o   nd n n     d    o  \"\n",
      "batch 18039  loss=143.5270  steps/s=104.43  prediction: \" regarded so take that w a grain of salt\" => \"tede  un m\n",
      "mmdd      ee aa   aa   aaa  a\"\n",
      "batch 18040  loss=155.3357  steps/s=103.88  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"ht e s t etene ?  e  e\n",
      "\n",
      "eee::::ttt:///tt\"\n",
      "batch 18041  loss=149.0634  steps/s=103.27  prediction: \"ns the returns are high on more of it :)\" => \"g  \n",
      "  li   h  ttes  re      re  rr      \"\n",
      "batch 18042  loss=143.4539  steps/s=99.21  prediction: \"on your end, try a different browser idk\" => \"n  o gh y h n e               r   err rr\"\n",
      "batch 18043  loss=167.6309  steps/s=103.02  prediction: \"sist... bait.... https://t.co/FSXHHMMAoD\" => \" osl  .  s..............tt ttttttt//////\"\n",
      "batch 18044  loss=166.6081  steps/s=101.01  prediction: \"the man just liked big words and spirals\" => \"he  risrst  mtt  ta   i       d    ssdd \"\n",
      "batch 18045  loss=163.0275  steps/s=102.73  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n  &ittimitimitimiiiiiiizztzziiiiiii i  \"\n",
      "batch 18046  loss=144.4842  steps/s=104.98  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  n     t t tt t  t tt    llll l  ll ll\"\n",
      "batch 18047  loss=156.4309  steps/s=104.18  prediction: \"ard players used to get through the race\" => \"ttto   e e arareree  e   e       t   t  \"\n",
      "batch 18048  loss=146.0634  steps/s=104.61  prediction: \" not super out of alignment with reality\" => \"topai\n",
      "n s nnn uu  o     o   e  n        \"\n",
      "batch 18049  loss=138.8731  steps/s=102.91  prediction: \"egression to my past actions and results\" => \" rine r emers  s    s          s  s   s \"\n",
      "batch 18050  loss=147.4507  steps/s=103.94  prediction: \" random nonsense will escape containment\" => \"tetesmeeemm sm nsssnnnnsn es ese eeennen\"\n",
      "batch 18051  loss=137.4341  steps/s=102.80  prediction: \"companies spend that much cash on a logo\" => \"hmre ave e es enee                      \"\n",
      "batch 18052  loss=157.3545  steps/s=103.47  prediction: \"coordinates are busted\n",
      "just buy new ones\" => \"hmdMn  tarannarr aa e a eeete e   e e te\"\n",
      "batch 18053  loss=164.0759  steps/s=97.70  prediction: \"7 make money so you can make video games\" => \"7Boic y c7me7er  ooee oo  s u u    e   e\"\n",
      "batch 18054  loss=183.6092  steps/s=99.11  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"ng y Braie ene   e ee o  e t tt////o/oo4\"\n",
      "batch 18055  loss=146.8729  steps/s=103.91  prediction: \"d take a bite of a giant company's lunch\" => \" th ans zet                a     aaa a  \"\n",
      "batch 18056  loss=144.1981  steps/s=104.29  prediction: \"xample\n",
      "Do this and then train them on it\" => \" c dof@ tt em tt    t    t   t t  t t  t\"\n",
      "batch 18057  loss=162.5370  steps/s=105.88  prediction: \"he making a dingboard clone or something\" => \"e i ggg\n",
      " mg iigi    g    a       oo   oo\"\n",
      "batch 18058  loss=182.0352  steps/s=101.30  prediction: \"u helped a ton, hugely appreciate it bro\" => \"tti__ ___   1e n     e     ee a   eee ir\"\n",
      "batch 18059  loss=149.0335  steps/s=104.57  prediction: \"ow readable zig is. how does ak do it???\" => \"u \n",
      "  so ee    hr      e                 \"\n",
      "batch 18060  loss=145.6065  steps/s=104.27  prediction: \"s, have back and forth conversations etc\" => \"  pr  r  c ec g a   a                 o \"\n",
      "batch 18061  loss=200.6385  steps/s=103.77  prediction: \"needed to dl this. meme delivery service\" => \"  lo  n  y    ed       e d  deeeeeeeeeee\"\n",
      "batch 18062  loss=151.0724  steps/s=104.11  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"torewe t t eo   e e  eeet\n",
      "\n",
      "ttttt////s///\"\n",
      "batch 18063  loss=183.7339  steps/s=84.50  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"ybw  ood tlee  ooo\n",
      "\n",
      "\n",
      "\n",
      "t/t\n",
      "hth/ttst5sssst\"\n",
      "batch 18064  loss=147.4254  steps/s=104.47  prediction: \"wn for a game sometime? also lichess ftw\" => \"i t @twy o             m    e         ss\"\n",
      "batch 18065  loss=147.7094  steps/s=104.92  prediction: \"ful if youre a complete beginner like me\" => \" l e eian Ts  f     u e    e e ee eeee e\"\n",
      "batch 18066  loss=151.5658  steps/s=103.13  prediction: \"amount of time, or did you just enjoy it\" => \"ne i al iman   n  o o      oo       ujj \"\n",
      "batch 18067  loss=144.7164  steps/s=102.44  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"nd na   inain  iiiiiiiii       /////////\"\n",
      "batch 18068  loss=150.2704  steps/s=98.59  prediction: \"high quality patches they send to FFmpeg\" => \"enk   nn nhhtht  h       h    t    t  e \"\n",
      "batch 18069  loss=136.1513  steps/s=104.22  prediction: \"onna think in terms of utility and price\" => \"ne nm ent nnnnhnnnnn                    \"\n",
      "batch 18070  loss=164.3856  steps/s=98.97  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" i te a en  n n   oo  o ttttttttt/////VV\"\n",
      "batch 18071  loss=133.8528  steps/s=104.63  prediction: \"t you are in fact to blame for everyoneâ€¦\" => \"hat a i  a                           e e\"\n",
      "batch 18072  loss=148.1516  steps/s=103.26  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"epl yg,  ne  @w á´‡*@OX^|$**O*^á´¡á´›O{*ðŸ˜á´€â€ðŸ˜‰^Êœ\"\n",
      "batch 18073  loss=145.0081  steps/s=102.52  prediction: \"s\n",
      "\n",
      "so super frictionless, it sounds like\" => \" \n",
      "e nrt  ueu sr sssrrsssrss ss isssss ss\"\n",
      "batch 18074  loss=159.1568  steps/s=99.50  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \"hnn sti eee nnene\n",
      "n\n",
      "eeeesen eoennn ne t \"\n",
      "batch 18075  loss=135.4045  steps/s=104.42  prediction: \"i is a smart idea to pitch to the public\" => \"niese pe  o                 t   tt tttt \"\n",
      "batch 18076  loss=160.8307  steps/s=101.32  prediction: \"\n",
      "\n",
      "and give it slightly higher privileges\" => \"\n",
      "Ye imin wtn o  7,vjvkbJ70k0b70Av0MxFTxM\"\n",
      "batch 18077  loss=155.7376  steps/s=105.13  prediction: \"re you need to make a sphere version now\" => \"epln n@Hvr t oa gyvjv?bJ?/k/b??kv?MxFTxM\"\n",
      "batch 18078  loss=152.2152  steps/s=102.09  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \" nw n s c   s ss                        \"\n",
      "batch 18079  loss=162.9574  steps/s=100.84  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"t s  cetten  to    ttsttttstttttt///////\"\n",
      "batch 18080  loss=170.5360  steps/s=97.03  prediction: \"zing\n",
      "Pronounced \"geeyou eye\" or \"gooey\"?\" => \"enz y a  rte    (zvA+(P((:(Pv.w,kKbR,TI(\"\n",
      "batch 18081  loss=150.8694  steps/s=97.30  prediction: \"o church\n",
      "Starting everything immediately\" => \"nmaioieonoon cncc    rr rttt  ereee eeee\"\n",
      "batch 18083  loss=176.0507  steps/s=89.78  prediction: \"CMEGroup ayy lets go more monopoly money\" => \"oey   wnlne slneMEGw+QGQQ,\"IQ.w,kSb7,\"?8\"\n",
      "batch 18084  loss=185.5624  steps/s=103.68  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"nn ae\n",
      "   \n",
      "    i nn   7    7  d7  s ss s \"\n",
      "batch 18085  loss=139.6004  steps/s=103.55  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"es   n n t nn  t                        \"\n",
      "batch 18086  loss=135.1451  steps/s=100.59  prediction: \"ood at noticing things, would be so kino\" => \"nl u  g tot go ttttttiigiiii      o     \"\n",
      "batch 18087  loss=139.4384  steps/s=104.97  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tl   a lellllll laa   aaaaaa      a     \"\n",
      "batch 18088  loss=194.6122  steps/s=97.39  prediction: \" QUICK delete this before sphere sees it\" => \"tbarlll r le  o ett tteet t  re  ee ree \"\n",
      "batch 18089  loss=159.5122  steps/s=104.02  prediction: \" wonder what else you could fast-preview\" => \"taea nai ed d e  ae   e    e         e  \"\n",
      "batch 18090  loss=137.8383  steps/s=105.27  prediction: \"n, tons of alpha is already in your head\" => \"g  tentitttto at o  a a   aaaa          \"\n",
      "batch 18091  loss=142.5805  steps/s=98.16  prediction: \"es courage\n",
      "lack of courage is a weakness\" => \"  insnene eesaeaaaaa    ca            a \"\n",
      "batch 18092  loss=155.6807  steps/s=100.59  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"eml c  p  eb Mh ==y(/:=jv==,===j=-=,6vU=\"\n",
      "batch 18093  loss=148.8316  steps/s=104.15  prediction: \"r the years for business/building things\" => \"e(t  benn  h c n(\"j)=w=((.=v==\"=/=)(=w=j\"\n",
      "batch 18094  loss=147.2440  steps/s=100.18  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" nl lol teii ic c cccccc cccc//cc///////\"\n",
      "batch 18095  loss=142.8906  steps/s=102.13  prediction: \"is barely trying https://t.co/sGecxUWdrr\" => \"n     i  l    e         t ttttttttt/////\"\n",
      "batch 18096  loss=137.9966  steps/s=104.34  prediction: \"sfully improved their lives tremendously\" => \" obtl t ef se  seeeeeee ee eeee eeeeee e\"\n",
      "batch 18097  loss=143.8153  steps/s=102.98  prediction: \"r taxes and splitting with other winners\" => \"eti  tehdg  eley~$á´„*)ð—±,É´`##'(Ê€#ÊœIxL~ðŸ«¡I((\"\n",
      "batch 18099  loss=146.6564  steps/s=103.73  prediction: \"n i did eventually. hypothesis confirmed\" => \" ma rn maedn  nnd   nn    eee   e    iei\"\n",
      "batch 18100  loss=150.0764  steps/s=103.72  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame  oa   c  c                         \"\n",
      "batch 18101  loss=144.3069  steps/s=103.30  prediction: \"icians and is a net negative for society\" => \"n  ae imc tti nta         a             \"\n",
      "batch 18102  loss=145.9038  steps/s=103.66  prediction: \" have to reprompt it like 1/3rd the time\" => \"tad aa        e                         \"\n",
      "batch 18103  loss=150.2530  steps/s=103.48  prediction: \"e algo show you a lot more similar posts\" => \" aa  kth   t    oo  o     o    o    o   \"\n",
      "batch 18104  loss=229.2214  steps/s=98.39  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OAOITt  O\n",
      "NOTN O ON  TNOI        / /tt//\"\n",
      "batch 18105  loss=158.9228  steps/s=104.86  prediction: \"tem\n",
      "- SPHERE GUN https://t.co/tqM3ZpJCkN\" => \" x  id eae tnseEEEEEEEE t tt///t//////t/\"\n",
      "batch 18106  loss=210.8399  steps/s=102.18  prediction: \"indie game of the year im calling it now\" => \"ng a din nn     i  e     e e     ai  m i\"\n",
      "batch 18107  loss=161.0925  steps/s=105.00  prediction: \" blindfolded and win 80% (timur garayev)\" => \"tlc a  l  lel delddd ddd d d   i   i   i\"\n",
      "batch 18108  loss=163.5010  steps/s=96.14  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"he a  l nre ee d d    i    o   o   rrr e\"\n",
      "batch 18109  loss=146.9165  steps/s=103.75  prediction: \" what to do next. i want to do my own tâ€¦\" => \"toa  a    d    o  o        t t       o  \"\n",
      "batch 18110  loss=182.3324  steps/s=99.98  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"t r  eo da`` ``` `   nttttt tttttt/ttt//\"\n",
      "batch 18112  loss=158.4520  steps/s=102.83  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"@ake m  mmm m m     l       oo  o   o o \"\n",
      "batch 18113  loss=148.1763  steps/s=100.91  prediction: \"high quality patches they send to FFmpeg\" => \"en  t nn nhhth h hh    hhh    h    t  e \"\n",
      "batch 18114  loss=164.7647  steps/s=73.58  prediction: \"@nlevnet that's a great thought actually\" => \"led      hht   aata  t hte t he    F FF \"\n",
      "batch 18115  loss=145.9087  steps/s=114.82  prediction: \"oo much context switching to twitter idk\" => \"ud:inee        ctt   ttctttttt tttttttit\"\n",
      "batch 18116  loss=142.2213  steps/s=103.31  prediction: \" the dark forest from the 3 body problem\" => \"@hent meete ee e e r  f r           o o \"\n",
      "batch 18117  loss=185.0285  steps/s=104.11  prediction: \"/t.co/tOGFm191Oe https://t.co/PidiKxGaEW\" => \"t.ceuu ::///t:/ttttttt11t1////tttt//tt//\"\n",
      "batch 18118  loss=165.0393  steps/s=101.50  prediction: \"ms\n",
      "Build cool stuff that's useful to you\" => \"e e  seep  loo  oool   ul     u  uu uf u\"\n",
      "batch 18120  loss=146.4659  steps/s=104.39  prediction: \"0yrs, person B (who has not followed x)â€¦\" => \"x s  (egO=(ht\n",
      "s,G)@,AT!IB1==B0,/,,0'NP,B\"\n",
      "batch 18121  loss=159.0430  steps/s=100.53  prediction: \"ding man! Yeah lmk how it goes next time\" => \" ne  hnn a anas n a   a                 \"\n",
      "batch 18122  loss=148.1706  steps/s=97.50  prediction: \"TB elon lived in leafland for a bit iirc\" => \"B nes   eneT  nle     i    l           t\"\n",
      "batch 18123  loss=181.5101  steps/s=99.63  prediction: \"/t.co/lBwBETlxDd cats are insane animals\" => \"t.ccs9  //////B/BBBBBBBl ta     aa aa  a\"\n",
      "batch 18124  loss=173.8967  steps/s=77.33  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"ys tsn //BtltBo  ttt  a ttass// aanaaasa\"\n",
      "batch 18125  loss=162.8807  steps/s=46.08  prediction: \"ly: @iamyourboon https://t.co/fGieEuRqXk\" => \"y: @lnnBottulBn  ttts s/ttts/// aaYYYasa\"\n",
      "batch 18126  loss=155.8927  steps/s=110.83  prediction: \"doing stuff their mind doesnt want to do\" => \" nn     d  d  dd                n  n    \"\n",
      "batch 18127  loss=158.4830  steps/s=94.86  prediction: \"ylde lowkey cant believe zompy said that\" => \":yinoijuindl ede    n    ee ee e e    oo\"\n",
      "batch 18128  loss=168.0540  steps/s=99.32  prediction: \"o make rlly complex interactive web apps\" => \"ufa a   e     o        ll      ele r tee\"\n",
      "batch 18129  loss=154.8185  steps/s=104.24  prediction: \"memory of doing a hard thing in the past\" => \"e ysohthao`.GðŸ˜ sXTð—¿#[ð—°k.*#]*G#\n",
      "NNNxxbð˜€T#\"\n",
      "batch 18130  loss=155.1833  steps/s=106.72  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" toi   nh c hhn       gt t      t    ooo\"\n",
      "batch 18131  loss=140.8099  steps/s=97.24  prediction: \"king spheres are infinitely many circles\" => \" nteceeegen nseeeeee eree   i   nin  y y\"\n",
      "batch 18132  loss=146.3320  steps/s=102.73  prediction: \", or if claude is in an india region tho\" => \" boierio in   i    i  i      i  i ii  i \"\n",
      "batch 18133  loss=153.7401  steps/s=102.25  prediction: \" btw? or does onnx just work well enough\" => \"tut   ntt  tt nn   o     o    o    w    \"\n",
      "batch 18134  loss=168.9408  steps/s=30.03  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @a etr  e  n         o    w    w    \"\n",
      "batch 18135  loss=152.4273  steps/s=110.15  prediction: \"dates/incentives to fund ai safety stuff\" => \" yn  an anaetenaaneeee  enn nn  t   sf s\"\n",
      "batch 18136  loss=166.5713  steps/s=102.93  prediction: \"e in milan venice florence.. sorrento rn\" => \" to  olnn\n",
      "lil niin   nnneneni en nee een\"\n",
      "batch 18137  loss=155.6824  steps/s=102.66  prediction: \"he building -&gt; increase skillset loop\" => \"e   ts  tiinni iiiii i  i i    ii  s s l\"\n",
      "batch 18138  loss=165.8972  steps/s=80.47  prediction: \"edydas @tanayj make one\n",
      "good opportunity\" => \"  oud d innn gi  in    geen ee ses lloll\"\n",
      "batch 18140  loss=189.2912  steps/s=107.22  prediction: \" @sunsettler 100%\n",
      "\n",
      "TIME AND FREEDOM BABY\" => \"@sonde @ea@ @nn n  tne \n",
      "\n",
      "000\n",
      "\n",
      "\n",
      "oEE DMEDD\"\n",
      "batch 18141  loss=157.6787  steps/s=104.28  prediction: \"r the years for business/building things\" => \"e(a vbrnr\n",
      "0%o  n(4j)'w2((M)vjl2p/j)(/w8/\"\n",
      "batch 18142  loss=169.8999  steps/s=101.36  prediction: \"as a BLAST dude. voice twitter is fun af\" => \"n    eat  t t              e  e   e   tt\"\n",
      "batch 18143  loss=149.2953  steps/s=105.30  prediction: \"re for blundering bc of moving too quick\" => \"eplya c o,jh mnsSTA@gxkk,STppkUL/Sq110Tq\"\n",
      "batch 18145  loss=145.8180  steps/s=102.06  prediction: \"ve you ever worked for a fast food chain\" => \"elyoudl   eve e eeee                    \"\n",
      "batch 18146  loss=157.4586  steps/s=103.57  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"d a oI ntdon  eoonooonsotttsott/ot//ttc/\"\n",
      "batch 18147  loss=161.4650  steps/s=104.41  prediction: \"h, that explanation/example makes sense'\" => \"e  ' la  a ha   aaaa aaaataxaxeaaaaaeeee\"\n",
      "batch 18148  loss=161.9487  steps/s=100.15  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \"  m it ' sre!= dPw@k3V,!g!!H!$g!$'/j0AI.\"\n",
      "batch 18149  loss=169.7955  steps/s=86.66  prediction: \"phere @gizmobly giz inc will change this\" => \"lob ol  te f   go o      n   n    lll  o\"\n",
      "batch 18150  loss=149.9536  steps/s=102.42  prediction: \"you should do it, youd learn a ton i bet\" => \":u  o  u  u  u o o  ooo uo   o    o     \"\n",
      "batch 18151  loss=176.7025  steps/s=31.89  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @ou  nuo   o o  ooo do   o          \"\n",
      "batch 18153  loss=144.8652  steps/s=112.43  prediction: \"he actual serious dangers of being smart\" => \"e  ad    e     a        a  s   s    s s \"\n",
      "batch 18154  loss=147.7455  steps/s=103.43  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"@s  aenn ee   dn   eee    eeeeee eeeeeee\"\n",
      "batch 18155  loss=156.9780  steps/s=105.03  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"dt  esteef ff rf  ff     s   t /tt////J/\"\n",
      "batch 18156  loss=154.9202  steps/s=104.81  prediction: \"mages looked smoother so it did that lol\" => \"ene i1et erhhv nâ˜ }ÊœÊœð—¿[ÊœÉ´yV[ÊœÉªpð—µ#|Éªð—¼ð—¯[##]\"\n",
      "batch 18157  loss=153.6990  steps/s=105.25  prediction: \"n clarity from practicing visualizationâ€¦\" => \"dioe enerme n i  rrrit rrc   ric  iiaiai\"\n",
      "batch 18158  loss=186.2488  steps/s=20.76  prediction: \"eply: @tunahorse21 its really that good?\" => \" ly: @rentn n  r rrritii c   ric  iiaiai\"\n",
      "batch 18159  loss=161.6102  steps/s=152.77  prediction: \"ake with two snakes would be interesting\" => \"ney nes n   r tt  iti  n     aa   ititin\"\n",
      "batch 18160  loss=160.6505  steps/s=97.61  prediction: \"utput brothers karamazov, word for word\"\" => \"n  miAAutA tttt tt t  raa  arrrarrrrorrr\"\n",
      "batch 18161  loss=151.2198  steps/s=104.09  prediction: \" the game loop in zig, rendering in cuda\" => \"toete thta t  ag                 ie ii  \"\n",
      "batch 18162  loss=173.6827  steps/s=104.56  prediction: \"is not true loss https://t.co/VvtOa0Aau2\" => \"n  oC a onss e essssssssstttts o// s tVt\"\n",
      "batch 18163  loss=160.2552  steps/s=102.78  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th  e thnent   ni   iiii i i ii     ssse\"\n",
      "batch 18164  loss=148.0873  steps/s=102.11  prediction: \"have primitives if you look close enough\" => \"ese o  tet i i ivieiiiiii  i i    e o o \"\n",
      "batch 18165  loss=149.0433  steps/s=105.20  prediction: \"ty) so they can be free to chase rewards\" => \"h ceostoe ero et t  e  ee  e    e e e e \"\n",
      "batch 18166  loss=137.7037  steps/s=101.63  prediction: \"t leak info from the stream accidentally\" => \"hiha  ntt  t on   o    o   o      t   aa\"\n",
      "batch 18168  loss=153.7982  steps/s=100.77  prediction: \" great for learning unix\n",
      "\n",
      "Very cool man.\" => \"too a !!nene  e       n nnnnnn  nn  r   \"\n",
      "batch 18169  loss=153.9557  steps/s=103.95  prediction: \"ool looking games, and get more interest\" => \" d e lcol  lolol oooooo o g g g g      e\"\n",
      "batch 18170  loss=146.4674  steps/s=103.02  prediction: \"ther reasons why\n",
      "https://t.co/C32Ru1Tc5u\" => \"he  a  io l loo o  hhhshhsssttsst//sts//\"\n",
      "batch 18171  loss=155.2136  steps/s=100.77  prediction: \"lity is really really powerful, actually\" => \"yso iieii i i i  illllylllllrrllll  rluu\"\n",
      "batch 18172  loss=161.0674  steps/s=101.71  prediction: \"ny part of a much bigger long term thing\" => \"    e  nahnnn n  a a                g   \"\n",
      "batch 18173  loss=173.9281  steps/s=104.25  prediction: \"ebsite https://t.co/fKvh5jFnKh somewhere\" => \" l    n      st t s tt /////KKKtKKKKKhhe\"\n",
      "batch 18174  loss=155.8160  steps/s=101.80  prediction: \"e chunking strategy. Good luck tomorrow!\" => \" la  t n  c  hn       t  t      t    ooo\"\n",
      "batch 18175  loss=149.8903  steps/s=104.93  prediction: \"y can approximate any func. they all can\" => \" aoaefv    an n  aa  aa aa n  a   n   y \"\n",
      "batch 18176  loss=149.9393  steps/s=104.85  prediction: \"n just build cool fun stuff all the time\" => \" toheet tn  u nu  u    uu u      l   l  \"\n",
      "batch 18177  loss=146.8674  steps/s=105.36  prediction: \"tention/effort with no results. Not easy\" => \" r  ist teetettettttttttt t    to o ot t\"\n",
      "batch 18178  loss=177.2160  steps/s=105.03  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/.ccs:o  :///T//TOOOOttOOtO/t/ttt////t//\"\n",
      "batch 18179  loss=192.7170  steps/s=95.44  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"yt  s  s cc hOeotct htthtth666th4ddRdttd\"\n",
      "batch 18181  loss=168.5245  steps/s=100.42  prediction: \" surprised at how clean of a read it was\" => \"@taY en r ssas r a  aa    a   aa  a     \"\n",
      "batch 18182  loss=169.7961  steps/s=104.21  prediction: \"h @tsoding Musializer looked pretty cool\" => \"eras ss  assn sn sisii   oa  aee e  ee  \"\n",
      "batch 18183  loss=147.0724  steps/s=103.31  prediction: \"nomena that i used to not have words for\" => \" tf t noen tn ne a  tet t  t t    t o  o\"\n",
      "batch 18184  loss=245.1741  steps/s=12.73  prediction: \"reply: @Nominus9 Yup. Its gonna get wild\" => \"eplyd @ ibjnof  Y\n",
      "xkyvzx\"1w\n",
      "zp:_bjbj@vbj\"\n",
      "batch 18185  loss=158.4743  steps/s=108.67  prediction: \"ipts into a gptâ€¦ https://t.co/tz9OncWzLg\" => \"ne  a tittst 3  sttptt ppt tstptt t ttt/\"\n",
      "batch 18186  loss=166.9344  steps/s=102.98  prediction: \" tool\n",
      "\n",
      "RECURSION https://t.co/VnbltPql2g\" => \"th  r lr rgmREâ€¦U oRCoRRCCCN NNN/tt/tt t/\"\n",
      "batch 18187  loss=153.1471  steps/s=102.86  prediction: \" interesting to see what it hallucinates\" => \"tt  i    ts ttttttt et     t e   t  t  t\"\n",
      "batch 18188  loss=157.7975  steps/s=96.81  prediction: \"B GPT isnt wrong, just ahead of its time\" => \" To ins iene t   n  n    t      a    at \"\n",
      "batch 18189  loss=169.6358  steps/s=88.73  prediction: \"ellessen Last time was ~6:20am cali time\" => \" l e esnness n nsn  t t   aaa  a6   iiai\"\n",
      "batch 18190  loss=156.3707  steps/s=103.85  prediction: \" did not answer. he just kept on yapping\" => \"tayap tatttt te      e  te   t    te p  \"\n",
      "batch 18191  loss=150.4356  steps/s=102.18  prediction: \"engl\n",
      "\n",
      "why would i use one over the other\" => \" d n     w nw  w                        \"\n",
      "batch 18192  loss=147.6196  steps/s=105.00  prediction: \"i), everything is deterministic (commonâ€¦\" => \"n tl  ne h yyeyy    e eeeiiiiiiiiiiiiiii\"\n",
      "batch 18193  loss=210.7084  steps/s=22.43  prediction: \"eply: @Laz4rz glad you brought the stuff\" => \" ly: @yaye eeehe  e eeeeeiiiiiiiiiiiiiii\"\n",
      "batch 18195  loss=153.5307  steps/s=106.01  prediction: \"ew_pynch join often, good guys to follow\" => \"  i   ee@wnnwnnon  onnnnnoooooo  o   oo \"\n",
      "batch 18196  loss=160.7181  steps/s=104.54  prediction: \"tbh, i like having control over my tools\" => \" oe etrbf  si e h  i    i i   ioe     oo\"\n",
      "batch 18197  loss=150.5382  steps/s=100.24  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r   nt esto l c@ðŸ“ˆ]{cá´›á´›ð—²#c##*ná´‡##]Éªá´â€[[#\"\n",
      "batch 18200  loss=167.6739  steps/s=100.77  prediction: \"here for the funny symbols and recursion\" => \"e  o errmrrmrh re h he rs e  s    es esr\"\n",
      "batch 18201  loss=145.1208  steps/s=104.47  prediction: \"oast. silencio until youve made progress\" => \" l e t   tt s is t ii iii i  o          \"\n",
      "batch 18202  loss=158.5642  steps/s=101.14  prediction: \"utput brothers karamazov, word for word\"\" => \"s   ABtut  to t ttt   rrtr aara rrrrorro\"\n",
      "batch 18203  loss=151.8804  steps/s=99.00  prediction: \"hnote uuuh i have a license for thse sir\" => \"esg utttteuttuthuu   auaa    a e   o   r\"\n",
      "batch 18204  loss=169.9901  steps/s=62.63  prediction: \"@jamstack_guru Speed of launches as well\" => \"ludi  touuhu uuuua   aeaa    e e    s  s\"\n",
      "batch 18205  loss=167.4846  steps/s=112.18  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" toa s tut rofeeSMTBk55TB:Iv(\n",
      "FK0FK::/1.\"\n",
      "batch 18206  loss=149.7963  steps/s=103.22  prediction: \"ommittal move like going on a sabbatical\" => \" e   e   omoamet    m e  o i o o  a a  a\"\n",
      "batch 18207  loss=167.0037  steps/s=103.73  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"t.ch th t///////ZZZZZtZtttp/t/t/////////\"\n",
      "batch 18208  loss=175.6815  steps/s=100.46  prediction: \"wigABAP thats why they call him zigmobly\" => \"agA tte  ill a  AA  hhthtthhh  hhh y c l\"\n",
      "batch 18210  loss=150.0069  steps/s=67.90  prediction: \"izmobly @juweeism i can try to help haha\" => \"nm bli  b@ll  thww  h h    a   hyy   lll\"\n",
      "batch 18211  loss=182.8531  steps/s=87.05  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"ltzziibi @ob wesww  i t    a     l ohhaðŸ›‘\"\n",
      "batch 18212  loss=154.2704  steps/s=107.78  prediction: \"mages looked smoother so it did that lol\" => \"eke  @tami   Q\n",
      "rð—¿#Ê€^*#á´˜}É´]*|wð—°æˆ‘###uðŸ“‰á´¡ðŸŒ‘[]\"\n",
      "batch 18213  loss=151.2009  steps/s=105.62  prediction: \" so I invested my time into that instead\" => \"ttreernr o   ote  seeee i e  e ti   tt t\"\n",
      "batch 18215  loss=150.2274  steps/s=104.45  prediction: \"her is metagocnition (for your own mind)\" => \"e  s  pe hr trgre  ooot ooo ioioo  on o \"\n",
      "batch 18216  loss=168.0584  steps/s=101.41  prediction: \"king one open rn just cause of this post\" => \"enn ccCrccan   in  nnn  n    n  ou    s \"\n",
      "batch 18217  loss=159.5158  steps/s=47.96  prediction: \"y: @benfleming__ its lifechanging really\" => \": @aciCa  in   en  nn   n    n  ss    s \"\n",
      "batch 18218  loss=166.1565  steps/s=116.78  prediction: \"nd beyond is such a gargantuan advantage\" => \"g  e ogn bn n d n  s    a aa aaaaaaaaann\"\n",
      "batch 18219  loss=169.8736  steps/s=100.45  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"ecle i H VSmhe lv-&Jv;ybJdf-&Jv;-&hH;bJJ\"\n",
      "batch 18220  loss=148.4223  steps/s=101.77  prediction: \"on your end, try a different browser idk\" => \"r gii                     r   r    er  e\"\n",
      "batch 18221  loss=161.6627  steps/s=104.95  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"eplor @ntSj  Zt -kx';Fkx'-&'\";,&g-v&/g?W\"\n",
      "batch 18222  loss=149.3144  steps/s=104.19  prediction: \"most rather just.. not have a device tbh\" => \"pbeei l u   ov  'IP(,'jjf').\"Y'Y)''\")gWj\"\n",
      "batch 18223  loss=142.5330  steps/s=104.06  prediction: \"w the entire thing works when you use it\" => \"it  en t n nn en    t        e   w      \"\n",
      "batch 18224  loss=157.4960  steps/s=103.85  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "e sd   cB,P G sPWGMbbWJv+cV,I,\n",
      ",,+p+b++\"\n",
      "batch 18227  loss=183.5959  steps/s=29.83  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: @P te veeev eeee e hh h h h   h     \"\n",
      "batch 18228  loss=140.0904  steps/s=106.50  prediction: \" one of the objects that could cast them\" => \"tf  an   o               ttttttttttttttt\"\n",
      "batch 18229  loss=158.0950  steps/s=108.12  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"ekeie da e   mr p%%%%%.7%/%%%%/%g%%%%g!!\"\n",
      "batch 18230  loss=152.5721  steps/s=104.19  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  hne       tt  t  tto ttttttt/t//t//o\"\n",
      "batch 18231  loss=145.0934  steps/s=102.56  prediction: \"if you have enough courage to go for it.\" => \"n    et  i    u      o       o  o  o  oo\"\n",
      "batch 18235  loss=137.2097  steps/s=102.54  prediction: \" will get back to you when this is fixed\" => \"thaeet niw  l w                         \"\n",
      "batch 18236  loss=141.9047  steps/s=104.39  prediction: \"ed around the data that flows through it\" => \"   s nt ea ed  d d d d aa   a t  t tt tt\"\n",
      "batch 18237  loss=169.1564  steps/s=104.00  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"h    suin n nnaa   aaad  a  aad  ladld  \"\n",
      "batch 18238  loss=152.6592  steps/s=100.24  prediction: \"y time back so i can work on what i want\" => \":hasamsam  m atmm    a    a    o   o  w \"\n",
      "batch 18239  loss=189.8153  steps/s=20.88  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly: @sam  m m  i    a    a    o   o  w \"\n",
      "batch 18240  loss=151.1351  steps/s=109.02  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"ti sr  o  e ne eineitinnnsttttt//t/ttt//\"\n",
      "batch 18241  loss=162.7348  steps/s=100.85  prediction: \"is the platonic form of a platonic form?\" => \"n  ra  oenesnthte   tt      to   of aofo\"\n",
      "batch 18242  loss=145.8711  steps/s=104.69  prediction: \"ng and figure out which freqs i care abt\" => \"  tto s     n nnn                       \"\n",
      "batch 18243  loss=142.7795  steps/s=102.60  prediction: \"s\n",
      "\n",
      "For example the place this was posted\" => \" \n",
      "e e i tveele\n",
      "ee eeeeeee ee    e       \"\n",
      "batch 18244  loss=146.7181  steps/s=105.40  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n  n   n at    o          tttt//t/tt////\"\n",
      "batch 18245  loss=175.2777  steps/s=59.94  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"iaatnn  dotoo       tttt/////t//9/9//x96\"\n",
      "batch 18246  loss=155.4698  steps/s=122.15  prediction: \"whoa thats wild, old twitter could never\" => \"aet @   e ttn   ht  tttst  tttttttltt dd\"\n",
      "batch 18247  loss=179.4987  steps/s=66.27  prediction: \" more to 400! Been a crazy two weeks lol\" => \"iane t et  thh0t0t   ddtt  tttttttote eðŸ›‘\"\n",
      "batch 18249  loss=163.9180  steps/s=113.76  prediction: \"effJezos Right to learn\n",
      "Right to compute\" => \" i s BnesBfeeefeRRR e     RRt    t  t to\"\n",
      "batch 18250  loss=171.6570  steps/s=83.32  prediction: \"kul07 Super awesome dude, great stuff!!!\" => \"entaeBeseseRfe eoee eee o    tt     tttt\"\n",
      "batch 18251  loss=150.7193  steps/s=105.32  prediction: \"d all the aliases for commands to bashrc\" => \" oh  l atad la laa       a              \"\n",
      "batch 18252  loss=139.9977  steps/s=103.24  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"u  b  bettt b  tt t     os s   eeee ee  \"\n",
      "batch 18254  loss=173.3414  steps/s=97.63  prediction: \"ure Beautiful, and great choice of music\" => \"te tttt etet uut  uu  iie   eee eee o oo\"\n",
      "batch 18255  loss=147.7504  steps/s=104.84  prediction: \"nomic than discord id switch immediately\" => \" thode  ae em omo       o cd ic  ii iddi\"\n",
      "batch 18257  loss=157.7166  steps/s=99.74  prediction: \"p was the ultimate signal the whole time\" => \"lt  te ttw   tet  ttt   t s tat t  e tlh\"\n",
      "batch 18258  loss=143.7437  steps/s=103.32  prediction: \"how u get llms to make huge projects btw\" => \"ew otf t i    t sl l  l    t   e   oe   \"\n",
      "batch 18259  loss=159.5879  steps/s=99.11  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" nt itt sg g  loooo    oot t  ott/////QQ\"\n",
      "batch 18260  loss=179.2060  steps/s=28.44  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: @t aehgegogoooo    ott t ///////QQQQ\"\n",
      "batch 18261  loss=161.7081  steps/s=110.90  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" \n",
      " oy yis e     zuufbbu,dEv?,,wf&zvQ,vzx\"\n",
      "batch 18263  loss=151.4460  steps/s=104.23  prediction: \"you should do it, youd learn a ton i bet\" => \":u  aj u  u nuno o  uoo  o   o          \"\n",
      "batch 18264  loss=171.8565  steps/s=102.36  prediction: \"/t.co/9dZqg8S9Ep https://t.co/I9PfxszeaH\" => \"v.dh t t////:///99998t8ttppt//tt////.///\"\n",
      "batch 18265  loss=171.5133  steps/s=30.43  prediction: \"ply: @dgant wild https://t.co/0HTLsAprAT\" => \"ly: @s  ////itg 999pEtEttppt//tt////P/Pt\"\n",
      "batch 18266  loss=192.9772  steps/s=134.58  prediction: \" @sunsettler 100%\n",
      "\n",
      "TIME AND FREEDOM BABY\" => \"tlunoe oettests  tte00%t0000TETEEEMDMEDD\"\n",
      "batch 18267  loss=147.7926  steps/s=103.55  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"n n t n nonn  o  oo    t tt   t   t   ss\"\n",
      "batch 18268  loss=158.7670  steps/s=102.64  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAP   nttn o t oo   a    t  ? s?sssssss\"\n",
      "batch 18269  loss=152.1332  steps/s=104.66  prediction: \"ng the wrong way https://t.co/BWVKdF1jox\" => \"d to pf  nr n n r  n  nt  ttw tttt ////t\"\n",
      "batch 18270  loss=174.5468  steps/s=59.70  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tjupte  no nn rn      pttttt//t/ttV//ott\"\n",
      "batch 18271  loss=165.0088  steps/s=109.90  prediction: \"mer.js to make it cost $0. took too long\" => \"a se  fsed d iind@.jbu$$c$0jm$0.jv@kxz$0\"\n",
      "batch 18272  loss=150.1424  steps/s=104.60  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"tuedeni ggg giegiiiiii##e#####e###SSSSee\"\n",
      "batch 18273  loss=182.2432  steps/s=95.15  prediction: \"Lynx the less you talk the more you walk\" => \"  Po h rngn ie neeee eessa  aka ee reeee\"\n",
      "batch 18274  loss=151.1190  steps/s=104.41  prediction: \"mpeg tho but not if i rely heavily on it\" => \"ale re   i ier eðŸ‘Œ,xá´„^â€™,*XXá´‡á´€[*Éª[Éª|**wgÊŸb\"\n",
      "batch 18275  loss=156.5312  steps/s=102.20  prediction: \"ooo\n",
      "\n",
      "ill send you a link around the 25th\" => \" l tllgyyolo   loooool       l    a     \"\n",
      "batch 18276  loss=170.2706  steps/s=30.75  prediction: \"ply: @sunsettler https://t.co/8FPo1elzOu\" => \"ly: @  gyolo llooo  l        l n        \"\n",
      "batch 18277  loss=149.1877  steps/s=154.80  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"y7 ososlehete r  st i    i   n n aa a na\"\n",
      "batch 18278  loss=156.0277  steps/s=63.25  prediction: \"yotzol its not a meme, its a way of life\" => \":u sootte tttiws st i        i a aaea  a\"\n",
      "batch 18279  loss=155.2778  steps/s=129.73  prediction: \"talexoki: good sunday anon\n",
      "\n",
      "go to church\" => \"hle  \"unet tt t  om     s a ann  o n noðŸ›‘\"\n",
      "batch 18280  loss=163.7256  steps/s=100.73  prediction: \"grammer extra respectfully:\n",
      "\n",
      "skill issue\" => \" oe  @u wroorrgr rrereeaeereree\n",
      "\n",
      "\n",
      " lll\n",
      "l\"\n",
      "batch 18281  loss=157.5707  steps/s=100.93  prediction: \"ynch Its official im naming my kid movie\" => \":t ludew@r  n ns   cff  f i   ii  ii mm \"\n",
      "batch 18282  loss=151.0993  steps/s=104.13  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e\n",
      "nb     I??tLurv3@3Pv&b;/PIbY3===&;;;^^\"\n",
      "batch 18283  loss=147.7953  steps/s=104.69  prediction: \"l tools for myself and they save me time\" => \"yo  u   uulloo l   l  ff                \"\n",
      "batch 18284  loss=148.7586  steps/s=100.47  prediction: \"r switching if mint doesnt serve me well\" => \"eeW't  en\n",
      "KItmaeI'X,ï¸.{WXá´€,,]ð—¼[*.á´€Wbâ€ð—¿[*\"\n",
      "batch 18285  loss=170.5204  steps/s=104.14  prediction: \"ock your 1000th follower and stay at 999\" => \" k o rnollltl el000000  olol   o     t  \"\n",
      "batch 18286  loss=183.4755  steps/s=64.88  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"ludwedo  l000000 0 loo l lo    o    !999\"\n",
      "batch 18287  loss=151.4430  steps/s=107.22  prediction: \"e some exciting long term vision then no\" => \" ae  ntt  seteet   e e  e e      i n  en\"\n",
      "batch 18288  loss=151.8879  steps/s=100.46  prediction: \" or so more to go. Lookin forward t o it\" => \"@f b !Io o oo ooo oooooooooooooo o  r   \"\n",
      "batch 18290  loss=154.8522  steps/s=105.80  prediction: \"be allocate some time to do fun projects\" => \"u ino  on    aa        t te       o     \"\n",
      "batch 18291  loss=169.4217  steps/s=58.71  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"ili oinn     ae   om  mt     e    o  o  \"\n",
      "batch 18292  loss=153.6735  steps/s=106.99  prediction: \" terms of a chess analogy\" whatever\n",
      "\n",
      "Mad\" => \"io    t  t    n      s      aa aaa aaaae\"\n",
      "batch 18293  loss=155.7210  steps/s=104.42  prediction: \"rflowsucks and never went on there again\" => \"eao   nii\n",
      "xh gge,xyybMQbkQ1x-dQ1b6Q-Zyvv\"\n",
      "batch 18294  loss=134.5288  steps/s=103.02  prediction: \"an is usually to attack so imma do that\"\" => \"nd .          h      t  t a  a a  a    a\"\n",
      "batch 18295  loss=154.4399  steps/s=102.75  prediction: \" is nice. idk much about distros tho lol\" => \"tn e  e eine  i   i ca  u  u   d d tht h\"\n",
      "batch 18296  loss=143.5112  steps/s=99.41  prediction: \"ood and helps you not waste future years\" => \" l i   io      d     o       o  t  uu  u\"\n",
      "batch 18297  loss=147.5481  steps/s=105.16  prediction: \"o make a significant impact on your life\" => \" ia   in    a  i iaiiiiiiiiii ii        \"\n",
      "batch 18298  loss=143.2043  steps/s=104.45  prediction: \"seless to ppl who dont know them already\" => \"  eee aiese ese s  s       o  o         \"\n",
      "batch 18300  loss=172.7307  steps/s=100.26  prediction: \"ight go back to ML stuff instead of this\" => \"nhiu   e t  t  t         t    t tt t  f \"\n",
      "batch 18301  loss=179.6796  steps/s=104.08  prediction: \" at 5:10 or something I just go til 9:10\" => \"tnd t stnn    at             t  t      t\"\n",
      "batch 18302  loss=165.6318  steps/s=100.95  prediction: \"l do bro, never had a french beer before\" => \"yte di e W ro  d   o  e      r h   e ere\"\n",
      "batch 18303  loss=140.2914  steps/s=105.86  prediction: \"tion WAY more than if its someone else's\" => \" mg   so o o Yo   to                  es\"\n",
      "batch 18304  loss=139.2729  steps/s=104.74  prediction: \"do 16hrs tmrw, test this and report back\" => \" n  t   sh    t       t   tt            \"\n",
      "batch 18305  loss=151.5728  steps/s=104.45  prediction: \"n run on my laptop, which I can do w ML?\" => \" ar H D m                               \"\n",
      "batch 18306  loss=159.7853  steps/s=101.61  prediction: \"ng to caffeine+building/studying for fun\" => \"  o  i m  nf fi fin+ingiinineggninninfii\"\n",
      "batch 18307  loss=156.5995  steps/s=104.89  prediction: \"s and $billions\n",
      "\n",
      "https://t.co/JAfCka4QWD\" => \" ae ee  dd dnd e d s ss ssssts/t//tt/tt/\"\n",
      "batch 18308  loss=152.3958  steps/s=104.32  prediction: \" is structured to add llms pretty easily\" => \"tndi eed in  et       d dd d   d    t   \"\n",
      "batch 18309  loss=150.4413  steps/s=103.99  prediction: \"up computing 'why' for free all the time\" => \"s  aa e   n n       ''''''              \"\n",
      "batch 18310  loss=175.0376  steps/s=60.21  prediction: \"@anish0209 gpt or claude or whatever LLM\" => \"lndveou u n   pg''' o               ee e\"\n",
      "batch 18312  loss=156.6363  steps/s=112.11  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"n eionoo tonrornoou   oou   nuee een  oo\"\n",
      "batch 18313  loss=152.9243  steps/s=103.36  prediction: \"m scratch in numpy like i did w backprop\" => \"ete  n  no  i  eTblTW,*v,,*vbMIbb`bfâ€MLI\"\n",
      "batch 18314  loss=199.6553  steps/s=103.64  prediction: \"needed to dl this. meme delivery service\" => \"  go  n  y e  ed      ee t   e eeeeeee e\"\n",
      "batch 18315  loss=163.4618  steps/s=104.06  prediction: \" 10% is figuring out a fix + applying it\" => \"t0eeerii  e  ig ii       i i i     i   i\"\n",
      "batch 18316  loss=144.9331  steps/s=102.62  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \" eth ps nnanaaan a    a         ///tt///\"\n",
      "batch 18317  loss=149.2740  steps/s=102.57  prediction: \"eet you can do some crazy things in life\" => \" d egtt  n    y      o                  \"\n",
      "batch 18318  loss=175.9729  steps/s=103.86  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nn rn aeeaa  ag n#  nnnnt ttnnst//tt///t\"\n",
      "batch 18319  loss=144.7021  steps/s=103.77  prediction: \"t info, hence why I expanded past papers\" => \" soe a t  n n h         e     e        p\"\n",
      "batch 18320  loss=157.1823  steps/s=105.66  prediction: \" coast US)\n",
      "\n",
      "I usually go from 5am to 9pm\" => \"tame  ae   c tt s  s\n",
      " \n",
      "   \n",
      " l        o  \"\n",
      "batch 18321  loss=145.5820  steps/s=95.06  prediction: \" takes a lot of work and years of it tho\" => \"th et cntete   t a l  oo  o    a        \"\n",
      "batch 18322  loss=161.7066  steps/s=102.60  prediction: \"/t.co/dWiO4erSb1 https://t.co/CyostzMCjv\" => \"/.ces sts///t/eet///ttttt:////tt////t/tC\"\n",
      "batch 18323  loss=175.0843  steps/s=100.05  prediction: \" lol positive feedback loops are awesome\" => \"testte   ode oo  oeee ie  o    oe   eeoe\"\n",
      "batch 18324  loss=146.8265  steps/s=103.82  prediction: \"conflicting values it would be a paradox\" => \"onte  a llil llllllii ii ll  l        a \"\n",
      "batch 18325  loss=157.8619  steps/s=105.61  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lo  neeingr rr  aiior\n",
      "o \n",
      "\n",
      "\n",
      "\n",
      "  VVV t tt a\"\n",
      "batch 18327  loss=177.9868  steps/s=36.73  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: eeein r orr ai\n",
      "oi\n",
      "o \n",
      "\n",
      " V  ttatt tt a\"\n",
      "batch 18328  loss=161.3640  steps/s=142.38  prediction: \"ily @ineedtolocking @kuberdenis detected\" => \"nl \n",
      "oecooeeneee  tionokkkk kkkkn ee ee e\"\n",
      "batch 18329  loss=160.1724  steps/s=100.33  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"n st  t           et  tttthtttttttt/////\"\n",
      "batch 18330  loss=149.2252  steps/s=101.38  prediction: \"ttler experimentation games are the best\" => \" ins t  e  te e  tttettttttat/s seee  ee\"\n",
      "batch 18331  loss=149.3089  steps/s=101.53  prediction: \" nothing\"\n",
      "socrates one upped us all here\" => \"@olw ni    n nnonnoooooooooo            \"\n",
      "batch 18332  loss=163.8441  steps/s=105.21  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"sden mem  m   m'''t'''' '   t e t   t te\"\n",
      "batch 18335  loss=152.7765  steps/s=101.37  prediction: \"xes this (whether you want it to or not)\" => \"ps  i n  i issess hh  eh    h   tt  t   \"\n",
      "batch 18336  loss=161.8350  steps/s=96.40  prediction: \" + shorten posts\n",
      "https://t.co/KoRnGnGtn0\" => \"@   enett n  th   ootshsttsttttttoto/o//\"\n",
      "batch 18337  loss=147.2343  steps/s=102.11  prediction: \" Post it in the disc it helps us all out\" => \"@os  ll s                               \"\n",
      "batch 18338  loss=147.5106  steps/s=104.34  prediction: \"sonnet3.5 for pretty much everything now\" => \"   se eonIone e    eet ttt     eee  et  \"\n",
      "batch 18339  loss=147.0687  steps/s=105.36  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in l n  n n   n n n   nnn n    n     n \"\n",
      "batch 18340  loss=147.7111  steps/s=104.36  prediction: \"time\n",
      "Then you stack lots of reps of this\" => \" me mo  et mm    ee et   t t   oo  t    \"\n",
      "batch 18341  loss=164.3559  steps/s=84.89  prediction: \"wigABAP a friendly virus. one that talks\" => \"htl     ny  A e  e   t     o  s o  o t t\"\n",
      "batch 18342  loss=148.0102  steps/s=105.59  prediction: \"es your data instead of storing the data\" => \" sikaneietetntg aa   aaaaa e    tt   t  \"\n",
      "batch 18343  loss=260.5361  steps/s=11.15  prediction: \"reply: @opaeoh ill lyk when i open it up\" => \"eply: @krhwcvwfnP@',X^\n",
      "Thwrw\n",
      ".bTyvkvk*yw\"\n",
      "batch 18344  loss=145.4424  steps/s=117.97  prediction: \" drag down/demotivate other team members\" => \"toe  d d  a ddr  ddddd ooooeeetteeoettem\"\n",
      "batch 18345  loss=150.2813  steps/s=103.02  prediction: \"isten to remixes of the ost all the time\" => \"n  to   s s s          e       t  t  tt \"\n",
      "batch 18346  loss=174.5530  steps/s=99.94  prediction: \"k man awesome work\n",
      "\n",
      "and super cool notes\" => \"easLawmem w mwewwwo w woe a o   r oo  oo\"\n",
      "batch 18347  loss=157.6821  steps/s=104.17  prediction: \"te correctly lol\n",
      "https://t.co/0eYn1IVGOH\" => \"hre peeteee cerceotttottt/tt///////////t\"\n",
      "batch 18348  loss=174.4362  steps/s=96.67  prediction: \"ellessen Last time was ~6:20am cali time\" => \" li ae sllseee tstttt tstt:t:00:00006002\"\n",
      "batch 18349  loss=179.8637  steps/s=102.50  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \"hactieall   WD t                        \"\n",
      "batch 18350  loss=166.3639  steps/s=102.84  prediction: \"\n",
      "\n",
      "pride, however, stops error correction\" => \"\n",
      "i t  pm ozð—ª ns T/aO,/bxx'v5x5xx(2vpwbv:\"\n",
      "batch 18352  loss=176.7529  steps/s=101.69  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"h t bnni g g gg  g  gtg    t  gt t t////\"\n",
      "batch 18353  loss=157.7859  steps/s=100.62  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"a ei ttga  a            e  a  aa   asala\"\n",
      "batch 18354  loss=144.1519  steps/s=101.48  prediction: \"fundamentals is a smart smart smart move\" => \" nh inna   s   nIpw|,kkyðŸ“ˆ*vXðŸ˜†kv[fbPLð—¼PLw\"\n",
      "batch 18355  loss=176.3207  steps/s=53.04  prediction: \"y: @tabtab0x_0 @Brycicle77 never mouse ðŸ«¡\" => \": @atceetaaa&Qata   aas  saas s smssm sm\"\n",
      "batch 18356  loss=183.9006  steps/s=40.74  prediction: \"eply: @PandoXiloscient integrity is king\" => \" ly: @tetaann esa   a s  saas s smmss sm\"\n",
      "batch 18357  loss=175.0953  steps/s=148.15  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"nrettcla aeX0 a    s  i OO  mee mmmm  r \"\n",
      "batch 18359  loss=145.9023  steps/s=105.24  prediction: \" i start walkin\n",
      "\n",
      "https://t.co/H2ODpcpNzs\" => \"t  d      t       ttttttttttt ttttt////p\"\n",
      "batch 18360  loss=153.3864  steps/s=104.28  prediction: \"his was a super helpful technique for me\" => \"anes ta tt t                 e   eeeeee \"\n",
      "batch 18361  loss=178.3560  steps/s=32.34  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly:    t                     e u eeeeee \"\n",
      "batch 18362  loss=148.8242  steps/s=107.26  prediction: \"uq?\n",
      "\n",
      "this freaked me out, didnt know ifâ€¦\" => \"scc   e  a  rqeraae   f fe de e dee  ddd\"\n",
      "batch 18363  loss=165.5751  steps/s=105.04  prediction: \"vars} complexity (O(f(n)) type stuff)\n",
      "-â€¦\" => \"etyaoro eher eh e eer( (((((((())))))   \"\n",
      "batch 18364  loss=147.8104  steps/s=103.00  prediction: \"ds (i think, music is not my strongsuit)\" => \"    tt osgo s s  i  i is iii  i  s   s s\"\n",
      "batch 18365  loss=144.8349  steps/s=99.40  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \"  a  ain esss mmmsr  n nnnoon nt t   t t\"\n",
      "batch 18366  loss=150.2493  steps/s=105.53  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"es  mn tet nn      o    oa      o       \"\n",
      "batch 18367  loss=152.0323  steps/s=104.31  prediction: \"on chunking showed higher level playersâ€¦\" => \"ret tst s  n nnh    hhhhhhih h hhe eee e\"\n",
      "batch 18368  loss=161.0998  steps/s=101.35  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"  e se g etttthntntetetttee eeeenin    i\"\n",
      "batch 18369  loss=151.1057  steps/s=106.46  prediction: \"the behavior, forming a habit eventually\" => \"her  i f rn   hg reiri  rri i rah eih  a\"\n",
      "batch 18371  loss=176.1196  steps/s=30.83  prediction: \"ply: @snats_xyz Hey that makes two of us\" => \"ly: eh fthir  e  ro ri  ohi i ran ean aa\"\n",
      "batch 18372  loss=167.5742  steps/s=107.55  prediction: \"esponses\n",
      "4 repeat step 3 til you have 1â€¦\" => \" s  t  esssessssesee seseee e  e te     \"\n",
      "batch 18373  loss=166.7277  steps/s=77.65  prediction: \"izmobly you have 3 days or youre blocked\" => \"ne  oe mosss eeeee e se 3 t    t t   e  \"\n",
      "batch 18374  loss=167.4504  steps/s=107.73  prediction: \" be cool to find some other players here\" => \"tedmotcosodl   o  oooo o    o     oeeee \"\n",
      "batch 18375  loss=150.6689  steps/s=101.22  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"ee o  @  4o  u  kv@,bwvu,!wl###hRR,vy#u,\"\n",
      "batch 18376  loss=150.1093  steps/s=102.34  prediction: \"dates/incentives to fund ai safety stuff\" => \" ve  an anaetenaaneeee  e n nn  a   tf s\"\n",
      "batch 18377  loss=156.5112  steps/s=96.27  prediction: \"B GPT isnt wrong, just ahead of its time\" => \" t @aana ene Ttennt tnn      a  a    ff \"\n",
      "batch 18378  loss=147.1857  steps/s=102.87  prediction: \"ranoid to install an extension like that\" => \"eml : @enenee@nek+@+77VAN/wVAx7INjRxg7\n",
      "T\"\n",
      "batch 18379  loss=157.4471  steps/s=102.47  prediction: \" but I learned\n",
      "\n",
      "ð—ªð—µð—¶ð—°ð—µ ð—¼ð—»ð—² ð˜€ð—¼ð˜‚ð—»ð—±ð˜€ ð—¯ð—²ð˜ð˜ð—²ð—¿?\" => \"@ed I di t    I\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "ð—µð—µð—µð—µð—µ ð—¼ð—¼ð—¼ð—¼ð—»ð˜€ð˜€ð˜€ð—²ð—²ð—²ð—²\"\n",
      "batch 18380  loss=153.0948  steps/s=104.80  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \"epl sd@hcitiihgiZ:$K:$/vmYkY:wk8kk8k:q84\"\n",
      "batch 18381  loss=155.9683  steps/s=99.43  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"e    tgna  a   e        a  a  a    aaaea\"\n",
      "batch 18382  loss=151.2501  steps/s=100.45  prediction: \"uth is the global maxima strat long term\" => \"l  te tietth tett t        aa aaaaaa laa\"\n",
      "batch 18383  loss=145.6257  steps/s=104.01  prediction: \" possible, at least quote and add a take\" => \"troe    s ss se   l l                aaa\"\n",
      "batch 18384  loss=133.8326  steps/s=104.38  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" o  ocasooto                          e \"\n",
      "batch 18385  loss=149.6152  steps/s=102.95  prediction: \"anything else would kneecap learning no?\" => \"ld  io ttrthtthni     ne n  e ee en en n\"\n",
      "batch 18386  loss=185.1650  steps/s=96.72  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \"  tr nenn te eee l kl ee t neteetta n/n/\"\n",
      "batch 18387  loss=161.1167  steps/s=102.84  prediction: \" quality than \"loading bar\" type writing\" => \"tu t  eet ettttet  tta   aaa \"\"\"\"\"\"   ti\"\n",
      "batch 18388  loss=173.5346  steps/s=98.19  prediction: \"OOYAH\n",
      "gl brotha\n",
      "Gonna join you in 6hrs ðŸ«¡\" => \"OO ste etOOOOOrH laaaanannnannnna  n    \"\n",
      "batch 18390  loss=144.7641  steps/s=102.53  prediction: \"t investment for your time generally imo\" => \"hbe  e e nnentneeteeett te   te    e   r\"\n",
      "batch 18391  loss=166.0535  steps/s=53.70  prediction: \": @yacineMTB Action produces information\" => \" @yas ryvT  mMh NAG?OkA{j:q)w.HxkwvG6kv:\"\n",
      "batch 18392  loss=159.6719  steps/s=105.69  prediction: \"movie)\n",
      "\n",
      "Wifi mode when its high (gaming)\" => \"ads i eo is lat (qgbcylvI))\n",
      "WWq)XðŸ°WqÊ€`vk\"\n",
      "batch 18393  loss=141.3909  steps/s=105.42  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tistbitt  t   \n",
      "    t tt ttttt-t--t-ttot\"\n",
      "batch 18394  loss=170.2002  steps/s=95.44  prediction: \"y based. how do you compile zig to wasm?\" => \":tr ezeobobed rsoed  ooooooououi oiiiiot\"\n",
      "batch 18396  loss=162.2908  steps/s=96.19  prediction: \" just signed up as a beta tester hehhehe\" => \"tuyzibel  b d  t uus  o p     ste t  tet\"\n",
      "batch 18397  loss=145.4837  steps/s=104.11  prediction: \" us safe from undetectable Dyson spheres\" => \"tsetnn  n eneenf  e ee eef  e e e e e e \"\n",
      "batch 18398  loss=170.5651  steps/s=104.19  prediction: \" of utility in my life (more like 97/10)\" => \"tf e en     t ti it    iy ii i    il  e \"\n",
      "batch 18399  loss=142.9458  steps/s=104.78  prediction: \"ugh the comments and it was pretty funny\" => \"th t  thhrhhn hhtt t etet          tt  t\"\n",
      "batch 18400  loss=151.3931  steps/s=102.34  prediction: \"icians and is a net negative for society\" => \"n a idtdi ttiant   a   n  a a   t       \"\n",
      "batch 18401  loss=187.6179  steps/s=106.50  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"nsn e s/////tsetBBBBBBB 9    o  o  o   l\"\n",
      "batch 18402  loss=155.4089  steps/s=84.39  prediction: \"hniacus specialized chips are the future\" => \"eop tc// hs sces o   l  c    ll       ft\"\n",
      "batch 18404  loss=164.6559  steps/s=106.40  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" hia   ddhd d\n",
      "esa e e    a  sssss sse   \"\n",
      "batch 18405  loss=145.4287  steps/s=105.46  prediction: \"ranoid to install an extension like that\" => \"enle: teneneernevU@U}v}A,}w}Ax}I5?{x,}wT\"\n",
      "batch 18406  loss=162.6918  steps/s=104.38  prediction: \"rs automatically slap that down to 10fps\" => \"e eero  n n s g kjuv/kvk0:g0fxb,kw150,\n",
      "1\"\n",
      "batch 18407  loss=163.5077  steps/s=102.69  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lr   y  n  n  m na   \"\"\"\"ta  \"t  a   aa \"\n",
      "batch 18408  loss=150.6634  steps/s=104.20  prediction: \"gful adventures\n",
      "\n",
      "https://t.co/yLJCZ2D3Tg\" => \" u   l  agen n eennae eenettts////ttet//\"\n",
      "batch 18409  loss=152.7354  steps/s=103.92  prediction: \"xes this (whether you want it to or not)\" => \" s  iinswe  sse shhh hehh  he   tt  t   \"\n",
      "batch 18410  loss=142.0427  steps/s=103.59  prediction: \"or a site with a manipulatable algorithm\" => \"n a a nooto   at      a  a aaaaaaaaaaaaa\"\n",
      "batch 18411  loss=257.1044  steps/s=11.56  prediction: \"reply: @graffioh HA thats really awesome\" => \"eply: @ieencitn.QQ,Q%Q%%(x,:KJx%%p/.L%.(\"\n",
      "batch 18412  loss=133.5506  steps/s=112.96  prediction: \"good at this and get bored\n",
      "\n",
      "one life man\" => \" o s casootot g                       e \"\n",
      "batch 18413  loss=142.4725  steps/s=99.11  prediction: \"chat is this what sweat equity means????\" => \"oae    teit t it t    t  t t  t  e eee e\"\n",
      "batch 18414  loss=167.3141  steps/s=85.58  prediction: \"t in a position to help you at all loool\" => \"hco  la   t  i sttit t     t   itt to ll\"\n",
      "batch 18415  loss=151.1759  steps/s=104.34  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"e ea eebe no  nopá´€[VðŸ¤£yá´x*ÊœX^||ðŸ‘Œ]â€*|;)|[y\"\n",
      "batch 18416  loss=143.0960  steps/s=104.02  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"er oea   aen  v       o  o  oo  o       \"\n",
      "batch 18417  loss=162.5968  steps/s=103.38  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \" ash s t   s  s oooo  ool onnnnn  nnn   \"\n",
      "batch 18418  loss=199.4875  steps/s=21.25  prediction: \"eply: @HSVSphere https://t.co/zrv3lw1wAE\" => \" ly: @o       gsoooo ooo\n",
      " nnnnnn  n     \"\n",
      "batch 18419  loss=146.6360  steps/s=107.68  prediction: \"ing ive wanted in life lol, complete 180\" => \"ng eie  ennenein n  i   ie  i lllllellle\"\n",
      "batch 18420  loss=154.6620  steps/s=96.94  prediction: \"TB you can just do things bro just do it\" => \"h  lm sennne   n    n   l         e    o\"\n",
      "batch 18421  loss=164.7843  steps/s=100.29  prediction: \"o make rlly complex interactive web apps\" => \"naa f d       e        ll      ele e eee\"\n",
      "batch 18422  loss=145.4117  steps/s=107.03  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e y eenletne eet e  y a a     a   aa    \"\n",
      "batch 18423  loss=167.0316  steps/s=55.22  prediction: \": @yacineMTB better start skilling up ig\" => \" @0xlun ooo rMsoNIj}xXx.j+v5.,@xQ@Xð—°NXkj\"\n",
      "batch 18424  loss=153.2753  steps/s=109.31  prediction: \" ad optimization, marketing agencies etc\" => \"tnte l   l to tiooiiiiiiaiiitiiaiaaeanie\"\n",
      "batch 18426  loss=154.3318  steps/s=103.66  prediction: \"having kids, etc) may be only palliative\" => \"enga  a       hii   i                   \"\n",
      "batch 18427  loss=149.7720  steps/s=105.94  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tns meneed dd n  d r   rrr r  rrrr  r  r\"\n",
      "batch 18428  loss=175.5437  steps/s=77.24  prediction: \"lose, but yet... https://t.co/ywD4Tld5qJ\" => \"ywe s  d a       r t ... ttttp///d  d ih\"\n",
      "batch 18430  loss=148.6783  steps/s=104.97  prediction: \"ful defensive ai to guard you in cyber,â€¦\" => \" l oe   ae,  ont\n",
      "v?~ð—ª?x@E\n",
      "g?,m@c?,ð—°ð—°ð—¶,â€¦â€¦\"\n",
      "batch 18431  loss=158.7834  steps/s=100.29  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"ene  ee aiv  tne\n",
      "I?]Êœ,`:?yg.,m\n",
      "]7,7bY,:ðŸ›‘\"\n",
      "batch 18432  loss=150.3672  steps/s=104.37  prediction: \"ace to both physical and mental reality.\" => \"lk t s tn en     tt s     a a        a a\"\n",
      "batch 18433  loss=166.9462  steps/s=101.15  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"toomo lnoooolleee  oo oooo oo  ooo too t\"\n",
      "batch 18434  loss=158.5414  steps/s=100.07  prediction: \"e irl. i dare u. https://t.co/NEk2CLBwti\" => \" m    t t          .     . ..ttt////////\"\n",
      "batch 18435  loss=144.0750  steps/s=103.03  prediction: \"ness should get\n",
      "otherwise skill issue ig\" => \" MT ooe re seshess s s  seeeeseessssssii\"\n",
      "batch 18436  loss=160.8372  steps/s=49.71  prediction: \"y: @yacineMTB ty @elonmusk for the dL/dW\" => \"  @n s nusus sh ss ee osseseeseessssssii\"\n",
      "batch 18437  loss=137.6508  steps/s=125.37  prediction: \"er this applies outside of chess as well\" => \" aosstsess  s  tts ss ss ss   o  s  s s \"\n",
      "batch 18439  loss=194.6806  steps/s=99.89  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"@heera eO%%%TTP OOOOO OO       tt///////\"\n",
      "batch 18440  loss=160.6988  steps/s=103.69  prediction: \"ls similar to me\n",
      "larger battery capacity\" => \"y   a neses s eses a   r er  e e rrearrr\"\n",
      "batch 18441  loss=154.2236  steps/s=105.92  prediction: \"k in college it worked for me super well\" => \"eaoab b    cc  c    l         e   ee eee\"\n",
      "batch 18442  loss=149.0808  steps/s=99.75  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ng  a  nl n gann   n o t  tttoott/tt///w\"\n",
      "batch 18443  loss=153.4734  steps/s=104.54  prediction: \"sk for, then train them to ask, then act\" => \" e t  h  tt   et     tt t tt          t \"\n",
      "batch 18444  loss=155.0586  steps/s=106.64  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ngM B  nneddd a    d      tt tttttttt///\"\n",
      "batch 18445  loss=151.5915  steps/s=97.32  prediction: \"feeling than automating hrs of work away\" => \" eh  eet T    sov00ð—µð—µð—µð—µ&0v,kð—¼&ð˜€ð—µz0ð˜€ð—µð˜zð—µ\n",
      "\"\n",
      "batch 18446  loss=173.3707  steps/s=51.37  prediction: \": @EsotericCofe what are you working on?\" => \" @y cieg s  suswv00b;kU+0v,k-qRUz0P3Pz?\n",
      "\"\n",
      "batch 18447  loss=140.8055  steps/s=107.27  prediction: \"to save this for later in case I forget\"\" => \"h   te l e                              \"\n",
      "batch 18448  loss=162.0994  steps/s=104.83  prediction: \"saas #developers https://t.co/GmrQaIKpLs\" => \" lce\n",
      "sh#ssss eeeseeessssesssessss///////\"\n",
      "batch 18449  loss=165.2121  steps/s=105.84  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"le es   \" s sses    @@ r rr rrrrr  r rra\"\n",
      "batch 18450  loss=168.9454  steps/s=103.41  prediction: \"manistic very very far but it was the pâ€¦\" => \"en    khd     o u7bB.v,,wð—µ)..I/,,JSb..II\"\n",
      "batch 18451  loss=149.1803  steps/s=104.48  prediction: \"g his own CAD thing and calls it dingcad\" => \" ie  bt  s n  h       nn  nn    nn  n   \"\n",
      "batch 18452  loss=147.7526  steps/s=102.23  prediction: \"utomatically imagine letters as colored?\" => \"s dh ououoo aaoaaaa aaa aalllatttt l    \"\n",
      "batch 18453  loss=141.2403  steps/s=103.01  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"aae nteI  p    vD@ð—°ð—°ð—°IcCAvIIfð—²vð—±ð—¯uð˜ð—¶ð—°bFF\"\n",
      "batch 18454  loss=176.2831  steps/s=95.80  prediction: \"i have good news https://t.co/C5gY0PwNAZ\" => \"nhm e t m  m e  e e   se    h sstt/t ///\"\n",
      "batch 18455  loss=153.9617  steps/s=103.54  prediction: \"ining data. The loss went down over time\" => \"n t  e nenttadnnneaa a    ee   e   nn   \"\n",
      "batch 18457  loss=145.8288  steps/s=99.49  prediction: \"gh Ive been wanting to do a wasm project\" => \"    tngn  l e  ee    en                 \"\n",
      "batch 18458  loss=144.1606  steps/s=98.55  prediction: \"erIntellectus the italians have returned\" => \" et  lt IheI eeeetett  ttt  aaaa aa a ae\"\n",
      "batch 18459  loss=156.5950  steps/s=103.45  prediction: \"how it is in c++. Trace them rays brotha\" => \"es a  lnol ss   i  +++++++              \"\n",
      "batch 18460  loss=147.1374  steps/s=104.37  prediction: \"ion, which allows better problem solving\" => \"nn  tte eotcoowo oooo  w  o   t   l  ell\"\n",
      "batch 18461  loss=156.5890  steps/s=104.26  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r    pe  t ttntir  t   ss rr rrssr  r r\"\n",
      "batch 18462  loss=140.9288  steps/s=102.35  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eyeinter  e     &@&/ð—µð—µð—µð—µð—µð—µIð—¼ð—»ð—»vð˜€ð˜€Ið˜€ð˜ð˜bð˜/\"\n",
      "batch 18463  loss=138.6370  steps/s=104.90  prediction: \"oncept but also show you how to apply it\" => \"n l  eeec cc c   c    o    o  ooo oo  o \"\n",
      "batch 18464  loss=167.6747  steps/s=97.04  prediction: \"t prototype done https://t.co/9pKpWZA02k\" => \" tn    oottnotttotoo oo    ot  tttpp/p/p\"\n",
      "batch 18465  loss=139.6107  steps/s=99.91  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"thi   i tggg   g  pppp pp               \"\n",
      "batch 18466  loss=142.8540  steps/s=104.83  prediction: \"ood direction to get more good direction\" => \"nl aegeroegdgoo eoooto   o  ooeo  ooo oo\"\n",
      "batch 18468  loss=148.2618  steps/s=104.32  prediction: \"es your data instead of storing the data\" => \" s knneietenntg aa   aaaat e    tt   t  \"\n",
      "batch 18469  loss=153.6986  steps/s=104.77  prediction: \"us example like this for numerous toolsâ€¦\" => \"st t l aenmerenmlmeemalee ile e  e  urer\"\n",
      "batch 18470  loss=146.0523  steps/s=100.42  prediction: \"ow is that i know nothing\n",
      "- some guy idk\" => \" s n t el  t    i    i i  t    t n  n n \"\n",
      "batch 18471  loss=149.9040  steps/s=102.22  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"toutohn  wt   no     i  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "e e gggggg\"\n",
      "batch 18472  loss=172.1401  steps/s=103.96  prediction: \"er did failed\n",
      "\n",
      "ðŸ“ˆ My hit rate is only abâ€¦\" => \"  rnd g nv r if  de   d    i  ii  t    i\"\n",
      "batch 18473  loss=158.2407  steps/s=103.54  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nn   e tintiitiit ttt   g  s so s gsssss\"\n",
      "batch 18474  loss=154.0316  steps/s=100.92  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" t  eunf t t nf    n    n  fof   ffffof \"\n",
      "batch 18475  loss=180.6730  steps/s=87.29  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \"r et wren  rrnh   of nf    ffff   t yR  \"\n",
      "batch 18476  loss=151.3839  steps/s=104.12  prediction: \" quarter is another kinda similar banger\" => \"@ue ee elne  e  n n  ri r  r aa  i ia a \"\n",
      "batch 18477  loss=166.8087  steps/s=104.29  prediction: \"wigABAP @yacineMTB avg lud vs selo match\" => \"hgh  eun@ @ @ riaABBB B B B        a a a\"\n",
      "batch 18478  loss=151.6263  steps/s=98.10  prediction: \" glitches\n",
      "your game is looking great btw\" => \"@oi  ae  gegl ge ee e ge         g  g  g\"\n",
      "batch 18479  loss=162.2819  steps/s=30.35  prediction: \"ply: @jaivinwylde top tier game for sure\" => \"ly: @Pisvecee ge ge e ae    o   og  go  \"\n",
      "batch 18480  loss=199.2387  steps/s=125.60  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"l SA  SAGGLLINLAIAAIAIAI A     /////////\"\n",
      "batch 18482  loss=169.0865  steps/s=100.24  prediction: \"t just means youre on par with a supergm\" => \" @o te@es s smssess ss s   o        e   \"\n",
      "batch 18483  loss=143.6611  steps/s=105.88  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \"te to t  ott  t  t  t t          u   u  \"\n",
      "batch 18484  loss=167.7527  steps/s=103.60  prediction: \" going straight there out of highschool)\" => \"teat eai  nn ihg tgit tttth   t  o    hh\"\n",
      "batch 18485  loss=150.1358  steps/s=103.41  prediction: \"ed for editing videos would be so goated\" => \"r oi  gn ned ede eeiidi iiddd   dod oo  \"\n",
      "batch 18486  loss=146.7686  steps/s=99.44  prediction: \"lsio recursive mind exploding adventures\" => \"y  el  rleeleiieeieiie ei   ee d idddd e\"\n",
      "batch 18488  loss=152.3680  steps/s=102.45  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"eply: reton niaikIh=MTB=@ETB=@Eâ˜ =Dwxð—¿v*~\"\n",
      "batch 18489  loss=149.1154  steps/s=105.00  prediction: \"\n",
      "\n",
      "A strategy in chess for example is toâ€¦\" => \"\n",
      "aoe( ed  w  oo ](ð—¯^â€Zá´˜/èµ°')â™‚]A]Éª[,|[([â€¦~\"\n",
      "batch 18490  loss=148.8077  steps/s=101.31  prediction: \" a while before I add it to the site tho\" => \"@ dy  i lil   ll      e e             tt\"\n",
      "batch 18491  loss=161.6956  steps/s=104.16  prediction: \"lf of that was way off. all good tho nbd\" => \"y o  m e h  t ta    f  ff fff  a     o  \"\n",
      "batch 18492  loss=153.5119  steps/s=104.03  prediction: \" which uses a superset of c. so not sure\" => \"ahi chtc c c   c    sss s s    s     s  \"\n",
      "batch 18493  loss=156.9162  steps/s=104.93  prediction: \"r months or yrs\n",
      "\n",
      "https://t.co/7N4QDEMGnO\" => \"ete t eosl t r eRDOD,v,:/f:.:7:7v47:4Q4Q\"\n",
      "batch 18495  loss=146.0106  steps/s=104.33  prediction: \"\n",
      "bc thats truly what your actions effect\" => \"\n",
      "tc e ne to  l by-@F,--F-.k#,,FF.CCvgvCðŸ›‘\"\n",
      "batch 18496  loss=147.5414  steps/s=105.33  prediction: \" could approximate non linear functionsâ€¦\" => \"ton   kt a t  ot    po ooao an  a n nnn \"\n",
      "batch 18497  loss=159.5739  steps/s=91.56  prediction: \"yan I have fun. does that make me a CEO?\" => \" cea tar  n n  taa    n n  a e aa   na  \"\n",
      "batch 18498  loss=145.8906  steps/s=103.68  prediction: \"ob/business but.. its fun to think about\" => \" l    n    b  o bbbssss ss   s     t   t\"\n",
      "batch 18499  loss=142.5984  steps/s=103.78  prediction: \"e seen it from all possible perspectives\" => \" aon  i  hee  e                l ss eeee\"\n",
      "batch 18500  loss=149.6276  steps/s=99.37  prediction: \"ok me a second but damn thats a good one\" => \"  eeesn    t  m o    s           att t  \"\n",
      "batch 18501  loss=149.4017  steps/s=105.57  prediction: \" is by how much detail you know about it\" => \"tn we ghg   n es     h               o  \"\n",
      "batch 18502  loss=161.0114  steps/s=99.83  prediction: \"oesnt matter if its not live.. but still\" => \"us   ths  s s  tettt i tt  it t       tt\"\n",
      "batch 18504  loss=148.7614  steps/s=103.96  prediction: \" life during hard times\n",
      "Thank God for it\" => \"tinp ien nmimine  i    i ri   i    d d  \"\n",
      "batch 18505  loss=144.4693  steps/s=104.74  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sa  en   s e e  e      t t ttt////////t\"\n",
      "batch 18506  loss=173.7971  steps/s=97.11  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"e slms s s e !h h e t   ttttt .ttt   uu \"\n",
      "batch 18507  loss=146.9305  steps/s=99.32  prediction: \"e or desire to practice for other things\" => \" saoptreterr  t rr  r  e  r c c re  r r \"\n",
      "batch 18508  loss=144.1272  steps/s=105.18  prediction: \"seless to ppl who dont know them already\" => \"   eeeaolse ese s  s       o  o         \"\n",
      "batch 18509  loss=178.3227  steps/s=104.18  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"tacl\n",
      "tt\n",
      "h///RQ1ottt1SSttS:S:tttt:/t/ttc/\"\n",
      "batch 18510  loss=222.7083  steps/s=21.52  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @t\n",
      "h///tttotSt1SSttt:::t/ttc///ttc/\"\n",
      "batch 18511  loss=154.8342  steps/s=107.57  prediction: \"lding w ai is gonna get left in the dust\" => \"e   dn  nndn iii                        \"\n",
      "batch 18512  loss=164.5706  steps/s=101.85  prediction: \"st went from rome to naples two days ago\" => \" uhre eaeet t r   tr t                t \"\n",
      "batch 18513  loss=166.9498  steps/s=103.82  prediction: \"ng up every word you hear more than once\" => \"   wor  oeon eo       o  rr r  r r  o r \"\n",
      "batch 18514  loss=147.6020  steps/s=104.32  prediction: \"ey reach great great heights\n",
      "\n",
      "you soundâ€¦\" => \"   tn  inh nn a e     e e eeeeegeehe    \"\n",
      "batch 18515  loss=146.7864  steps/s=100.69  prediction: \" in this article\n",
      "https://t.co/8gCd6cnXXP\" => \"t  tihnin iinieiiiiitttttttittttt///tt//\"\n",
      "batch 18516  loss=154.3359  steps/s=101.86  prediction: \" you have in mind\n",
      "\n",
      "extra debugging time?\" => \"toutthn sot    t          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " eegggggi\"\n",
      "batch 18517  loss=146.6349  steps/s=104.76  prediction: \"\n",
      "then do your own experiments from there\" => \"\n",
      "hhn t p$ mtaeq JJx/Êœqv`6q6],xg$qæˆ‘.{=',q\"\n",
      "batch 18518  loss=176.2742  steps/s=102.10  prediction: \"ot which will drain your web3 wallet. hâ€¦\" => \"nh e n  lhb  l  lli     i    w  w wlw   \"\n",
      "batch 18519  loss=147.7309  steps/s=102.42  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \"hr  t a eneeeeeneeeeeeleelllss ss  ssss \"\n",
      "batch 18520  loss=153.9305  steps/s=104.17  prediction: \"w, weve been going for a few weeks or so\" => \"  t  iit  n   w e eee   ee    e    e   e\"\n",
      "batch 18521  loss=159.2070  steps/s=103.77  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"ther noa   r re ro r  tt   tt s tt s///t\"\n",
      "batch 18522  loss=149.0321  steps/s=104.11  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" r n      n n e      n nnntntntttt/t////\"\n",
      "batch 18523  loss=162.7035  steps/s=103.82  prediction: \" i found it really hard for some things.\" => \"tn   st mn  o n  i       a              \"\n",
      "batch 18524  loss=147.9484  steps/s=104.02  prediction: \"es your data instead of storing the data\" => \" siinaeietenntg aa   aaaaa e    tt   t  \"\n",
      "batch 18525  loss=146.5521  steps/s=103.90  prediction: \" company dgaf and you can contact those?\" => \"to ee a n en anaaa a  a   n a a c c c c \"\n",
      "batch 18526  loss=149.7344  steps/s=105.21  prediction: \"aise), and we'd end up in the same place\" => \"tn nc noaeseaa a e ea  d dd  d  d       \"\n",
      "batch 18527  loss=149.8051  steps/s=104.57  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l n iw  eunn  o    o  ottt  ttttttttttet\"\n",
      "batch 18528  loss=141.9979  steps/s=102.81  prediction: \"oo, and the school wasn't even built yet\" => \"ndhat aa a    a                         \"\n",
      "batch 18529  loss=146.1953  steps/s=103.53  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \" ce aeiaen nniiiii iiittttttttttt/////st\"\n",
      "batch 18530  loss=141.2061  steps/s=102.48  prediction: \" different distribution of training data\" => \"tov evevth et eeeeeeetttiitiittttiiinini\"\n",
      "batch 18531  loss=154.4139  steps/s=103.64  prediction: \"ncoder-decoders\n",
      "\n",
      "https://t.co/bjOdSr4yjR\" => \" eoe er sodedeeeeeedeeeseetsete///////tj\"\n",
      "batch 18532  loss=158.6230  steps/s=101.34  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \" t e  nt    ni    i    s  sists s s s  t\"\n",
      "batch 18533  loss=146.5077  steps/s=102.95  prediction: \"our life if you make work look like this\" => \"n  a go    r  n i  i    o   o ko k kk kk\"\n",
      "batch 18534  loss=142.3647  steps/s=103.23  prediction: \"e, i would also have liked to be yacine\"\" => \"    a  n   n                            \"\n",
      "batch 18536  loss=144.4335  steps/s=103.96  prediction: \"ink in part bc you have more to remember\" => \"ng e et ii    i n                     r \"\n",
      "batch 18537  loss=149.9448  steps/s=104.93  prediction: \"n run on my laptop, which I can do w ML?\" => \" tr l nome                              \"\n",
      "batch 18538  loss=158.4798  steps/s=81.85  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"DSe a e  n  e n o o  ooo   ih   o  a    \"\n",
      "batch 18539  loss=143.7365  steps/s=105.05  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"en 1 timeèµ°S21isgk92@2222ck2I2CC94229u222\"\n",
      "batch 18540  loss=144.7699  steps/s=103.64  prediction: \" not abt to read through all of its code\" => \"te  ts  c  t  t        t    o  o        \"\n",
      "batch 18541  loss=166.1440  steps/s=105.19  prediction: \"ng up every word you hear more than once\" => \"    or  oeon eo       o  rr r  r r  o r \"\n",
      "batch 18542  loss=146.7649  steps/s=104.18  prediction: \"t\n",
      "so.. hopefully i can get it to do that\" => \" \n",
      "j a i    epeee                        \"\n",
      "batch 18544  loss=145.9312  steps/s=105.11  prediction: \"experience but i work w someone who does\" => \" pt  t nenn nepee eee e      e        oo\"\n",
      "batch 18545  loss=159.2807  steps/s=107.30  prediction: \" making anifusion in the first place btw\" => \"tastt  ttd  aannaiiniiinniiiiii i i     \"\n",
      "batch 18546  loss=185.2684  steps/s=51.55  prediction: \": @RajenJangam Thanks! Glad you liked it\" => \" @E @o @eneefeheB44MTBpT9!,Gyxxxpg2g22g2\"\n",
      "batch 18547  loss=172.2793  steps/s=132.82  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"ya ss snnet an@  hnnsh   st  t//  ///t  \"\n",
      "batch 18548  loss=148.4351  steps/s=97.68  prediction: \" sudo systemctl restart systemd-resolved\" => \"tep ap e h   sessssstttttttttstttrstsses\"\n",
      "batch 18550  loss=156.9253  steps/s=100.30  prediction: \"el editor and gameplay, that sounds cool\" => \" la   el l     d      a a aa aaaa a a   \"\n",
      "batch 18551  loss=143.1742  steps/s=104.74  prediction: \" us safe from undetectable Dyson spheres\" => \"ts e n nt enee f  e eeeeef  e e e e e ee\"\n",
      "batch 18552  loss=149.8840  steps/s=103.19  prediction: \"e some exciting long term vision then no\" => \" ao ontt  seteet   e e  e e    i iin  en\"\n",
      "batch 18553  loss=149.9165  steps/s=103.59  prediction: \"y mindset\n",
      "\n",
      "it spreads and is a contagion\" => \":ti e tt \n",
      "it tiitittt  tss sa s s  aa   \"\n",
      "batch 18555  loss=178.1640  steps/s=104.55  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nn rr #eeane ag na  nnnnn ttn/st//tt////\"\n",
      "batch 18556  loss=145.5186  steps/s=102.70  prediction: \"be distracted for longer periods of time\" => \"e l     s  d   n d dd d     r rr e r r e\"\n",
      "batch 18557  loss=145.8330  steps/s=102.56  prediction: \"e a great idea\n",
      "\n",
      "i should do this too tbh\" => \" aly   n a    a a     a       d      d  \"\n",
      "batch 18558  loss=158.3814  steps/s=102.81  prediction: \"tein I think\n",
      "carbs/sugar wreck my energy\" => \" r   ape tt ttntir  t   ss rr rrssr  r r\"\n",
      "batch 18560  loss=149.9527  steps/s=104.11  prediction: \"about things that have significant value\" => \"noe\"\n",
      " tts\n",
      "  ttet taa tt ta   hat  aiaa a\"\n",
      "batch 18561  loss=143.0675  steps/s=104.40  prediction: \"engagement-bait generating llm finetunes\" => \" t saaeneaeegeeggegeegeaeneeeenggnnntine\"\n",
      "batch 18562  loss=170.3844  steps/s=80.49  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"ni ea Bamnenbame eeeetannn    n  ee e ne\"\n",
      "batch 18563  loss=172.1133  steps/s=107.11  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nn r  #aaaaeeaa ##  nnnnn ttnnst//tt////\"\n",
      "batch 18564  loss=155.4014  steps/s=101.61  prediction: \"r model architecture not based on tokens\" => \"ebt  ceyrio r mo4qA2b9qAkkkv]-r\n",
      "v:k0l.ar\"\n",
      "batch 18565  loss=147.4850  steps/s=100.48  prediction: \"ers had a username but idk his name name\" => \"  @iete@mtt r e ea euea         a      e\"\n",
      "batch 18566  loss=144.4575  steps/s=105.65  prediction: \" in those days will have had it too easy\" => \"tt m \n",
      "  ss n  t s  is  s s  h i  hh    a\"\n",
      "batch 18567  loss=180.1926  steps/s=46.09  prediction: \"y: @EsotericCofe https://t.co/qJ19YldyDK\" => \"  @niosss\n",
      "s   hs   hs  s s  ha   h   a a\"\n",
      "batch 18569  loss=149.1013  steps/s=111.04  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"tsit et f ir t ratrattraahaaahhha hh  hh\"\n",
      "batch 18570  loss=147.8298  steps/s=100.79  prediction: \"ning arc, off in a remote cave somewhere\" => \"gni lt  iin  inn i                 e  e \"\n",
      "batch 18571  loss=144.4156  steps/s=102.70  prediction: \" bricked my laptop\n",
      "patronizing bloatware\" => \"tee ee  deer          pppppppppppppapaao\"\n",
      "batch 18572  loss=158.8289  steps/s=103.80  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly:  a eppoe  e     o   \n",
      "e  ho  ooow oo \"\n",
      "batch 18573  loss=153.0772  steps/s=102.10  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"toe i go r r   e    e e  g g  o g g    h\"\n",
      "batch 18574  loss=152.2316  steps/s=103.94  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tn teiitiinniniiniiniiiiiiiiiiii i ii   \"\n",
      "batch 18575  loss=155.1948  steps/s=105.63  prediction: \"can kick enemies away and they go flying\" => \"oneo   o        k            e    a   y \"\n",
      "batch 18576  loss=174.6950  steps/s=102.38  prediction: \"o fr tho im not) https://t.co/Qo0JnvIRSr\" => \" fuic orfn fo    o o  ooo  o tt o/// o//\"\n",
      "batch 18577  loss=154.7968  steps/s=103.15  prediction: \"be setting a deadline might help as well\" => \"e tii  k  ttt       e     e  e  e i ee  \"\n",
      "batch 18579  loss=149.2543  steps/s=104.87  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"00o 1 is a      0     h ht ttt/tt//t////\"\n",
      "batch 18580  loss=147.4335  steps/s=105.42  prediction: \"y abt compression, which is intelligence\" => \" th aapt aa   tt   a   i    ii iss iiii \"\n",
      "batch 18581  loss=144.1947  steps/s=104.54  prediction: \"mands it outputs\n",
      "https://t.co/dWiO4erSb1\" => \"andt erhosn  he F,=gg::/.((=wkWW:,,\n",
      ".Sb1\"\n",
      "batch 18582  loss=147.8216  steps/s=101.84  prediction: \"great great thurs\n",
      "key was blocking x lol\" => \" e eot  gt t tr t ttrt rrt s  srs   k   \"\n",
      "batch 18583  loss=199.8229  steps/s=88.41  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"t.chgtoteg//tto  ttt    st   ttsc////o o\"\n",
      "batch 18584  loss=145.5338  steps/s=106.35  prediction: \" use commonly are invisible fundamentals\" => \"tps pep e se  m mel   ee e le   e en ann\"\n",
      "batch 18586  loss=172.4366  steps/s=104.03  prediction: \"er did failed\n",
      "\n",
      "ðŸ“ˆ My hit rate is only abâ€¦\" => \"  rn  g nv r ei  de   d    i  ii  t    i\"\n",
      "batch 18587  loss=211.5754  steps/s=11.03  prediction: \"reply: @RGBCubed https://t.co/pXi52bngaE\" => \"eply: t9 eoos s hw0á´€bI4wIIðŸ“ˆâ€MÉªXðŸ“ˆ0Mb[wg/I\"\n",
      "batch 18588  loss=161.0789  steps/s=111.27  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tn ii h sniisshessststtstttttttt/t/////6\"\n",
      "batch 18589  loss=161.1838  steps/s=104.94  prediction: \"w the game state https://t.co/jm2YeI7PB9\" => \"hw     ce ne e t e  t t  ttttt tttt t//e\"\n",
      "batch 18590  loss=171.1063  steps/s=101.12  prediction: \" grows ur skills\n",
      "https://t.co/9ZBc4ushgS\" => \"trol  tt t ot g   ss  ssss ttss///st////\"\n",
      "batch 18591  loss=155.6394  steps/s=105.44  prediction: \" but back in the day thats how I learned\" => \"tuc chc  ic t e       t       th    a   \"\n",
      "batch 18592  loss=151.9076  steps/s=100.44  prediction: \"ok me a second but damn thats a good one\" => \"u c eatS   t  t e    aa    t    a  t aa \"\n",
      "batch 18593  loss=157.4291  steps/s=103.96  prediction: \"at the beginning\n",
      "https://t.co/3p7b8v9xhe\" => \"n e   t b tt  e  tttitnnntnttnttttttt///\"\n",
      "batch 18594  loss=156.5095  steps/s=38.98  prediction: \"ly: @horseracedpast Hows it goin so far?\" => \"y: @eel ettt     tttntnnnttttg/tttt/////\"\n",
      "batch 18595  loss=163.8656  steps/s=130.16  prediction: \"e IRL, its fundamentals all the way down\" => \" toai isa s s  ds t  tn  ttn nnnlaat all\"\n",
      "batch 18596  loss=190.7302  steps/s=100.55  prediction: \" NO BLACKPILLING https://t.co/djaWm13aKZ\" => \"tooI  st%ðŸ“‰LLKLLLNLLIINNILIItt /t//t ////\"\n",
      "batch 18597  loss=192.2841  steps/s=56.89  prediction: \" @Aryvyo Whoa\n",
      "You actually did pivot lol\" => \"tIRI e tKK LIIIIINILItt/t//tt/////tW/tat\"\n",
      "batch 18598  loss=150.8460  steps/s=113.04  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"to t  a Tt t  a  t    a a      i   i    \"\n",
      "batch 18600  loss=204.3613  steps/s=95.38  prediction: \"@___________11hz helped me out with mine\" => \"yInaatt ______________11111 eee e    e  \"\n",
      "batch 18601  loss=158.3399  steps/s=104.19  prediction: \"ing vidya except w only positive effects\" => \"ng  iie niggiiie     eee     y     eiii \"\n",
      "batch 18602  loss=146.1431  steps/s=104.68  prediction: \"\n",
      "\n",
      "saves a ton of headaches down the line\" => \"\n",
      "t en atul   uh 1pd_,-ðŸ’ªðŸ’ªg,vuqv,KðŸ’ªKKvwDDðŸ’ª\"\n",
      "batch 18603  loss=152.5720  steps/s=105.08  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"n  seeslt ete ae  eeaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 18604  loss=149.7984  steps/s=106.07  prediction: \"he case for some regions outside the US.\" => \"e   t   ee t sis s  e e e  ososo oes eee\"\n",
      "batch 18605  loss=148.4256  steps/s=104.57  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"000   is a    h 0     h httttttt///t////\"\n",
      "batch 18606  loss=169.0400  steps/s=102.68  prediction: \"uff\n",
      "\n",
      "1. frogbrot https://t.co/JfifQf9WWd\" => \" f n o a  d ffr\n",
      "\n",
      "\n",
      " ttttfttt//tttto///ffo\"\n",
      "batch 18607  loss=162.2129  steps/s=96.82  prediction: \"enko Could probably do this w ai now lol\" => \" d ffcnc oc oooorot  p pttbo  tot ff f  \"\n",
      "batch 18608  loss=166.3732  steps/s=99.23  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"nd  ik nir  o    bob  t  tts  s   to/o  \"\n",
      "batch 18609  loss=160.1796  steps/s=104.01  prediction: \"lf of that was way off. all good tho nbd\" => \"y t  a e h  t t        aa   a  a f   o  \"\n",
      "batch 18611  loss=140.1926  steps/s=104.64  prediction: \"to use resumes if lying becomes the meta\" => \"  i i a s seeessesess  e  e  eeee  ee  e\"\n",
      "batch 18612  loss=143.6903  steps/s=104.85  prediction: \" by breaking the file into smaller files\" => \"tuts hsb bb b e         e        e   lll\"\n",
      "batch 18613  loss=153.0084  steps/s=98.66  prediction: \"ewpantswhodis you have good taste brotha\" => \" _i  AeA nenen n i        ooo   oo   e  \"\n",
      "batch 18614  loss=149.2304  steps/s=105.88  prediction: \"e walking through a memory palace maybe)\" => \" d ll t  l e  ne       h   m o a a aa  a\"\n",
      "batch 18615  loss=141.9108  steps/s=98.23  prediction: \"s. let the people decide. for danmocracy\" => \"  tle teett te  ee  ee eeee ee eee de  c\"\n",
      "batch 18617  loss=152.3371  steps/s=95.34  prediction: \"an wrong something something bla bla bla\" => \"n   ne ln n  neg    g  oom nooggminn  b \"\n",
      "batch 18618  loss=160.6406  steps/s=105.14  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"e  i eir  r   o   t o  tot            v \"\n",
      "batch 18620  loss=152.1839  steps/s=95.78  prediction: \"farming simulator but with a circle tool\" => \" ml s e es hs hakyÊŸv]6Éª$`á´˜*`n\n",
      ".â€m,$*Ê€,\n",
      "d\"\n",
      "batch 18621  loss=146.4344  steps/s=97.35  prediction: \"us im in, gonna do this rn, on the rocks\" => \"st aamnd iimm nn i  nn  tt       r     o\"\n",
      "batch 18622  loss=176.3347  steps/s=101.46  prediction: \"ombies, lethal company, misc other stuff\" => \"u s  o t soet t l l l m ,, m c    o c st\"\n",
      "batch 18623  loss=148.4158  steps/s=102.24  prediction: \"you should do it, youd learn a ton i bet\" => \":u     n  n   no o  ooo do   o    o     \"\n",
      "batch 18624  loss=165.9153  steps/s=89.68  prediction: \"ach_ @pixqc that's smart. will try this.\" => \"nta   uo ooc   o t    d a    l t    l   \"\n",
      "batch 18625  loss=171.4866  steps/s=33.42  prediction: \"ply: @2wlearning https://t.co/8ri7u6xMxw\" => \"ly: @ts o c      t      a    l t    l  t\"\n",
      "batch 18626  loss=149.8756  steps/s=108.46  prediction: \"all the way down https://t.co/uP6ieWqBYQ\" => \"nl tatst naa    llta   tt  t//t //t  //t\"\n",
      "batch 18627  loss=186.4254  steps/s=94.83  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \":bana e n l   t h t ttt/////ttt:////cYQQ\"\n",
      "batch 18628  loss=167.8275  steps/s=101.82  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"s al  oo t000000000t ttttttttt///t///t/3\"\n",
      "batch 18629  loss=148.3181  steps/s=103.71  prediction: \" interesting to see what it hallucinates\" => \"tt  iu  itt ttttttt  t     t    tt  t   \"\n",
      "batch 18630  loss=147.6451  steps/s=98.92  prediction: \"but openai is cringe so obviously sonnet\" => \"et iie ntnnt    ii  i i  i      o  s oos\"\n",
      "batch 18631  loss=152.7262  steps/s=89.58  prediction: \"ake with two snakes would be interesting\" => \"le  Me  ii    et   w   sooo o o    onene\"\n",
      "batch 18632  loss=146.8681  steps/s=105.83  prediction: \"all the way down https://t.co/uP6ieWqBYQ\" => \"ns tils enaa    llta   tt  tatt /tt  //t\"\n",
      "batch 18633  loss=146.9173  steps/s=101.95  prediction: \"nd stop you from seeking rewards in life\" => \"dame aal l n ou  oo   o                 \"\n",
      "batch 18634  loss=159.9780  steps/s=102.85  prediction: \"uch working tomorrow, key is consistency\" => \"sh  ou ou otooo  oorooororo    o   oo so\"\n",
      "batch 18635  loss=152.5391  steps/s=88.08  prediction: \"eMTB i wonder which anime pfp is his alt\" => \"pTB o cin  t    oororr w i     ii  ss is\"\n",
      "batch 18636  loss=149.0896  steps/s=104.65  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"  c\n",
      " nesi       o                       \"\n",
      "batch 18637  loss=203.9451  steps/s=56.12  prediction: \" @458gdb @gizmobly @crypt0x_0 100% agree\" => \"tsui    df  o llo       l       e n   nr\"\n",
      "batch 18638  loss=158.6580  steps/s=115.66  prediction: \"n just do things https://t.co/909bTHzmml\" => \"garh i5 st      o      t t tt tttt999/9/\"\n",
      "batch 18639  loss=160.2275  steps/s=99.14  prediction: \"ple deep q network has achieved insanity\" => \"ly: @sp s  e ee e t    e t  h ahhha  aha\"\n",
      "batch 18640  loss=145.6101  steps/s=102.31  prediction: \"entation, the cooler everything will get\" => \" t   tm omeetthttttt oooeoeeeeeeeeee ei \"\n",
      "batch 18641  loss=159.1710  steps/s=95.62  prediction: \" @yotzol prelude in c major from scratch\" => \"@lot ono@o t o tle  e e e  i r r  orr r \"\n",
      "batch 18642  loss=143.4516  steps/s=97.72  prediction: \"he race to steal the eu tech bros begins\" => \"e l ao  otre e t et   e ee    ee   et   \"\n",
      "batch 18643  loss=164.6683  steps/s=49.40  prediction: \": @djcows you can make the jungle levels\" => \" @yae rhj@ancjon=pz@vjv0@0vd,,kxj.9mwj\n",
      "ðŸ’ª\"\n",
      "batch 18645  loss=149.0620  steps/s=107.83  prediction: \"all the way down https://t.co/uP6ieWqBYQ\" => \"nl tils enal    llta   tt  twtt //t  //t\"\n",
      "batch 18646  loss=161.4551  steps/s=92.72  prediction: \"yan I have fun. does that make me a CEO?\" => \":c nena   n a  n n    dtt  t/tt t e  me \"\n",
      "batch 18647  loss=151.3794  steps/s=104.67  prediction: \"ar mongering gets attention (clicks etc)\" => \"lee  e  es ene ee eee  ee ettntttnttt  t\"\n",
      "batch 18648  loss=178.1983  steps/s=100.83  prediction: \" you find running helps you work better?\" => \"touua nn bondnnd  nn  d n nu  innn  n e \"\n",
      "batch 18649  loss=164.6548  steps/s=100.93  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"tet   zn iiibni iibi   il  sotttoo/to/ct\"\n",
      "batch 18650  loss=168.0554  steps/s=101.91  prediction: \"t just means youre on par with a supergm\" => \"hma t lescs smssess  s o            o   \"\n",
      "batch 18651  loss=145.7451  steps/s=98.74  prediction: \" random cat or yours\n",
      "is rabies a concern\" => \"@e t       n  o   o   o  oorr r  rs s   \"\n",
      "batch 18653  loss=150.4410  steps/s=99.83  prediction: \"r switching if mint doesnt serve me well\" => \"eaeiv  hn\n",
      "\n",
      "ItvaeI'vIV.$W$ð—ª$|á´‡k$\n",
      ".dW$u:/y\"\n",
      "batch 18654  loss=150.4538  steps/s=105.09  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yat ds a nm l lsel l  sll lll ss tt/t///\"\n",
      "batch 18655  loss=158.4206  steps/s=103.33  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"em  t  c ,B,   fj'yI,.@jw:3,b.0jkyG,jVGz\"\n",
      "batch 18656  loss=174.7224  steps/s=100.65  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:  tnm    ppD0   0 000  0t /tt////t///\"\n",
      "batch 18657  loss=170.3601  steps/s=104.06  prediction: \"papers\n",
      "ooh definitely examples are great\" => \"lngo@ brte e  nrp  e o   eeiiee  eeee ee\"\n",
      "batch 18658  loss=148.2826  steps/s=101.76  prediction: \" Post it in the disc it helps us all out\" => \"@oo  llo       t                        \"\n",
      "batch 18659  loss=151.0318  steps/s=104.60  prediction: \"b, octane, trending on artstation 4k HD\"\" => \"e ni e,,  ,,,,d   en ae    nn nntntnn   \"\n",
      "batch 18660  loss=159.1968  steps/s=48.73  prediction: \"y: @justalexoki Oh shoot youre right nvm\" => \": @aea,aneaen dt  nnnoon   nt rttnt n   \"\n",
      "batch 18661  loss=147.2685  steps/s=110.01  prediction: \" and realized idk what it actually means\" => \"tb  hf n n f  ne  ddd d dd dia   a aa a \"\n",
      "batch 18662  loss=164.0427  steps/s=105.38  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tud)io d   ddd d        a      ss s     \"\n",
      "batch 18663  loss=159.0811  steps/s=99.74  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  +eed eeed ldoeo eeette tttttt t   t   \"\n",
      "batch 18664  loss=175.6114  steps/s=77.48  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ydede lrdodde d  tt  ttp tt  t  L L f a \"\n",
      "batch 18665  loss=141.2485  steps/s=107.33  prediction: \" adding the context into the computation\" => \"ind    toe r   ee ooe t  t ntee te ttttt\"\n",
      "batch 18666  loss=149.2908  steps/s=104.52  prediction: \"dont just mean wrt doing logic with them\" => \"   it rd a d na n   n   n     n   t t  i\"\n",
      "batch 18667  loss=157.4447  steps/s=100.19  prediction: \" surprised at how clean of a read it was\" => \"ion een s ss  as     s         a  a     \"\n",
      "batch 18668  loss=151.6007  steps/s=102.41  prediction: \"icians and is a net negative for society\" => \"n m iatci ttiant   a   n  a a   t      e\"\n",
      "batch 18669  loss=143.1429  steps/s=108.47  prediction: \"yself infinite runway to build fun stuff\" => \" tid it em niff ii iin in   i i      t  \"\n",
      "batch 18670  loss=144.2081  steps/s=104.25  prediction: \"be distracted for longer periods of time\" => \"e       s  d   n d dd d     r rr e r r e\"\n",
      "batch 18671  loss=186.0979  steps/s=61.14  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"leddbd s $idd d     o r  ee rrr rfor!   \"\n",
      "batch 18672  loss=142.5064  steps/s=106.21  prediction: \"th `sudo service NetworkManager restart`\" => \" e   tetn  e rhr e s  ee e we eereeerere\"\n",
      "batch 18673  loss=150.4868  steps/s=104.80  prediction: \"re much lower on time than your opponent\" => \"e oene fefh  knt...%%,&fk%RRfnEEfvEf55w%\"\n",
      "batch 18674  loss=156.7263  steps/s=102.08  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \" to  yu ruut ur   t i ttttt tttt///////Q\"\n",
      "batch 18676  loss=146.0244  steps/s=99.98  prediction: \"pen theatre stairs door and ruin the run\" => \"lr  @  c   tttttte t    ao     rr      r\"\n",
      "batch 18677  loss=159.0587  steps/s=98.35  prediction: \"n pulls models too, but only from github\" => \" ga eaot n    aes  oooso  oo   ot   o   \"\n",
      "batch 18678  loss=153.7651  steps/s=102.97  prediction: \"nd mental storage/organization efficient\" => \"  ueenom t  t t eent   enat  antaaiioeie\"\n",
      "batch 18679  loss=154.3951  steps/s=104.48  prediction: \"te how much some debuffs will damage yoâ€¦\" => \" m    f the eee tt    m  e    e      e  \"\n",
      "batch 18680  loss=149.5094  steps/s=104.00  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \"ne aee   e    et  t hthhttthtttt/tt/////\"\n",
      "batch 18681  loss=184.1844  steps/s=22.34  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @ee dete e   t hthhtttttttt///////h\"\n",
      "batch 18682  loss=156.0203  steps/s=123.56  prediction: \"onscious does work in the background idk\" => \"  tbmnb n ns  ocoo   oo   oo   o kk   o \"\n",
      "batch 18683  loss=141.9494  steps/s=104.06  prediction: \"ve to or weak squares/pieces etc etc etc\" => \"e s ess  e   e       e  e   eeeeeee eeee\"\n",
      "batch 18684  loss=152.2985  steps/s=102.28  prediction: \"y visualize fundamentals is super useful\" => \" to ilt liilili iill la aaa ssss  ssssss\"\n",
      "batch 18685  loss=152.1126  steps/s=104.35  prediction: \"memory of doing a hard thing in the past\" => \"e h eitsaieeps sv}[,ð—¶[GpðŸ›‘Êœ*{Gk\n",
      "\n",
      "*x**èµ°b][\"\n",
      "batch 18686  loss=148.5746  steps/s=103.50  prediction: \"ession youll do something until its done\" => \"   e  peppeeperl o  oooooooo     i i i  \"\n",
      "batch 18687  loss=142.2815  steps/s=104.68  prediction: \"f you could 1.2x all the engineers there\" => \" aoane nie\n",
      "v``$BqNv6,{v6á´ð—²*Q,Má´¡1.21.2xÊœÊœ\"\n",
      "batch 18688  loss=165.1083  steps/s=102.70  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" te o   rg n  o e  o o   ooo ooeo   f f \"\n",
      "batch 18689  loss=146.1150  steps/s=105.21  prediction: \". some, years later, have paid off a ton\" => \" so s  r  seeeese  e eeeee  aaa aaa    a\"\n",
      "batch 18690  loss=156.8787  steps/s=103.56  prediction: \"ting should not be taking customer calls\" => \"hceri, f   guou nno no  nonnn  t  tt t  \"\n",
      "batch 18691  loss=144.8604  steps/s=100.28  prediction: \"pen theatre stairs door and ruin the run\" => \"l   @  g e tetttte t    ta     rr      r\"\n",
      "batch 18692  loss=140.5153  steps/s=104.46  prediction: \" a long line? aight imma work on bug xyz\" => \"t  tn a  nn \n",
      " nnn  n n  iii    i        \"\n",
      "batch 18693  loss=177.8213  steps/s=103.96  prediction: \"OHN and some edm\n",
      "https://t.co/lnkXHuFGxu\" => \"OO\n",
      "\n",
      "\n",
      "  fon  n   d      d   tt ///tt/////\"\n",
      "batch 18694  loss=151.9789  steps/s=79.73  prediction: \"ki i have an idea but it will cost $1600\" => \"en\n",
      "  ana i          a  e tttt   tt t t  \"\n",
      "batch 18695  loss=171.0938  steps/s=107.73  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tf    o     ri    \n",
      "     a pp   lll     r\"\n",
      "batch 18696  loss=151.9394  steps/s=103.90  prediction: \"ull potential. That would be surprising.\" => \"sd ot  t htt tt  t   tttlt ttll         \"\n",
      "batch 18697  loss=158.9388  steps/s=99.72  prediction: \"rse21 doing is a fundamental of learning\" => \"e,n  m cte a @tsy21IkGw21ObO21pOO,Og,LL.\"\n",
      "batch 18698  loss=160.7827  steps/s=105.36  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \" raata\n",
      "\n",
      "l\n",
      "aLoo  aalallllllllllct/tt/t///\"\n",
      "batch 18699  loss=154.2608  steps/s=105.12  prediction: \" approximate it better outcompete others\" => \"tbl l uter rm  t aat ett ettt   teteteto\"\n",
      "batch 18700  loss=198.2596  steps/s=100.48  prediction: \"RAFT clone?????? https://t.co/LpT9VeD8p0\" => \"  ptCa c l l l  ???????????tttttt///////\"\n",
      "batch 18701  loss=145.1685  steps/s=105.17  prediction: \"more efficient parameters in the network\" => \"evei) oh)ha  ha)Q?h?v,6})Q,ð—°],?|Êœ????ðŸ§ â€™â€\"\n",
      "batch 18702  loss=153.5640  steps/s=104.00  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "Tuprnen t c tt ðŸ¤¯I,6ÊŸ,vXðŸ‘I,,É´*ð—±{ð—±â™‚,,Iá´€uðŸ›‘\"\n",
      "batch 18703  loss=142.3607  steps/s=102.90  prediction: \"he audiobook content is better than both\" => \"e o bh thuuououoooooooooo ttttttttttt tt\"\n",
      "batch 18704  loss=153.7536  steps/s=100.64  prediction: \" for yourself they pay dividends forever\" => \"touoo doo ooo ooo    o   y y y y  d  ded\"\n",
      "batch 18705  loss=171.0660  steps/s=52.17  prediction: \": @moh1xabc i cooked so hard i burned it\" => \" @7eee 5ne  nbanxIIgZ,v~ðŸ˜¤I,,[Ê€?]kf,,Ik?c\"\n",
      "batch 18706  loss=149.0835  steps/s=108.19  prediction: \"g down other hard but unproductive paths\" => \" to   edee on n  o    o   r r    r   u t\"\n",
      "batch 18707  loss=152.3624  steps/s=104.68  prediction: \", its everywhere https://t.co/hHirNEgYqf\" => \" aob,tr, e  e e rtr  er  ttetr /t/ee///t\"\n",
      "batch 18708  loss=164.7859  steps/s=102.00  prediction: \"he making a dingboard clone or something\" => \"e i gogd gg eig    igi         d     o  \"\n",
      "batch 18709  loss=152.2609  steps/s=96.60  prediction: \"ake with two snakes would be interesting\" => \"re,  tl g    ngt   w   ooo    oe  eein e\"\n",
      "batch 18710  loss=142.6570  steps/s=95.39  prediction: \" thanks man! i should uh sleep more yeah\" => \"th n aht ntat t  s s  s       le eeee  e\"\n",
      "batch 18711  loss=161.3631  steps/s=100.65  prediction: \"t just means youre on par with a supergm\" => \" ta t l snmt mssms   u o  ee            \"\n",
      "batch 18712  loss=158.4597  steps/s=103.16  prediction: \"many roadblocks trying to automate stuff\" => \"ey  itnnee met tMIpIpfAIAn!fwIkwkð—¯/dbpb:\"\n",
      "batch 18713  loss=176.6447  steps/s=101.91  prediction: \"an just do this: https://t.co/1xgV5Vs635\" => \"rd _ta_ ontu t  ut  tstt t:: :t/t  /ttVV\"\n",
      "batch 18714  loss=155.9731  steps/s=98.25  prediction: \"r cool. i wish llms were better with zig\" => \"etln erbnz neaprjyj_X..f}juká´‡pjlm/\n",
      "..c//\"\n",
      "batch 18715  loss=144.9751  steps/s=104.08  prediction: \"oast. silencio until youve made progress\" => \"u  t t sott s is t ii iii i  o          \"\n",
      "batch 18716  loss=143.7535  steps/s=104.98  prediction: \" does blade+motor=tablesaw or battlebot?\" => \"tearerh r steehs ee+ooooetoaeoeoaaaboabb\"\n",
      "batch 18717  loss=148.4371  steps/s=104.14  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yi h   tt it t     t  tt tttttttt/////YY\"\n",
      "batch 18718  loss=155.1652  steps/s=102.79  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"rd tat eeaaa  naaannaaeeee neeent ee e e\"\n",
      "batch 18719  loss=145.9965  steps/s=101.57  prediction: \"e drew your whole country as the soyjack\" => \" au o i rrrr  r  r  r  ro oo   oo    y  \"\n",
      "batch 18721  loss=175.8134  steps/s=61.22  prediction: \" @skydotcs @0xluffyb @levelsio bro ships\" => \"tya r  o  rrr er e oe  r    o  o   o  h \"\n",
      "batch 18723  loss=152.6227  steps/s=108.89  prediction: \" the past two months and its so worth it\" => \"toe ton  ae t et o ttt    t t t s s so s\"\n",
      "batch 18724  loss=152.6599  steps/s=102.90  prediction: \" anyways\n",
      "might as well switch in advance\" => \"tn r nee ane awm aaa  wa a aw w  ww  s  \"\n",
      "batch 18726  loss=171.2242  steps/s=98.55  prediction: \"ut 20,000 times? https://t.co/herw3K3aAI\" => \"s aa    0t00 000000   ss tt ttt t///////\"\n",
      "batch 18727  loss=154.4525  steps/s=104.24  prediction: \"gram faster which made him have more fun\" => \" ae a  err re r  ar h hh hhh  h mh mh m \"\n",
      "batch 18728  loss=156.8211  steps/s=104.63  prediction: \"itor as I was with 2 screens and a mouse\" => \"n a a asat n   s    a w       s   s s   \"\n",
      "batch 18729  loss=156.5788  steps/s=104.16  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  t e   b bb  bb bb b b             o\"\n",
      "batch 18730  loss=150.2173  steps/s=103.25  prediction: \" of just doing what fundamentally worked\" => \"tn ttte s tts t     t     d a  na aa  aa\"\n",
      "batch 18731  loss=156.8535  steps/s=104.98  prediction: \"\" and idk what that is? Time to learn it\" => \" aa  \"\"iai  naa     a                   \"\n",
      "batch 18732  loss=182.3017  steps/s=83.76  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"u aisnde a dd a    OO   OO            t \"\n",
      "batch 18733  loss=148.6612  steps/s=105.14  prediction: \"nd seem more limited in possible results\" => \"g ara ates  m n em em ee i m  i ie se se\"\n",
      "batch 18734  loss=161.5569  steps/s=99.60  prediction: \"hess isnt hard just make the right moves\" => \"ir   n s s n isii s  s    t t  h e ett t\"\n",
      "batch 18735  loss=151.5682  steps/s=99.63  prediction: \" it\n",
      "Nice nice\n",
      "Those are insane gains wtf\" => \"ts   teutyteeeieeee eeeieieeeie eeee ee \"\n",
      "batch 18737  loss=145.7119  steps/s=105.12  prediction: \"als and make smaller and smaller circles\" => \"rl  ee e nanmaenaam aaam aaall aallma ll\"\n",
      "batch 18738  loss=167.9944  steps/s=53.54  prediction: \": @djcows you can make the jungle levels\" => \" @lalenhelo nke b%kpOTjwk4O'2kUjf%kwbjgb\"\n",
      "batch 18739  loss=234.4865  steps/s=121.25  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"he Oh emMO  OOEOEPPPPMEEEEEE E/t// ///cs\"\n",
      "batch 18740  loss=149.0886  steps/s=101.37  prediction: \"just happen to have sicilian parents lol\" => \"ust llh e  t  t  e    e        a  i    a\"\n",
      "batch 18741  loss=147.9089  steps/s=104.78  prediction: \"learn thing -&gt; compress thing, repeat\" => \"yxo )neendenrn engng ngn gtg t s g gtg  \"\n",
      "batch 18743  loss=148.9217  steps/s=102.36  prediction: \"b, octane, trending on artstation 4k HD\"\" => \"e ,a e,,  ,,,,d   en ae    nn nntntnn   \"\n",
      "batch 18744  loss=165.7353  steps/s=93.90  prediction: \"sha Keep grinding ig\n",
      "\n",
      "Ppl love to see it\" => \" are a  n ene rrnenngin ng ng otto  o o \"\n",
      "batch 18745  loss=156.1175  steps/s=104.41  prediction: \"dvanced with it \n",
      "https://t.co/QLl4s598Uy\" => \" in an y ne v  v       tttttttttt///////\"\n",
      "batch 18746  loss=190.0247  steps/s=20.70  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @d deevv  e  t t  tttttttt/t///////\"\n",
      "batch 18747  loss=134.3230  steps/s=116.18  prediction: \" the skill ceiling is really really high\" => \"to   e l  t t  lll lliiiiiiillllllllllll\"\n",
      "batch 18748  loss=152.1203  steps/s=104.61  prediction: \" but vanilla obsidian seems very mid imo\" => \"tedewenvruuu  eeu luall    sa aa    ev i\"\n",
      "batch 18749  loss=152.4262  steps/s=103.42  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"nlet t t t  t   t  t                    \"\n",
      "batch 18750  loss=151.6036  steps/s=103.94  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te    et      tt  t  tto ttttttt/t//t//o\"\n",
      "batch 18751  loss=164.2297  steps/s=104.89  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"toe  U   nt   ne  e      ttt e/z/tz/tt/t\"\n",
      "batch 18752  loss=162.1333  steps/s=95.28  prediction: \"h mines a $10 quintillion metal asteroid\" => \"eD  st cntUUiein   i    in i  iiiiliittt\"\n",
      "batch 18753  loss=144.4685  steps/s=103.99  prediction: \"ink not tho, I believe in synthetic data\" => \"ng f t i inhntt  t    t            i   e\"\n",
      "batch 18754  loss=149.9743  steps/s=104.19  prediction: \"em all the cool ML stuff out there thatâ€¦\" => \"  e   t   l l  ll    l            t  tt \"\n",
      "batch 18755  loss=164.4698  steps/s=101.22  prediction: \"ur enemy when they are making a mistake\"\" => \"t  ntueereer ehe r eeey  e  t  ye  m  a \"\n",
      "batch 18756  loss=146.2769  steps/s=104.56  prediction: \"l tools for myself and they save me time\" => \"yp  ue uuu loo ll  l  ff                \"\n",
      "batch 18757  loss=140.9830  steps/s=98.31  prediction: \" takes a lot of work and years of it tho\" => \"aoe   inse  s    o o   o       e e  e   \"\n",
      "batch 18758  loss=155.1092  steps/s=99.83  prediction: \" seems to be doing pretty good with both\" => \"too e g sae  e     e  e        e  to oot\"\n",
      "batch 18759  loss=142.8227  steps/s=103.32  prediction: \" eu would lose half its talent overnight\" => \"tvee  m  leneel  eel   le   ll   l   t  \"\n",
      "batch 18760  loss=143.5260  steps/s=105.30  prediction: \" keep doing it for more and more phrases\" => \"tne naenneegneeee e                 r   \"\n",
      "batch 18761  loss=145.4512  steps/s=104.87  prediction: \"ob/business but.. its fun to think about\" => \"nl    n n  b  o sssssss ss   s     t   t\"\n",
      "batch 18762  loss=143.4488  steps/s=104.57  prediction: \" information for improvement, like above\" => \"tt l  anenniniffoioo ooioooiomooomem   e\"\n",
      "batch 18763  loss=164.1736  steps/s=105.15  prediction: \"ed in joining, repeat these instructions\" => \"  l  r tnenneeieinnie enee    eneteettet\"\n",
      "batch 18764  loss=135.1310  steps/s=101.19  prediction: \"ood at noticing things, would be so kino\" => \"uk hteg got go ttttttigiiiii            \"\n",
      "batch 18765  loss=182.5458  steps/s=105.81  prediction: \"w many GFLOPS? Are these legal in CA????\" => \" t  @o o o  ona   n  n    e   e   e    ?\"\n",
      "batch 18766  loss=158.0894  steps/s=104.80  prediction: \"orn to make cash forced to consooolidate\" => \"u t= ttit tt          c cc c  co ooooooo\"\n",
      "batch 18767  loss=140.6021  steps/s=99.64  prediction: \" ill dm you a link to it around the 25th\" => \"@n eteete t   el                     t  \"\n",
      "batch 18768  loss=159.0543  steps/s=102.67  prediction: \"owing that your food supply doesnt scale\" => \"u    taat n t  ttt     oo      o o  o   \"\n",
      "batch 18769  loss=144.9375  steps/s=105.21  prediction: \"\n",
      "bc thats truly what your actions effect\" => \"\n",
      "ou e ne t   l  2525,55Y5Y55,55K9Q6vgvK6\"\n",
      "batch 18770  loss=156.8237  steps/s=103.79  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"tdertpnr eetaenreaa   aattaattttt////t//\"\n",
      "batch 18771  loss=165.6390  steps/s=101.75  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" te o  nrg n  o e  ooo   ooo  ooo   o e \"\n",
      "batch 18772  loss=150.1883  steps/s=101.24  prediction: \"ly know how many angels fit on a pinhead\" => \"y: @nn l l n    w   n   n  n n        n \"\n",
      "batch 18773  loss=158.3108  steps/s=96.94  prediction: \"ded something to edit gifs/clips quickly\" => \" dnean   edeenhn e ee e    ti ii ii  iii\"\n",
      "batch 18774  loss=148.8542  steps/s=103.76  prediction: \"self tho prob cause that sounds more fun\" => \"  mm  hsse m  et      e  s  t stss  so  \"\n",
      "batch 18775  loss=160.6171  steps/s=101.89  prediction: \"f flipped around https://t.co/tQfmcgFqBM\" => \"fph  t g t  neg \n",
      "!,!!\n",
      "vv!..!:bQQ.v%FFQBl\"\n",
      "batch 18776  loss=158.3147  steps/s=102.21  prediction: \"blue, someone is working harder than you\" => \"ee   les  rs esee e  e eo    e  or      \"\n",
      "batch 18777  loss=149.4499  steps/s=103.89  prediction: \"ite complexity? If not, what is the max?\" => \"n ie dii nini it ii t i       t  t      \"\n",
      "batch 18778  loss=148.8976  steps/s=105.62  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \":tr a t ta n  ju       n    t    LLLL nL\"\n",
      "batch 18779  loss=161.0022  steps/s=100.60  prediction: \"ho. i like it much much better than rome\" => \"e. itsoni  nooen    t i    t    th    tt\"\n",
      "batch 18780  loss=158.1716  steps/s=108.51  prediction: \"B GPT isnt wrong, just ahead of its time\" => \" @ i ns i n     n   u     tt    tt    tt\"\n",
      "batch 18781  loss=185.7697  steps/s=90.57  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \":jone   n n   g n g t tth  httt a//t tGc\"\n",
      "batch 18782  loss=145.0260  steps/s=103.82  prediction: \"ans are measured in centuries. (im ngmi)\" => \"n  nMTBTB  e        e  ser e eeceee nii \"\n",
      "batch 18783  loss=152.7868  steps/s=104.86  prediction: \"e and remember as much as possible after\" => \" iia c s      mme e mmmmme     s  s  sss\"\n",
      "batch 18785  loss=174.2401  steps/s=104.28  prediction: \"77 oh whoa i didnt know abt tabs, thanks\" => \"   yxaeabcbr7  h  d             bbb  b b\"\n",
      "batch 18786  loss=142.9505  steps/s=105.00  prediction: \"be helpful, so I recommend taking a look\" => \"ett    ell l lb   l    e         e      \"\n",
      "batch 18787  loss=199.8154  steps/s=100.21  prediction: \"1 @yacineMTB just dmd you the term sheet\" => \" (ua enn a en5r 15@41z@34MTBFjTBDjMTBDjg\"\n",
      "batch 18788  loss=164.5136  steps/s=64.49  prediction: \"opaeoh Duuuude lets go this is awesome!!\" => \" e esaa an@ e juue   m  d d td  e m  m e\"\n",
      "batch 18789  loss=187.3131  steps/s=35.73  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @s ae ue euue   e  d d ti  e m  mee\"\n",
      "batch 18790  loss=153.0953  steps/s=143.77  prediction: \"arcyan now you can make pokemon real too\" => \"ne  3e  nuu   u ue   u  o  ots  e mo see\"\n",
      "batch 18791  loss=176.5878  steps/s=37.07  prediction: \"ply: @2wlearning https://t.co/8ri7u6xMxw\" => \"ly: @l  i y   e ue   e  o  oke  e em tee\"\n",
      "batch 18792  loss=149.5254  steps/s=106.19  prediction: \"xample\n",
      "Do this and then train them on it\" => \" c defo tm ememtoe  t    t   t t thn  tt\"\n",
      "batch 18793  loss=144.5623  steps/s=104.58  prediction: \"ody wake up??\n",
      "Youve killed us all skooks\" => \"neno ne nn     n o???????ee    u u     l\"\n",
      "batch 18794  loss=152.3014  steps/s=95.16  prediction: \" its a sign you should make react in zig\" => \"tt owAAA      n  s   uuou  u           a\"\n",
      "batch 18795  loss=172.4085  steps/s=103.26  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"nthe l \n",
      "///TT///th thZZZZWZ Z  t a..1  1\"\n",
      "batch 18796  loss=210.0707  steps/s=10.92  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"eply: @t n   p  ECWjZxCW(ZxCW(ZxZx(1.5S)\"\n",
      "batch 18797  loss=164.0708  steps/s=100.14  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tudat  d e ddd d        a      ss ss  s \"\n",
      "batch 18798  loss=151.0895  steps/s=101.81  prediction: \"xes this (whether you want it to or not)\" => \" d wsinsws  sses  s   hh   h  t tt  t   \"\n",
      "batch 18799  loss=167.8162  steps/s=83.20  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \" l@ s s  e s   w ehee e    t  t tt  oo  \"\n",
      "batch 18800  loss=144.3772  steps/s=99.23  prediction: \"ob/business but.. its fun to think about\" => \"nl    n n  b  o sbbssss sss  s     t   t\"\n",
      "batch 18801  loss=158.7228  steps/s=77.28  prediction: \"daily Whats your roadmap for learning ml\" => \" n   ioeso s  ss   ts    u           nn \"\n",
      "batch 18802  loss=150.5080  steps/s=101.00  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"tu   a   a n  h  i i o  i  i io i       \"\n",
      "batch 18803  loss=155.7949  steps/s=105.89  prediction: \"ore descriptive titles for the rest lool\" => \"nk i   eene d  teeiiiiiieee e ttre e  tt\"\n",
      "batch 18804  loss=190.3644  steps/s=10.54  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"eply: @n  ntee  I67IdIdc6cp-pvvvGgX7lqIc\"\n",
      "batch 18805  loss=166.4717  steps/s=107.61  prediction: \"expected him to be maybe 55 or something\" => \" a  n   Ie eses       ee  ee    555     \"\n",
      "batch 18806  loss=143.5076  steps/s=99.51  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"  a aty       e   e   ttthhttttt////t///\"\n",
      "batch 18807  loss=141.3270  steps/s=102.88  prediction: \"i is a smart idea to pitch to the public\" => \"nt oo  oo o    s      a   ii tt  i tt t \"\n",
      "batch 18808  loss=149.0674  steps/s=101.01  prediction: \" The fundamentals contain the most alpha\" => \"the aenA n  a dnaa   naaa tatt t  tttt  \"\n",
      "batch 18809  loss=150.1063  steps/s=111.66  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e n  ranmer tLurvOT=wv&bO/O.b:+===&;;;^^\"\n",
      "batch 18810  loss=147.3465  steps/s=109.89  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"AnoiiAae  neeete eeee  e    e   s   ss  \"\n",
      "batch 18811  loss=160.7242  steps/s=108.70  prediction: \"ree simple moves to DESTROY any opponent\" => \"eply rou nwrnd aP1@yMT&RvMTd^xvDESTRODES\"\n",
      "batch 18812  loss=223.2270  steps/s=84.40  prediction: \"OT MOVEMENT LADS https://t.co/NxHblUdYfq\" => \"h 0LWe  OTMVEOEee N DDDSSttt  / /  ooooN\"\n",
      "batch 18813  loss=162.3428  steps/s=98.06  prediction: \"ething. @dnbt777 https://t.co/i9PslcwipA\" => \" ton e ot o  o  tt77777  ttt7ttttt.////s\"\n",
      "batch 18815  loss=143.0757  steps/s=103.47  prediction: \"ad a concept of \"I\" they would probablyâ€¦\" => \"ro sc s     t         \" \" \"\"         o  \"\n",
      "batch 18816  loss=145.5946  steps/s=100.67  prediction: \"ns you get the yellow letters on lichess\" => \"  t o ty it e t   te  ee  lellee ee  ee \"\n",
      "batch 18817  loss=150.0445  steps/s=87.93  prediction: \"y be a way to do it without grad descent\" => \":ho tte t                t  t  t  t  o  \"\n",
      "batch 18818  loss=169.7946  steps/s=110.75  prediction: \"erous people, very sad, but also fixable\" => \" e nnse nhe  eeeeeeeee e   e       s    \"\n",
      "batch 18819  loss=172.5375  steps/s=93.75  prediction: \"fects the rest of the day. Cheers brotha\" => \" e o  o ea   OinOOOOOOcOOOCCOO7p.SCxpOgk\"\n",
      "batch 18820  loss=171.7447  steps/s=104.77  prediction: \"n and are kindaâ€¦ https://t.co/zyjcsUAF4i\" => \"gmoi an  iin nnd a   a   a  tt t//t/////\"\n",
      "batch 18821  loss=140.4953  steps/s=103.18  prediction: \"t channel you found that effing exploded\" => \"hwe   a  t nn hnn  n           n     f  \"\n",
      "batch 18822  loss=154.9436  steps/s=91.81  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" seerepentemeremmmen me eoen n t  t ntn \"\n",
      "batch 18824  loss=172.1381  steps/s=110.93  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"noheQsoe////ot/tt/55tttot:/tt/t:/t//tt/t\"\n",
      "batch 18825  loss=150.9189  steps/s=109.54  prediction: \"\n",
      "\n",
      "\"fly over xyz tourist location for $5\"\" => \"\n",
      "w a  @phs l za\"j,fx\"z,:bxvzk:xEzqLN$j\"k\"\n",
      "batch 18826  loss=171.4061  steps/s=108.19  prediction: \"ff has been helping ppl. I love humanity\" => \"fy ta t odst @e P,@0fT,:bxbk.:IbkcQ:.TIðŸ›‘\"\n",
      "batch 18827  loss=162.1097  steps/s=37.54  prediction: \"ply: @jaivinwylde top tier game for sure\" => \"ly: @eertefs   ee  e   ee   llpp    ll e\"\n",
      "batch 18828  loss=142.7286  steps/s=116.38  prediction: \"a wave of weird suspensions going around\" => \"nte  tte te   es e  e  s s sss s sio  so\"\n",
      "batch 18829  loss=141.1841  steps/s=103.22  prediction: \"or a site with a manipulatable algorithm\" => \" _a t nooto   a       a  a aaaaaaaaaaiaa\"\n",
      "batch 18830  loss=151.2737  steps/s=109.97  prediction: \"is not concrete enough to put into words\" => \"n  ta ian   t  n  t  nn no     t   t  oo\"\n",
      "batch 18831  loss=150.8322  steps/s=108.08  prediction: \"eel free to run ideas by me whenever btw\" => \" d a  r fhtfeeef   e                eee \"\n",
      "batch 18832  loss=149.7405  steps/s=106.75  prediction: \"e context, like words, strengthen ideas?\" => \" c?     o c tont  e e   ,  e e  etee e e\"\n",
      "batch 18833  loss=179.6296  steps/s=65.76  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tlre  ononetto tore , , s  s eentttene e\"\n",
      "batch 18834  loss=160.9750  steps/s=115.17  prediction: \"employees) do half the work in a company\" => \" s  t   o   s os oeo o o  o       o   o \"\n",
      "batch 18835  loss=151.5816  steps/s=110.83  prediction: \"ly know how many angels fit on a pinhead\" => \"y: I n len n    w   w   n  n n n        \"\n",
      "batch 18836  loss=159.7459  steps/s=111.81  prediction: \" i found it really hard for some things.\" => \"tn timt sn  o n  o       a              \"\n",
      "batch 18837  loss=158.4725  steps/s=56.86  prediction: \"@skooookum i forget but its at least 100\" => \"ludpibx_oi   u  i   r    r   o          \"\n",
      "batch 18838  loss=159.3495  steps/s=89.42  prediction: \" but also, probably, very poorly sampled\" => \"@uo ln  u lle olo  bblo bbob   ooo yyyy \"\n",
      "batch 18839  loss=143.3450  steps/s=97.83  prediction: \" commonly use amd it works insanely well\" => \"@ays  s  i    n                         \"\n",
      "batch 18840  loss=151.2891  steps/s=97.47  prediction: \"ull potential. That would be surprising.\" => \"nd  t    htt tt  t   tttlt ttl          \"\n",
      "batch 18841  loss=153.7191  steps/s=106.97  prediction: \"no work on my part? ok lol thanks @sama\"\" => \"gtr e  sn r  o          o   o   ok   o k\"\n",
      "batch 18842  loss=156.9047  steps/s=92.71  prediction: \"tus Even more bc this doesnt have alaska\" => \"hr     wnonete  e          t  t    saa a\"\n",
      "batch 18843  loss=156.0112  steps/s=58.05  prediction: \"igABAP Born to consoom, forced to signal\" => \"nA tttgen  n  c  o  oooo ooooo     as aa\"\n",
      "batch 18844  loss=151.3861  steps/s=93.92  prediction: \"l release results soonish #buildinpublic\" => \"ymo   n rt leee le eelesssessssss sssiis\"\n",
      "batch 18845  loss=157.6731  steps/s=108.33  prediction: \"at the beginning\n",
      "https://t.co/3p7b8v9xhe\" => \"n e tto \n",
      " te  e  tetitnngttttn///tt/////\"\n",
      "batch 18846  loss=153.1059  steps/s=90.29  prediction: \"his was a super helpful technique for me\" => \"eve ttattt t                 e   eeeeee \"\n",
      "batch 18847  loss=250.9373  steps/s=11.89  prediction: \"reply: @justalexoki He is the goat fr fr\" => \"eply: iyane.n8noÉ´vðŸ°H{*#bb*k[..X**v`Éªâ€/â€™v\"\n",
      "batch 18848  loss=144.2078  steps/s=103.11  prediction: \"dit on my phone)\n",
      "https://t.co/iWZ4An9PaZ\" => \" n  b t  t  t          tttttttt/////////\"\n",
      "batch 18849  loss=156.6452  steps/s=107.78  prediction: \" pre session lift make a difference btw?\" => \"tro so   ss sss   s          i     eeee \"\n",
      "batch 18850  loss=162.6482  steps/s=78.48  prediction: \"ere @jaivinwylde prime rgb lore revealed\" => \" a  S ssessee ili iie        reeeereeeee\"\n",
      "batch 18851  loss=148.1164  steps/s=113.14  prediction: \" the gap\n",
      "\n",
      "down the energy gradient we go\" => \"to  ton  g    g          eeee ee eeee ee\"\n",
      "batch 18852  loss=162.8473  steps/s=39.75  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y: @g   tgg   et       e eeee ee e ee g \"\n",
      "batch 18853  loss=163.2661  steps/s=132.91  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"ozti    rxtai'xeO@cR)I3,Py?W,2,UObj,7W:F\"\n",
      "batch 18854  loss=206.1507  steps/s=109.74  prediction: \" ML AND HASKELL DETECTED\n",
      "\n",
      "instant follow\" => \"@Lsl o u   ++   AALLLLDEDEEEEEDDTTTTT E\n",
      "\"\n",
      "batch 18855  loss=186.8819  steps/s=105.22  prediction: \"\n",
      "Lemme know if you want a different song\" => \"\n",
      "ov : @i ro tSa kku3)v/kcyD\n",
      "k2,Nxbj,mMfl\"\n",
      "batch 18856  loss=134.0847  steps/s=113.08  prediction: \"ments as opposed to making the user wait\" => \"o oe  nam  tl@  --@_---&_;-\n",
      "^-9-99-;;;f^\"\n",
      "batch 18857  loss=192.9481  steps/s=41.87  prediction: \"ly: @I_Like_Buttes @opaeoh CANT TOUCH ME\" => \"y: @ee esess seesss s   oo        e     \"\n",
      "batch 18858  loss=134.7403  steps/s=136.02  prediction: \" least its not opengl like this poor kid\" => \"ti  e tn  t ttttt t t   t              i\"\n",
      "batch 18859  loss=180.7764  steps/s=105.86  prediction: \"e77 @0xdiicell turkish coffee is amazing\" => \" 7 tt e st te t  t il  lk   ki e  o oii \"\n",
      "batch 18860  loss=153.6690  steps/s=112.57  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd et    aaa  naaannaaeeee neeenr ee e e\"\n",
      "batch 18861  loss=159.2967  steps/s=107.34  prediction: \"n pulls models too, but only from github\" => \"dasse  d ne   les   elt   ot t tto  t   \"\n",
      "batch 18862  loss=149.3502  steps/s=96.25  prediction: \"he just checkmated because he got lucky\"\" => \"e  i\"he\" e\" hhshhhheeceecccceeceeeeeeee \"\n",
      "batch 18863  loss=155.1593  steps/s=109.28  prediction: \"round PNGs in powerpoint xDDDDDDDDDDDDDD\" => \"engejgeeh tnecetGPNGFFF&j&,w&^;,Fj;Fx^j&\"\n",
      "batch 18864  loss=164.6725  steps/s=102.16  prediction: \" way I implemented it might be different\" => \"tam m ima ememd  e e mem ememe e  ii ie \"\n",
      "batch 18865  loss=140.3199  steps/s=104.59  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \"he ta t s ee e tnen   eeehe ee e eee eee\"\n",
      "batch 18866  loss=153.9008  steps/s=108.15  prediction: \" even the ones i disagreed with the most\" => \"tt n teenin  ee  e    e e e ee    e    e\"\n",
      "batch 18867  loss=148.3911  steps/s=112.84  prediction: \"eel free to run ideas by me whenever btw\" => \" m i    fhtfeeef   e                eee \"\n",
      "batch 18868  loss=146.5400  steps/s=113.33  prediction: \"s called it tho, dont practice deception\" => \" bh n  ess    t      t  t t  t t ccccc c\"\n",
      "batch 18869  loss=151.2311  steps/s=112.94  prediction: \" which uses a superset of c. so not sure\" => \"t i chtc c cn  s    sss s s    s     s  \"\n",
      "batch 18870  loss=140.5828  steps/s=98.27  prediction: \", usually because you border more things\" => \" mndins et  ees eseesu u uuuuuu e  e eer\"\n",
      "batch 18871  loss=175.8023  steps/s=106.38  prediction: \"ng jai??? Instantly 10x more interesting\" => \"     t iii  i???????? a   n    n     t  \"\n",
      "batch 18872  loss=174.8031  steps/s=90.97  prediction: \"minds me of this https://t.co/Qoy9ykJ35M\" => \"eniae e ts teInecR,_P:R10xw:/,N.9kvQp,:f\"\n",
      "batch 18873  loss=180.1068  steps/s=77.08  prediction: \"h1xabc king shit https://t.co/UJrAexS6FM\" => \"e r o mem o   nii   ttt :t/t:////t.oJJJJ\"\n",
      "batch 18874  loss=160.3998  steps/s=114.89  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"h  te   i////RthhtttOhhtttt//ttttt////tP\"\n",
      "batch 18875  loss=149.0514  steps/s=112.01  prediction: \"l possible golden gate bridge existences\" => \"yf  lln   l ll lol  l        ee e  eee e\"\n",
      "batch 18877  loss=144.6006  steps/s=108.76  prediction: \"mes? maybe you could make a mod you want\" => \"e t n s hrtcnittð—»ð—¯ðŸ˜á´€xxá´€[:â€œbxð—ª*\n",
      ":*?xXD*?]\"\n",
      "batch 18878  loss=160.2592  steps/s=111.53  prediction: \"movie)\n",
      "\n",
      "Wifi mode when its high (gaming)\" => \"edi  se    nlat (MbbcxvvI))\n",
      "WWq)b?Wqâ€]v*\"\n",
      "batch 18879  loss=158.1873  steps/s=113.28  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" \n",
      "mt    nnl nnt zMgjcbvvIp(x.MqfkzzqDv)ðŸ›‘\"\n",
      "batch 18880  loss=164.4474  steps/s=114.21  prediction: \"y did my idea :(\n",
      "https://t.co/wC1KdndUrR\" => \" iicaMe dd dd   d d d  dd   :   :/:://tt\"\n",
      "batch 18881  loss=142.3073  steps/s=113.62  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sin iionnneeieien iitnteteitttctc/ttKKY\"\n",
      "batch 18882  loss=150.7472  steps/s=113.63  prediction: \"ncredibly painful, so a great motivator.\" => \"ghhotn   i cc  nici  i i  a aa    a  aaa\"\n",
      "batch 18883  loss=148.7486  steps/s=112.27  prediction: \"times and pick up new details every timâ€¦\" => \"hm  i tuof 0  an        n      de   ee e\"\n",
      "batch 18884  loss=175.5388  steps/s=95.50  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"tn lo   m moeeo orllllllo o eooeee   eo \"\n",
      "batch 18885  loss=158.4254  steps/s=112.63  prediction: \"t.co/RTzhOLWPSu) https://t.co/ihBxRwQlAa\" => \"h c /   i////htOhttt hhtttth/ttttt////tt\"\n",
      "batch 18886  loss=149.6132  steps/s=109.99  prediction: \"have primitives if you look close enough\" => \"ete e  tet t i ivieiiiiiii i i    e o o \"\n",
      "batch 18887  loss=149.8921  steps/s=108.12  prediction: \" so I invested my time into that instead\" => \"tkreern  r   oIe  seeee t e  e ti   tt t\"\n",
      "batch 18888  loss=143.9708  steps/s=107.71  prediction: \"hink about a post before responding lool\" => \"en  tctt  nnn                o oo  oe oo\"\n",
      "batch 18889  loss=177.9944  steps/s=110.51  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"e.e   ee eooleCaYYf0DDNNDðŸ«¡ðŸ«¡E0ðŸ«¡AAD::EO:EA\"\n",
      "batch 18890  loss=168.1022  steps/s=109.77  prediction: \"y off w a banger\n",
      "https://t.co/tLQiboLkG6\" => \" mo  s ant n  tatattatt tttt /tt/ t//tLL\"\n",
      "batch 18891  loss=156.6108  steps/s=112.86  prediction: \" make no?\n",
      "\n",
      "maybe @yacineMTB can add this\" => \"tose pss  oem oeme    \n",
      "e  eee aaaaa an  \"\n",
      "batch 18892  loss=161.8577  steps/s=41.01  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y  @   o  oe  mee   e eee y e aaaaa an  \"\n",
      "batch 18893  loss=145.3814  steps/s=117.14  prediction: \"the (fake) claim about compromising info\" => \" e  fon a t e c e   a  a     o   ooooiii\"\n",
      "batch 18894  loss=159.0346  steps/s=97.01  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \" lpn#  pman n \n",
      "\n",
      "     ao  aa aa a  aa    \"\n",
      "batch 18895  loss=172.2936  steps/s=97.64  prediction: \"//t.co/hjQfCWaZxw (banger on 1.5x speed)\" => \"/t.tI GGEEGá´˜E///thst/ZZZZWZZZZ o axxxx x\"\n",
      "batch 18896  loss=164.2339  steps/s=98.12  prediction: \"nvm then, enjoy your rain water counting\" => \" a  bort tttt  nt n n    on   onr   r r \"\n",
      "batch 18897  loss=167.1675  steps/s=104.20  prediction: \"pmillyair lichess is like 200 elo higher\" => \"lot @ na t me len r      e  e  0 00 e000\"\n",
      "batch 18898  loss=157.5847  steps/s=107.53  prediction: \"n to achieve an awesome long term vision\" => \" m  tmia l acee  a  a ae a  ae o ee e  e\"\n",
      "batch 18899  loss=149.6189  steps/s=108.39  prediction: \"ly pretending to give unsolicited advice\" => \"y   h e t rreehteee e     n  n nii tiii \"\n",
      "batch 18900  loss=177.6395  steps/s=105.77  prediction: \"up man youre gonna go far over the years\" => \"seee  tepn  punniep e een e          e e\"\n",
      "batch 18901  loss=152.6380  steps/s=113.83  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei   not    ii  i iiii   ii   i  u uuu \"\n",
      "batch 18902  loss=149.3000  steps/s=107.14  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"td hbh tenteeenneet nnnn    n       a   \"\n",
      "batch 18903  loss=162.6309  steps/s=108.04  prediction: \"ME but you do not follow CHRIST? curious\" => \"L  a oloo  oo   oo    oo oo  oo oo oo oo\"\n",
      "batch 18904  loss=147.1043  steps/s=113.47  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"oeaein n cnec nc ni      ee  t t tette t\"\n",
      "batch 18906  loss=156.4643  steps/s=107.45  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" a            n           o             \"\n",
      "batch 18907  loss=139.8155  steps/s=107.74  prediction: \" wrong pix (supposed to be @pixqc )\n",
      "\n",
      "rip\" => \"ton   d tttg      pppp pp               \"\n",
      "batch 18908  loss=162.1894  steps/s=112.84  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"/..ineeeeiot:/t/t/tFFFttthp///pt//tt.///\"\n",
      "batch 18909  loss=149.9653  steps/s=112.74  prediction: \"it seems like using a spoon vs a scalpel\" => \"n loo   rel  es  e se s   s  ss   s  s s\"\n",
      "batch 18910  loss=165.0132  steps/s=67.62  prediction: \"@IterIntellectus have you brrrytt today?\" => \"ltxqag t eesees is    s          s a   s\"\n",
      "batch 18911  loss=177.7792  steps/s=113.76  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..co  ooeo/o/o///too/ttttt/tttt////t///\"\n",
      "batch 18912  loss=171.0428  steps/s=113.42  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"g othb@ tht  eb r o tyy  o o  yrr t  t  \"\n",
      "batch 18914  loss=191.6140  steps/s=106.42  prediction: \"ineMTB here u go\n",
      "https://t.co/oR4fVr3TMW\" => \"ng ny yine @c   reootnhe e t  ert to os4\"\n",
      "batch 18915  loss=156.4336  steps/s=101.87  prediction: \", Heaven and hell are both one step away\" => \" to ia  snnes  e   ee ne e ae    o   o  \"\n",
      "batch 18916  loss=143.2266  steps/s=113.05  prediction: \" good at developing your own techniquesâ€¦\" => \"testewn tet got oo   oo eog oo  oo   n  \"\n",
      "batch 18917  loss=135.6111  steps/s=106.21  prediction: \"anning on putting this in an actual bot?\" => \"td noe   a n nnnnn  nnnii i nn   nn    n\"\n",
      "batch 18918  loss=155.3355  steps/s=110.22  prediction: \"ur own projects. https://t.co/lsNyRzPzsb\" => \"se wtnw onono  oooo       tt  tttttstt/s\"\n",
      "batch 18919  loss=172.6216  steps/s=110.87  prediction: \"eres so little time to things in the day\" => \"   ieetlese e tee e    tttett i tt      \"\n",
      "batch 18920  loss=172.9575  steps/s=111.95  prediction: \"ess while retaining the same information\" => \" s    r  t s srs  s  e  ie  ieeee e  ii \"\n",
      "batch 18921  loss=152.5284  steps/s=108.91  prediction: \" I wouldnt know, maybe someone else does\" => \"t    ts  h o   oo  o o  o   o oo   ome o\"\n",
      "batch 18922  loss=154.4725  steps/s=107.10  prediction: \"uick free working solution, see my tweet\" => \"sld   e  u ke kk k  e  ooo nooe  eo s ee\"\n",
      "batch 18923  loss=168.1207  steps/s=113.00  prediction: \" through nevada w my dad as a little kid\" => \"the ir  ngd g  n    v  d a d a  d  a a a\"\n",
      "batch 18925  loss=155.3830  steps/s=111.38  prediction: \"enjoyable is such a gargantuan advantage\" => \"  i  tao gt nns       a aaaaaaa naa aaaa\"\n",
      "batch 18926  loss=142.0530  steps/s=113.55  prediction: \"tw, my b, but ill hop in on the next one\" => \" pasgite s m  nt      b                 \"\n",
      "batch 18927  loss=147.2822  steps/s=113.30  prediction: \" company dgaf and you can contact those?\" => \"tore  a   en anaaa a aa a n a a ccc c cc\"\n",
      "batch 18928  loss=152.7050  steps/s=110.55  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"e i  s e ll le leeeeeeee   e            \"\n",
      "batch 18929  loss=141.4869  steps/s=112.66  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly  oo tn  p        e tetteteeeeeeenunnu\"\n",
      "batch 18930  loss=150.5758  steps/s=112.83  prediction: \" ppl twist your arm behind your back lol\" => \"trtet  t it t  t                        \"\n",
      "batch 18932  loss=160.5078  steps/s=109.24  prediction: \"ing all my money https://t.co/IXXYEJUqHm\" => \"ng oe ef   el   l  om  m  y  ot  o//tXXt\"\n",
      "batch 18933  loss=154.7602  steps/s=114.35  prediction: \"/t.co/dWiO4erSb1 https://t.co/VaQuvIKJWu\" => \"/.copp  t///t/toW/WWOOtttSS/t/tt////t//.\"\n",
      "batch 18934  loss=154.2991  steps/s=113.46  prediction: \"ve gradient it lives in? Something else?\" => \"er  rn ti enniii ieiii i iii i i i  e ee\"\n",
      "batch 18935  loss=169.1988  steps/s=113.68  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" aedi  0 , ,, ,,,,,...........    xx xxx\"\n",
      "batch 18936  loss=164.3914  steps/s=111.83  prediction: \"aftinginterpreters\n",
      "- got back into 3d pâ€¦\" => \"tter    hc e trtfrtrrtereretrretttte    \"\n",
      "batch 18937  loss=169.2642  steps/s=101.60  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \"h r f conatiti  ies etttttsttttto/// 899\"\n",
      "batch 18938  loss=146.8480  steps/s=114.32  prediction: \"atrophy, you have to like, keep doing it\" => \"nii tt et ttthth h                      \"\n",
      "batch 18939  loss=156.3624  steps/s=109.47  prediction: \"le brotha, ill dm you a link on the 25th\" => \"yt tt e t tc tt     lll                 \"\n",
      "batch 18940  loss=150.4558  steps/s=112.87  prediction: \"have become too big and are rotting away\" => \"etgsiem neame   e e   o   oo  o   o   a \"\n",
      "batch 18941  loss=165.4245  steps/s=114.00  prediction: \"ded techniques too, lmk if you know more\" => \"  n elieendddededdedee ee      o  o    o\"\n",
      "batch 18942  loss=144.0252  steps/s=113.09  prediction: \"ressures me to say things I dont believe\" => \"epleree niy i~wiÉª%$å€‘8%$%ðŸ˜¢j%kj$`jâ™‚jp~ÊŸ.ww\"\n",
      "batch 18944  loss=153.8428  steps/s=110.62  prediction: \" btw? or does onnx just work well enough\" => \"tate tn n  tt nn   o    oo    o  w w    \"\n",
      "batch 18945  loss=154.3597  steps/s=109.62  prediction: \"i know bedrock api has a chat window too\" => \"nka b tot tb  tb           aa  a aa   a \"\n",
      "batch 18946  loss=156.3740  steps/s=96.34  prediction: \"my ability to make things I want to make\" => \"p l a  le\n",
      "ss Ae `~A`Ê€|vá´¡fIX`\n",
      "èµ°ÉªÊ€y|æˆ‘ð—²`~mâ€œ\"\n",
      "batch 18947  loss=180.6475  steps/s=24.05  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @t  i ni  i          i       n     \"\n",
      "batch 18948  loss=145.4403  steps/s=103.74  prediction: \"etter, all in your head\n",
      "Can explain more\" => \" t le tn  tt   l                   aa aa\"\n",
      "batch 18949  loss=154.1864  steps/s=89.16  prediction: \"otten most of my follows from Yacine lol\" => \" he  tet etttte     t  o   o oooo      o\"\n",
      "batch 18950  loss=174.7689  steps/s=97.75  prediction: \" possible the true x for elon is 42,069x\" => \"@rm  nserb   s    se s  e e e   r    o  \"\n",
      "batch 18951  loss=154.1815  steps/s=97.77  prediction: \" this era where breaches happen so often\" => \"aoe  mnente si   eii eee  hhhehe e  hee \"\n",
      "batch 18952  loss=153.9020  steps/s=101.66  prediction: \" ive been doin\n",
      "Hard to study w music tho\" => \"at  ren rle neCe  e i              dd   \"\n",
      "batch 18953  loss=185.6308  steps/s=105.69  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"ns h n nn   n n    t t ttt  \n",
      "ttt t////t/\"\n",
      "batch 18954  loss=147.8706  steps/s=104.28  prediction: \"l tools for myself and they save me time\" => \"ypeiu  ouulloo ll  l  ff                \"\n",
      "batch 18955  loss=150.9197  steps/s=84.14  prediction: \"w site! Not gonna say much til it's done\" => \"iwo e  n  eseN eN                       \"\n",
      "batch 18957  loss=143.5898  steps/s=88.54  prediction: \"y noticed the last time i was there, lol\" => \":ia in  eiietieteettett t      tt       \"\n",
      "batch 18959  loss=157.0931  steps/s=101.64  prediction: \" you can do the second without the first\" => \"ioungan n      n              o      o  \"\n",
      "batch 18960  loss=147.4912  steps/s=102.87  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \"  n a e eent er seennronnnoonntttt   t t\"\n",
      "batch 18961  loss=147.4327  steps/s=100.98  prediction: \" I didnt post AT ALL til it was 98% done\" => \"a eka  ed    dI         A  L   t      t \"\n",
      "batch 18962  loss=152.9638  steps/s=100.00  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "suprn n t c 8t â€¦I,8`,v8Ê€I,,$$â€%`ðŸ«¡,,I}uá´€\"\n",
      "batch 18964  loss=165.6007  steps/s=99.63  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"xxa  am on((n)n)    e                fff\"\n",
      "batch 18965  loss=159.8299  steps/s=106.09  prediction: \"he stopped existing after the last frame\" => \"e  s d es nnO ee  i e e  ee ee   tttet t\"\n",
      "batch 18966  loss=149.6829  steps/s=99.61  prediction: \"imated stills have finally been defeated\" => \"ne ae ae dn eeessi ti   illl   aeeeffeee\"\n",
      "batch 18967  loss=159.0925  steps/s=99.34  prediction: \"\n",
      "laughed pretty hard when I saw this ngl\" => \"\n",
      "int a  mB   G tPâ˜ GMð—±Êœxvwð—ª`{xvÉ´$É´á´€vv{`x{\"\n",
      "batch 18968  loss=149.2611  steps/s=105.58  prediction: \"has any non-json, ask for json in prompt\" => \"et s . f      nnnnn nnnnnn   o    o  o  \"\n",
      "batch 18969  loss=150.3534  steps/s=106.05  prediction: \" fast eventually. i know this from chess\" => \"tur rt ess stte  ee e el          t     \"\n",
      "batch 18970  loss=165.3344  steps/s=105.00  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \" tt in  L lft_ntMSE_MSEw^,MSEMSE).baxkâ€¦(\"\n",
      "batch 18971  loss=149.1036  steps/s=105.66  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"e vHe ana  naeh e aae  eaa  anaa aadae  \"\n",
      "batch 18972  loss=179.5338  steps/s=52.00  prediction: \": @0x77er some likes are worth 100 likes\" => \" @tn@ en totefioy.L(TT_^w(^_y.y()vH1)0â€¦v\"\n",
      "batch 18973  loss=236.5826  steps/s=113.23  prediction: \"HR SESSION GANG\n",
      "\n",
      "https://t.co/33daS76d39\" => \"eNG  A NS SS SSSG GGGGGGGNN  tt/:////33/\"\n",
      "batch 18975  loss=166.7725  steps/s=105.62  prediction: \"ou can dive unbelievably deep into these\" => \"nt ti dene nnne n    n eebebbe ee eeee i\"\n",
      "batch 18976  loss=240.6601  steps/s=11.26  prediction: \"reply: @crackeddl its hard. but worth it\" => \"epay  @ eiteok oGkDd)vGBY/AkYYH(ycvGId3b\"\n",
      "batch 18977  loss=152.8778  steps/s=108.96  prediction: \" IP, imo\n",
      "\n",
      "vpns are not security products\" => \"a aeotor gi i in i    o            r   r\"\n",
      "batch 18978  loss=169.7155  steps/s=100.40  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl e do  is.krtB.I1k/K8%kxByÉªB${IPIF$01\"\n",
      "batch 18979  loss=153.2707  steps/s=101.97  prediction: \"ens w high space https://t.co/yxAYpo0ESY\" => \" tse wen e                  h s/////////\"\n",
      "batch 18980  loss=261.7805  steps/s=12.87  prediction: \"reply: @Brycicle77 polnareff could never\" => \"estye waloy t$ktxðŸ¤¯ð—¼kðŸ¤·kq$%`kXâ€¦x$$%fÊ€â˜ ÉªðŸ§ á´‡k\"\n",
      "batch 18981  loss=164.8611  steps/s=107.99  prediction: \"ant use it for what i need to work on :(\" => \"nd  e  ashn  aa   t   a  e t      t t  o\"\n",
      "batch 18982  loss=135.4954  steps/s=78.59  prediction: \"d work that into my current program haha\" => \" ca   o       hw               rr r rrrr\"\n",
      "batch 18983  loss=147.7659  steps/s=93.31  prediction: \"now how to do it https://t.co/y5LFqaVw5b\" => \"gtia   n nw w no o    t tttttttttttt///5\"\n",
      "batch 18984  loss=149.9534  steps/s=90.64  prediction: \"xist simultaneously sometimes, its crazy\" => \" m  e n n  t  ttt t ssss siosomsomssss s\"\n",
      "batch 18985  loss=176.1290  steps/s=66.04  prediction: \"rchived_videos @LimkarRohit @discord LOL\" => \"ehle:seo n rs,yðŸ¤¦vf@L,Rx@LRfxvvR@4w42@O2,\"\n",
      "batch 18986  loss=155.4837  steps/s=94.71  prediction: \"r the years for business/building things\" => \"ehe vbrnt   octn(4j),wk((,)vjl4p/j)(/w&/\"\n",
      "batch 18987  loss=148.4746  steps/s=92.92  prediction: \"hey shot at it and it exploded\n",
      "\n",
      "insane..\" => \"e   totetrhtt tthh t tt tt       d   i d\"\n",
      "batch 18988  loss=150.0169  steps/s=81.32  prediction: \"ust linux mints built in text editor lol\" => \"tt ae itet t i n t ii  i iiit  intt   i \"\n",
      "batch 18989  loss=160.1887  steps/s=122.47  prediction: \"r_fusion based\n",
      "i cant read apparently xD\" => \"ee e   nmager_f juxVgw?wVgbvjwVgyjubux\n",
      "/\"\n",
      "batch 18990  loss=143.7464  steps/s=101.05  prediction: \"lgos to live by, and the art of learning\" => \"yoe  e te  lt  e  l  ,  e               \"\n",
      "batch 18991  loss=149.2100  steps/s=98.37  prediction: \"e increased space the model has to think\" => \" to t  te    ec eeesee  eeee ee  e      \"\n",
      "batch 18992  loss=163.4944  steps/s=78.77  prediction: \"ezm progressive overload builds strength\" => \" ioteemoerees scsseese eee  a d o d  t t\"\n",
      "batch 18993  loss=144.0196  steps/s=92.25  prediction: \"ny depressions ripple to other countries\" => \"  ae  ea   s  messsesss sppp  pe p ooo o\"\n",
      "batch 18994  loss=146.3125  steps/s=94.52  prediction: \"o him) and he begged to pay me to use it\" => \" al   tlt n n  n                        \"\n",
      "batch 18995  loss=208.0825  steps/s=97.52  prediction: \"07 .-.. ..-. --. --. --. --. --. --. --.\" => \"x_u h  we   r07 44,k4444(44,4(4J,CCC\n",
      "kcC\"\n",
      "batch 18996  loss=174.3542  steps/s=98.13  prediction: \"e @sunsettler youre in the nix dimension\" => \" ai  te  h ne  s   ee  e                \"\n",
      "batch 18997  loss=154.2853  steps/s=97.85  prediction: \"visualize 5d and if so whats your method\" => \"en   ou uiu  ue    i   i                \"\n",
      "batch 18998  loss=143.6514  steps/s=104.10  prediction: \"ncing is just how things go in business.\" => \" h   an  en eien e i  s   ii  g  i in  i\"\n",
      "batch 18999  loss=160.9189  steps/s=96.78  prediction: \"ot even... this? https://t.co/vAkhEpFVm1\" => \" he emee  n   .....  tt t t tt /t//ht///\"\n",
      "batch 19000  loss=151.2518  steps/s=103.94  prediction: \"evant documents\n",
      "\n",
      "https://t.co/oLuRW4NPNs\" => \" enn n f n  eo eeetteneetee\n",
      "t\n",
      "tt\n",
      "ot/tt/t\"\n",
      "batch 19001  loss=143.7609  steps/s=104.30  prediction: \"it got like 2x fps rendering ocean waves\" => \"n  w  wete    i           e   e e  eeee \"\n",
      "batch 19003  loss=142.6622  steps/s=104.13  prediction: \"l here is better than funny number go up\" => \"ype  nin p n   e    e  e      nnnn  nn  \"\n",
      "batch 19004  loss=146.6078  steps/s=104.36  prediction: \"DLR but could just be forward/left/right\" => \"oNihu ee      Unu  u u       u      r  r\"\n",
      "batch 19005  loss=162.8532  steps/s=100.61  prediction: \"st went from rome to naples two days ago\" => \" etrh etre tt,@   tr t  o        to   t \"\n",
      "batch 19006  loss=142.7313  steps/s=104.19  prediction: \" my weird posts but im happy nonetheless\" => \"tore  n  tete  t  e            p   p    \"\n",
      "batch 19007  loss=147.5213  steps/s=103.42  prediction: \"stion, why do they cluster where they do\" => \"   r  yuot  ,,,       yy      e    heee \"\n",
      "batch 19008  loss=156.2117  steps/s=101.41  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"tao   b    rb    .    ...  ... ./..t////\"\n",
      "batch 19009  loss=157.0087  steps/s=97.96  prediction: \"feeling than automating hrs of work away\" => \"    inot inonoliPjvI@.'vw2:/:j2qkg6/2J25\"\n",
      "batch 19010  loss=148.9252  steps/s=100.09  prediction: \"ld love to hear if you dont mind sharing\" => \"y   te s llolo l          o             \"\n",
      "batch 19011  loss=172.8080  steps/s=51.80  prediction: \": @moh1xabc i cooked so hard i burned it\" => \" @lan   mei nmou~y~~~v/gQ~/s?aw!?g!k~?v!\"\n",
      "batch 19012  loss=168.6745  steps/s=101.79  prediction: \"@JsonBasedman just veto their veto, easy\" => \"sortiene  o      o e    oo o id   nrdn  \"\n",
      "batch 19013  loss=210.8124  steps/s=84.18  prediction: \" @Laz4rz IM FREE https://t.co/6zRFYN5bNS\" => \"tsul/@e d aa??MFo  e    oo o ii    ee   \"\n",
      "batch 19014  loss=164.8774  steps/s=106.45  prediction: \"the community give me energy to do these\" => \" e  e   n t    t    t m  ee e e eeee  e \"\n",
      "batch 19015  loss=161.0905  steps/s=104.15  prediction: \"sure there are lots of 100xers out there\" => \" r l eh  m e exree eee     e  re  ere re\"\n",
      "batch 19016  loss=176.8948  steps/s=98.05  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nA Au eA nggA iogggoo oto ttttt/////  //\"\n",
      "batch 19017  loss=186.9522  steps/s=91.73  prediction: \"re @ludwigABAP @sebby_builds hood braces\" => \"eply:n hn SP@rBHP@pABJPv@BAP1@_xCpl_fff.\"\n",
      "batch 19018  loss=154.0305  steps/s=103.06  prediction: \"g us calculate costs some weird jank way\" => \" toa  te   n  a   a c s scs ssss  ss s  \"\n",
      "batch 19019  loss=156.2362  steps/s=104.41  prediction: \"'ll see models get good at outputting it\" => \" elnee ien ee weeleleeee oe  e   oo oot \"\n",
      "batch 19020  loss=168.6787  steps/s=104.21  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \"i d  s donnono o o o         /ttt///t///\"\n",
      "batch 19022  loss=174.5926  steps/s=74.66  prediction: \"xluciusv cool cool goal\n",
      "progress so far?\" => \" ur wt  long ronoo   oo/  go//ttsttrtstt\"\n",
      "batch 19024  loss=163.7376  steps/s=105.90  prediction: \"ou get faster and faster at solving them\" => \"u     t te   ttt    a   a      a  a     \"\n",
      "batch 19025  loss=159.2530  steps/s=101.35  prediction: \"nrot swe competition\n",
      "Gm level strategery\" => \" etr  era a  oototot totooo ttieeeteeeet\"\n",
      "batch 19026  loss=182.4723  steps/s=97.01  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \"   t @oen re ee  t tiit  tti tettttte/t/\"\n",
      "batch 19027  loss=153.5687  steps/s=103.32  prediction: \"ic training data\n",
      "https://t.co/wWfEPsk8NI\" => \"n \n",
      "\n",
      "ntn n itititntttttittttttttttt//////\"\n",
      "batch 19028  loss=166.2733  steps/s=99.71  prediction: \" flick of the wrist instead of traveling\" => \"tinr iwf i  f   t   i t  iit    tt t i  \"\n",
      "batch 19029  loss=151.8980  steps/s=103.87  prediction: \"ked bc i could make cool fun stuff in it\" => \"e    hontht oodoooo    oo   oo          \"\n",
      "batch 19030  loss=152.7628  steps/s=104.34  prediction: \" know. But this will help you immensely.\" => \"tit   d no    o   t    o    l         li\"\n",
      "batch 19031  loss=224.2684  steps/s=97.23  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"B Bo  tsO   OOMO TT MMPP   Ett tt/s///.s\"\n",
      "batch 19032  loss=156.0833  steps/s=103.45  prediction: \" random nonsense will escape containment\" => \"tet smeiemmesm mm ssennesens  sen eenaen\"\n",
      "batch 19033  loss=150.6565  steps/s=103.82  prediction: \"urself, if you can manage to pull it off\" => \"re lee ll l l f                         \"\n",
      "batch 19034  loss=154.1196  steps/s=102.64  prediction: \"eting ppl on here\n",
      "\n",
      "the next half WE BALL\" => \" te   eeettet     e    ee e ee eee    h \"\n",
      "batch 19035  loss=183.8065  steps/s=58.55  prediction: \" @AI_Solzhenitsyn it's an acquired taste\" => \"tle eet ee  te    e   nee  ne h  e  e  t\"\n",
      "batch 19037  loss=146.9020  steps/s=105.16  prediction: \"n for games (more encouraging?) but canâ€¦\" => \"gp sith    n  n   o     e  rereor g gnn \"\n",
      "batch 19038  loss=142.5879  steps/s=105.00  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sin rionnneei ien iitnteteitttc///tKKKK\"\n",
      "batch 19039  loss=154.8006  steps/s=103.77  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \" enr  e   t t t  \n",
      "ee\n",
      "\n",
      "\n",
      "\n",
      "et\n",
      "\n",
      "ett\n",
      "\n",
      "t//tth/\"\n",
      "batch 19040  loss=160.0661  steps/s=103.20  prediction: \"know what it is\n",
      "\n",
      "https://t.co/wJ5n1H6JUK\" => \"eot n  n t  t      i  ttttttttttttt////J\"\n",
      "batch 19041  loss=156.1167  steps/s=100.68  prediction: \"ool\n",
      "\n",
      "yacine is really cooking over there\" => \"u, os s cyccs i\n",
      "    i  i       o   oo  o\"\n",
      "batch 19042  loss=231.0688  steps/s=13.26  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"eply: @cenr nS, $â€œAb$I8@SuX8@,u$:@A{.$SA\"\n",
      "batch 19043  loss=149.0992  steps/s=130.01  prediction: \", welcome to circle gang @ineedtolocking\" => \" todoon nool  ce ce c  c cc ee eee geeee\"\n",
      "batch 19044  loss=171.7756  steps/s=96.76  prediction: \"t new one is kinda Y shaped too in a way\" => \" il en umene ot  e    e ii   naee  toooo\"\n",
      "batch 19045  loss=144.5537  steps/s=101.23  prediction: \"ny depressions ripple to other countries\" => \"  ae  oa o s  resssrsss sp p  pp p  o  o\"\n",
      "batch 19046  loss=140.5889  steps/s=97.01  prediction: \"ur input). Otherwise, you would need toâ€¦\" => \"se te t   tt  t  t  t t          u   u  \"\n",
      "batch 19047  loss=169.0424  steps/s=86.88  prediction: \"oh_ Oooh great suggestion\n",
      "\n",
      "Will do ty ty\" => \"ue trnnon oOOot  ree  see  uuoo eoo  d  \"\n",
      "batch 19048  loss=146.5130  steps/s=90.76  prediction: \"ed hard at improving, mostly by studying\" => \"  ao   wrrdd  dd   r r    o  o         y\"\n",
      "batch 19049  loss=147.1683  steps/s=79.39  prediction: \"t your iq has to be under 70 or over 170\" => \" so   hstt t  ht        t              7\"\n",
      "batch 19050  loss=164.8768  steps/s=92.03  prediction: \" square gang wont let this happen &gt;:(\" => \"tu  io r uq a    a    n    e   o    r   \"\n",
      "batch 19051  loss=147.7453  steps/s=105.98  prediction: \"sonnet3.5 for pretty much everything now\" => \"  ese us e t  4    eet ttt     eee  et  \"\n",
      "batch 19052  loss=144.1962  steps/s=100.40  prediction: \"he gamer would make for some great games\" => \"e  eo    o m of  o     e m mome m e meme\"\n",
      "batch 19053  loss=155.0916  steps/s=92.35  prediction: \"n confirm this is a very goated strategy\" => \" ef aht eaoan ama   o  s r  i r  a a  t \"\n",
      "batch 19054  loss=142.5860  steps/s=105.97  prediction: \"his, and even then you might get mislead\" => \"es ptt    e   h    e             e   t  \"\n",
      "batch 19055  loss=163.4860  steps/s=102.54  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"here ato t n  nnnne nu nn ttttt/t//tt/ts\"\n",
      "batch 19056  loss=146.4874  steps/s=110.58  prediction: \"yping on the terminal bc it looked cool)\" => \"     ittti  t  t                        \"\n",
      "batch 19057  loss=143.6796  steps/s=110.18  prediction: \"s are your own, and i need to prove that\" => \" tot t t  mh  gr     o                  \"\n",
      "batch 19058  loss=171.2802  steps/s=109.37  prediction: \"eople want. Nowâ€ https://t.co/yxXaaiHzQ1\" => \" p atnin e n eeee  n   wt   tttt ////a//\"\n",
      "batch 19059  loss=153.6086  steps/s=111.71  prediction: \" strategy of perception?\n",
      "Dang thats cool\" => \"toue e u ss t s   e ee eeee eeeeet  tatt\"\n",
      "batch 19060  loss=146.0933  steps/s=110.07  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yt  don d m m c       u   u u uuu  uu uu\"\n",
      "batch 19061  loss=164.4173  steps/s=107.11  prediction: \"mber that quote\n",
      "\n",
      "sounds like a smart man\" => \"oed t  t t  wi obw@,Nvb@kqjb4k)q\"â€.(q\"4)\"\n",
      "batch 19062  loss=154.6346  steps/s=108.59  prediction: \"board wave and its constituent sinusoids\" => \"ls m ber  trr aaa   aa  nnns sts tisst i\"\n",
      "batch 19063  loss=176.6722  steps/s=111.69  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"o.e   een eole AYAfADOONEðŸ«¡ðŸ«¡E1ðŸ«¡vAD::EO:EA\"\n",
      "batch 19064  loss=139.5149  steps/s=110.11  prediction: \"uscle and you get better as you practice\" => \"se  ttn  t       u       te  ee       tt\"\n",
      "batch 19065  loss=147.4049  steps/s=98.02  prediction: \"ernet becomes, say, 100x more addictive?\" => \"   n nh enenneteeeeeeee    000000       \"\n",
      "batch 19066  loss=230.2694  steps/s=107.03  prediction: \"u helped a ton, hugely appreciate it bro\" => \"sctthe__tn__1_ 111,zz00xexper od,, ,, ,y\"\n",
      "batch 19067  loss=163.5268  steps/s=109.75  prediction: \" that initially seemed meaningless to me\" => \"the  ttt  t ia titti iee  eiei iiee  e e\"\n",
      "batch 19068  loss=138.9576  steps/s=104.55  prediction: \"t. have they found the piece yet or what\" => \"h hete tiet t tt  h         eeee e e  e \"\n",
      "batch 19069  loss=148.2949  steps/s=99.25  prediction: \"c, just separated by some amount of time\" => \"h n  t t r,t   s ta  teee  e        tt  \"\n",
      "batch 19070  loss=144.5764  steps/s=104.78  prediction: \"o actually understand the program better\" => \" th  sn e t t    a aaa  a  tt  tr   r rr\"\n",
      "batch 19071  loss=161.0766  steps/s=112.91  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"torerniit enntn teteettt tttehttttt////t\"\n",
      "batch 19072  loss=161.4768  steps/s=81.94  prediction: \"eCachet Consistency is a deadly strategy\" => \" i ed@it  tententette e  tt////t/tt35ttS\"\n",
      "batch 19073  loss=157.8861  steps/s=107.78  prediction: \"st (30% done w this)\n",
      "4 open a small beta\" => \"  e    ce   3 (3        o      o       e\"\n",
      "batch 19074  loss=150.1506  steps/s=112.36  prediction: \"quickly that require a variety of skills\" => \"uirt o real    gq  rqq qq rarar a rr r  \"\n",
      "batch 19075  loss=145.4691  steps/s=108.04  prediction: \" adventure over the comfort of certainty\" => \"tbde tetentteeeveeee  eee re   oo ofof  \"\n",
      "batch 19076  loss=162.9503  steps/s=109.88  prediction: \" surprised at how clean of a read it was\" => \"@tae an r  sesir r   a    a   a   a    a\"\n",
      "batch 19077  loss=178.5565  steps/s=108.52  prediction: \"ood combo for stuff like this, ive found\" => \" m o go\n",
      "topf ooo f fmm ffff   io  o i   \"\n",
      "batch 19078  loss=149.4654  steps/s=104.03  prediction: \" loss (erroneously a vector) as a scalar\" => \"tog ehd h sss seoooooo  ee              \"\n",
      "batch 19079  loss=149.4104  steps/s=112.87  prediction: \"urself, if you can manage to pull it off\" => \"teltee ll l l f                         \"\n",
      "batch 19080  loss=136.7699  steps/s=111.33  prediction: \"ether they are good or bad on their face\" => \" t dddeed tteeheeeee                    \"\n",
      "batch 19081  loss=138.7580  steps/s=112.26  prediction: \"hem better bc you can do engine analysis\" => \"e   yt et te t t                   nnnnn\"\n",
      "batch 19082  loss=143.8242  steps/s=100.48  prediction: \"ves\n",
      "\n",
      "the other, for a job\n",
      "\n",
      "just my guess\" => \"er    e tseete setee ethee \n",
      " o\n",
      "\n",
      " jj    \n",
      "\"\n",
      "batch 19083  loss=143.2042  steps/s=105.60  prediction: \"tic paper searches\n",
      "at this rate it willâ€¦\" => \" ne emao pepm  e pease rs errae aarateaa\"\n",
      "batch 19084  loss=158.7380  steps/s=102.30  prediction: \"f children will build my programs for me\" => \" phet eofecetlet-1)-MTk,-v-\n",
      "--\n",
      "-----,-â€¦v\"\n",
      "batch 19085  loss=149.4156  steps/s=103.08  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" iut  t ttan a i a    ttti h tttst//t/t/\"\n",
      "batch 19087  loss=141.7272  steps/s=98.99  prediction: \"on mars we will make this a top priority\" => \"u  oo  m  s s  w                        \"\n",
      "batch 19088  loss=163.8086  steps/s=66.02  prediction: \"@Aryvyo use the api\n",
      "anthropic or bedrock\" => \"suniett s w                        rr ro\"\n",
      "batch 19089  loss=160.3231  steps/s=89.53  prediction: \"@yacineMTB so youre no longer locked in?\" => \"saciert e   w       a  i a  ooo  r rrikðŸ›‘\"\n",
      "batch 19090  loss=145.5131  steps/s=112.71  prediction: \"s aside though, why wouldn't that work?)\" => \" (oo   netske  ts   h hh  ho  h   h w w \"\n",
      "batch 19091  loss=171.6781  steps/s=101.23  prediction: \"ich in this case, is their lack of speed\" => \"n easetahs s    h     s  i i  ii        \"\n",
      "batch 19092  loss=152.5029  steps/s=97.07  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"tce lenu yele u iee e     o      a a a l\"\n",
      "batch 19093  loss=149.8706  steps/s=104.52  prediction: \"per curious to see what youre working on\" => \"lr    atsn s  io s        o     o ro o  \"\n",
      "batch 19094  loss=152.8002  steps/s=99.10  prediction: \" they secretly exercise and dont tell us\" => \"the ste   se  ss  eeeeeeeeeee e ee      \"\n",
      "batch 19095  loss=172.6525  steps/s=23.40  prediction: \"ply: @sunsettler https://t.co/5aSVR7XfZZ\" => \"ly:   aps see se eeeeseeeeee    ee      \"\n",
      "batch 19096  loss=143.5180  steps/s=59.91  prediction: \"y: @sunsettler gl w luffy tomorrow bro ðŸ«¡\" => \"  @seuse hetllt  eeeese eee  d   e    ZðŸ›‘\"\n",
      "batch 19097  loss=148.1736  steps/s=110.60  prediction: \"tal clarity and less of a need for sleep\" => \" ns   n no mnnel l  llal al    e    e   \"\n",
      "batch 19098  loss=168.9661  steps/s=100.82  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "Is l eiue1o lkt6ðŸ«¡,vI,ðŸ«¡MfIA/iE\n",
      "A/vj25Xv/\"\n",
      "batch 19099  loss=163.8443  steps/s=98.92  prediction: \"ased. Me neither. This is the way to go.\" => \"t     sot  se n   ee  eei  ih hi    h  h\"\n",
      "batch 19100  loss=147.7382  steps/s=98.30  prediction: \"ing this with terms masters commonly use\" => \"ng f  l noni  htii    t t  ts tsms smmmm\"\n",
      "batch 19101  loss=144.6551  steps/s=104.78  prediction: \", how do WE figure out where things are?\" => \" io  i nn     o                e   e   e\"\n",
      "batch 19102  loss=167.2772  steps/s=100.67  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \" l  t  mohsetes teeetetethettot//t/t/tt/\"\n",
      "batch 19103  loss=155.0669  steps/s=97.45  prediction: \"n i did eventually. hypothesis confirmed\" => \" hh en mted   nnd d n  n letee  i   eeei\"\n",
      "batch 19105  loss=162.0064  steps/s=72.90  prediction: \"a Meet the new boss\n",
      "Same as the old boss\" => \"niea oG e tet tea   e  teeheess  so eae \"\n",
      "batch 19106  loss=147.1147  steps/s=98.91  prediction: \"he going gets tough, the tough get going\" => \"en ehbt n g eg gte ggtet   gg tt gghg gg\"\n",
      "batch 19107  loss=142.9588  steps/s=91.87  prediction: \"pen theatre stairs door and ruin the run\" => \"lr  @  g e tetttte t    to     rr      r\"\n",
      "batch 19108  loss=148.8687  steps/s=103.99  prediction: \" not super out of alignment with reality\" => \"toeiaen n  nn utu   o   o oee nn n   t  \"\n",
      "batch 19109  loss=146.0562  steps/s=101.63  prediction: \"did something similar w his site i think\" => \" nih t r ani eomin  im  am s sisi ii  ii\"\n",
      "batch 19110  loss=149.1922  steps/s=98.02  prediction: \" random people you dont really know well\" => \"temek  o n.   m o    oo  oo   o  l   l l\"\n",
      "batch 19111  loss=151.3952  steps/s=104.08  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tadpia    ittit ii iiii r ii            \"\n",
      "batch 19112  loss=152.9208  steps/s=110.22  prediction: \"s, 30% make garbage, and 64% ruin things\" => \"  so, t nigg  g    g  aa aaaa           \"\n",
      "batch 19113  loss=184.1526  steps/s=74.54  prediction: \"d @gizmobly @covix2772 store files in it\" => \" tgt   g g gm bag b a    2772277    in  \"\n",
      "batch 19114  loss=153.0167  steps/s=53.90  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @ddgg em  @gaaa  277277772  r    ii  \"\n",
      "batch 19115  loss=142.6176  steps/s=99.07  prediction: \"risk of rain music for 2 seconds at 5:00\" => \"eplynn aennngen @x2z$$ÉªMTBx]$\n",
      "X}$å€‘vp###[\"\n",
      "batch 19116  loss=153.5682  steps/s=84.06  prediction: \"in galen fan too https://t.co/wSeZG5wvx3\" => \"ng     n  n nannn  n n n   ttoo///tt////\"\n",
      "batch 19118  loss=148.8755  steps/s=79.84  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tm a h e.n.eeennentnn nn    n       a   \"\n",
      "batch 19119  loss=149.4344  steps/s=98.95  prediction: \"ing already paved paths is the only wayâ€¦\" => \"n  in  nn  nn ad p  aa aaa     a     h  \"\n",
      "batch 19120  loss=184.7510  steps/s=37.13  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"y: @n no nnn   d pdaap a a           y  \"\n",
      "batch 19121  loss=157.7454  steps/s=98.68  prediction: \"ng to caffeine+building/studying for fun\" => \"g  iet m  tm fgn+i++in+iiginegininninfii\"\n",
      "batch 19122  loss=163.1526  steps/s=93.74  prediction: \"ttempt to appeal to ipad kid generation?\" => \"hlne etotatt a pp tapppp  p  pppa    i  \"\n",
      "batch 19123  loss=171.8529  steps/s=99.81  prediction: \"mannak Duh they used the hydraulic press\" => \"ekr   totei au nTcx.Dkwk/+bu+b++bm/,T/k/\"\n",
      "batch 19124  loss=145.1338  steps/s=103.49  prediction: \"d from 15 relevant studies in 10 seconds\" => \" bo mummemer eere  e  e ee ee e  s  e  s\"\n",
      "batch 19125  loss=151.3789  steps/s=109.53  prediction: \" apart and send each one off to an agent\" => \"tne   at  a a  aaaa  d  a ee     oo     \"\n",
      "batch 19126  loss=151.1259  steps/s=106.40  prediction: \"ow readable zig is. how does ak do it???\" => \"u \n",
      "  n nee    hr                        \"\n",
      "batch 19127  loss=145.6266  steps/s=99.24  prediction: \"gonna code to one song and one song only\" => \" oe  @in  non w  o  o oonn  nn  o n  nn \"\n",
      "batch 19128  loss=173.3387  steps/s=90.50  prediction: \"y brotha ty, nah no zig for this bad boy\" => \":sina andho t not  n t  n a   oon  o o  \"\n",
      "batch 19129  loss=145.8303  steps/s=98.90  prediction: \"s using techniques right under our noses\" => \" pur w o   e  us un   s  i  n ueuuu   n \"\n",
      "batch 19130  loss=145.4576  steps/s=102.94  prediction: \"zations seem like they could be improved\" => \"e  ol tb  r ddn z'qF.zFE6.EEAl6zz6,6kyqA\"\n",
      "batch 19131  loss=154.6354  steps/s=97.82  prediction: \"ental growth is king. get that bread son\" => \" t   neea e t  rr tt      g  gt  t tt  t\"\n",
      "batch 19132  loss=190.0798  steps/s=79.20  prediction: \"072 im super glad man! love to hear that\" => \"x u x @ nerhw enz'qkg!!/q//w!/kpz!./?y.A\"\n",
      "batch 19133  loss=157.3018  steps/s=105.92  prediction: \"nt ask for almost bricked my work laptop\" => \"  u  a  r dd  n                    k    \"\n",
      "batch 19134  loss=136.9322  steps/s=104.57  prediction: \"ion ability. should be trained first tbh\" => \"nntio c too lliiiii         i        i  \"\n",
      "batch 19135  loss=139.3159  steps/s=96.49  prediction: \"gh, regardless it needs a lot of work xD\" => \" tnot  io ,r rtr   eee ee  e s e      o \"\n",
      "batch 19136  loss=177.6572  steps/s=61.99  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"tbs, neeretoerg    eeessss e t     o  o \"\n",
      "batch 19137  loss=179.5487  steps/s=127.70  prediction: \"t; triang L gang https://t.co/qWvYlj8BfE\" => \"h urann egig gg gg  gtg   tt/ //// t////\"\n",
      "batch 19138  loss=164.5720  steps/s=105.24  prediction: \"ort (effort is proportional to time butâ€¦\" => \"u_ tert  e  tff fffr  orpoooooro oootto \"\n",
      "batch 19139  loss=151.9503  steps/s=98.53  prediction: \"cise or anything else prevent this loss?\" => \"hnleirhrreee eee  e      e eeeeeeee e  e\"\n",
      "batch 19140  loss=143.8308  steps/s=101.97  prediction: \"oser and closer until you can putt it in\" => \"ut:iltt th     l                        \"\n",
      "batch 19141  loss=170.3482  steps/s=109.84  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" siffo et  l         s  s s   ttt.t//s/t\"\n",
      "batch 19142  loss=146.1529  steps/s=105.61  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \" ce aegaan nniiiii iiitttttttttt//////tt\"\n",
      "batch 19143  loss=147.0885  steps/s=103.30  prediction: \"ow is that i know nothing\n",
      "- some guy idk\" => \"  t tt el ttt t      t t  t    n n  n n \"\n",
      "batch 19144  loss=155.1684  steps/s=113.23  prediction: \"cipe for less funny + fake feeling posts\" => \"hne oem te eee s   se  ef   e   f ff e  \"\n",
      "batch 19145  loss=181.9777  steps/s=112.74  prediction: \"ful to me, like use every day type stuff\" => \"ol  c thv  tnenn,bN)ER-y(N3R).\n",
      "W(R.33,,F\"\n",
      "batch 19146  loss=149.7333  steps/s=111.31  prediction: \"like there's more of a person there, idk\" => \"yteip e esl leleee   ee e e       e   re\"\n",
      "batch 19147  loss=148.4519  steps/s=109.25  prediction: \"sively going up\n",
      "But make responsibilityâ€¦\" => \" bll  v rrrev h  gggggg g    ee     pe  \"\n",
      "batch 19148  loss=151.2015  steps/s=90.10  prediction: \"lity is really really powerful, actually\" => \"yv  lAeii i iiii il  lylllll elll   elll\"\n",
      "batch 19149  loss=172.9738  steps/s=56.09  prediction: \"@startupmillyair https://t.co/QgfnCndCQA\" => \"sucwiAA in  iillyyly lylllllll llluaalau\"\n",
      "batch 19150  loss=177.3560  steps/s=73.52  prediction: \": @0xluffyb graphics programming be like\" => \" @sta ne  e  on P\n",
      "BuwB`:kw,k:A/Qd\n",
      "c/QgbQ\"\n",
      "batch 19151  loss=147.4015  steps/s=115.61  prediction: \"nomic than discord id switch immediately\" => \"gte irh nggemmomo       o cd ic  ii iddi\"\n",
      "batch 19152  loss=145.3907  steps/s=111.85  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e  eeenletne eet e  e a a     a   aa    \"\n",
      "batch 19153  loss=175.2892  steps/s=110.67  prediction: \" 4min miles, need to know whats possible\" => \"t7tciatthmihn  m  i    ee e        wwwww\"\n",
      "batch 19154  loss=151.7779  steps/s=112.85  prediction: \"ain (they \"want\" to work), but work silâ€¦\" => \"tl t t tll  t   t  t  \"\"\"\"              \"\n",
      "batch 19155  loss=150.3912  steps/s=99.43  prediction: \"MTB a dollar flowing through the economy\" => \"TB @ aen  n na la lll    ow t t  t oo   \"\n",
      "batch 19156  loss=172.9419  steps/s=50.31  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @0i XnTll laala lll    oo t t  h oo oo\"\n",
      "batch 19158  loss=155.9241  steps/s=115.94  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" an i   oononoa n  o   ett     tdt atast\"\n",
      "batch 19159  loss=152.9392  steps/s=108.39  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \"hoh   bt a t t    t  t tttt tt  ///xx///\"\n",
      "batch 19160  loss=167.7195  steps/s=102.48  prediction: \"king one open rn just cause of this post\" => \" na cranccnan  o  onn   n   on  so    s \"\n",
      "batch 19163  loss=149.1355  steps/s=103.98  prediction: \"ugh or is it just whatever comes to mind\" => \"sh  o tr ir g  or i       tt   t t  t  t\"\n",
      "batch 19165  loss=145.3541  steps/s=112.53  prediction: \"ed hard at improving, mostly by studying\" => \"   o   wdhdd  dd   r r    o  o         y\"\n",
      "batch 19166  loss=146.9942  steps/s=113.74  prediction: \"e did not seem like the type to work out\" => \" so r tf ae   de  e   ee  e e e t e  e t\"\n",
      "batch 19167  loss=160.0246  steps/s=110.74  prediction: \"am and it doesnt mess your sleep up much\" => \"r   a  n a  d d d    n       s  sss    u\"\n",
      "batch 19169  loss=169.1747  steps/s=107.34  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \"g  o 9hh aot  t  t  t  oeeo  ee eo   e r\"\n",
      "batch 19170  loss=160.1624  steps/s=108.40  prediction: \"ce nice\n",
      "Any idea what youre gonna print?\" => \"h aa a  n ecnncn  ei    e    e        t \"\n",
      "batch 19171  loss=155.5158  steps/s=107.45  prediction: \"almost as bad as jan blocking his bishop\" => \"r  e  on s l ol a   aa aa  a  n  n iin  \"\n",
      "batch 19172  loss=154.3998  steps/s=113.56  prediction: \" of how i debug and catch inefficiencies\" => \"af p sorma p a t o  o    a   i i a iccic\"\n",
      "batch 19173  loss=153.9512  steps/s=111.89  prediction: \"x len output, custom system prompts, etc\" => \"_c@e ptm em  u t  eutuu uut t m s stttmp\"\n",
      "batch 19174  loss=153.3300  steps/s=113.56  prediction: \"potential. then one day, it all explodes\" => \"lst ontla t e ttten  ntn   e    e  l   l\"\n",
      "batch 19175  loss=155.5363  steps/s=105.20  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"aMSB o eaate    o   oo n o n    n  n   e\"\n",
      "batch 19177  loss=142.2242  steps/s=104.69  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"te eMTB n  enenn  e              a      \"\n",
      "batch 19178  loss=149.5342  steps/s=113.77  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" entuet rn  r  trr   r o oroo o ooo o oo\"\n",
      "batch 19179  loss=160.4562  steps/s=111.37  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"ttaaa anannana ammam m mmammmm a   a    \"\n",
      "batch 19180  loss=154.7191  steps/s=112.68  prediction: \"cipe for less funny + fake feeling posts\" => \"onlaoss te eee s   se  ef   e   f ff e  \"\n",
      "batch 19181  loss=145.2605  steps/s=113.47  prediction: \"o make a significant impact on your life\" => \"umu   in    a ai iaiiiiiiiiiiaii        \"\n",
      "batch 19182  loss=142.6664  steps/s=111.89  prediction: \"this the more you will see it everywhere\" => \"he  o e ththt               e    iee eee\"\n",
      "batch 19183  loss=152.9617  steps/s=109.28  prediction: \" wanted to include infinite programs too\" => \"aat  net n n t nnn i  i iiniii iiiniin r\"\n",
      "batch 19184  loss=151.3871  steps/s=113.26  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"aak  en eeooll tool ll  lllllll  al  a  \"\n",
      "batch 19185  loss=135.4880  steps/s=113.73  prediction: \" local optima solution they got stuck in\" => \"tise  tt    t  t  t toooooo oooottt tttt\"\n",
      "batch 19186  loss=175.2717  steps/s=113.24  prediction: \"/t.co/b4u15DdxTi https://t.co/zpqmNRvyAq\" => \"/.otpso ////otett44tttt/t:p/t/t./t//tt/t\"\n",
      "batch 19187  loss=149.2419  steps/s=110.65  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"  e ttl,nndn  a                /////t///\"\n",
      "batch 19188  loss=173.2055  steps/s=108.49  prediction: \"ff has been helping ppl. I love humanity\" => \"   ta g tdst  e w/,vvT.EvObb(GIbk,u)fTIE\"\n",
      "batch 19190  loss=158.7034  steps/s=113.62  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltee nlalols oslp kkookkkooonoono oono  \"\n",
      "batch 19191  loss=141.6745  steps/s=114.12  prediction: \"n stuff that just sounds nice in my head\" => \" ae a us,ettstt t tt ttt ss s s  n    n \"\n",
      "batch 19192  loss=153.9316  steps/s=110.30  prediction: \"e, and i know i need to get back into it\" => \"  rsi in i    nn      n       e         \"\n",
      "batch 19193  loss=160.2084  steps/s=109.70  prediction: \" student theorem https://t.co/kq5y3YH26S\" => \"ttr iniid enntn  eeeettt ttte ttttt////t\"\n",
      "batch 19195  loss=154.7021  steps/s=111.43  prediction: \" a lot will impact the rest of your life\" => \"t dinog ni  n ll   ilt   t    t  t   o  \"\n",
      "batch 19196  loss=151.3940  steps/s=113.14  prediction: \" strategy is short term low integrity BS\" => \"too  e   an s es s  ss s  s  tr t  t  it\"\n",
      "batch 19198  loss=156.8511  steps/s=81.97  prediction: \"notmoeezm gotta love the non specificity\" => \"gtsr  wi aite nsttt  te   o   t    t tii\"\n",
      "batch 19199  loss=151.6266  steps/s=106.74  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"n ns e lt  te ae  eeaeeeeeeeeeeeeeeeeeee\"\n",
      "batch 19200  loss=151.1516  steps/s=105.80  prediction: \"w zooming forward on an electric scooter\" => \"amu e ntew woon oo ooo  o oon n    nc ec\"\n",
      "batch 19201  loss=163.2079  steps/s=105.49  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \" t t i i g  n           a  ttttt/////to/\"\n",
      "batch 19202  loss=142.4982  steps/s=106.52  prediction: \"e know this isnt https://t.co/q4hu54bfZT\" => \" aoe  w  n ww     t tttttttttt////////44\"\n",
      "batch 19203  loss=150.9787  steps/s=105.91  prediction: \".. would love to be proven wrong on this\" => \"\n",
      " i l t daw.. .l o   o     o    oooo  o \"\n",
      "batch 19204  loss=145.3814  steps/s=102.55  prediction: \"t\n",
      "so.. hopefully i can get it to do that\" => \" \n",
      "o a i  e epeee                        \"\n",
      "batch 19205  loss=140.8095  steps/s=107.67  prediction: \"vision how great itll be once youre done\" => \"en hena nhn   n  o                     e\"\n",
      "batch 19207  loss=144.9966  steps/s=92.80  prediction: \"h\n",
      "Also good to know abt the muting thing\" => \"e\n",
      "iss d dsodooooooooooooo            tt \"\n",
      "batch 19208  loss=145.8687  steps/s=98.50  prediction: \"d hire my friends to do research with me\" => \" to  tto te   ye  r          rr re  r   \"\n",
      "batch 19209  loss=143.3600  steps/s=106.96  prediction: \" the zero quine: https://t.co/qt0qAp9ZYk\" => \"the te tttttt              t::tt////qqqq\"\n",
      "batch 19210  loss=190.2237  steps/s=125.77  prediction: \"ze regret &gt;&gt;&gt;&gt; minimize pain\" => \"irg x e0 tgA tP B@;zmjzlmIz,,A1IkIIzIyzy\"\n",
      "batch 19211  loss=158.2032  steps/s=106.50  prediction: \"gh Ive been wanting to do a wasm project\" => \" t  t @ b lle  eee  e   n   t           \"\n",
      "batch 19212  loss=155.7028  steps/s=86.47  prediction: \"nsettler cant spell family without AI :D\" => \"   zt   be te    n n        a         o \"\n",
      "batch 19213  loss=184.4542  steps/s=73.96  prediction: \" 6. sidescroller https://t.co/kldrXQtTOI\" => \"tlte ne eeen  n  n     e    a o    t  o \"\n",
      "batch 19214  loss=168.8501  steps/s=110.41  prediction: \"mannak Duh they used the hydraulic press\" => \"aze e I tai em r&;k&Du:;&;v:;/kvzIXQlTOA\"\n",
      "batch 19215  loss=161.6389  steps/s=106.71  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAP t nst  A t  u   t e  ???? B???saees\"\n",
      "batch 19216  loss=168.1478  steps/s=112.16  prediction: \"p chats and 4chan are two i can think of\" => \"ltt  . nt\n",
      " ttoat  a4   a   h     a  aac \"\n",
      "batch 19217  loss=148.5672  steps/s=111.84  prediction: \"on\n",
      "\n",
      "im guessing you do that a lot to huh\" => \"ue t  tatt es  nssss      t        t  t \"\n",
      "batch 19218  loss=148.6049  steps/s=91.54  prediction: \" a friend that did this for a CS project\" => \"t       ea  s a    d d    t        o    \"\n",
      "batch 19219  loss=144.2494  steps/s=109.45  prediction: \"ational ones it might actually be useful\" => \"n s  nr ndr foont io in n   t t tlt aala\"\n",
      "batch 19220  loss=142.4347  steps/s=100.19  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t    ete           hhtttttttttttttt/////\"\n",
      "batch 19221  loss=169.3610  steps/s=94.11  prediction: \"ay and thursday bros\n",
      "THE GRIND DONT STOP\" => \"n o t ol n     n  y  d     ds r  TTTD TT\"\n",
      "batch 19222  loss=146.9657  steps/s=96.45  prediction: \"nd me tracks and ill render them for you\" => \"d  eeci nh  n                   r   e   \"\n",
      "batch 19223  loss=141.4878  steps/s=100.84  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \"  istnist  t        t tt tttttot--ttttot\"\n",
      "batch 19224  loss=147.7079  steps/s=107.92  prediction: \"nin man, was a great great time as usual\" => \" s oe t shn a w n a a  a aaa a  a aa at \"\n",
      "batch 19225  loss=161.7637  steps/s=109.90  prediction: \"uper hard but I think it could be doable\" => \"te n  l  mppe rprrar r  r r  t        u \"\n",
      "batch 19226  loss=193.8712  steps/s=88.74  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"tra ba u    d %%OOOOO O      t//////t///\"\n",
      "batch 19227  loss=184.3046  steps/s=32.09  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y: @Jade r  e  TOOOO      S /t///////VV6\"\n",
      "batch 19228  loss=178.6165  steps/s=86.21  prediction: \"ply: @yacineMTB Just ask it to go faster\" => \"ly: @  tes  TT POO       SS// /////t/66ðŸ›‘\"\n",
      "batch 19229  loss=153.7824  steps/s=113.39  prediction: \"nbelievably cracked\n",
      "\n",
      "still 25 years left\" => \" s ae  m eet e  e  eecee ell ll ll  e ll\"\n",
      "batch 19230  loss=149.2302  steps/s=98.20  prediction: \"olve for the entire past week was a typo\" => \"  e te        e  e e e    e eeeeee    e \"\n",
      "batch 19231  loss=152.9098  steps/s=112.82  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \" \n",
      "e iti\"\n",
      " \n",
      "\"iioffof ffffofof  looo   n  \"\n",
      "batch 19232  loss=150.3907  steps/s=108.05  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"   rondodno  on    d   n    ne  eer  ee \"\n",
      "batch 19233  loss=182.4603  steps/s=113.11  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" yoe tt  o  sddn+z\n",
      "-xxmpd,+:bf4.:/xz.ZZq\"\n",
      "batch 19234  loss=152.9274  steps/s=113.48  prediction: \"s with standard sees wrapping (somewhatâ€¦\" => \" boe  foe  ese ss  s sa s ar ssssssew wa\"\n",
      "batch 19235  loss=145.3601  steps/s=111.27  prediction: \"mind responds to and processes phenomena\" => \"anesa so nnw y tU@U`BJP99BAPJVJJJJ(8(b%J\"\n",
      "batch 19236  loss=166.8876  steps/s=88.19  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"edg ook mo ro  n o    d    ppsesspnesene\"\n",
      "batch 19238  loss=142.3943  steps/s=112.75  prediction: \"a single man who can bench more than 400\" => \"td en non n n en          n          n  \"\n",
      "batch 19239  loss=156.9189  steps/s=68.95  prediction: \"@btwphones thanks! its going well so far\" => \"ytdwcw_ n n     n nn   nn   n     h    0\"\n",
      "batch 19240  loss=140.6395  steps/s=120.10  prediction: \" ill dm you a link to it around the 25th\" => \"tn wteete te  el   l                 t  \"\n",
      "batch 19241  loss=150.5378  steps/s=113.17  prediction: \"m, are also used in calculating/thinking\" => \"a s  sol  nn pn ï¸cbÊ€p=#bá´˜{$á´›#b,$â€¦,â€œ$vb$ðŸ˜¢\"\n",
      "batch 19242  loss=163.0554  steps/s=100.57  prediction: \"p in the readme\n",
      "\n",
      "https://t.co/dWiO4erSb1\" => \"ltae@te  e tte \n",
      "ee\n",
      "tet\n",
      "\n",
      "\n",
      "tett  //eht//tt\"\n",
      "batch 19244  loss=147.0676  steps/s=111.20  prediction: \"is such a great productivity improvement\" => \"n     uctt     s              t i tttiii\"\n",
      "batch 19245  loss=145.0736  steps/s=110.35  prediction: \"was making me sleep deprived unknowingly\" => \"_y n t n i      e  e e  eee  eee eeeenee\"\n",
      "batch 19246  loss=161.1026  steps/s=114.20  prediction: \"ogical Calculusâ€¦ https://t.co/NKruhIqhgv\" => \"rraara\n",
      "en \n",
      "Loo  aalallllllllll tsct/tt//\"\n",
      "batch 19247  loss=172.3342  steps/s=110.75  prediction: \"like 2 cups of coffee\n",
      "\n",
      "Need to downcycle\" => \"yte  ss t     u       e  efff\n",
      "eeeee  o e\"\n",
      "batch 19248  loss=160.0180  steps/s=111.89  prediction: \" learning how things work under the hood\" => \"tone  n eaen n     i  hn  n   no   nn   \"\n",
      "batch 19249  loss=145.1572  steps/s=111.81  prediction: \"ind. also so my brain doesnt deteriorate\" => \"ng   ng na  n                         dr\"\n",
      "batch 19250  loss=168.0331  steps/s=110.05  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "  mea  ns m seesees es ees es es  s  s\"\n",
      "batch 19251  loss=156.0670  steps/s=113.84  prediction: \" approximate it better outcompete others\" => \"tbl lniter rmr t aat iti et t   tttete o\"\n",
      "batch 19252  loss=155.9497  steps/s=108.85  prediction: \"durr. the kings gambit. crazy mf opening\" => \" se eueerter  hr   r     t  .        m  \"\n",
      "batch 19253  loss=160.5685  steps/s=110.26  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \" se str  it   asa   aasan s   naaa\n",
      "a t  \"\n",
      "batch 19254  loss=145.4770  steps/s=113.32  prediction: \"experience but i work w someone who does\" => \" at    n nn netee eee e      e       ooo\"\n",
      "batch 19255  loss=174.9489  steps/s=113.04  prediction: \" 4min miles, need to know whats possible\" => \"txt ia thmih  mm  i    ee e        wowww\"\n",
      "batch 19256  loss=150.3397  steps/s=110.37  prediction: \"eft\n",
      "right looks right\n",
      "its a miracle init\" => \" u lln\n",
      "\n",
      " lonll loololt tttttt     tiii i\"\n",
      "batch 19257  loss=137.9858  steps/s=113.52  prediction: \"t half-done things\n",
      "\n",
      "putting them in theâ€¦\" => \"hia te hb  t  t t   nntttntttttttntn ttt\"\n",
      "batch 19258  loss=147.6771  steps/s=113.06  prediction: \"tal clarity and less of a need for sleep\" => \" ls   t ne mnnel l  llal al    e    e   \"\n",
      "batch 19259  loss=147.0366  steps/s=113.33  prediction: \"s but I strongly believe in it long term\" => \" ao  t a   ss g              e          \"\n",
      "batch 19261  loss=156.8570  steps/s=110.59  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tao tee    t   et t tt  ttttt /t/tt/////\"\n",
      "batch 19262  loss=159.0221  steps/s=109.80  prediction: \"ee time lately\n",
      "\n",
      "it has a long ways to go\" => \" mie  rmer meea ee ttee lte  a  lal l s \"\n",
      "batch 19263  loss=143.9288  steps/s=106.06  prediction: \"chat is this what sweat equity means????\" => \"h   s at et t it hht  t  t t  t  t e ts?\"\n",
      "batch 19264  loss=153.6490  steps/s=112.08  prediction: \" which uses a superset of c. so not sure\" => \"tai chtc c cn  c    ss  s s    s     s  \"\n",
      "batch 19265  loss=152.6875  steps/s=113.57  prediction: \" improve a processing unit's ability toâ€¦\" => \"ts eara nrc    p rpr  s s    ssss i iiii\"\n",
      "batch 19266  loss=144.1405  steps/s=113.79  prediction: \"oast. silencio until youve made progress\" => \"nl eit so t s is t ii ioi i  o          \"\n",
      "batch 19267  loss=160.7620  steps/s=111.45  prediction: \"tent and youll get stronger and stronger\" => \" r t  e s tt nt t        n   n   nt n rr\"\n",
      "batch 19268  loss=177.2862  steps/s=87.89  prediction: \"eigecamry @sunsettler shredded that shit\" => \" r nn@ e en n  l   tt sttt rrn eeded nrr\"\n",
      "batch 19269  loss=165.3128  steps/s=112.33  prediction: \"s every time I'm getting comfortable lol\" => \" me  i i memm   t m te e tiie  etm e tet\"\n",
      "batch 19270  loss=166.4744  steps/s=112.31  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nesom \n",
      "\n",
      "ndnl l      N N NN ::::/:://////\"\n",
      "batch 19271  loss=154.2752  steps/s=104.75  prediction: \"sed\n",
      "\n",
      "Try it asap\n",
      "https://t.co/ZK8YpKEtoP\" => \" lr   o rf rs n \n",
      "r a\n",
      "\n",
      "es ss\n",
      "\n",
      "\n",
      "t  //t/Zp/\"\n",
      "batch 19272  loss=133.5042  steps/s=113.20  prediction: \"nd of mental ownership over the codebase\" => \"g i tneit                        ee eeee\"\n",
      "batch 19273  loss=140.9689  steps/s=112.92  prediction: \"he end result could look like\n",
      "\n",
      "followed!\" => \"e e  o  t teeeht e  ee    o llll llollll\"\n",
      "batch 19274  loss=137.6727  steps/s=109.93  prediction: \"gh, regardless it needs a lot of work xD\" => \" t oe  re erhrgr   eee ee  e   e        \"\n",
      "batch 19275  loss=140.4011  steps/s=111.83  prediction: \" to get tons of llms to output good code\" => \"theetnei tg gt tt  oo      o  o   oo  oo\"\n",
      "batch 19276  loss=147.8040  steps/s=113.64  prediction: \" loss (erroneously a vector) as a scalar\" => \"tot  hd h s s sooooooo  ee              \"\n",
      "batch 19277  loss=154.9098  steps/s=98.71  prediction: \"ht. i feel like i barely understand them\" => \"et o ne n   le n  e    i ee   lee  e e e\"\n",
      "batch 19278  loss=130.4802  steps/s=100.38  prediction: \" the skill ceiling is really really high\" => \"the le l  t    l  iiiiiiiiiillllllllllll\"\n",
      "batch 19279  loss=168.1500  steps/s=86.43  prediction: \"Gotta make one and learn that skill then\" => \"oeb d anelrnt ate e  aee nn   a laaea  h\"\n",
      "batch 19280  loss=155.1309  steps/s=95.31  prediction: \"ng so you can automate ruining your life\" => \"g ia e oma nn nn    o     a  a unu uui u\"\n",
      "batch 19281  loss=161.3024  steps/s=104.83  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " k dninn nm    Êœá´„á´„ÊœðŸ›‘#æˆ‘vð—µQp#v$gbÊœá´˜#Éªæˆ‘cI^\"\n",
      "batch 19282  loss=162.5748  steps/s=111.51  prediction: \"rs automatically slap that down to 10fps\" => \"e   ro 0fht s g Sxuv!:vW0:gjf.bv5w150,k1\"\n",
      "batch 19283  loss=150.2619  steps/s=107.93  prediction: \"ven a bit is a huge anti pattern i think\" => \"er eevevean   biin a a  ii    i    t    \"\n",
      "batch 19284  loss=146.8646  steps/s=113.96  prediction: \"w. Might do one every mon and every tues\" => \"a te  o t trro t ooooo o   e     e   e e\"\n",
      "batch 19285  loss=141.3492  steps/s=112.70  prediction: \"endeavors im going to do til ive done it\" => \" ti    e a    ft o ooo       o io   i   \"\n",
      "batch 19286  loss=134.9827  steps/s=110.77  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"tnt e  t            ssssssssss//////////\"\n",
      "batch 19287  loss=144.8609  steps/s=113.09  prediction: \"compress a lifetime into a few sentences\" => \"omp ite tnses s  e e eiii i          eee\"\n",
      "batch 19288  loss=158.2136  steps/s=98.48  prediction: \"erminal sub window alongside your files?\" => \"  ina et   n       aa  aa  a  on  ii    \"\n",
      "batch 19289  loss=174.1104  steps/s=30.49  prediction: \"ply: @ns123abc mad growth, what happened\" => \"ly:  sp a  a  a    aa wan  w  oo  ii    \"\n",
      "batch 19290  loss=160.7364  steps/s=112.16  prediction: \"orn to make cash forced to consooolidate\" => \"  tt ttit tt t        c cc c  co  oooooo\"\n",
      "batch 19291  loss=153.9291  steps/s=92.02  prediction: \" is actually happening behind the scenes\" => \"tn e oente  t l aaa a aaa   nn hnhn    e\"\n",
      "batch 19292  loss=157.9372  steps/s=86.36  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \" ctaiea  eett nee    a       ht e e ee  \"\n",
      "batch 19293  loss=152.9414  steps/s=106.56  prediction: \"gram faster which made him have more fun\" => \" a  a nerr mr rr ar h hh hhh mh mh mh m \"\n",
      "batch 19294  loss=158.1294  steps/s=114.00  prediction: \"from 20% to 13.5% in like 3-4 months lol\" => \" oa g   i   )% aF13355(wv20%)kFw-445%,)u\"\n",
      "batch 19295  loss=148.0588  steps/s=112.88  prediction: \"r reward, wrecking the incentive to work\" => \"eie tn oot t tttVVV,â€¦HHxV\"xzz7VHVVDDVHV\"\"\n",
      "batch 19296  loss=143.6209  steps/s=112.99  prediction: \"e the reward dips down below the average\" => \" aodrg  ereerrrerer  d dddd    we    e  \"\n",
      "batch 19298  loss=145.6674  steps/s=110.85  prediction: \"hange your brain. something to think abt\" => \"ev  sr  sor  orr  rr r   or    o  no  t \"\n",
      "batch 19299  loss=140.7429  steps/s=112.69  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \"nsonin in t       t                   ee\"\n",
      "batch 19300  loss=145.3816  steps/s=112.03  prediction: \" fundamentals.  Take the time to invest.\" => \"too oto   t  ttta  a a                  \"\n",
      "batch 19301  loss=145.4555  steps/s=113.10  prediction: \"ngry each chunk) it pretty much kills it\" => \"g   e n  a  n  h                        \"\n",
      "batch 19302  loss=138.7144  steps/s=110.90  prediction: \"quote a lot bc it seems to come up a lot\" => \"cas_isi it    ttt                       \"\n",
      "batch 19303  loss=127.8110  steps/s=109.26  prediction: \" feel to be a tier above elon @teodor_io\" => \"toi  ie te    e           e     eeeoeooo\"\n",
      "batch 19304  loss=157.5272  steps/s=31.90  prediction: \"ply: @jaivinwylde top tier game for sure\" => \"ly: @ atwe    eee     e e ee    eeeooooo\"\n",
      "batch 19306  loss=172.6197  steps/s=125.52  prediction: \"@jamstack_guru Speed of launches as well\" => \"aaeeiallo e   tee   eee e oe e  eee oooðŸ›‘\"\n",
      "batch 19307  loss=147.4183  steps/s=116.69  prediction: \"sonnet3.5 for pretty much everything now\" => \"  e\n",
      "e  e tone e    eet ttt     eee  et  \"\n",
      "batch 19308  loss=159.6984  steps/s=109.36  prediction: \"sing llms to their full potential rn tbh\" => \" vesn  eel rs e    l  tllt  l   tle   tn\"\n",
      "batch 19309  loss=136.7604  steps/s=111.12  prediction: \"t leak info from the stream accidentally\" => \"hihe  ito  t on   o    o   o      e  aaa\"\n",
      "batch 19310  loss=149.8080  steps/s=113.57  prediction: \"eving it is super painful\n",
      "\n",
      "Very valuable\" => \" ei  fnit    ii  i iii i  ii   i     uue\"\n",
      "batch 19312  loss=147.0189  steps/s=113.90  prediction: \"this is needle in haystack\n",
      "\n",
      "imo its weak\" => \"he  on nh   i ii  i  ii  i  i  ii   si i\"\n",
      "batch 19313  loss=166.9726  steps/s=107.00  prediction: \" tool\n",
      "\n",
      "RECURSION https://t.co/VnbltPql2g\" => \"the relrrro  o   oRoURRSOONONN:/tt/tt/tt\"\n",
      "batch 19314  loss=222.3507  steps/s=93.61  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OTVITo IOE OTN N ON  T OI         ttt //\"\n",
      "batch 19315  loss=170.9017  steps/s=109.67  prediction: \"t just means youre on par with a supergm\" => \"hat t hisssesmsstss  s s   o            \"\n",
      "batch 19316  loss=163.3178  steps/s=109.82  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @ a o  e     e  o o     o oo        \"\n",
      "batch 19317  loss=170.3198  steps/s=23.46  prediction: \"ply: @sunsettler https://t.co/gCxzVkTiTl\" => \"ly: @ ano tee    t  o o   o o o       r \"\n",
      "batch 19318  loss=142.5293  steps/s=113.02  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"y\n",
      " eileiei lllip        p   p    a a    \"\n",
      "batch 19319  loss=135.4793  steps/s=109.35  prediction: \"ntext into a computation to make it pure\" => \"gi s asi  tnt no    ttttttttototttt  t  \"\n",
      "batch 19320  loss=179.2697  steps/s=111.62  prediction: \"rs of Chipotle priced in already??? Wtf?\" => \"e iihyt s thi t yk.2xB,2EC,uv\n",
      "I,CbjWC??x\"\n",
      "batch 19321  loss=149.8038  steps/s=112.60  prediction: \"ooks like from someone elses perspective\" => \"n h wht  te   ko   ooo ooeooeoeeseeeseee\"\n",
      "batch 19322  loss=143.0065  steps/s=110.80  prediction: \"ns you get the yellow letters on lichess\" => \"g  an te ot e t t tt  ee  le tee ee lee \"\n",
      "batch 19323  loss=149.9702  steps/s=88.37  prediction: \"wigABAP a friendly virus. one that talks\" => \"igABn  ynt  t y ee e  ll l e  ee  t te t\"\n",
      "batch 19324  loss=149.5082  steps/s=103.13  prediction: \"een enough to find mentorable candidates\" => \" d h   n e  n hn     e  e    n   nennnan\"\n",
      "batch 19325  loss=174.0314  steps/s=30.73  prediction: \"ply: @sunsettler https://t.co/New7TNXl4J\" => \"ly: @t t      n      n  n n  n   n nnnaa\"\n",
      "batch 19326  loss=156.3382  steps/s=99.72  prediction: \"while his chess opponents mind went 3fps\" => \"ieds ten ii  h  ih hsssss s ppp sssn   s\"\n",
      "batch 19327  loss=153.4169  steps/s=90.86  prediction: \"be allocate some time to do fun projects\" => \"e  io  on    aa        t          o     \"\n",
      "batch 19328  loss=149.8192  steps/s=96.72  prediction: \"erfect timing actually if thats the case\" => \" esn  g Pett itttittt ti tt  t    t t t \"\n",
      "batch 19330  loss=142.2355  steps/s=98.12  prediction: \"he end result could look like\n",
      "\n",
      "followed!\" => \"e e  etet teeeht e  ee    o llll llollll\"\n",
      "batch 19331  loss=140.3069  steps/s=88.96  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \"nnt pnpi e o oeno  e  e     ee    e    e\"\n",
      "batch 19333  loss=143.7439  steps/s=105.18  prediction: \" the time. personally i havent done this\" => \"the tet t   tt t  ee  ll    ell l      e\"\n",
      "batch 19334  loss=162.4083  steps/s=98.78  prediction: \"t in a position to help you at all loool\" => \" firbrabn a pi otton n     a  oot  oo  l\"\n",
      "batch 19335  loss=174.6202  steps/s=51.40  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"lud4al    o iiiotttnit        y l  !! ll\"\n",
      "batch 19336  loss=146.9798  steps/s=97.11  prediction: \"sonnet3.5 for pretty much everything now\" => \"   se ee tote e    eet ttt     eee  et  \"\n",
      "batch 19337  loss=155.8772  steps/s=97.92  prediction: \"r die, and when they swim they find food\" => \"eso   @s  n  egtPv,,,vLOw2m.\n",
      ",145k,1LO1)\"\n",
      "batch 19338  loss=149.8512  steps/s=98.02  prediction: \"aise), and we'd end up in the same place\" => \"nn t  n   s aa ade ea  d dd  d  n       \"\n",
      "batch 19340  loss=171.1609  steps/s=96.07  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"pkih iea o te_s P'BkTwHqk!),H0u!DHAELOq[\"\n",
      "batch 19341  loss=149.9422  steps/s=96.48  prediction: \" then maybe do a bit of chess, or watchâ€¦\" => \"to   teg etn  b                         \"\n",
      "batch 19342  loss=176.2351  steps/s=94.36  prediction: \"@p0nnnpppppppppp https://t.co/5V1IjMrIYA\" => \"lidwigA  h ppppppppppppppppttp//////cc//\"\n",
      "batch 19343  loss=173.3456  steps/s=94.65  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \"Ov  it      \"\"     t tttttttttt/////////\"\n",
      "batch 19345  loss=147.4390  steps/s=93.81  prediction: \"r coding lol. And some chess. Great move\" => \"elo tmeenerteeeePR6bvN.kAwbvS.bA)O.IAAR)\"\n",
      "batch 19346  loss=151.8061  steps/s=87.10  prediction: \" that initially seemed meaningless to me\" => \"the utrt  tnee tilti iee  eiei eieee e e\"\n",
      "batch 19347  loss=160.7041  steps/s=98.33  prediction: \"w the game state https://t.co/jm2YeI7PB9\" => \"iw   t le w    t e  t t  ttttt tttt t//e\"\n",
      "batch 19348  loss=154.3127  steps/s=96.31  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"ne ts  e\n",
      "\n",
      "m\n",
      " \"\n",
      " mmmm\n",
      "\n",
      "\n",
      "m&&&&;;;;;gtttttu\"\n",
      "batch 19349  loss=155.5374  steps/s=88.39  prediction: \"forward, forever\n",
      "https://t.co/zlto3SBYwd\" => \" r  ti  w,ttths x@BlxbbBMx$$*M&&^;;bÉ´kk*\"\n",
      "batch 19350  loss=151.0961  steps/s=88.64  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to entest  s g     ssss   s            \"\n",
      "batch 19352  loss=147.6216  steps/s=96.56  prediction: \"g correct (fingers crossed its this one)\" => \" ase era tt rrrrr err  rrerr   sse s ss \"\n",
      "batch 19354  loss=149.0502  steps/s=89.78  prediction: \" thanks man! i should uh sleep more yeah\" => \"the    tentan t  n    oss    s s   e   e\"\n",
      "batch 19355  loss=140.6143  steps/s=98.36  prediction: \"u decide to start building it initially?\" => \"sgen se nhdde d  t d  dd  t  t iitiiii i\"\n",
      "batch 19356  loss=158.7015  steps/s=94.28  prediction: \"owing that your food supply doesnt scale\" => \"u wi taet n t  ttt     oo      o o  oo  \"\n",
      "batch 19357  loss=155.6779  steps/s=95.27  prediction: \"lex code across multiple (simple!) Files\" => \"ym o ro nn  ce co c  o   ll els  llp lel\"\n",
      "batch 19358  loss=145.8636  steps/s=91.73  prediction: \"just point to concepts and arent reality\" => \"ust      is   ot   oo  o t  tnn n  nnn t\"\n",
      "batch 19359  loss=145.5612  steps/s=88.52  prediction: \"is such a great productivity improvement\" => \"n  cn  cta    hs              t itttiiii\"\n",
      "batch 19360  loss=149.1484  steps/s=100.55  prediction: \"y just dumping them into an LLM and mayâ€¦\" => \" rp oopat  nn mu     m n  t t    LLLL nL\"\n",
      "batch 19361  loss=167.7982  steps/s=90.97  prediction: \"ller accurate. really useful distinction\" => \"y   ane t nur t tt u t   n  a    i an  i\"\n",
      "batch 19362  loss=148.0577  steps/s=95.44  prediction: \"miliar with a place and the things in jt\" => \"enina iathot ne fGbG,Gf@jgzfGz.wyMHjw7jQ\"\n",
      "batch 19363  loss=143.8116  steps/s=86.14  prediction: \"ably do this for all future projects tbh\" => \"tt  o  oeil bbl   o  ol  l   r      r  r\"\n",
      "batch 19364  loss=152.1891  steps/s=88.37  prediction: \"otten most of my follows from Yacine lol\" => \"  e  tet ett te     t  o   ofoooof     o\"\n",
      "batch 19365  loss=163.2976  steps/s=33.23  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y: @Ltt  nttttet    oo o ffof oo       o\"\n",
      "batch 19366  loss=149.1234  steps/s=92.56  prediction: \"DLR but could just be forward/left/right\" => \"o\n",
      "i i eee       uu u u      bu b    r  r\"\n",
      "batch 19367  loss=147.2809  steps/s=91.38  prediction: \"your life (which is what happened to me)\" => \" ur a s  yr  le        ii     whhhh  hh \"\n",
      "batch 19368  loss=140.4218  steps/s=94.83  prediction: \" android OS inside of a virtual machine?\" => \"tnd  nd d  nn  n dd          i       i  \"\n",
      "batch 19369  loss=143.1154  steps/s=90.50  prediction: \"u were in vim, it should start the timer\" => \"sdon gyt y r  i     i  i       t    tt  \"\n",
      "batch 19370  loss=141.0554  steps/s=89.18  prediction: \" to get tons of llms to output good code\" => \"theetnei ttttt tt  to      o  o   oo  oo\"\n",
      "batch 19371  loss=148.8292  steps/s=75.36  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"Vueheneott tottto o totot  s  s t tot tt\"\n",
      "batch 19372  loss=149.5675  steps/s=96.09  prediction: \" then maybe do a bit of chess, or watchâ€¦\" => \"to   teg etn  b                         \"\n",
      "batch 19373  loss=184.6733  steps/s=30.63  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: tsr ee nb n                         \"\n",
      "batch 19374  loss=144.9445  steps/s=108.57  prediction: \"feels better than giving to the homeless\" => \"  de n n_ r c_ag$ffCmzy:./S..w/4CÊ€CU..1O\"\n",
      "batch 19375  loss=142.4460  steps/s=88.20  prediction: \" the most important parts of improvement\" => \"toe te  etto  oo   ottt t  t ott   tt mm\"\n",
      "batch 19376  loss=156.4358  steps/s=88.24  prediction: \" pre session lift make a difference btw?\" => \"tro s    ss sssss s          e     eefef\"\n",
      "batch 19377  loss=148.3045  steps/s=76.90  prediction: \"erIntellectus the italians have returned\" => \"     leeshen eeeetttte   t aaaeaeaaeaeee\"\n",
      "batch 19378  loss=173.3717  steps/s=94.62  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"onbnt  lnenen@ @@ jjjjjj j j    OOOOOOOO\"\n",
      "batch 19379  loss=177.2495  steps/s=98.81  prediction: \" who build cool stuff get followers here\" => \"@eaes nd   epdedloo l o o o l  oo   olf \"\n",
      "batch 19380  loss=170.4481  steps/s=31.10  prediction: \"ply: @pixqc @ludwigABAP i like it\n",
      "boolin\" => \"ly: @  @u  slll loo l o o o l  oo   ole \"\n",
      "batch 19381  loss=152.1361  steps/s=123.17  prediction: \"daily Whats your roadmap for learning ml\" => \" ted l il    ll   o u    oo o  ofl   rrr\"\n",
      "batch 19382  loss=148.1211  steps/s=99.55  prediction: \"as soon as there are melons in the shop)\" => \"n yelt is s    n o  s a a e    e e ee   \"\n",
      "batch 19383  loss=146.0388  steps/s=93.87  prediction: \"n, tons of alpha is already in your head\" => \"g )to  nntttnoat a  a a    a a       a  \"\n",
      "batch 19384  loss=148.4875  steps/s=97.13  prediction: \"at flashcards worked 10x better (bc theâ€¦\" => \"nh reeli t hh hraaa r      rer    ee  ee\"\n",
      "batch 19385  loss=147.5202  steps/s=94.09  prediction: \"to play chess sometime, my li is dnbt777\" => \"h t  bed i            s e   e e         \"\n",
      "batch 19386  loss=152.4586  steps/s=99.70  prediction: \"\n",
      "Learning is the precursor to succeeding\" => \"\n",
      "oe   c  ttet i GLLvkBvy1up'S.jkLvO(1,7,\"\n",
      "batch 19387  loss=175.7513  steps/s=92.76  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \" d feren  fee  e  n          tt/////HH//\"\n",
      "batch 19388  loss=178.6220  steps/s=89.92  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..co  s eott/oo/ttoottttt/ttttt////t///\"\n",
      "batch 19389  loss=153.8900  steps/s=96.74  prediction: \" the time and not spread important info?\" => \"toe t l tll  ee                t  t t an\"\n",
      "batch 19390  loss=135.3713  steps/s=89.26  prediction: \" local optima solution they got stuck in\" => \"tiset tl    t  t  t toooooo oooottt tttt\"\n",
      "batch 19391  loss=159.7455  steps/s=88.45  prediction: \" learning how things work under the hood\" => \"ticd  n eaen nh    i  hn  n   nn   nn   \"\n",
      "batch 19392  loss=190.1782  steps/s=18.71  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @deersennn?   i  hn  n   nn   nne  \"\n",
      "batch 19393  loss=153.9989  steps/s=92.43  prediction: \"rs a question i've been unable to crackâ€¦\" => \"e heo nn inn ansquqq,\n",
      "IqB''v''bIB'B.Bb.B\"\n",
      "batch 19394  loss=164.5312  steps/s=89.15  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \"   eh\"e et&e teggtggtttttotoor t LL tLL \"\n",
      "batch 19395  loss=145.0594  steps/s=87.26  prediction: \"e transformer architecture works so well\" => \" ar     n  n  nnr  rrrrrrrrrrrrrrrrrrre \"\n",
      "batch 19396  loss=152.0915  steps/s=86.49  prediction: \" cs maps btw? would love to see pictures\" => \"toy      o  s    s          o  o o  o   \"\n",
      "batch 19397  loss=171.1595  steps/s=88.90  prediction: \"/t.co/T03I8pk4ER\n",
      "https://t.co/XSr1ijr0iv\" => \"t.cu : :t////t/////888tpppEpttttt////t/X\"\n",
      "batch 19398  loss=161.5885  steps/s=85.84  prediction: \"conclusion that the zig code IS the docs\" => \"ont 0  m cc o  to tth tot  th t t      o\"\n",
      "batch 19399  loss=177.0069  steps/s=94.64  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \" i et  e ce  n tje h tt      tt/t / /coc\"\n",
      "batch 19400  loss=146.8272  steps/s=97.15  prediction: \"elete post but it works on anyone's post\" => \" ynntn ueetetebbte t t  tt  o  o   ooo  \"\n",
      "batch 19401  loss=177.7666  steps/s=85.92  prediction: \"ubed making gpt2 from scratch in c(obol)\" => \"stete neleene   tt t  t o  oo   n  noon \"\n",
      "batch 19402  loss=147.4535  steps/s=93.38  prediction: \" the code in my head like an interpreter\" => \"thinti  ttn t           h    e       e e\"\n",
      "batch 19403  loss=167.1748  steps/s=68.39  prediction: \"helscom a new $500k logo should fix this\" => \"e u hco tt    e e         e  n  ie e eie\"\n",
      "batch 19404  loss=150.3880  steps/s=96.90  prediction: \"i can keep it up https://t.co/aDUupaUfqR\" => \"nto  na  e c   ce  ee  p  t s  p  p pp U\"\n",
      "batch 19405  loss=137.4907  steps/s=88.80  prediction: \"ive impact on me yrs after i had to stop\" => \"ne is  s isti i                         \"\n",
      "batch 19406  loss=146.5539  steps/s=94.07  prediction: \"tication string\n",
      "\n",
      "https://t.co/R8lgxFJD3E\" => \"hnn rbl   iiniiiiiitititttttsttttttt///t\"\n",
      "batch 19407  loss=151.0889  steps/s=103.98  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"on o  evan   a c a      ouu    uouu o oo\"\n",
      "batch 19408  loss=140.6857  steps/s=84.94  prediction: \"on said we cant use that word any more!!\" => \"n    n t                     t          \"\n",
      "batch 19409  loss=148.7160  steps/s=90.67  prediction: \"een enough to find mentorable candidates\" => \" dst   n e  n hn     e  n    n   n nnnaa\"\n",
      "batch 19411  loss=137.1623  steps/s=91.34  prediction: \" ill dm you a link to it around the 25th\" => \"tneeteele t    l                     t  \"\n",
      "batch 19412  loss=146.8411  steps/s=93.77  prediction: \"s but I strongly believe in it long term\" => \" an  t d   ss g              e          \"\n",
      "batch 19413  loss=150.8879  steps/s=86.42  prediction: \" muscle for mentally doing them will get\" => \"tort e terrre e rr   e   ll   le  l mll \"\n",
      "batch 19414  loss=172.8479  steps/s=89.48  prediction: \" To Learn (LHTL)\n",
      "https://t.co/zMGdAcfDpd\" => \"tha  trLea   LeL LLT  T  T  L  //tt////t\"\n",
      "batch 19415  loss=156.3118  steps/s=83.69  prediction: \", welcome to circle gang @ineedtolocking\" => \" tnzoo  noolg no eeoc  c cc ee e e@ooeee\"\n",
      "batch 19416  loss=156.1778  steps/s=93.83  prediction: \"rce on github to figure some of this out\" => \"eh i  @egean sotOOwOQOQchpzzb,Q.hybz.,zP\"\n",
      "batch 19417  loss=158.6218  steps/s=94.57  prediction: \"illed w AI tools https://t.co/AIn5typg7l\" => \"nl netetE l l    l       tttttt tttttt//\"\n",
      "batch 19418  loss=151.9079  steps/s=99.38  prediction: \"g Seatbelt doesn't want you to know this\" => \" ah oe le teteetteeeettt e ttt  tt  t  t\"\n",
      "batch 19419  loss=160.8582  steps/s=94.27  prediction: \"roject, complete https://t.co/sjanmaz6rU\" => \"evabce p nei ah jI'k.wojv:y:w.(j\n",
      "kb,:SU)\"\n",
      "batch 19420  loss=150.1180  steps/s=84.07  prediction: \"am not fixing it https://t.co/dsgcKVp5Ha\" => \"ne      a n  n   ii   i tt tt/ /t/t ///t\"\n",
      "batch 19421  loss=164.7445  steps/s=74.02  prediction: \"hones Hype, solid 4hr block, lets get it\" => \"ew aono  n n ii iit   iitt tt/  tccc gtt\"\n",
      "batch 19422  loss=147.1048  steps/s=87.04  prediction: \"gger stuff, maybe thatll make me faster?\" => \"  \n",
      " to ie ig     g      tttt  t a a  a m\"\n",
      "batch 19423  loss=159.2324  steps/s=85.67  prediction: \"(uvw)\n",
      "each cube contains a subcube (xyz)\" => \"in cg s  a eu  b c cecc  c c   c b bcbbu\"\n",
      "batch 19424  loss=180.1300  steps/s=83.07  prediction: \"its pretty quick https://t.co/6ST0NV7fGK\" => \"n      ae tr te     t t  ttt  uctc c/ttc\"\n",
      "batch 19425  loss=148.7472  steps/s=87.15  prediction: \"earning by doing\n",
      "https://t.co/a3crVS8yHk\" => \" rt   .. .n n e      n nnntntnttttt////t\"\n",
      "batch 19426  loss=142.9415  steps/s=97.87  prediction: \"tic paper searches\n",
      "at this rate it willâ€¦\" => \" ne sr o pepr ee pease rs errae aarateaa\"\n",
      "batch 19427  loss=176.5666  steps/s=62.07  prediction: \"@ludwigABAP it just like you fr!!!!!.jpg\" => \"ludenpMp gesr se srass tst rrae rtr!!iâ€¦â€¦\"\n",
      "batch 19428  loss=149.3265  steps/s=106.92  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"   tt  it  t t        pppppppppptp    a \"\n",
      "batch 19429  loss=156.2566  steps/s=99.49  prediction: \"high quality patches they send to FFmpeg\" => \"enk tGnn n hth hhhhh   h h th t t  e te \"\n",
      "batch 19430  loss=155.8557  steps/s=97.42  prediction: \"fected, i hope none of my followers were\" => \" kh re amyoo  hog'DvppvDw,&I,1b!0Ikv.,I.\"\n",
      "batch 19432  loss=156.8720  steps/s=82.21  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ng rernedn e  c epee oon n  o  no lo  wr\"\n",
      "batch 19434  loss=146.4126  steps/s=100.48  prediction: \"n while still being consistent each week\" => \" tho esu      i   l     i i  iiins nn ne\"\n",
      "batch 19435  loss=152.7600  steps/s=96.70  prediction: \"caveman do xyz?\"\n",
      "https://t.co/TlhgHoICNd\" => \"on c do                    tt t/t///////\"\n",
      "batch 19436  loss=142.4807  steps/s=93.21  prediction: \"d luck to step on worms and they stopped\" => \" i  t oett    tt                     t  \"\n",
      "batch 19437  loss=173.0460  steps/s=97.44  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"eb e  aDyg    iP0,@j$$5@j\n",
      "yp5z4809z4809T\"\n",
      "batch 19438  loss=143.1385  steps/s=86.34  prediction: \" im pretty screwed when we play sap then\" => \"tt es  e  t   r  seeee r ewew ewe w   ee\"\n",
      "batch 19439  loss=147.2566  steps/s=99.88  prediction: \"al of life that pays some huge dividends\" => \"n nh  moenf  f f       f    a    e    i \"\n",
      "batch 19440  loss=156.0144  steps/s=101.10  prediction: \"tputs timestamps of ads =&gt; remove ads\" => \" sesesem )uomto tsttss s  mts t   &;;;s \"\n",
      "batch 19441  loss=157.7775  steps/s=100.01  prediction: \"d you man. Yea whenever you can do join!\" => \" to  ses      a       e eeeee eee       \"\n",
      "batch 19442  loss=159.1304  steps/s=98.51  prediction: \"tic strategy\n",
      "Positional chess type stuff\" => \" me i ir  oetttttttttottttisssstsststsss\"\n",
      "batch 19443  loss=151.3754  steps/s=94.20  prediction: \"you could just make move that looks good\" => \":u in n  y n  w         u         oo   o\"\n",
      "batch 19444  loss=150.1354  steps/s=103.91  prediction: \" cliff in one go. like, good luck w that\" => \"too   onttf f  f           o    o   oo  \"\n",
      "batch 19445  loss=168.1805  steps/s=75.25  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" B othegttf   i oo   o  o oo   o???  eee\"\n",
      "batch 19446  loss=157.2524  steps/s=96.49  prediction: \"ally understand the problem and the goal\" => \"n   oo  t eel  l  e      e  e   e   d   \"\n",
      "batch 19447  loss=144.9249  steps/s=70.14  prediction: \"sunsettler hes locked in to the outdoors\" => \" rso  ool t ler eee dred e  nn t  e o   \"\n",
      "batch 19448  loss=182.1042  steps/s=33.09  prediction: \"eply: @Nominus9 should be out soon   : D\" => \" ly: @selettnerteee dree e  nn t  e o t \"\n",
      "batch 19449  loss=151.1503  steps/s=100.51  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \"hettuet rnt r  tr r  r p oroo opooo o go\"\n",
      "batch 19450  loss=162.5027  steps/s=90.84  prediction: \"autoplayed after\n",
      "https://t.co/90dW9ll9Ay\" => \"nte  enyt tt tt   tt tattttatttt/////999\"\n",
      "batch 19451  loss=166.2111  steps/s=89.93  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" teeae bet@5oeeewMTB(55TBcIkCF\n",
      "KkFK::S1.\"\n",
      "batch 19452  loss=166.8425  steps/s=67.91  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"n n  ai fp       chhchss:/:::///.///ScSS\"\n",
      "batch 19453  loss=153.6086  steps/s=95.14  prediction: \"you could just make move that looks good\" => \":u nnnn  w    y         u         o    o\"\n",
      "batch 19454  loss=151.7097  steps/s=95.35  prediction: \"my laptop\n",
      "Forgot to remove the audio rip\" => \"e t e o2eNiheeHew**\n",
      "ÊŸ*ÊŸ$Éªj$**.Éªj/\n",
      "F*â€/]F\"\n",
      "batch 19455  loss=148.4092  steps/s=89.71  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn eoo   n  ee e eeeee e eee ttet////ttt\"\n",
      "batch 19456  loss=147.6295  steps/s=93.33  prediction: \"p, dont go on twitter/yt/etc immediately\" => \"l n iwa e nn  o    o  o tt  ttttttttttet\"\n",
      "batch 19457  loss=154.6626  steps/s=98.05  prediction: \" w as in why tf would you use white mode\" => \"the eannr   n  n  w   w            u   u\"\n",
      "batch 19458  loss=144.3048  steps/s=101.53  prediction: \" Post it in the disc it helps us all out\" => \"@rs  llosl     t                        \"\n",
      "batch 19459  loss=178.9903  steps/s=101.18  prediction: \"d to death\n",
      "\n",
      "Such is the life of a signal\" => \" sott rt dedodhettt  hh hhh  he         \"\n",
      "batch 19460  loss=192.3357  steps/s=25.55  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @gotdddoddhhth  hh hhh  he         \"\n",
      "batch 19461  loss=154.8567  steps/s=103.73  prediction: \" of how i debug and catch inefficiencies\" => \"tf e sorma   a t o  o    a   i i a i cic\"\n",
      "batch 19463  loss=171.2715  steps/s=89.78  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"emt  t ho       d|@j|[p@jï¸w$wz480ÊŸT480kT\"\n",
      "batch 19464  loss=172.9651  steps/s=98.92  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"t..tI eEG//Et// QQQQhZZZZWZ a  ( axxxxx2\"\n",
      "batch 19465  loss=159.9936  steps/s=104.77  prediction: \"owing that your food supply doesnt scale\" => \"u  i taat n t  ttt      o      o o  o   \"\n",
      "batch 19466  loss=148.3436  steps/s=101.25  prediction: \"have the opposite happen, do more stuff?\" => \"et s \n",
      "e t oo  t e   popoppe   ppeepe   o\"\n",
      "batch 19467  loss=148.1438  steps/s=101.06  prediction: \"and then pivot to doing a project in zig\" => \"td ami onhnin i n  t   n n  oo o oo     \"\n",
      "batch 19468  loss=177.9303  steps/s=55.38  prediction: \"@skooookum based https://t.co/I8UBeujUj6\" => \"lunaminonenin   t  o  t  p  o  o oi     \"\n",
      "batch 19469  loss=146.7699  steps/s=105.82  prediction: \"d of random strings, and removing a bitâ€¦\" => \" inii n  n n  an n n   nnn n    n     n \"\n",
      "batch 19470  loss=190.7150  steps/s=79.69  prediction: \"tygal777 ðŸŒ‘ and 12 others liked your post\" => \"h ee ra d  n77dðŸŒ‘ n n       r rr  i     i\"\n",
      "batch 19471  loss=179.4202  steps/s=39.07  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @   ie  77n  n n 1  r  rr r  i     o\"\n",
      "batch 19472  loss=156.4313  steps/s=115.95  prediction: \"blue, someone is working harder than you\" => \"ee   aes     esee e  o  o    e  er  r   \"\n",
      "batch 19473  loss=136.8245  steps/s=93.07  prediction: \"ive impact on me yrs after i had to stop\" => \"ne is  s  sti i                         \"\n",
      "batch 19474  loss=154.6107  steps/s=98.58  prediction: \"/t.co/pFqHtR4mHC https://t.co/2sTYtfPwu0\" => \"/.ceanttpp//tt//ppHHHttHtH/:t/tt:///tttt\"\n",
      "batch 19475  loss=164.8037  steps/s=94.28  prediction: \"at's definitely part of the current meta\" => \"n dal getdte   te t ttet  t    t tt   re\"\n",
      "batch 19476  loss=159.3583  steps/s=88.65  prediction: \"here you go mate\n",
      "https://t.co/oR4fVr3TMW\" => \"e   ne  nh                ttttot/tt/////\"\n",
      "batch 19477  loss=163.6968  steps/s=97.61  prediction: \"E gambits dude\n",
      "Punish mode is goated too\" => \"TtIO_ I  toneea =k=%PPud%cP%LOVE%kcF%k\"N\"\n",
      "batch 19478  loss=152.8698  steps/s=90.45  prediction: \"almost as bad as jan blocking his bishop\" => \"nliea \n",
      "fes l al as  aa a  bas   a  iib  \"\n",
      "batch 19479  loss=149.0270  steps/s=94.21  prediction: \"d to seeing your progress on nand2tetris\" => \" oo o  org     er  r ore rgrr or n n nnn\"\n",
      "batch 19480  loss=158.0498  steps/s=99.38  prediction: \"n just do things https://t.co/909bTHzmml\" => \"gto  oa st      n    t t s tt ttst/t9/9/\"\n",
      "batch 19481  loss=198.4477  steps/s=96.77  prediction: \"nly read a bit so far but its super good\" => \"gy  lttoctton a \n",
      "  a   o  o o t   t  t  \"\n",
      "batch 19482  loss=149.8652  steps/s=101.64  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"8Vo1ctis  t 0 h 0     h ht ttttttt/t////\"\n",
      "batch 19484  loss=169.9404  steps/s=45.30  prediction: \"y: @sebby_builds Japan sounds way better\" => \": @cant    0    h  hhhhthtttt//////t////\"\n",
      "batch 19485  loss=157.0668  steps/s=107.57  prediction: \"Logit transform: https://t.co/MtjBY3y5n5\" => \"ogeo we n   ttio o   ttt t:t::ttt:t/tttt\"\n",
      "batch 19486  loss=140.4694  steps/s=98.56  prediction: \"code base to get something super complex\" => \"onin ts  se t    ee  e    e    e     oe \"\n",
      "batch 19487  loss=164.1411  steps/s=98.84  prediction: \"d help you sleep\n",
      "https://t.co/gSjOxwH6Wj\" => \" tu   detls  ll  e leele psttspsptepopxx\"\n",
      "batch 19488  loss=158.9798  steps/s=104.20  prediction: \"18/hr\n",
      "\n",
      "cons\n",
      "- none\n",
      "- i only know scratch\" => \"6h rae -iga }ðŸŒ‘g ð—»$18/]|$18/ð—ª]Ê€m$18ÊŸ:-18/\"\n",
      "batch 19489  loss=154.3683  steps/s=102.08  prediction: \"e things getting done\n",
      "\n",
      "Keep it up brotha\" => \" soes e te e  g e   e ett eee eeee t e  \"\n",
      "batch 19490  loss=149.4473  steps/s=99.82  prediction: \"a good way to beat addictions in general\" => \"nfai w  n s t o o      a  ta aa   ii    \"\n",
      "batch 19491  loss=132.3666  steps/s=104.24  prediction: \"nd of mental ownership over the codebase\" => \"g i  ne t                        ee eeee\"\n",
      "batch 19492  loss=230.0975  steps/s=102.21  prediction: \"OOOOOOOOOOOOOOOO\n",
      "https://t.co/DRSJEEJtxo\" => \"OOOOOUd OOOOOOOOOOOOOOOOOOOOhtthohhttJJJ\"\n",
      "batch 19493  loss=163.3995  steps/s=101.61  prediction: \"ppen twice now\n",
      "\n",
      "maybe @yacineMTB can fix\" => \"lln @moro   pepe  ee    e ee eea eea eac\"\n",
      "batch 19494  loss=167.8826  steps/s=101.83  prediction: \"here for the funny symbols and recursion\" => \"ey o er trherhtre h  e  y    e    rnn rr\"\n",
      "batch 19496  loss=171.9554  steps/s=76.85  prediction: \"ohnUBalis whoa i love slop now\n",
      "\n",
      "followed\" => \"n  h ntnemh r w   h     o    s    rrneor\"\n",
      "batch 19497  loss=183.7124  steps/s=105.58  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"S ICd GesfOL OOOOOOOOOOOOO\n",
      "OO\n",
      "sO\n",
      "//tt/2t\"\n",
      "batch 19498  loss=151.7804  steps/s=91.77  prediction: \"go, the name.. none of that shit matters\" => \" o   i g   oe t  ee  o   e o        thtt\"\n",
      "batch 19499  loss=155.3745  steps/s=95.81  prediction: \" I got a creality one, works well so far\" => \"t eb  bd      n                     o   \"\n",
      "batch 19500  loss=166.4352  steps/s=91.04  prediction: \"the man just liked big words and spirals\" => \"he ee trdg  men  t    t  t    s   sss   \"\n",
      "batch 19501  loss=152.9774  steps/s=94.92  prediction: \"r time your focus muscle will strengthen\" => \"eoerg thvn  osa Ovj@wkymy:yffbhbkmb)ybOv\"\n",
      "batch 19502  loss=204.3243  steps/s=95.19  prediction: \"@___________11hz helped me out with mine\" => \"siltre    ____________11111 lle e e  tt \"\n",
      "batch 19503  loss=148.7655  steps/s=97.61  prediction: \"its bad but, it has pros you can play to\" => \"n  tonet na s est t     t   s      s a  \"\n",
      "batch 19505  loss=157.8830  steps/s=70.82  prediction: \"rdenis grats btw. site looks amazing too\" => \"e t   @ an   eh 1d__,1,11wO.Pcczkmllykzv\"\n",
      "batch 19506  loss=160.2565  steps/s=74.07  prediction: \"neMTB @justalexoki the rise of carmacine\" => \"g   rtu area   tatt t  et   o    iasa oa\"\n",
      "batch 19507  loss=154.7683  steps/s=78.26  prediction: \"doomslide its over needleinhaystack bros\" => \"  iyion nine  t s s te  ie  o   aaasaa c\"\n",
      "batch 19508  loss=183.5219  steps/s=107.97  prediction: \"ez5341 Will do brother. Much appreciated\" => \"  eeeodire l  i i o ee eeeerh haaa acaa \"\n",
      "batch 19509  loss=141.5914  steps/s=90.94  prediction: \"light show swarm and rent it to concerts\" => \"yk   a elhl   e     w           t    t  \"\n",
      "batch 19510  loss=156.6808  steps/s=40.33  prediction: \"y: @benfleming__ its lifechanging really\" => \": @lurbe r w  h     a        t  t  t ttt\"\n",
      "batch 19511  loss=144.4123  steps/s=102.45  prediction: \"anding pages or whatever feels gross idk\" => \"td a ae s n n  n       a ee  e eeeee  e \"\n",
      "batch 19512  loss=146.6634  steps/s=105.13  prediction: \"t, hence why lack of sleep kills my whys\" => \"h   is crae t n e     e e     ee     l l\"\n",
      "batch 19513  loss=154.8965  steps/s=104.73  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \"hon  i eio tiii   iii    i   ooh    h  o\"\n",
      "batch 19514  loss=155.9668  steps/s=98.45  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" dios ana wawaeaawllllll  lll   l  lllli\"\n",
      "batch 19515  loss=166.1825  steps/s=97.60  prediction: \"reaks). During these sessions my producâ€¦\" => \"eploc( (ile   e k7)MkD)AMDBR6T7@Tkv).fDI\"\n",
      "batch 19516  loss=151.7888  steps/s=99.32  prediction: \"m scratch in numpy like i did w backprop\" => \"ete en  ei  ie eTbly7,Xv,,#vbTIbbÉªbf.MOI\"\n",
      "batch 19517  loss=158.3681  steps/s=101.00  prediction: \"ty, as opposed to an engagement-heavy OF\" => \"h ' tis  om tsa  oo    oo o       nennee\"\n",
      "batch 19518  loss=173.6932  steps/s=96.07  prediction: \"77 oh whoa i didnt know abt tabs, thanks\" => \"7 a0cbeibc cc  o  7    oo    t taa   t n\"\n",
      "batch 19519  loss=151.1076  steps/s=104.06  prediction: \" software used that widely is so awesome\" => \"tom   nofa    f e  a e e    e    s  s se\"\n",
      "batch 19520  loss=156.0220  steps/s=38.95  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @ ono r    f e  t t  e d e    s  s se\"\n",
      "batch 19521  loss=149.7001  steps/s=103.37  prediction: \"AM much more energy and thoughts flowing\" => \"P P @ eae  n      ee    e   e e    h o g\"\n",
      "batch 19522  loss=152.5057  steps/s=39.55  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \"  @ wn  m     ne  eee       h hh h o   g\"\n",
      "batch 19523  loss=144.6289  steps/s=107.38  prediction: \"n up a simple ec2 and try it there maybe\" => \" th s t oo                              \"\n",
      "batch 19524  loss=157.2510  steps/s=99.26  prediction: \"rse21 doing is a fundamental of learning\" => \"eelf  @yt     tsHB1MRcT21k44219\n",
      ",Tw_jZv4\"\n",
      "batch 19525  loss=160.4484  steps/s=83.85  prediction: \"rdenis grats btw. site looks amazing too\" => \"ee2   @ien    r A21MFc.21kj.21'\n",
      ",Tw?jkz6\"\n",
      "batch 19526  loss=147.8651  steps/s=97.55  prediction: \". some, years later, have paid off a ton\" => \" io    he  oot t^vhðŸ˜*.vbå§#d,fwcc.*.*.k#ðŸ›‘\"\n",
      "batch 19527  loss=145.1855  steps/s=93.45  prediction: \"ntelligence\" + related learning concepts\" => \" e r no  s sni\" ei eelelleele e  nenen n\"\n",
      "batch 19528  loss=180.6557  steps/s=95.74  prediction: \"t btw, WASDQE for xyz and IJKLUO for uvw\" => \"haali pela t t t                        \"\n",
      "batch 19529  loss=147.9617  steps/s=90.93  prediction: \" billion zimbabwe dollars of labor hours\" => \"tuvi ab bal  biibbbbllllll l  lllo ll oo\"\n",
      "batch 19530  loss=154.1385  steps/s=96.16  prediction: \"snt, now i think and focus waaaay better\" => \" ie ttt, n   t            n     aaa aaa \"\n",
      "batch 19531  loss=162.8211  steps/s=92.61  prediction: \" it click for me\n",
      "https://t.co/AMSIT0bgJh\" => \"t  a  t  a l li i    i  t tt////t/tt///t\"\n",
      "batch 19532  loss=148.5894  steps/s=98.05  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn eo e    noe e eeeee e eee tttt/////tt\"\n",
      "batch 19533  loss=144.1866  steps/s=100.17  prediction: \"nd requires a phone app to connect to it\" => \"  9h  na ea reeee     e   p  p          \"\n",
      "batch 19534  loss=145.8157  steps/s=99.23  prediction: \"just point to concepts and arent reality\" => \"ust    t hs n ot   oo  o t  tnn n  nnn t\"\n",
      "batch 19535  loss=138.8192  steps/s=91.05  prediction: \"ot a lot of sleep last night, feels good\" => \"n   e toot  oo    o     l        t   ee \"\n",
      "batch 19536  loss=163.7478  steps/s=106.82  prediction: \"grammer unfortunately you are correct xD\" => \" aoe  ewr rlerrtr r trarrtn   uu  ere ee\"\n",
      "batch 19537  loss=166.2551  steps/s=97.48  prediction: \" just signed up as a beta tester hehhehe\" => \"tua  y l  g t  tuuus es u u   e a  e eet\"\n",
      "batch 19538  loss=128.9628  steps/s=103.55  prediction: \" into local files when you need to build\" => \"tn   d t nt                             \"\n",
      "batch 19539  loss=144.5467  steps/s=96.49  prediction: \"ink in part bc you have more to remember\" => \"ng i   in  t  i n                     o \"\n",
      "batch 19541  loss=189.0447  steps/s=18.19  prediction: \"eply: @bozo10n you can just build things\" => \" ly: @ inh  n i                  o  e re\"\n",
      "batch 19542  loss=154.7964  steps/s=116.26  prediction: \" personally wasted many years bc of this\" => \"trne.teni  r e  a ea  aaa  ayaayyyaay   \"\n",
      "batch 19543  loss=160.7732  steps/s=89.47  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"ton  nlaassem s mmessssssste  tt////////\"\n",
      "batch 19544  loss=163.7249  steps/s=89.66  prediction: \"ed in joining, repeat these instructions\" => \"  e  nttneteenieinnie enee    eneteettet\"\n",
      "batch 19545  loss=149.7117  steps/s=89.61  prediction: \"he case for some regions outside the US.\" => \"e   te fe    sis s se e e sososs oes eee\"\n",
      "batch 19546  loss=157.7691  steps/s=91.97  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  a   k   nce r  e  e e   e       r r r \"\n",
      "batch 19548  loss=162.2491  steps/s=90.03  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e   sn@ t      tcFFq(@@b)q(@ABBP{,'B{Py{\"\n",
      "batch 19550  loss=151.7433  steps/s=90.35  prediction: \"i can keep it up https://t.co/aDUupaUfqR\" => \"nwonsne ne n    e  ee  t  t s  p  p // p\"\n",
      "batch 19551  loss=143.5052  steps/s=94.99  prediction: \"your time for fruitful endeavors instead\" => \" u you   oon         ffffff fff    r  ee\"\n",
      "batch 19552  loss=159.6350  steps/s=98.14  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"sedI lotto 1 o t   o       o   e   eee e\"\n",
      "batch 19553  loss=172.9338  steps/s=100.24  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"ete  ncT_T ee_sT6IIkTjH767I7H7j!@H2U7.*A\"\n",
      "batch 19554  loss=169.9923  steps/s=77.03  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eeto n@ te eere 6c@kTjj7k0I7@70!@H107.UA\"\n",
      "batch 19556  loss=140.9333  steps/s=97.32  prediction: \"you into thinking hes an anime character\" => \" u  es rn ottonn i i iin n  n  nn nn  n \"\n",
      "batch 19557  loss=148.6949  steps/s=89.41  prediction: \"ions you choose, like oregon or whatever\" => \"nn re nnfoeotocons oe   eoo ooo o o oeeo\"\n",
      "batch 19558  loss=149.1542  steps/s=86.44  prediction: \"forming around AI or aroumd a fear of AI\" => \" r s   atc l sy IÊŸðŸ˜‰*#b`#,á´€,,kbAIÊœ*bkgâ€œ]b\"\n",
      "batch 19559  loss=192.9057  steps/s=39.56  prediction: \"y: @covix2772 @gizmobly s***** tool gang\" => \": @cer tntrrrnt n  r  r   r      a a    \"\n",
      "batch 19560  loss=158.1874  steps/s=115.66  prediction: \"y_builds i wouldrather shootmyself loool\" => \":c ce@iinnr nud d  o o rrrr *    ooo  go\"\n",
      "batch 19561  loss=172.1711  steps/s=19.86  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: @cini i uidd  ooo rrrro*    ooof go\"\n",
      "batch 19562  loss=160.2450  steps/s=90.89  prediction: \"ort (effort is proportional to time butâ€¦\" => \"ne tw t  e ttff fffr  orpoooooro oootto \"\n",
      "batch 19563  loss=161.1206  steps/s=96.93  prediction: \"C $ they raisedâ€¦ https://t.co/8AMjPz3k5K\" => \"owCwCor tisninoo:kuYN8k/VCw$(kVCM$PzbbKK\"\n",
      "batch 19564  loss=156.8563  steps/s=97.83  prediction: \"his data. boom, HD real world sim. GTA 7\" => \"es   s n t nda  oo at DDDD D   oodl ao l\"\n",
      "batch 19565  loss=180.9795  steps/s=92.37  prediction: \"ure thing brotha\n",
      "https://t.co/cvOCTnh7G1\" => \"   o isnit intebeotht ahatht /// s./:.7T\"\n",
      "batch 19566  loss=182.1321  steps/s=96.32  prediction: \"hich might mean making changes, so, yes?\" => \"es  ahnD D}toDDgnmigg g timimhtcigh,gha,\"\n",
      "batch 19567  loss=167.5231  steps/s=89.47  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t    i e  e  t e ahahe h tt eo/ /ot  otE\"\n",
      "batch 19568  loss=178.5172  steps/s=31.31  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"e: @G     e  t etahahe h tt c// /EtMEojj\"\n",
      "batch 19569  loss=183.8575  steps/s=121.30  prediction: \" @yotzol prelude in c major from scratch\" => \"tiac    to  ot  tlepep  t co/jjjcjorSoSðŸ›‘\"\n",
      "batch 19570  loss=177.9543  steps/s=69.51  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"eply   o @yewyotzfbhprpsjj/r.5dW5s5O.7d1\"\n",
      "batch 19571  loss=178.7554  steps/s=80.22  prediction: \"Veraciety We're goin alright, we're goin\" => \"arvyia   erecy ty'WhWgp5g5gd.LoM5M5g,M,1\"\n",
      "batch 19572  loss=159.0766  steps/s=40.05  prediction: \"ly: @larpertony @kuberdenis my elo is 10\" => \"y: @zer ert n en heWii  i  pa a oiea s o\"\n",
      "batch 19573  loss=174.7628  steps/s=92.71  prediction: \".. would love to be proven wrong on this\" => \" .oeh   teo e olfsdfvkvbs...bnayvddyb.sp\"\n",
      "batch 19576  loss=170.6544  steps/s=98.77  prediction: \"ntiers out there we dont even know about\" => \"  te  gatoe s  sfmfhvyfspmuivnhhrfywiksðŸ›‘\"\n",
      "batch 19577  loss=172.6414  steps/s=94.71  prediction: \"r time your focus muscle will strengthen\" => \"eoe   thgn  orhfmvdyvmvucrmfmcmclmfscwcv\"\n",
      "batch 19578  loss=169.9370  steps/s=87.96  prediction: \", because integrity is incredibly useful\" => \" th   f ra  e o f oro i  i reca ie ibii \"\n",
      "batch 19579  loss=172.7587  steps/s=98.79  prediction: \"tuff goes for you\n",
      "gpu stuff is super fun\" => \"has e stite go seuw!hwwukgdka!fkf\n",
      "gmynmc\"\n",
      "batch 19580  loss=165.3302  steps/s=100.28  prediction: \"ot of politics is reinforcement learning\" => \"n  o oo o  to t oos i s  if ir  s erere \"\n",
      "batch 19581  loss=175.6321  steps/s=96.32  prediction: \"what overlaps stand out to you the most?\" => \"aad @te e ed a  .vwhl.wuv.disv.ucvgivuvl\"\n",
      "batch 19582  loss=170.4899  steps/s=94.29  prediction: \"y laptop and hope the bits line up right\" => \":ianaa  tt em  ot t o    a ppp e  epe th\"\n",
      "batch 19583  loss=196.1408  steps/s=83.34  prediction: \"rs: John 14:6-14 https://t.co/37ryh1InfG\" => \"e to  e n    n414-6-uJJhk/kb:661143737h:\"\n",
      "batch 19585  loss=189.1415  steps/s=94.53  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"serpn_A  nk tthy ay y I salt s sels eiCr\"\n",
      "batch 19586  loss=184.5477  steps/s=96.77  prediction: \"yup totally agree. Very powerful mindset\" => \":pi et d y tlt t aley a eyVe Ve.r e eeer\"\n",
      "batch 19587  loss=170.9416  steps/s=28.99  prediction: \"ply: @sunsettler im down another weekend\" => \"ly: @ ecd HAtel HApAaVkhuVyV/v.VV.yV.fVm\"\n",
      "batch 19588  loss=173.0059  steps/s=102.93  prediction: \" dingboard. Several others ive seen irl.\" => \"tome   ni in  id.iaSSad S  e a r o veers\"\n",
      "batch 19589  loss=169.3281  steps/s=99.89  prediction: \"more efficient parameters in the network\" => \"evei)  egec int  ghdphpfgsdhaolpfscvinny\"\n",
      "batch 19591  loss=174.6663  steps/s=85.52  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"ts tiee ne e te tetiec it rs//pet/etZ2Z2\"\n",
      "batch 19592  loss=171.7784  steps/s=101.39  prediction: \"did it again w feedback itd be the paper\" => \" ft  edd d  did  d did a d d dtia t b e \"\n",
      "batch 19593  loss=172.2241  steps/s=87.34  prediction: \"esting example of goodharting the reward\" => \"    tetten ee tste exe et e ae  o eg ete\"\n",
      "batch 19594  loss=182.7612  steps/s=72.26  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1ittnerne  r t ietgit D::DDat t/ p/e3d3\"\n",
      "batch 19595  loss=167.8777  steps/s=87.36  prediction: \"experience but i work w someone who does\" => \" p\n",
      "  t    t n p e x eet e  e w  w o  o n\"\n",
      "batch 19596  loss=181.7063  steps/s=37.91  prediction: \"ly: @ludwigABAP Its a good hivemind, sir\" => \"y: @ en   ete   e t eet e  e w  w n ro n\"\n",
      "batch 19598  loss=179.1166  steps/s=97.65  prediction: \"while his chess opponents mind went 3fps\" => \" ed  oen h ote l3bbapdawmopnmd3ofw0mwn33\"\n",
      "batch 19599  loss=174.7322  steps/s=93.28  prediction: \" to see sry lol) https://t.co/Ix77zjdmxB\" => \"thee nrs e tar  olrro )ot  ht )stol777 t\"\n",
      "batch 19600  loss=173.1670  steps/s=90.44  prediction: \"kind of just whatever I want to pivot to\" => \" np rr tin   di j jtej tt t seew  t we t\"\n",
      "batch 19601  loss=183.9582  steps/s=86.85  prediction: \" through nevada w my dad as a little kid\" => \"theeir ei i irmndvr v vd a d a ad  aa   \"\n",
      "batch 19602  loss=173.9676  steps/s=85.25  prediction: \" ive had programming in a long long time\" => \"ts om f n  e  ne h  im  m  gnanmaig ng  \"\n",
      "batch 19603  loss=186.0844  steps/s=90.32  prediction: \"rammer you love lean? prove it (in lean)\" => \"enla  @h  HyHvgle@dgrf?u?vpy?nfl?v??grs(\"\n",
      "batch 19604  loss=184.4314  steps/s=87.84  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"h totth //  h t TPPSLPSSSW)S:)p).c/H.HHH\"\n",
      "batch 19605  loss=180.4277  steps/s=92.16  prediction: \"t really is a long term + hard work game\" => \"hfo/t rhcneP i) W)z)))en:)::/ap+H//6BV+B\"\n",
      "batch 19606  loss=174.3512  steps/s=94.42  prediction: \"r than age sounds like a skill issue tbh\" => \"etnio @nu TzLzt zzmetheuyup:lgkP:duwdckðŸ›‘\"\n",
      "batch 19607  loss=187.6755  steps/s=92.26  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"etne ioHS S&bz;tp-&k-;-&;&;-;g-;-djnwiwðŸ›‘\"\n",
      "batch 19608  loss=175.4898  steps/s=86.01  prediction: \"chat is this what sweat equity means????\" => \"oar   aneee  ed wdre\n",
      "u-wgaq&lquagqjqqinðŸ›‘\"\n",
      "batch 19609  loss=175.1186  steps/s=96.40  prediction: \" two next to each other. then a 4x4. etc\" => \"the ai e t  t t tenet e  eht t o  tt4 4.\"\n",
      "batch 19610  loss=184.1268  steps/s=80.62  prediction: \"ach_ @pixqc that's smart. will try this.\" => \"ni c  en q to thteh t e ' 't t t  . .  t\"\n",
      "batch 19611  loss=175.8001  steps/s=100.11  prediction: \" sessions with you and everyone else man\" => \"the tnnrete sen s  et eoohnoi deiyyoe y \"\n",
      "batch 19612  loss=193.8296  steps/s=96.17  prediction: \"e huge win, and yeah consistency is king\" => \" sod!!!!! ! !ugt gu e g g, y de h ynns n\"\n",
      "batch 19613  loss=186.7290  steps/s=92.81  prediction: \"kage\n",
      "\n",
      "no but for real thats a smart move\" => \" lp7 papmen p bemoappcgrornatnenr \n",
      "gnts \"\n",
      "batch 19614  loss=177.1915  steps/s=100.39  prediction: \"pen theatre stairs door and ruin the run\" => \"lrg @  y y toeunorbrngenutatruyltourdfnp\"\n",
      "batch 19615  loss=176.8569  steps/s=90.59  prediction: \"best way ive found so far to order tasks\" => \"e  tket st   tst t   o e      f     eo o\"\n",
      "batch 19616  loss=171.4655  steps/s=88.49  prediction: \"ody wake up??\n",
      "Youve killed us all skooks\" => \"neno nen ne n et o ? YYe?ku u kekd uku l\"\n",
      "batch 19617  loss=173.4487  steps/s=87.66  prediction: \"ike the programming skillset example is.\" => \"ne to  uheth  heogn hm oh  milg e  itmml\"\n",
      "batch 19618  loss=172.5122  steps/s=95.55  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \" r en  oeBðŸ›‘Pâ™‚Êœcfy\"w\"f\"\"\n",
      "bbw\"wibwv\n",
      "vbupdo\"\n",
      "batch 19619  loss=175.4912  steps/s=89.32  prediction: \"n i did eventually. hypothesis confirmed\" => \" mt tn nnee drdi\n",
      "puv.fvln..y.pp.lvv.fukf\"\n",
      "batch 19620  loss=176.9349  steps/s=92.41  prediction: \"very instructive zig raylib example/code\" => \"e u inti  nirsh ts   r r r tii  rae e e \"\n",
      "batch 19621  loss=159.7675  steps/s=86.75  prediction: \"iked the architecture diagram\n",
      "\n",
      "followed!\" => \"ne a     lea ehee  ttet era ier rter aar\"\n",
      "batch 19622  loss=172.8952  steps/s=90.97  prediction: \" life you have to put in work to do this\" => \"ton  t nrt\n",
      "leel o iiuelale ae  uu  ut  i\"\n",
      "batch 19623  loss=170.7262  steps/s=93.44  prediction: \"ticated strings as defined by kolmogorov\" => \"hngo  eneobsblcnbyvbdgubypbRywrypg\n",
      "fwpyd\"\n",
      "batch 19624  loss=179.7830  steps/s=93.72  prediction: \"etting about them, is a v common mistake\" => \" at o tg nsoggetino  oti,e, iee it t mmo\"\n",
      "batch 19625  loss=193.8279  steps/s=88.83  prediction: \" at 5:10 or something I just go til 9:10\" => \"tnd t sttr  t11 11  11s 0g0  o jt j j   \"\n",
      "batch 19626  loss=185.3954  steps/s=18.14  prediction: \"eply: @MafiaJoeg https://t.co/kGkkdevlHa\" => \" ly: @attitst1n 11   :s 0g   o jt jjj   \"\n",
      "batch 19627  loss=182.0627  steps/s=92.42  prediction: \"l. but really, I have absolutely no clue\" => \"y  sg g grnpnpw.nau   rl e ae a ab babta\"\n",
      "batch 19628  loss=174.6346  steps/s=91.18  prediction: \" not abt to read through all of its code\" => \"tes ts  n  b tn    t   att tb oh  ra  s \"\n",
      "batch 19629  loss=167.2132  steps/s=97.20  prediction: \" takes a lot of work and years of it tho\" => \"tha a tnt  T  a t  t  o t arr ad   d  o \"\n",
      "batch 19630  loss=175.1055  steps/s=99.72  prediction: \"the model well except for precisely howâ€¦\" => \"hen t e  teernunwhnrmfxsrxhspmrfxrxxwxhx\"\n",
      "batch 19631  loss=190.4766  steps/s=53.21  prediction: \": @ns123abc meet only one of her parents\" => \" @ya  r  o23rnl whxrxfxmIxhspdrfxrepwxâ€¦x\"\n",
      "batch 19632  loss=175.6023  steps/s=109.20  prediction: \"al hypotheses to search through and test\" => \"nl ao er   lo ep tepoto oe esh sht hoeoh\"\n",
      "batch 19633  loss=184.3833  steps/s=105.42  prediction: \"xamples b4 posting)\n",
      "- did research/workâ€¦\" => \"pm Pi  teene ihp e4s 4  ess ) dd edse  e\"\n",
      "batch 19634  loss=191.0243  steps/s=98.98  prediction: \"up man youre gonna go far over the years\" => \"ne!!  t pm uummnmeruieeee  gn a   eerree\"\n",
      "batch 19635  loss=174.9382  steps/s=98.83  prediction: \"hange your brain. something to think abt\" => \"etg  r  w wr eg n yr r r  or  no  i e to\"\n",
      "batch 19636  loss=187.2589  steps/s=92.85  prediction: \"n\n",
      "\n",
      "luckily the hard part is already done\" => \"g\n",
      "ii sic  n aam /b/ycks//dtym\n",
      "cuck\n",
      "lluti\"\n",
      "batch 19637  loss=164.9042  steps/s=90.58  prediction: \"n while still being consistent each week\" => \" iho eot ety_junkwjwv\n",
      "ujdbtpmbmbrgDgjDvðŸ›‘\"\n",
      "batch 19638  loss=183.3312  steps/s=87.79  prediction: \"MTB Yup, totally, would be best actually\" => \"TB aCayynh TT y  yl ,l, llllllo bebbe  b\"\n",
      "batch 19639  loss=176.7895  steps/s=86.64  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"tu a a  mt,ai mn d dso o     io d h t  '\"\n",
      "batch 19640  loss=186.0948  steps/s=82.39  prediction: \"ontend ai stuff is pretty cool. followed\" => \"n  n  ttftoni ad din t i  i fs st  i os \"\n",
      "batch 19641  loss=178.2843  steps/s=91.27  prediction: \"2 and 3 forever\n",
      "\n",
      "https://t.co/4TGEKmEHO0\" => \" @ir teaere reo4  fn3r3  f \n",
      "e e  o/tTGEG\"\n",
      "batch 19642  loss=181.6304  steps/s=99.82  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nhoy re  i t rCee  et\n",
      "e e y ue b t   ao \"\n",
      "batch 19643  loss=187.3636  steps/s=80.96  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \" tno t  n n bex dx.x.xoxxy/y.y:d.Z:pZZpZ\"\n",
      "batch 19645  loss=181.9272  steps/s=89.58  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t iasaeo oe rraseta es s t s   a tee\"\n",
      "batch 19646  loss=169.2221  steps/s=90.39  prediction: \"tion WAY more than if its someone else's\" => \" mn   so etiYbyoAYppjlgWAYWAYAYYymWAYaml\"\n",
      "batch 19647  loss=176.2039  steps/s=98.60  prediction: \"ace to both physical and mental reality.\" => \"nh tot oc ott   tp oa pas atoaa  t snato\"\n",
      "batch 19648  loss=174.5835  steps/s=101.66  prediction: \"how u get llms to make huge projects btw\" => \"ewe   o  i  alte s lsoim t i hle   oo to\"\n",
      "batch 19649  loss=197.3975  steps/s=92.25  prediction: \"load this prompt https://t.co/Ug4apoNeat\" => \"et ao ok o a    t tt t ptht p/sp/tttt//t\"\n",
      "batch 19650  loss=172.2869  steps/s=99.90  prediction: \"wn for a game sometime? also lichess ftw\" => \"    @tuyo dglyigh@wncfprwlbg?cv/:u?b/?me\"\n",
      "batch 19651  loss=194.8134  steps/s=99.96  prediction: \"f cuda+zig combo https://t.co/i4ntqAK26E\" => \" eo pnex  ++x\n",
      "\n",
      "n+z+z\n",
      "+mbba::/h..://4.:qq\"\n",
      "batch 19652  loss=184.9953  steps/s=104.90  prediction: \"cay principles, and it ended up formingâ€¦\" => \"olegiol dl ncksnwcybpgrf,winah,dapdcs,ip\"\n",
      "batch 19654  loss=178.5414  steps/s=100.38  prediction: \"igh, make schizo\n",
      "// TODO remove appendix\" => \"nh  h nh ih hi    ihi  oh/  OO/O OOo  oo\"\n",
      "batch 19655  loss=188.2939  steps/s=89.17  prediction: \"of learning is learning from the past ig\" => \"  r  da e alaifal enr le frinegnr ng  fo\"\n",
      "batch 19656  loss=184.5058  steps/s=87.52  prediction: \"ers @iliekcomputers is a p strong player\" => \"  tiit n eie sd i  ess i lierp er pls rp\"\n",
      "batch 19657  loss=182.1096  steps/s=90.47  prediction: \"rf spatial in problem solving efficiency\" => \"eioi tesnemfthf ghw\n",
      "dpwtbdwbrhbsvdhrrbvh\"\n",
      "batch 19658  loss=187.7229  steps/s=99.39  prediction: \" possible the true x for elon is 42,069x\" => \"@rm  sse t o se  tssmr ee x ert  so  i  \"\n",
      "batch 19659  loss=175.9988  steps/s=104.47  prediction: \" know. But this will help you immensely.\" => \"ano   ddno t otdtt nt ws wowi t twi iooo\"\n",
      "batch 19660  loss=195.8731  steps/s=21.72  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @dooo t otwit nt ws wowi t owi io.o\"\n",
      "batch 19661  loss=177.5475  steps/s=104.50  prediction: \"problems im overlooking, then solve them\" => \"lob  t od   gbnopcabvlmbfbmgpk,kk,am,nvh\"\n",
      "batch 19662  loss=177.0326  steps/s=96.52  prediction: \"tiary structures. spirals within spirals\" => \"hng  t/ er  ywn huy/iway.,./fuc.u.,..ur.\"\n",
      "batch 19663  loss=184.6343  steps/s=69.63  prediction: \"ew4rd Oh whoa\n",
      "Thanks for the RT btw man!\" => \" _ipmaret e rhheurtse sara sstrititRiwRi\"\n",
      "batch 19664  loss=181.9279  steps/s=90.42  prediction: \"@arthur_d3nt cool shit\n",
      "cuda interop too?\" => \"sndmerh h o ratthr3h3 h ho  s hi hi e it\"\n",
      "batch 19665  loss=182.2980  steps/s=87.02  prediction: \"file llm editing stuff is the future imo\" => \"onl   her .larfi.wrwhdo\n",
      ".ufaulnwedm\n",
      "mula\"\n",
      "batch 19666  loss=172.5818  steps/s=18.24  prediction: \"eply: @djcows you need attention, is all\" => \" ly: @\n",
      "olimell l llltidiiiluftli iu tsf \"\n",
      "batch 19667  loss=170.8559  steps/s=97.17  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \" iooo eedintfly dgmahiegwruuyfincifOo\n",
      "OO\"\n",
      "batch 19668  loss=181.8671  steps/s=87.11  prediction: \" @yotzol prelude in c major from scratch\" => \"tsu  in ct ozo niloiooi i  oaj jr jr oru\"\n",
      "batch 19669  loss=170.6071  steps/s=93.18  prediction: \"assume that had a large effect back then\" => \"nk o      ine a  t e a at a  e e a ae c \"\n",
      "batch 19670  loss=182.4581  steps/s=89.73  prediction: \"n doing on a method of learning faster)â€¦\" => \" w de i r d ivgivrnvnwnvdvbdbifgmdlbbevo\"\n",
      "batch 19671  loss=176.5862  steps/s=92.77  prediction: \"e waves stopped\n",
      "\n",
      "https://t.co/FO1wQxoZRU\" => \" (shee d ht et esedpehpptets/t/sp://tFFQ\"\n",
      "batch 19672  loss=179.3570  steps/s=96.44  prediction: \"s message is NOT approved by square gang\" => \" ooieo   st seh\n",
      "sie NO ptNOOosTpwo qoqee\"\n",
      "batch 19673  loss=179.8288  steps/s=90.56  prediction: \"e building an army of tiny little robots\" => \" soo    l    in  a  a n  i       l    n \"\n",
      "batch 19674  loss=171.2712  steps/s=91.38  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" sin liontne '  e'''ttntnsethtts//KKKtKc\"\n",
      "batch 19675  loss=191.1270  steps/s=73.67  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ngieelieinee== 'ne\n",
      "cht tnn/t/tts////c==c\"\n",
      "batch 19676  loss=179.5018  steps/s=91.01  prediction: \"code is here btw https://t.co/pvaVTH05yr\" => \"omce h ne \n",
      " a\n",
      "h fhy)sucedhtw::/p.::/::vV\"\n",
      "batch 19677  loss=179.1470  steps/s=91.84  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \" ti gieae   Igntqq eq  qqqrenr  cuiAAtiA\"\n",
      "batch 19678  loss=183.9912  steps/s=95.30  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"toaetigeeal afgerigenei anrrnl gcn:/:t99\"\n",
      "batch 19679  loss=181.8172  steps/s=90.15  prediction: \"r easy setup btw\n",
      "https://t.co/dWiO4erSb1\" => \"eate  @ptex lmy u\n",
      "muywxiww:/r:p\n",
      ":/wW.OW/\"\n",
      "batch 19680  loss=178.2290  steps/s=89.51  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"om ecoe ec  xbii(bxpbx..uohaxx::/iCpoCBq\"\n",
      "batch 19681  loss=183.3582  steps/s=71.49  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"are  me lyblyp....ak?:/?:/ht/f:/CYqXqqXq\"\n",
      "batch 19682  loss=185.1891  steps/s=95.41  prediction: \"nd beyond is such a gargantuan advantage\" => \"g to e g i  bvvovkips:pbkhut/sv/cwwpwrgu\"\n",
      "batch 19683  loss=175.3824  steps/s=96.19  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" ao t   t ctt  h tBt t  t tnn  t  t  ot \"\n",
      "batch 19684  loss=181.8062  steps/s=97.99  prediction: \"right words can change entire industries\" => \"eccn Gev  _ pwy whBgwiwhiwwagwo cavcordw\"\n",
      "batch 19686  loss=170.8889  steps/s=84.61  prediction: \"imated stills have finally been defeated\" => \"np in ya ra tahlethlce  gla hn in intdle\"\n",
      "batch 19687  loss=166.9865  steps/s=87.80  prediction: \", thanks\n",
      "Been trying to get it to happen\" => \" ih c   t cttk   t t t  nntn   t  t tet \"\n",
      "batch 19688  loss=221.6845  steps/s=89.94  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"Sp5tWeHO Ht NGALEVVHETSEATSATSO SSHT:Qc:\"\n",
      "batch 19690  loss=182.3669  steps/s=85.26  prediction: \" figuring it out. it just clicked for me\" => \"@or o t fft  ff ing iite itjuitt ut  utt\"\n",
      "batch 19691  loss=179.2501  steps/s=93.14  prediction: \"rong tho, my confidence is only like 70%\" => \"egithienesO%x.Odwh.d.x.lw,bOy,bwr,u.da,%\"\n",
      "batch 19692  loss=168.7241  steps/s=98.52  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"nd a ms rg     mn a  r r m  a n  a a    \"\n",
      "batch 19693  loss=179.3976  steps/s=91.02  prediction: \"freedom fighters. ppl who wanted freedom\" => \" on tn ier2)1f  )mgwg.dg.)2.pfl2ww.ri.sg\"\n",
      "batch 19694  loss=184.5682  steps/s=93.48  prediction: \"d @gizmobly @covix2772 store files in it\" => \" doreeet eigigge o eo 2777772272  r feee\"\n",
      "batch 19696  loss=177.0997  steps/s=84.88  prediction: \"ce for an american traveling there soon?\" => \"os  ital cbeefd ?pgrgvydpdfupf2fpabywb?v\"\n",
      "batch 19697  loss=182.1330  steps/s=90.02  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \" y _  nr y dnnhndaoa aS d d Snn d d  te \"\n",
      "batch 19698  loss=196.4609  steps/s=25.52  prediction: \"ply: @camhowe1729 No problem, good tweet\" => \"ly:  a   etedhyGu9SravmSpdSSkS\n",
      "S\n",
      "luShk\n",
      "k\"\n",
      "batch 19700  loss=175.1495  steps/s=95.63  prediction: \"deviating\n",
      "and it lets you do that faster\" => \"    e v egdevineind an  ani t  teoot aa \"\n",
      "batch 19701  loss=167.5391  steps/s=85.84  prediction: \" @discord I made my own bot from scratch\" => \"tard ide idddio  dd  eod     o t oo o r \"\n",
      "batch 19702  loss=174.3738  steps/s=91.51  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n d      h i  gt id d d AAAAid dtt   d d\"\n",
      "batch 19705  loss=168.5561  steps/s=99.09  prediction: \"nd requires a phone app to connect to it\" => \"g th a m   r,q9ilqyuqtbk4s,bfkhk,MqukAM,\"\n",
      "batch 19706  loss=182.2443  steps/s=96.81  prediction: \"rse21 doing is a fundamental of learning\" => \"e aid itt @9,@Ig211t21f21b2121hk,g,umAD,\"\n",
      "batch 19708  loss=181.1804  steps/s=68.14  prediction: \"atedro @gizmobly https://t.co/IFzJo2qtyj\" => \"n  deod ere i  o oos a   n anonn ta aF F\"\n",
      "batch 19709  loss=177.0855  steps/s=93.07  prediction: \"e\n",
      "\n",
      "swapped to mint and never looked back\" => \" \n",
      "tr s ep pappesd \n",
      "psppdat  n tetaed nde\"\n",
      "batch 19710  loss=179.7221  steps/s=60.11  prediction: \"bly same, llms are so much faster though\" => \"ee urses saa a\n",
      "me ss anese  n te aeoaeke\"\n",
      "batch 19711  loss=173.8498  steps/s=94.81  prediction: \"dont just mean wrt doing logic with them\" => \"    e rd i dja\"a ajdj j n ao at t t w tt\"\n",
      "batch 19712  loss=178.1893  steps/s=73.89  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"ebto atate mmmod d  i e nm og e t t h tm\"\n",
      "batch 19713  loss=172.6047  steps/s=102.61  prediction: \"ler its always an :x day here on twitter\" => \"ym mse ut  li cw ww wse sesx::  dnn not \"\n",
      "batch 19714  loss=166.5004  steps/s=102.76  prediction: \"e, i would also have liked to be yacine\"\" => \"    a  nee   icnal  aol  aa l ll      ee\"\n",
      "batch 19715  loss=179.1869  steps/s=102.82  prediction: \"ur advantage\n",
      "Ex: https://t.co/UObmaG3B5l\" => \"te i  t en t to\n",
      "t  t a tt: : at a:/U aU/\"\n",
      "batch 19716  loss=179.6134  steps/s=100.94  prediction: \"e, and i know i need to get back into it\" => \"  rsiein a r erd aned e ddoi inee  k  et\"\n",
      "batch 19717  loss=173.4592  steps/s=89.72  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \" trst set t  e eittitetestttttt/te/tt/s/\"\n",
      "batch 19718  loss=221.0187  steps/s=13.86  prediction: \"reply: @Brycicle77 polnareff could never\" => \"eply: @h e,okIdnImkc\n",
      "ruw/\n",
      ":g\n",
      "p.bl0:.0M37\"\n",
      "batch 19719  loss=183.1372  steps/s=124.72  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lst @   s  su\"dtA\n",
      "\"\"AIAI/\n",
      "fAIouba\"yI\"Akv\"\n",
      "batch 19720  loss=178.4564  steps/s=100.93  prediction: \" something rudimentary could be possible\" => \"tpmine st net n r mnn mhthr hinemintment\"\n",
      "batch 19721  loss=176.9360  steps/s=104.51  prediction: \"ing responses seems like a better metric\" => \"nt \n",
      "ose nt  os iiooeess es e  ie  s e ee\"\n",
      "batch 19722  loss=172.3160  steps/s=102.82  prediction: \" been some adventure man. God bless him.\" => \"te   tese s  sve veveeven eem e eGe  eee\"\n",
      "batch 19723  loss=173.1466  steps/s=103.49  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"eatf nt o \n",
      "oc@\n",
      "nhfcpu\n",
      "yrcadfcrbc.ncflfdl\"\n",
      "batch 19724  loss=174.0034  steps/s=51.39  prediction: \": @granawkins me\n",
      "https://t.co/Ml5XtT4kj8\" => \" @goontn  foh@hnhfcpu\n",
      "yr:adf/rbcMnMX5X4T\"\n",
      "batch 19725  loss=178.5032  steps/s=108.13  prediction: \"e broth its much better\n",
      "How you been man\" => \" aeo   i o oth o o bt ooh  bb heoHobet u\"\n",
      "batch 19726  loss=175.2480  steps/s=104.66  prediction: \"pl to influence what they think (cringe)\" => \"ly:   pneesogpdlbgcpcuwwopcufofpawgck(((\"\n",
      "batch 19727  loss=197.6370  steps/s=95.19  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"B d d \n",
      " t o dOsOOOOOOOO\n",
      "\n",
      "\n",
      " s ts:O//NNNNN\"\n",
      "batch 19728  loss=182.3930  steps/s=96.66  prediction: \" the gap\n",
      "\n",
      "down the energy gradient we go\" => \"to  ten  g   ou o t ge thg\n",
      "   g   dteg e\"\n",
      "batch 19729  loss=177.4379  steps/s=102.22  prediction: \"inlet like me to test experiments out on\" => \"ng ro et lr  eo r eo er e te ie e  t ot \"\n",
      "batch 19731  loss=172.6166  steps/s=99.12  prediction: \"e firework chair https://t.co/J6w6odDBx3\" => \" fun neroene on nr cohihrihei ci/i6rJ6J6\"\n",
      "batch 19732  loss=178.4890  steps/s=86.92  prediction: \"ler i wish it tasted as good as it looks\" => \"yag@ wereeweriewa h ch /tet/i  w asodo d\"\n",
      "batch 19734  loss=187.9564  steps/s=32.76  prediction: \"ply: @snowclipsed Youll see, almost done\" => \"ly: @ oenoewflknkfckrkhe:pf:.cp.cs/p.:.o\"\n",
      "batch 19735  loss=172.0822  steps/s=103.77  prediction: \"ng i correctly understood what you meant\" => \"  b  it   \n",
      " owbmf')y')ly'rhntlygmbygwhal\"\n",
      "batch 19736  loss=180.9005  steps/s=98.08  prediction: \"ection to go in\n",
      "\n",
      "https://t.co/V6EzIZNqae\" => \" tnrlitent  t do to tnt o  o tto \n",
      "/o/tt/\"\n",
      "batch 19737  loss=170.8067  steps/s=95.80  prediction: \" just be a webpage visit, its in browser\" => \"tu  ll llnt lj  t  t e  a  et,a t isi  t\"\n",
      "batch 19738  loss=171.6349  steps/s=89.75  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"tasr rn  nneorn  re  obb ae  eui ub uin \"\n",
      "batch 19740  loss=182.9814  steps/s=103.09  prediction: \" fit-to-content) https://t.co/kIAe5BVk05\" => \"tiaee te..-.--h--te tnttt )) ett////co5t\"\n",
      "batch 19741  loss=174.4601  steps/s=92.63  prediction: \" like i can do so much more in python :(\" => \"tike l l    l i  ii  i i   m o   o  ho e\"\n",
      "batch 19742  loss=187.6062  steps/s=38.31  prediction: \"ly: @ludwigABAP Deserved\n",
      "See you at 100k\" => \"y: @      e      ii  i e   m o   oo ho e\"\n",
      "batch 19743  loss=187.7338  steps/s=66.60  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @aatoissaAg DmDbrvuvfkbSfklzklWa1k1z\"\n",
      "batch 19744  loss=169.6984  steps/s=115.16  prediction: \"thing you do very often, like constantly\" => \"hi  aaotra  mgv bnsvr:u:\n",
      "fgv/,/P,wivg,yg\"\n",
      "batch 19745  loss=166.9460  steps/s=104.47  prediction: \"tion WAY more than if its someone else's\" => \" mn e so etiYbyoAYppjlgWAYWAYAAYymWAYaml\"\n",
      "batch 19746  loss=182.6389  steps/s=79.97  prediction: \" flick of the wrist instead of traveling\" => \"tonm i1  f o  o oi  i t o htiwist stoto \"\n",
      "batch 19747  loss=170.7755  steps/s=83.63  prediction: \"d hire my friends to do research with me\" => \" to   to mo eare nr   dr r  sr s n  re e\"\n",
      "batch 19748  loss=177.7185  steps/s=93.69  prediction: \"a bajillion ppl\n",
      "\n",
      "my literally shit posts\" => \"nlo to  mn i s  oipi a liliy yllllyipilt\"\n",
      "batch 19749  loss=177.6342  steps/s=87.46  prediction: \"ellessen Last time was ~6:20am cali time\" => \" y     sllnlseinLL   ai e ll ~a~2 2 2i t\"\n",
      "batch 19750  loss=175.2956  steps/s=104.28  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" seer pen e ereteto\n",
      "e\n",
      "\n",
      "m rmn m me mext x\"\n",
      "batch 19751  loss=171.0372  steps/s=96.25  prediction: \"uch  there would be to take into account\" => \"scian   e n ec   e ho   toe   e u   e co\"\n",
      "batch 19752  loss=159.2471  steps/s=66.94  prediction: \"sunsettler hes locked in to the outdoors\" => \" pcnnh    w eoh we eo e tow taeta t e to\"\n",
      "batch 19753  loss=181.8165  steps/s=102.77  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "uthir) st)S))LSgSSGGIsIIm!eT:ITs:7::7UV\"\n",
      "batch 19754  loss=218.1656  steps/s=95.91  prediction: \"FREEEEEDOOOOOOOM\n",
      "thats why we do it lads\" => \"oc yaLET te FRFRDIMDEDs:M.:MOMAV7UBAV7AV\"\n",
      "batch 19755  loss=178.8017  steps/s=104.27  prediction: \"he pot of gold at the end of the rainbow\" => \"e r t toeoo ert o r  ootoe o e t ot td  \"\n",
      "batch 19756  loss=176.2031  steps/s=99.91  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"n ns  eln   eaðŸ‘Œ  a eee le eetee eeteetee\"\n",
      "batch 19757  loss=172.7522  steps/s=104.36  prediction: \"ouraging way, not stressful for the kid)\" => \" l   nginhgin/ennug ngnug nun aanus ters\"\n",
      "batch 19758  loss=179.5655  steps/s=12.44  prediction: \"reply: @ludwigABAP @0xluffyb just be you\" => \"eply: @nuru/inwow,ing,,so,.,fuo,snfr,fi)\"\n",
      "batch 19759  loss=176.2406  steps/s=132.76  prediction: \"rd it means theyre giving you a discount\" => \"eel   e ad ia,g wf dv,mswuyrfuohvbvdvgiv\"\n",
      "batch 19760  loss=183.7347  steps/s=108.94  prediction: \"of work every monday and thursday brotha\" => \"   io  tri  ohhn oor  r  reorr oyydyy  r\"\n",
      "batch 19761  loss=185.6962  steps/s=75.01  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"yd oorsiren A  n Mo   R   dorra ayayy ha\"\n",
      "batch 19762  loss=173.7357  steps/s=115.89  prediction: \"that was probably its entire purpose lol\" => \" e i is wa  wshhpvblam\n",
      "of\n",
      "bthu\n",
      "vppyppfb\n",
      "\"\n",
      "batch 19763  loss=179.6223  steps/s=73.44  prediction: \" miss the good old completion model days\" => \"tim en etthar waonh hoab boits oe pt p t\"\n",
      "batch 19764  loss=174.2892  steps/s=115.25  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" x it @enen,kxhxpkx.xIxIa\n",
      ":I:p.:.:G:cNMN\"\n",
      "batch 19765  loss=177.8003  steps/s=112.90  prediction: \"/t.co/ijkDs8PScw https://t.co/PiGqd4ZNLk\" => \"eocasist /:/t//is//sDsD/PPSc:cPtPts/P//P\"\n",
      "batch 19766  loss=182.1935  steps/s=112.42  prediction: \" lets you debug your own problems easily\" => \"tiaeat ttte tlate its uoe  uy ue lou  ye\"\n",
      "batch 19767  loss=176.1456  steps/s=99.81  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" at  sieigezaze ia se te ieioi nn siti  \"\n",
      "batch 19768  loss=179.4539  steps/s=41.48  prediction: \"ly: @Yosef_Frost https://t.co/dWiO4erSb1\" => \"e: @eotea zzaee ia te to ieioi nn si i  \"\n",
      "batch 19769  loss=180.6302  steps/s=148.60  prediction: \"thy I wonder how attention relates to IQ\" => \" e   teno  i_FI Igmvho:h:wim./eWdO4O4Sb1\"\n",
      "batch 19770  loss=184.6664  steps/s=107.15  prediction: \"E gambits dude\n",
      "Punish mode is goated too\" => \"GIN_VVI  tVOVEhmbPEOPPIP\n",
      "IPEPunp\n",
      "PudPdPu\"\n",
      "batch 19771  loss=179.0302  steps/s=66.78  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" d   ga est a kb HHaH gm iodim go gedeJJ\"\n",
      "batch 19772  loss=174.4684  steps/s=106.14  prediction: \"s like envy, lust, gluttony, pride/selfâ€¦\" => \" to  nt  ei eiti eioyt, eye, ens, tlysil\"\n",
      "batch 19773  loss=179.0601  steps/s=108.59  prediction: \" way I implemented it might be different\" => \"tannme\n",
      "ma e ea a e eI  m nmemen d miefef\"\n",
      "batch 19775  loss=178.6189  steps/s=104.77  prediction: \"good idea but whatever, i wanna have fun\" => \" r  nno\n",
      " i  tohaagd\n",
      "pduvybdurgwadhavewwh\"\n",
      "batch 19776  loss=177.6806  steps/s=113.16  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e eg: \n",
      " ee???LLrLxL/0Lba=&==&w;=&&^;;;^^\"\n",
      "batch 19777  loss=189.7874  steps/s=74.07  prediction: \"2wlearning Great stuff man, keep pushing\" => \" rrr)een  n ein  oelen=&&=;;n^^ ^en nxen\"\n",
      "batch 19779  loss=179.1120  steps/s=119.42  prediction: \" personally wasted many years bc of this\" => \"tena tenie  Hae  oeast leeyaasana aey y \"\n",
      "batch 19780  loss=184.9755  steps/s=107.93  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"sgaui (rot lt 8   44c ts  tot::// tsQ//A\"\n",
      "batch 19781  loss=189.0921  steps/s=101.68  prediction: \"igure out how to improve your work ethic\" => \"nh  s ts t  u huo  ou t  o  o o   twrtu \"\n",
      "batch 19782  loss=173.8190  steps/s=110.97  prediction: \"ny depressions ripple to other countries\" => \"  ie e a    oa@e??vp?c?adppceripsgchuwnc\"\n",
      "batch 19783  loss=184.6960  steps/s=101.90  prediction: \"article on RNNs: https://t.co/vQdYuCAdT9\" => \"nes dp\n",
      "\n",
      "t unie   ll NNNNNNNN::::tst/////\"\n",
      "batch 19784  loss=186.4319  steps/s=37.52  prediction: \"ly: @archived_videos am american, so idk\" => \"y: @hneoenonllh  :RNN::N:NNt:::/tst/////\"\n",
      "batch 19785  loss=175.3816  steps/s=115.07  prediction: \"tups are hidden in the fog 2 moves ahead\" => \"hr f s orenpivvpavLvhhidfsn\n",
      "L2lv2pfu2f22\"\n",
      "batch 19786  loss=184.7479  steps/s=107.82  prediction: \"18/hr\n",
      "\n",
      "cons\n",
      "- none\n",
      "- i only know scratch\" => \"0\n",
      " r e hag/$18/t1818-81818/ympy8/hy1yhk/\"\n",
      "batch 19787  loss=180.6652  steps/s=108.11  prediction: \"t sure though. lmk if you find something\" => \"hcoi nd ot  .v. ..sl.f.skmgahglngliflwkl\"\n",
      "batch 19788  loss=164.1993  steps/s=40.76  prediction: \"y: @thevalidcode Was just gonna say this\" => \"  @w.enocono . n e . .u.....  t uiou  nm\"\n",
      "batch 19789  loss=178.4461  steps/s=96.80  prediction: \"\n",
      "\n",
      "Any kind of work counts, its up to you\" => \"\n",
      "iv iten  vike0 kvxdA!A!ouiA,\n",
      "fgw\n",
      "wkpy,w\"\n",
      "batch 19790  loss=174.0938  steps/s=87.14  prediction: \"im how fun the funny computer things are\" => \"np  t phs\n",
      "nhofs hn w fu ht  uunfuun t nn\"\n",
      "batch 19791  loss=178.9509  steps/s=38.78  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \": @ a    h h f hun   fu ht  uuu  un t nn\"\n",
      "batch 19792  loss=168.2280  steps/s=119.33  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"taoot      m mt olom toet  t mmtt pt orp\"\n",
      "batch 19794  loss=171.7341  steps/s=106.83  prediction: \"mple py script manages building/updating\" => \"ait pe a    iwf lvvyvwvvimpymgcy\n",
      "bc[mavc\"\n",
      "batch 19795  loss=187.2819  steps/s=109.24  prediction: \"man!! Happy thursday grind my dude\n",
      "vibin\" => \"ane pneT  iTn!n HaHyHgHuHmu\n",
      "mg/r\n",
      "//ymyvðŸ›‘\"\n",
      "batch 19796  loss=182.9470  steps/s=42.69  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \": @lnsa m py pt  n  ay yai t uy dudad dr\"\n",
      "batch 19797  loss=180.6142  steps/s=118.66  prediction: \"but its ok bc I know theyre high density\" => \"et i   tnetet  ns bbt  kkok kb nIe  hn  \"\n",
      "batch 19798  loss=186.2669  steps/s=64.33  prediction: \" @MaxMynter Careful. Its addicting stuff\" => \"tAe  t     et   k  bt  kkee ki t e  hg  \"\n",
      "batch 19800  loss=175.0988  steps/s=114.74  prediction: \"you find God, the truth, and help people\" => \" u  anwonure eoeG G  G u,e,th dd  the he\"\n",
      "batch 19801  loss=178.6472  steps/s=71.88  prediction: \"paeoh do it man!! making games is so fun\" => \"lct @ ot te uhGiw,yG,vfh!akvydigom,mfivy\"\n",
      "batch 19803  loss=168.2371  steps/s=97.87  prediction: \"s after monads.. https://t.co/V7s73DqEAF\" => \" oos booesn sse s e  tss ....  t//7/V7s7\"\n",
      "batch 19804  loss=172.7771  steps/s=102.24  prediction: \"seless to ppl who dont know them already\" => \"  ele tile   leesepl oop l p  o wo eow  \"\n",
      "batch 19805  loss=172.2199  steps/s=105.29  prediction: \" being mediocre\n",
      "\n",
      "who cares if loss goesâ€¦\" => \"te    beg g i g5oerege eo e re eo resso \"\n",
      "batch 19806  loss=163.3019  steps/s=106.89  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \" ar a  netue  an aeet t eeerrnren n  ner\"\n",
      "batch 19807  loss=189.9250  steps/s=112.59  prediction: \"lEnergel @jesx64 https://t.co/gyECG7Z8jB\" => \"y iu enltgo e@ee tee6 6 et ssee //t eeC/\"\n",
      "batch 19809  loss=169.2719  steps/s=84.93  prediction: \"d size to whatever you want which helps.\" => \" bo u sott  t zh  t ee tt t woi w  e   h\"\n",
      "batch 19810  loss=175.5772  steps/s=75.66  prediction: \"hess isnt hard just make the right moves\" => \"e  iseis shh swhi h rs tt t rt t ea h  a\"\n",
      "batch 19811  loss=169.9534  steps/s=104.71  prediction: \"sonnet3.5 for pretty much everything now\" => \"  ese ee Iue  e    te e te    e  retet  \"\n",
      "batch 19812  loss=206.5275  steps/s=111.07  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"17 A1AAAA6A1A19191929A1213131BB13A3A333B\"\n",
      "batch 19813  loss=184.2909  steps/s=108.59  prediction: \"izer\n",
      "\n",
      "his uses a NN this uses Q learning\" => \"nisA s l au suass  s NNNNNN ssss s   QQ \"\n",
      "batch 19814  loss=176.0779  steps/s=109.43  prediction: \"ave been trying to compress these lately\" => \"ne      se  te n enen o to no tee oeee s\"\n",
      "batch 19815  loss=198.2864  steps/s=55.72  prediction: \": example output https://t.co/jRATFli0Ik\" => \" @aodeiing1,o,bel,N,bwag:v:,cvyngRjRFTF0\"\n",
      "batch 19816  loss=176.8822  steps/s=106.22  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \" \n",
      "o it \"\n",
      " e i\"i \"ofofiofof fn lol Ca C l\"\n",
      "batch 19817  loss=171.7987  steps/s=108.59  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" c yn eanehr ofovdown.wC.ifwmcinHHuH:XKw\"\n",
      "batch 19818  loss=172.1104  steps/s=111.09  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"e iilnil i  e e n ill il  i  ile  in h h\"\n",
      "batch 19819  loss=170.3087  steps/s=111.99  prediction: \"s using techniques right under our noses\" => \" wut oeo n u uudueu   inhi  nihn iun eni\"\n",
      "batch 19820  loss=184.5133  steps/s=89.66  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"nd testacitit   hkspsktkpoktkp  //prM /t\"\n",
      "batch 19821  loss=183.2539  steps/s=105.50  prediction: \"t just means youre on par with a supergm\" => \"hmo telisncomjItIjIjkjj2jp2m2IB.jp/B0s0p\"\n",
      "batch 19822  loss=174.4399  steps/s=94.16  prediction: \"your life (which is what happened to me)\" => \" ur a l  yo  fh  (( (i hwh   wa haha ep \"\n",
      "batch 19823  loss=170.8663  steps/s=102.07  prediction: \"do all of those\n",
      "\n",
      "https://t.co/C4hXOs7hck\" => \" mb u il f o  o6  lo  o oot ohotttht//h/\"\n",
      "batch 19824  loss=169.5626  steps/s=89.10  prediction: \"ion ability. should be trained first tbh\" => \"nntl  c t oialitlili  il  lo t  i dd i  \"\n",
      "batch 19825  loss=177.9316  steps/s=99.54  prediction: \"r time your focus muscle will strengthen\" => \"eoerg thgnv6Ovhrmvdyvmvucrmfmcmclmfscwcv\"\n",
      "batch 19826  loss=179.5912  steps/s=110.53  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tir te  a  i nger s etsett t ent/ t .eY/\"\n",
      "batch 19827  loss=173.8636  steps/s=96.42  prediction: \"e some exciting long term vision then no\" => \" te  not  no  ene  tet  o t tn e ni   en\"\n",
      "batch 19828  loss=179.4241  steps/s=107.63  prediction: \"inful to stfu but it works suuuuper well\" => \"ng  lk ls\n",
      " tllht s f i  t  sttuttt   su \"\n",
      "batch 19829  loss=172.1053  steps/s=96.67  prediction: \"Simple p5. Will look into matter though.\" => \"amlyetl a fS p t lt5iW  lo k tutt o tr t\"\n",
      "batch 19830  loss=176.5358  steps/s=98.48  prediction: \"a youtube video about it and it exploded\" => \"npot h t m m et eate t bbouai t ito t a \"\n",
      "batch 19831  loss=172.1376  steps/s=93.03  prediction: \"works for the first time is the most fun\" => \"ar  o enhti wkskthgwchflmcghwamdbwmguwpf\"\n",
      "batch 19832  loss=178.0211  steps/s=96.18  prediction: \" something rudimentary could be possible\" => \"tptinea t tet n r mnn mhthr hinemintment\"\n",
      "batch 19833  loss=175.3369  steps/s=93.30  prediction: \"e irl. i dare u. https://t.co/NEk2CLBwti\" => \" yai  ttt  t rm i d. .. u. .. .tt/s//E//\"\n",
      "batch 19834  loss=178.5382  steps/s=90.73  prediction: \" log(distance) to things instead of theâ€¦\" => \"tiseo s itgi  (  ote  tggtg  ts t  tn ti\"\n",
      "batch 19835  loss=191.7659  steps/s=98.16  prediction: \"t 7am cali time)\n",
      "https://t.co/F2CTiqaZnI\" => \"hto (Oit na sB7oII7(7))7OIl)::/)F):TFF:C\"\n",
      "batch 19838  loss=179.5825  steps/s=88.63  prediction: \"rd it means theyre giving you a discount\" => \"e 2 mae ld,2ved vdrwv:phw.ld.d//g.rgvypv\"\n",
      "batch 19839  loss=172.6752  steps/s=110.97  prediction: \"ut from having 1/3rd the progress per hr\" => \"s      u n ou uo  or    hr  r3 gr    e  \"\n",
      "batch 19840  loss=177.8776  steps/s=92.90  prediction: \"entives require computation\n",
      "\n",
      "Also lol Iâ€¦\" => \"  i gnea     gntqn eq  qqqrenre cuieetiA\"\n",
      "batch 19841  loss=181.1987  steps/s=97.54  prediction: \"right words can change entire industries\" => \"ecln Gh_e _Gphrtgldmwowhidha\n",
      "wluwrndoenw\"\n",
      "batch 19842  loss=176.5915  steps/s=107.03  prediction: \"ugh or is it just whatever comes to mind\" => \"sh i  or inoh ghuwu r  i  u  t tet w r s\"\n",
      "batch 19843  loss=171.6492  steps/s=110.62  prediction: \"lf of that was way off. all good tho nbd\" => \"y o ma e h  a w a    a  f f      l o o  \"\n",
      "batch 19844  loss=175.2071  steps/s=96.91  prediction: \" what? never heard of it lol skill issue\" => \"tame  gaeem ???s?meer rar   dear loer l \"\n",
      "batch 19845  loss=175.8952  steps/s=108.73  prediction: \"tony learns domain expansion in season 5\" => \"h c  o t g  twhtcokklkflxvxxvnhsxdexxyxs\"\n",
      "batch 19846  loss=174.2292  steps/s=106.41  prediction: \"deviating\n",
      "and it lets you do that faster\" => \" no a d e deianeind an  ati t  teoot aa \"\n",
      "batch 19847  loss=171.0481  steps/s=101.68  prediction: \"e Bible has treasure but you have to dig\" => \" mhr  nf n  t\n",
      "dte haioetheauttetrethea t\"\n",
      "batch 19848  loss=176.0302  steps/s=104.37  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"ectnt  (rmv(,o( wa)(g)()):(t:p::/35:35KY\"\n",
      "batch 19850  loss=176.4952  steps/s=71.85  prediction: \"sunsettler hes locked in to the outdoors\" => \" nog aeit r dirienredte::/:nit 35KY99Y9s\"\n",
      "batch 19851  loss=173.6823  steps/s=104.37  prediction: \"ment it with all the details that pop up\" => \"e i in oorB4ðŸ¤”he nb$nbgwwtocblwcmh8smpwur\"\n",
      "batch 19853  loss=183.3290  steps/s=107.58  prediction: \" through nevada w my dad as a little kid\" => \"the  r egg  i dnivr v vd a d a ad  aa   \"\n",
      "batch 19854  loss=175.8387  steps/s=104.92  prediction: \"gram faster which made him have more fun\" => \" amwa ne  pe gnhcufpufiffsfprubcfwsowvdw\"\n",
      "batch 19855  loss=163.8896  steps/s=104.83  prediction: \"ments as opposed to making the user wait\" => \"erle mn mrká´›ðŸ˜dc m,dkopg,gu,cbwgmkgcv(ck,\"\n",
      "batch 19857  loss=168.7771  steps/s=101.05  prediction: \"ernet becomes, say, 100x more addictive?\" => \"  tt nh enen eween tene s,es,1e0 , e  e \"\n",
      "batch 19858  loss=174.1884  steps/s=102.40  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" rmdit hucB_ðŸ‘Œâ€™c C~Cfyh\n",
      "PcPmyCCnmyC\n",
      "PPvyC\"\n",
      "batch 19859  loss=172.6557  steps/s=104.22  prediction: \"forward, forever\n",
      "https://t.co/zlto3SBYwd\" => \" rmtb   w,@Z,â€™l u@flygu:ugb:bgw.z3gzfSr3\"\n",
      "batch 19860  loss=174.1178  steps/s=98.80  prediction: \"atched this 8 times\n",
      "actually cannot stop\" => \"neea eewon wnd ti 8 8e8 s t ts ltccttltt\"\n",
      "batch 19861  loss=176.7662  steps/s=104.08  prediction: \" works if you did it right, or it doesnt\" => \"thke  tt w  t  t  o   ii oid ii  t it it\"\n",
      "batch 19862  loss=183.1476  steps/s=102.39  prediction: \"ers @iliekcomputers is a p strong player\" => \" siielen1eie sd i dess i l epp eetp s  p\"\n",
      "batch 19865  loss=171.3596  steps/s=104.98  prediction: \"just point to concepts and arent reality\" => \"ust      ar n jt osit  s no oonot t no a\"\n",
      "batch 19866  loss=178.6655  steps/s=95.20  prediction: \"nts also on the nm level, but, 3d not 2d\" => \" io  e tnts npgt.m.gm.l.thav,v,u,v3,p3b3\"\n",
      "batch 19867  loss=185.8286  steps/s=100.62  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"tt ii issn  inh nt,ths,s,t/hsttei:/:2c6/\"\n",
      "batch 19868  loss=174.1304  steps/s=94.63  prediction: \"be setting a deadline might help as well\" => \"e t n  k  t t dn tene d tdai ea e ienh i\"\n",
      "batch 19869  loss=176.5564  steps/s=54.70  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"taa i  e te t ye tede  ged i e  e i ah h\"\n",
      "batch 19870  loss=170.3955  steps/s=99.12  prediction: \"ling down on stuff I initially dismissed\" => \"yn o  roeg nnm  ff ff on n on  o i in os\"\n",
      "batch 19871  loss=170.7558  steps/s=93.29  prediction: \" been some adventure man. God bless him.\" => \"tee  tese s  see veveevee een e eGeG e e\"\n",
      "batch 19872  loss=188.7583  steps/s=94.68  prediction: \"copy ... etc\n",
      "\n",
      "my bottleneck is LLM speed\" => \"odei    nt,srho ry...acpb,\n",
      "i.ybb,b\n",
      "..kbk\"\n",
      "batch 19873  loss=179.9352  steps/s=67.24  prediction: \"atedro @gizmobly https://t.co/IFzJo2qtyj\" => \"ne     ro e  e e \n",
      "ymtt y  ee /c LLL LLJe\"\n",
      "batch 19874  loss=165.0128  steps/s=99.61  prediction: \" they secretly exercise and dont tell us\" => \"the  yst dsteeml  eeyteeteeeecc  e   tt \"\n",
      "batch 19875  loss=177.2469  steps/s=83.82  prediction: \"he second one Unison (Knife Party Remix)\" => \"e ie     tseeet eneeeeenononin nin n  t \"\n",
      "batch 19876  loss=178.9775  steps/s=83.24  prediction: \"grammer extra respectfully:\n",
      "\n",
      "skill issue\" => \" e P n mw gPgAPm@U@xdxKg(K(xP:xPxPRr:R:)\"\n",
      "batch 19877  loss=193.2667  steps/s=80.90  prediction: \"@yacineMTB bedrock aws, us-west-whatever\" => \"saciigb A m    nerreTe ceec  sk-k-s--l-t\"\n",
      "batch 19878  loss=174.1607  steps/s=83.59  prediction: \"sing llms to their full potential rn tbh\" => \" 23e a eel re is  lr    ls  ll iteatottl\"\n",
      "batch 19879  loss=177.0322  steps/s=86.53  prediction: \"it playable on lichess and post the link\" => \"t  en    ll aabel    ll tee i n  l ene  \"\n",
      "batch 19880  loss=177.8860  steps/s=88.39  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"tor sarr  ororeeeg\n",
      " \n",
      "s es se\n",
      "eso eo o  m\"\n",
      "batch 19881  loss=177.2622  steps/s=86.97  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"toeamnY shsN N e sss  s h  shsh6 h6 ihsi\"\n",
      "batch 19882  loss=183.6051  steps/s=103.19  prediction: \"MTB a dollar flowing through the economy\" => \"TB YYY|Keine T la sot w h  shs g rs ohst\"\n",
      "batch 19883  loss=171.6219  steps/s=100.50  prediction: \" v. move forward/backward is layer stuff\" => \"tet  n vn cv   ovv  vv  or  ar  arrw  d \"\n",
      "batch 19884  loss=174.5394  steps/s=104.56  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"tn tiiit aliCsainii ei ai n\n",
      "\n",
      "i ii ihiisi\"\n",
      "batch 19885  loss=175.9534  steps/s=102.92  prediction: \"hemes\n",
      "John waitzkin called this chunking\" => \"e s :+ n \n",
      "ls\n",
      "J:\n",
      "J tn tah z ezeznzcth thi\"\n",
      "batch 19886  loss=180.3816  steps/s=105.44  prediction: \"erous people, very sad, but also fixable\" => \" s t se no   oeoeeeue ep s  e  , , s   s\"\n",
      "batch 19887  loss=187.3153  steps/s=104.36  prediction: \"you get used to it and overcome the fear\" => \" u  graat ro out u  e  t  o  e   d  eto \"\n",
      "batch 19888  loss=171.5363  steps/s=104.90  prediction: \"ed for editing videos would be so goated\" => \"  ee  gdonodoiheded ed oedi eo  eoi dsoe\"\n",
      "batch 19889  loss=183.0901  steps/s=104.62  prediction: \"utput in readme\n",
      "\n",
      "https://t.co/hKCmvzerIc\" => \"s  s sptt    p , tu t a\n",
      "ute\n",
      "\n",
      "\n",
      "//\n",
      "\n",
      "\n",
      "///KK\"\n",
      "batch 19891  loss=211.1008  steps/s=91.26  prediction: \"ARD LETS GOOOOOO https://t.co/VIgkyoiBY2\" => \"PA@ xt i  GOGOOGOOtOtGO /t/t:////t.VVI/I\"\n",
      "batch 19892  loss=178.3834  steps/s=91.96  prediction: \"g us calculate costs some weird jank way\" => \" toa et  maoeof idklfkmagfomrcppimgkjzjt\"\n",
      "batch 19893  loss=164.0316  steps/s=86.49  prediction: \" can so can you. But maybe im projecting\" => \"@ak i  i n   c    a s u  u  ao m  m m i \"\n",
      "batch 19894  loss=176.3528  steps/s=88.04  prediction: \"thought I would\n",
      "\n",
      "Now, I shall take tomoâ€¦\" => \" a  se m th eoI7i.g,NuIdI.Nlw,aN.NhNul,g\"\n",
      "batch 19895  loss=172.9633  steps/s=87.99  prediction: \"ing ive wanted in life lol, complete 180\" => \"ng e ettenv  vwtten n  e   lell  lll lle\"\n",
      "batch 19896  loss=172.9713  steps/s=87.74  prediction: \"ill you get better at as you practice it\" => \"nl t rtt      h  et eet etea  tet a    a\"\n",
      "batch 19897  loss=172.7300  steps/s=95.49  prediction: \"erscores the importance of curating andâ€¦\" => \" -n a   th   he irin t snts  rer r coren\"\n",
      "batch 19898  loss=180.4031  steps/s=96.85  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"tineo  n eo oweowe no eofe foh ooo ter t\"\n",
      "batch 19899  loss=165.3811  steps/s=68.44  prediction: \"yotzol its not a meme, its a way of life\" => \":u  o lno dlnwfdfe fo e hh  oh ooo ter t\"\n",
      "batch 19900  loss=162.5553  steps/s=102.10  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: sesssesssesln el   llelln.l..le.lleee\"\n",
      "batch 19902  loss=175.8199  steps/s=92.87  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"@h  eehhs tsin ns ne ei\n",
      "\n",
      " diepiaipi pes \"\n",
      "batch 19903  loss=176.7867  steps/s=96.44  prediction: \"p in the readme\n",
      "\n",
      "https://t.co/dWiO4erSb1\" => \"lpee@t\n",
      "nnelt  dBlvhyj:v:mc::///mc::/WWW4\"\n",
      "batch 19904  loss=197.2515  steps/s=88.15  prediction: \"t, learning lot.\n",
      "https://t.co/zdN159Agt6\" => \"  R sdinng a !\n",
      " ,,,7d.\n",
      "g,loo:/,..!p::::5\"\n",
      "batch 19907  loss=174.1692  steps/s=95.55  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"taa een eeaolroc io \n",
      "o   alyer p ey  are\"\n",
      "batch 19908  loss=176.8184  steps/s=97.63  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"g ea    oint d  wvvkckoc:v:ikgivoCVC:W\n",
      "H\"\n",
      "batch 19909  loss=186.4126  steps/s=90.65  prediction: \"r man\n",
      "\n",
      "your blog has an awesome aura btw\" => \"edo tiCe mnrsecohry@uymky1uc\n",
      "y\n",
      "hb1bbbbog\"\n",
      "batch 19910  loss=171.9109  steps/s=88.95  prediction: \"t them as axioms, and it screws you over\" => \" th  atr ire ae dxs,axduxxxga,d,cxypcr,x\"\n",
      "batch 19911  loss=170.3553  steps/s=89.32  prediction: \"e refined your taste will be\n",
      "\n",
      "idk though\" => \" th  m  efee tfoteo ere r ee ee r  t ee \"\n",
      "batch 19912  loss=170.7423  steps/s=74.26  prediction: \"igABAP Born to consoom, forced to signal\" => \"nA e  oeigBBo AorBo noeoetel oe \n",
      "\n",
      "dt otd\"\n",
      "batch 19913  loss=186.4783  steps/s=89.51  prediction: \"saas #developers https://t.co/GmrQaIKpLs\" => \" ine\n",
      "n ser#a#iee#eeas es lsaspp/e//:tQpG\"\n",
      "batch 19914  loss=190.2758  steps/s=93.49  prediction: \"/t.co/cU8TdGmOOe https://t.co/zDRTVLYdCb\" => \"/..cs:   h ::://UUUTUUGOOtcOOOp t/co.c//\"\n",
      "batch 19915  loss=203.6138  steps/s=95.50  prediction: \"luffyb Xorswap, what a username, love it\" => \"ydwr17_0x 1xyy fXXywXXXXwwppa   hs, aa ,\"\n",
      "batch 19916  loss=169.3328  steps/s=99.60  prediction: \"his is the same w similar things in life\" => \"engs e iings\n",
      "i g s ihi   iheie  s itii t\"\n",
      "batch 19917  loss=173.4449  steps/s=98.92  prediction: \"r time your focus muscle will strengthen\" => \"eter  thgn  ovhfOvdOvOvucrmfmymylmfscwcv\"\n",
      "batch 19918  loss=174.1454  steps/s=91.72  prediction: \"indows couldnt load. Fixed after 20mins)\" => \"ng io i nti  w( dwd ddoi do Fo dd    add\"\n",
      "batch 19919  loss=172.4940  steps/s=87.32  prediction: \"re just doin their part to get us to AGI\" => \"e lno ejost   jrqqjTsTyTytylfypuldTaA\n",
      "gh\"\n",
      "batch 19920  loss=173.7954  steps/s=94.46  prediction: \"ore descriptive titles for the rest lool\" => \"nkie   een e  trieitiitiin  d tirt ti er\"\n",
      "batch 19921  loss=187.4136  steps/s=90.42  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \"nn e ne Q##Q#Qetie tiitre e \n",
      "e\n",
      "he\n",
      " t  l \"\n",
      "batch 19922  loss=180.5167  steps/s=91.17  prediction: \"the behavior, forming a habit eventually\" => \"he   nefobcbd, t,cg,,hfing,lga,bfnbvinvh\"\n",
      "batch 19923  loss=180.2893  steps/s=93.10  prediction: \"this. or you can win by trading seats wâ€¦\" => \"he  ib  y ducbb cbdfbysrhiig.w.hybuucu.d\"\n",
      "batch 19924  loss=183.0959  steps/s=100.19  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u yont moa t,    a at u 0thth0ue0% 0%% \"\n",
      "batch 19925  loss=172.8185  steps/s=98.77  prediction: \"he just checkmated because he got lucky\"\" => \"e bi\"\"\"\" e\"\" \"shh het t eecce ceee e e e\"\n",
      "batch 19926  loss=179.7373  steps/s=81.79  prediction: \"xes this (whether you want it to or not)\" => \" s Vein we  e hih the hs   te te w  e  t\"\n",
      "batch 19927  loss=176.6801  steps/s=89.97  prediction: \"[listen to tpod] https://t.co/T4E8ws1uTP\" => \"looy ten inndo [bi[]wd]:is:pi:]rw]]4E:4E\"\n",
      "batch 19928  loss=174.9719  steps/s=89.95  prediction: \" the db he can just delete all of reddit\" => \"thezzzzs  sei b e e e       e  eete  l l\"\n",
      "batch 19929  loss=172.3868  steps/s=90.84  prediction: \"ed hard at improving, mostly by studying\" => \"  iy   w rdrdrddr rd  or  ar t t os  i  \"\n",
      "batch 19930  loss=171.1500  steps/s=91.51  prediction: \"dont just mean wrt doing logic with them\" => \"  get rd i?doafo deds d n ao at t t w tt\"\n",
      "batch 19931  loss=175.0490  steps/s=93.63  prediction: \" of why i used to get work sniped looool\" => \"tf e h ttfr  hwo  h i   e gt t  w t tow \"\n",
      "batch 19932  loss=177.9036  steps/s=95.34  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \"hon  abt bett  eciocp,?/xff/x:bxys:?EExc\"\n",
      "batch 19933  loss=179.7527  steps/s=90.85  prediction: \"makes it an order of magnitude harder...\" => \"eyr  ate n dr\n",
      "onybyynmkudkdbofncygdkvuk\n",
      "\"\n",
      "batch 19934  loss=175.8295  steps/s=87.89  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"toko  id tak th0aaGGddeG at  a o   e b r\"\n",
      "batch 19935  loss=161.9928  steps/s=67.59  prediction: \"atedro buildin something ppl want lesgoo\" => \"t  l d   dd ihuadied o s sh  e o   t t r\"\n",
      "batch 19936  loss=185.2510  steps/s=91.45  prediction: \"ess while retaining the same information\" => \"   ttel lsor snreta  tes  h te  ini t i \"\n",
      "batch 19937  loss=172.9229  steps/s=86.84  prediction: \"igABAP Born to consoom, forced to signal\" => \"nh   sg lgBBArAi tn noes me sn  ior i in\"\n",
      "batch 19938  loss=177.6950  steps/s=95.05  prediction: \"s every time I'm getting comfortable lol\" => \" aee r i nere n t eite e I''egeet fet eo\"\n",
      "batch 19939  loss=177.1112  steps/s=91.43  prediction: \"urs out of 16 I enjoyed the session verâ€¦\" => \"te h louto1t   u111  o  oo I   e  oo  oo\"\n",
      "batch 19940  loss=175.2836  steps/s=82.13  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" e te t te  os nkIImfkjfmvvvIhdvIcvipbIv\"\n",
      "batch 19941  loss=174.2174  steps/s=88.45  prediction: \"ore descriptive titles for the rest lool\" => \"rk e   een d  trde tiitiite d tort ti er\"\n",
      "batch 19942  loss=193.3111  steps/s=93.75  prediction: \"ood combo for stuff like this, ive found\" => \"rm o goitooffffeptems ffip gegkmdggok oo\"\n",
      "batch 19944  loss=170.3422  steps/s=98.59  prediction: \" adding the context into the computation\" => \"tnd    ioero o  e one itnt otte tneoto t\"\n",
      "batch 19945  loss=165.4951  steps/s=97.12  prediction: \" fly everywhere\n",
      "\n",
      "idk how lidar works btw\" => \"tir t      t ev tvvve\n",
      " w\n",
      "r \n",
      "he wi i w ro\"\n",
      "batch 19946  loss=174.2042  steps/s=97.40  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th  e thsetsin nt ti tii\n",
      "idi e  ipi pers\"\n",
      "batch 19947  loss=178.0698  steps/s=95.48  prediction: \"ent in pygame and the network in pytorch\" => \" tne  tee n invn e    e ae e nn et ene  \"\n",
      "batch 19948  loss=168.1723  steps/s=35.96  prediction: \"ply: @sunsettler https://t.co/zjvWwH1Tz5\" => \"ly: @a pa se p eevorwklkvgtdpypzygWgHpTg\"\n",
      "batch 19949  loss=170.4920  steps/s=102.10  prediction: \"e algo show you a lot more similar posts\" => \" ah  mth   oe n hoo too  o o   o   oo   \"\n",
      "batch 19950  loss=158.0593  steps/s=100.11  prediction: \"agnosed as wise old man (thanks to tpot)\" => \"ne  e t n t ns s  e     s   a  o a  st  \"\n",
      "batch 19951  loss=159.7166  steps/s=99.93  prediction: \" trait to have\n",
      "Ideas flowin like a river\" => \"thenaes taa taha t t  aat   aaa    ieea \"\n",
      "batch 19952  loss=190.0720  steps/s=99.53  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"lOdty teteHUUGGEHUGUGEGEm//vc\n",
      "hQQQp::WRR\"\n",
      "batch 19953  loss=178.4237  steps/s=105.34  prediction: \"ly harder than the last. repeat forever.\" => \"y: @Le ehteartt  arrhte  ha e nheh r.ter\"\n",
      "batch 19954  loss=168.0171  steps/s=103.27  prediction: \"the highest quality music we have so far\" => \" e   tai   ofpn wÊ€{lgwI.nfqraly.yqmqvtgq\"\n",
      "batch 19955  loss=178.6742  steps/s=100.75  prediction: \" flick of the wrist instead of traveling\" => \"to n igf f o  e oi  i t e wtfwist st so \"\n",
      "batch 19956  loss=188.9568  steps/s=91.52  prediction: \"mobly @amix011 May do this in the future\" => \"ase eninizn ol@e@wx0M0\n",
      "MnMrgcdwdwscsfv\n",
      "r\"\n",
      "batch 19957  loss=180.1704  steps/s=104.78  prediction: \" easy to use too\n",
      "https://t.co/EjkhiWdtX3\" => \"tdde tettn noowneoshs tta se/s.s.t.t :E/\"\n",
      "batch 19958  loss=179.8766  steps/s=100.15  prediction: \"g, thx\n",
      "Interested in hearing how it goes\" => \"  i sthg hnre,eshx,I,fx\n",
      "x\n",
      "I,x,IxgI\n",
      "Iwxwd\"\n",
      "batch 19959  loss=179.9044  steps/s=105.18  prediction: \"day grind man\n",
      "Solid chunk of time so far\" => \" to_  nd yhdrthn nttdSi Srdai noh d  \n",
      " n\"\n",
      "batch 19960  loss=166.0130  steps/s=103.83  prediction: \" deadlines dont really get done the same\" => \"toi  hn\n",
      "n setoitee ddnnl delt  deed onel\"\n",
      "batch 19961  loss=168.1725  steps/s=96.41  prediction: \"opped this, king https://t.co/XoVrIPw6zw\" => \"r   su et  ee  ee    ppt pisp st/tt  oV \"\n",
      "batch 19962  loss=166.5907  steps/s=98.34  prediction: \"ed around the data that flows through it\" => \"     nn  ao dredne d ad td  nhee trot dh\"\n",
      "batch 19963  loss=172.0441  steps/s=100.43  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"toe ingoer r  g  eoge ðŸ’ª ðŸ’ªo ðŸ’ª eo i g shth\"\n",
      "batch 19964  loss=173.4684  steps/s=84.48  prediction: \"ircle tool gang) https://t.co/eWviZR2Y3N\" => \"neBr c clelcl  oo lcoltg) otggo//th  t/Z\"\n",
      "batch 19965  loss=173.5740  steps/s=94.12  prediction: \"aken further tho https://t.co/F3Chh2YU7z\" => \"te r     e lteet     th ttthettttt////F/\"\n",
      "batch 19966  loss=172.7346  steps/s=84.98  prediction: \"king spheres are infinitely many circles\" => \"engaioeod   oe rh  rte  tr inttnni htt h\"\n",
      "batch 19967  loss=206.9673  steps/s=10.08  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @t sng o o.lRsbT:sTk.comF3Cbi2YU7z\"\n",
      "batch 19968  loss=173.6368  steps/s=94.61  prediction: \"unctional adults that they interact with\" => \"ts henif fdn dho  n n tat al ntan thte t\"\n",
      "batch 19969  loss=163.5762  steps/s=88.38  prediction: \" billion zimbabwe dollars of labor hours\" => \"tydi bblbalb ba bab illlllol olllbllloor\"\n",
      "batch 19970  loss=185.2060  steps/s=89.41  prediction: \"/t.co/3niiW6u2N4 https://t.co/AMiuse1VEj\" => \"t.pe ct/ttd////:WWWWWW6NNNNN:4/t:t:////M\"\n",
      "batch 19971  loss=178.3167  steps/s=84.46  prediction: \"he race to steal the eu tech bros begins\" => \"e    / tinj tNc  hehrt/s t et ehhtstsebu\"\n",
      "batch 19972  loss=167.7975  steps/s=86.70  prediction: \"ive impact on me yrs after i had to stop\" => \"ne a   s ia iai          m      i  a  a \"\n",
      "batch 19973  loss=181.1909  steps/s=96.76  prediction: \" youre so smart why are you conquered??\"\" => \"tou   ootp   mimma yy ye se re  oy ar er\"\n",
      "batch 19974  loss=159.1814  steps/s=99.52  prediction: \"stop at polynomials\n",
      "\n",
      "it gets way crazier\" => \" i   tottnt t  topt t tolt l oostsltts t\"\n",
      "batch 19975  loss=166.4547  steps/s=96.11  prediction: \"sire, and if it sounds good to them\n",
      "\n",
      "idk\" => \" peeeen  tt i eieei  e  id s  d  toot so\"\n",
      "batch 19977  loss=171.2407  steps/s=98.75  prediction: \"tumbling on oneâ€¦ https://t.co/yj41try7Vy\" => \" re tni d  tendak)y kâ€¦â€¦aklâ€¦â€¦::/y.::/g.44\"\n",
      "batch 19978  loss=168.9991  steps/s=89.62  prediction: \"e the reward dips down below the average\" => \" aeer  te erern r dhewre de  eerdwwr e w\"\n",
      "batch 19980  loss=169.2518  steps/s=89.94  prediction: \"ncredibly painful, so a great motivator.\" => \"gh otn   ie  a nblyfwbruf)...gu.pyhdvb.f\"\n",
      "batch 19981  loss=170.3830  steps/s=86.49  prediction: \" the gap\n",
      "\n",
      "down the energy gradient we go\" => \"tho t n  g   oj op  gh \n",
      "n hn  gg g\n",
      "t gee\"\n",
      "batch 19982  loss=186.2213  steps/s=101.79  prediction: \"/t.co/OJgBwNc4TP https://t.co/3w0gRFnyKS\" => \"/.cp\n",
      "tet: ::/tJsOJOBJBBNct4PPc/t..st/tt.\"\n",
      "batch 19983  loss=169.9034  steps/s=95.77  prediction: \"house? where is your phone charger? etc)\" => \"ere yryeer  ee  ? or uo e hhe  hr o rro \"\n",
      "batch 19985  loss=174.2130  steps/s=91.15  prediction: \"ll be easy to remember every single move\" => \"yye  llle tl l lt te bem  e  e e  eeee e\"\n",
      "batch 19986  loss=168.9527  steps/s=92.61  prediction: \"c, just separated by some amount of time\" => \"h nkst d     oedpyfjdgcjujk,f,pjp.jydDb\n",
      "\"\n",
      "batch 19987  loss=172.7916  steps/s=87.02  prediction: \"all of the theories that we could invent\" => \"tl   ea   tfe ne t th oeoh o a te ehe ta\"\n",
      "batch 19988  loss=168.4542  steps/s=89.27  prediction: \"my efficiency. But overall cause its fun\" => \"e e epnin mp ew Bhsm.iB.rB.vBrmy.vBkysdB\"\n",
      "batch 19989  loss=170.7936  steps/s=99.02  prediction: \" she got into medschool after graduating\" => \"tta ohn gnt oghste too  htt  te  h  s ao\"\n",
      "batch 19990  loss=173.2804  steps/s=95.10  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \"hon  t ei e ne(n\n",
      "nu((w(ta(\n",
      "h(d(wmrlh)fo \"\n",
      "batch 19991  loss=182.9833  steps/s=91.24  prediction: \", 256, 144, ...]\n",
      "maybe x/max(x) is moreâ€¦\" => \" ai t p0^i0, 0 44,,.4,]]11]  ].m mxx m  \"\n",
      "batch 19992  loss=179.3284  steps/s=88.96  prediction: \"sicily, i hope to see the island one day\" => \" oer e  mmiy ii   ei i   se ts e selsi  \"\n",
      "batch 19993  loss=173.7242  steps/s=87.91  prediction: \"t progress/mistakes made/lessons learned\" => \" wo  o ao totees//,s/ga/m,/maknpdktkempg\"\n",
      "batch 19994  loss=172.0606  steps/s=88.81  prediction: \"ing cringe)\n",
      "\n",
      "you bulk some, you cut some\" => \"ng fo n on e innggggnggue\n",
      "u u u uouu  ou\"\n",
      "batch 19995  loss=159.3965  steps/s=93.19  prediction: \"u decide to start building it initially?\" => \"ndes te tht e t ee d  de tt bd  i ittiti\"\n",
      "batch 19996  loss=192.5565  steps/s=92.65  prediction: \" know some ppl this would help immensely\" => \"tnreaG we k wGIe maw lonm sow  sowltwp l\"\n",
      "batch 19997  loss=173.4285  steps/s=101.58  prediction: \"ful info have you learned from it so far\" => \" tl    cxeti pecpdvhdymwhlv8dyownlvimvin\"\n",
      "batch 19998  loss=174.6253  steps/s=99.52  prediction: \"discovering new unseen fundamentals, too\" => \" n  ted m\n",
      "oco ic n dneenneeieuune e nnun\"\n",
      "batch 19999  loss=170.5152  steps/s=99.61  prediction: \"l assemblies lol https://t.co/yG2bV74ZrB\" => \"yat  m aol asal oalem s l l //ss://soG/G\"\n",
      "batch 20001  loss=177.1701  steps/s=99.26  prediction: \"gh info density\n",
      "so that seems normal tbh\" => \" oa    ti  lgt Dtfowbwtpflydflgfpygfny\n",
      "u\"\n",
      "batch 20003  loss=172.4780  steps/s=101.88  prediction: \"g US aws regions\n",
      "\n",
      "claude 3 is on bedrock\" => \" to uneesing US kwcgUUSUSwkUSiUSbyw\n",
      "3wkg\"\n",
      "batch 20004  loss=171.1624  steps/s=92.60  prediction: \" that is not working out for some reason\" => \"to n rt ni t en i thin ni t tt o t  or r\"\n",
      "batch 20005  loss=171.3406  steps/s=39.17  prediction: \"y: @gizmobly nooooooooo my plans, foiled\" => \": @t r ini  nenno t on no t tt oot  or r\"\n",
      "batch 20006  loss=173.8560  steps/s=112.60  prediction: \"unctional adults that they interact with\" => \"ndebendr idn dee  i n  at ud ntadti te t\"\n",
      "batch 20007  loss=172.6967  steps/s=97.84  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \"    ntone tlln  t i ght   tt nt/ctcct:/t\"\n",
      "batch 20008  loss=185.3970  steps/s=96.32  prediction: \"cineMTB @jasonjoyride LETS GOOOOOOOOOOOO\" => \"onels  bnhsneMMgB@@@jBM@ja.cLETLEEETGGGT\"\n",
      "batch 20010  loss=180.4008  steps/s=94.71  prediction: \" thought they became ugly when they fell\" => \"@he e eothhht  tet  the eeh   ehy  hth  \"\n",
      "batch 20011  loss=179.4569  steps/s=84.51  prediction: \"iggy physiognomy https://t.co/kN6wq0jizX\" => \"nheoudoadtdtogoy y  hhtg  ytthth// /ee/N\"\n",
      "batch 20012  loss=190.1233  steps/s=44.97  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"stdwugAe P goghy y pttp/ //tthNN/tqqqqXX\"\n",
      "batch 20013  loss=165.8251  steps/s=110.50  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"@lso o     m mn ol\n",
      "m eo t  t mmte ppeo p\"\n",
      "batch 20014  loss=171.8197  steps/s=104.72  prediction: \"otential for small - very small things.â€¦\" => \"u  o tlot ntttot la l   sl -l l   a a   \"\n",
      "batch 20015  loss=177.7128  steps/s=66.82  prediction: \"@ludwigABAP ever thought of moving here?\" => \"sudiIob  e onts  l- - -- l  l s  m  s l \"\n",
      "batch 20016  loss=182.6046  steps/s=116.93  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \"p1mottouiei e21  eo lht D: Dm st/ZZ/Z.ZðŸ›‘\"\n",
      "batch 20017  loss=183.1965  steps/s=39.17  prediction: \": @yacineMTB jak creep is a real problem\" => \" @audr@nu1e2 rneD1:vDbD:uDv.D:DZ3.xZ3Zx/\"\n",
      "batch 20018  loss=167.9287  steps/s=130.71  prediction: \"s. let the people decide. for danmocracy\" => \"  eet ieertee  ee ltetpet pt .oe dlec ee\"\n",
      "batch 20020  loss=176.5889  steps/s=91.98  prediction: \"ed_videos Thanks!! Yea I took like 0.3mg\" => \"p let  rebi e  ee  tst!!  !o YeYod e le \"\n",
      "batch 20021  loss=170.7026  steps/s=95.27  prediction: \"you into thinking hes an anime character\" => \":u  t  trho ton  ino no  k ont kt ini nn\"\n",
      "batch 20022  loss=171.8145  steps/s=100.52  prediction: \"to build anyways\n",
      "https://t.co/wdCcR50W0E\" => \"  e )n  m  o    aafwbywc:))\n",
      "/w.c):/bCCRR\"\n",
      "batch 20023  loss=177.6677  steps/s=101.29  prediction: \"r easy setup btw\n",
      "https://t.co/dWiO4erSb1\" => \"eits  @ te   te utfwbuwbh.:h/:pc:/wW.WWO\"\n",
      "batch 20024  loss=165.7736  steps/s=102.26  prediction: \"losoft and make the circle tool yourself\" => \"ycg eoslloteoe se e e  e e   o    o     \"\n",
      "batch 20025  loss=174.9308  steps/s=103.53  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"etn th tro  a  3hgngy\n",
      "wvwv@l:fypJ:N.JZNJ\"\n",
      "batch 20026  loss=167.3777  steps/s=102.21  prediction: \"marter you get the more the traps change\" => \"et   e@ogtf. T@ TT9gC.bTybcbycdugc.din/ðŸ›‘\"\n",
      "batch 20027  loss=178.8316  steps/s=103.23  prediction: \"ing interviewer. https://t.co/wWOnnFvDyA\" => \"ng o    iiine  e ennt rntr. tt e.//.r/nn\"\n",
      "batch 20028  loss=172.4103  steps/s=104.09  prediction: \"pl to influence what they think (cringe)\" => \"ly:  gp e so ptlbgcpcu\n",
      "wopcwfwfyargwk(((\"\n",
      "batch 20029  loss=172.5465  steps/s=102.39  prediction: \"so much better than ppl who dont anyways\" => \"  s  o ho  o ot o t  t      p   hh thhn \"\n",
      "batch 20030  loss=163.7211  steps/s=101.95  prediction: \" is it some kind of info storage system?\" => \"tt ti i,nen i ie in sits o  o ii i  i so\"\n",
      "batch 20031  loss=166.5974  steps/s=98.24  prediction: \"P get him toys, play w him, lasts longer\" => \" pei ien go A  nti ts is t  o ai a  s se\"\n",
      "batch 20032  loss=178.8623  steps/s=93.94  prediction: \"ure Beautiful, and great choice of music\" => \"neigABA et e Bm t at,  l n     t a  s so\"\n",
      "batch 20033  loss=171.7743  steps/s=103.18  prediction: \"ave been trying to compress these lately\" => \"ne  lit t   ne n  nen o ioino tee o ee  \"\n",
      "batch 20034  loss=180.9953  steps/s=104.02  prediction: \"r you choose is not technically infinite\" => \"eao  ieh r  er rvuycbwmbcbvbbfyiuvghvfve\"\n",
      "batch 20035  loss=188.4281  steps/s=101.72  prediction: \" 4min miles, need to know whats possible\" => \"t8t ia thmit m    4et tistoh w wtn wnhts\"\n",
      "batch 20036  loss=170.1786  steps/s=104.41  prediction: \" real info about me\n",
      "\n",
      "whos building this?\" => \"taur rn  nne rn  ne  nbb ae  eu\n",
      " ub uin \"\n",
      "batch 20037  loss=167.4328  steps/s=100.47  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"neM n   o  dd t  t d      t  t//// ////t\"\n",
      "batch 20038  loss=173.0541  steps/s=104.38  prediction: \"the behavior, forming a habit eventually\" => \"he  tn f b nge t,cg,,hfing,lga,bfnfvinvh\"\n",
      "batch 20039  loss=173.5178  steps/s=96.21  prediction: \"e but it really is super flawed probably\" => \" sld ctele e   c  eeell li  sseeu e   ap\"\n",
      "batch 20041  loss=183.9984  steps/s=49.61  prediction: \" @anish0209 And now hes making it run js\" => \"tt0ice  8%%9%/9t  eeell il  ssee peablap\"\n",
      "batch 20042  loss=180.4767  steps/s=16.93  prediction: \"reply: @dwbypass https://t.co/k3grlVSm53\" => \"eply: @a  i 02eevAmuuwvwpbuabl//inspprgh\"\n",
      "batch 20043  loss=175.0777  steps/s=106.01  prediction: \"of time has been the problem in the past\" => \"  tife u f  tie  a e ea tta t e  th t e \"\n",
      "batch 20044  loss=172.4603  steps/s=100.96  prediction: \"riting style lol\n",
      "https://t.co/AO6VntSGJp\" => \"eage  @ e  e wm wbs\n",
      "yb\n",
      "b\n",
      "wpl:i:ny:.6AO6V\"\n",
      "batch 20045  loss=176.1550  steps/s=85.84  prediction: \"ettler @crypt0x_0 @EsotericCofe thanks!!\" => \"    t ga e  e yt l0 t0 0E_EE@EtAt/CC/CoJ\"\n",
      "batch 20046  loss=184.7421  steps/s=105.98  prediction: \"/t.co/lR1QfSHwXS https://t.co/7tEc48RWyG\" => \"tocl tt\n",
      " c/// :\n",
      "lSHQQSHHXXSS:tXt:://.../\"\n",
      "batch 20047  loss=168.1813  steps/s=101.88  prediction: \"seful instances of delayed gratification\" => \" d    nt  t  uent stse ef ose e  f f e a\"\n",
      "batch 20048  loss=179.9661  steps/s=99.87  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"e  settne tae  eee de   s a et g gslsse \"\n",
      "batch 20049  loss=165.1049  steps/s=103.10  prediction: \" to get tons of llms to output good code\" => \"theee eo nt gi g g totot   t tootol uo l\"\n",
      "batch 20050  loss=173.5852  steps/s=50.97  prediction: \": @teodor_io funny number go up type shi\" => \" @lalmone nen nsgbEEgscrbynpcichmvdkwgr\n",
      "\"\n",
      "batch 20051  loss=174.5930  steps/s=108.31  prediction: \" this long lost treasure of a song, damn\" => \"toe rrori mni isng lo o  t ts re ooto  s\"\n",
      "batch 20052  loss=172.4920  steps/s=95.57  prediction: \"neMTB i dream in ai generated js slop :/\" => \"g ye mfthgs eMnilfwd\n",
      "gnmnybuwpfutr,kjg,j\"\n",
      "batch 20053  loss=165.1002  steps/s=72.12  prediction: \"@btwphones thanks! its going well so far\" => \"stepfoMT        r  n  i in ag ge sjd  js\"\n",
      "batch 20056  loss=176.2063  steps/s=105.82  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"te.ciit .io/ .tc.4//88889S44SSStS::///t.\"\n",
      "batch 20057  loss=162.0031  steps/s=99.25  prediction: \"stry\n",
      "\n",
      "yet another reason we need nuclear\" => \"  u i  neuua tan yettry eee nnrenen  nen\"\n",
      "batch 20058  loss=176.3591  steps/s=105.54  prediction: \"makes it an order of magnitude harder...\" => \"ara  aness oteonybyynfkydkdvgfncygdkvuky\"\n",
      "batch 20059  loss=171.4263  steps/s=104.69  prediction: \"y want to use something feeling-relatedâ€¦\" => \" ti e bobyy y eb  oe s o    ee n eeeeeet\"\n",
      "batch 20060  loss=165.3352  steps/s=106.60  prediction: \"ssir\n",
      "\n",
      "ill dm you on the 25th with a link\" => \"  eot neoloe stml   l  o  ooe 2  2etheit\"\n",
      "batch 20061  loss=168.4601  steps/s=100.89  prediction: \" said it was his last email, he meant it\" => \"therhen rhs  st a i  s ia t  ia t s  e i\"\n",
      "batch 20062  loss=156.3320  steps/s=91.01  prediction: \"elf even if it overlaps with signoooling\" => \" yye  l ll  l le    e  ee e  i     i    \"\n",
      "batch 20064  loss=182.0325  steps/s=47.13  prediction: \" @jaivinwylde how many rs are in \"aura\"?\" => \"tsslein     i  v    e   e    i  i iiiooo\"\n",
      "batch 20065  loss=178.9340  steps/s=105.49  prediction: \" bet, im down, whats a good time for you\" => \"@eeeaanet  ei b  ,  w n wa a ta t oo ioo\"\n",
      "batch 20067  loss=168.0712  steps/s=83.39  prediction: \"see more details as you unblur an image.\" => \" lol    m d eee im  e ao d asta loua nno\"\n",
      "batch 20068  loss=173.5180  steps/s=91.81  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \" aa sanl tbao  eu-bybuobfscomiblrzyzubzo\"\n",
      "batch 20069  loss=188.9544  steps/s=22.01  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly: @t to e t  e oe o ot e  t o  t z et\"\n",
      "batch 20070  loss=168.5072  steps/s=131.01  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"eted  o il d b ecdkydlokpk:om:yfG.f:\n",
      ":mY\"\n",
      "batch 20071  loss=160.0800  steps/s=95.31  prediction: \"to use resumes if lying becomes the meta\" => \"h i ims   m tearcyupm:kkfkmpyjgfhpcp/,ly\"\n",
      "batch 20072  loss=162.6041  steps/s=81.22  prediction: \" giz tarantinos alt?????? this shit fire\" => \"teizsez z es i nsi  s?????? ?e st?ss it \"\n",
      "batch 20073  loss=166.9893  steps/s=99.33  prediction: \"his is the same w similar things in life\" => \"engs etii gsnisg s ihi   iheie  s itii  \"\n",
      "batch 20074  loss=173.2722  steps/s=99.57  prediction: \"ng to close your eyes to and just listen\" => \"g \n",
      " bli me  _n el0wb\n",
      "ybabrwcrhgaglordhyn\"\n",
      "batch 20075  loss=154.9205  steps/s=99.48  prediction: \" they secretly exercise and dont tell us\" => \"th   t ly see sse eeyeeexe ee  dd d sd  \"\n",
      "batch 20076  loss=178.9758  steps/s=100.42  prediction: \"sed\n",
      "Whatre you gonna run on it this time\" => \" bb  eneadt tet e eere  nr  u n   tn on \"\n",
      "batch 20077  loss=170.7051  steps/s=103.28  prediction: \"ces for speed and it makes the game wild\" => \"h ss yeiee n  ntlyfifdkpvpdhayfny.rp,pfk\"\n",
      "batch 20079  loss=173.6012  steps/s=99.40  prediction: \"rflowsucks and never went on there again\" => \"eai    a  r krwtQdshgucflymyldywrmwmuyfv\"\n",
      "batch 20080  loss=163.8407  steps/s=103.29  prediction: \" the most important parts of improvement\" => \"to  te  eet      tootto t o  ot ppprp om\"\n",
      "batch 20081  loss=171.7681  steps/s=89.73  prediction: \"concept, yes\n",
      "\n",
      "2/3 depends on the concept\" => \"kmes We c   e Qvb,/2232/3/3,2/3e2\n",
      "3//,vc\"\n",
      "batch 20082  loss=162.4362  steps/s=93.89  prediction: \"ow is that i know nothing\n",
      "- some guy idk\" => \"  t st el tl    l i  inon i nnot n  - e \"\n",
      "batch 20083  loss=173.0441  steps/s=96.37  prediction: \"sy and they put bugs in the concrete lol\" => \" bil  baeny a en ey an   bu  t s  nn  ct\"\n",
      "batch 20084  loss=169.1852  steps/s=94.57  prediction: \"file editing program, will show vid soon\" => \" leiInen n edi ifglgkpug,\n",
      ",p,pwn,m,p,gwl\"\n",
      "batch 20085  loss=197.9519  steps/s=93.47  prediction: \"its a good time\n",
      "\n",
      "https://t.co/2Np3fEHzbx\" => \"n      nn    o o toti i s   ///t\n",
      " /tNNN/\"\n",
      "batch 20086  loss=183.2965  steps/s=108.16  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"reexx nx ff    iox og o\n",
      "\n",
      "\n",
      "\n",
      "t ss//s//WW11\"\n",
      "batch 20087  loss=174.1363  steps/s=106.32  prediction: \"d agree probably\n",
      "\n",
      "or diagramming even...\" => \" tn o  t ag e   a lgala \n",
      "a ror\n",
      "grad\n",
      "\n",
      "g a\"\n",
      "batch 20089  loss=169.5207  steps/s=102.06  prediction: \"i wonder what the 3rd+ order effects are\" => \"nwB     d oi eo d wh war rr++ +d  ee e r\"\n",
      "batch 20090  loss=172.3458  steps/s=109.11  prediction: \"round PNGs in powerpoint xDDDDDDDDDDDDDD\" => \"ebl nt nu s l odGPNGpkplwpkx\n",
      "kgDDDDDPNGP\"\n",
      "batch 20091  loss=181.9953  steps/s=108.20  prediction: \" filter out slop https://t.co/RA1wtAYLES\" => \"ton ff t faiftrofs  uil s oltp  /tp/stAo\"\n",
      "batch 20093  loss=188.7151  steps/s=118.92  prediction: \"Some Tal games are real art masterpieces\" => \"TmERf f iptilmTt et prl s pstere/tt rtap\"\n",
      "batch 20094  loss=181.1931  steps/s=109.95  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e e   \n",
      " ey???\n",
      "trL1L?bLka=&==&?;;&&^;;;^^\"\n",
      "batch 20095  loss=174.1601  steps/s=105.51  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \" s\n",
      "ieseie e s se sesee e ie i       i   \"\n",
      "batch 20096  loss=187.1960  steps/s=106.44  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl e /  .nBldadk1,1,010xu1cuxu\n",
      "FaF\n",
      "F.nF\"\n",
      "batch 20097  loss=171.3807  steps/s=110.04  prediction: \" ai chatbot hole https://t.co/joMEd7z8Fj\" => \"t a  ite  o  t ttahahe h tt eo  /ct  oMM\"\n",
      "batch 20098  loss=183.2313  steps/s=92.95  prediction: \"neMTB @justalexoki the rise of carmacine\" => \"g  eiai cubM@M sj@j?bGbx:x:k.c.bj/MEM7z8\"\n",
      "batch 20099  loss=182.0070  steps/s=109.09  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"to   We en e  I    r nl    l  al  lal   \"\n",
      "batch 20100  loss=172.9070  steps/s=109.51  prediction: \" about it and in 1 weekend jumped up 200\" => \"t a s a  ad  ttaa ii  t   t ee  e  ei ed\"\n",
      "batch 20101  loss=169.5110  steps/s=109.42  prediction: \"stion, why do they cluster where they do\" => \"   r  ouo to  o ytoey ty y   te e   ret \"\n",
      "batch 20102  loss=175.7289  steps/s=99.59  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e  e:th   na   s@221bm,21u212rdc,ep\n",
      "pt,,\"\n",
      "batch 20103  loss=175.1788  steps/s=98.14  prediction: \"erIntellectus the italians have returned\" => \"   lrttalh eIee  leet sseo  h ae s sae a\"\n",
      "batch 20104  loss=178.3025  steps/s=102.44  prediction: \"grammer extra respectfully:\n",
      "\n",
      "skill issue\" => \" erhcg  rwerme r rterreeera rltresestlul\"\n",
      "batch 20105  loss=178.2079  steps/s=108.66  prediction: \"uch working tomorrow, key is consistency\" => \"nh  ou  to  ooom oor t o t trkko  ri k  \"\n",
      "batch 20106  loss=228.9542  steps/s=80.89  prediction: \"OT MOVEMENT LADS https://t.co/NxHblUdYfq\" => \"r g ME Oti Moro  orr DDS k wc  o  cs  eH\"\n",
      "batch 20107  loss=181.6194  steps/s=98.44  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"@un o e  e loweowe fo eole  oh  oo so  t\"\n",
      "batch 20108  loss=176.5415  steps/s=93.32  prediction: \"ai car tire\n",
      "\n",
      "may not get smart money tho\" => \"n on \n",
      "a rctat t e\n",
      "\n",
      "\n",
      "\n",
      "iai ao ean amaa t n\"\n",
      "batch 20109  loss=172.3526  steps/s=101.41  prediction: \"Logit transform: https://t.co/MtjBY3y5n5\" => \" klo n  te osge p?.cn:gl:.L.gLs\n",
      "p///M35B\"\n",
      "batch 20110  loss=168.7273  steps/s=94.31  prediction: \" ive had programming in a long long time\" => \"ts  m s me e  ne h   m  m  nn oma ggngn \"\n",
      "batch 20111  loss=168.7280  steps/s=104.01  prediction: \"n getting rid of the phone really is key\" => \"gao  iniyp et n \n",
      "bzbbz4zrgdzhz\n",
      "ybyh\n",
      "ybyy\"\n",
      "batch 20112  loss=183.1319  steps/s=104.95  prediction: \"xt song auto plays\n",
      "&gt; its gingle bells\" => \"  jio ofnt g t nn go t   on ssgg  otg s \"\n",
      "batch 20113  loss=165.8933  steps/s=106.96  prediction: \"r coding lol. And some chess. Great move\" => \"el  tmien tmiie z.IAfiAuA\n",
      "bvi.AApdtGAmGb\"\n",
      "batch 20114  loss=177.3527  steps/s=97.89  prediction: \"orkin on it boss https://t.co/QJydrZyW9y\" => \"  o ri  nn  i   i in oo  etso s /scQ/QQQ\"\n",
      "batch 20116  loss=168.5279  steps/s=106.34  prediction: \"he case for some regions outside the US.\" => \"e   t  te  e e e s se i re  ss  s eo ee \"\n",
      "batch 20117  loss=172.9234  steps/s=96.60  prediction: \"good idea but whatever, i wanna have fun\" => \" r    o nf f ioout idet ete eta  a a en \"\n",
      "batch 20118  loss=174.0595  steps/s=105.85  prediction: \"100x bigger than the others\n",
      "\n",
      "I dunno lol\" => \" 1h0n n  lea  n 110x1bb1gbxmbwbIkrcnxIhc\"\n",
      "batch 20119  loss=170.4543  steps/s=93.65  prediction: \"han automating friction out of your work\" => \"et to  nenen  baetnn trtntnn eo totttno \"\n",
      "batch 20120  loss=170.2676  steps/s=60.49  prediction: \"@vorpal_strikes Does it replicate tho???\" => \"yewatxe e in   retin tfeitin uo aoto nor\"\n",
      "batch 20121  loss=175.1580  steps/s=113.72  prediction: \"ly know how many angels fit on a pinhead\" => \"y: It eten l w oww  onw aalw nyw t on a \"\n",
      "batch 20122  loss=169.2954  steps/s=103.47  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \" l  tte  reilh  kdcwuhauykmpx\n",
      "xgxfypxmxh\"\n",
      "batch 20123  loss=186.6967  steps/s=106.19  prediction: \" industries, etc\n",
      "https://t.co/I216QEL6uq\" => \"@n iihhssn  , h nt,tss,stt/httteth/:6c6/\"\n",
      "batch 20125  loss=169.1893  steps/s=106.40  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"taa  en e  olroc po \n",
      "oa  llyer p eye are\"\n",
      "batch 20126  loss=172.8848  steps/s=93.87  prediction: \"ying/whatever, every monday and thursday\" => \":ng/ioodinegng/ngningnrinryyrd yvnyaydyy\"\n",
      "batch 20127  loss=178.5519  steps/s=84.55  prediction: \"ctus infobalking https://t.co/B3UT9nTonq\" => \"h piegtstas f  ow6u,ly,c,f:by:.:b.BB3B3B\"\n",
      "batch 20128  loss=178.6053  steps/s=104.54  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"tac  alaassomme laip mmstan  otstt//4/4N\"\n",
      "batch 20129  loss=185.7769  steps/s=64.24  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"ypes   a% ssAm  papppppst/: //t444//NNGN\"\n",
      "batch 20130  loss=225.4477  steps/s=104.30  prediction: \"OT MOVEMENT LADS https://t.co/NxHblUdYfq\" => \"T H\n",
      "Ti%AOA MOVi pNpppppp//:LLL:/uHNHHNrH\"\n",
      "batch 20131  loss=168.5407  steps/s=101.62  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"u e   trnoton e oo  n et yt ttet ytt t e\"\n",
      "batch 20132  loss=170.4637  steps/s=93.51  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \"irl @ aleai e e xexxc?l:cm:k:yVMVxMVMV05\"\n",
      "batch 20133  loss=181.2107  steps/s=104.65  prediction: \"owed em all\n",
      "How tf do you find these ppl\" => \"n a @o ldaelo et HowHolwHHH ww dl d  d  \"\n",
      "batch 20134  loss=166.6089  steps/s=97.18  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"eno  utel aooY  YoY Yoou tn ot dlee tpl \"\n",
      "batch 20135  loss=176.3404  steps/s=92.15  prediction: \" know any easy way to work with cuda btw\" => \"@io  tnn yn   y a y y ow w wo   y wa w w\"\n",
      "batch 20137  loss=164.4090  steps/s=91.86  prediction: \"works for the first time is the most fun\" => \"irl a en ci to knhgichfd#pdrngmgpwmdkwmf\"\n",
      "batch 20138  loss=163.9541  steps/s=90.82  prediction: \"ve you an electronic high five\n",
      "\n",
      "quine rt\" => \"eriilnwl a  e e e iln ien i  iie  ii e h\"\n",
      "batch 20139  loss=171.5932  steps/s=34.12  prediction: \"ly: @larpertony @kuberdenis my elo is 10\" => \"y  @  n     e elo ien ii  i  iii  in e i\"\n",
      "batch 20140  loss=181.0304  steps/s=114.43  prediction: \"mobly @amix011 May do this in the future\" => \"eno  t@tin t  t @v@kM0vMdMvulymyfcnrog10\"\n",
      "batch 20142  loss=166.4732  steps/s=90.52  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" n nznhano r  so0yg0xrv::/:d.c.hfcIKKXKc\"\n",
      "batch 20143  loss=173.1064  steps/s=92.76  prediction: \"essing\n",
      "You help cure that if you do this\" => \"  e e ietrn   stesseYse s hn e  eu  eo t\"\n",
      "batch 20144  loss=180.5285  steps/s=102.46  prediction: \"18/hr\n",
      "\n",
      "cons\n",
      "- none\n",
      "- i only know scratch\" => \"00 t d eag t 8 t18/8/81y/y/yppy-thyeyhk/\"\n",
      "batch 20145  loss=180.6200  steps/s=94.54  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"u    h  y ,,,  l'   t  h heoh o   ohnho \"\n",
      "batch 20146  loss=187.2954  steps/s=85.46  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \"hnl    n   g a txudpgxwxyxlxxpxcgnfyxwgu\"\n",
      "batch 20148  loss=170.4050  steps/s=94.52  prediction: \"i have a few libraries in there sadly :9\" => \"nco   sti  ea  aww ww aw e ie  i rree  i\"\n",
      "batch 20149  loss=165.5155  steps/s=92.38  prediction: \"uff and just pretending to do side stuff\" => \" f f  o0 n in  taft  duf   u t ddedg n n\"\n",
      "batch 20151  loss=170.3913  steps/s=96.93  prediction: \"e the last clip\n",
      "\n",
      "https://t.co/CPSXwfs38G\" => \" toi nts hm  a \n",
      "aettiet ht hte/e\n",
      "/\n",
      " S\n",
      "SS\"\n",
      "batch 20152  loss=163.8399  steps/s=91.66  prediction: \"aluable to do\n",
      "after talking for like 40â€¦\" => \"tl   a  evlalll ll  le  aata  t  lal    \"\n",
      "batch 20153  loss=166.7211  steps/s=90.45  prediction: \"et good at the ones youre not so good at\" => \" tanem anaaet tnt  t etotoo e  oo e  ooe\"\n",
      "batch 20154  loss=168.0198  steps/s=91.80  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"am hh ans n e e EfHEHv(Ew(wEv(y(H(y()(s)\"\n",
      "batch 20155  loss=187.8723  steps/s=100.53  prediction: \"/t.co/zlto3SBYwd https://t.co/d6c2IkZxcz\" => \"/..Cttst ut:::i/z///3B33BBBYtYYt./ot.t//\"\n",
      "batch 20156  loss=176.9582  steps/s=103.86  prediction: \"was making me sleep deprived unknowingly\" => \"is   eeIi zwoi edkzEzwkkzndkzrgvl:gwvkdp\"\n",
      "batch 20157  loss=174.6465  steps/s=98.45  prediction: \"a, good reference\n",
      "Its a tough one so far\" => \"l   h i hs   g  e eeee eee r Ie   neeo e\"\n",
      "batch 20158  loss=172.2474  steps/s=106.11  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"ial   tle  e,    .  e .e . ... .h.t / t/\"\n",
      "batch 20159  loss=171.3160  steps/s=105.31  prediction: \"worst part, as demonstrated by the graph\" => \"hrk  hec h owsp uncw,J,\n",
      "wd:df,rw.J,/:p,:\"\n",
      "batch 20160  loss=172.4982  steps/s=100.50  prediction: \"houlda stuck to planting apple trees smh\" => \"euli sba rt  ttd dslsutottta aa pl n aep\"\n",
      "batch 20161  loss=168.6537  steps/s=93.00  prediction: \"builds 2012 but yet blunders mate in one\" => \"ei o  bass 222ol22 t  tnt pln t tle ss e\"\n",
      "batch 20162  loss=172.7211  steps/s=101.28  prediction: \"e soda\n",
      "\n",
      "actually nvm this one tastes meh\" => \" ioeeyte het o ee\n",
      "ey   e \n",
      "\n",
      " tl tlis  tem\"\n",
      "batch 20163  loss=168.9471  steps/s=100.03  prediction: \"never I see that in mc, programming, etc\" => \"  a  t t  se wtakdtkygIds#^h#wðŸ›‘á´„kc,IpvI*\"\n",
      "batch 20164  loss=185.0317  steps/s=79.03  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \"nl levne Ie  ee  eet t   t  r  mr gm  mF\"\n",
      "batch 20165  loss=175.1948  steps/s=99.96  prediction: \"an esopost to english translator service\" => \"nd    a   we es e  t nt tn toeo tnst  is\"\n",
      "batch 20166  loss=173.7210  steps/s=95.88  prediction: \"MTB a dollar flowing through the economy\" => \"TB h aenoe BBTe l le i rtn trrogso th ec\"\n",
      "batch 20167  loss=179.5526  steps/s=105.75  prediction: \"ing interviewer. https://t.co/wWOnnFvDyA\" => \"ng  t   iidne  e er t rntr. it e.//.O/On\"\n",
      "batch 20168  loss=186.3715  steps/s=96.13  prediction: \"/t.co/8gCd6cnXXP https://t.co/IQEJLWxuF5\" => \"/..Io     ott\n",
      "h//8/C6686XPPcPXXP::/ttct/\"\n",
      "batch 20169  loss=189.8891  steps/s=21.10  prediction: \"eply: @kayzee_ow https://t.co/y0ck4lbyrK\" => \" ly: @I   ott\n",
      "t /8/C66/6XPPcPXPP::/ttQt/\"\n",
      "batch 20170  loss=183.3005  steps/s=145.36  prediction: \"wphones @netcapgirl @yacineMTB kiki take\" => \"ohte .tkted6cn eP@PPPpP:@h:@s@/0QE4LMxLK\"\n",
      "batch 20171  loss=180.5799  steps/s=106.77  prediction: \"gonna humble him\n",
      "https://t.co/HUMAzXB4rm\" => \" o  hoasdo nd n htmh i htmmhhthsht/UtUUU\"\n",
      "batch 20172  loss=170.5618  steps/s=97.23  prediction: \"ely one-shot by breakfast (i was hungry)\" => \" s tg n  oi g  n  on tt o  bo bst t s( s\"\n",
      "batch 20173  loss=167.2890  steps/s=19.86  prediction: \"eply: @timeiskey https://t.co/gqHUofFeYv\" => \" ly: @ionoi i     ob tt b  b  a t ( s( s\"\n",
      "batch 20174  loss=167.1813  steps/s=101.72  prediction: \"lace\n",
      "\n",
      "im curious how you structure yours\" => \"yc  don do  a  i  c coiuiou u uu uoouruu\"\n",
      "batch 20175  loss=181.2323  steps/s=91.72  prediction: \"ge&gt;\n",
      "\n",
      "works for text only LLMs too btw\" => \" tnesgci ntn eaggtrgto\n",
      "\n",
      "ioreor eLttsxto \"\n",
      "batch 20176  loss=175.6472  steps/s=91.37  prediction: \"ntellectus little italy?? nah. big italy\" => \" hlt c; t gIew e&wk;kxksgxsx\n",
      "xaMfkrM?Mbl\"\n",
      "batch 20177  loss=169.6734  steps/s=105.75  prediction: \"engthen the habit over reps\n",
      "Cool thought\" => \"  ioerti ethene hre thethrnet reeo eo ot\"\n",
      "batch 20178  loss=172.8235  steps/s=70.47  prediction: \"@nlevnet that's a great thought actually\" => \"soeethee e re   hsi thetho en reCo eolot\"\n",
      "batch 20179  loss=172.2255  steps/s=84.07  prediction: \"aulg We like memoizing physical patterns\" => \"nroeleee t ttethese gieeio tg r co lplot\"\n",
      "batch 20180  loss=171.4754  steps/s=87.84  prediction: \"@skooookum i forget but its at least 100\" => \"steltete egttem e i ziezioitg racclatl ðŸ›‘\"\n",
      "batch 20181  loss=168.3606  steps/s=110.86  prediction: \"to someone on X, its laggy when it plays\" => \"h  ener stmioet ,..X,dc.wX,oX,X,nbXX,lX,\"\n",
      "batch 20182  loss=170.6266  steps/s=96.44  prediction: \"ing responses seems like a better metric\" => \"ntsoeeetn\n",
      "e  s inooeess es e  iee s e ee\"\n",
      "batch 20183  loss=172.6246  steps/s=89.83  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"@h  e dhsetsin ns ne tii\n",
      "i t pioipi pess\"\n",
      "batch 20184  loss=168.4415  steps/s=94.12  prediction: \"ard to realize. lies are really blinding\" => \"ld  e r tlo o  ra r  . iee eare re l  e \"\n",
      "batch 20185  loss=165.9651  steps/s=91.36  prediction: \"st powerful learning techniques there is\" => \"  n t   et t one  o f er   oee ne t qene\"\n",
      "batch 20186  loss=180.6043  steps/s=102.68  prediction: \"ng bro we only got 10yrs to start nvidia\" => \"  o3 st rbbcowhehghgua0101gwgy1010b1n101\"\n",
      "batch 20187  loss=180.3528  steps/s=78.30  prediction: \"uine Good taste is a very powerful thing\" => \"nldnr  rhthq G  GGto0nt stnoswes snv ns \"\n",
      "batch 20188  loss=183.3466  steps/s=98.73  prediction: \"an that sounds like such a relaxing time\" => \"ld   ro e tt tmenet a aroeooswer lthing \"\n",
      "batch 20189  loss=176.6508  steps/s=106.28  prediction: \" God for helping us both out\n",
      "it was hell\" => \"@orlle  lel oo   e  r h on  o    t ho th\"\n",
      "batch 20190  loss=165.5018  steps/s=105.73  prediction: \"on mars we will make this a top priority\" => \"n t    w  n oh wwo  wls  me s oe e l  o \"\n",
      "batch 20191  loss=211.8691  steps/s=98.76  prediction: \"H LETS GOOOOO\n",
      "truly a masterpiece lmaooo\" => \"Swve  t le LETe ETSETSEGSTGyG\n",
      "cO\n",
      "Oyukuka\"\n",
      "batch 20192  loss=159.2129  steps/s=106.47  prediction: \"and run it in the front end of a browser\" => \"nt  dd    t   e      e      n  t nn t t \"\n",
      "batch 20193  loss=173.1009  steps/s=91.86  prediction: \"pression contest\n",
      "https://t.co/bLEHGWjFSr\" => \"lo    comompio  umI\n",
      "pw:y:\n",
      "mpr:g:E::/::/E\"\n",
      "batch 20194  loss=165.3673  steps/s=96.59  prediction: \" long run in weird ways you dont realize\" => \"tona w l l   inn   nn n        y   y  o \"\n",
      "batch 20196  loss=167.5573  steps/s=100.35  prediction: \"s of thought, and your ability to thinkâ€¦\" => \" ee pe aahe  en   t  hou   t  hui o i io\"\n",
      "batch 20198  loss=185.6387  steps/s=29.82  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @t    rtins df,p,AYUpc,pg,d,bduypybâ€¦\"\n",
      "batch 20199  loss=172.9116  steps/s=100.38  prediction: \"good idea but whatever, i wanna have fun\" => \" od t   sfid ioout idet ete eta  a a nn \"\n",
      "batch 20200  loss=163.6841  steps/s=102.49  prediction: \"ad a concept of \"I\" they would probablyâ€¦\" => \"no  c ts ntet at o  \" \" \"I \" t    o  o  \"\n",
      "batch 20201  loss=167.1238  steps/s=99.67  prediction: \"s it and im unaware (would love to know)\" => \" iou t ans s  n  ii  ia u ( (u ulo al  w\"\n",
      "batch 20202  loss=171.6138  steps/s=92.59  prediction: \"ncredibly painful, so a great motivator.\" => \" e otn   ihb.sinblyfmbruf,...vk.pthd.b.f\"\n",
      "batch 20203  loss=166.4455  steps/s=90.71  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  o  tte    m stm y  s y  e t i    t t e\"\n",
      "batch 20204  loss=166.9173  steps/s=91.91  prediction: \"ntiers out there we dont even know about\" => \"   B  gmtew sl sywbybkfr.v.blgharuywvkdo\"\n",
      "batch 20205  loss=167.5619  steps/s=92.31  prediction: \" then maybe do a bit of chess, or watchâ€¦\" => \"to   teg e    b e  b b    b   e         \"\n",
      "batch 20206  loss=184.8186  steps/s=104.65  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tud)ii doe  aj  ds fs  fad Tsi su  a  nu\"\n",
      "batch 20207  loss=175.0753  steps/s=101.06  prediction: \"gonna code to one song and one song only\" => \" t    sn nw   oo e  o ao   ons no nn   n\"\n",
      "batch 20208  loss=198.7301  steps/s=11.62  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"eply: @ter ci'a 9'w9'9p'\n",
      "ffb,UmuycuTpbtb\"\n",
      "batch 20209  loss=181.4382  steps/s=156.63  prediction: \"owTiedFox 16hrs every day is crazy,  wow\" => \"n  no  n d     n e6 o aon  on  ns n    n\"\n",
      "batch 20210  loss=170.8429  steps/s=109.27  prediction: \" did not answer. he just kept on yapping\" => \"@ap patamn t t   a taa tt  e t st te n p\"\n",
      "batch 20211  loss=169.2146  steps/s=98.99  prediction: \"hings way easier\n",
      "https://t.co/SoZ8VeXTFk\" => \"engyeranim tnt   it iataea is:ti:::tttVZ\"\n",
      "batch 20213  loss=188.0066  steps/s=102.82  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "be d eit  w Itw6ðŸ«¡goIy:I\n",
      "I/si/S/SS.rodF5\"\n",
      "batch 20214  loss=168.6797  steps/s=99.61  prediction: \"write higher quality papers ~10x fasterâ€¦\" => \"his  Iecae u etnqsucIwIgqImcquq~q0qw/hp~\"\n",
      "batch 20215  loss=174.8191  steps/s=97.40  prediction: \"e or desire to practice for other things\" => \" aoop ret er eo  eicr  t ortcceitc io  r\"\n",
      "batch 20216  loss=167.4944  steps/s=103.03  prediction: \"the (fake) claim about compromising info\" => \" e  bod   s  (nhk()bck))w),)(g(kb)p)k,)m\"\n",
      "batch 20217  loss=162.5828  steps/s=101.68  prediction: \"y is nothing like early morning sunlight\" => \":pa e nehrn  en la iie il  ln nl nini ei\"\n",
      "batch 20218  loss=173.6176  steps/s=99.34  prediction: \"st? I believe Jesus gave us the playbook\" => \"t    m m  ti  ? e  iJi JJ se ue ee ee e \"\n",
      "batch 20219  loss=166.9924  steps/s=96.29  prediction: \"de you hate work\n",
      "https://t.co/2jmiAqT1C6\" => \" cini tin  ae  e toa o tt /t//  / t/ tAA\"\n",
      "batch 20220  loss=184.1429  steps/s=96.00  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "onneae  n ess ee\n",
      " \n",
      "\n",
      "eeseea esaes eeshs\"\n",
      "batch 20221  loss=172.3819  steps/s=105.63  prediction: \" learning how things work under the hood\" => \"tonnn n eaor  h  r rrne s n    h s wrw r\"\n",
      "batch 20222  loss=172.7395  steps/s=99.50  prediction: \" funny i like it https://t.co/gxpcMrRiHL\" => \"tunf  snned   dikee e  t enn     it i/ i\"\n",
      "batch 20223  loss=176.1703  steps/s=106.39  prediction: \"entives\n",
      "example:\n",
      "https://t.co/emVy7xnag2\" => \"  bcnte cincem  tecemte ps:exttpe\n",
      ":/e77x\"\n",
      "batch 20224  loss=173.7022  steps/s=98.17  prediction: \"s message is NOT approved by square gang\" => \" on   tetbs  aes sOOOO ppTN  pmpsvpseyey\"\n",
      "batch 20225  loss=173.0546  steps/s=106.72  prediction: \"freedom fighters. ppl who wanted freedom\" => \" oo tnaier ) f  )mg)2.rg.)2.2fv2)w.ri.s.\"\n",
      "batch 20226  loss=170.8817  steps/s=97.37  prediction: \"builds 2012 but yet blunders mate in one\" => \"et eeebo   2222s22 2p e t h a n e   rere\"\n",
      "batch 20227  loss=183.3466  steps/s=11.20  prediction: \"reply: @gizmobly https://t.co/dgCgB3AN81\" => \"eply: @ner_e_f  01201.1g.tf.b.ub[b.dyosg\"\n",
      "batch 20228  loss=172.0751  steps/s=118.12  prediction: \"e tbh\n",
      "My projects arent that big yet tho\" => \" ieecieene  pnh   Mc cectereett   t t   \"\n",
      "batch 20229  loss=178.2249  steps/s=102.73  prediction: \"t in a position to help you at all loool\" => \" a  ela l   ny n\n",
      "baacnpnyt\n",
      "ith\n",
      "hpboghyuh\"\n",
      "batch 20230  loss=175.9365  steps/s=105.06  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"ndt t  r ear rnna tert atp a a teato/tnR\"\n",
      "batch 20231  loss=172.6224  steps/s=105.05  prediction: \"he goated advice https://t.co/gZx1K1OtSg\" => \"a th th  tn  te eat a   ta he /tt eg/t/K\"\n",
      "batch 20232  loss=180.8220  steps/s=99.10  prediction: \"is i need to make golden gate tetris bot\" => \"n c   n ate to  e h td dt t to/te tO1S1 \"\n",
      "batch 20233  loss=171.1011  steps/s=102.23  prediction: \"coder trust me bro im high iq, see above\" => \"om tsJiod    ec ji@jcjpvkckduiglsbqtriq,\"\n",
      "batch 20234  loss=176.0246  steps/s=100.95  prediction: \"nces contains homotopies (find them idk)\" => \" e saat  ttl aen\n",
      "+fbaof\n",
      "xW\n",
      "sx(l[xaxp%blc\"\n",
      "batch 20235  loss=173.0005  steps/s=103.16  prediction: \"ective, its significantly more efficient\" => \" te ct aloee i i eisis i i niiittiti  ef\"\n",
      "batch 20236  loss=174.8630  steps/s=102.69  prediction: \"m scratch in numpy like i did w backprop\" => \"ete  no eib lome,flhmertb,vcu,bbhlbf\n",
      "tor\"\n",
      "batch 20237  loss=177.3309  steps/s=93.33  prediction: \"or.. umm.. uh.. hold on give me a second\" => \"  ahts oo...........u..uh h. h  e       \"\n",
      "batch 20238  loss=184.2867  steps/s=89.59  prediction: \"ne was right the rates arent high enough\" => \"  pt aietaeit  nykwygsa..gvcso.tfrurulf.\"\n",
      "batch 20239  loss=166.5714  steps/s=93.15  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"  ehent n nt een nee en  ennonnentnon so\"\n",
      "batch 20240  loss=177.3208  steps/s=85.00  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \" een nnu  o  go  non ostro s/ttco:/PPPUU\"\n",
      "batch 20241  loss=211.3421  steps/s=12.50  prediction: \"reply: @cachecrab ah, the french defense\" => \"e gy: @ en oe  rcucct,bo:gswus::p,:cUN/P\"\n",
      "batch 20243  loss=176.1856  steps/s=99.79  prediction: \"is fine and expected, giving up is death\" => \"n  \n",
      "a  ofeeer aiiseetnia i  e ae upipege\"\n",
      "batch 20244  loss=174.9332  steps/s=90.74  prediction: \" this\n",
      "\n",
      "filing divorce papers as we speak\" => \"th  e thsetsin ns te ei\n",
      "\n",
      "ipiepteipd pess\"\n",
      "batch 20246  loss=168.7577  steps/s=82.53  prediction: \"mirages keep getting crazier and crazier\" => \"ene an o r t  n vvokfkphdlvdfazzcwnzuzwc\"\n",
      "batch 20247  loss=176.1509  steps/s=99.08  prediction: \"no work on my part? ok lol thanks @sama\"\" => \"gtr e  sten oe wgmki?v?h?gk?0??myaly@p@?\"\n",
      "batch 20248  loss=167.1161  steps/s=101.73  prediction: \"ndustries\n",
      "Currently building semi public\" => \"g rotos i  n u dCmk?mCCgCggk?ef\n",
      "y\n",
      "Cf\n",
      "fdðŸ›‘\"\n",
      "batch 20249  loss=166.5735  steps/s=105.89  prediction: \"ill consider leaning into it more though\" => \"nd n  b t d w  di lill nlnii n ni    ono\"\n",
      "batch 20250  loss=174.6803  steps/s=93.76  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"r  it..in till  li ltttis s iut lu utof \"\n",
      "batch 20251  loss=169.4936  steps/s=99.92  prediction: \"y do what sounds more interesting to you\" => \" th oool bob   o   ooo sd  s  s st s  to\"\n",
      "batch 20252  loss=171.9885  steps/s=90.08  prediction: \"almost as bad as jan blocking his bishop\" => \"nl  lt whta  ss as   a aa bsas b n   b o\"\n",
      "batch 20253  loss=169.1911  steps/s=75.09  prediction: \"_software its c to wasm using emscripten\" => \"i _l  na af  aa as  st  o taai i g sisi \"\n",
      "batch 20254  loss=177.8001  steps/s=101.41  prediction: \"h @tsoding Musializer looked pretty cool\" => \"eaooifsn  nsassn s  ats ioii i lerirorpp\"\n",
      "batch 20255  loss=170.6119  steps/s=91.06  prediction: \"minds me of that old gpt engineer script\" => \"ane ine tm pfRd u,pfpmN'pp,eNNg\n",
      "klmfg,f,\"\n",
      "batch 20256  loss=182.3059  steps/s=101.19  prediction: \" but also, probably, very poorly sampled\" => \"tut enteu loeloldplob ollolo,,poralyoly \"\n",
      "batch 20257  loss=170.8344  steps/s=90.20  prediction: \" to me except this feels 100x better fug\" => \"thet  tsn n te  e  stee tht stex0xe0000 \"\n",
      "batch 20258  loss=167.5939  steps/s=90.12  prediction: \"e drew your whole country as the soyjack\" => \" th r io vr  ow  erwe or o e  oee   oyt \"\n",
      "batch 20259  loss=180.9462  steps/s=92.77  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee   k n  ne eangâ€¦ en tt /t//t //BBB/\"\n",
      "batch 20260  loss=177.8852  steps/s=100.44  prediction: \"many roadblocks trying to automate stuff\" => \"ak sie neo mbh tIIhIimypk\n",
      "flachnkmkybfbk\"\n",
      "batch 20261  loss=190.7302  steps/s=106.45  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tte   de dd e #ee  es hPttst  t/ts //SSh\"\n",
      "batch 20262  loss=186.7301  steps/s=101.39  prediction: \"is not true loss https://t.co/VvtOa0Aau2\" => \"n     te ttset eress osss sots////VsVVVt\"\n",
      "batch 20263  loss=172.2827  steps/s=106.32  prediction: \"ge a window's file\n",
      "\n",
      "i never use ! really\" => \" th    t non eoaia a ew n  ia ww  i ie !\"\n",
      "batch 20264  loss=161.5975  steps/s=107.13  prediction: \"endeavors im going to do til ive done it\" => \" ti    euts  ttn oaeoto  oo  g i iv itd \"\n",
      "batch 20265  loss=164.8861  steps/s=45.20  prediction: \"y: @_diginova i served my time in x jail\" => \"  @ya nes s  tt  oago o  oi  i i in idd \"\n",
      "batch 20266  loss=178.2443  steps/s=112.14  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"nd t  t tigowr hcospcctcphrp s  p/crs /t\"\n",
      "batch 20267  loss=179.8305  steps/s=84.15  prediction: \"wphones Love the plan, sounds meaningful\" => \"aht  a oihi  aiewLhiksyw:k.:,/B.BMTMTsDO\"\n",
      "batch 20268  loss=168.6819  steps/s=104.94  prediction: \"ncredibly painful, so a great motivator.\" => \"ge otnc  ie la nblyfwbruf,.,.:h.,ahd.,.,\"\n",
      "batch 20269  loss=177.5655  steps/s=95.51  prediction: \" from scratch, and a bit of transformers\" => \"ton  a o re   rcan mr cccr ac aoa f rfof\"\n",
      "batch 20270  loss=166.3573  steps/s=105.11  prediction: \"eepfake the adobe CEO's face onto Yezhov\" => \" zuls  fee ee lte   ade e  ea aa  f at  \"\n",
      "batch 20272  loss=170.6040  steps/s=107.34  prediction: \"out efficiency of function approximation\" => \"ul  t  n t t afc it oficnfinnf fc on ppp\"\n",
      "batch 20273  loss=169.2766  steps/s=99.53  prediction: \"was intentional but it sounds super cool\" => \"ayt t e s te k thrg,lzbzszwrlmgdhabdblgk\"\n",
      "batch 20274  loss=167.7474  steps/s=112.73  prediction: \" least its not opengl like this poor kid\" => \"tik  atn  nt ttttit no sot it l otos i l\"\n",
      "batch 20275  loss=179.0069  steps/s=111.08  prediction: \"ded techniques too, lmk if you know more\" => \" rpeec einneddIet edde    et eoee o  ono\"\n",
      "batch 20276  loss=174.4216  steps/s=102.31  prediction: \"tor more visible https://t.co/v12Ak2lHUD\" => \"   l re lore  e uizzbo,,pmc/p::/:122.A12\"\n",
      "batch 20277  loss=163.5949  steps/s=102.43  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \" se ini ntt   nti t  t  n e nnt  elelte \"\n",
      "batch 20278  loss=160.5632  steps/s=76.92  prediction: \" miss the good old completion model days\" => \"ta  oi eito  hsoi t  t doee nnel elelfâ€¦ \"\n",
      "batch 20279  loss=231.3745  steps/s=105.45  prediction: \"TOR MVP COMPLETE https://t.co/JY5kclLIms\" => \"h d    s r od oPMPPEPMELEEEEtt ot/l//J55\"\n",
      "batch 20280  loss=180.6821  steps/s=94.50  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e n r \n",
      " t  r artkwBPvcAPvgbvarv/ltupouew\"\n",
      "batch 20281  loss=166.5581  steps/s=98.72  prediction: \" long time. Play a game or two a day idk\" => \"tea  a n   l an   l a l  aala  a  a o o \"\n",
      "batch 20282  loss=179.1236  steps/s=110.89  prediction: \"verfit test btw) https://t.co/qErYnoBOJi\" => \"erybo t b   t\n",
      "o or t  t t st tt tttttt/t\"\n",
      "batch 20283  loss=162.4395  steps/s=115.35  prediction: \"learning is by doing stuff. For anything\" => \"ya hhngen   snb n  i    i   ngnin FF  Ff\"\n",
      "batch 20284  loss=182.9402  steps/s=104.75  prediction: \"tellectus cause hes got that TAUG in him\" => \" r  then eh ea bcpcmupgmhbukT.buAU.UGUGU\"\n",
      "batch 20286  loss=165.4307  steps/s=96.58  prediction: \"to work on things that make sense to you\" => \"   oa ousdaoi   v[uâ€œg*vQZ|w]vkluwywvv`wv\"\n",
      "batch 20287  loss=172.2464  steps/s=113.36  prediction: \"potential. then one day, it all explodes\" => \"lsn  ntne i  u afpk)\n",
      "wp.dp.,pi.,.l.xw,cy\"\n",
      "batch 20288  loss=170.5130  steps/s=98.52  prediction: \" sensors lol thats much less complicated\" => \"toa asu nsrusoon stos  lhs llss luot  lc\"\n",
      "batch 20289  loss=164.1193  steps/s=113.47  prediction: \"the angle of ur screens after she leaves\" => \"hesto dhntdexio fpxcyxac2fgxwh.fRprgcyxd\"\n",
      "batch 20290  loss=168.1013  steps/s=104.75  prediction: \"he gamer would make for some great games\" => \"e re e   or  ra ofm  m e ro   fme fr aoe\"\n",
      "batch 20291  loss=170.5465  steps/s=23.66  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @d  or  oaroemr m e ro r fme frmare\"\n",
      "batch 20293  loss=168.5927  steps/s=110.93  prediction: \"cle, leading to more patterns to betterâ€¦\" => \"oeaein n c cleln,lm,,c,m,bpum,mr,sd)apad\"\n",
      "batch 20294  loss=172.7528  steps/s=103.57  prediction: \"nserve the good parts against decay/loss\" => \"g yo  ae  ctos dreacthc\n",
      "ovcdpvecv\n",
      "ldcpgs\"\n",
      "batch 20295  loss=175.5872  steps/s=108.72  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"tue   ne de d ;e o   ECICICICICIFdI  end\"\n",
      "batch 20296  loss=200.1017  steps/s=87.77  prediction: \"yon Super hyped to see what youre cookin\" => \" u nerp  yoepS r CFICI I Ie d dnndg  uâ€¦e\"\n",
      "batch 20297  loss=177.5502  steps/s=108.67  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"eke  niSqen  hthypinhalvp\n",
      "whvdlypusuerur\"\n",
      "batch 20298  loss=163.1237  steps/s=97.40  prediction: \" talking to more med school students lol\" => \"toeee t te     tte  e   o oo  o e tss o \"\n",
      "batch 20299  loss=167.1831  steps/s=108.66  prediction: \"e ive been thinking the exact same thing\" => \" taonie iei  e eee  e inonho t e etes s \"\n",
      "batch 20301  loss=169.4940  steps/s=107.21  prediction: \"s\n",
      "\n",
      "probably gets more views bc of it tho\" => \" \n",
      "we sos \n",
      "oyonaa y b\n",
      "ey  y  s obeos b be\"\n",
      "batch 20302  loss=168.3118  steps/s=98.67  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"  e  ot      otooo ar    oa  oos als sap\"\n",
      "batch 20303  loss=168.3129  steps/s=108.08  prediction: \"ingly, doable) youre in for a goood time\" => \"ng    aovrs d i rrrly  yr  y yo oo   ooo\"\n",
      "batch 20304  loss=164.9482  steps/s=97.82  prediction: \"iot index of 720\n",
      "https://t.co/9xKSI6Oj1y\" => \"n tn,  n pn at  t it  7 02 0o/ :  :/xt9t\"\n",
      "batch 20305  loss=184.0698  steps/s=103.93  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lrt  e  s  aoestAI\"\"AIr\n",
      "umomIIcs\n",
      "\"rp/dxh\"\n",
      "batch 20306  loss=171.3631  steps/s=111.07  prediction: \" approximate it better outcompete others\" => \"tnl anutem r ritri t r a itotet tpee e o\"\n",
      "batch 20307  loss=177.7064  steps/s=111.37  prediction: \"here for the funny symbols and recursion\" => \"erso er t ee tt e ht e ft  eoe hh te err\"\n",
      "batch 20308  loss=171.3188  steps/s=115.41  prediction: \" sum bros.. pivot, its worth it trust me\" => \"tum ceo    o  osu..oss.o . o r o ir ts i\"\n",
      "batch 20309  loss=172.4299  steps/s=114.99  prediction: \"forward, forever\n",
      "https://t.co/zlto3SBYwd\" => \" r ttt  w,n  be bbth^gbá´˜:gbfbgwvz*wbfSr\n",
      "\"\n",
      "batch 20310  loss=180.6391  steps/s=111.48  prediction: \"ly know how many angels fit on a pinhead\" => \"y: @ l wen w w oow  oew haow nyw t wo ao\"\n",
      "batch 20311  loss=173.3743  steps/s=46.18  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y: @    ne w wnnow  o w fanw nyl t in ao\"\n",
      "batch 20312  loss=185.4770  steps/s=104.22  prediction: \"ludwigABAP ty bro\n",
      "i need to post more fr\" => \"yt ina  d lg a oy y on@ afn  nktp nonlap\"\n",
      "batch 20313  loss=165.8064  steps/s=118.52  prediction: \" unsurvivable, when in fact, youd manage\" => \"tses eotogsen uis vevn vven  en ,nn, , u\"\n",
      "batch 20314  loss=182.9990  steps/s=89.39  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \" gehonle hn i le e inn hht,  ,/  na  a F\"\n",
      "batch 20315  loss=181.3058  steps/s=117.49  prediction: \" going straight there out of highschool)\" => \"tean eais n  ihng err t ttg h r  oee  oh\"\n",
      "batch 20317  loss=161.7639  steps/s=111.56  prediction: \"ht them the openscad to make the pulleys\" => \"etr in t ere ttt hthe  t t ee t et t   e\"\n",
      "batch 20318  loss=178.1987  steps/s=109.33  prediction: \"wesome looking pieces though, im jealous\" => \"a' B  ah n jB@liPj@AjbjAwgwrAwAwjlÊŸjpulp\"\n",
      "batch 20320  loss=175.4187  steps/s=115.87  prediction: \"mpactful on actual success for me though\" => \"euhf  n fmiaptetb3bsyg*virpvkÊœpgryobf*fv\"\n",
      "batch 20321  loss=167.0450  steps/s=116.55  prediction: \" think it applies to others that do this\" => \"th    inimin  dt t t it   p ito ttio t i\"\n",
      "batch 20322  loss=171.1382  steps/s=114.73  prediction: \"th `sudo service NetworkManager restart`\" => \"he  etetg tww hn``uuNwdwNvNMNwNMkMcMiMMc\"\n",
      "batch 20323  loss=195.2462  steps/s=111.32  prediction: \".03$ a day you can help a webdev in need\" => \" )ox sto0 j3itf0$$3$dwjw.y3jcj.r3wk.0bvy\"\n",
      "batch 20324  loss=194.6003  steps/s=59.63  prediction: \": @RajenJangam Thanks! Glad you liked it\" => \" @lxdr  0d$3stf03 3Tdwr!.!hGcsldkwlbkbvðŸ›‘\"\n",
      "batch 20325  loss=186.0039  steps/s=121.78  prediction: \"Grats!!! Always awesome to see successes\" => \"EeD     a3hGo   GkyTAGr!pAlAlpAdAwlwkbdðŸ›‘\"\n",
      "batch 20326  loss=172.0563  steps/s=118.65  prediction: \"gorithm just be you\n",
      "I enjoy your posting\" => \" o ti@tta s slst s  o ho jjje yey uyujee\"\n",
      "batch 20327  loss=166.1897  steps/s=112.09  prediction: \"he audiobook content is better than both\" => \"e g t nnhuuthtbouoooontot  t tb te t ntt\"\n",
      "batch 20328  loss=179.0400  steps/s=91.56  prediction: \"n Twitter\n",
      "\n",
      "I have a post where I demo it\" => \"gtha  a  o  YkdhwnITTIuTITb\n",
      "IIcrvvIfvkpc\"\n",
      "batch 20329  loss=165.1865  steps/s=114.33  prediction: \"this the more you will see it everywhere\" => \"he    e nenes  toukkkbbkwvblkÉªpcsw\n",
      "mwvyr\"\n",
      "batch 20330  loss=168.1320  steps/s=107.40  prediction: \"tart over again with a new hard problem?\" => \"hn  one  are o noumlybrvwbvlvsvcvwmhwrnðŸ›‘\"\n",
      "batch 20331  loss=170.3539  steps/s=97.89  prediction: \"d xD but maybe its trying to communicate\" => \" toyl l bebal bbbay   bb ty   t  t it  t\"\n",
      "batch 20332  loss=186.4969  steps/s=108.79  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \" es ytetonoeoepldcxDadlx,,b\n",
      "ddxxybphkxsD\"\n",
      "batch 20333  loss=189.1906  steps/s=106.17  prediction: \"wigABAP why a few years\n",
      "\n",
      "do it this week\" => \"htAn e @eeolieotAPBAPkPkAPAwewfayfbfb\n",
      "sl\"\n",
      "batch 20334  loss=172.3707  steps/s=102.89  prediction: \"al, one of the most cracked players ever\" => \"nl t o  n f  ea \n",
      " e e   oeo  oot    cec \"\n",
      "batch 20335  loss=172.2076  steps/s=103.21  prediction: \"rning gpu acceleration is super valuable\" => \"e  t le ntse i tcgmlufwafJfpdfdfufudndrg\"\n",
      "batch 20336  loss=176.5640  steps/s=81.96  prediction: \"you build cool stuff i follow\n",
      "\n",
      "simple as\" => \":urnnnn uiea cl rarel e af a eee s ia le\"\n",
      "batch 20337  loss=207.3424  steps/s=83.47  prediction: \" @___________11hz thanks\n",
      "fuck these guys\" => \"tsa i   u=b=+$!e aftl n afoo ese s ie lu\"\n",
      "batch 20338  loss=170.7942  steps/s=121.15  prediction: \"ns you get the yellow letters on lichess\" => \"  e nnte  s  is oguxuulahMgpkwdfwwywwmrw\"\n",
      "batch 20339  loss=173.3490  steps/s=106.01  prediction: \"es your data instead of storing the data\" => \"ps innei ne  t ea r r tnat en  ta   ot e\"\n",
      "batch 20341  loss=157.1046  steps/s=112.60  prediction: \" for  processing info and learning stuff\" => \"@un it  oo         os  io      i   nnn n\"\n",
      "batch 20342  loss=185.5699  steps/s=100.54  prediction: \"upmillyair microsoft is a faulty company\" => \"s rs t rt pspr siiioro is oi  inna anf n\"\n",
      "batch 20343  loss=165.2524  steps/s=115.47  prediction: \" in bend you should post, sounds awesome\" => \"t  a nten nn teun io s istlou u o ndou d\"\n",
      "batch 20345  loss=169.9703  steps/s=117.07  prediction: \"so much better than ppl who dont anyways\" => \"  oo o hon o ot o t  h      p   hh tthn \"\n",
      "batch 20346  loss=170.1828  steps/s=114.49  prediction: \"e are, so it has a ton of ripple effects\" => \"psri  t wane an w a  a  a  o ot   o  e  \"\n",
      "batch 20347  loss=178.4026  steps/s=113.79  prediction: \"file llm editing stuff is the future imo\" => \" nt tiie   l   i.wh.lhwudu\n",
      "\n",
      "ofbgtdmufulm\"\n",
      "batch 20348  loss=191.7946  steps/s=111.44  prediction: \"g-&gt;fb\n",
      "\n",
      "for cooler info, swim upstream\" => \" &ge t t-get;it;&g\n",
      ";fgttler\n",
      "grff,r for i\"\n",
      "batch 20349  loss=176.7911  steps/s=116.72  prediction: \" through nevada w my dad as a little kid\" => \"thedir eigg i tnivr v vd a d a ad  aa   \"\n",
      "batch 20351  loss=172.5581  steps/s=87.72  prediction: \"ressure either turns to dust or to a gem\" => \"eplns  gan e  p zpprcscndlpvwdasrpwluahy\"\n",
      "batch 20353  loss=176.1430  steps/s=90.22  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"@ dsrusa r a a et tnrrt  t sd //:t:9/919\"\n",
      "batch 20354  loss=180.4533  steps/s=78.75  prediction: \"arpertony lichess? and what time control\" => \"neurr r  oed   etoltrl? t?es?? t coce  s\"\n",
      "batch 20355  loss=168.4511  steps/s=103.58  prediction: \"t on bad apple vs python library anyways\" => \"hsi th utttounthoy\n",
      "hlbwg\n",
      "ppgfvbmnwivdgjf\"\n",
      "batch 20356  loss=171.1425  steps/s=93.96  prediction: \" did not answer. he just kept on yapping\" => \"ta  p tamn t t     t a tt  e t tt te t p\"\n",
      "batch 20357  loss=167.9187  steps/s=108.35  prediction: \"ession youll do something until its done\" => \"   e  pepn  iesn e so oo  oo oi n  otiis\"\n",
      "batch 20358  loss=174.9051  steps/s=111.32  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"   t  th  w  e t    h  et  t /ht//e /tVV\"\n",
      "batch 20359  loss=168.7607  steps/s=98.42  prediction: \"s aside though, why wouldn't that work?)\" => \" (o    s esn s teohes ho whotwwt 't tht \"\n",
      "batch 20360  loss=169.9633  steps/s=102.28  prediction: \"that there were pink cubes at some point\" => \" ir r  neonoi snkwcknd\n",
      "dahychalprwkkcbce\"\n",
      "batch 20361  loss=167.0698  steps/s=109.37  prediction: \"the (fake) claim about compromising info\" => \"he  oon n s  (nhk))bck))w)u)(,(kb)pgkchm\"\n",
      "batch 20362  loss=177.3868  steps/s=96.20  prediction: \"ne was right the rates arent high enough\" => \" s efai tie t enm(wbkupfihwglghiroprlfmðŸ›‘\"\n",
      "batch 20363  loss=177.7913  steps/s=116.37  prediction: \" will lose to one w more accurate values\" => \"tha h=i=  =l  nls iol  n     e  o e  eae\"\n",
      "batch 20364  loss=162.1591  steps/s=81.65  prediction: \" it chief\n",
      "may need to sleep negative hrs\" => \"tn iaev   e e  i    e    oeeee e eeeee  \"\n",
      "batch 20365  loss=169.3374  steps/s=68.28  prediction: \"sunsettler hes locked in to the outdoors\" => \" nre e i  a   a   e ed    eeee t ee e e \"\n",
      "batch 20366  loss=184.4185  steps/s=103.99  prediction: \"istake minimization\n",
      "\n",
      "Bezos lives by this\" => \"n oitatig&g&ge agtitizntmzmBmBmBoBBsBi i\"\n",
      "batch 20367  loss=166.9174  steps/s=112.79  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"@s e n e  n tot ff  ouo tt u ://: //tUUS\"\n",
      "batch 20368  loss=169.4743  steps/s=110.49  prediction: \"ly pretending to give unsolicited advice\" => \"y   ere e   r ete e etpt tte onig  g toe\"\n",
      "batch 20369  loss=171.1657  steps/s=108.62  prediction: \"ow readable zig is. how does ak do it???\" => \" i   n nee      e   e e ioi     do  da  \"\n",
      "batch 20370  loss=182.3297  steps/s=100.84  prediction: \"utput in readme\n",
      "\n",
      "https://t.co/hKCmvzerIc\" => \"s  s spt     e ue u t t ute\n",
      "\n",
      "\n",
      "//\n",
      "e\n",
      "///KC\"\n",
      "batch 20371  loss=192.1954  steps/s=9.06  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"ealy: t oxtse   x+m+xgm+y\n",
      "+:+up:://.KCnh\"\n",
      "batch 20372  loss=165.4223  steps/s=96.45  prediction: \"going into space man its truly beautiful\" => \" r\n",
      "   ee tn   o ing innan t n  ns  si ae\"\n",
      "batch 20373  loss=165.0554  steps/s=98.44  prediction: \"he audiobook content is better than both\" => \"e   t nnhtu  toouoooonto   t tb te t ntt\"\n",
      "batch 20374  loss=170.0260  steps/s=107.41  prediction: \"uters. i dont like those tbh. weird shit\" => \"t tho tmt n    rl t  l  t i l  t. t  .e.\"\n",
      "batch 20375  loss=173.7883  steps/s=83.26  prediction: \"you build cool stuff i follow\n",
      "\n",
      "simple as\" => \" u  ecteeihe im l ti s  t ool .t. i hish\"\n",
      "batch 20376  loss=169.9194  steps/s=95.81  prediction: \"activation energy as much as possible ig\" => \"nk r d  tgdn  o tion o ti e cs aus cc a \"\n",
      "batch 20377  loss=173.9648  steps/s=107.23  prediction: \"google very cool https://t.co/6SQb4zQ4zI\" => \" on ado  ooneen gve  ooo l  cop/s//6QQ44\"\n",
      "batch 20378  loss=190.3750  steps/s=116.19  prediction: \"ich in this case, is their lack of speed\" => \"nh sneihhch     i h,i s hs isss  s  a is\"\n",
      "batch 20379  loss=171.8299  steps/s=103.79  prediction: \"lls that help me do other ml experiments\" => \"y oe atelegt he e me le heh  oe phme oer\"\n",
      "batch 20380  loss=165.9214  steps/s=94.16  prediction: \"verything that happens to everyone else'\" => \"eryeees  thh et ththh theh ttentet ne n \"\n",
      "batch 20381  loss=168.5570  steps/s=87.03  prediction: \"ning\n",
      "3 insanely useful/interesting books\" => \" n oreine 3v\n",
      "3 i,g\n",
      "3m//mvulfyg//,\n",
      "v\n",
      "/\n",
      "3p\"\n",
      "batch 20382  loss=177.3515  steps/s=91.08  prediction: \"tech pointed out\n",
      "https://t.co/2uUpBg8KHz\" => \"h    h meh no n :esp@_lac,:d::/m.d2o22:U\"\n",
      "batch 20383  loss=191.9698  steps/s=92.05  prediction: \" make https://t.co/s6ZBWGye2X executable\" => \"tas  see k\n",
      " k  t  :///  o 66tZ/W/ZtXXtG2\"\n",
      "batch 20384  loss=178.0704  steps/s=88.37  prediction: \" it sucked but couldve been 1000x worse.\" => \"tt e dhi  t ksa  tkc t  ou tdet de1011e1\"\n",
      "batch 20385  loss=167.8777  steps/s=100.79  prediction: \"t, bc you can edit/delete prompt history\" => \"h h  batnchc an ,g,p,,pi,uy,uy/,n/d/i/dh\"\n",
      "batch 20386  loss=169.5370  steps/s=102.10  prediction: \"ntiers out there we dont even know about\" => \"  ie  gmthw s  sfgblbgfbemyuly/frbswikdo\"\n",
      "batch 20387  loss=197.6030  steps/s=107.66  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"tnerit     ne i\n",
      "int7 .\n",
      "@d7@ n'77't (s ((\"\n",
      "batch 20388  loss=168.3124  steps/s=103.90  prediction: \"ginal returns idea seems to pop up a lot\" => \" ne  g eonsr sl   ininaa  ae e se   u p \"\n",
      "batch 20389  loss=179.2179  steps/s=98.69  prediction: \"your .env and fill it out\n",
      "\n",
      "then it works\" => \":u n  nn m ne   ve v anvvid tielout  ot \"\n",
      "batch 20390  loss=164.6178  steps/s=97.50  prediction: \"o have positive interactions its to grow\" => \" sa   got n  o t ioti ti eitetitioni sii\"\n",
      "batch 20391  loss=182.8084  steps/s=95.08  prediction: \"amming you can make bigger leaps though.\" => \"n  s  ioonre  n r ngn innr min  iige oeg\"\n",
      "batch 20392  loss=185.0437  steps/s=96.00  prediction: \"7 gm pretty great how about yours brotha\" => \"7tty i  e ie7 nnmanrn iagbrba a a tebou \"\n",
      "batch 20393  loss=178.4518  steps/s=94.27  prediction: \" is from u a g:\n",
      "\n",
      "https://t.co/WkQRLnq0Jt\" => \"tt w iw ftttof iu   a s  s  ::/:t\n",
      "totW/Q\"\n",
      "batch 20394  loss=178.1550  steps/s=85.76  prediction: \" Nothing will stop the 16hr sessions!!!!\" => \"tEuYYmk  hsemN e   s  s h  tht s hs 1hs \"\n",
      "batch 20395  loss=164.8194  steps/s=91.39  prediction: \" problems\n",
      "\n",
      "Limit one attempt per problem\" => \"tau s      mmmn o Lm Loot  t mmt  ete pp\"\n",
      "batch 20396  loss=176.1650  steps/s=87.02  prediction: \" mf a forcefield https://t.co/XI2BbQJO77\" => \"ta t t t  t       fffefef et t tt/o///XX\"\n",
      "batch 20397  loss=190.5834  steps/s=61.59  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" th ogne a fcrldg.dvhf:pcbf:b.XIfBIQJOPP\"\n",
      "batch 20398  loss=186.1766  steps/s=105.55  prediction: \"Grats!!! Always awesome to see successes\" => \"OOd\n",
      "a  oli Gove GkGkAGw!\n",
      "AfA/6A.0W6fW0Ub\"\n",
      "batch 20399  loss=169.7960  steps/s=91.02  prediction: \"ill consider leaning into it more though\" => \"ny  a g a s w  de liln  lnni e ni    ono\"\n",
      "batch 20400  loss=167.0709  steps/s=87.72  prediction: \"rip\n",
      "\n",
      "he open sourced it to @crypt0x_0 ig\" => \"esharo tt ns _tacbyvy\n",
      "ht,,pwwyn,0dwr,udh\"\n",
      "batch 20401  loss=168.8204  steps/s=89.89  prediction: \" to me except this feels 100x better fug\" => \"thets ts  t  e  e  etee tht stexsxs xx  \"\n",
      "batch 20402  loss=176.8122  steps/s=86.24  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng  oo  ie int  inteehsthhs inae est ate\"\n",
      "batch 20403  loss=202.2061  steps/s=80.57  prediction: \"/t.co/zlto3SBYwd https://t.co/UFbXiSjnRR\" => \"t.oeetntengenzeozztBwSBBhlal aap cntiFF?\"\n",
      "batch 20404  loss=182.2654  steps/s=71.72  prediction: \"aulg We like memoizing physical patterns\" => \"ns nheee n  ni oiStYwezziza hUFFUcSSiSRðŸ›‘\"\n",
      "batch 20405  loss=164.1680  steps/s=93.64  prediction: \" a long line? aight imma work on bug xyz\" => \"t  in  m n  aonnl?na????l?g?  mimi ii a \"\n",
      "batch 20406  loss=170.4692  steps/s=95.30  prediction: \"reevaluating concepts you often overlook\" => \"e ly   lhnr  vr ivsv\n",
      "uufpmgfvalwh)pKhyyt\"\n",
      "batch 20407  loss=171.4802  steps/s=90.07  prediction: \"ing responses seems like a better metric\" => \"nts\n",
      "eeeingen s inooeess es e  ien s e ee\"\n",
      "batch 20408  loss=174.1508  steps/s=40.26  prediction: \": @EsotericCofe what are you working on?\" => \" @0olni    est ngfbpf#wbpblykmbwbbmwkgyk\"\n",
      "batch 20409  loss=169.0367  steps/s=103.58  prediction: \"u can build in a week is actually insane\" => \"swanum tte n mmncnuou n a an iwtek  i ae\"\n",
      "batch 20411  loss=167.3667  steps/s=95.79  prediction: \"useful directions to take the project in\" => \" efo efe    fufeu  s e ee to ettteto e t\"\n",
      "batch 20413  loss=181.3514  steps/s=86.88  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \"hr e  nte f ,  a!_I'l,g!dI'I'!kI'I'jI'kj\"\n",
      "batch 20414  loss=189.5088  steps/s=96.50  prediction: \"/t.co/cU8TdGmOOe https://t.co/wR9o8NrNIm\" => \"/.ccst h : tt:///UUTOG/OOtcOOOp t/co.c//\"\n",
      "batch 20415  loss=226.2772  steps/s=104.56  prediction: \"THOSE NUMBERS UP https://t.co/7EB6O8ih5c\" => \"h  E P o   T   EUSUSSU S tEES/E/t B E/BB\"\n",
      "batch 20416  loss=172.0310  steps/s=107.61  prediction: \" possible, at least quote and add a take\" => \"@re    olswls esssl le t  st a tt at t a\"\n",
      "batch 20417  loss=178.8681  steps/s=105.92  prediction: \"mer.js to make it cost $0. took too long\" => \"ens   @eraos  t jmwjdwhdk$m$0$$.$0.$0 $0\"\n",
      "batch 20418  loss=188.5666  steps/s=31.91  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly:  sateans  z.jmkedw$$0$0$0.0.$0.$0 d0\"\n",
      "batch 20419  loss=193.1494  steps/s=112.78  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"H IEd   o s O sOOOOOOOO\n",
      "\n",
      "\n",
      " s ts O\n",
      "/o\n",
      "\n",
      " s\"\n",
      "batch 20420  loss=184.8591  steps/s=92.27  prediction: \"TB cant even ðŸ˜­ because no fluid dynamics\" => \"H GuoO Oornnt c nnðŸ˜­ðŸ˜­ e cðŸ˜­  eet noesoo f \"\n",
      "batch 20421  loss=179.4608  steps/s=82.90  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BsP mcentn   t ensu eeco ?? e d? sdacss\"\n",
      "batch 20422  loss=178.8029  steps/s=98.54  prediction: \" mean impossible https://t.co/uA4rHNrGbN\" => \"@o0l ataas omm mlaip mmtt b potstt// /4A\"\n",
      "batch 20423  loss=169.1531  steps/s=101.48  prediction: \"resting, what kinds of tools has he made\" => \"epl  g  rhal i  bpsðŸ¤¦bndnd:wps,gkgwhwhg,i\"\n",
      "batch 20424  loss=178.9595  steps/s=99.82  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"sd      t    e n  t   e  e e e â€   e- e-\"\n",
      "batch 20425  loss=164.5641  steps/s=97.66  prediction: \" the scaling laws for language models...\" => \"@he t erente  n   ta tee l g  la   oageg\"\n",
      "batch 20426  loss=191.7602  steps/s=108.16  prediction: \"@Micky__21_ @dnbt777 finished the blog:â€¦\" => \"lC(â€œ`â€œQ*`9do  ak121@k_2@21_ @bMi27121d1n\"\n",
      "batch 20427  loss=180.2615  steps/s=104.28  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"@ir tee   aai: er s mtnet  t ets. t .es/\"\n",
      "batch 20428  loss=177.0090  steps/s=95.59  prediction: \"ers had a username but idk his name name\" => \"  @i le@ttm s   u tusermeter a eusun ssa\"\n",
      "batch 20429  loss=177.5032  steps/s=99.05  prediction: \"rf spatial in problem solving efficiency\" => \"eioe t s es the gdamrhmthnomrhblvohvrnvs\"\n",
      "batch 20430  loss=175.9971  steps/s=90.55  prediction: \"eadphones dead gonna recharge real quick\" => \" r h ad heahe a asndp s aoado r neargsig\"\n",
      "batch 20431  loss=168.1611  steps/s=100.17  prediction: \"pl make it interesting/fun/useful? dunno\" => \"ly:e p ltolse gecwa,kg,kt,iwmfkdmucplkp?\"\n",
      "batch 20432  loss=165.2025  steps/s=91.54  prediction: \"per solid learning loop, love it love it\" => \"lr e@ ed taunep uSuik//kt~itmfrd??dmg,mp\"\n",
      "batch 20433  loss=172.3841  steps/s=94.20  prediction: \" join the discord if you haven't! httpsâ€¦\" => \"@u   a   aiai te n d o d     ioid   o  h\"\n",
      "batch 20434  loss=175.6302  steps/s=94.43  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"tt   +np    t   ptor tâ€¦pâ€¦â€¦ pt p tttt ///\"\n",
      "batch 20435  loss=175.2650  steps/s=98.96  prediction: \"igh, make schizo\n",
      "// TODO remove appendix\" => \"nn    togi  he    i/i  oi/  / /  OOo  ao\"\n",
      "batch 20436  loss=170.2070  steps/s=102.04  prediction: \"dont just mean wrt doing logic with them\" => \"  io? td i?d e\"a dedj don ao at t t w tt\"\n",
      "batch 20437  loss=169.9483  steps/s=106.86  prediction: \"n run on my laptop, which I can do w ML?\" => \" ar ltn me sikeiI]ykkIDIcp,kwkuwhuIyul,m\"\n",
      "batch 20438  loss=183.2110  steps/s=101.62  prediction: \"rious -&gt; win more\n",
      "\n",
      "working just works\" => \"en e i He e ie iw-&,-;-&;&;-;;-;hwmywl?\n",
      "\"\n",
      "batch 20439  loss=167.9146  steps/s=103.06  prediction: \"o beta testers, and the world soon after\" => \" be  nte  ett  t eeta ta rt  e  a d to o\"\n",
      "batch 20440  loss=173.7968  steps/s=106.78  prediction: \"eakens your life-problem solving ability\" => \" r d  gann     tin io oo  - re-lineei bl\"\n",
      "batch 20441  loss=179.6375  steps/s=105.92  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"te ic c yena7ehwis soaobtri inititeuito \"\n",
      "batch 20442  loss=177.5031  steps/s=102.89  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nl t       tor l t  titeli/teaitit//ttth\"\n",
      "batch 20443  loss=173.8999  steps/s=97.37  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \"  nd   ad d s\n",
      "sis\n",
      " \n",
      "im s*x++x+x+ z  xx((\"\n",
      "batch 20444  loss=185.0319  steps/s=95.18  prediction: \" be cool to find some other players here\" => \"tyowo c   l      co od o se o oe ot t er\"\n",
      "batch 20445  loss=165.8868  steps/s=91.34  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"tt e n e  n i f ef  oou tt t t//  //tUUS\"\n",
      "batch 20446  loss=167.3575  steps/s=88.54  prediction: \"his wtf\n",
      "\n",
      "ill dm u a link around the 25th\" => \"eng t i itt t it it     li i  l  tlu  u \"\n",
      "batch 20447  loss=178.7822  steps/s=85.43  prediction: \"ue unfortunately https://t.co/LC7TD8X88U\" => \"t r t r    tr    lete l ututr aththuCCCC\"\n",
      "batch 20448  loss=186.1151  steps/s=85.39  prediction: \"ed\n",
      "Hes just gonna keep goin up from here\" => \"   o  tyfeet n   deoet  tnpt ko a op ku \"\n",
      "batch 20449  loss=185.1592  steps/s=92.99  prediction: \"orn to make cash forced to consooolidate\" => \"u tt ttit n ce oao?tc m ctokctc caacoctd\"\n",
      "batch 20450  loss=175.8041  steps/s=76.15  prediction: \"my database is a text file called main.c\" => \"e re en S t   atybsekfcrxrxexxaxeixacdaf\"\n",
      "batch 20451  loss=175.5661  steps/s=96.06  prediction: \"sing way more efficient/scalable methods\" => \" nt   l  oni   e iuri  eoie eiea ia ea e\"\n",
      "batch 20452  loss=164.5958  steps/s=100.93  prediction: \"ding up to that over which skill matters\" => \" ng taet nta  en t ete  eht   th t  th l\"\n",
      "batch 20453  loss=171.3209  steps/s=95.47  prediction: \"forever w Christ\n",
      "Prob worth checking out\" => \" r ejt tutaau i CpCfdanPuPpyCCnwsC\n",
      "PPvbC\"\n",
      "batch 20454  loss=183.3404  steps/s=97.69  prediction: \" enjoyer\n",
      "\n",
      "ill try to keep em comin loool\" => \"tv lo   zozeeeo or\n",
      "\n",
      "\n",
      "r l yrroooeee roei \"\n",
      "batch 20455  loss=179.1621  steps/s=65.64  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \" su  tbereor\n",
      " mljywjnjvf\n",
      "p::/y:.yW66W06W\"\n",
      "batch 20457  loss=171.9134  steps/s=94.80  prediction: \" if they'll give you access to that zone\" => \"tn ie\n",
      "  ee t ee  i  i ie e se ioes to t \"\n",
      "batch 20458  loss=179.4966  steps/s=89.81  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lte @y ms  aoes AI\"\"IIAIgmtapIupa\"du\"sIA\"\n",
      "batch 20459  loss=173.9133  steps/s=89.86  prediction: \"ready having better days from this stuff\" => \"eplg gid  tuoenecrèµ°uvirsahvvngvid\n",
      "bbufgy\"\n",
      "batch 20460  loss=189.2429  steps/s=85.66  prediction: \"binet_ Sweet!!! Let me know how 3js goes\" => \"et ea yaarnn n  _tS  !t!Le Lrrerhoh his \"\n",
      "batch 20461  loss=170.8069  steps/s=91.48  prediction: \". but idk thats just my weird take on it\" => \" itu tb eae h  n.dkldjvbjvjvdjykjkgbbjyj\"\n",
      "batch 20462  loss=170.3523  steps/s=94.04  prediction: \"ngry each chunk) it pretty much kills it\" => \"  imenn  steoty utvmv)rymw)c,dvw)Éªk)ynk)\"\n",
      "batch 20463  loss=173.6754  steps/s=90.53  prediction: \"rong tho, my confidence is only like 70%\" => \"egrtliesesar  tdwh.d.x.lw,bfb,bdr,f.d7,%\"\n",
      "batch 20464  loss=165.5447  steps/s=87.30  prediction: \"have primitives if you look close enough\" => \"eve i itit t v i itii itie tii ivie iie \"\n",
      "batch 20466  loss=167.3907  steps/s=93.34  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   o  hhs  h     h oc  coiiocoi ooi \n",
      "o t\"\n",
      "batch 20467  loss=181.4172  steps/s=86.71  prediction: \"here for the funny symbols and recursion\" => \"er e er toee ht   hmnsunm hehs hh te err\"\n",
      "batch 20468  loss=184.2979  steps/s=88.76  prediction: \"ttps://t.co/xZ7HHHQGpn.DB().happy==true?\" => \"hlu  tai    t.ne::/7Z7GQGQGHHQGGGHDBBB.)\"\n",
      "batch 20469  loss=181.6883  steps/s=95.51  prediction: \"ard players used to get through the race\" => \"tete   e  ereedep a   e  tereer t t t  t\"\n",
      "batch 20470  loss=177.4373  steps/s=90.87  prediction: \"on adding sound!\n",
      "https://t.co/7jVECuxgpx\" => \"u g o rn a okn odngnd dinn d! noddo/tEt/\"\n",
      "batch 20471  loss=193.3594  steps/s=88.12  prediction: \" job adding the australian language pack\" => \"turecr  t0e_ing notosg adi gontn suungpa\"\n",
      "batch 20472  loss=173.1122  steps/s=91.09  prediction: \"ether they are good or bad on their face\" => \"   dedeed whehthhe hheehhe r o o o  o  a\"\n",
      "batch 20473  loss=184.5215  steps/s=84.13  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"aMo ne  MTLMLB sHLgHgH.lHdHpdTlT.bTtTfnT\"\n",
      "batch 20474  loss=174.8571  steps/s=90.85  prediction: \"t 200hrs in around the same time you did\" => \"hw o oe2fmsgumnn0sr2,,pbtp2bma,tu2, spma\"\n",
      "batch 20475  loss=181.2564  steps/s=88.19  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"tdat   r eat rn agt rt p gene/hnea:: t t\"\n",
      "batch 20476  loss=191.2594  steps/s=82.92  prediction: \"binet_ Sweet!!! Let me know how 3js goes\" => \"et u pci rnng_ n_gt pnL/tL L / RToWZOBBZ\"\n",
      "batch 20477  loss=170.0741  steps/s=96.90  prediction: \"ion ability. should be trained first tbh\" => \"nn io satoeiali lili  il bbu t  i dd i  \"\n",
      "batch 20478  loss=168.3056  steps/s=90.57  prediction: \"ything rewarding that follows from that)\" => \" hmaaiiege aeng gingiaing rrgra aa tiaal\"\n",
      "batch 20479  loss=171.3523  steps/s=86.55  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"ethi:gohed bobosfrfwdldhby:ff:fbvpn:/:LY\"\n",
      "batch 20480  loss=181.8837  steps/s=89.72  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"torewe t t oog -ete \n",
      "\n",
      "gte \n",
      "\n",
      "p opst//QQs/\"\n",
      "batch 20481  loss=184.6574  steps/s=91.20  prediction: \"/t.co/YpddagC5uf https://t.co/GdftPhw7eI\" => \"/.ccs30   tt:pt//YC/5YC55Cp5Cthp.:st.ptt\"\n",
      "batch 20482  loss=187.6530  steps/s=93.83  prediction: \" followed\n",
      "Thanks for the shoutout brutha\" => \"tooeo    e lo eoTTTmo eowl we  ofo teh t\"\n",
      "batch 20483  loss=182.9353  steps/s=81.59  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1 o nedsehln11 1elDoDt De DoDutou /thut\"\n",
      "batch 20484  loss=169.6458  steps/s=89.73  prediction: \" into local files when you need to build\" => \"tn   a t n nt  n  t  n lolio l  nn in u \"\n",
      "batch 20485  loss=166.6714  steps/s=96.69  prediction: \"p infested regions of their latent space\" => \"lta  ou c fosintcðŸš€mfmpckgfmyludcp}pmfngd\"\n",
      "batch 20486  loss=177.6187  steps/s=81.60  prediction: \"super super cool. may use this\n",
      "\n",
      "followed\" => \" pot n peu u sr nn spee e e ea t stse aa\"\n",
      "batch 20488  loss=175.1628  steps/s=92.16  prediction: \"n X and see people dropping crazy things\" => \" ioo  ec tna ta X..XIXpan.Xc.ywpswrtz.zz\"\n",
      "batch 20489  loss=166.3716  steps/s=99.45  prediction: \"nd me tracks and ill render them for you\" => \"  te ca coeeri eAlwowck,kywunyku wfndkkðŸ›‘\"\n",
      "batch 20490  loss=178.6376  steps/s=97.04  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"teo   n  m titi inbibn  blbllsibn sto/om\"\n",
      "batch 20491  loss=180.8790  steps/s=91.07  prediction: \" w as in why tf would you use white mode\" => \"th  ern rhogaeetgptip dnl d  w  wn toy w\"\n",
      "batch 20492  loss=163.1110  steps/s=92.52  prediction: \" building blocks\n",
      "https://t.co/AmxwOfcoSg\" => \"tut pez  w t ti i biblihbhbbls bth to/o:\"\n",
      "batch 20493  loss=179.9814  steps/s=105.08  prediction: \" 10% is figuring out a fix + applying it\" => \"t0tmerii n\n",
      "\n",
      " h %fi rf  ufiti ier + + g +\"\n",
      "batch 20494  loss=190.8501  steps/s=87.92  prediction: \"ubed making gpt2 from scratch in c(obol)\" => \"neetce  s ei re1og rf g2 i+f isr i a pp(\"\n",
      "batch 20495  loss=167.0083  steps/s=96.25  prediction: \" in those days will have had it too easy\" => \"tt  oossmm i it   d y dsis  s i il  ha h\"\n",
      "batch 20496  loss=171.2633  steps/s=97.97  prediction: \" approximate it better outcompete others\" => \"tnlea utemer rhtriat roa itotetitpee eto\"\n",
      "batch 20497  loss=158.8311  steps/s=101.83  prediction: \"d work that into my current program haha\" => \"eah   o   e  ih  tt    t t  r rt   o rrr\"\n",
      "batch 20498  loss=174.2988  steps/s=100.22  prediction: \"t the truth/reality?\n",
      "\n",
      "sounds paradoxical\" => \" ie  leeih nols posðŸ¤·pbsf/rfal/ha?ffs/?//\"\n",
      "batch 20499  loss=177.4287  steps/s=91.56  prediction: \"important piece of advice here by a mile\" => \"nin i taia  et  rpno ppott iop ro ier  e\"\n",
      "batch 20500  loss=186.9742  steps/s=92.29  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"lt: @ tmoe_AkðŸ§ teVBEEDkkfpw::/kC.CVrVCTED\"\n",
      "batch 20501  loss=169.3858  steps/s=90.19  prediction: \"losoft and make the circle tool yourself\" => \"yckss stloteoe  e e ee e e   t ee o    e\"\n",
      "batch 20502  loss=175.3666  steps/s=91.55  prediction: \"be for a ton of triangles, bvh vs no bvh\" => \"u  t eir   o  e t r t nr t t t ne   n b \"\n",
      "batch 20503  loss=165.7795  steps/s=102.05  prediction: \"f time and space that can reach in here?\" => \" ooer @ru s  a tcbofynidfp,fmfcprypmyncs\"\n",
      "batch 20504  loss=182.8390  steps/s=93.83  prediction: \"ou can dive unbelievably deep into these\" => \" ttt  dete  e o ntemou uivebbyydnvelu  d\"\n",
      "batch 20506  loss=172.8137  steps/s=97.55  prediction: \"uild themselves\n",
      "\n",
      "https://t.co/jBlyguZKp9\" => \"tldntihd  n th 7thttsd ehtthtt/\n",
      "slshjs:/\"\n",
      "batch 20507  loss=170.8206  steps/s=19.18  prediction: \"eply: @visakanv The attack of the clowns\" => \" ly: @ga  n thetthttsd ehttstt/\n",
      "slshjsK/\"\n",
      "batch 20509  loss=177.8570  steps/s=130.60  prediction: \"TB you can just do things bro just do it\" => \"h @ist    n nsetheuttsj/std/ thjsjg jstðŸ›‘\"\n",
      "batch 20510  loss=206.9786  steps/s=84.47  prediction: \" LETS GOOO!!!\n",
      "Sounds like an awesome day\" => \"@ind chnT TEnSLnLS StGn!sS!SoSSus dsustt\"\n",
      "batch 20511  loss=184.5146  steps/s=31.63  prediction: \"ly: @justalexoki https://t.co/XmWFPd7zQu\" => \"y: @ncr erTE SonOS St!n!s \n",
      "d SsusodsdstðŸ›‘\"\n",
      "batch 20512  loss=177.9422  steps/s=93.20  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tet  t aatti uno lthp tutttu puttptt/D0D\"\n",
      "batch 20513  loss=176.0706  steps/s=101.13  prediction: \"r beforehand\n",
      "Makes the difference for me\" => \"ewite e efdn nr MbMbuMoliha\n",
      "MbMbkfowb/d\n",
      "\"\n",
      "batch 20514  loss=171.7417  steps/s=102.02  prediction: \"rogress\n",
      "Is the side proj the ml project?\" => \"eneey  \n",
      "r g   t IckakIvpimangrIIIkIhIslI\"\n",
      "batch 20515  loss=186.4942  steps/s=35.46  prediction: \"ply: @CreativeBuilds mason? is that you?\" => \"ly: @s irne e o IckakIjjimenjrIjIkIhIslI\"\n",
      "batch 20517  loss=168.4134  steps/s=102.45  prediction: \"etter but pretty good time bender though\" => \" t  ot t boete e etr   brette e t  oebee\"\n",
      "batch 20520  loss=174.4283  steps/s=81.60  prediction: \"nes thanks brother!! its good to be free\" => \"gM teot t t  seouympt!!gkrdlmb\n",
      "m!.yngsod\"\n",
      "batch 20521  loss=181.5092  steps/s=88.09  prediction: \"ight go back to ML stuff instead of this\" => \"nh  thrt l  ro t  o  bhtL LLMLLMst to de\"\n",
      "batch 20522  loss=198.8200  steps/s=93.65  prediction: \" QUICK delete this before sphere sees it\" => \"@io   gog get hoC t  thtf ohith st tf h \"\n",
      "batch 20523  loss=176.6110  steps/s=45.16  prediction: \": @archived_videos definitely the latter\" => \" @lowaodr h  K rUICIthkhgbhbmkfhksckchod\"\n",
      "batch 20524  loss=173.2472  steps/s=92.61  prediction: \"sy and they put bugs in the concrete lol\" => \"  e   baeny a yn ey an y uu  t b  nn  ct\"\n",
      "batch 20525  loss=177.4845  steps/s=86.82  prediction: \"hackers #saas #developers #buildinpublic\" => \"esgs i t  snahGe i#cic # # #seaerese#s #\"\n",
      "batch 20526  loss=178.9537  steps/s=67.69  prediction: \"by_builds another $20 trillion to ludwig\" => \"u ch ni  #saa e de chor2$r2$20ailelebubu\"\n",
      "batch 20527  loss=173.7833  steps/s=96.34  prediction: \"nrot swe competition\n",
      "Gm level strategery\" => \"de oa e aenaet kMbkwvMlGmM\n",
      "GrfbGmbGmvl#p\"\n",
      "batch 20528  loss=201.2201  steps/s=76.68  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"eined ezae  o  sw1k1Gm0Gmv\n",
      "Gr.crmbGmv.yk\"\n",
      "batch 20529  loss=181.3141  steps/s=93.12  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"iu   os o o ne)))nS o n\n",
      " aaheoeh h a h f\"\n",
      "batch 20530  loss=193.3988  steps/s=102.62  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" tovtrEree\n",
      "cLL  \n",
      "LLLLLqqq\n",
      "qchte hethtt/X\"\n",
      "batch 20532  loss=183.6066  steps/s=88.63  prediction: \"is i second this https://t.co/3JrtWEMXgK\" => \"n    t etnenense  hdipt:tshh te:t/3333t3\"\n",
      "batch 20533  loss=185.2929  steps/s=93.76  prediction: \" off with a basic template and modify it\" => \"tn ttito tf it f  hta sitfcsitttta acttc\"\n",
      "batch 20534  loss=167.9070  steps/s=92.68  prediction: \" deadlines dont really get done the same\" => \"to   in n tetootee ddnn  deln  deed onel\"\n",
      "batch 20535  loss=181.8362  steps/s=94.64  prediction: \"he making a dingboard clone or something\" => \"e iom t  mg i   eg ang  edna d d and n i\"\n",
      "batch 20536  loss=166.2734  steps/s=94.76  prediction: \"tput something as unexpected as possible\" => \" soio lo ho  mt ugngampsmxaxpexgxlsxmexx\"\n",
      "batch 20537  loss=166.8721  steps/s=39.99  prediction: \"y: @kuberdenis @crypt0x_0 real ones know\" => \": @tuto o to titt u  otextoee  stens poe\"\n",
      "batch 20538  loss=161.9144  steps/s=100.49  prediction: \"ments as opposed to making the user wait\" => \"e he tn tre  dt mgdkwpg,guvcmwgmkgcvbck,\"\n",
      "batch 20539  loss=169.8275  steps/s=94.66  prediction: \"im definitely not an expert in it though\" => \"n oo  n ue   i ni  ii  e  e  nn  et te n\"\n",
      "batch 20540  loss=163.6600  steps/s=91.73  prediction: \"ry awesome goal list\n",
      "Lmk how it goes man\" => \"e at no   beti v\n",
      "ay,Tw,kvmw]xpwd}vâ€™ry\n",
      "Lv\"\n",
      "batch 20541  loss=170.1352  steps/s=40.88  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \": @caeas    e r   el   l   ol   w  o s  \"\n",
      "batch 20543  loss=175.0230  steps/s=96.29  prediction: \"about things that have significant value\" => \"noet  otng e  ets aaat  tatn sinitnitat \"\n",
      "batch 20544  loss=180.3630  steps/s=45.18  prediction: \"ly: @Nominus9 Oooh I meant in your head!\" => \"y  @\n",
      " ton\n",
      "n t tts aaat  tatn sinitnitat \"\n",
      "batch 20545  loss=166.4700  steps/s=72.38  prediction: \"ly: @1owroller you spelled haskell wrong\" => \"y: @  toern t t s a ats t in ninitniaav \"\n",
      "batch 20546  loss=173.1324  steps/s=96.62  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"nle  eku y ba u u  o ie f f   o  a a ael\"\n",
      "batch 20547  loss=174.2052  steps/s=91.34  prediction: \"cept\n",
      "High levelâ€¦ https://t.co/NZUDp7sGkN\" => \"h sg iceot    o câ€¦ncHâ€¦H\n",
      "â€¦ocH:pâ€¦â€¦â€¦cvDNZUN\"\n",
      "batch 20548  loss=173.5609  steps/s=91.55  prediction: \"ith (progressive overload)\n",
      "you will getâ€¦\" => \"n  loo f  r  aeterth  veooiir  vee ivl  \"\n",
      "batch 20549  loss=175.5644  steps/s=85.00  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"irl @siwh  nor trcfmDstxD)xDD\n",
      "xDxDyxDxDâ€¦\"\n",
      "batch 20550  loss=167.7920  steps/s=90.18  prediction: \"her level abstraction of piece movements\" => \"e e ates tre   rt e atireet e ea   otiec\"\n",
      "batch 20551  loss=179.3828  steps/s=94.84  prediction: \"re not a midwit, the phase is midwit\"..?\" => \"epl\n",
      "r @nre  oti wxxkwi\"x,x\n",
      "\"\",wyx, phdwc\"\n",
      "batch 20552  loss=187.6139  steps/s=92.07  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BAPily mP @oZ lBBAP@@B@PA@h@juysjl\".dwðŸ›‘\"\n",
      "batch 20553  loss=176.8338  steps/s=80.27  prediction: \"wigABAP a friendly virus. one that talks\" => \"igABig BnPeaeu  BgP,div,Buhj@juy.j.\".fwðŸ›‘\"\n",
      "batch 20554  loss=178.3194  steps/s=107.60  prediction: \"nt ask for almost bricked my work laptop\" => \"g he  uareas aneidgkpdAkyblxwklckxfmkfgðŸ›‘\"\n",
      "batch 20555  loss=172.7533  steps/s=101.10  prediction: \"f this song and never listen to it again\" => \" y to @elc ooh tifExxvgmsfyxvgvckcsvwhcðŸ›‘\"\n",
      "batch 20557  loss=170.8502  steps/s=90.98  prediction: \" strategy is short term low integrity BS\" => \"too     aan e etear  e s  etr este i tei\"\n",
      "batch 20558  loss=192.5157  steps/s=89.67  prediction: \"ly @covix2772 â˜ ï¸ https://t.co/2A3p3rDVtF\" => \"y: sin nat  s  h2oâ˜ 272 â˜ ï¸ â˜ ï¸rtest/ti t r\"\n",
      "batch 20559  loss=174.5120  steps/s=90.81  prediction: \"gt; practicing them -&gt; mastering them\" => \" ;e   ba tig tt &m--&b;;cpahhmg-&&g;;raa\"\n",
      "batch 20561  loss=182.0583  steps/s=83.09  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tn tnennh hp_ict5t5th : DtD D:D: DtZgZ:Z\"\n",
      "batch 20562  loss=188.2827  steps/s=84.99  prediction: \" lol positive feedback loops are awesome\" => \"@ewtsan oot  eed p\n",
      "epdoodioo oopee ae le\"\n",
      "batch 20564  loss=179.2608  steps/s=11.86  prediction: \"reply: @calbch its the year of the monad\" => \"eply: @den ll lodiahvivepe bx\n",
      "vbkv\n",
      "kd\n",
      "ad\"\n",
      "batch 20565  loss=172.5277  steps/s=99.34  prediction: \"etty interesting\n",
      "https://t.co/vb0h37MG3v\" => \" t sttset t  e eetestet ststttt/tt/tt/t/\"\n",
      "batch 20566  loss=169.5654  steps/s=95.31  prediction: \"erful tool, extremely extremely powerful\" => \" y retelm  eleoereexlr extyemxtetmely ee\"\n",
      "batch 20567  loss=166.6237  steps/s=95.62  prediction: \"ational ones it might actually be useful\" => \"n    o   es noimr it nnna   t t tlt asa \"\n",
      "batch 20568  loss=184.0135  steps/s=84.15  prediction: \" @sunsettler 100%\n",
      "\n",
      "TIME AND FREEDOM BABY\" => \"tnunionoeernitï¸â˜ e r@00%%T % 1T0NNFFFMEFD\"\n",
      "batch 20569  loss=179.1809  steps/s=90.48  prediction: \"while his chess opponents mind went 3fps\" => \"oene oen hhoes l3bbapdawmopn3f\n",
      "ofwbmwn33\"\n",
      "batch 20570  loss=173.1253  steps/s=94.02  prediction: \"d now your follower base is more aligned\" => \" ff et ln fr i nr owen wnr f l oos  omls\"\n",
      "batch 20571  loss=204.2642  steps/s=88.41  prediction: \"luffyb Xorswap, what a username, love it\" => \"ydw@1 _1r 1 fy fXXfXX XXor yaw  fs, aa ,\"\n",
      "batch 20572  loss=172.7385  steps/s=89.24  prediction: \"just happen to have sicilian parents lol\" => \"ust e i e ht  t  ea h pe   a  ea einii e\"\n",
      "batch 20573  loss=177.7220  steps/s=96.43  prediction: \"or yrs its TRASH\n",
      "https://t.co/KCyzMmhzkI\" => \"u     t   y          StSt  t s/t//tt t//\"\n",
      "batch 20575  loss=196.3836  steps/s=97.83  prediction: \"yacine needs a dingboard wrap on his car\" => \":ci critsr 0  T itH n:tttst//K/K/othztzt\"\n",
      "batch 20576  loss=169.4807  steps/s=90.17  prediction: \"better generalizer than the classic MLP?\" => \"a t e t t  tetn  a  ar eetet  e e tees e\"\n",
      "batch 20577  loss=206.2559  steps/s=10.27  prediction: \"reply: @kubeden Id be down in the future\" => \"eply: Li na i  tvcvgvfengfozgzbvzzfwzhbn\"\n",
      "batch 20578  loss=171.1676  steps/s=118.39  prediction: \"ticed this too, its what got me thinking\" => \" nl  a os so   ndcbgld,fgf,,i,b,rw,wngbo\"\n",
      "batch 20579  loss=200.4305  steps/s=89.87  prediction: \"YYYYYYYYYYYYYYY\n",
      "\n",
      "https://t.co/xt0RP3tmNR\" => \" u YYYYYYYY T   \n",
      "YYYY \n",
      "Yh\n",
      "\n",
      "s //Y://\n",
      "\n",
      "ttR\"\n",
      "batch 20580  loss=199.3787  steps/s=92.30  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"h G dOe    TO OOOOOOOOO\n",
      "\n",
      "\n",
      " s ts O//NN222\"\n",
      "batch 20581  loss=171.5591  steps/s=90.67  prediction: \"ty) so they can be free to chase rewards\" => \"h rersto t )le  )as)vv)by)fy)cbm)bscbivb\"\n",
      "batch 20582  loss=168.3776  steps/s=92.79  prediction: \" exercise days, and just work a bit less\" => \"txe eememt n   nae saa s  ss  e s  aa  s\"\n",
      "batch 20583  loss=169.7950  steps/s=46.00  prediction: \"y: @melqtx every mon and thurs ma brotha\" => \"  @le  eo tn e e e san s  ss  jss   a  t\"\n",
      "batch 20584  loss=183.9987  steps/s=104.08  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"tom aile an    e coc cd tar  a g n /at99\"\n",
      "batch 20585  loss=169.2974  steps/s=89.71  prediction: \"s creatine in it https://t.co/KH2Tzx2YwO\" => \" of et te a   reaetet in  t  ttict// 2/H\"\n",
      "batch 20586  loss=178.8508  steps/s=44.67  prediction: \"y: @crypt0x_0 thank you for reminding me\" => \"  @laa re t   e nntet in  tt/tti///2222H\"\n",
      "batch 20587  loss=171.4636  steps/s=100.17  prediction: \" been some adventure man. God bless him.\" => \"aev  teve '  see veveeveu ennue e en e e\"\n",
      "batch 20588  loss=172.3359  steps/s=99.25  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"os ot chen t e shvlvvvmavaffucuvv\n",
      "bwbfdh\"\n",
      "batch 20589  loss=167.6606  steps/s=103.28  prediction: \"o beta testers, and the world soon after\" => \"nie   te  et   t ttta tt tt   e d d to t\"\n",
      "batch 20590  loss=172.2749  steps/s=87.99  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"tb     otaoo    as s    essesst/ht/s//SS\"\n",
      "batch 20591  loss=169.7618  steps/s=98.88  prediction: \"reason...\"\n",
      "Had this actually happen once\" => \"eply       s  r \n",
      "HbHcn.\".H\n",
      "H\n",
      "Hh\"\n",
      "Hldvm\"\n",
      "\"\n",
      "batch 20592  loss=177.7704  steps/s=102.12  prediction: \" different on your OS. you can google em\" => \"tor tt  ehf e  t fsfyrtuonny uy rer  Sno\"\n",
      "batch 20593  loss=165.2903  steps/s=101.17  prediction: \"t really is a long term + hard work game\" => \" bo s h  ses is rhebtm\n",
      "fOS.OrOOOcyyrun+a\"\n",
      "batch 20594  loss=171.6685  steps/s=101.06  prediction: \"uters. i dont like those tbh. weird shit\" => \"s  o  tmt l  e  t t  e   oi k  so t  .e.\"\n",
      "batch 20595  loss=193.4645  steps/s=109.01  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"   etdan to eS Sq@xqFFINFTFINORRCURDEODI\"\n",
      "batch 20596  loss=176.7175  steps/s=99.54  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"s  s.nein tisl  li ltttut s iut lu utof \"\n",
      "batch 20597  loss=166.1749  steps/s=93.33  prediction: \" a bool so you just become sick again :/\" => \"t  i got gag lo l s o o oou  s  e s so  \"\n",
      "batch 20598  loss=182.5705  steps/s=88.08  prediction: \"ouchdaily LETS GOOOO\n",
      "welcome back brotha\" => \"   aogl  sel lo  osob o ooes s co e bick\"\n",
      "batch 20599  loss=165.8032  steps/s=43.80  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: @oel l  l  o  OOo  oOooe  s ck a bicðŸ›‘\"\n",
      "batch 20600  loss=168.7052  steps/s=94.56  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n aisl sl sn sis s iis  s  at  n     ao \"\n",
      "batch 20601  loss=169.4184  steps/s=94.00  prediction: \"eful/true)\n",
      "\n",
      "sometimes thisll take months\" => \" uees etn u uuuteuutetesueesm sssleetl s\"\n",
      "batch 20602  loss=168.5867  steps/s=92.86  prediction: \"r the years for business/building things\" => \"etaeitentd     n(bh)w)m)cu)vvl/)u8)d/)X/\"\n",
      "batch 20603  loss=168.2398  steps/s=97.18  prediction: \"yping on the terminal bc it looked cool)\" => \" eiw intth     e  in nen t n t   tn ei  \"\n",
      "batch 20604  loss=174.4114  steps/s=90.34  prediction: \"be allocate some time to do fun projects\" => \"e i o  onh  aeeao lo  ooa t  mo motte o \"\n",
      "batch 20606  loss=171.8307  steps/s=87.25  prediction: \"suck but its fun\n",
      "What do you play mostly\" => \" nueo s ane  sts   suu WW s Woo  o u o y\"\n",
      "batch 20607  loss=169.8640  steps/s=95.16  prediction: \"ate, but I think about this all the time\" => \"n  e  ien t   t a tbtut   tti tat  t t t\"\n",
      "batch 20608  loss=166.9684  steps/s=94.30  prediction: \"ol shit way more than alcohol and gaming\" => \" l:  nil cil   t  o i   oo oh   oah haa \"\n",
      "batch 20609  loss=159.8647  steps/s=95.73  prediction: \"ness should get\n",
      "otherwise skill issue ig\" => \"gM  o ec d ance mybkyIfIkbh\n",
      "ImyIkwwbv\n",
      "nk\"\n",
      "batch 20610  loss=169.5000  steps/s=91.24  prediction: \" away looks smoother than a bowling ball\" => \"tn   fawn oa  wro rar a thoosa a oorso l\"\n",
      "batch 20611  loss=182.9960  steps/s=94.71  prediction: \"8k ccores 240gb) https://t.co/bQ6pAjTFAl\" => \"0gbc_  rot  c e   44c ts  tot::// tsQ//A\"\n",
      "batch 20612  loss=171.6924  steps/s=92.83  prediction: \"d thing happens\" (like a nuke going off)\" => \" ioo   t na th  h  h   aippn  n   k ake \"\n",
      "batch 20613  loss=178.5201  steps/s=96.54  prediction: \"yeah, tunisia... carthage would be nice\"\" => \" a ntuir n  nn iaai.... a.nh gi ia na e \"\n",
      "batch 20614  loss=168.4534  steps/s=93.39  prediction: \"fe but fixed it\n",
      "\n",
      "https://t.co/iiwNMy9BqU\" => \" r at tenan e e wkx.xIxhl\n",
      ":I:p.:.:$:vNMN\"\n",
      "batch 20615  loss=168.6230  steps/s=94.37  prediction: \"l\n",
      "Gives ppl a way to practice and learnâ€¦\" => \"i\n",
      "  il iei e peps  p l p   airt  acrlcee\"\n",
      "batch 20616  loss=164.8810  steps/s=90.85  prediction: \"people skills of almost everyone ive met\" => \"lr nest ito ab nmá´›dcv`.wÊœ.kbá´‡bhbkbpc..ok\"\n",
      "batch 20617  loss=162.7838  steps/s=85.69  prediction: \"the beta (should be around the 25th)\n",
      ": D\" => \"he linorts  ro of(bc(,w(uw,Fg(2,2525wk)2\"\n",
      "batch 20618  loss=173.9824  steps/s=89.99  prediction: \"owing that your food supply doesnt scale\" => \"r  n t  t wa t ttat w  t yi u  tuy so st\"\n",
      "batch 20619  loss=170.6998  steps/s=56.51  prediction: \"yotzol its not a meme, its a way of life\" => \" u iitagt w ttnotyr    t piot  oua yo sl\"\n",
      "batch 20621  loss=172.0954  steps/s=92.89  prediction: \" this guy did it\n",
      "https://t.co/Mx8AIWdLRf\" => \"the kk s ii   di  is  its  ii ttit ///Mt\"\n",
      "batch 20623  loss=174.2652  steps/s=93.80  prediction: \" (by trusting in ideas) and testing them\" => \"tytsthes  tthtnts stiseess intit nii tis\"\n",
      "batch 20624  loss=167.4049  steps/s=89.36  prediction: \"lped me too yrs ago. very inspiring dude\" => \"ye  te te  o oe   ee o e e  os  iri ioi \"\n",
      "batch 20625  loss=185.9789  steps/s=86.93  prediction: \"0x_0 how is crypto this good at replying\" => \"909 @er0pn0  t  @w@cxypxgxwhvwhwbymve)yb\"\n",
      "batch 20626  loss=176.9485  steps/s=91.69  prediction: \"morrow, hope it goes well for you brotha\" => \"edeio  f m    etmfwyfw,thypvi,wg\n",
      "ghvecy\n",
      "\"\n",
      "batch 20627  loss=165.9804  steps/s=85.88  prediction: \"us im in, gonna do this rn, on the rocks\" => \"st nrjn  wa   nnnin , eo s do roeo    o \"\n",
      "batch 20628  loss=172.1721  steps/s=88.94  prediction: \"more friction than they need to function\" => \"ereise soos nte .vovvvrvofrff\n",
      "cmrimohlyf\"\n",
      "batch 20629  loss=173.1469  steps/s=93.83  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \" \n",
      "no   ut d s:sis\n",
      " ++m+s*x++xxx* s  xx&\"\"\n",
      "batch 20630  loss=185.0201  steps/s=61.20  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"ydw uud\"; mdA\n",
      " i**++*m+\n",
      "Rx i x\"e )  & &;\"\n",
      "batch 20631  loss=169.9341  steps/s=96.51  prediction: \" for yourself they pay dividends forever\" => \"ioooooloool ooo  ol  so    y   y e  ydde\"\n",
      "batch 20632  loss=171.0790  steps/s=93.50  prediction: \" to use. code is linked in another reply\" => \"toe      er esn pe  ooee o  ois s  in ei\"\n",
      "batch 20633  loss=176.8228  steps/s=94.29  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"u   n n waIa    F\n",
      "!FLFFF!!!\n",
      ":/ F Fo/Wt0F\"\n",
      "batch 20635  loss=173.1114  steps/s=96.93  prediction: \"t 200hrs in around the same time you did\" => \" tno o  sns utnn02r2,,pbtp2bma,tu2, spma\"\n",
      "batch 20636  loss=171.6687  steps/s=93.77  prediction: \"y is that the levels of learning theory?\" => \" wfee en @o  i tae t t l ll hs le  e ele\"\n",
      "batch 20637  loss=183.6679  steps/s=49.28  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tlu  hnil       he thv l lleas l   nrel?\"\n",
      "batch 20638  loss=179.4838  steps/s=101.65  prediction: \"i it does look super nice, was gonna say\" => \"nta acn  w @t caseits  i eusuiio  euee g\"\n",
      "batch 20639  loss=180.4483  steps/s=82.68  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \" tio to stoenowtCkmsunupJ,J,k,JppJpkJgmJ\"\n",
      "batch 20640  loss=169.5675  steps/s=91.46  prediction: \"e real for this\n",
      "\n",
      "https://t.co/XuMxlWAwBE\" => \" bent a tewr e  a\n",
      "\n",
      " \n",
      "\n",
      " tt\n",
      "ar et e///XMMX\"\n",
      "batch 20641  loss=174.7221  steps/s=99.15  prediction: \" and can be much more useful to increase\" => \"tranaerare     hns aa bbe ma   cc e se e\"\n",
      "batch 20642  loss=167.2152  steps/s=103.45  prediction: \"was intentional but it sounds super cool\" => \"oyo @ e sh ank tcbwflg,zizwrlsbdmzbdbzok\"\n",
      "batch 20644  loss=173.8112  steps/s=90.23  prediction: \" interesting, and way more distracting ðŸ˜†\" => \"tn   h  e..seinntentn  n  n e ae t ad  s\"\n",
      "batch 20645  loss=175.4218  steps/s=97.03  prediction: \"/t.co/am8kS4P9S4 https://t.co/Xh3TC5ZKAo\" => \"teac\n",
      "tn a  / :8/St//888P9S44S44tt::/:/tT\"\n",
      "batch 20646  loss=174.1583  steps/s=83.72  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \" eaoaaeteins mtsrarcarahtacoanhtthoa ttt\"\n",
      "batch 20647  loss=177.9581  steps/s=42.60  prediction: \"y: @2wlearning Thats incredibly cool wtf\" => \"  @ceaetni s mterarnar ctaooa htthoa ttt\"\n",
      "batch 20648  loss=173.4797  steps/s=98.83  prediction: \"s the error correction mechanism go away\" => \" io e n onon     ee \n",
      "rrnecroor trroencic\"\n",
      "batch 20649  loss=171.6526  steps/s=96.05  prediction: \"t. good thing we still have comonad club\" => \"   atnhtee itee grd..c.odowd.mgrchmcgvdg\"\n",
      "batch 20650  loss=172.2940  steps/s=85.43  prediction: \"xes this (whether you want it to or not)\" => \" rfViin wth i hs eewit s iewh  e tt w  o\"\n",
      "batch 20651  loss=176.1871  steps/s=79.54  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \" prs ti sn thes @1M1M(cf(.x(ymunwymchmb \"\n",
      "batch 20652  loss=171.6913  steps/s=90.68  prediction: \"ter today.\n",
      "oh, and less music helped too\" => \" r  snen    seayordlf.gy.,fe,mun.\n",
      "y.,t.,\"\n",
      "batch 20653  loss=172.1511  steps/s=90.06  prediction: \"gpt-5 powered robot of him into the wild\" => \" l@  p le  ist t-5lj-sammjHhmdu-fb-5msgn\"\n",
      "batch 20654  loss=168.2181  steps/s=90.66  prediction: \"sively going up\n",
      "But make responsibilityâ€¦\" => \" brl  velrreo  eiieg gggg BBBBe ir  ie  \"\n",
      "batch 20655  loss=187.6197  steps/s=65.62  prediction: \"@gizmobly @XEng lol why did he block you\" => \"aicsee  eis l  giEng gg g spppesir  ie â€¦\"\n",
      "batch 20658  loss=166.9085  steps/s=100.31  prediction: \" can be taken much much much further tbh\" => \"@oacch c   t nen    tnce   much muc m ch\"\n",
      "batch 20659  loss=170.3975  steps/s=89.09  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"g i  ca va e v  cyxugxuvkkwBmfDp\n",
      "xxrx\n",
      "bd\"\n",
      "batch 20660  loss=162.8661  steps/s=86.49  prediction: \"d useful stuff better with the new tools\" => \" bulu leful fut ffu ttuf   uttu   tee te\"\n",
      "batch 20661  loss=176.8949  steps/s=95.45  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \" lell    nle oi l\"!\" \"e\" xnnx eoneoe ! !\"\n",
      "batch 20662  loss=232.6314  steps/s=97.07  prediction: \"90lpzRtMaMwL30MuqPOvLF40 without soylent\" => \" MKTOT999T9pz9Mb0MTL0qM0OqLLF0FF00tLtu0l\"\n",
      "batch 20663  loss=179.1960  steps/s=92.82  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"  soiisi tiiididdii e tdit titt t/ticc//\"\n",
      "batch 20664  loss=174.6993  steps/s=79.79  prediction: \"ttler experimentation games are the best\" => \"heobosrtsneelio cxpxvdw\n",
      "mpyp/li\n",
      "dkm/mdvr\"\n",
      "batch 20665  loss=171.1014  steps/s=85.39  prediction: \", even my llm is on 3 cups of coffee bro\" => \" sndaneeee e  n ee i moil sc s s cc cf c\"\n",
      "batch 20666  loss=174.9999  steps/s=88.98  prediction: \"evels of goated\n",
      "\n",
      "https://t.co/GAYjU5bjIR\" => \" el lrror n eleoo egoegee\n",
      "ee\n",
      " t:/://o/Yo\"\n",
      "batch 20667  loss=183.1837  steps/s=86.84  prediction: \"pl go in 70-80?ðŸ¤” https://t.co/DsQK3A6SDh\" => \"ly:o@ ndn exdgx 7p-707ðŸ¤”-?ðŸ¤”?ðŸ¤”-?ðŸ¤”?ðŸ¤”.cA8D?Q\"\n",
      "batch 20668  loss=184.2198  steps/s=40.58  prediction: \"y: @Brycicle77 Way of the house husband?\" => \"  @Npo  do  7  ? ?ðŸ¤”ðŸ¤”ðŸ¤”ðŸ¤”?ðŸ¤”th/ /.:D/DDDQQQD\"\n",
      "batch 20669  loss=171.9568  steps/s=102.61  prediction: \" now i have this https://t.co/NCsyY5vpWl\" => \"to  irc ne        h h hh hs t /:/t/NNNNN\"\n",
      "batch 20670  loss=174.4097  steps/s=97.05  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \"rtao og too    hh fife iht ttt ////s cQt\"\n",
      "batch 20671  loss=204.6245  steps/s=25.33  prediction: \"ply: @ns123abc mad growth, what happened\" => \"ly: @ i Kâ€œðŸ¤¦88r( )hucurcadmu))u)Q6)::Y1.c\"\n",
      "batch 20672  loss=172.5280  steps/s=129.15  prediction: \"tcs Some say zig has a secret 4th letter\" => \" he rnh d toorn )huczrf:,z,fwhdQ6y::Y48M\"\n",
      "batch 20673  loss=167.1835  steps/s=92.13  prediction: \"ductive. Its something im working on too\" => \" sGso m m e  ote  oee otm ti eo m tm mi \"\n",
      "batch 20674  loss=162.7922  steps/s=85.86  prediction: \" What are your personal long term games?\" => \"thodiclhct a oae r er roe ooreo e og og \"\n",
      "batch 20675  loss=182.0690  steps/s=34.20  prediction: \"ly: @IsntTrivial https://t.co/5iBit5syTv\" => \"y: @hul  h a  re rrer roo oone  g og mgm\"\n",
      "batch 20676  loss=170.5727  steps/s=103.92  prediction: \" of twitter it usually means engineering\" => \"tf h en    t ta t  tert e  st isa  ea ee\"\n",
      "batch 20677  loss=166.7444  steps/s=62.15  prediction: \"dejavucoder roon was gpt5 the whole time\" => \"  et totor t tt t  t  t e  sr s aneeinee\"\n",
      "batch 20678  loss=185.7915  steps/s=112.36  prediction: \"s man. i try to keep it real as they say\" => \" arr es@the  itnri t k  t  te  ea  trtie\"\n",
      "batch 20679  loss=165.9828  steps/s=89.77  prediction: \"re for blundering bc of moving too quick\" => \"epline@e n novn A\n",
      "Aw\n",
      "Abcurg\n",
      "ggcum\n",
      "vfqAvc\"\n",
      "batch 20680  loss=172.9755  steps/s=85.48  prediction: \"eeded this\n",
      "ty ty https://t.co/V2DVPMnbxh\" => \" p   teo     dhettotttt yt tt ty t//////\"\n",
      "batch 20681  loss=187.8748  steps/s=33.50  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"y  @ohno dne dt ttytttt ytttt ///t//V/VV\"\n",
      "batch 20682  loss=181.4871  steps/s=93.52  prediction: \"imental is gzip) https://t.co/TDxAQ8YLdZ\" => \"npe  e tn t e ietii   iptp)  )/tt//// /t\"\n",
      "batch 20683  loss=175.1352  steps/s=97.49  prediction: \"ing vidya except w only positive effects\" => \"ng eeieinlg eiieg g eeee   e y    y eii \"\n",
      "batch 20684  loss=174.6616  steps/s=88.92  prediction: \"ing, do this\n",
      "I went from C/Fs to As w it\" => \"ngie   yeefo  h   i  h n o  o    o Ct ts\"\n",
      "batch 20685  loss=175.2163  steps/s=89.20  prediction: \". seems like a fancy type of hard coding\" => \" whe  .r n  sht r.gamwchfudgkw/g.cdc.fpn\"\n",
      "batch 20686  loss=180.7115  steps/s=84.20  prediction: \" cool\n",
      "\n",
      "ez follow\n",
      "https://t.co/F6AUVWpskt\" => \"tani ii ico  ltoo \n",
      "\n",
      "\n",
      "loto\n",
      "tlott//// ///6\"\n",
      "batch 20687  loss=222.5939  steps/s=9.35  prediction: \"reply: @IterIntellectus no i forgot srry\" => \"eply: @_Fe tDAe AcAMmwmhzyzi: [azcá´€zF6:U\"\n",
      "batch 20688  loss=174.2710  steps/s=95.10  prediction: \"e soda\n",
      "\n",
      "actually nvm this one tastes meh\" => \" io eamenhe  o ee\n",
      "ayl  a \n",
      "  tl tlis  tem\"\n",
      "batch 20689  loss=197.7613  steps/s=16.47  prediction: \"ost: RT @Saraht0n1n: research is fractal\" => \"rt:oaa m ad  eaee\n",
      "ayl  a t  tl tlis  sem\"\n",
      "batch 20690  loss=175.1019  steps/s=109.53  prediction: \"locking @ludwigABAP circleboard!?!?!?!?!\" => \"ywe ene@o @ @e @idlAlA AAAAAPc  Ars!?!?!\"\n",
      "batch 20691  loss=175.8522  steps/s=86.17  prediction: \"ore descriptive titles for the rest lool\" => \"re ee  ienre \n",
      "erit tii iit  d tirt ti er\"\n",
      "batch 20692  loss=174.0482  steps/s=99.05  prediction: \"rong tho, my confidence is only like 70%\" => \"egitlaenesars.tdwh.d.x.lw,bdb,bmr,u.d7,%\"\n",
      "batch 20693  loss=169.2029  steps/s=89.34  prediction: \"ns the returns are high on more of it :)\" => \"   r diilon\n",
      " hn chl,wgwhuralywrwcfkgu0oðŸ›‘\"\n",
      "batch 20694  loss=182.3758  steps/s=92.85  prediction: \"i target GL TEXTURE MIN FILTER GL LINEAR\" => \"nhoale er errrteet  tTETETTTETERETLILRRI\"\n",
      "batch 20696  loss=172.3671  steps/s=10.83  prediction: \"reply: @gizmobly https://t.co/dgCgB3AN81\" => \"eply: @  nm  L  GXRXRXRURNrNINXFGLGLMTUU\"\n",
      "batch 20697  loss=177.1410  steps/s=103.93  prediction: \"custom extension to watch yt on 4x speed\" => \"hreM  y ahgugMnaGTxmr:x/wxIw/EgCcxwA4c44\"\n",
      "batch 20698  loss=172.6957  steps/s=87.31  prediction: \"ng cd /;sudo rm -rf * and pressing enter\" => \"  ly ((l re o;et/;p-gy-*)/-;hp*/;md-g/hg\"\n",
      "batch 20699  loss=173.6899  steps/s=86.24  prediction: \" set at 5mins by default when unblocking\" => \"tui dtiwdidt  e  st t it5  at e  aaa b w\"\n",
      "batch 20700  loss=156.4805  steps/s=95.00  prediction: \"ideo editor I posted earlier\n",
      "took 20mins\" => \"ne e   ke ete  ted  eedede   rd eo too e\"\n",
      "batch 20701  loss=167.0905  steps/s=104.11  prediction: \"ntinuations lol\n",
      "\n",
      "https://t.co/ulcMU11Nuc\" => \"  so  inrs   A uywkmbAI:kfk.vwh:g:A:k.I.\"\n",
      "batch 20702  loss=174.9341  steps/s=63.31  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" nu a A rh e le ywbmb:/:k.k.vwh:MU1UN929\"\n",
      "batch 20704  loss=181.2191  steps/s=98.69  prediction: \"it dude\n",
      "Im hyped to see how it turns out\" => \"ns      tese  de hded ttd sethto httos c\"\n",
      "batch 20705  loss=172.1136  steps/s=92.98  prediction: \"f\n",
      "\n",
      "maybe one day ill have pink cubes too\" => \" \n",
      "l   i mzll \n",
      "t yphmb\n",
      "vmfbbgsplfsfvvmvpv\"\n",
      "batch 20706  loss=165.1444  steps/s=96.06  prediction: \"this the more you will see it everywhere\" => \"he  oeetnenesr tvukkkbbktbigkpgysw\n",
      "wwvyr\"\n",
      "batch 20707  loss=178.1299  steps/s=94.05  prediction: \"\" and idk what that is? Time to learn it\" => \" apio\"\"  ih ada d a s  dah t hhst attiie\"\n",
      "batch 20708  loss=167.2334  steps/s=85.44  prediction: \"he going gets tough, the tough get going\" => \"ers  n  n n  eethet g g  g  e ttt ghg gg\"\n",
      "batch 20709  loss=169.2897  steps/s=89.08  prediction: \"eel free to run ideas by me whenever btw\" => \" d a  , r  f e   eetef   ree e ee  eeeee\"\n",
      "batch 20710  loss=174.9397  steps/s=91.48  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"g er r hoint d  wvvicwIc:v:ykgov:mVC:g\n",
      "n\"\n",
      "batch 20711  loss=193.1703  steps/s=84.28  prediction: \"mobly @covix2772 https://t.co/zm76Rx2XNl\" => \"erl  bteran  dWzzvzxr:/c:oxi.772omRIzgz6\"\n",
      "batch 20712  loss=194.4554  steps/s=51.43  prediction: \" @ineedtolocking https://t.co/9ler2RdWf9\" => \"tgoz n  zgloo2  2772ip2:22t.cot:t/6./R6R\"\n",
      "batch 20715  loss=175.8479  steps/s=97.37  prediction: \"ttler experimentation games are the best\" => \"hl   ir ol   d  oxbxpb:/vo.i:/977929XWN9\"\n",
      "batch 20716  loss=169.5785  steps/s=90.42  prediction: \" better solution\n",
      "https://t.co/9xKSI6Oj1y\" => \"te  h Dt     tb t io tthotetth t//ttotK9\"\n",
      "batch 20717  loss=177.6398  steps/s=94.23  prediction: \"ay simpler, but also much more effective\" => \"n   t e ds mt es ip s ,so, m mulo uuromo\"\n",
      "batch 20718  loss=170.2628  steps/s=70.26  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"pap on opl e tbs  o loa  u m ms esfsmeft\"\n",
      "batch 20719  loss=173.4187  steps/s=90.79  prediction: \"potential. then one day, it all explodes\" => \"lnt  ntde ie u afpng\n",
      "wp.dn.,ps...l.hw,oy\"\n",
      "batch 20720  loss=165.1758  steps/s=95.43  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"eua sb eoin ale pbmcmkwwb\n",
      "lpy6yfdocbw\n",
      "bs\"\n",
      "batch 20721  loss=174.3620  steps/s=84.90  prediction: \"Simple p5. Will look into matter though.\" => \"pnphe apa ppte l leWrte lo toeet  rt euu\"\n",
      "batch 20722  loss=176.4257  steps/s=91.66  prediction: \"ls similar to me\n",
      "larger battery capacity\" => \"y r einisit  aeell s slslf tar r erate r\"\n",
      "batch 20723  loss=172.8394  steps/s=91.98  prediction: \"e exposure therapy and learn more abt it\" => \" ahoot t  trt ogr pohexpypr p p er   art\"\n",
      "batch 20724  loss=173.5275  steps/s=85.71  prediction: \"ng to close your eyes to and just listen\" => \"d  obl xm0rn_bt buxr_ybybhdglcbnjlundcjm\"\n",
      "batch 20725  loss=176.0558  steps/s=95.83  prediction: \"f w gpt 5 access\n",
      "https://t.co/FKc0S1iFhu\" => \" t aaeethtn ofeehu5kM55TI:I5j\n",
      "5K:FK::/y.\"\n",
      "batch 20726  loss=166.3869  steps/s=93.30  prediction: \" new meta\n",
      "dont think too hard about that\" => \"@ot io oti itnt n  tien nt nh tno tothtt\"\n",
      "batch 20727  loss=164.4272  steps/s=87.92  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"t   ae  n e nnnn  a etineet e ea------- \"\n",
      "batch 20728  loss=172.4353  steps/s=93.92  prediction: \"DLR but could just be forward/left/right\" => \"oMioxn ren o eu R iu b bu bubu be e ot o\"\n",
      "batch 20729  loss=167.9185  steps/s=95.52  prediction: \" eu would lose half its talent overnight\" => \"tvee  mo lo l re el  e le e e lale e l l\"\n",
      "batch 20731  loss=175.6103  steps/s=88.56  prediction: \"o church\n",
      "Starting everything immediately\" => \"npeto eo oo   ntc  etr hnc trarrtinige i\"\n",
      "batch 20732  loss=178.6255  steps/s=90.01  prediction: \"e in milan venice florence.. sorrento rn\" => \" toe \n",
      "l b\n",
      "w e  e\n",
      "ii lmnion  c.il n nne  \"\n",
      "batch 20734  loss=166.3718  steps/s=89.93  prediction: \" different distribution of training data\" => \"tov  ve   t e eeeef fttrtr i tiiifiin ni\"\n",
      "batch 20735  loss=164.4101  steps/s=94.43  prediction: \"ould color their pill white for the lolz\" => \"n e ten c c  orot r ohlr hoi t iir r ti \"\n",
      "batch 20736  loss=172.7171  steps/s=90.05  prediction: \"us example like this for numerous toolsâ€¦\" => \"st t l aerm \n",
      "  mumelmale e leme  e  eeoe\"\n",
      "batch 20737  loss=171.9772  steps/s=96.75  prediction: \"ten me\n",
      "\n",
      "complex analysis is so damn cool\" => \" rm   a   e lh skakkhhfhioxo\n",
      "nagxpfnxmxs\"\n",
      "batch 20738  loss=169.9737  steps/s=87.79  prediction: \"nt get too random with high stakes stuff\" => \"   e eihsna ae bkbxbhybâ€ybxp\n",
      "]bdan^nawwðŸ›‘\"\n",
      "batch 20739  loss=176.8241  steps/s=91.49  prediction: \"s\n",
      "\n",
      "been doing this over half my life now\" => \" \n",
      "e   t% n tee  esst  sein iie  hhi n ie\"\n",
      "batch 20740  loss=169.1806  steps/s=89.63  prediction: \"y, gpt 4o was bad at the first iteration\" => \"  \"haet\"lao  l t 4lt  4 tai t a   tr  at\"\n",
      "batch 20741  loss=170.0663  steps/s=75.93  prediction: \"ler i wish it tasted as good as it looks\" => \"y?t  olneao  w wa t  t  tat d as tt i it\"\n",
      "batch 20742  loss=173.8462  steps/s=86.71  prediction: \"eed you on my side during the robot wars\" => \" d o stbn\n",
      "a  eo ooe\n",
      "onnonon de dn onde r\"\n",
      "batch 20743  loss=165.3034  steps/s=91.01  prediction: \" talking drains your energy for building\" => \"toie  dad  aia nk dd a an   e  r  er r r\"\n",
      "batch 20744  loss=179.1693  steps/s=34.04  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"y: @k daddlaiai k d  a an r e  an or r r\"\n",
      "batch 20745  loss=189.3619  steps/s=94.41  prediction: \"fects the rest of the day. Cheers brotha\" => \" wh  cohtth  hinkvvkfvcfeccC..CC.CCk\n",
      "drm\"\n",
      "batch 20746  loss=184.3416  steps/s=86.74  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \" ng ref e  e aotxsgsgxfxexpxxpxpsxpr\n",
      "yaw\"\n",
      "batch 20747  loss=177.9775  steps/s=99.47  prediction: \"pi key and throw it in the settings\n",
      "done\" => \"lnt o it  aaien irkfd.keyrwnfwrkpdwkhely\"\n",
      "batch 20748  loss=167.9505  steps/s=89.14  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"nl  i kan k  n no it ti  e in t  issi i \"\n",
      "batch 20749  loss=171.0251  steps/s=105.05  prediction: \"llows you to better descend the gradient\" => \"y s  wolrwo  ws olb so soo e seet t s td\"\n",
      "batch 20750  loss=174.6152  steps/s=93.45  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @ ai s an nojiHvxHxHLwhrRLxRLRLxjypf\"\n",
      "batch 20751  loss=171.7225  steps/s=93.35  prediction: \" life during hard times\n",
      "Thank God for it\" => \"tile ieieg yiin lirnrd eirg   rd T GianG\"\n",
      "batch 20752  loss=182.8371  steps/s=97.62  prediction: \"teresting! I'll keep that in mind\n",
      "\n",
      "lets!\" => \" ri   nte 1s,  n!_I'h,d!gI'I'r\n",
      "!cI'fI'I'\"\n",
      "batch 20753  loss=200.1780  steps/s=102.00  prediction: \"1 Suuuper super cool\n",
      "Big RL WONT STOP US\" => \" ouo 1w  aeze  n4SpShngBBTBRurWWNWTNTRSP\"\n",
      "batch 20756  loss=185.3054  steps/s=89.91  prediction: \"uff\n",
      "\n",
      "1. frogbrot https://t.co/JfifQf9WWd\" => \"rffofd a   tftt\n",
      "111  f sro// ttot.::/Jtt\"\n",
      "batch 20757  loss=201.5663  steps/s=77.08  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \" M s tssico \n",
      " e APAPCRUDECEs:/J:.cQ.9Lbj\"\n",
      "batch 20758  loss=200.9765  steps/s=100.84  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"x 4MT1A0 h0 eeetE@bobn.:.cpsujsjH5H/PI/j\"\n",
      "batch 20759  loss=164.6747  steps/s=89.67  prediction: \"neMTB i dream in ai generated js slop :/\" => \" MTB @nc \n",
      "B TCniEfroan/ancpsujsjLpopjvvj\"\n",
      "batch 20760  loss=170.8355  steps/s=95.57  prediction: \"yping on the terminal bc it looked cool)\" => \" e   tn ti t   t  in nen t n t   tntei  \"\n",
      "batch 20761  loss=166.4982  steps/s=92.37  prediction: \"ol shit way more than alcohol and gaming\" => \"  l  nil cel   d  a i n io oh   olh haa \"\n",
      "batch 20762  loss=175.7671  steps/s=89.25  prediction: \"y started pushing the boulder 5x as much\" => \" ch aa  eaie eds tadeerhted hte  e t e  \"\n",
      "batch 20763  loss=192.2274  steps/s=25.51  prediction: \"ply: @ludwigABAP to succeed, help people\" => \"ly: @teg  dny s yrgyahpagmpddpby5ytgs55x\"\n",
      "batch 20764  loss=195.1945  steps/s=97.17  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nn rn ieian i # #aennn dtsdainn  /tt/t8/\"\n",
      "batch 20765  loss=187.0263  steps/s=87.65  prediction: \"echo4eva @us_east_1_ i love lex friedman\" => \" tnaeneng @@@ nee_e_s__ _at1t 1   ttitvd\"\n",
      "batch 20766  loss=168.5086  steps/s=91.71  prediction: \"en get way too absorbed into one of them\" => \"   o  getet   tt  oet o   t o  ot oooe  \"\n",
      "batch 20767  loss=177.2979  steps/s=34.77  prediction: \"ly: @kair0smtc I made them all permanent\" => \"y: @  nne e   t   oat o obb o  ot  ooe  \"\n",
      "batch 20768  loss=169.6320  steps/s=114.67  prediction: \"qc Based, a true warrior of the zig army\" => \"2 3e4o ei@d   ntt ta tooa r oo or  tee  \"\n",
      "batch 20770  loss=167.6667  steps/s=92.17  prediction: \"r these very cool words. well said, dang\" => \"ette   o   ho n uhuvfvyfcvwovhthkyy.y.wy\"\n",
      "batch 20771  loss=165.2219  steps/s=40.01  prediction: \"y: @atris_eth even x isnt headwaters yet\" => \": @ toethere e  e y yt toer  re s leds  \"\n",
      "batch 20772  loss=178.9459  steps/s=116.00  prediction: \"nch lobotomies are back in style baby  ðŸ˜Ž\" => \"dh au  n rono tlveuwxrxecvwovhb.d,dc..sn\"\n",
      "batch 20773  loss=171.1214  steps/s=85.46  prediction: \"ting the entire GOL industry as we speak\" => \"hn)ko   c rlom  IbswbGbLntcGOLGOLGOLOLGO\"\n",
      "batch 20774  loss=164.6810  steps/s=88.83  prediction: \"d useful stuff better with the new tools\" => \" ms f lufuolfus ffu ttuf   utt f  tef te\"\n",
      "batch 20775  loss=179.1601  steps/s=18.81  prediction: \"eply: @BuxdahMo its not the real discord\" => \" ly: @lufu lfusfffu ttuf   utt    tef te\"\n",
      "batch 20776  loss=165.2513  steps/s=129.05  prediction: \"you should do sidetweets with the aliens\" => \":u nsu se llo  tutdl t e  dett ee weotst\"\n",
      "batch 20777  loss=163.5797  steps/s=61.31  prediction: \"justalexoki the t has always meant taoki\" => \"ustso tul  t  ststd eswe wseetheese ttst\"\n",
      "batch 20778  loss=169.4948  steps/s=109.47  prediction: \"he thing, no? All you need is prediction\" => \"e @ r te ti ono , oe t lA non e o l  el \"\n",
      "batch 20779  loss=173.7370  steps/s=93.29  prediction: \"air they do have the best premove system\" => \"nn ife  y t ilhaoe t  e eythe ee t t ept\"\n",
      "batch 20780  loss=172.6996  steps/s=88.56  prediction: \"at large scale\n",
      "\n",
      "Adventure beats hedonism\" => \"ne s eeln  reel  a eee le eetee eeteetee\"\n",
      "batch 20781  loss=187.7892  steps/s=96.04  prediction: \"\n",
      "get_cracked() in log project complexity\" => \"\n",
      "ahh ion eceastnb_g()()__()jk()()gjp\n",
      "gjb\"\n",
      "batch 20782  loss=194.7149  steps/s=90.50  prediction: \" TOP 5% LETS GOO https://t.co/BVY64DK9O7\" => \"@heetaeta  ee   OT TOGOO  t   /// ////VV\"\n",
      "batch 20783  loss=173.1970  steps/s=91.37  prediction: \"aw of undulation https://t.co/VdFFnrRkLH\" => \"ne do   en t Lw   \n",
      "o  n aa    t tt/o/Ft/\"\n",
      "batch 20784  loss=172.2429  steps/s=93.85  prediction: \"l, titan, stable diffusion, a few others\" => \"y b ions t it tt,,te ,aal, afisi, s,f ii\"\n",
      "batch 20785  loss=173.1171  steps/s=92.92  prediction: \"morrow, hope it goes well for you brotha\" => \"ade a  a m h  etmfwywwwvhypvi,wg\n",
      "ghbpcyb\"\n",
      "batch 20786  loss=171.7587  steps/s=87.51  prediction: \" can instantly runit w the runit command\" => \"aoo s  e nnnsnson  s  n nt tan n   o t n\"\n",
      "batch 20787  loss=161.9054  steps/s=86.80  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: i sss seeessn el   nn lei.l..l .lleee\"\n",
      "batch 20788  loss=158.2725  steps/s=84.05  prediction: \"n in the ass to get it to stop shuffling\" => \"daae eevrdeoitvtw.IvQIoIdcbpd.bwmcawdfbp\"\n",
      "batch 20789  loss=167.2741  steps/s=89.10  prediction: \"cise or anything else prevent this loss?\" => \"hn    eung ici ohN?xxmycuUxgx?idp`xvdv?ðŸ›‘\"\n",
      "batch 20790  loss=167.3989  steps/s=98.39  prediction: \"write all of dingboard in zig @crypt0x_0\" => \"oi a Bnt tc i ntvtlxyrpcvvxzrbz@of@vzvzðŸ›‘\"\n",
      "batch 20791  loss=163.4541  steps/s=83.04  prediction: \"but i followed just in case you do pivot\" => \"ethh  or      f o  o   uolo  o   o i  oo\"\n",
      "batch 20792  loss=168.4217  steps/s=87.33  prediction: \"se? seems like death spiral potential no\" => \"  en rre seeeee  eeese  e es easeapialee\"\n",
      "batch 20793  loss=171.1094  steps/s=89.17  prediction: \"ways but in many cases it holds you back\" => \"os e alotn  we  .nsmbfwrybi.ulw..w.ysyby\"\n",
      "batch 20794  loss=175.5483  steps/s=86.25  prediction: \"makes it an order of magnitude harder...\" => \"agr  asess o eonybyynfkudk\n",
      "tofncygdkvuky\"\n",
      "batch 20796  loss=175.3461  steps/s=33.96  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y  @i noia  i i a  n i   atitoane ia    \"\n",
      "batch 20797  loss=171.9077  steps/s=92.99  prediction: \" component that approximates transformsâ€¦\" => \"tonee t  hwt oennnet tta ppppopaopttaota\"\n",
      "batch 20798  loss=168.6923  steps/s=88.17  prediction: \"mple py script manages building/updating\" => \"alt p  a    iet lvvyvwvvifp\n",
      "mgcr\n",
      "bc]pavv\"\n",
      "batch 20800  loss=171.8291  steps/s=83.90  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \" n  pntosybc taelSgySgSfibbOmg/Og// paOðŸ›‘\"\n",
      "batch 20801  loss=172.8524  steps/s=89.67  prediction: \"ool looking games, and get more interest\" => \" l e lcol eo lol  loossno g g m m g   nn\"\n",
      "batch 20802  loss=166.7693  steps/s=91.28  prediction: \"e some exciting long term vision then no\" => \"rao  dtt  n e ene  tot  o t to e ni i en\"\n",
      "batch 20804  loss=184.6917  steps/s=86.42  prediction: \"fects the rest of the day. Cheers brotha\" => \" nmo oohtthe  inkvgkgyffyscy..CC.CCk\n",
      "y.w\"\n",
      "batch 20805  loss=174.7361  steps/s=85.09  prediction: \"new super super early on she was the one\" => \" M rece  t b i kwkhmgvdupkwbwbpyrirdybkm\"\n",
      "batch 20806  loss=167.3761  steps/s=88.11  prediction: \"d it! Lmk how it goes man. Hope it helps\" => \" bni sie li   n  o   k   i i       H   o\"\n",
      "batch 20807  loss=166.0861  steps/s=96.28  prediction: \"ything rewarding that follows from that)\" => \" iiaaiiegh ae r ginghaing rrgra aa twaal\"\n",
      "batch 20808  loss=166.9246  steps/s=90.89  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   t she   h     h oc  coiiocoi ooi \n",
      "o t\"\n",
      "batch 20809  loss=168.1572  steps/s=88.26  prediction: \", how do WE figure out where things are?\" => \" so  ienni o  o WoW  oooie oee   o e   h\"\n",
      "batch 20810  loss=177.2039  steps/s=18.55  prediction: \"eply: @arno_gn acct seems cool, followed\" => \" ly: @in   o  w WoE  ooo e oee   i e   h\"\n",
      "batch 20811  loss=170.5290  steps/s=98.74  prediction: \" elon keep going once they have billions\" => \"tve  pi   pe    ee   eege  neg  e e hh  \"\n",
      "batch 20812  loss=168.6849  steps/s=89.69  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"nt  n en n  n i  a iii izi/  /://::///XB\"\n",
      "batch 20814  loss=166.7074  steps/s=88.85  prediction: \"ast 3 weeks so development has been slow\" => \"n     o no n tte e e s  o ee  s s see  n\"\n",
      "batch 20815  loss=172.2907  steps/s=92.83  prediction: \"\n",
      "just put work into improving the basics\" => \"\n",
      "er iwen mil  mnb7brkcvbm-'-'-'yvbj-j-j'\"\n",
      "batch 20817  loss=168.7375  steps/s=90.32  prediction: \"o him) and he begged to pay me to use it\" => \"nao   ttt i    n) )h  te ge d gg d  te o\"\n",
      "batch 20818  loss=168.2426  steps/s=92.82  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" \"o e tare   l  ev n eo o iolel  eiDeDDe\"\n",
      "batch 20819  loss=170.4242  steps/s=98.71  prediction: \"t your iq has to be under 70 or over 170\" => \" tut  astaio iasqeh qbuqmfq.\n",
      "70qbl70sd70\"\n",
      "batch 20820  loss=174.2188  steps/s=94.47  prediction: \"ective, its significantly more efficient\" => \" ost t al  e s i , sis stins ii eiti  if\"\n",
      "batch 20822  loss=181.7950  steps/s=89.65  prediction: \"s, have back and forth conversations etc\" => \"  pr a a cas  s ah aroh  a  nrohv  nv ct\"\n",
      "batch 20823  loss=169.5800  steps/s=98.89  prediction: \"term, informative/useful is more memetic\" => \" r e tn  loer n ib,/l,fvk/a/mnh/u,/dsot,\"\n",
      "batch 20824  loss=167.2343  steps/s=95.76  prediction: \"ld me, no clue lool\n",
      "\n",
      "its good to be back\" => \"y   e e mte e,m n  e  oltololo \n",
      "oo\n",
      " o  o\"\n",
      "batch 20825  loss=171.7696  steps/s=95.93  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"   o  do no  ou  l yl olndoonl  \n",
      "oN\n",
      "ree\n",
      "\"\n",
      "batch 20826  loss=177.0115  steps/s=91.25  prediction: \"ed in joining, repeat these instructions\" => \"  e  retneteintete tij  re in nnitrerest\"\n",
      "batch 20827  loss=182.7708  steps/s=93.80  prediction: \"ice didnt know they made it that low, ty\" => \"ntet  ee f cd a  nntc n hene dndi  ttttt\"\n",
      "batch 20828  loss=170.3486  steps/s=92.46  prediction: \"es\n",
      "\n",
      "in many more contexts than just this\" => \" teprrpen   or tepo\n",
      "e\n",
      "\n",
      "tirmn e mo text x\"\n",
      "batch 20829  loss=170.7280  steps/s=93.77  prediction: \"ang out in tunisia every once in a while\" => \"n  e r tn n ntt  na i nt tininie inn i i\"\n",
      "batch 20830  loss=166.1314  steps/s=95.19  prediction: \"e did not seem like the type to work out\" => \" ro r hn aeo tf  id d e   eie di ee eoe \"\n",
      "batch 20831  loss=186.8383  steps/s=88.33  prediction: \"eople want. Nowâ€ https://t.co/yxXaaiHzQ1\" => \" ri enhnie e ee ee N NNNâ€â€â€â€/o.. //t/.//\"\n",
      "batch 20832  loss=174.9355  steps/s=93.72  prediction: \"aster i u know its just abt authenticity\" => \"n  t bat t gnui i itr   u  u t attt i t \"\n",
      "batch 20833  loss=174.9290  steps/s=89.38  prediction: \"g us calculate costs some weird jank way\" => \" t a it  rao  m mdhmhkdakf\n",
      "mrcapcdlkjCjt\"\n",
      "batch 20834  loss=168.2909  steps/s=97.79  prediction: \"onna think in terms of utility and price\" => \" e  moentamnn h nt tn nn  n  i  m  i  tt\"\n",
      "batch 20835  loss=177.9980  steps/s=87.12  prediction: \" ...but will it work, thats the question\" => \"tns unou n...tet t t  t ot t  t kt ttqtt\"\n",
      "batch 20836  loss=178.1609  steps/s=94.27  prediction: \"you beat the 20hrs guys 100% of the time\" => \" u aont moa       a at u 0thth0u101 0%% \"\n",
      "batch 20837  loss=176.2570  steps/s=95.24  prediction: \"houghts on this\n",
      "\n",
      "https://t.co/BV7iOyFnzq\" => \"eu oo  inew    os th oho ishshth  ho/:VO\"\n",
      "batch 20838  loss=180.3239  steps/s=94.62  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \"  isaa   s n aiaias\n",
      "tt  dy iysa\n",
      " neey o \"\n",
      "batch 20839  loss=173.1758  steps/s=52.13  prediction: \": @Wooltard @paulg Or better compression\" => \" @talri ni el tlHdcHwOkOpfrcp,dalcly,mfy\"\n",
      "batch 20840  loss=163.4550  steps/s=100.21  prediction: \" and the quote tweet is the reply itself\" => \"t qtthe tq tt t e t  tu ett e tte   e te\"\n",
      "batch 20842  loss=172.3851  steps/s=101.97  prediction: \"cting statements, they cease to conflict\" => \"oit     se i gi gfcxcfemh,cghseyuffo,mf,\"\n",
      "batch 20843  loss=167.8391  steps/s=81.84  prediction: \"ng that solves a problem you're close to\" => \"tlyceths ry  omsgf,vc,rmyvc'bhvm'val'mvb\"\n",
      "batch 20844  loss=163.9002  steps/s=93.72  prediction: \"verything app\n",
      "may take like a decade tho\" => \"ery eenl tne ehtt e eaa a aa  kaea a ea \"\n",
      "batch 20845  loss=181.1778  steps/s=91.05  prediction: \" going straight there out of highschool)\" => \"teat  a   n tihng ear t ttg h r  oie  oh\"\n",
      "batch 20846  loss=178.3849  steps/s=94.05  prediction: \"actually protects me from getting hacked\" => \"niy5    n  c  y  ac   tct o    mtttmc tt\"\n",
      "batch 20847  loss=170.4594  steps/s=93.24  prediction: \"f lol. but ppl jump at the local optimas\" => \" lhnr g   atf bogfgbul.kbpijjmkfjfjub..b\"\n",
      "batch 20848  loss=175.0950  steps/s=93.12  prediction: \"st? I believe Jesus gave us the playbook\" => \"  u  mi   t i t e  iei JJ se uevee e  e \"\n",
      "batch 20849  loss=184.6159  steps/s=31.90  prediction: \"ply: @Aryvyo yup https://t.co/4dtcUwcmOS\" => \"ly: @an  e  tas JxIJIJv:,JhvJ?JIkprUy?vp\"\n",
      "batch 20850  loss=165.1722  steps/s=112.65  prediction: \" cs maps btw? would love to see pictures\" => \"toy      oa o    so       o s  o o  oo  \"\n",
      "batch 20852  loss=167.3436  steps/s=100.76  prediction: \"usually good metrics, good feedback, etc\" => \"st n o to g     lol touoogtol go s good \"\n",
      "batch 20853  loss=168.1610  steps/s=90.34  prediction: \"een\n",
      "always will be\n",
      "The signal is\n",
      "utility\" => \" llas ene waaw slwlla e wlll l ei l lils\"\n",
      "batch 20854  loss=170.8186  steps/s=87.36  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e o@ tiitg uoeeoMdBMA,mAyb,:Th,dw::9:.QC\"\n",
      "batch 20855  loss=165.6687  steps/s=90.50  prediction: \"o my head\n",
      "\n",
      "empirical blog posts are king\" => \" geile n t  ien ehe ee i il po eopoi ooa\"\n",
      "batch 20856  loss=168.2561  steps/s=97.47  prediction: \"ed, neuron connections atrophy, so yourâ€¦\" => \"   iintetti, een ,et en  ennonnentnon so\"\n",
      "batch 20857  loss=169.6440  steps/s=93.99  prediction: \" its a sign you should make react in zig\" => \"tn itnwAg i A  n son out onuooheotc  a r\"\n",
      "batch 20858  loss=168.2233  steps/s=96.50  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \"hkne n@ot bc tiecSycShSipdwpayoOh,ycwkOf\"\n",
      "batch 20859  loss=171.9136  steps/s=92.08  prediction: \"to the planning phase with more momentum\" => \"h a edke n  i esgo,mamkdsbwbkhpcppksw/wd\"\n",
      "batch 20860  loss=218.3454  steps/s=88.21  prediction: \"VITATE THE BOATS https://t.co/EnvmksQfpc\" => \"apY   EO  OVNGA EVIHETHEATSATSEmS:AT:.O:\"\n",
      "batch 20862  loss=171.9044  steps/s=91.23  prediction: \" set an alarm\n",
      "dang id love that gene lol\" => \"@o esnt@ el a  saa a  nn  ad   a  t an  \"\n",
      "batch 20863  loss=165.0478  steps/s=88.97  prediction: \"unning hack.exe twitter -unban --dnbt777\" => \"sss a aon e nnnn  a n en e tett t------ \"\n",
      "batch 20864  loss=170.5204  steps/s=89.46  prediction: \". but idk thats just my weird take on it\" => \" i h tb eah h  n.djldjvbjvjvdjykj.gbhjyj\"\n",
      "batch 20865  loss=179.1712  steps/s=60.86  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"lnnsett eu s tt  h t  t tt  t td ta t it\"\n",
      "batch 20866  loss=167.9647  steps/s=93.77  prediction: \"our life if you make work look like this\" => \"u daa   rn re r ff y fo yo ik kouo ikokk\"\n",
      "batch 20867  loss=174.0000  steps/s=88.54  prediction: \"ooks like from someone elses perspective\" => \"u hanen  ti e le  uom meo m s ee esoso e\"\n",
      "batch 20868  loss=201.8878  steps/s=18.52  prediction: \"eply: @crypt0x_0 sharif didnt like it :(\" => \" ly:  t     e  k  mom meo m s ee esoso e\"\n",
      "batch 20869  loss=166.1783  steps/s=94.81  prediction: \"this is the same as the place where theâ€¦\" => \" it  n i e t  enfbflab.,kdmp..d..n.w.ymi\"\n",
      "batch 20870  loss=169.7768  steps/s=84.76  prediction: \"feeling than automating hrs of work away\" => \" r n not e   el fggifglpfauemwc.mngwrgâ€¦ðŸ›‘\"\n",
      "batch 20871  loss=170.2206  steps/s=91.37  prediction: \"re obvious. some are really hard to see.\" => \"e l   nlt   s  ivv.wsdbvyfub.cbvm.uylm.d\"\n",
      "batch 20872  loss=176.8732  steps/s=83.72  prediction: \"the funny number https://t.co/KCUFeujsbJ\" => \"heno st ewe  i  yi.wy.bfyfuw:p::/U:yKCKK\"\n",
      "batch 20873  loss=181.3029  steps/s=82.47  prediction: \" off with a basic template and modify it\" => \"tf tiot  tn i  f  bib f bpspitaseasa dem\"\n",
      "batch 20874  loss=182.0110  steps/s=90.01  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltee naon seop swlfpkpwwrkpkcnskkoislgp\n",
      "\"\n",
      "batch 20875  loss=182.0661  steps/s=81.16  prediction: \"ks!! Yeah pretty scummy. But we survived\" => \"e   oe s!s   a! ! ieo    sm tB te  B u  \"\n",
      "batch 20877  loss=184.1660  steps/s=89.30  prediction: \"ork\n",
      "Until it did https://t.co/nY6zvVWYaH\" => \"u :ed  t pn nt  tiiddid ttdn/tt t//:Y6Y6\"\n",
      "batch 20878  loss=167.5313  steps/s=88.59  prediction: \" drag down/demotivate other team members\" => \"to   d de d d d do dodeeood ae  tetotm a\"\n",
      "batch 20879  loss=170.6723  steps/s=93.15  prediction: \"ts good for helping u learn patterns inâ€¦\" => \"  e\n",
      " nef r da   skkup,k,,h,,pi,,fc,,hfoo\"\n",
      "batch 20880  loss=191.8938  steps/s=88.53  prediction: \"OOYAH\n",
      "gl brotha\n",
      "Gonna join you in 6hrs ðŸ«¡\" => \"O vBOn,eleYOOOgYHlg     orno  a a  nn   \"\n",
      "batch 20881  loss=182.6653  steps/s=20.01  prediction: \"eply: @tszzl &gt; the present will\n",
      "how??\" => \" ly: @ne eYOOOe Hlg    Gorno  a a  nn   \"\n",
      "batch 20882  loss=188.0550  steps/s=119.82  prediction: \"eCachet Consistency is a deadly strategy\" => \" tfet@ l{{}A&CosGno   r oeno  a a  r   ðŸ«¡\"\n",
      "batch 20883  loss=185.8814  steps/s=91.65  prediction: \"ex Only if you get a lobotomy afterwards\" => \" pfnte tnhlOxgi  y i  y  e a  o i yoay y\"\n",
      "batch 20884  loss=171.7583  steps/s=94.07  prediction: \" the past two months and its so worth it\" => \"thi tot oae ttetot t tt   t o ots t s   \"\n",
      "batch 20885  loss=174.4790  steps/s=90.77  prediction: \"etting about them, is a v common mistake\" => \" ts o tg ntoegetano  o,i,e, ioe it t mmo\"\n",
      "batch 20886  loss=173.1553  steps/s=89.00  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tn o s  l   oggg iz\"\"\"\"iiiii  i ei i i i\"\n",
      "batch 20887  loss=196.6046  steps/s=79.10  prediction: \"072 im super glad man! love to hear that\" => \"x Eaxi@eteze07enB,,MwrMBvvBs!tz!n!bvozht\"\n",
      "batch 20888  loss=171.3209  steps/s=89.47  prediction: \" this technology https://t.co/9gpz6ovdrc\" => \"@hi asal e tete  ote oh t th h/t/////999\"\n",
      "batch 20889  loss=161.7159  steps/s=88.88  prediction: \"n while still being consistent each week\" => \"gthoeest ety jrnXwjwv\n",
      "pj\n",
      "bj6mbmbnjpg\n",
      "Xv\n",
      "\"\n",
      "batch 20890  loss=170.3531  steps/s=85.43  prediction: \"r switching if mint doesnt serve me well\" => \"etgi   ons ae.l dw.wc.uj\n",
      "dffmfwp.d.wffkm\"\n",
      "batch 20891  loss=173.0966  steps/s=91.27  prediction: \"s, but eventually this catches up to you\" => \"  n   bde nt aeenl el uteee t ulleetst a\"\n",
      "batch 20892  loss=186.7600  steps/s=86.78  prediction: \" job adding the australian language pack\" => \"tudeil  t0ena_l nl jld adcinc tu  e suua\"\n",
      "batch 20893  loss=176.4302  steps/s=87.09  prediction: \"ective, its significantly more efficient\" => \" ortrt al  epa ite sis stins ti eitit if\"\n",
      "batch 20894  loss=171.4545  steps/s=97.15  prediction: \"otential for small - very small things.â€¦\" => \"n    tlot nttoot la f   sl al l   a a   \"\n",
      "batch 20895  loss=160.9338  steps/s=102.73  prediction: \" front end. i want minimal backend stuff\" => \"toi d t     e enn   e    e inni in   in \"\n",
      "batch 20896  loss=178.1591  steps/s=89.73  prediction: \"ks suuuuper well\n",
      "https://t.co/kQAcIS3etz\" => \" ,ww nnnis ruu oese  esutept p/l/tQsQtQQ\"\n",
      "batch 20898  loss=169.8302  steps/s=92.33  prediction: \"stead of just knowing what they were, Iâ€¦\" => \"  n mvnatete (  eoneje j se tt e wt w tw\"\n",
      "batch 20899  loss=173.8559  steps/s=75.86  prediction: \"eMTB i wonder which anime pfp is his alt\" => \" TBnm@can  e Ti eono d t at tt we t wh s\"\n",
      "batch 20900  loss=176.6181  steps/s=88.05  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"r et  th  w    th   e h t  t /ht// t/t /\"\n",
      "batch 20901  loss=168.5135  steps/s=93.70  prediction: \"ment it with all the details that pop up\" => \"ene in to  d t  nb'nbgwwtoablwbmh;umpwur\"\n",
      "batch 20903  loss=167.9115  steps/s=90.05  prediction: \" of all time itd be sebby and his 9 alts\" => \"tf     fan o to o   f  loe oe  i   s  e \"\n",
      "batch 20904  loss=169.7312  steps/s=92.28  prediction: \"ingly, doable) youre in for a goood time\" => \"ng  h sovrn yyi rrrry) yr yr yo oo   ooo\"\n",
      "batch 20905  loss=172.4539  steps/s=97.84  prediction: \"problems im overlooking, then solve them\" => \"lob  t on e o n pcvbvfmbfbmg,k,kk,am,nvh\"\n",
      "batch 20906  loss=175.1661  steps/s=89.87  prediction: \"y cool implications, seems like it would\" => \" too ea e    iilo oliiameloso ssessie et\"\n",
      "batch 20907  loss=157.4163  steps/s=89.37  prediction: \"in but u see it everywhere after a while\" => \"ne to srs st    eee t   e e  e e   te e \"\n",
      "batch 20908  loss=159.9767  steps/s=83.34  prediction: \"ki i have an idea but it will cost $1600\" => \" n  teti u   i  eee i  ee i it     t le \"\n",
      "batch 20909  loss=161.6815  steps/s=89.70  prediction: \"e knows what a kernel or text editor are\" => \" koiwe w en wwwe a k  k e  e  r et eer r\"\n",
      "batch 20910  loss=168.4602  steps/s=89.67  prediction: \"it seems like using a spoon vs a scalpel\" => \"n eoo e cereesneis  s il  s s o  nn ae e\"\n",
      "batch 20911  loss=169.6036  steps/s=97.64  prediction: \"ouraging way, not stressful for the kid)\" => \" ld  nginhnini nnug ngnug nun aanus ters\"\n",
      "batch 20912  loss=169.2559  steps/s=101.04  prediction: \"otential for small - very small things.â€¦\" => \"   o tlot nottot la f   al -l l s a a   \"\n",
      "batch 20913  loss=165.5337  steps/s=91.15  prediction: \"resent them in (i.e. \"jimmy shot a ballâ€¦\" => \"epln aoa  re a tyb(bmsb(\"(p.f(j(j.(\"j\".m\"\n",
      "batch 20914  loss=176.6594  steps/s=90.46  prediction: \" right now its just learning on the side\" => \"ter a agt a   t t n r u r n i n   iog t \"\n",
      "batch 20917  loss=166.5903  steps/s=100.84  prediction: \"is posting a.. oh wait nvm he got banned\" => \"n   s  r  ss sisp  sis  s  ..  n  a  aa \"\n",
      "batch 20918  loss=169.3546  steps/s=105.36  prediction: \" regarded so take that w a grain of salt\" => \"iedem e\n",
      " ai e na  kr e  e e a e  a t g  \"\n",
      "batch 20919  loss=164.9191  steps/s=89.20  prediction: \"hag_ its good to be on the outside again\" => \"erle dea as   os  to a  a e ata to  eio \"\n",
      "batch 20920  loss=182.9838  steps/s=99.24  prediction: \"de!!! Huge achievement\n",
      "\n",
      "What did u study\" => \" rnenngn  sdd d!!!HHd  ue e aueete  \n",
      " t\n",
      "\"\n",
      "batch 20921  loss=162.9798  steps/s=104.41  prediction: \"e first img generation models rolled out\" => \" ion  ebna i  g   e  e ig n ge  n eelelr\"\n",
      "batch 20922  loss=161.0966  steps/s=102.11  prediction: \"builds mcdonalds just wants to grill man\" => \"et b  bii  ig    ae ta nd nt tt l  ll ll\"\n",
      "batch 20923  loss=166.7913  steps/s=95.59  prediction: \"l tools for myself and they save me time\" => \"yp  ui ooul  ool oof  f lf   fs  se    e\"\n",
      "batch 20924  loss=164.1774  steps/s=89.41  prediction: \"her level abstraction of piece movements\" => \"e t ates tre   rahe at  ee  e  a e oteee\"\n",
      "batch 20926  loss=187.1066  steps/s=85.05  prediction: \"/t.co/hjQfCWaZxw\n",
      "https://t.co/VFbc29W7Ct\" => \"e.co sht ho/ttt ///QQQWCZZZxZZ:t.c./ttVc\"\n",
      "batch 20927  loss=181.1039  steps/s=53.29  prediction: \"@yacineMTB You want us to find our moms?\" => \"yacioe  e s ttt\n",
      "twtht://:hp\n",
      ".VVtVc29W9t7\"\n",
      "batch 20928  loss=186.7349  steps/s=96.32  prediction: \"ock's claude api may not have this issue\" => \"nkc owe sc cae  epa c co   a a e  a  tat\"\n",
      "batch 20929  loss=182.6652  steps/s=91.06  prediction: \"/t.co/nXwXlMr3PT https://t.co/Qtlv9lakAW\" => \"e.VE   V.  t   /PX.3/3X3P/3P:PTt:po:.:o/\"\n",
      "batch 20930  loss=179.6819  steps/s=84.35  prediction: \"nd @notmoeezm Ill read abt it! Thank you\" => \"   P deos  ste  T@Tz@P@tlzm/z.zI/IQ9v!9A\"\n",
      "batch 20931  loss=176.8857  steps/s=77.91  prediction: \"ylde lowkey cant believe zompy said that\" => \":d nainei wody  lol  e a e bt bt  eaa ay\"\n",
      "batch 20932  loss=182.6156  steps/s=87.06  prediction: \"eMTB here you go https://t.co/oR4fVr3TMW\" => \" TB nh  naMyee yey  eoe uh ht /t /ot//o4\"\n",
      "batch 20933  loss=159.5840  steps/s=91.77  prediction: \"agi safety\n",
      "use the agi to defeat the agi\" => \"ri aa @ee  s  t ae  aaee  ate tae  te t \"\n",
      "batch 20934  loss=166.8204  steps/s=93.96  prediction: \"elligence' thing\n",
      "https://t.co/KcKUYwoDYA\" => \" pin tiontte '  e'''ttntnsethtts/cKKKtKc\"\n",
      "batch 20936  loss=175.6534  steps/s=89.43  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly:set  osipl \n",
      "el\n",
      "oyMyck/f4cTwy4w4r44TT4\"\n",
      "batch 20937  loss=188.0103  steps/s=93.25  prediction: \"10^10^10^10^10^10^10^10^10\n",
      "so maybe 2064\" => \"0^10100^0010^^0^^10^10^10^10^10^10^00\n",
      "b0\"\n",
      "batch 20938  loss=173.4755  steps/s=98.59  prediction: \"going into space man its truly beautiful\" => \" t   tdtint e t cpfvpkylthbs\n",
      "afyobky8bed\"\n",
      "batch 20940  loss=163.8683  steps/s=86.66  prediction: \"ng that solves a problem you're close to\" => \"g go ths n  hop cpivcksgtvus\n",
      "uvp'vdl'rvb\"\n",
      "batch 20942  loss=180.1191  steps/s=105.35  prediction: \" going straight there out of highschool)\" => \"tean  ai  n  ihng eht t ttg h r  oie  oh\"\n",
      "batch 20943  loss=171.6467  steps/s=91.70  prediction: \" like this too? They come in pairs often\" => \"tove paen te   toe i ?  oo? isoe eie  ii\"\n",
      "batch 20944  loss=171.7518  steps/s=99.50  prediction: \"f you can read graphs youre already ngmi\" => \" totis njwe toi tTd?yTTnlycikmTghmnydckT\"\n",
      "batch 20945  loss=183.5578  steps/s=85.97  prediction: \"ting seeds\n",
      "\n",
      "exponential growth type beat\" => \"hni r pno antgntxlxslxlxlxcxxuxphnlrgydw\"\n",
      "batch 20946  loss=184.2833  steps/s=96.16  prediction: \"ere @jesx64 never stop having fun either\" => \"   it      se ex4464464 oetpenar hyt ge \"\n",
      "batch 20947  loss=170.4404  steps/s=104.28  prediction: \"orce you to clean to avoid embarrassment\" => \"    ci cno i   t    c e eo  to o  a r  a\"\n",
      "batch 20948  loss=172.7703  steps/s=38.88  prediction: \"ly: @kuberdenis @yacineMTB MAP EXPANSION\" => \"y: @ oceoy c   t t  c   eo  to oara r  a\"\n",
      "batch 20949  loss=179.2161  steps/s=119.77  prediction: \"@sunsettler fight me (i would 100% lose)\" => \"Hunppltee  s   e @ tneet oe oi oi mm me%\"\n",
      "batch 20951  loss=182.3190  steps/s=93.68  prediction: \" be cool to find some other players here\" => \"@eoio c   l d    co odlo le o oe oo e er\"\n",
      "batch 20952  loss=182.4890  steps/s=81.05  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" tolo o ww  ki e s LLzLLzzezo oe oe t re\"\n",
      "batch 20953  loss=177.8948  steps/s=94.76  prediction: \"houghts on this\n",
      "\n",
      "https://t.co/BV7iOyFnzq\" => \"eue oy inezo   oi ghoono ishshts o:o/7o7\"\n",
      "batch 20955  loss=168.1032  steps/s=84.11  prediction: \"ogan?? was he on sidetweets or something\" => \"rgooo jen w??on ? os oe  ew s  e  sose o\"\n",
      "batch 20957  loss=163.2075  steps/s=92.94  prediction: \" cs maps btw? would love to see pictures\" => \"@oye     oa o o  so       o w w  o  o   \"\n",
      "batch 20958  loss=178.9504  steps/s=93.39  prediction: \"ers @iliekcomputers is a p strong player\" => \"   eetentiie nd il ess ikk epp er pus rp\"\n",
      "batch 20959  loss=171.0235  steps/s=94.81  prediction: \"ns you get the yellow letters on lichess\" => \"gera  ie  st ia @kaguhg0x1kchrwMmwypwigw\"\n",
      "batch 20960  loss=169.7858  steps/s=89.20  prediction: \"s large of a positive impact as possible\" => \" Inla  aaaa     ao  a   ai  aiai i sa  p\"\n",
      "batch 20961  loss=165.8347  steps/s=90.13  prediction: \"ideo of you doing some crazy stuff. damn\" => \"ne w e o  to    i  y o oi o  o o s  oo  \"\n",
      "batch 20962  loss=166.1741  steps/s=88.15  prediction: \"oves ahead\n",
      "or 1000 hrs of work ahead\n",
      "etc\" => \"uetep o d     00e oo 11001  h 1  ho0 a h\"\n",
      "batch 20963  loss=166.8557  steps/s=97.51  prediction: \"e seen it from all possible perspectives\" => \" oene is ih net  on   os els llee sospee\"\n",
      "batch 20964  loss=174.2952  steps/s=95.51  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"u  h  th  f  e  hhe wthet  t /ht//et/tx/\"\n",
      "batch 20965  loss=167.9206  steps/s=106.89  prediction: \"t, bc you can edit/delete prompt history\" => \"  r  hcnnchc a  ,g,/,,p,,uy,uy/uy/d/i/dr\"\n",
      "batch 20967  loss=171.5579  steps/s=99.81  prediction: \"n pick your own time though its flexible\" => \" th   aous an  ty////lpicpck/ymuy/rwtgyðŸ›‘\"\n",
      "batch 20968  loss=171.2978  steps/s=89.15  prediction: \"e and @grok both came from that, I think\" => \" ooentoa s a mh eno@ nomm oom  taha a o \"\n",
      "batch 20969  loss=178.0228  steps/s=90.78  prediction: \"\" and idk what that is? Time to learn it\" => \" asin\"n  ih ada dda s  dah t hhTt attiie\"\n",
      "batch 20970  loss=176.6161  steps/s=71.20  prediction: \"odor_io worst metric youve heard so far?\" => \"r ai nddod a  a hht i  TTT t hest ate  a\"\n",
      "batch 20971  loss=165.2227  steps/s=102.16  prediction: \"sts w good content from this perspective\" => \"  s  to t ws so  so  ooo on   tt t t  to\"\n",
      "batch 20972  loss=173.2178  steps/s=95.93  prediction: \"ut still some stuff is unclear to me soâ€¦\" => \"n ti.l.in till  li utttut s iut lu utof \"\n",
      "batch 20973  loss=195.2362  steps/s=86.06  prediction: \" song of the day https://t.co/ukgKg1AkCo\" => \"ton igF riig gn gnt s thson  h/tt::/// K\"\n",
      "batch 20974  loss=170.9154  steps/s=94.85  prediction: \"ng term\n",
      "\n",
      "Best signal to work on for sure\" => \"g o io i  lome tyrB\n",
      "BBfblsklbaabmk\n",
      "mkrdk\"\n",
      "batch 20975  loss=171.1407  steps/s=93.62  prediction: \"imize model performance (we are talkingâ€¦\" => \"npt t  s  t  m  e ii e  mmr mme rr  ae  \"\n",
      "batch 20976  loss=169.1855  steps/s=88.24  prediction: \"nds like a super cool premise for a game\" => \"  \n",
      "Sish tndnSs ikSvrfduckv(up(umupgcbpww\"\n",
      "batch 20977  loss=175.8891  steps/s=89.54  prediction: \"e building an army of tiny little robots\" => \" so o   o o  in  ai a n  i       l    n \"\n",
      "batch 20978  loss=164.0783  steps/s=100.24  prediction: \"r) instead of giving you an easy way out\" => \"e e   e s i ene ))mgbv(k)cuhyg()pbms))wd\"\n",
      "batch 20979  loss=159.6193  steps/s=97.67  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e a  to  ahateh e eh thettht\n",
      "/ t/otthKtI\"\n",
      "batch 20980  loss=176.1551  steps/s=93.41  prediction: \"o you get more data) or hit a \"dampener\"\" => \" s m se etotoosoet  ore oro o mo  et et\"\"\n",
      "batch 20981  loss=167.3343  steps/s=96.40  prediction: \"stly a system 1 thinker. i dont need toâ€¦\" => \"  mn tie    m stm    s y  e t i    t t n\"\n",
      "batch 20982  loss=216.8452  steps/s=11.32  prediction: \"reply: @crackeddl its hard. but worth it\" => \"epty: q e lsen iac2.mu1ulvlykwukvs.v1x1y\"\n",
      "batch 20983  loss=183.4126  steps/s=134.09  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "sout ait  6eld qðŸ«¡qqIuwI.I.bhwd.vsmu1u25\"\n",
      "batch 20984  loss=187.4244  steps/s=21.37  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @il iell  s\n",
      "\n",
      "   li i e      hd toen\"\n",
      "batch 20985  loss=169.8081  steps/s=108.03  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"@heeetd ned  d    i  h  ist /st/tt//ttz/\"\n",
      "batch 20986  loss=166.3685  steps/s=89.77  prediction: \"o make a significant impact on your life\" => \"niaa  int  a  an i iiniai  i  na nn  ini\"\n",
      "batch 20987  loss=162.9287  steps/s=86.50  prediction: \" it just for you https://t.co/USXyB8qOSU\" => \"as e n e  n uotfff  ouo ttot st/ t//tUU/\"\n",
      "batch 20988  loss=171.7549  steps/s=95.86  prediction: \"kely to succeed\n",
      "pretty awesome story btw\" => \"e g  o were  e e o e t  yccete toyete o \"\n",
      "batch 20990  loss=171.3283  steps/s=99.08  prediction: \"kind of just whatever I want to pivot to\" => \"enp ir tin   di o eter tt t weew  t we t\"\n",
      "batch 20991  loss=169.9834  steps/s=98.93  prediction: \"cy and then work up to really short ones\" => \"o  uot o     t e7pw%wkykblbd%oPblwdbk%wc\"\n",
      "batch 20992  loss=181.2292  steps/s=85.66  prediction: \"2 and a monkey pfp too.. this is bananas\" => \"09i ccni77d   a k ek po to pp o..o.. t o\"\n",
      "batch 20993  loss=168.1471  steps/s=99.18  prediction: \"umps ig\n",
      "\n",
      "all good, just gotta never stop\" => \"sp  an  g nb  g bo  godo g gdtg ooe a  s\"\n",
      "batch 20994  loss=173.5161  steps/s=69.67  prediction: \"zmobly has selo made the circle tool yet\" => \"moblz @ar a banbug\n",
      "vy,pjbagd,jjuj\n",
      "bjlgrj\"\n",
      "batch 20995  loss=233.8984  steps/s=97.70  prediction: \"log(S)))/50.){p=vec3((FC.xy-.5*r)/r.y*gâ€¦\" => \"yne,-l*---)o)()))).0{{{){v{0C(((.CCF55-5\"\n",
      "batch 20996  loss=185.5646  steps/s=97.45  prediction: \"he phone seems to make a huge difference\" => \"e ettth ded e se s o o he ee e he ee efe\"\n",
      "batch 20998  loss=187.8289  steps/s=95.55  prediction: \"G SUB 30 BABYYYY https://t.co/E87r3E6tgg\" => \"oOE SPLUU \n",
      "U)GPYUYABF33ASAA:/0:AA8EE37:3\"\n",
      "batch 20999  loss=178.0822  steps/s=90.95  prediction: \"read it maybe. Yea dude Josh is a wizard\" => \"epltymos oshhorekIeIdypmypmy.Y..YYIJ3sJJ\"\n",
      "batch 21000  loss=176.3727  steps/s=90.32  prediction: \"'ll see models get good at outputting it\" => \"seane  ten l nleenel ndeg ed eodg e get \"\n",
      "batch 21001  loss=175.1173  steps/s=96.57  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"ekn nat  meba beLGLknGPGGPrhLcmbypkL\n",
      "gLu\"\n",
      "batch 21002  loss=162.8186  steps/s=102.64  prediction: \"on said we cant use that word any more!!\" => \"n  b n to o   e   o a n a  n et w w a   \"\n",
      "batch 21003  loss=170.6805  steps/s=91.95  prediction: \"cuda skills, so its a fun way to do both\" => \"onl no cnio sttlwg,kiphpmpfmndyuekymcg,i\"\n",
      "batch 21004  loss=196.0505  steps/s=89.24  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"n  e  t d  n  o ia`i`  an` stn o:///tTNN\"\n",
      "batch 21005  loss=201.0532  steps/s=11.38  prediction: \"reply: @djcows leveraged short positions\" => \"epl m @a ee oll ps,uif``frfun::/e.y:N::I\"\n",
      "batch 21006  loss=183.4853  steps/s=129.57  prediction: \"ts insane. madlad\n",
      "\n",
      "glad i already follow\" => \"  a   n n foe  ip`,...``:hfu\n",
      "\n",
      "y/5adbogII\"\n",
      "batch 21007  loss=174.9998  steps/s=68.81  prediction: \"am_Kantor actually something came up rip\" => \"np   nan in  tsa t tlatl\n",
      "i lld ailaada  \"\n",
      "batch 21008  loss=175.3856  steps/s=92.78  prediction: \"n?'\n",
      "2: then crop the quadrant, repeat #1\" => \"  a   ke  it?'ne:\n",
      "2:?2:22:in:'\n",
      "'q2:qbhqf\"\n",
      "batch 21009  loss=170.3210  steps/s=87.64  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"toe rtd ned  d       n  ii  stt tt//ttD/\"\n",
      "batch 21010  loss=165.0791  steps/s=88.41  prediction: \" into local files when you need to build\" => \"tn  na t n nt  n  tl e  ileo lo nn oo i \"\n",
      "batch 21011  loss=180.9482  steps/s=78.75  prediction: \" its crack bro. be careful. i warned you\" => \"tn  taon eit o l ci  e be e  l eon ooli \"\n",
      "batch 21012  loss=173.4844  steps/s=88.01  prediction: \"encoded url that leads to discord invite\" => \"  o  reineeee ne  r  rlt td  t d  t  ddd\"\n",
      "batch 21013  loss=172.4701  steps/s=96.15  prediction: \" this era where breaches happen so often\" => \"toe  m enpe  e s erl theraih shp e  n e \"\n",
      "batch 21014  loss=170.8245  steps/s=26.04  prediction: \"eply: @djcows you need attention, is all\" => \" ly: @pe hn  e s erl theraih php e  n eo\"\n",
      "batch 21015  loss=170.6330  steps/s=146.03  prediction: \"kuba c compiled w emscripten\n",
      "and some js\" => \"ebn  ekocea  e s erl ehereps spp nn notðŸ›‘\"\n",
      "batch 21016  loss=169.8296  steps/s=93.74  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" teh win dts    I\n",
      "wIckg\n",
      "ggmgibg\n",
      "v\n",
      "\n",
      "b\n",
      "bcr\"\n",
      "batch 21017  loss=173.5590  steps/s=93.50  prediction: \"ng game becomes abt strategizing aroundâ€¦\" => \"    o  t  h  aethn\n",
      "ngmngmic\n",
      "kz\n",
      "mcbbuczpz\"\n",
      "batch 21018  loss=179.3017  steps/s=83.96  prediction: \"dusseoGeko Have a good time\n",
      "Follow Jesus\" => \" tng te u ag e me Hase ogaoez zttigo aoâ€¦\"\n",
      "batch 21019  loss=174.6602  steps/s=105.31  prediction: \"ntellectus To beat paranoia, accept risk\" => \"g   i   t m e e knTspTnTbgbz,p,paF,uFdFr\"\n",
      "batch 21021  loss=168.3775  steps/s=46.45  prediction: \"y: @mayfer easy, just ask it what to ask\" => \": @Aateenoee e  a o T  oatoio laoi otasc\"\n",
      "batch 21022  loss=168.4296  steps/s=92.99  prediction: \"i), everything is deterministic (commonâ€¦\" => \"n  a   e e)ttetsyyeete   sie ietie tiii \"\n",
      "batch 21024  loss=170.2755  steps/s=94.99  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \" wa  ot too     a fiee tht ttt ////QQ666\"\n",
      "batch 21025  loss=187.9131  steps/s=85.59  prediction: \"end to work, and they pretend to pay us\"\" => \" d o tppne  n  oe end tdatdotpr nret  nd\"\n",
      "batch 21026  loss=186.6722  steps/s=92.58  prediction: \"o make rlly complex interactive web apps\" => \" au fnd a  o    r  o y lle c c ece itcci\"\n",
      "batch 21027  loss=178.9458  steps/s=92.76  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"o s  s a t  wowpAoApAwAwdfAkxAwvwvLELELE\"\n",
      "batch 21028  loss=167.8473  steps/s=87.92  prediction: \"lves and destroy it all for local optima\" => \"yerraltea   e seteatess ae y o  ll oal  \"\n",
      "batch 21029  loss=173.1006  steps/s=95.68  prediction: \"r run? Much less do grad descent??? Wtf?\" => \"ew ne @wn eo    \n",
      "l?vMmkpw??MMMk?hMvMsc,v\"\n",
      "batch 21030  loss=168.3492  steps/s=93.58  prediction: \"escape outwards\n",
      "the out-of-distributionâ€¦\" => \" tis nggt o    et atte ou est-tet-ou----\"\n",
      "batch 21031  loss=170.1470  steps/s=105.63  prediction: \"azy interesting\n",
      "\n",
      "https://t.co/YpddagC5uf\" => \"ni e   o ny cei se ytin snatissi//\n",
      "t\n",
      "tYt\"\n",
      "batch 21032  loss=173.0122  steps/s=99.36  prediction: \"nds like a super cool premise for a game\" => \"  i e h pnss o a\n",
      "kadbuu:/g.co:/psdecg5uf\"\n",
      "batch 21033  loss=181.3744  steps/s=105.64  prediction: \"ncy, and bitcoin was invented by midwits\" => \" e oidais mhe ct,wbmndgilcwg,,,m,dbnby,h\"\n",
      "batch 21034  loss=180.6796  steps/s=97.51  prediction: \"an that sounds like such a relaxing time\" => \"ndno t te ttatynnin ai ton sicd et eiid \"\n",
      "batch 21035  loss=169.4400  steps/s=85.02  prediction: \"ant believe I havent been napping before\" => \"ndnh t tnidbs e ne IeIe ee  baeinbnbe n \"\n",
      "batch 21036  loss=170.2075  steps/s=100.63  prediction: \"ur goal is to obliterate them with ideas\" => \"t  no  tr to  s ha e ttr to ro atait r  \"\n",
      "batch 21037  loss=182.2852  steps/s=92.19  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "ie  enphs is\n",
      "ta ealaileasassensldme s \"\n",
      "batch 21038  loss=184.3624  steps/s=73.81  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ng \n",
      "t n a  ett \n",
      "p eeias insa sinskcoc sc\"\n",
      "batch 21039  loss=170.6560  steps/s=98.64  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"ttstiiit asics inii ei ni T\n",
      "TT ii ihiisi\"\n",
      "batch 21040  loss=167.7633  steps/s=90.83  prediction: \" software used that widely is so awesome\" => \"tom ehnofat   f ea a d i wa d  tai  w s \"\n",
      "batch 21041  loss=175.8695  steps/s=68.74  prediction: \"aulg We like memoizing physical patterns\" => \"ns   d w neer  ee ewad    ise a  s   eeo\"\n",
      "batch 21043  loss=170.7653  steps/s=95.28  prediction: \"ng them as irrational, then assigning 0â€¦\" => \"g  rh eh  s ehn ga\n",
      "d,zcczczh,g,n\n",
      "n,c,he0\"\n",
      "batch 21045  loss=169.5763  steps/s=70.53  prediction: \" miss the good old completion model days\" => \"tare gherthe  a at tniitnaleatao thhin0â€¦\"\n",
      "batch 21046  loss=171.9622  steps/s=108.89  prediction: \"your brain doesnt have weird hooks in it\" => \":u  ee urtbr io e eren  rrvv edhe w hin \"\n",
      "batch 21047  loss=181.4572  steps/s=100.44  prediction: \"igure out how to improve your work ethic\" => \"nA ttetc t t tout rou to oo o o    w ou \"\n",
      "batch 21048  loss=185.2323  steps/s=79.01  prediction: \"Rohit @archived_videos @discord its fake\" => \" miuirtnohohht  t ioo t  o _ @o @@o@rts \"\n",
      "batch 21049  loss=172.1141  steps/s=99.58  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" mou a  t t  on  hh\n",
      "h o  ooh       DD   \"\n",
      "batch 21050  loss=168.9811  steps/s=100.76  prediction: \"r the years for business/building things\" => \"e(tavtent      nwbh)w)md0u)vvl/b/7cd/w!/\"\n",
      "batch 21051  loss=167.9822  steps/s=41.59  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \"  @voe ese r sffre s e s ess sbes  bsins\"\n",
      "batch 21052  loss=186.1159  steps/s=113.58  prediction: \"d to seeing some cool stuff being made ðŸ˜Ž\" => \" me o   wg  doo eoeg i se   ooooe  ff ff\"\n",
      "batch 21053  loss=181.8766  steps/s=95.58  prediction: \"ors let you get to the meat of it faster\" => \"nk   r ce  looets  g ito o te eot to fft\"\n",
      "batch 21054  loss=172.4736  steps/s=99.76  prediction: \"ugh\n",
      "\n",
      "but lud should be up there for sure\" => \"rh g  no  nout noou  u u  d uu uh uh    \"\n",
      "batch 21055  loss=178.1216  steps/s=91.48  prediction: \"ates Hear me out https://t.co/M8bURSdiT1\" => \"ne   s B les    uouu tutt h /p  /  8o M8\"\n",
      "batch 21056  loss=167.0316  steps/s=99.10  prediction: \"hat light mode is good for you. i don't!\" => \"etk tnti tiththt t t th td  d   do  oo o\"\n",
      "batch 21057  loss=171.7997  steps/s=99.84  prediction: \"ways but in many cases it holds you back\" => \" rd @ l tn Nwe  .wsmbpwrib\n",
      ".plw..w.yscby\"\n",
      "batch 21058  loss=195.3191  steps/s=76.47  prediction: \" QUICK delete this before sphere sees it\" => \"teal oao   e  a  KKa t it t iss s b  oe \"\n",
      "batch 21059  loss=171.5632  steps/s=94.20  prediction: \"r reward, wrecking the incentive to work\" => \"eie tn o lo  ienn,$,\"\"a\"m\"gmd,ðŸ¤·hfack,,\"\"\"\n",
      "batch 21060  loss=178.5594  steps/s=79.77  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" i   td sose ti T,@,MTBMTMTBd:ph:9:k/Q9/\"\n",
      "batch 21061  loss=182.2876  steps/s=89.65  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \" \"area y talten ele ho h t..:./e.t./LLL5\"\n",
      "batch 21062  loss=177.0671  steps/s=85.19  prediction: \"great great thurs\n",
      "key was blocking x lol\" => \" aaana ett    n mf!fg!pklygydwfbk\n",
      "pjp\n",
      "w.\"\n",
      "batch 21063  loss=171.5889  steps/s=91.01  prediction: \"think you can do cdn type stuff w em btw\" => \" e   (lttaa tteikI3)h)kIhuokckId\n",
      "rgckdg\n",
      "\"\n",
      "batch 21064  loss=175.9469  steps/s=85.56  prediction: \"ly got above len=2 for the longest time.\" => \"y: @ iag re t  o b t 2==2=2t2t le tont t\"\n",
      "batch 21065  loss=170.5967  steps/s=91.64  prediction: \"e context, like words, strengthen ideas?\" => \" so    so c et t te to, , s  oerestsnt e\"\n",
      "batch 21066  loss=174.8148  steps/s=84.25  prediction: \"utput brothers karamazov, word for word\"\" => \"r inAioo   t  t ort  tr roor oaorr ra r \"\n",
      "batch 21067  loss=173.6608  steps/s=91.95  prediction: \" something rudimentary could be possible\" => \"tptin ert tet n r mnn mhahr hinemintment\"\n",
      "batch 21068  loss=167.7066  steps/s=98.49  prediction: \"to them\n",
      "\n",
      "good recipe for a solid society\" => \"h yr  e      e tlbdm\n",
      "my\n",
      "bghlmcdcbfdkmfkg\"\n",
      "batch 21069  loss=172.6792  steps/s=100.66  prediction: \" people who find their work fun win more\" => \"tron e p eno    pho  ho  ieohe fiw  onw \"\n",
      "batch 21070  loss=167.0492  steps/s=96.40  prediction: \"ng i correctly understood what you meant\" => \"g y  i       srmf'gy'wly'rhnt'ygmbygwhal\"\n",
      "batch 21071  loss=165.2931  steps/s=91.23  prediction: \" personally make you a funny monkey meme\" => \"tla  n n   l l nily ll     lny ayu  y my\"\n",
      "batch 21072  loss=190.9270  steps/s=44.31  prediction: \": @ludwigABAP @teodor_io and a real hero\" => \" @buihe  e t ed Pnkm_ki_w_yCbEfkbwfupbak\"\n",
      "batch 21073  loss=172.6667  steps/s=92.77  prediction: \"nd super useful: https://t.co/i2lqZZ1GQR\" => \"g i   v en  sd  h:prdbyv:l:::cvtb2:./.1.\"\n",
      "batch 21074  loss=177.3680  steps/s=91.21  prediction: \" drains your energy by paying attentionâ€¦\" => \"tutt tai ng nr tnat  ng niygyyne gtggngy\"\n",
      "batch 21075  loss=172.8719  steps/s=86.82  prediction: \"inlet like me to test experiments out on\" => \"ng e een  n b   r eo ra i te ixre itest \"\n",
      "batch 21076  loss=165.6519  steps/s=92.69  prediction: \"wn for a game sometime? also lichess ftw\" => \"h n ituns ds y gh@wksfmrxpcg?r&xpu?pu?sr\"\n",
      "batch 21077  loss=166.8130  steps/s=89.84  prediction: \"of em\n",
      "\n",
      "not exactly easy but its possible\" => \"u    ntnnoton e oo  n et \n",
      "t ttet ett t e\"\n",
      "batch 21078  loss=181.0416  steps/s=93.57  prediction: \"yo grand children at 85. gps kids r busy\" => \" u  an1 nre   ea dr nd  aee adr n5. d5  \"\n",
      "batch 21080  loss=177.5880  steps/s=75.78  prediction: \"rew_pynch the magic of p5 and LLMs loool\" => \"e tn:  e to iyag5ralt885.lcs858dtp5.kMpi\"\n",
      "batch 21081  loss=166.8792  steps/s=92.95  prediction: \", usually because you border more things\" => \" indans eio  elea  eeusubeseu boe ee uro\"\n",
      "batch 21083  loss=171.7083  steps/s=82.02  prediction: \" it goes \"ziiiiirp\" when u slide down it\" => \"tn ehl  lee oosg \" \"\"\"iiiiii ii      iii\"\n",
      "batch 21084  loss=168.3315  steps/s=90.99  prediction: \"my efficiency. But overall cause its fun\" => \"e e  dnan mp et B,sm.rp.,B.vBumy.vBky.dv\"\n",
      "batch 21085  loss=181.4700  steps/s=86.97  prediction: \"ff has been helping ppl. I love humanity\" => \"   te @etult ed ogsvfrmybpbubbIbk.cIfnIv\"\n",
      "batch 21086  loss=175.9216  steps/s=98.40  prediction: \" useful stuff to save hrs of your day ig\" => \"tp   sNNuuN   ufffu s sfs   sssf    f   \"\n",
      "batch 21087  loss=180.7907  steps/s=82.91  prediction: \"y cool. followed https://t.co/L5UjFCVhd6\" => \":ba ea f t l e  elt follotfol./ . lo  UU\"\n",
      "batch 21088  loss=168.1870  steps/s=19.36  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @ls  olte  elt follot.ol./ . lo  UU\"\n",
      "batch 21089  loss=167.0819  steps/s=104.37  prediction: \"ellite imagery onto the photos they took\" => \" y s stt t    tr elt e i t et o ttetotoe\"\n",
      "batch 21090  loss=175.0416  steps/s=90.02  prediction: \"sicily, i hope to see the island one day\" => \" oer.  ommiy ii   sl i   se ts i s lsi  \"\n",
      "batch 21091  loss=173.6701  steps/s=90.21  prediction: \".. would love to be proven wrong on this\" => \"  ctllee e    olwsdI.kvbs...bnayvddyb.sp\"\n",
      "batch 21092  loss=166.8808  steps/s=96.91  prediction: \"he case for some regions outside the US.\" => \"e  st  ae  e ehe s se r re  sr  s eo ee \"\n",
      "batch 21093  loss=167.7701  steps/s=92.95  prediction: \"e and some others, and it works\n",
      "truuuust\" => \" ait aexatt tan  mtae  ea e  e ae st  t \"\n",
      "batch 21094  loss=161.1969  steps/s=102.78  prediction: \"e readme was a good read on ai reasoning\" => \" acss e sh   eae e e ooe e  a  o o d  ao\"\n",
      "batch 21095  loss=158.3000  steps/s=88.98  prediction: \"irak seems fine to me (i am brainwashed)\" => \"n  sa   eed a  s e s o e  e ao  a ai an \"\n",
      "batch 21096  loss=164.3802  steps/s=99.76  prediction: \"ndustries\n",
      "Currently building semi public\" => \"  ra dtfi  n  stC.wp\n",
      "CC\n",
      "Chb.jys\n",
      "C\n",
      "Cfin..\"\n",
      "batch 21098  loss=180.5116  steps/s=102.90  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" Bxt sD D  r   lByPB@PBAPA@.@ym\n",
      "y\n",
      "ðŸ¤·f,mg,\"\n",
      "batch 21099  loss=167.8420  steps/s=89.06  prediction: \"you can get a stronger 'muscle' for this\" => \":u h ntyo   h   ota got sage  '' rr 'o' \"\n",
      "batch 21100  loss=170.0718  steps/s=92.86  prediction: \"sed\n",
      "\n",
      "Try it asap\n",
      "https://t.co/ZK8YpKEtoP\" => \" la  ei rn eo n \n",
      "T a re  ssrs s p/sK/ZpZ\"\n",
      "batch 21101  loss=187.2697  steps/s=104.19  prediction: \"es matching *.js https://t.co/KxmIcJLlqB\" => \" si f eetc  ci`e ***l* *s scc//:i.c.s /t\"\n",
      "batch 21102  loss=194.3312  steps/s=104.60  prediction: \"d LLM techniques https://t.co/XbnCKZYbBa\" => \" mpKta  \n",
      "c\n",
      "cLLr \n",
      "LLLLLqqq\n",
      "hchte hethtt/X\"\n",
      "batch 21103  loss=190.4069  steps/s=96.71  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tt  r o  eh terir edtpt rerii  lt r let \"\n",
      "batch 21104  loss=167.3038  steps/s=95.18  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: iesss sesessn eln  nl llnnleelen.leee\"\n",
      "batch 21105  loss=178.1885  steps/s=95.01  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" p  ly@ ue u th @B@gMTBMTBTBd:o/:9mw/Q93\"\n",
      "batch 21106  loss=173.2213  steps/s=101.90  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"rn e tt  ne     o ggie t eeeoot toe/t/TT\"\n",
      "batch 21107  loss=171.0891  steps/s=95.95  prediction: \"y time back so i can work on what i want\" => \":honi sana i et m  t i  t c  oac coonww \"\n",
      "batch 21108  loss=166.2575  steps/s=87.71  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"ane  t  txo xoso RaRkacwwswmempa:awt.c:/\"\n",
      "batch 21109  loss=175.3526  steps/s=97.92  prediction: \"is such a great productivity improvement\" => \"n a    stb   a su   s r ru air tutti iv \"\n",
      "batch 21110  loss=167.4664  steps/s=95.58  prediction: \"d of random strings, and removing a bitâ€¦\" => \" in ien  ni      n o   trndnd   nornn   \"\n",
      "batch 21111  loss=165.9958  steps/s=91.42  prediction: \"ool\n",
      "\n",
      "Maybe youll be the dude to crack it\" => \"ulchsos  cco oo \n",
      "oolo  e ol e e e  e uc \"\n",
      "batch 21112  loss=169.3448  steps/s=96.14  prediction: \"n just do things https://t.co/909bTHzmml\" => \"gir   @ cla  a ejby\n",
      "Mjuvjfjvgtp9::/T:z0\n",
      "\"\n",
      "batch 21113  loss=178.7148  steps/s=90.88  prediction: \"aunch\n",
      "imma remember that for a long time\" => \"nlaaa a o t  ana iamamremamhmham e etmre\"\n",
      "batch 21114  loss=160.6920  steps/s=63.17  prediction: \"sunsettler hes locked in to the outdoors\" => \" n laeienai eamhmiamamremenh t t e eemo \"\n",
      "batch 21115  loss=171.4742  steps/s=93.09  prediction: \"imme cmd\"\n",
      "&gt;cmd\n",
      "runit\n",
      "&gt;runs the cmd\" => \"nma  a en\n",
      "aae \n",
      "eg;mm d;&m&&&;;;;\n",
      "uut \n",
      "g\n",
      "\"\n",
      "batch 21116  loss=175.9213  steps/s=70.89  prediction: \"thy I wonder how attention relates to IQ\" => \"he   a\"n\"  em s Iygl;rw\n",
      "skd;lu&&&;&&y;;I\"\n",
      "batch 21117  loss=177.1293  steps/s=93.68  prediction: \"a get my future kids on this kinda stuff\" => \"npo I wyn ce  nteu tuttu dtu n tekiakiak\"\n",
      "batch 21118  loss=170.9781  steps/s=89.14  prediction: \"AM much more energy and thoughts flowing\" => \"PAA B eaef  B  ne e e ereh me eg t ehrn \"\n",
      "batch 21119  loss=168.8440  steps/s=89.36  prediction: \"\n",
      "bc thats truly what your actions effect\" => \"\n",
      "uc   th th  i  vaorabruvvyfscgbc\n",
      "iswvbu\"\n",
      "batch 21120  loss=178.7537  steps/s=83.71  prediction: \"houlda stuck to planting apple trees smh\" => \"ase asaa ba  utcsteutuasstta tloti atrns\"\n",
      "batch 21122  loss=165.3738  steps/s=91.27  prediction: \"resent them in (i.e. \"jimmy shot a ballâ€¦\" => \"eply aoa   e e ayb(bmsb(\"(p.f(j\"j.(\"j\".â€¦\"\n",
      "batch 21123  loss=169.7683  steps/s=87.67  prediction: \"an get immense alpha if you keep zooming\" => \"nd ooe taet   mmn   e  me  ie  ei  e   o\"\n",
      "batch 21124  loss=175.1895  steps/s=89.85  prediction: \"/t.co/emubOEhMKJ https://t.co/Fxx5eUVcPp\" => \"/.d4nc  pa  coo:oEeEEEKKJJKJthJ::/:.FhFF\"\n",
      "batch 21126  loss=172.3603  steps/s=88.46  prediction: \"g correct (fingers crossed its this one)\" => \" sae e  oaa ct svabc(a(yib.(bw(fwu(d6y()\"\n",
      "batch 21127  loss=165.5337  steps/s=88.30  prediction: \"g correct (fingers crossed its this one)\" => \" cae e hoaa ct soabc(a(yil.(bw(fwn(dXn(f\"\n",
      "batch 21128  loss=171.3690  steps/s=87.90  prediction: \" for weeks\n",
      "\n",
      "gives me so much damn energy\" => \"tor ga r   r reeeg\n",
      " ra es se\n",
      "es\n",
      " eo o  m\"\n",
      "batch 21129  loss=165.6621  steps/s=86.93  prediction: \"times and pick up new details every timâ€¦\" => \"hcefict ewe  estBBfYvwcw:vivyhuykvbwglkw\"\n",
      "batch 21131  loss=173.9141  steps/s=59.43  prediction: \"yMazza my favorite systems administrator\" => \" B  onae ta d  n   it  ne  e deia idti e\"\n",
      "batch 21132  loss=221.2695  steps/s=100.21  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"hc //hth    rWo WWCFWCWCWChs zs:.cFHFoFH\"\n",
      "batch 21133  loss=195.5590  steps/s=70.11  prediction: \"ZyMazza what do they call this opening??\" => \"yMaco:Mp at CCtt6bBCBbb\n",
      "/:.pbbHH\n",
      "H.F55V9\"\n",
      "batch 21134  loss=186.9068  steps/s=96.32  prediction: \"g\n",
      "\n",
      "And people usually have your problems\" => \" \n",
      "o!  to ne ifriga\n",
      "AAfhp esgtgindn\n",
      "\n",
      "u\n",
      "\n",
      "h\"\n",
      "batch 21135  loss=172.0024  steps/s=97.50  prediction: \" and the quote tweet is the reply itself\" => \"t qtthe tq tthw e t  te ett e tte   e te\"\n",
      "batch 21136  loss=179.4616  steps/s=89.28  prediction: \"as experimental\n",
      "ran each on a differentâ€¦\" => \"n t t wawaap oe rraseta es s t s   a tee\"\n",
      "batch 21137  loss=181.0173  steps/s=89.00  prediction: \"cay principles, and it ended up formingâ€¦\" => \"ol g,atrel nc  nkcybpgrh,kinaf,dandca,wp\"\n",
      "batch 21138  loss=170.8633  steps/s=93.39  prediction: \" giz tarantinos alt?????? this shit fire\" => \"aei@ieziz   iyinsi  a??????t?  st? ? ini\"\n",
      "batch 21139  loss=186.5912  steps/s=86.02  prediction: \"of work every monday and thursday brotha\" => \"u iioi lre  oohn oorn  y  e rryeyy ay nd\"\n",
      "batch 21140  loss=172.0277  steps/s=87.55  prediction: \"g the day\n",
      "i dont tho bc well, i cant lol\" => \" ao  win  ts I  I\n",
      "wIckguckIgimg\n",
      "vI\n",
      "b\n",
      "owb\"\n",
      "batch 21141  loss=183.6906  steps/s=89.99  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"/.ces  /fsta/ZP/QZZZPZPZPttT:://...:/K.K\"\n",
      "batch 21142  loss=172.2092  steps/s=86.44  prediction: \"seeing other stuff we can get done\n",
      "Chess\" => \" tdo e'm eeenret e ne e   n e   e  e  t \"\n",
      "batch 21144  loss=175.7499  steps/s=90.07  prediction: \"'re not the same https://t.co/5QlKrss5WG\" => \"me innig '   'oe'tn  nae  tt  he tht / t\"\n",
      "batch 21145  loss=182.3141  steps/s=91.99  prediction: \"ny part of a much bigger long term thing\" => \"g h eeart inhtnarpT\n",
      "mTngm\n",
      "Ty/bTrf//pufba\"\n",
      "batch 21146  loss=175.8452  steps/s=90.49  prediction: \"y with any industry/niche and ill run it\" => \":gicteiny ay inynittyiny hnt inty hn hn \"\n",
      "batch 21147  loss=186.9196  steps/s=88.24  prediction: \"ke half my followers came from shoutouts\" => \"e 90 oiie b  o l  alll l    flofofo fo e\"\n",
      "batch 21148  loss=184.1377  steps/s=105.00  prediction: \"of learning is learning from the past ig\" => \"u aenda\n",
      "le lalfallenr ll fri laor mga ne\"\n",
      "batch 21149  loss=173.6739  steps/s=101.68  prediction: \"cking a computable number from the reals\" => \"heeoo nlexekieg s\n",
      "f\n",
      "kyfbibl*wkYktcrfpd\n",
      "p\"\n",
      "batch 21150  loss=183.6348  steps/s=40.16  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: @ noaina mi oiaa c  mb umbb bmr e  re\"\n",
      "batch 21151  loss=177.8820  steps/s=99.91  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"r  to t%  w  i thhe wehet  t tht//et/t /\"\n",
      "batch 21152  loss=190.1410  steps/s=92.12  prediction: \"GE net positive\n",
      "\n",
      "https://t.co/QTjQWURLO0\" => \"EOO\n",
      "yatet  sXGn HUGEGEGEmfvvE\n",
      "hvQQpj:WR.\"\n",
      "batch 21153  loss=186.1812  steps/s=71.36  prediction: \"seatedro c-&gt;wasm and js, all frontend\" => \" 2ta   XUUe  E  tvi \n",
      " \n",
      "t\n",
      "\n",
      "t:ttj\n",
      "\n",
      "///jQQQ\"\n",
      "batch 21154  loss=176.5774  steps/s=91.57  prediction: \"e rewards\n",
      "\n",
      "doing it on snake to learn it\" => \" at  siei e aze ia se tori\n",
      "ioi nn siti  \"\n",
      "batch 21155  loss=175.9364  steps/s=88.70  prediction: \" dingboard. Several others ive seen irl.\" => \"tone e ni. n did..a San S  e v r o veerv\"\n",
      "batch 21156  loss=179.1441  steps/s=95.55  prediction: \"y highest elo and post cool results on x\" => \" mi ee \n",
      "esses nst   oh eho   t  let  oss\"\n",
      "batch 21157  loss=181.8076  steps/s=94.64  prediction: \"77x im guessing you're super cracked huh\" => \"2  hiet7t  es7ess  gs   oo   r u e  cucu\"\n",
      "batch 21158  loss=171.9174  steps/s=91.98  prediction: \" the past two months and its so worth it\" => \"to  tot  hert etot t th   t e sts n s   \"\n",
      "batch 21159  loss=164.6759  steps/s=91.43  prediction: \"andom ah number 20yrs ago and stuck w it\" => \"nd t mo   t n  nm a    r 2  r r  a a a  \"\n",
      "batch 21160  loss=165.2141  steps/s=90.34  prediction: \"ounts for new lengths of weeks/months ig\" => \"r w  w n wtoue  w  n o now n e ne osonse\"\n",
      "batch 21161  loss=173.9498  steps/s=99.87  prediction: \" before\n",
      "\n",
      "also you were a cracked 3yo lol\" => \"tete e  ln reee lee  se   eer  \n",
      " aaaer  \"\n",
      "batch 21162  loss=171.4151  steps/s=85.10  prediction: \"nis @startupmillyair pretty solid rating\" => \" n    eno def   @f@vp\n",
      "wbrfmlyklmb3mug3kr\"\n",
      "batch 21163  loss=162.0784  steps/s=86.46  prediction: \"seful instances of delayed gratification\" => \" e neffu ones enttsne se  oes e  f fteda\"\n",
      "batch 21164  loss=172.4572  steps/s=88.33  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn eooee  eneg  o geee e eeeo/t/toe///55\"\n",
      "batch 21165  loss=178.7928  steps/s=88.96  prediction: \"unto the end of the worldâ€\n",
      "\n",
      "- Matthew 28\" => \"sa g    tn   een  n   ee e e e e   -t MM\"\n",
      "batch 21166  loss=165.2087  steps/s=88.02  prediction: \"r the picture\" for any industry or niche\" => \"ethe ieu  ncl tepmdwp\"cfubf\"rbTpyc'pcc\"w\"\n",
      "batch 21167  loss=177.8821  steps/s=93.80  prediction: \"darin and english which they are meh at)\" => \" ypy pmn anrren aaennan   ia inhi hh h n\"\n",
      "batch 21168  loss=185.7035  steps/s=96.50  prediction: \" on the 25th : D https://t.co/Z00IinOQsN\" => \"tf eae c(_oc eh 525255D D:DDD:t:h::Z/e:Z\"\n",
      "batch 21169  loss=176.2818  steps/s=89.47  prediction: \"n but once it sees them it zooms off\n",
      "hmm\" => \" ah tanl tbao  nu-bybuobfsczmibfrzyzubzo\"\n",
      "batch 21170  loss=169.3256  steps/s=97.89  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tar at ier n i iiena i ite  i   aa/ H H/\"\n",
      "batch 21171  loss=174.4801  steps/s=88.85  prediction: \"ore descriptive titles for the rest lool\" => \" kie    enee  erititii iine d tirt ti er\"\n",
      "batch 21172  loss=161.7260  steps/s=86.48  prediction: \"secret instructions on the 25th (a link)\" => \" eile ir r re icr crs etr  ott tt 22t  n\"\n",
      "batch 21173  loss=154.5880  steps/s=89.74  prediction: \"velsio im hyped to see what youre cookin\" => \"e avellne@ee ee e  oo      e    e   o  o\"\n",
      "batch 21174  loss=211.3123  steps/s=72.60  prediction: \"x140201 @teodor_io start with the Gospel\" => \"a7ole  vlh i    o  o     t et    t  o o \"\n",
      "batch 21175  loss=177.8942  steps/s=89.51  prediction: \"el editor and gameplay, that sounds cool\" => \"  l a et a  l  da el e eaee  t  ta a   o\"\n",
      "batch 21176  loss=170.0963  steps/s=89.20  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eee ntiIe  ime tb@b,lrkr\n",
      "kogn\n",
      ",lbmy\n",
      "lhkt\"\n",
      "batch 21177  loss=170.9317  steps/s=95.83  prediction: \"i is a smart idea to pitch to the public\" => \"nc so deet oop st  oe tti ta ti  a to to\"\n",
      "batch 21179  loss=173.3554  steps/s=87.86  prediction: \"n confirm this is a very goated strategy\" => \"gioi  n aiemCas imafCtmdtkvfpvarhmvsuyhg\"\n",
      "batch 21180  loss=167.1530  steps/s=90.56  prediction: \"ng that solves a problem you're close to\" => \"   net i mr hamsfmlvgpmgypgsgl'r'ð—±bs'mhb\"\n",
      "batch 21181  loss=170.6137  steps/s=88.11  prediction: \"mple py script manages building/updating\" => \"ele t  @    iet lvvyvivvimp\n",
      "mgcr\n",
      "bchpavv\"\n",
      "batch 21182  loss=174.3167  steps/s=95.15  prediction: \"on adding sound!\n",
      "https://t.co/7jVECuxgpx\" => \"  i o ln a oin  dngnd d!nn do noddo/tj7/\"\n",
      "batch 21184  loss=174.5148  steps/s=91.93  prediction: \"rflowsucks and never went on there again\" => \"eao  e h  u krwtQckhvuhklyhmebvwrmwsuyfv\"\n",
      "batch 21185  loss=179.7137  steps/s=81.11  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u lc  wnce a s e ere  nseotos  nee/e3o3\"\n",
      "batch 21186  loss=174.7003  steps/s=86.85  prediction: \"urity\n",
      "\n",
      "rather than having your hand held\" => \"n  t  t fhoritea th t \n",
      "i eatrhtr tnh rha\"\n",
      "batch 21187  loss=168.5594  steps/s=92.24  prediction: \"r coding lol. And some chess. Great move\" => \"elo amior roi f s.nA.AAuA\n",
      "AIi.AGpab.hGGI\"\n",
      "batch 21188  loss=167.4121  steps/s=94.61  prediction: \"other approaches lol\n",
      "this was a speedrun\" => \"  o  ot  o   o oo  ar    oa  oh  all s p\"\n",
      "batch 21190  loss=169.7304  steps/s=92.16  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" mh  enge sse e  eamtâ€¦â€¦â€¦ ttms  ttt  //tB\"\n",
      "batch 21192  loss=176.7889  steps/s=90.50  prediction: \" I'm super down for another one thursday\" => \"t  !!e !  !e   dse  r     o d  or on r e\"\n",
      "batch 21193  loss=189.8875  steps/s=93.61  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tte   de dd e â€¦De  tU hsttst  t/tst//SSt\"\n",
      "batch 21195  loss=184.9107  steps/s=89.98  prediction: \"yybe RTs, and definitely intriguing QRTs\" => \"  r ae . agea  aRRsn, seyd aadyyieiyyit \"\n",
      "batch 21197  loss=179.7817  steps/s=9.48  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"esly: aget aba  T,,RTR,b,Ty,T,,bl,T,,,fQ\"\n",
      "batch 21198  loss=178.2079  steps/s=97.10  prediction: \"xluciusv cool cool goal\n",
      "progress so far?\" => \"tuo  n enanna enn snei eidnrairyregQ iR \"\n",
      "batch 21199  loss=169.5803  steps/s=93.35  prediction: \" is structured to add llms pretty easily\" => \"tnde eideid  eu t ueddu t  dd  et  dd td\"\n",
      "batch 21200  loss=166.3375  steps/s=88.67  prediction: \"tler where would you say you are on this\" => \" e  ee s  srl  erIbpyaitwichlo,,ptmb,pbg\"\n",
      "batch 21201  loss=169.2508  steps/s=42.99  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \"  @ssnsc trerrt edredd lo  y u ty  rr or\"\n",
      "batch 21202  loss=172.6899  steps/s=96.68  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \"aYo in \" he i ia\"ofofiofof fn lol Ca C l\"\n",
      "batch 21203  loss=166.7753  steps/s=89.97  prediction: \"gh times when it all looks bleak/failing\" => \" t  th  sre grme.cwsfwvrcwgvvbgpmr/mdseb\"\n",
      "batch 21204  loss=167.8680  steps/s=89.30  prediction: \"d into using dishonest middlewit tactics\" => \" ee sssner enen    i onssd  ines o id i \"\n",
      "batch 21205  loss=167.9102  steps/s=90.87  prediction: \"st zip is one..? https://t.co/aEF6Fs5nwe\" => \" riee bnett      it .   .?? t t...///F/F\"\n",
      "batch 21206  loss=170.3618  steps/s=97.51  prediction: \"ies and more insights. Then will release\" => \"ns e diien tr  e  s n si i eishieihnh e \"\n",
      "batch 21207  loss=181.6913  steps/s=87.93  prediction: \"read 100,000x faster.\n",
      "Follow for updates\" => \"epl ei/\n",
      "   ereanB1,1,010x,xcyxuyFxF\n",
      "F.nF\"\n",
      "batch 21208  loss=167.9998  steps/s=92.74  prediction: \"category so the rule is to tell everyone\" => \"on ito  r n e nnvogmv.\n",
      "vihppy0.\n",
      "mpdcaguv\"\n",
      "batch 21209  loss=171.7757  steps/s=91.31  prediction: \"urself, if you can manage to pull it off\" => \"ne tee ll yll y y y o  a a   o      a   \"\n",
      "batch 21210  loss=179.7047  steps/s=89.91  prediction: \"nism oooh possibly, thats a good thought\" => \" nio   s @o @etHb,b,hluwd\n",
      "uhcwrfmp,vb,bt\"\n",
      "batch 21211  loss=196.2326  steps/s=84.75  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \" sos  sis i y  o  o shsioiattts a/to Y Y\"\n",
      "batch 21212  loss=165.3022  steps/s=90.73  prediction: \" selected\n",
      "\n",
      "Or better yet skip selection?\" => \"tesine nt   see ett O OO tee eet y  sete\"\n",
      "batch 21213  loss=161.3546  steps/s=18.40  prediction: \"eply: @sunsettler you are the dan herder\" => \" ly: @tot    e nett O  O tet eet y  sete\"\n",
      "batch 21214  loss=167.8031  steps/s=95.23  prediction: \"to someone on X, its laggy when it plays\" => \"     e  sthih t mb.Xuic.wXmoX,X,nbX,,lXy\"\n",
      "batch 21215  loss=180.8496  steps/s=92.10  prediction: \" get good sleep\n",
      "\n",
      "https://t.co/rQasZTP7ce\" => \"torewe t t oogt-ege \n",
      "\n",
      "gte \n",
      "\n",
      "e :pst//sQs/\"\n",
      "batch 21217  loss=169.5583  steps/s=92.13  prediction: \"lf of that was way off. all good tho nbd\" => \"y0o  m e  t a t a    a  f f      l o o  \"\n",
      "batch 21218  loss=168.8735  steps/s=91.29  prediction: \" now i have this https://t.co/NCsyY5vpWl\" => \"tot ffi ne    n h h h  hht  t h /h/ttNs/\"\n",
      "batch 21219  loss=161.0695  steps/s=61.24  prediction: \"eMTB I see slop poasting is the meta now\" => \" TB i i TMMB Th h h s s  pt ttss t5 tWhðŸ›‘\"\n",
      "batch 21221  loss=159.7973  steps/s=92.37  prediction: \" will get back to you when this is fixed\" => \"thae pa  w illp  al   e  e  w  w  eh t  \"\n",
      "batch 21222  loss=190.4944  steps/s=86.76  prediction: \"as irl but the ppl here are way higher x\" => \"l io  t s d  ot  tll  lt hre h s he  rra\"\n",
      "batch 21223  loss=168.6347  steps/s=87.80  prediction: \"hings and learn from that\n",
      "\n",
      "yea, idk, lol\" => \"ecgedd   ddd   nd  lann  ra    aat  aa  \"\n",
      "batch 21224  loss=164.8665  steps/s=83.44  prediction: \"ur gzip stuff? training on gzipped data?\" => \"t .i  owe  s sa s r r?tff n ff in  znnn \"\n",
      "batch 21225  loss=176.4522  steps/s=89.23  prediction: \"is fine and expected, giving up is death\" => \"n  ha  lreent  iixeetniaxxx x ne updpege\"\n",
      "batch 21226  loss=172.5489  steps/s=89.97  prediction: \"ot good results: https://t.co/KAmykVYFyw\" => \"r  i   a     d  oo  gos to::s:t/::/K//KA\"\n",
      "batch 21227  loss=169.4762  steps/s=83.40  prediction: \"v ill send you a link around the 25th! ðŸ«¡\" => \"ec iwa    g oltso oe os t/to ttstoutoytt\"\n",
      "batch 21228  loss=172.5410  steps/s=100.51  prediction: \"uff like explore exploit basically daily\" => \"sf efu  fnluie  lue  xxsxolo e  loll lei\"\n",
      "batch 21229  loss=168.9473  steps/s=79.90  prediction: \"ake with two snakes would be interesting\" => \"tion  i l etn   wo w e so sise  llieee i\"\n",
      "batch 21230  loss=170.7408  steps/s=95.04  prediction: \"otten most of my follows from Yacine lol\" => \"r   etet ottt    t    et o  f tf f  fo f\"\n",
      "batch 21231  loss=177.5804  steps/s=82.27  prediction: \"ure Beautiful, and great choice of music\" => \"se t ttnenot ea f f   f l   ro o c  c  o\"\n",
      "batch 21232  loss=165.7514  steps/s=94.37  prediction: \"rally where the word came from, i think)\" => \"elry:i es  l t ab,yy\n",
      "h,bntb,w,ldowfcdm,v\"\n",
      "batch 21233  loss=163.4018  steps/s=98.79  prediction: \"TB elon lived in leafland for a bit iirc\" => \"B t  i  eler  l ee e ei  a alao afr  o i\"\n",
      "batch 21236  loss=180.0741  steps/s=97.84  prediction: \"r you choose is not technically infinite\" => \"eal  yoh r  er rvuycbwmbtbvni'yiuvghvmve\"\n",
      "batch 21237  loss=173.0594  steps/s=98.64  prediction: \"ike\n",
      "sound on btw https://t.co/HHEmCMksqU\" => \"ne  a l eiklino  nio  nl t  tt////H/tHHH\"\n",
      "batch 21238  loss=167.6220  steps/s=94.52  prediction: \"so i havent used anything like webgl yet\" => \"  s  eno sas  s  n s  a snn  t ae n e i \"\n",
      "batch 21239  loss=177.0886  steps/s=91.97  prediction: \"mannak Duh they used the hydraulic press\" => \"ent ni@steo a  rkvDcDuvscfoufydoarvdvvnv\"\n",
      "batch 21240  loss=162.3724  steps/s=94.83  prediction: \"ning arc, off in a remote cave somewhere\" => \" nialneaotde  ngkjkc,uv\n",
      "dhjuqy,jdf,ucvdr\"\n",
      "batch 21241  loss=180.2133  steps/s=96.13  prediction: \"(n)).\n",
      "\n",
      "Store hash of each frame from ofâ€¦\" => \"ieedooe   otne) SnS o n\n",
      " aaoeoeh h a h f\"\n",
      "batch 21242  loss=170.0158  steps/s=106.03  prediction: \"he race to steal the eu tech bros begins\" => \"e  in) aort tor hhe o ea aaha eh o  o m \"\n",
      "batch 21243  loss=166.0372  steps/s=20.63  prediction: \"eply: @yacineMTB https://t.co/H0UMjZbPTA\" => \" ly: @c nan  ohehhe o ea aa a eh o  o b \"\n",
      "batch 21244  loss=181.0061  steps/s=102.97  prediction: \"Sorry I mean\n",
      "advanced tpot poasting here\" => \"oreeei r  s er  ne  eare\n",
      "o\n",
      "ncedvaedtnpop\"\n",
      "batch 21245  loss=164.0616  steps/s=39.36  prediction: \"y: @sunsettler write a will just in case\" => \": @yastr he\n",
      "era ne  earedopoc apaedtnaop\"\n",
      "batch 21246  loss=173.6479  steps/s=100.34  prediction: \"allenge\n",
      "however: https://t.co/TzbAuUlGIG\" => \"nl  u p   ua a eue hetee:t: ::t:p:t//z/T\"\n",
      "batch 21247  loss=187.6665  steps/s=97.89  prediction: \"? i actually dont know anything abt groq\" => \"?Aiait wtyo lst dvhk:kv:aigungkdubick ku\"\n",
      "batch 21248  loss=164.0676  steps/s=91.61  prediction: \"ad a concept of \"I\" they would probablyâ€¦\" => \"to  c o   t t ot o  \" \"c\"I \" t a  o  o  \"\n",
      "batch 21249  loss=173.3217  steps/s=95.92  prediction: \"ame theory\n",
      "change the expected value\n",
      "win\" => \"toi c et  hee ghegg ege ge ehgoe th  hah\"\n",
      "batch 21250  loss=168.5296  steps/s=97.86  prediction: \"TB elon lived in leafland for a bit iirc\" => \"B   n e ethl  nlne e ee  e anade ae  aa \"\n",
      "batch 21251  loss=171.6683  steps/s=98.50  prediction: \"it. \n",
      "I used to tell people all my plansâ€¦\" => \"n  t  msen teti  i r ete t petp o te t t\"\n",
      "batch 21252  loss=161.8138  steps/s=94.08  prediction: \"got the bit order backwards or something\" => \" t  he a re  ee gtdmpnprbcnlkwpbfbkpkkdu\"\n",
      "batch 21253  loss=177.2411  steps/s=86.74  prediction: \"rf spatial in problem solving efficiency\" => \"eio  ter es  nf grwmrpwtpdwmrhmlvdhrobvs\"\n",
      "batch 21254  loss=189.8868  steps/s=92.19  prediction: \"dgrammer it was a really fun time though\" => \" ra  er tn   @ @wsrwmrr wwiwmrra lr ere \"\n",
      "batch 21255  loss=166.8138  steps/s=90.29  prediction: \"ck and forth as much as possible I think\" => \"o t o mina m r nknbkdkcacyvbbcpkdkfgmsvu\"\n",
      "batch 21256  loss=175.6666  steps/s=72.23  prediction: \"ruck is this you https://t.co/TaMoSJicnx\" => \"eiois ew an k tmufbiducac:vmbfk:s:f/TsMT\"\n",
      "batch 21257  loss=185.4686  steps/s=88.83  prediction: \" you find running helps you work better?\" => \"toukain  ao  ndd unu nu  irp uinnn  h nk\"\n",
      "batch 21258  loss=181.1469  steps/s=86.21  prediction: \" fit-to-content) https://t.co/kIAe5BVk05\" => \"tiree t  tt  -he-oentnttt )) ett//// o5t\"\n",
      "batch 21259  loss=170.9403  steps/s=89.07  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"totenoe  rel   e mmnee tlste t/emertojjD\"\n",
      "batch 21260  loss=172.0375  steps/s=86.52  prediction: \"\n",
      "\n",
      "can they do it perfectly? no, can you?\" => \"\n",
      "iettreoleh c nhbhudhdy\n",
      "\n",
      "h.\n",
      "\n",
      "\n",
      "chiy?h?iyo\"\n",
      "batch 21261  loss=176.2115  steps/s=88.40  prediction: \"you could just make move that looks good\" => \" u cenn  to  ou h jj j knke mkst ku toha\"\n",
      "batch 21262  loss=179.0320  steps/s=90.75  prediction: \"agnusCarlsen or @GMHikaru or @Kasparov63\" => \"ne   (  e s ls ls @  s raMrks r r@  Kraa\"\n",
      "batch 21263  loss=182.1300  steps/s=91.56  prediction: \"t.co/RTzhOLWPSu) https://t.co/LtcVnD19hs\" => \"h R/tth //e hzt LWPLWPPSSOPS:)p).S/).cVV\"\n",
      "batch 21264  loss=200.2374  steps/s=93.74  prediction: \"dnt acct for maintenance/electricity tho\" => \" tti ae cira indt  cc  ntecttaoacinieaec\"\n",
      "batch 21265  loss=187.4910  steps/s=99.43  prediction: \" is wild\n",
      "\n",
      "my laptop barely runs this lol\" => \"tn  ano  e  tiririeitd  rprdi  yt r lyi \"\n",
      "batch 21266  loss=172.3828  steps/s=94.51  prediction: \"re you have fun\n",
      "\n",
      "https://t.co/wqa4oxdnF8\" => \" pl sr@,tent hr yknurarvkykur\n",
      "kv.vf::qv.\"\n",
      "batch 21267  loss=167.3794  steps/s=95.00  prediction: \"this is the same as the place where theâ€¦\" => \"hi   n iie t  enfbflab.,kdmp..d..n.w.ymi\"\n",
      "batch 21268  loss=206.8732  steps/s=11.30  prediction: \"reply: @HSVSphere how high agency of you\" => \"esly: @@-VðŸ«¡Q.   fbflab.,kdmp..c..n.w.ymi\"\n",
      "batch 21269  loss=182.2145  steps/s=129.79  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \" o ts    thsts sx1xwxgl110xx.1:y:EFK.tpE\"\n",
      "batch 21270  loss=185.8057  steps/s=95.40  prediction: \"f is MSE derivative and df_dconstant isâ€¦\" => \" th so _L  L_ n MSEMSEvzMSMSvmc_vf_af_bc\"\n",
      "batch 21271  loss=181.0560  steps/s=90.10  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e  ts@g3t nr artkwvbdilmfgbvarclrfu\n",
      "wulðŸ›‘\"\n",
      "batch 21272  loss=170.9348  steps/s=91.93  prediction: \"conflicting values it would be a paradox\" => \"onveo a ld co  sjnubv,rvegf,npwdrbonfflb\"\n",
      "batch 21273  loss=173.6433  steps/s=91.84  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"tneth  ss  hee  e  o s bhetssss//oso //R\"\n",
      "batch 21274  loss=197.2519  steps/s=80.91  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"mtme  @LSaeds ShAWLFWTF:TF:.nh.d:/:7.6./\"\n",
      "batch 21275  loss=176.9251  steps/s=87.10  prediction: \"new super super early on she was the one\" => \"tm ttdet t b i kmkwmyhsupkwgirpmrwruyfyb\"\n",
      "batch 21276  loss=171.9780  steps/s=82.18  prediction: \"bly same, llms are so much faster though\" => \"ey t n e peu spme es r a  aso  h s ee  o\"\n",
      "batch 21277  loss=173.0667  steps/s=95.17  prediction: \"y abt compression, which is intelligence\" => \":wi taplpa b  lpaitbtsiosirssior iwhiis \"\n",
      "batch 21278  loss=175.8626  steps/s=88.30  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \"   a tomeotl o io t tiit nh sh /lthlin/x\"\n",
      "batch 21279  loss=181.2438  steps/s=87.07  prediction: \"LiGHtmOde\" posts https://t.co/zZslih1Sec\" => \"ezpa ol nsttaHe LhGHbGHGH\" O\"Gp\":hOx.\":/\"\n",
      "batch 21280  loss=171.9220  steps/s=96.22  prediction: \"you into thinking hes an anime character\" => \" u  t  rrhorton  ino nog kiont kt ini nn\"\n",
      "batch 21281  loss=174.2669  steps/s=93.91  prediction: \"than \"heres a tool to solve problem xyz\"\" => \" in,  er t i  i \"lgcul\"\n",
      "w\"uc\"ar\"p\"\"ev\"az\"\n",
      "batch 21282  loss=172.8554  steps/s=97.06  prediction: \" function w gpt3.5 instead of uppercaseâ€¦\" => \"tinl enl te  te  ti  t t5   t ote tpte p\"\n",
      "batch 21283  loss=174.0534  steps/s=93.88  prediction: \"ible w lots of work??? Sign me tf up NOW\" => \"nle   s    s  s  o  s  ow   ??????S S  f\"\n",
      "batch 21284  loss=205.6819  steps/s=89.92  prediction: \"nket @pixqc INFINITE HOUR CODING SESSION\" => \"g Mh nakwt @  etq@ANFF@xqEFHNORECCOUEGCR\"\n",
      "batch 21285  loss=180.0092  steps/s=89.05  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"nt.   oo  o  rt eo oeee     reeeie  e ee\"\n",
      "batch 21286  loss=159.8520  steps/s=87.08  prediction: \"ure the first man on mars thats so crazy\" => \"t  ota reree   f t t ne mr mtmrttrst  as\"\n",
      "batch 21287  loss=168.2796  steps/s=88.41  prediction: \" bc random twitter guy said itd be funny\" => \"tema ms b me a  t mtte t  die   d detde \"\n",
      "batch 21288  loss=176.5596  steps/s=90.51  prediction: \"makes it an order of magnitude harder...\" => \"ame  anes  d eonybyynmkudkdngfncygdklukl\"\n",
      "batch 21289  loss=165.0488  steps/s=87.59  prediction: \"f time and space that can reach in here?\" => \" twern@n, su a tulyluu,uwpafpfofrgpwpuds\"\n",
      "batch 21290  loss=175.0544  steps/s=81.31  prediction: \" i gotchu\n",
      "its https://t.co/5a2OVgZKZc yw\" => \"ts iiee nenT ih oetht httt h//acc/c  cZc\"\n",
      "batch 21291  loss=170.0087  steps/s=90.58  prediction: \"l ideas\n",
      "\n",
      "say if youre trying to learn ML\" => \"yf f neel ned i eae  ieeelray  s  e yre \"\n",
      "batch 21292  loss=174.6005  steps/s=100.71  prediction: \"ad to give some direction/motivation tho\" => \"n     yt  d to toe  oio t rodt  ioeotovo\"\n",
      "batch 21293  loss=174.8417  steps/s=91.85  prediction: \"discovering new unseen fundamentals, too\" => \" n mte  c\n",
      " cn ic n dneenneeueuune e nnun\"\n",
      "batch 21294  loss=181.9886  steps/s=90.19  prediction: \"Grats!!! Always awesome to see successes\" => \"rad     lleGo olh\n",
      "GkAGvGfocA!hAyAfyw,vn,\"\n",
      "batch 21295  loss=189.8601  steps/s=92.39  prediction: \" speed things UP https://t.co/ShePlGSrtZ\" => \"tte   de dd e Dee  ts hsttst  t/tt ////t\"\n",
      "batch 21296  loss=183.1098  steps/s=91.19  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \" t tedeet Gn e     ts :/tttt:://t:.///tG\"\n",
      "batch 21297  loss=171.2790  steps/s=92.41  prediction: \"but for now ill run whatever ppl ask for\" => \"et h n t  o  oe  ut  ouo  nuw ll  wl  pl\"\n",
      "batch 21298  loss=175.9472  steps/s=84.52  prediction: \"ased. Me neither. This is the way to go.\" => \"n     ) Bct  e e nn.  . teit  ph  ehe  s\"\n",
      "batch 21299  loss=174.4472  steps/s=52.18  prediction: \"@squirtle_says yacine what have you done\" => \"yuiontM Bt   eMe .h.  e te t  hie  h  oo\"\n",
      "batch 21300  loss=176.1524  steps/s=90.10  prediction: \"amount of time, or did you just enjoy it\" => \"ne ia ln ia  a  n mtimmion   dod ti  ju \"\n",
      "batch 21301  loss=171.9371  steps/s=95.40  prediction: \"her is metagocnition (for your own mind)\" => \"er s  penotn e troohere o  eto(noter( o \"\n",
      "batch 21302  loss=170.7794  steps/s=94.12  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"en   nses  o i  YoYoYoY onouta nool t r \"\n",
      "batch 21303  loss=181.1984  steps/s=45.16  prediction: \"y: @01beigecamry https://t.co/qAESPOcfdy\" => \": @juuoe   ooY  YonoYoY onout   ool t r \"\n",
      "batch 21304  loss=175.4242  steps/s=105.53  prediction: \"thanks man\n",
      "these have been super fun tbh\" => \" er r tot  k s nkihuhcs:h\n",
      "f.u./vAESPObOk\"\n",
      "batch 21305  loss=176.5096  steps/s=88.34  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"enl   on r d   wyspMockkhaymi:e:fh:zM:/M\"\n",
      "batch 21307  loss=174.5378  steps/s=84.63  prediction: \"ffects that are extremely hard to notice\" => \" e i  @p p ee tfgtrsshx/xpxxrxxxxgylbjhf\"\n",
      "batch 21308  loss=204.9432  steps/s=92.80  prediction: \" --. .. ...- . / -.-- --- ..- / ..- .--.\" => \"@-  . /t   -e/ttee /e- et/ .aaa t /o t-t\"\n",
      "batch 21309  loss=182.9394  steps/s=99.13  prediction: \"/t.co/z7o68IdnYR https://t.co/uxpBjiQYOe\" => \"t..SStSSth:/ ///77//8888RRRRRRRt:/t/:///\"\n",
      "batch 21310  loss=170.7354  steps/s=94.45  prediction: \"s large of a positive impact as possible\" => \" aiea  fa ae     o  a   ai  aiai i sa  p\"\n",
      "batch 21311  loss=183.6574  steps/s=96.24  prediction: \"k h(x,n) = x^n and g(y, a_n) = a_n@y\n",
      "\n",
      "iâ€¦\" => \"eoo,))nni (h hwx n nx n^( , , = nn)=_ _ \"\n",
      "batch 21312  loss=173.3385  steps/s=91.29  prediction: \"xample\n",
      "Do this and then train them on it\" => \"tcffofs saat emtDDo t a aa het t thea ni\"\n",
      "batch 21314  loss=183.6145  steps/s=101.82  prediction: \"/t.co/3niiW6u2N4 https://t.co/AMiuse1VEj\" => \"t..dscp/ttc//// 3WWWW22N444444/t:t:////u\"\n",
      "batch 21315  loss=175.9920  steps/s=86.42  prediction: \"argantuan amounts of data into LLMs\n",
      "You?\" => \"tdice edettan g ggatunaunu to ottantn oL\"\n",
      "batch 21316  loss=178.4646  steps/s=85.25  prediction: \"conclusion that the zig code IS the docs\" => \"ome 0aitn ao  olutvd.drzcoz/czuziShISzIS\"\n",
      "batch 21317  loss=171.7556  steps/s=82.66  prediction: \"ped to have you join!!\n",
      "gl and have fun ðŸ«¡\" => \"lrt @eione  a  nu\n",
      "hzvhrzjvzjISjgjShIS!\n",
      "g\"\n",
      "batch 21318  loss=178.5604  steps/s=52.89  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"yrnetoe tthtv oo h jo!!! io!  g ade af ðŸ«¡\"\n",
      "batch 21319  loss=166.4930  steps/s=93.90  prediction: \"have primitives if you look close enough\" => \"ete etitit t v i irii ivee tii io e iii \"\n",
      "batch 21320  loss=193.5065  steps/s=90.68  prediction: \"ful to me, like use every day type stuff\" => \" l n rthn tteannpb3pm\n",
      ",yh)kdbfp)o#,m,i,o\"\n",
      "batch 21321  loss=174.1366  steps/s=92.23  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"ed moreiw   e  owrw\"\"\"xxxpx:x:p??xxwl5:5\"\n",
      "batch 21322  loss=170.0218  steps/s=88.99  prediction: \"esome trend of advice sharing, i love it\" => \" sehlteote    mn e  me deer or iicese co\"\n",
      "batch 21323  loss=181.1690  steps/s=88.80  prediction: \"nvestor\n",
      "\n",
      "Simpleagreementforfuture Equity\" => \" e  nn  nel  n iSSAng\n",
      "SSgSvmSvAfvmaumsgm\"\n",
      "batch 21324  loss=176.1508  steps/s=83.93  prediction: \"ng a circle tool https://t.co/Uj5nNmO40z\" => \"   oeom  int irakpmpv\n",
      "cfmrcl/:ps:E:ujUjN\"\n",
      "batch 21325  loss=173.4144  steps/s=93.36  prediction: \"\n",
      "\n",
      "how did karpathys advice work out btw?\" => \"\n",
      "sopr@er t ttt omIu,F,v,Fu,llnHvwHr,ltk*\"\n",
      "batch 21326  loss=175.2738  steps/s=85.49  prediction: \" thought they became ugly when they fell\" => \"@oedd_eolhe t  teh  h   eyh y ehy  ehy  \"\n",
      "batch 21327  loss=167.6976  steps/s=87.20  prediction: \"answer in as few characters as possible\"\" => \"t  he  t s e   esa ee   w w a asas ara a\"\n",
      "batch 21329  loss=170.8632  steps/s=101.22  prediction: \"your life (which is what happened to me)\" => \" ur aos  yo   e  i  fi hwh h ww haha ep \"\n",
      "batch 21331  loss=167.5139  steps/s=105.56  prediction: \"useful directions to take the project in\" => \"se  fefer   ffff   e e ee ti e tteto e  \"\n",
      "batch 21332  loss=171.6102  steps/s=92.84  prediction: \"it playable on lichess and post the link\" => \"n  rea rae rnaael    lt tes s n  i ens  \"\n",
      "batch 21333  loss=167.1794  steps/s=87.29  prediction: \"re. it can only get 103 on snake though.\" => \"epl   thn irt  ipmsrr.cpcgo1010103y10333\"\n",
      "batch 21334  loss=179.4431  steps/s=64.38  prediction: \"ryvyo no ffmpeg itd be too slow id think\" => \"e  o sunurort  isms103cocgb1030303y11333\"\n",
      "batch 21335  loss=178.2236  steps/s=103.85  prediction: \" blud @covix2772 https://t.co/nyfCqYreff\" => \"tu c lcogeg  g  77c2 c277x2 t2xc /it oc:\"\n",
      "batch 21336  loss=170.0369  steps/s=82.89  prediction: \" busy so i havent been posting much my b\" => \"tu   benn s b s ysv  t b bv e iene t ot \"\n",
      "batch 21337  loss=172.3565  steps/s=82.62  prediction: \"amebedan since ports dont allow weapons.\" => \"ne n n  n se  i s nentnbponts t ne oecy \"\n",
      "batch 21339  loss=168.9764  steps/s=77.13  prediction: \"stalexoki trail mix but its all m&amp;ms\" => \" u e   unbh  ii i ni  n  o ts tw a mps&&\"\n",
      "batch 21340  loss=175.3971  steps/s=56.57  prediction: \": @minamisatokun https://t.co/7cpKcX83WN\" => \" @junt@jt  mx trkpunpnclbp:xchwywc7Kb&uX\"\n",
      "batch 21341  loss=171.3450  steps/s=94.17  prediction: \"pl to influence what they think (cringe)\" => \"ly:  mp e so ptl\n",
      "gmpcwwwopcwfwfyachck((c\"\n",
      "batch 21342  loss=173.8007  steps/s=93.18  prediction: \"om gpt10 how strong could you make gpt2?\" => \"npyata tnetta   t 1  oo  or  t uoo   uou\"\n",
      "batch 21343  loss=200.5701  steps/s=94.47  prediction: \"7AHwatHv6Y was really really really good\" => \"0  phe ih tttoh 6YHv66Y666w y rlyyrea ly\"\n",
      "batch 21344  loss=173.9784  steps/s=86.07  prediction: \"see more details as you unblur an image.\" => \" tpe  e6w   ee  ras  rtall  s ally y olr\"\n",
      "batch 21345  loss=170.7005  steps/s=96.17  prediction: \"onder if he stuck w onnx or went w tf.js\" => \"u   eln\n",
      " e    n e  s     no i  o n w n w\"\n",
      "batch 21346  loss=168.5072  steps/s=95.14  prediction: \"eep your mouth shut haha\n",
      "\n",
      "super powerful\" => \"   eo    e u  uo e uhu  uhu  hhuh  h eh \"\n",
      "batch 21347  loss=169.7135  steps/s=86.69  prediction: \"ng ideas man\n",
      "excited to see where you go\" => \"g rls n va   v  fav\n",
      "xxkvekdkrknflxxcxckx\"\n",
      "batch 21348  loss=183.6782  steps/s=90.02  prediction: \"ork\n",
      "Until it did https://t.co/nY6zvVWYaH\" => \"u   d et nn nt  tinddid ttdndtt t//t: Yz\"\n",
      "batch 21349  loss=173.5497  steps/s=100.82  prediction: \"ire effing timeline is circle tool posts\" => \"n  in  me din tieee enii  ine ie  eici i\"\n",
      "batch 21350  loss=184.8284  steps/s=98.70  prediction: \"boards to learn the keys other ppl used)\" => \"et d  aerdaa o aat t rtee ar tet        \"\n",
      "batch 21351  loss=167.2762  steps/s=92.63  prediction: \"re fun\n",
      "\n",
      "will post useful shortcuts later\" => \"epl es hatmt et kofuslgkfhkn\n",
      "wwklmpw)slo\"\n",
      "batch 21352  loss=172.8746  steps/s=90.66  prediction: \"this. or you can win by trading seats wâ€¦\" => \" e p b. y tni t cbffbysrhiig.w.hybuucs.d\"\n",
      "batch 21353  loss=167.5096  steps/s=89.85  prediction: \" random nonsense will escape containment\" => \"tatesmeberre m n mm e neno ns ssn eessee\"\n",
      "batch 21354  loss=178.6463  steps/s=89.94  prediction: \" fit-to-content) https://t.co/kIAe5BVk05\" => \"toree    t   -he-oo tnttt)en ett////II5I\"\n",
      "batch 21355  loss=173.3782  steps/s=82.91  prediction: \" is nice. idk much about distros tho lol\" => \"ts e ne etne ii n c ch tn h.cktkcdkthoot\"\n",
      "batch 21356  loss=181.2068  steps/s=87.64  prediction: \" srsly the golden age of building things\" => \"teo e toosao     sloo  s  eo  g lde geg \"\n",
      "batch 21357  loss=178.6753  steps/s=90.16  prediction: \"is here, line 7: https://t.co/72Mt9DfH09\" => \"n \n",
      "imp rnomt oi m ter77re 77 ::th 7:// M\"\n",
      "batch 21358  loss=168.4877  steps/s=88.48  prediction: \"ound this in btw\n",
      "https://t.co/U9iM8AWCn6\" => \"    cood tn i hi it   t ht  /t /t// t//U\"\n",
      "batch 21359  loss=171.1260  steps/s=88.84  prediction: \"th `sudo service NetworkManager restart`\" => \" e   tetg r o hn``uuNwNwNvNrNMNMkMvMpMer\"\n",
      "batch 21360  loss=180.3287  steps/s=86.91  prediction: \"a get my future kids on this kinda stuff\" => \"nto w t n teg nteu tuteu d k tnkr s disu\"\n",
      "batch 21361  loss=176.2076  steps/s=79.16  prediction: \"Sharpest oh shoot this is smart\n",
      "ty ty ty\" => \"aeedat etn e   seu t seu d s tnki tadi u\"\n",
      "batch 21362  loss=170.8443  steps/s=96.97  prediction: \"e the last clip\n",
      "\n",
      "https://t.co/CPSXwfs38G\" => \" ouiisen hm  a \n",
      "aettcct htthtt/e\n",
      "/\n",
      "PSPPS\"\n",
      "batch 21363  loss=184.1431  steps/s=25.46  prediction: \"ply: @camhowe1729 No problem, good tweet\" => \"ly: @maceas\n",
      "  t c9)plmpf::/:h.:hCPPSPSXP\"\n",
      "batch 21364  loss=166.7619  steps/s=104.04  prediction: \"etter but pretty good time bender though\" => \" tt ot n boe eterett   tttt e e ot o tee\"\n",
      "batch 21365  loss=161.0230  steps/s=90.39  prediction: \"dit on my phone)\n",
      "https://t.co/iWZ4An9PaZ\" => \" n  o t  to e    o  t  ntetoottto/tt/ZZZ\"\n",
      "batch 21366  loss=190.6555  steps/s=84.48  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" t  o e ani k  hhntLLzL/zz4z//tt4AtnniPn\"\n",
      "batch 21367  loss=157.1831  steps/s=93.59  prediction: \"us things that make your life easier ig?\" => \"tt ut  iiioi it t  t   ta t       e   a \"\n",
      "batch 21368  loss=168.9624  steps/s=91.92  prediction: \"lly click for me\n",
      "https://t.co/LHjT6ITtSs\" => \"y  i in eai   ili  ll l ltt  c c /  cL/t\"\n",
      "batch 21369  loss=166.5119  steps/s=90.34  prediction: \"t info, hence why I expanded past papers\" => \" doe r ted io,o yIcwrwrxhIuIx,xpIldxpc\n",
      "f\"\n",
      "batch 21370  loss=163.2389  steps/s=100.51  prediction: \"op over and over is the opposite of slop\" => \" lnt n sn   o o  a ovov o s ei   o os oo\"\n",
      "batch 21371  loss=176.2642  steps/s=100.00  prediction: \"here for the funny symbols and recursion\" => \"er   er toee htr  hthe em or s f r snerr\"\n",
      "batch 21372  loss=172.2029  steps/s=92.39  prediction: \"f thing = free yourself to chase rewards\" => \" ao  f rHah  taer ==dfihhu===rhrsgc=isir\"\n",
      "batch 21373  loss=183.0379  steps/s=86.58  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAPcf nriri Ai P ==yfuyhunkyrhisBchBdBr\"\n",
      "batch 21375  loss=171.5799  steps/s=93.29  prediction: \"aw of undulation https://t.co/VdFFnrRkLH\" => \"n   o   hn t \n",
      "n   \n",
      "o  n aa    t tt/V/Ft/\"\n",
      "batch 21376  loss=168.8022  steps/s=97.58  prediction: \" just need to learn the secret shortcuts\" => \"tui  ks nst  te tee    te te  ee  e  ese\"\n",
      "batch 21377  loss=177.5340  steps/s=93.69  prediction: \"ntellectus little italy?? nah. big italy\" => \"de      t i e  ekIljIsjckrkI\n",
      "j/j.dyr?\n",
      "b.\"\n",
      "batch 21378  loss=172.0524  steps/s=96.75  prediction: \"this. or you can win by trading seats wâ€¦\" => \" e p o  y tni t cbffbysrhiig.w.hybuucu.d\"\n",
      "batch 21379  loss=163.8723  steps/s=93.32  prediction: \"w the entire thing works when you use it\" => \"imt an    t e entchingcdowcdkm,ghkyayfud\"\n",
      "batch 21380  loss=162.6753  steps/s=98.40  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" nmemn anhon alov~hifgæˆ‘dok:dkðŸ¤£ð—²gdHIHKfKðŸ›‘\"\n",
      "batch 21381  loss=166.3272  steps/s=97.31  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \"  ioie   t i ddddii t tit  ittt teticcst\"\n",
      "batch 21382  loss=160.8151  steps/s=99.22  prediction: \"on + analysis, considering posting on gh\" => \"   aonon   aaaa aniio oninninsi o  singi\"\n",
      "batch 21384  loss=172.1952  steps/s=93.68  prediction: \"everything is simple after you learn it\"\" => \" erei  nn i e  si  gegs   i    ite ee   \"\n",
      "batch 21385  loss=174.8612  steps/s=38.32  prediction: \"y: @Nominus9 So no chess players, got it\" => \"  @l g nnn  g rsi  iegs   iy   steree t \"\n",
      "batch 21386  loss=176.4174  steps/s=95.96  prediction: \"ot rlhf'd, only watches john oliver now\"\" => \"     e  e t    l'      h h  lho   olo l \"\n",
      "batch 21387  loss=158.6433  steps/s=93.64  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \" teomeon en eo ee  d  d  de   ed ad yd t\"\n",
      "batch 21388  loss=172.0353  steps/s=90.67  prediction: \" of times\n",
      "\n",
      "Based https://t.co/zl5CiEWkKb\" => \"tf a ne e  t ena BBoB B e setts e//:5555\"\n",
      "batch 21389  loss=166.6342  steps/s=89.62  prediction: \"ight radius\n",
      "Hmm 5px or 5%? Maybe 4.9%...\" => \"nh a  n nt h  itr  ti 5 55 555  5%  M%%%\"\n",
      "batch 21391  loss=165.8279  steps/s=88.70  prediction: \"cise or anything else prevent this loss?\" => \"hn  h htng i i oWDWxxWycuW?gl?YapYxv?x?u\"\n",
      "batch 21392  loss=165.6323  steps/s=88.90  prediction: \"bithole goes. question is if any of itsâ€¦\" => \"er h   i tb o tbeo oqeqeoq ss so  i io i\"\n",
      "batch 21393  loss=175.5666  steps/s=85.00  prediction: \"ates Hear me out https://t.co/M8bURSdiT1\" => \"t networ o  s seee oeotsthis  si/ . o8 8\"\n",
      "batch 21394  loss=173.7068  steps/s=89.55  prediction: \"ch though if i cant fix a particular bug\" => \"he   tw  wm e tay.fy,pcfui,cif/xdsxpwxfb\"\n",
      "batch 21395  loss=166.6224  steps/s=74.61  prediction: \"nis @sunsettler sun yearns for the mines\" => \" cih  w unh    u@m@y,xcfxircifcudexpfx.b\"\n",
      "batch 21396  loss=169.6845  steps/s=94.94  prediction: \"ire effing timeline is circle tool posts\" => \"ne e t N  nin  i ee eni   i e ie  ei l i\"\n",
      "batch 21397  loss=162.7857  steps/s=95.65  prediction: \"ink not tho, I believe in synthetic data\" => \"ng a   i in  tt It    o    n    i  ieeee\"\n",
      "batch 21398  loss=173.4257  steps/s=99.25  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" xe ia n e    waWIxbjgFxvjFkjFjkgvd,,IIb\"\n",
      "batch 21399  loss=160.4794  steps/s=99.87  prediction: \"n people imagine\n",
      "https://t.co/ZYfaaoNir7\" => \" ai de tan pe  lbrin'bQc'\n",
      "ð˜:bZf:cwdZYfbZ\"\n",
      "batch 21400  loss=167.1331  steps/s=104.71  prediction: \"fected, i hope none of my followers were\" => \" at re amtiot t g,slppdsc,rv,m,\n",
      "pghl.,v.\"\n",
      "batch 21401  loss=167.4709  steps/s=91.40  prediction: \"that there were pink cubes at some point\" => \"he    ei  dettnrr ieer t  t  i te re e t\"\n",
      "batch 21402  loss=172.4719  steps/s=83.62  prediction: \"P get him toys, play w him, lasts longer\" => \" @ot thAiAe e   e n i  t es    te e a st\"\n",
      "batch 21403  loss=185.2419  steps/s=92.40  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \" d feben  nee ie  b n  b nt stp/ ://KKK/\"\n",
      "batch 21404  loss=163.2835  steps/s=102.21  prediction: \"s of industry water cooler conversations\" => \" aot dto   nothso u  od o  o  c    ooter\"\n",
      "batch 21405  loss=164.5051  steps/s=104.57  prediction: \"B meet the new boss\n",
      "same as the old boss\" => \"Ab iaAtii BB  teet  eeeee  es s s  sasss\"\n",
      "batch 21406  loss=163.6263  steps/s=98.67  prediction: \"fecting\"\n",
      "\n",
      "but low level compsci version?\" => \"reler   u    e swpg\"fj\":yv.\"Cyj\"\"\n",
      "svu-m?\"\n",
      "batch 21408  loss=155.3365  steps/s=89.58  prediction: \"een enough to find mentorable candidates\" => \" deht tn eh   ene  e ee e  e n   nennnaa\"\n",
      "batch 21409  loss=165.0881  steps/s=85.15  prediction: \"ff bro, gl on your journey btw\n",
      "\n",
      "followed\" => \" em  r s  oe  etlcjchB,,1fjB,10,v,vjjv,.\"\n",
      "batch 21410  loss=153.5231  steps/s=88.73  prediction: \"do 16hrs tmrw, test this and report back\" => \" na to  sh s  a  s   s s  ts t tts   r r\"\n",
      "batch 21413  loss=170.9124  steps/s=89.28  prediction: \"ift camera to dogs perspective = dataset\" => \"n ott e ;ng tt c  dat  t as tt  es attt=\"\n",
      "batch 21414  loss=164.1799  steps/s=88.83  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tar at ier n i ii  iii at   i    t/  /t/\"\n",
      "batch 21415  loss=169.4518  steps/s=89.16  prediction: \"there\n",
      "\n",
      "65% done\n",
      "\n",
      "https://t.co/E0y7ZskhYs\" => \" atoe     t t e \n",
      "\n",
      "6e\n",
      "\n",
      "\n",
      "\n",
      "t t  et/\n",
      "\n",
      "//EEE/\"\n",
      "batch 21416  loss=165.7156  steps/s=86.90  prediction: \"e algo show you a lot more similar posts\" => \" ane mahe  a    hoo too  oo    o   oos  \"\n",
      "batch 21417  loss=163.2092  steps/s=88.71  prediction: \"i), everything is deterministic (commonâ€¦\" => \"n  ll  e   tteyt  ee e  i eeeietiiii ii \"\n",
      "batch 21418  loss=180.1694  steps/s=83.30  prediction: \"sonnet 3.5v2 its amazing for programming\" => \"  c  etqe  et i   e  2 ii  isi i rrimrno\"\n",
      "batch 21419  loss=160.3899  steps/s=86.98  prediction: \"snt even intentionally trying to do that\" => \" t  t n dnt  t nn etinntneentntinn tt tn\"\n",
      "batch 21420  loss=177.2832  steps/s=92.63  prediction: \" going straight there out of highschool)\" => \"teat  ie  n  iiggtght t ttht     o    hh\"\n",
      "batch 21421  loss=176.6801  steps/s=10.04  prediction: \"reply: @helscom OF NOTHING\n",
      "IN PARTICULAR\" => \"eply: gae iei   (cNâ€wfoNlvwNaf)g(ydl)vwv\"\n",
      "batch 21422  loss=195.7993  steps/s=145.25  prediction: \"ly @covix2772 â˜ ï¸ https://t.co/2A3p3rDVtF\" => \"y: n n n   g@iho272272  ï¸tâ˜ ï¸t /  / oh2o2\"\n",
      "batch 21423  loss=184.5246  steps/s=86.93  prediction: \"ns to the left of me\n",
      "Jokers to the right\" => \"  mo teo c ecoClCcï¸OTfopJ\n",
      "J:acJ//J.kJ/DJ\"\n",
      "batch 21424  loss=164.0373  steps/s=90.49  prediction: \"e forever with a simple 5min interaction\" => \" son ne eoheoetso eiir  e   eie im i  i \"\n",
      "batch 21426  loss=166.7369  steps/s=87.30  prediction: \" have to reprompt it like 1/3rd the time\" => \"tas  a  aen   e    e        e  t e  t  t\"\n",
      "batch 21427  loss=165.9357  steps/s=91.50  prediction: \"zations seem like they could be improved\" => \"m gom  ei  z  zozlwzyzsbvikydkmklakyuyfu\"\n",
      "batch 21428  loss=169.6973  steps/s=88.27  prediction: \"tand on the shoulders of retarded giants\" => \" r itiotiet  stls ehn teo hoe seerd d re\"\n",
      "batch 21429  loss=172.9081  steps/s=97.96  prediction: \"niped by x today https://t.co/pZx65NULyu\" => \"gt i aeinipt inewxuloxcxuh/xdc:ulZ:x:NNZ\"\n",
      "batch 21430  loss=169.2433  steps/s=94.81  prediction: \" on linkedin will be typing in lowercase\" => \"tn  oneen    in ioneon  l i liil  in  n \"\n",
      "batch 21431  loss=163.8187  steps/s=69.67  prediction: \"omeik that is super super super cool wtf\" => \" e  enoen i  k l ne  e  l    pip  ii   l\"\n",
      "batch 21432  loss=165.9959  steps/s=90.70  prediction: \"he building -&gt; increase skillset loop\" => \"e  ais  ti  ii   ii  igg ii i iii   itll\"\n",
      "batch 21433  loss=162.6064  steps/s=89.79  prediction: \"w up wherever decision making is present\" => \"hst n   e  sp  g,cupvw,u,.cfygov,,ak5,gh\"\n",
      "batch 21434  loss=177.1608  steps/s=55.71  prediction: \"@JsonBasedman just veto their veto, easy\" => \"grcho d s  w e r e    ei   o nisi i  iee\"\n",
      "batch 21435  loss=178.6767  steps/s=74.76  prediction: \"@startupmillyair https://t.co/c3FxqzjmK3\" => \"guohoea ense ede u irse s  o nieioi asee\"\n",
      "batch 21436  loss=182.0201  steps/s=82.73  prediction: \"m @MarcEsserman A fellow morra fan I see\" => \"aki g eo     @ @MAEyEwr:At:A:A/v3FxqzjqK\"\n",
      "batch 21439  loss=191.1928  steps/s=79.14  prediction: \"mobly weak neck? https://t.co/XRcWwRXqHu\" => \"abe  se se@m n  uAEk?cr?k?rApA:h:mIXI/X/\"\n",
      "batch 21441  loss=160.3160  steps/s=98.53  prediction: \"snt even intentionally trying to do that\" => \" o  t  wdnt  t nt etinntntentntinnntt tn\"\n",
      "batch 21442  loss=176.9641  steps/s=85.75  prediction: \"mannak Duh they used the hydraulic press\" => \"ane ne@emain   tk,DuD.yluy,k/yhyf (v/Xhy\"\n",
      "batch 21443  loss=170.7461  steps/s=97.98  prediction: \" where this goes ðŸ’ª good luck with the RL\" => \"too n goer r    gsese ðŸ’ªðŸ’ªðŸ’ªðŸ’ª ðŸ’ªoeo iig ghth\"\n",
      "batch 21444  loss=166.2292  steps/s=96.99  prediction: \"e or desire to practice for other things\" => \" ioop  ct cr  t  er r  e  rrccccccr o  r\"\n",
      "batch 21445  loss=165.9648  steps/s=93.03  prediction: \"per curious to see what youre working on\" => \"lrp   ondr at t ,k,gvv.s,,,,iðŸ˜†u,ðŸ«¡É´m,cl,d\"\n",
      "batch 21446  loss=174.6738  steps/s=79.43  prediction: \"ontend ai stuff is pretty cool. followed\" => \"   nr ttnto s en u s s    s s  ut to otl\"\n",
      "batch 21447  loss=157.4117  steps/s=88.57  prediction: \" different distribution of training data\" => \"tav  ve   i e eeeet ettttr i titi iin ni\"\n",
      "batch 21448  loss=163.3365  steps/s=86.56  prediction: \"lly click for me\n",
      "https://t.co/LHjT6ITtSs\" => \"ye t in  liii il    l   lt   c /t/ c///t\"\n",
      "batch 21449  loss=166.7235  steps/s=84.26  prediction: \"ns the returns are high on more of it :)\" => \"  a\n",
      "  iiconi oamcbbk.fwpudr\n",
      "vwrw\n",
      ":ggpskw\"\n",
      "batch 21450  loss=173.1903  steps/s=84.17  prediction: \"ls similar to me\n",
      "larger battery capacity\" => \"yo  aeniset   eirlass lmlm  ir t e  ae e\"\n",
      "batch 21451  loss=161.1900  steps/s=90.89  prediction: \"anding pages or whatever feels gross idk\" => \"td at  st s n  nggr  aaa ee     eee r er\"\n",
      "batch 21452  loss=166.3132  steps/s=84.72  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng io tengesenn intiwgsw  atwaa taa aalh\"\n",
      "batch 21453  loss=169.7531  steps/s=91.88  prediction: \" into a projectâ€¦ https://t.co/vcUZYZskRt\" => \"tn   +npe  tt   pto pt pâ€¦  â€¦t p tttt////\"\n",
      "batch 21454  loss=168.5748  steps/s=95.36  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"    n r nah wo  Fo!FnFFF!!!\n",
      "G\n",
      "tF!Fo/Wt0F\"\n",
      "batch 21455  loss=167.7361  steps/s=93.19  prediction: \"than \"heres a tool to solve problem xyz\"\" => \" an,o  sh hrr hnh  e ee t  to oere ts ol\"\n",
      "batch 21457  loss=164.6566  steps/s=71.73  prediction: \"is would make a really cool pfp actually\" => \"n  r  hicat s tah  e ee to to ol e oa zl\"\n",
      "batch 21458  loss=170.1609  steps/s=94.51  prediction: \"te\n",
      "\n",
      "thanks swap\n",
      "\n",
      "https://t.co/6ZawSRo1dn\" => \" re  t ne te   \n",
      "\n",
      "aa\n",
      "\n",
      "\n",
      "hhatt\n",
      "\n",
      "t\n",
      "ttt////s/\"\n",
      "batch 21459  loss=167.6270  steps/s=94.96  prediction: \"nt properties. huts dont have penthouses\" => \"  te te e gests lfpdr0.uwgnf.dgvufmwvcmf\"\n",
      "batch 21460  loss=176.3834  steps/s=97.71  prediction: \"e a monitor? lol https://t.co/V2QYVL07Il\" => \" trernanu eou t u e to t ntotl/t VVVVVQQ\"\n",
      "batch 21461  loss=164.2364  steps/s=85.47  prediction: \"tler where would you say you are on this\" => \" doree perc hre   t lo /o/ o///soY YLtou\"\n",
      "batch 21462  loss=168.7776  steps/s=89.89  prediction: \"ed, its worth at least giving a shot tho\" => \"  net  set  ttt   t  t t   a a    t g t \"\n",
      "batch 21463  loss=176.3193  steps/s=82.77  prediction: \"ed\n",
      "\n",
      "lightmode starts with L for a reason\" => \"  +eed eeed \n",
      "d \n",
      "otee etoerrttttt    ttt \"\n",
      "batch 21464  loss=164.9164  steps/s=95.30  prediction: \"ys end up thinking \"nah they would justâ€¦\" => \"   s  It ao  I nta       nt  n\"n   t h  \"\n",
      "batch 21465  loss=153.8426  steps/s=104.10  prediction: \"do 16hrs tmrw, test this and report back\" => \"    to  sh s 6a  s   s st ts t tts   r r\"\n",
      "batch 21466  loss=164.0480  steps/s=99.23  prediction: \"the coolest shit\n",
      "https://t.co/PZBHaS9Qz5\" => \"hes e         sh th hsshtttttstttttt////\"\n",
      "batch 21467  loss=172.7265  steps/s=102.96  prediction: \"freedom fighters. ppl who wanted freedom\" => \" oo tn ie)2r f  )m2)g)dg2I..2.v2cw.ri.h.\"\n",
      "batch 21468  loss=161.3012  steps/s=106.64  prediction: \"ut with an empty prompt\n",
      "\n",
      "final answer, 2\" => \"   tu  ut uttt  t  t   ptp ppttptp    n\n",
      "\"\n",
      "batch 21469  loss=175.2616  steps/s=101.16  prediction: \" I'm super down for another one thursday\" => \"t   !en!  !e !  se  r     o e  on on rr \"\n",
      "batch 21470  loss=166.4561  steps/s=100.04  prediction: \" liked it haha\n",
      "God bless you too brother\" => \"tit   od ya  dt d   d  a  hoGe oo os oso\"\n",
      "batch 21471  loss=189.7152  steps/s=11.62  prediction: \"reply: @calbach_ https://t.co/Gyx4pLqxKX\" => \"eply: @oenlad.e mI1ya\n",
      "G\n",
      "Gkb.bkn\n",
      "GahG.GXk\"\n",
      "batch 21472  loss=162.6971  steps/s=104.75  prediction: \" just be a webpage visit, its in browser\" => \"tu  llt lnt l   t aa     b ei s i i i  t\"\n",
      "batch 21473  loss=187.1393  steps/s=99.03  prediction: \" job adding the australian language pack\" => \"tu ilt  jg  beb e  i e a a s  an  i s ia\"\n",
      "batch 21474  loss=161.9938  steps/s=96.69  prediction: \" was mated instead, so he resigned lmaoo\" => \"tht thno ha a e att t tet ea  as ees  sd\"\n",
      "batch 21475  loss=158.8954  steps/s=98.11  prediction: \"he result, its equivalent to convolution\" => \"e fo  nr  t  rr tr rqequqtqqeqqee tevi s\"\n",
      "batch 21476  loss=173.0099  steps/s=91.75  prediction: \"e, and i know i need to get back into it\" => \"  esiein eeo ind inod e o  i  ned     et\"\n",
      "batch 21477  loss=166.8146  steps/s=90.04  prediction: \"gh Ive been wanting to do a wasm project\" => \" torr yP r e n  N,k#kkIi#IvgIvIv*hkblb,b\"\n",
      "batch 21478  loss=163.2785  steps/s=94.10  prediction: \"s away\"\n",
      "\n",
      "by football I mean american ofc\" => \" in eo l a a  lob a\n",
      "ab  olba   a aaa a a\"\n",
      "batch 21479  loss=158.0303  steps/s=92.43  prediction: \"o do this\n",
      "already f'ed it up today loool\" => \"rbo b on en eo ee  d  d adet  ed ad ed a\"\n",
      "batch 21481  loss=167.6791  steps/s=95.20  prediction: \"ney OR something extremely useful to you\" => \"de o endne  te  ORrdmORRxixR-yxypygxxxru\"\n",
      "batch 21482  loss=173.9793  steps/s=104.72  prediction: \"e convos with -c https://t.co/AfDOg5Ufj8\" => \" aonno   e t ct  ew coas  /t  c:s:t: DcD\"\n",
      "batch 21483  loss=184.6551  steps/s=95.25  prediction: \"working long hrs https://t.co/baIKtrB2L3\" => \"irk    t  see   kfy/ðŸ’ªwp:/:ke:./w.cK:KBIK\"\n",
      "batch 21484  loss=208.3266  steps/s=101.00  prediction: \"@___________11hz helped me out with mine\" => \"snnrhr eeo   _______11__1hz hze eht tet \"\n",
      "batch 21485  loss=158.6007  steps/s=96.23  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \"nse in  n t   n i t  t      n nn eeeele \"\n",
      "batch 21486  loss=165.6503  steps/s=97.72  prediction: \"uick free working solution, see my tweet\" => \"rtd   e  eiae nre e n  koo  n  liee o e \"\n",
      "batch 21487  loss=159.2220  steps/s=101.25  prediction: \"your time for fruitful endeavors instead\" => \" u yo u nuo   oo   o r fufr fur errr  ni\"\n",
      "batch 21488  loss=159.3257  steps/s=91.50  prediction: \"do all of those\n",
      "\n",
      "https://t.co/C4hXOs7hck\" => \"      in fof   o  fo  o oot ooo/ttht//h/\"\n",
      "batch 21489  loss=173.3218  steps/s=94.13  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"hihe s   e t   e:):)bWh:))s)w?).w//Dp.RD\"\n",
      "batch 21490  loss=179.0347  steps/s=84.57  prediction: \" based\n",
      "\n",
      "whats contributed to it the most\" => \"tyt r ceiame7eeb\n",
      "w h\n",
      "str t toretete et t\"\n",
      "batch 21492  loss=161.4333  steps/s=93.51  prediction: \"mm\n",
      "yeah seems like some nihilistic thing\" => \"eieint ye t\n",
      " ea wlIkcIbFIkI.kg,pbuWbcbu/\"\n",
      "batch 21493  loss=171.9451  steps/s=100.69  prediction: \"\n",
      "LETS GET IT!!!!\n",
      "https://t.co/oAV7UBBlmp\" => \"\n",
      "lth iasttoS a  ESSGGLkfS\n",
      "GETSIGmpb::/AV\"\n",
      "batch 21494  loss=168.2082  steps/s=104.82  prediction: \"he building -&gt; increase skillset loop\" => \"e g sn ot\n",
      " nii   ii  igg ii i iii   itll\"\n",
      "batch 21495  loss=161.5676  steps/s=94.04  prediction: \"hem better bc you can do engine analysis\" => \"e s  neetetete t tt c e  yeycbn ne  eaan\"\n",
      "batch 21496  loss=164.8825  steps/s=91.37  prediction: \" opposed to satisfying) two-way auctionâ€¦\" => \"tf p    i f asasspsps  os ssssisi ttt t \"\n",
      "batch 21497  loss=165.0259  steps/s=104.36  prediction: \" v. move forward/backward is layer stuff\" => \"tev  ne t c,   ovv   o    rwrraraarr wa \"\n",
      "batch 21498  loss=175.4048  steps/s=107.02  prediction: \" I know!!! I laughed so hard when it hit\" => \"t  t t    r !!rw!w  wara d   ra ar r  r \"\n",
      "batch 21499  loss=162.0826  steps/s=88.78  prediction: \" since llms are not great with zig (ime)\" => \"tos  nsi e   e sl m   le       e e   i  \"\n",
      "batch 21501  loss=161.2104  steps/s=97.04  prediction: \"dates/incentives to fund ai safety stuff\" => \" ca otnta aeee eaneete  enntene n  fsfst\"\n",
      "batch 21502  loss=168.4457  steps/s=94.97  prediction: \"inlet like me to test experiments out on\" => \"near   c  r    li  l ee e te itee etr t \"\n",
      "batch 21503  loss=162.8171  steps/s=100.39  prediction: \"ng them as irrational, then assigning 0â€¦\" => \"t  ri eh  su  n ,,ddpzwcTfzhum,zw\"mc\"0p0\"\n",
      "batch 21504  loss=165.6680  steps/s=102.43  prediction: \"minds me of this https://t.co/riUOdjhmWV\" => \"ane  n  txokiax kRðŸ«¡R,m,n#.fhuf,fOÉªmgp0â€¦0\"\n",
      "batch 21505  loss=185.2591  steps/s=96.05  prediction: \" your own game engine\n",
      "challenge accepted\" => \"toudwd iige otm to   ot  e cn aieegaengc\"\n",
      "batch 21506  loss=161.4724  steps/s=64.46  prediction: \"udwigABAP Insanely helpful, thanks a ton\" => \"sw   dwwig  e   gon  oe  elln g eccceelc\"\n",
      "batch 21507  loss=149.9989  steps/s=103.55  prediction: \" learn if youre not an opening memorizer\" => \"tetoh wn t            o  n   oo nen nnnn\"\n",
      "batch 21509  loss=177.1228  steps/s=48.82  prediction: \" @ludwigABAP @echo4eva So much nostalgia\" => \"tluo        o    oo   o  n nn n nn noe o\"\n",
      "batch 21510  loss=170.5445  steps/s=105.45  prediction: \"pin it locked up https://t.co/ULHT2ys50k\" => \"lns @susto P Ap @p4pv4wSkvSkSku.w2wULHT2\"\n",
      "batch 21511  loss=167.0524  steps/s=94.36  prediction: \"h yes it is? I would literally sit on aâ€¦\" => \"ewh  tt\n",
      "nn tt s   s  s   uu     li li  l\"\n",
      "batch 21512  loss=163.4208  steps/s=94.19  prediction: \"irl. So in irl it is probably not as bad\" => \"neeae  lr onn in i    i   r  il ii   b b\"\n",
      "batch 21513  loss=172.6039  steps/s=88.81  prediction: \"t may be helpful https://t.co/vWFRQhJmDt\" => \" io mor ntn t mt b  f e f  tt t//t/F/F F\"\n",
      "batch 21514  loss=166.3018  steps/s=89.87  prediction: \" it that one RL phd keeps talking abt it\" => \"ts t hthtnntt h   t  t   e   et   e     \"\n",
      "batch 21515  loss=171.3081  steps/s=90.13  prediction: \"mirages keep getting crazier and crazier\" => \"enb    i  nh#AnoSkrRLv.vAzkBRpfz.zlkLzpf\"\n",
      "batch 21516  loss=170.9315  steps/s=90.97  prediction: \"cking a computable number from the reals\" => \"hesob nsesohxAt bCmsgyazyzkycgyz.zfkfug:\"\n",
      "batch 21517  loss=162.8528  steps/s=94.15  prediction: \" drag down/demotivate other team members\" => \"@or  d de d d d do dodedooo ae eteomte a\"\n",
      "batch 21518  loss=168.2643  steps/s=99.31  prediction: \"es in claude does the page size decrease\" => \"  I co  cno icldi i  deo s ed e ee   ee \"\n",
      "batch 21519  loss=169.9980  steps/s=98.02  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt  e ts toheytiwhcmdmlyc:g.-.J:JHJ.N:CH\"\n",
      "batch 21520  loss=169.7805  steps/s=94.54  prediction: \"dibly efficient and powerful compression\" => \" t eert in  neininieffrifin iffi cn efce\"\n",
      "batch 21521  loss=165.9700  steps/s=99.17  prediction: \"ight any pros youd get in the short term\" => \"nh ettietp n   t    o       t o  tt  hht\"\n",
      "batch 21522  loss=163.6575  steps/s=102.68  prediction: \"y guard? oh wait https://t.co/OrQfoQXval\" => \" oo oou uuouu ro    t    tt t tt/ ///tQ/\"\n",
      "batch 21523  loss=178.3060  steps/s=80.98  prediction: \"amebedan since ports dont allow weapons.\" => \"ti u e cn r  ai   t r s tt  t//t/o QwX w\"\n",
      "batch 21524  loss=183.2045  steps/s=106.76  prediction: \"d\n",
      "Yeah sleep makes things so much better\" => \" \n",
      "  meae nn   s eeY maeeseea esaes meshs\"\n",
      "batch 21525  loss=158.1083  steps/s=93.01  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"@ot uil  wt      s    s  ss s  s s  tt h\"\n",
      "batch 21526  loss=156.4060  steps/s=96.94  prediction: \"d useful stuff better with the new tools\" => \" bu u l full ut ffu  ttf    ttt   tee te\"\n",
      "batch 21527  loss=179.0310  steps/s=70.15  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"oiu o tuus f  s tf   tte   tttt   teet t\"\n",
      "batch 21528  loss=168.0862  steps/s=100.51  prediction: \"tion (which is a form of the above)\n",
      "\n",
      "Idk\" => \" ol  o  ti tcif n it   h i fffoh  ofh  o\"\n",
      "batch 21529  loss=159.8690  steps/s=93.46  prediction: \"d thing happens\" (like a nuke going off)\" => \" toet  t na  a     h     n n  n k  kk   \"\n",
      "batch 21530  loss=159.9432  steps/s=103.67  prediction: \"ding up the drive thru for 1000 episodes\" => \" v enneihe n  n  h e      h   r r  00000\"\n",
      "batch 21532  loss=161.2018  steps/s=104.98  prediction: \"rough a floppy disk inserted in my brain\" => \"ebai onleirt  loywughcfkgygdwyk0kyk0vhkk\"\n",
      "batch 21533  loss=172.8951  steps/s=106.81  prediction: \"d of just putting in more and more hours\" => \" oo ten  gi  sntdstt i guin  tttn d  nn \"\n",
      "batch 21534  loss=184.4396  steps/s=96.99  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"r s  ahtetat i egunt i iiono t tt F FW55\"\n",
      "batch 21535  loss=178.9985  steps/s=89.67  prediction: \"h's run are: samplesize=64, epochs=100,â€¦\" => \"esgaht sranpa n : s:aparszps==6=e=6=44s=\"\n",
      "batch 21536  loss=190.9127  steps/s=88.38  prediction: \"on every monday and thursday of the week\" => \"r      sredeon ssoe donnn eyrysy dno ada\"\n",
      "batch 21537  loss=169.8327  steps/s=89.13  prediction: \"ing already paved paths is the only wayâ€¦\" => \"n  rn  tp  g aod ipi p  pt pd hathd dyay\"\n",
      "batch 21538  loss=164.1979  steps/s=87.67  prediction: \"and completely unknown to the other half\" => \"td o         ll plp l  nloon en nn e tnn\"\n",
      "batch 21539  loss=169.3486  steps/s=88.61  prediction: \"memory of doing a hard thing in the past\" => \"e yieitratoet eugwm#rc#prm#chugdð—°uodðŸš€gmu\"\n",
      "batch 21540  loss=162.4884  steps/s=84.47  prediction: \" the scaling laws for language models...\" => \"the t eneutut n   ta aeg l l r     oa eg\"\n",
      "batch 21541  loss=169.4836  steps/s=88.45  prediction: \"hine now. unless anybody has a spare one\" => \"en setn  ttm   iee nta e   nn an   sns n\"\n",
      "batch 21542  loss=170.1740  steps/s=91.39  prediction: \"how it is in c++. Trace them rays brotha\" => \"el \n",
      "oeln w s    ii +++ i++ +        es  \"\n",
      "batch 21543  loss=163.0785  steps/s=88.43  prediction: \"ogan?? was he on sidetweets or something\" => \"ur h  je  o? onw      e  ee s ee     e s\"\n",
      "batch 21544  loss=163.6437  steps/s=86.75  prediction: \"o beta testers, and the world soon after\" => \"ube  nte tet   t eee  te tt   t s e oo o\"\n",
      "batch 21546  loss=167.1335  steps/s=90.98  prediction: \"how it is in c++. Trace them rays brotha\" => \"el \n",
      "oeln w s    ii  +  i++++        es  \"\n",
      "batch 21547  loss=175.7768  steps/s=87.66  prediction: \"n I drink tons of coffee wtf\n",
      "yap yap yap\" => \" wa ihn  eh e Isdu.nT,ht.msefmw,k..pkr\n",
      "y\"\n",
      "batch 21548  loss=167.1319  steps/s=93.27  prediction: \" unsurvivable, when in fact, youd manage\" => \"tse   otogie  u n sev vvvin  en ,nn, , u\"\n",
      "batch 21549  loss=164.5271  steps/s=94.92  prediction: \"r the picture\" for any industry or niche\" => \"eteh ten  n   tepmdwp\"b\n",
      "ub\n",
      "\"rb'pyc\n",
      "pcc\"w\"\n",
      "batch 21550  loss=188.9682  steps/s=53.21  prediction: \"@ns123abc Yee\n",
      "complex w a bit of chaotic\" => \"soolnr   t   ee\"urr   e  ou  nr  ry  nrn\"\n",
      "batch 21551  loss=180.3764  steps/s=97.62  prediction: \"you have ffmpeg installed on your system\" => \" u  enent em t ah  eu t tent t en t s en\"\n",
      "batch 21552  loss=176.5403  steps/s=100.57  prediction: \"te wow\n",
      "\n",
      "followed https://t.co/riXL2UlhdY\" => \"hlt  edFo ntte  pygxcywin:\n",
      ":flg.pa:dLXL2\"\n",
      "batch 21553  loss=185.5516  steps/s=95.64  prediction: \"zzl\n",
      "\n",
      "Or maybe he got it from someone idk\" => \"ioBlysomel\n",
      "Ot  aIO@OroklkbOg/lcgbrfgfmbl\"\n",
      "batch 21554  loss=184.9021  steps/s=84.66  prediction: \"wigABAP thats why they call him zigmobly\" => \"hll @  u yb@b eAPbPBrPBAPAmgfbaycrflydkðŸ›‘\"\n",
      "batch 21555  loss=173.6845  steps/s=88.40  prediction: \" pieces until you have solved the puzzle\" => \"to   z psge    ntieyee   yoyl yve s lve \"\n",
      "batch 21556  loss=168.3037  steps/s=98.72  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" to   th e   n  ev n eo o ioleo  eiDeDDe\"\n",
      "batch 21557  loss=172.0493  steps/s=98.21  prediction: \"e component is the key to crazy stuff...\" => \" pons   ne onet sne n  t  ont ce ocoto  \"\n",
      "batch 21559  loss=212.5507  steps/s=11.98  prediction: \"reply: @CConnorMahoney mate in two* oops\" => \"espy: @be tps  em\n",
      "bmmconnkllhmgknbkkkmhp\"\n",
      "batch 21560  loss=182.3220  steps/s=109.88  prediction: \"s, have back and forth conversations etc\" => \"  nr i c casa   ah atoh  a  trocv  nvevt\"\n",
      "batch 21561  loss=173.4493  steps/s=93.32  prediction: \"chain' (see imgâ€¦ https://t.co/7Zq2swkcIS\" => \"a re  ti 'r( ts b(lâ€¦vâ€¦v'pâ€¦:h:yl(:â€¦7Z7Zq2\"\n",
      "batch 21562  loss=167.7120  steps/s=88.37  prediction: \"ecide to do this\n",
      "\n",
      "#1 tho?? Why post face\" => \" t   c dde d   o  o t  o t #  ?o ?o ?? t\"\n",
      "batch 21563  loss=166.3907  steps/s=84.93  prediction: \"ieved internally https://t.co/tbnU75n8eA\" => \"ns ae   ee  dieeeed ithn  htt/t/tt//////\"\n",
      "batch 21564  loss=166.5493  steps/s=100.67  prediction: \"ink in part bc you have more to remember\" => \"ng eneti i r  pi i i  n e e o  tre  m  e\"\n",
      "batch 21565  loss=181.4561  steps/s=101.98  prediction: \"those games lool\n",
      "\n",
      "funny number go WAY up\" => \"ha h i t   t   ekm\n",
      "mygnphaukgfaypgbmWYY\n",
      "\"\n",
      "batch 21567  loss=202.7400  steps/s=11.26  prediction: \"reply: @CConnorMahoney mate in two* oops\" => \"eply: @thast   ekm\n",
      "mygnphaukgfaypgbmWYY\n",
      "\"\n",
      "batch 21569  loss=174.0383  steps/s=108.43  prediction: \"ike a combinatoric sized pain in the ass\" => \"ne   eod oo   no iito   o aic inon  n ia\"\n",
      "batch 21570  loss=181.5037  steps/s=90.31  prediction: \"norary dan if i can be an honorary denis\" => \" w  c aebeoserttkmxhnphb@cgdvbokafyhfgdc\"\n",
      "batch 21571  loss=184.2270  steps/s=89.17  prediction: \"u helped a ton, hugely appreciate it bro\" => \"nchn e _1r1  h n  e  e      e  a pey  aa\"\n",
      "batch 21572  loss=168.2078  steps/s=100.03  prediction: \"useful analogies that show up everywhere\" => \"nt hs hnsusuuus ual su  ass  aa  h e eeh\"\n",
      "batch 21573  loss=168.1007  steps/s=87.95  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \" s eeseiese s s   e e     i i           \"\n",
      "batch 21574  loss=208.1936  steps/s=89.27  prediction: \" (to learn zig): https://t.co/tIgeHjq28P\" => \"t1oobq t gbzgo  (z ol(ti)):i)tisg:oItIg/\"\n",
      "batch 21575  loss=178.0565  steps/s=98.92  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"n  on n waIaXX  t\n",
      "LFLLnF!!!\n",
      "F\n",
      " F Fo/Wt0F\"\n",
      "batch 21576  loss=182.1616  steps/s=101.96  prediction: \"r you choose is not technically infinite\" => \"eatn soh w ver rvuycbwmkcbvbi+yiuvghvfve\"\n",
      "batch 21577  loss=167.2987  steps/s=103.83  prediction: \"orce you to clean to avoid embarrassment\" => \"u   f  cnonc      o c e eo oto o ra r  a\"\n",
      "batch 21578  loss=158.2446  steps/s=91.26  prediction: \"on the manager/grifter/sociopath problem\" => \"u  oe oot  o eoe  erea arerrarerrrrrtaor\"\n",
      "batch 21579  loss=181.2961  steps/s=90.07  prediction: \"p slop\n",
      "kino kino kino\n",
      "golden gate bridge\" => \"ltee eeon slop swlwpkpww\n",
      "kpkhfkkkkislgk\n",
      "\"\n",
      "batch 21580  loss=191.0714  steps/s=91.49  prediction: \" ITTTTTTTTTTTTT\n",
      "\n",
      "https://t.co/7uhSNn1VI6\" => \"t  e    ET\n",
      " EETG  TTII TTTTTTTTtT:o/\n",
      "htS\"\n",
      "batch 21581  loss=198.0892  steps/s=77.23  prediction: \"rz rent 1000 drone cluster. sleep in sky\" => \"ei    Ez r It  tT1y10y0l\n",
      "\n",
      "/tp.y//7u.NN/V\"\n",
      "batch 21582  loss=189.7418  steps/s=101.60  prediction: \"gABAP @sunsettler good, i enjoy the fuel\" => \" BP//TD n000t  lBgPB@PBAPA@h@.c//$ug,kk,\"\n",
      "batch 21583  loss=200.8595  steps/s=11.46  prediction: \"reply: @HSVSphere @DanielW_Kiwi stickers\" => \"eply: @Hn00á´›0 d BgPB@PBAPA@j@.c//iug,kk,\"\n",
      "batch 21584  loss=193.2651  steps/s=129.37  prediction: \"y: @0x158 @gizmobly avg circle gang post\" => \": @PDAlA A@A@AAsl ttseottteojojjjjj jj l\"\n",
      "batch 21585  loss=169.6791  steps/s=108.39  prediction: \" her it was fake https://t.co/Hgy6bLWfis\" => \"tar at ier n ioiiena i ite  i   ae/ H H/\"\n",
      "batch 21586  loss=177.3727  steps/s=103.22  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"ne     n    e eeolwo  ??wott  e/ / tppM2\"\n",
      "batch 21587  loss=169.8882  steps/s=97.62  prediction: \"so they get into an unending doom spiral\" => \" mi t  to \n",
      "\n",
      "tthst\n",
      "e tto ot te ntet en   \"\n",
      "batch 21588  loss=164.9917  steps/s=96.40  prediction: \"d stuff just happens. stochastic winning\" => \" to  o oo   u n  juut st st pstsstst ctn\"\n",
      "batch 21589  loss=171.9392  steps/s=94.31  prediction: \"he building -&gt; increase skillset loop\" => \"e   iniagi gii   gi  ii&gig i ine snitl \"\n",
      "batch 21590  loss=165.7958  steps/s=97.19  prediction: \"r been a better time to be a corn kernel\" => \"eaoe  @rtinh   rcmvv\n",
      "rbbhlyvngv.merwlkbm\"\n",
      "batch 21591  loss=170.8460  steps/s=95.59  prediction: \" is a wild computational rabbithole man.\" => \"tn rptel  as s w ca  as a a  a abiboaal \"\n",
      "batch 21593  loss=188.4431  steps/s=84.83  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"ebpe:r ho  @ate4e4zz88z880yTkz4i04T08TaT\"\n",
      "batch 21594  loss=182.4575  steps/s=83.79  prediction: \"day night and posted this sunday morning\" => \" tsi t e adt taddyh ytaddiis thadts ssoo\"\n",
      "batch 21595  loss=166.1320  steps/s=92.24  prediction: \". some, years later, have paid off a ton\" => \" s  s dh  dna  tho..h.yk.myym..cvk.nsv,.\"\n",
      "batch 21596  loss=169.7536  steps/s=104.36  prediction: \" to put in effort to unwire it (nbd tho)\" => \"thie taw  te  t on i    t ft t tt e it i\"\n",
      "batch 21597  loss=173.0337  steps/s=93.01  prediction: \" tuna is his alt https://t.co/izq2DGkjQT\" => \"toe  td ned  d       n  ii   tt/tt//ttz/\"\n",
      "batch 21598  loss=176.6974  steps/s=94.55  prediction: \"xplode!\"\n",
      "\"no its gonna explode twice!!!\"\" => \"peell    e e oi l\"!\" \"enexnnx eoneoee! !\"\n",
      "batch 21599  loss=185.2195  steps/s=54.21  prediction: \"fuck it. we ball https://t.co/Nz29MNoylA\" => \" l  n i r  !  e b!\"pw!gl!t\n",
      "w:xsN!xNxN929\"\n",
      "batch 21600  loss=174.1684  steps/s=96.61  prediction: \"n i googled jai\n",
      "\n",
      "https://t.co/0iPetw3vE0\" => \"tinoar   t w en yb\n",
      "k,wjj:/jbjIju::0,P.:/\"\n",
      "batch 21602  loss=173.9547  steps/s=96.38  prediction: \" God for helping us both out\n",
      "it was hell\" => \"werlao  lo Goo   e  r   oh  o    t ho th\"\n",
      "batch 21603  loss=174.2816  steps/s=91.24  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" da  n e  en e lrbsbjubhkyjab#ygbpbkbjub\"\n",
      "batch 21604  loss=176.3105  steps/s=97.04  prediction: \"everything is simple after you learn it\"\" => \" eren  n  iie  si  iegs  ii    ste eeri \"\n",
      "batch 21605  loss=173.2364  steps/s=99.20  prediction: \"ly makes things\n",
      "\n",
      "https://t.co/5PmnBqCvCt\" => \"        n a e  al  tltnlt  tntsss //55P/\"\n",
      "batch 21606  loss=179.8158  steps/s=95.79  prediction: \"verflow they shoulda forked this instead\" => \"ercaacoteally oth tstle/t/hth//PsBttqthm\"\n",
      "batch 21607  loss=170.0598  steps/s=103.66  prediction: \"isten to remixes of the ost all the time\" => \"n  ls   l t msn i  tt i  oe  t l  t   l \"\n",
      "batch 21608  loss=179.6574  steps/s=54.26  prediction: \": @sunsettler SAP is gonna go hella hard\" => \" @Wa r,she,i oenSAIxPIaIx,muxfIcmcxplx,x\"\n",
      "batch 21609  loss=182.7030  steps/s=128.57  prediction: \"5 custom tools speed things up a TON tbh\" => \" m  o l0senb oc SmSAP,apf,mundichcxTOTON\"\n",
      "batch 21610  loss=173.6738  steps/s=106.14  prediction: \"than \"heres a tool to solve problem xyz\"\" => \"hin, ien n i ei \"lgcul\"kw\"wc\"ar\"ps\"cv\"az\"\n",
      "batch 21611  loss=177.4572  steps/s=97.25  prediction: \"n doing on a method of learning faster)â€¦\" => \" wide  er beiteivrnvewbvdvbdbifgmdmbbeho\"\n",
      "batch 21612  loss=174.0092  steps/s=97.80  prediction: \"oger @sunsettler @tunient baller name xD\" => \"nreabfong gt @ne  @to@er@ten netn elentn\"\n",
      "batch 21613  loss=173.1274  steps/s=90.33  prediction: \"too, its good to break your priors intoâ€¦\" => \"  t  me domn  egIuIiwb,ebImngsybIrIIbhsb\"\n",
      "batch 21614  loss=169.1784  steps/s=102.70  prediction: \" linux like it hallucinated csgo or doom\" => \"tel l iene l li i  e    llllliiii  catcc\"\n",
      "batch 21615  loss=171.0137  steps/s=97.23  prediction: \"e enlightened than me, i need to wake up\" => \" tee   ee  r le eneee tehen eeete et e  \"\n",
      "batch 21616  loss=163.1497  steps/s=105.63  prediction: \"s on the first? only read the abs so far\" => \" anr oetn nhtt th   o t ?en    ee  e    \"\n",
      "batch 21617  loss=175.1274  steps/s=95.10  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \" ah nans  e  gto o  ntt ot e t/s a/PPPHH\"\n",
      "batch 21618  loss=193.2699  steps/s=93.74  prediction: \" know some ppl this would help immensely\" => \"wnrn t ne k a tekmnw kkmt npw  sod hwp  \"\n",
      "batch 21619  loss=191.5155  steps/s=98.13  prediction: \"x workflow loool https://t.co/qf4yGSoqeb\" => \"pko  i  f wo of oonorlu tisa:/ :/q/4q/4q\"\n",
      "batch 21620  loss=175.6499  steps/s=99.07  prediction: \"your post, your app has been declined :(\" => \" u catn e ry t  ,auruy oy, opyorsep  a a\"\n",
      "batch 21621  loss=177.5014  steps/s=102.64  prediction: \"g the hopfield one lol\n",
      "Funny coincidence\" => \" x  Waine npe po@yiEygFxhjFFcFwFuddwnid,\"\n",
      "batch 21623  loss=177.3189  steps/s=100.43  prediction: \" from scratch, and a bit of transformers\" => \"@onp m o rep  pc   m acccraa  aoa f rfof\"\n",
      "batch 21624  loss=175.7009  steps/s=105.52  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"ene   @ ic ba beLuLknkPypsfdLwybeyks\n",
      "gko\"\n",
      "batch 21625  loss=173.4099  steps/s=102.46  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \":de ne el  o      d e dethd dhdid d/t 7t\"\n",
      "batch 21626  loss=174.7871  steps/s=97.75  prediction: \"rd)\n",
      "- write down my thoughts in my notes\" => \"e  ing eth ld o B()\n",
      ")asd(vv(dywsr))--wor\"\n",
      "batch 21627  loss=184.3317  steps/s=10.71  prediction: \"reply: @gizmobly https://t.co/j0wN7UJaJ2\" => \"eply: @wan l  o 2()\n",
      ")asd(vvldywsrm)--wsr\"\n",
      "batch 21628  loss=170.1616  steps/s=96.45  prediction: \"all a month ago\n",
      "Dang good stuff bro!!!!!\" => \"nly tl n   tt th a   aoa  tg ot g g o g \"\n",
      "batch 21629  loss=181.9121  steps/s=84.29  prediction: \"goes 100x harder\n",
      "https://t.co/vEFK6lr8q9\" => \" thie    tehis ox1xhxsm110xxpx:d:E:K6x.E\"\n",
      "batch 21630  loss=178.9262  steps/s=66.99  prediction: \"minus9 This is my new favorite edm track\" => \"enhi  @1en  esr Tvxhx:/o:.xx.gEFK6FK8q98\"\n",
      "batch 21632  loss=167.4156  steps/s=99.21  prediction: \"er this applies outside of chess as well\" => \"   e n Tnih i  r as ep   ss otte o  erca\"\n",
      "batch 21635  loss=169.3805  steps/s=88.32  prediction: \" pfp of Euler ðŸ¤£ \n",
      "Gotta love overtraining\" => \"ariatnaianof f fE  E ðŸ¤£ðŸ¤£ðŸ¤£ ðŸ¤£o o G \n",
      " ve e v\"\n",
      "batch 21636  loss=178.4171  steps/s=25.50  prediction: \"eply: @calbch mind viruses are the enemy\" => \" ly: @aimeef f fE  ðŸ¤£ ðŸ¤£ðŸ¤£ðŸ¤£ Go o t \n",
      " ve e v\"\n",
      "batch 21637  loss=170.7160  steps/s=118.32  prediction: \"ding man! Yeah lmk how it goes next time\" => \" nsh hn  sea aian YY Y  aea o mh   e   e\"\n",
      "batch 21638  loss=173.7271  steps/s=94.57  prediction: \"upmillyair microsoft is a faulty company\" => \"teks  rtm ma a nm amr   t i o n o  e   e\"\n",
      "batch 21639  loss=173.0953  steps/s=100.66  prediction: \"forming around AI or aroumd a fear of AI\" => \"or t  eate  c mfyAfhAbigrcAIuAAIAAIAmbub\"\n",
      "batch 21640  loss=165.3264  steps/s=99.33  prediction: \"gh, regardless it needs a lot of work xD\" => \" t oen n   n  is8,IypIAngc,isuIdyh,um,,,\"\n",
      "batch 21641  loss=170.7128  steps/s=93.47  prediction: \"he building -&gt; increase skillset loop\" => \"a  ain ag  gii   g   in& ii i ine seisl \"\n",
      "batch 21642  loss=165.9083  steps/s=97.55  prediction: \"t info, hence why I expanded past papers\" => \" so  r ted fo,o yIcwrwrxhIuIx,xpIldxpc\n",
      "f\"\n",
      "batch 21643  loss=169.5466  steps/s=107.84  prediction: \"visualize 5d and if so whats your method\" => \"edynuosi ua i   5  i i za i d  a a sa o \"\n",
      "batch 21644  loss=159.9720  steps/s=101.08  prediction: \"ver, then go for a long walk\n",
      "\n",
      "ez a mimir\" => \"er oea   ve   ree   r  r  a no  a a  oa \"\n",
      "batch 21645  loss=167.6973  steps/s=96.12  prediction: \"learn and have fun building baller stuff\" => \" vro wn  po  rp anr  an   u aud  bnb lbn\"\n",
      "batch 21646  loss=173.3440  steps/s=101.31  prediction: \"mes often times.\n",
      "anyone can pivot though\" => \"e e rei  to ta  fs.fk.hkfkm.s.lfih.pp\n",
      "vf\"\n",
      "batch 21647  loss=166.4021  steps/s=95.43  prediction: \"learn and have fun building baller stuff\" => \" aro wn  po  rp anr  an   u aud  bnb lnn\"\n",
      "batch 21648  loss=171.4279  steps/s=93.97  prediction: \"caveman focuses on\n",
      "but double down on it\" => \"tnio  ehenot e sivgvveamvifgubcbv\n",
      "m\n",
      "b\n",
      "\n",
      "b\"\n",
      "batch 21649  loss=173.2340  steps/s=91.66  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \"he s @e oernm e IcIuI\n",
      "IumjIku0gw%\n",
      "1wtj%h\"\n",
      "batch 21650  loss=170.9129  steps/s=99.78  prediction: \"y put it back, just gotta wait a few yrs\" => \" cosaalalall  t   t      t a t tt t t t \"\n",
      "batch 21652  loss=182.0139  steps/s=92.80  prediction: \"t.co/RTzhOLWPSu) https://t.co/gkPHDZ6BV2\" => \"h notth%//.  ot WWOLWWPPS))S:)p).:/H.HHH\"\n",
      "batch 21653  loss=185.1901  steps/s=27.96  prediction: \"st: caffeine is steroids but for posting\" => \"  a  n etsn/RR tOOWWPOLWPh.)SP)/h..P//ZP\"\n",
      "batch 21655  loss=178.1449  steps/s=114.21  prediction: \"in 2029 actually\n",
      "https://t.co/198mtENwVf\" => \"ng set tns n    22 t  te tt/p ///tc/////\"\n",
      "batch 21656  loss=174.6072  steps/s=90.38  prediction: \"re ways than one\n",
      "https://t.co/EY4mlytbld\" => \"esli   ouege w  kymhwororwskuc:EaEY4\n",
      "hEY\"\n",
      "batch 21657  loss=170.0566  steps/s=93.65  prediction: \"calization does this too, and I suspectâ€¦\" => \"ane ouentd)e   gVqzuzfzb)\n",
      ")\n",
      "()kyzbzfgzI)\"\n",
      "batch 21659  loss=169.8515  steps/s=101.77  prediction: \"t lately\n",
      "\n",
      "Your RPA loop is pretty useful\" => \"h(o hnsoe  it a kwYxp\n",
      "YYPA,RRAAuYRRAARPA\"\n",
      "batch 21660  loss=172.1978  steps/s=103.91  prediction: \"mpactful on actual success for me though\" => \"elhfa n i  apthtfwkðŸ˜‰ygkvirpvrypgrypkf~fo\"\n",
      "batch 21661  loss=167.8564  steps/s=102.87  prediction: \"onscious does work in the background idk\" => \"n y ccb c ss soc st co   io  e  er    e \"\n",
      "batch 21662  loss=174.2576  steps/s=92.94  prediction: \" super awesome, wait why multiple chats?\" => \"tua s sra   s  s  ,  s  s,wea aaw em  ah\"\n",
      "batch 21663  loss=178.6147  steps/s=69.59  prediction: \"t be a full moon\n",
      "https://t.co/6Wn0PGfn4U\" => \"hahs myo  e   l swzz,zp,iz:w/yhp6w66WG6W\"\n",
      "batch 21664  loss=180.7443  steps/s=97.62  prediction: \"nfidence\n",
      "\n",
      "\"idk\" is often the best belief\" => \"gidet       i  shvs /lvdklmnpr\n",
      "bnckkfrcd\"\n",
      "batch 21665  loss=178.5786  steps/s=98.77  prediction: \"h mines a $10 quintillion metal asteroid\" => \"efenr  mnteiecite$$qs q  qqeqqin  eei et\"\n",
      "batch 21666  loss=211.3101  steps/s=101.49  prediction: \"needed to dl this. meme delivery service\" => \"g  o  ianyoieiiekfdMboikllHh.i..m.mmmTAv\"\n",
      "batch 21667  loss=170.8657  steps/s=103.96  prediction: \"ed for editing videos would be so goated\" => \"  ee egn n doiseded ed oedg eii ioi dsos\"\n",
      "batch 21668  loss=166.1632  steps/s=102.98  prediction: \"asily, and they compound with each other\" => \"nt beeant  eee la  eea o e e ooot      t\"\n",
      "batch 21669  loss=171.4751  steps/s=80.35  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \"hre inc   bd bhexSsiSiSf,flw,y,O)mpmp4Of\"\n",
      "batch 21670  loss=180.3087  steps/s=98.26  prediction: \"them depth wise, learning â€œon demandâ€ (â€¦\" => \"hiari  a idm c epaak,mkl,lrh,giâ€œâ€œ,â€œâ€œe,,â€œ\"\n",
      "batch 21671  loss=183.4895  steps/s=93.08  prediction: \"an that sounds like such a relaxing time\" => \"nd m tith tt nmeemt atatdn oskd decnianr\"\n",
      "batch 21673  loss=181.9628  steps/s=87.58  prediction: \"ysis\n",
      "\n",
      "Hyped to see you in a future one!!\" => \": asaaeeas n \n",
      "iasls\n",
      "tt\n",
      " dy ayta ssyuy o \"\n",
      "batch 21674  loss=176.6381  steps/s=91.81  prediction: \"rite shakespeare https://t.co/czMo11bjnn\" => \"eplor on r d   wyupjo:kkka:ki:.:Mh:z::/M\"\n",
      "batch 21675  loss=164.4694  steps/s=96.61  prediction: \"nse and you can't efficiently work withâ€¦\" => \"gea t e'ondtdo tuhk'k'4ykc'm'k'dhecfdcak\"\n",
      "batch 21676  loss=187.1400  steps/s=96.89  prediction: \"king stuff part of twitter is so fun wtf\" => \"eng c  n  t0  anknt  fficee yf  ww w iwi\"\n",
      "batch 21677  loss=224.7460  steps/s=75.28  prediction: \"OT MOVEMENT LADS https://t.co/NxHblUdYfq\" => \"D  O_t et  uOfa L t Lffiprtp r  tf toffi\"\n",
      "batch 21679  loss=182.7312  steps/s=104.71  prediction: \"n just do things https://t.co/909bTHzmml\" => \"gtat sa EMTNtarejSAotjiwjgswwtpx::/N:Y0Y\"\n",
      "batch 21680  loss=177.4309  steps/s=93.89  prediction: \"er important first step towards progress\" => \"    gono prpt nr trstttast stspartepproa\"\n",
      "batch 21681  loss=173.2836  steps/s=86.85  prediction: \"al hypotheses to search through and test\" => \"nl r soa      ep tepoth oe es  sht hoooh\"\n",
      "batch 21682  loss=182.1071  steps/s=87.52  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e ea:i  2ui21   s211hyrh1vm1rcuhum,gug,,\"\n",
      "batch 21683  loss=178.6900  steps/s=96.09  prediction: \"et looking thing https://t.co/2bxyyufxD7\" => \" t p tonleae o eolios  thog s t/hs 2t2/2\"\n",
      "batch 21684  loss=181.6406  steps/s=86.33  prediction: \" its crack bro. be careful. i warned you\" => \"tf tle nleai n crgrot  t /c /2t/o.e.xD.x\"\n",
      "batch 21685  loss=178.8559  steps/s=70.83  prediction: \"jaynz_way Tetris 3d would be interesting\" => \"ust  soket   oc r babr 3 oc ul. b.tf oeu\"\n",
      "batch 21686  loss=181.1509  steps/s=102.51  prediction: \"e21 i built  : D\n",
      "https://t.co/Z3pxGgtbr3\" => \" 1lo @eczeh12 i t b b: u: DtiDt /eZ/Z3Z3\"\n",
      "batch 21687  loss=178.8503  steps/s=91.75  prediction: \"than \"heres a tool to solve problem xyz\"\" => \" er,  ene\" i  i \"lgcul\"kw\"uc\"ar\"psvcv\"az\"\n",
      "batch 21688  loss=180.4384  steps/s=88.20  prediction: \"n its value sharing it causes\n",
      "\n",
      "full linâ€¦\" => \"gbrnohenhvroetn volmivilvevvhvrtngaahevt\"\n",
      "batch 21689  loss=170.4863  steps/s=91.14  prediction: \"so i havent used anything like webgl yet\" => \"  so  no gas  s  e   sa snnnit ie n e i \"\n",
      "batch 21690  loss=181.9031  steps/s=79.92  prediction: \"gABAP you also like ror?? Baassssseeeeed\" => \" BAPateswBgP Ao Pvrcvgvsku@v,avhyBhr?vBv\"\n",
      "batch 21691  loss=172.3318  steps/s=98.87  prediction: \"e, which is compounding\n",
      "\n",
      "other stuff too\" => \"   t  hhw  h     h oc  coiiohoi ooi \n",
      "o t\"\n",
      "batch 21692  loss=174.7257  steps/s=93.69  prediction: \" ill dm you a link to it around the 25th\" => \"tn eweele l  l  l  i   no io  o  tt tt  \"\n",
      "batch 21693  loss=184.7467  steps/s=95.47  prediction: \" quality than \"loading bar\" type writing\" => \"tuee ne qqqt    ttartt\"i\"\"nebin \"b\"a  tr\"\n",
      "batch 21694  loss=175.5600  steps/s=87.10  prediction: \"ave been trying to compress these lately\" => \"te    e tee ne n  ne  o to no toe oeee  \"\n",
      "batch 21695  loss=170.5478  steps/s=84.14  prediction: \"ler its always an :x day here on twitter\" => \"ya  s  et e i att n  a  n s  e e s eees \"\n",
      "batch 21696  loss=183.0467  steps/s=74.25  prediction: \"tswhodis madness https://t.co/8N9XXq7c59\" => \"h  o  r pow ad edv::xy:xyv/:xv:x88N8X/8N\"\n",
      "batch 21697  loss=177.3697  steps/s=91.34  prediction: \" this a bit here\n",
      "https://t.co/LodKIC2izF\" => \"the  atthtr a  btihri thrtibh /hoh/LLLKK\"\n",
      "batch 21698  loss=181.3492  steps/s=91.89  prediction: \"c high entropy stuff that fits the curve\" => \"ofp  ta ehor ea \n",
      "omacb:rff.k\n",
      "punpeIpauzh\"\n",
      "batch 21699  loss=179.3648  steps/s=86.40  prediction: \"t prototype done https://t.co/9pKpWZA02k\" => \" thg  roh nr  ntuomyys:rof.t\n",
      "\n",
      "inpi:KsK.W\"\n",
      "batch 21700  loss=177.2405  steps/s=92.66  prediction: \"d some stuff!!!!\n",
      "https://t.co/160qafZKAk\" => \" to   ii t ssu!!!!f s!!! !stt sst//f6/66\"\n",
      "batch 21701  loss=168.0945  steps/s=96.78  prediction: \" by breaking the file into smaller files\" => \"tuts isb b b ie   e  i  ee  i  t  i llll\"\n",
      "batch 21703  loss=184.1595  steps/s=89.27  prediction: \"uff\n",
      "\n",
      "1. frogbrot https://t.co/JfifQf9WWd\" => \"tf y r a dlffttfto   fffoo   ttot.ro/.ti\"\n",
      "batch 21704  loss=194.0784  steps/s=93.18  prediction: \"bile and desktop https://t.co/f8MrtrXK28\" => \"etl sdted\n",
      "n  ede dse oetotto  ss /t8/Mt8\"\n",
      "batch 21705  loss=177.8814  steps/s=91.15  prediction: \"nsions have a different message, I think\" => \"  st  s \n",
      "en    syeavvmffd/av\n",
      "rmvpymm,nII\"\n",
      "batch 21706  loss=176.6508  steps/s=87.60  prediction: \" sudo systemctl restart systemd-resolved\" => \"theens   hso setdssnsuteastsrsst mrs --e\"\n",
      "batch 21707  loss=179.9572  steps/s=85.95  prediction: \"probably because we were ballin too hard\" => \"lob @a  p9uea  dvabmpmyfdmcyulyv-yagt,k \"\n",
      "batch 21708  loss=170.4364  steps/s=87.12  prediction: \"es courage\n",
      "lack of courage is a weakness\" => \" s\n",
      "eenesatnoe onccaek  ceco c coaae a  k\"\n",
      "batch 21709  loss=161.7269  steps/s=82.42  prediction: \"omeik that is super super super cool wtf\" => \"nin eseatha  k tc s csuoureu  ur au e  s\"\n",
      "batch 21710  loss=170.3400  steps/s=94.17  prediction: \"useful analogies that show up everywhere\" => \"n9 hsshnsuesuu  ual su  ass  aa  h e eeh\"\n",
      "batch 21711  loss=175.9796  steps/s=101.26  prediction: \" his story you wont regret it, its crazy\" => \"tas aa se a   s sso y  os  t  ro rt rtrt\"\n",
      "batch 21713  loss=181.6607  steps/s=75.51  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"n ssassasr   s s to r ooy  t  re it  ert\"\n",
      "batch 21714  loss=171.3662  steps/s=94.39  prediction: \"experience but i work w someone who does\" => \" pt a   e xxt p e xpeet e  e w  w o  o n\"\n",
      "batch 21715  loss=230.5588  steps/s=103.96  prediction: \"GOT NOTHIN ON US https://t.co/daGXfFWrIv\" => \"OTYIT   OYrWRiH AAwUSUUSOTHIs:USrISNOG:G\"\n",
      "batch 21716  loss=195.9830  steps/s=86.96  prediction: \"5 custom tools speed things up a TON tbh\" => \"-T  O  0705e5Uc GAwOS:/wI.\n",
      ":p::GX.FWOIXG\"\n",
      "batch 21717  loss=179.4223  steps/s=90.48  prediction: \"mul, transitions from one derivative toâ€¦\" => \"ecc i envvzin  ezfduv,h,,z,,chvavi,l,ff,\"\n",
      "batch 21718  loss=171.4806  steps/s=92.84  prediction: \"ng signals from constant individual lies\" => \"  re eito\n",
      "gdsnenwtpupluwemgwawawd wuvfvl\"\n",
      "batch 21719  loss=170.7266  steps/s=98.74  prediction: \"d of random strings, and removing a bitâ€¦\" => \" io l n  ni      n o   trndnd   nornn   \"\n",
      "batch 21720  loss=172.6692  steps/s=97.41  prediction: \"ind groups of ppl who love what you love\" => \"n   e  n  ts si s   pp    s po wo       \"\n",
      "batch 21721  loss=175.4026  steps/s=40.66  prediction: \"ly: @scheminglunatic @calebsirak do tell\" => \"y: @t aotan  os p   pp    w wo wo       \"\n",
      "batch 21722  loss=167.7267  steps/s=98.47  prediction: \" the time. personally i havent done this\" => \"thestet  tbt e t t eet ilo  ell n een ee\"\n",
      "batch 21723  loss=165.4488  steps/s=90.47  prediction: \" by breaking the file into smaller files\" => \"tuts  sb b b ie e e  i  ee  i  t  i l ll\"\n",
      "batch 21724  loss=176.1569  steps/s=94.28  prediction: \"s:\n",
      "\"hmm is it x+y*z/a + exp(b)\" -&gt; no\" => \" \n",
      "/r  uwt :  \n",
      "sis\n",
      " ++m+s*x++xxx* z  xx(\"\"\n",
      "batch 21725  loss=177.9295  steps/s=96.28  prediction: \" absolutely mind blowing post all around\" => \"t  tlin te tl o lnlutl ini dinslggswint \"\n",
      "batch 21726  loss=169.3627  steps/s=95.76  prediction: \"s called it tho, dont practice deception\" => \" bo    este  et litits  t ot  o   d ct o\"\n",
      "batch 21727  loss=171.4147  steps/s=94.02  prediction: \"dering doing another one of these monday\" => \" r    s snsoi ing gg non  onn eeon  oe n\"\n",
      "batch 21728  loss=185.2697  steps/s=43.98  prediction: \": @archived_videos definitely the latter\" => \" @h.diese      mvIm.chIkng.gfmkcdsyAm.c\n",
      "\"\n",
      "batch 21729  loss=189.6573  steps/s=92.41  prediction: \"ou get like 5 seconds to shoot your shot\" => \"u dD  HA e  y   55 e  n       oose    s \"\n",
      "batch 21730  loss=180.5325  steps/s=92.08  prediction: \" srsly the golden age of building things\" => \"teo   too ho     slso  s  eo  g lde geg \"\n",
      "batch 21731  loss=182.4201  steps/s=87.98  prediction: \"/t.co/UIDMbyf7hp https://t.co/DOgAJOsPbg\" => \"t p   \n",
      "  \n",
      "etto///U/UUU777M77hph:hptttO//\"\n",
      "batch 21732  loss=178.3365  steps/s=79.47  prediction: \" its a sign you should make react in zig\" => \"tn  tdI   B s  tssts oys  ooh hh ht  e t\"\n",
      "batch 21733  loss=165.9585  steps/s=87.47  prediction: \"hat light mode is good for you. i don't!\" => \"ete tnth tiththt t t th td  d   do  oo o\"\n",
      "batch 21735  loss=170.0020  steps/s=85.10  prediction: \"monstration purposes, i am not a heathen\" => \"ere  as ntr  n  /'mwf/wfstfwcfof/pwspu,u\"\n",
      "batch 21736  loss=167.9319  steps/s=89.75  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \"g  hhts  sb  degbcfrp0d0nb0::/b:bf:JBBM4\"\n",
      "batch 21737  loss=169.2292  steps/s=89.70  prediction: \"s of thought, and your ability to thinkâ€¦\" => \" fe   acn e   nse thtaou  nt thuira ihiy\"\n",
      "batch 21738  loss=185.7328  steps/s=89.85  prediction: \" got it!!! LFG!! https://t.co/uOhxqR3F8G\" => \"tot bt  e bgt ðŸ¤¯e LF! FFt!  GFt  :/tt tqt\"\n",
      "batch 21739  loss=178.8702  steps/s=92.17  prediction: \"ely matters when the post is this useful\" => \" yer l a e ttrttiersere w tlesyyse i th \"\n",
      "batch 21740  loss=177.8688  steps/s=78.78  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"pane  inmtat  nth@ @ehe MMthes@y@@ @ she\"\n",
      "batch 21741  loss=172.2972  steps/s=90.32  prediction: \"a youtube video from a small channel, Iâ€¦\" => \"nle lepuey b  u ue o ie f f   a ma a  el\"\n",
      "batch 21742  loss=168.2187  steps/s=89.55  prediction: \" to recover from if it becomes a problem\" => \"thr otot  oor r  or o oe rr  oeo       o\"\n",
      "batch 21743  loss=170.6652  steps/s=87.00  prediction: \"ate? i mean i can guess, but.. nice work\" => \"n  th   stc caaai  ac an ie a    u    e \"\n",
      "batch 21744  loss=164.1188  steps/s=87.03  prediction: \"utomatically imagine letters as colored?\" => \"n ao oda oaaa oaa  iaaaiiaait   ee e te \"\n",
      "batch 21745  loss=174.1076  steps/s=91.55  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" iis n  t et e lrbsbjubhky.wbqqgbpbkbjus\"\n",
      "batch 21748  loss=168.9207  steps/s=88.99  prediction: \" gonna go my guy https://t.co/DHKcK43289\" => \"tot ini tti ogn  g gnu g   ut ot /t//DK/\"\n",
      "batch 21749  loss=178.6819  steps/s=84.59  prediction: \"feels better than giving to the homeless\" => \" c   p nee teiesybkbkhinmbavgbvvyvgvyvyv\"\n",
      "batch 21750  loss=175.6269  steps/s=91.21  prediction: \"C $ they raisedâ€¦ https://t.co/8AMjPz3k5K\" => \"ownd is t VC  ti:fuâ€¦k$rthâ€¦â€¦Vâ€¦krA::8:MjPz\"\n",
      "batch 21751  loss=221.9539  steps/s=85.92  prediction: \"E CAMERA WORKING https://t.co/L0OJnFdB2X\" => \"RGOlAG$O+VERGCa RORKORKKNNNGINGI::/L0L0O\"\n",
      "batch 21752  loss=185.4605  steps/s=93.64  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \"t  s  @00sk 000eesk ks0kk kt000 /t ce Rt\"\n",
      "batch 21753  loss=174.7580  steps/s=96.33  prediction: \". seems like a fancy type of hard coding\" => \" she  .ren  s t r.gwmwmhfu\n",
      "pkghtpcsk.fpn\"\n",
      "batch 21754  loss=174.9443  steps/s=93.51  prediction: \" never rule things out as impossible tbh\" => \"tete  eet teeettn uet tusesu itu  uit t \"\n",
      "batch 21755  loss=170.0742  steps/s=94.92  prediction: \"ur goal is to obliterate them with ideas\" => \"n ean  tr go  s oa e ttr to ro atait r  \"\n",
      "batch 21756  loss=190.4574  steps/s=18.43  prediction: \"eply: @jsuarez5341 smart move smart move\" => \" ly: @teerno   5ha e ttr to rsiatait r  \"\n",
      "batch 21757  loss=168.3621  steps/s=99.54  prediction: \"sively going up\n",
      "But make responsibilityâ€¦\" => \" bll  @ lrreo  eiieg gggg i gBe ir  ie  \"\n",
      "batch 21758  loss=180.7533  steps/s=103.85  prediction: \"ce nice\n",
      "Any idea what youre gonna print?\" => \"h snos  n o  i egAAuA\n",
      "ApAkAckdAdowhdbgdi\"\n",
      "batch 21759  loss=178.4805  steps/s=93.20  prediction: \"neMTB Skill issue canada\n",
      "Get better news\" => \"gM  oioen    i ewSAhA\n",
      "ApAkwckgcGypGbGg?w\"\n",
      "batch 21760  loss=176.2805  steps/s=90.92  prediction: \"right words can change entire industries\" => \"etro shv    ph  ghkcancdivhadwbpcsndhidðŸ›‘\"\n",
      "batch 21761  loss=186.4791  steps/s=99.79  prediction: \"ess while retaining the same information\" => \"   etel ns res reta  tes  r te  ini t i \"\n",
      "batch 21762  loss=177.1924  steps/s=100.85  prediction: \"\n",
      "If someone hasnt made it by then I will\" => \"\n",
      " kidn sn nmt   \n",
      "IibðŸ¤¯kud\n",
      "Ik9hbybuporkckf\"\n",
      "batch 21763  loss=170.2916  steps/s=99.18  prediction: \"o him) and he begged to pay me to use it\" => \"rai   tnt io  i ) th  te ge d gg d  te o\"\n",
      "batch 21764  loss=174.8545  steps/s=94.42  prediction: \"ntellectus little italy?? nah. big italy\" => \"g      en nIe hem)cdmdmhbinaedbmb,bd?uy.\"\n",
      "batch 21765  loss=161.9886  steps/s=100.00  prediction: \"ntellectus To beat paranoia, accept risk\" => \"g In rt t rIe eecbTsuT?Tbiba.ybmbcbd.,y,\"\n",
      "batch 21766  loss=174.8469  steps/s=100.08  prediction: \"be allocate some time to do fun projects\" => \"u  no non   aeeao to  ota t  mo mo te   \"\n",
      "batch 21767  loss=168.9231  steps/s=82.77  prediction: \"whoa thats wild, old twitter could never\" => \" yt  sun  sr t oifgwsrh,wgcdoncud,brfjif\"\n",
      "batch 21768  loss=169.0135  steps/s=90.59  prediction: \"et good at the ones youre not so good at\" => \"  anem mnaaet tng  t tto oo ee to e  ooe\"\n",
      "batch 21769  loss=175.1752  steps/s=92.72  prediction: \"meone should make a zig finetune dataset\" => \"eney s ignonB t zzdbbb@khbhyzlzbkbkruz\n",
      "z\"\n",
      "batch 21770  loss=170.4421  steps/s=96.33  prediction: \"ros named tuna but he swam like a salmon\" => \"em aon   ieit ieckbupadr*wwdkruwawa\n",
      "ik\n",
      "g\"\n",
      "batch 21771  loss=176.3754  steps/s=94.54  prediction: \" way I implemented it might be different\" => \"taen\n",
      "misa e ea   e e   m e emet   mihien\"\n",
      "batch 21772  loss=167.9906  steps/s=85.39  prediction: \"ris yeltsins alt https://t.co/ugwGLYijll\" => \"ennd:toe n d boscgupwlwedw:lÉ´:.ngpa:/:LY\"\n",
      "batch 21773  loss=170.1474  steps/s=88.51  prediction: \"hat \"group photo\" means several entities\" => \"etp  e nn is thgr  hoo \"  ot ss etoao on\"\n",
      "batch 21774  loss=169.9926  steps/s=89.31  prediction: \"rogress\n",
      "Is the side proj the ml project?\" => \"eu  t  sr g   o IdmkkIkjkprkjoIjIkIvIFkd\"\n",
      "batch 21775  loss=181.4876  steps/s=89.72  prediction: \"of work every monday and thursday brotha\" => \"r  o i lre  o hn oor  r  roor eor  yy  a\"\n",
      "batch 21776  loss=174.3905  steps/s=18.02  prediction: \"eply: @djcows ok https://t.co/ZxLjHc2lnu\" => \" ly: @tioe  o r  oor  r  roorrady dyy  a\"\n",
      "batch 21777  loss=166.1726  steps/s=104.71  prediction: \"so i havent used anything like webgl yet\" => \"  s   n  s ss e  e s sa t nn t ie n e i \"\n",
      "batch 21778  loss=176.3722  steps/s=92.50  prediction: \"ng v interesting\n",
      "https://t.co/VCxWrHICr1\" => \"  e  n   int d  wvvkckuc:v:u.cdh:CVC:W\n",
      "H\"\n",
      "batch 21779  loss=169.4080  steps/s=100.76  prediction: \"miliar with a place and the things in jt\" => \"eni g @alioe n  fpbjubecbudfhybwyljjwjfw\"\n",
      "batch 21781  loss=168.9007  steps/s=102.95  prediction: \"n run on my laptop, which I can do w ML?\" => \"gtr Htr me site I]ykkI#Ick,nw,uwhukyun,m\"\n",
      "batch 21782  loss=181.0018  steps/s=80.43  prediction: \"wigABAP a friendly virus. one that talks\" => \" te    aniel At P,y,kISIcp,nw,uwhu.yMLML\"\n",
      "batch 21783  loss=193.8809  steps/s=109.51  prediction: \"y rgb-grey thing https://t.co/YGc4zRQJ90\" => \":wrn  ei  yry rel-ny ninh h t .  / o t t\"\n",
      "batch 21785  loss=173.0828  steps/s=107.00  prediction: \"s. im betting on that. but i am not sure\" => \"  y thataa ya tm yi tn.tath  n .n  t tb \"\n",
      "batch 21786  loss=180.2449  steps/s=23.01  prediction: \"eply: @yacineMTB Found cave johnsons alt\" => \" ly: @t  a ya y. hi tn.tath  n .n  t ti \"\n",
      "batch 21787  loss=178.0741  steps/s=107.37  prediction: \"e but kino video\n",
      "https://t.co/OLZUwIo8wn\" => \" poomteltstt   nkb okkieite \n",
      "\n",
      "p/p/OL///Z\"\n",
      "batch 21788  loss=169.1479  steps/s=93.34  prediction: \" not abt to read through all of its code\" => \"to  ts ob  o  n  n t   o t td oh  ro  s \"\n",
      "batch 21789  loss=150.8283  steps/s=99.20  prediction: \" the skill ceiling is really really high\" => \"thi t  t ea    t   i  l lliilli ll  ll l\"\n",
      "batch 21790  loss=168.2009  steps/s=93.01  prediction: \"he just checkmated because he got lucky\"\" => \"e bi h beh\"\"h shh het t eecce ceee e e e\"\n",
      "batch 21791  loss=182.9082  steps/s=87.67  prediction: \"fyb is there a SWE equivalent of goggins\" => \" bl  e@ 0s PcAPi@uxSWEgyquSWEWEqbqSWESkq\"\n",
      "batch 21793  loss=171.3115  steps/s=98.48  prediction: \"oncept but also show you how to apply it\" => \"n t  eeec bn cn c co  s a  oo toow oo wo\"\n",
      "batch 21794  loss=181.9963  steps/s=97.05  prediction: \" more cracked by the day, love to see it\" => \"ta t ce te   oe eoso  yyaye hh e  y   ho\"\n",
      "batch 21795  loss=209.5826  steps/s=89.23  prediction: \"1A9A19A26B19B10B29A13A33A35B33B32A8A AB\"\" => \"2B1i  t2oe e54056B5m4r54y529316s705l56i0\"\n",
      "batch 21796  loss=173.4021  steps/s=90.14  prediction: \"l ideas\n",
      "\n",
      "say if youre trying to learn ML\" => \"ytf ene l ned   eay yieee\n",
      "\n",
      "iy  l ia yre \"\n",
      "batch 21797  loss=164.7841  steps/s=90.52  prediction: \"a wave of weird suspensions going around\" => \"nled  tlei eb e   e s  ee  e    eiioo so\"\n",
      "batch 21798  loss=169.0037  steps/s=92.05  prediction: \"of the network (target, a_output, loss,â€¦\" => \"  ba fp  he   tte t rt  (t r t_ett_u_,,t\"\n",
      "batch 21799  loss=168.7779  steps/s=90.59  prediction: \"ncredibly painful, so a great motivator.\" => \" e otn   ie l  nb.yfwbruf)...gu.pyhdvb.f\"\n",
      "batch 21801  loss=172.0943  steps/s=89.38  prediction: \" his story you wont regret it, its crazy\" => \"tas aa sa a   s sys o  sy oy  ro rt  trt\"\n",
      "batch 21802  loss=171.5895  steps/s=92.89  prediction: \"ight any pros youd get in the short term\" => \"nh tiie thit   t    y    o  o o   e  hht\"\n",
      "batch 21803  loss=165.6368  steps/s=92.32  prediction: \"nts of time. its like skilling up almost\" => \" i   aieto s  h rc.,.m..bu.fndkcd.kf.y,n\"\n",
      "batch 21804  loss=178.9310  steps/s=95.88  prediction: \"xperience that will make me live longer)\" => \" l e  titioe tie  a t ae  eai  w l  l e \"\n",
      "batch 21805  loss=169.6081  steps/s=93.36  prediction: \"_opener oops i misread your comment my b\" => \"_rnnk  @ore_oooei o o eeo  oe r  oome   \"\n",
      "batch 21806  loss=183.8833  steps/s=90.80  prediction: \"gram rlly helped https://t.co/ymqE5CrUM0\" => \" aA   a  ieg  a dngar1dmhyl,h:/rl:d/h:qq\"\n",
      "batch 21807  loss=161.6396  steps/s=95.09  prediction: \"elped other ppl do that too\n",
      "\n",
      "and its fun\" => \" f  et  ht  eh  p    eh  tto o to t   to\"\n",
      "batch 21808  loss=172.2017  steps/s=92.48  prediction: \"ked bc i could make cool fun stuff in it\" => \"e on hont n c i ec  k coo h c o  toooel \"\n",
      "batch 21810  loss=168.6806  steps/s=89.55  prediction: \"o nothing for now but funny number go up\" => \" hs eht\n",
      " ton  onen oo non no  ou un   un\"\n",
      "batch 21811  loss=184.0224  steps/s=76.38  prediction: \"cle77 arabian mate is a similar good one\" => \"oipe  rarecieieg7uyrdmiwmbgaifhrygdumwwc\"\n",
      "batch 21812  loss=176.7414  steps/s=93.12  prediction: \"underneath again https://t.co/onRTkWZOBa\" => \"tde  h r ean rnnagternhptgent/rt:a:: RRT\"\n",
      "batch 21814  loss=164.6615  steps/s=92.05  prediction: \"res a reason they dont but i dont see it\" => \"eply ma r n o ithIdk,kigmb:m.vIrk,ck,.bB\"\n",
      "batch 21815  loss=161.0479  steps/s=82.10  prediction: \"ochenko curious, can you elaborate more?\" => \" k  ae ta  e       oss   t    o t b e  e\"\n",
      "batch 21816  loss=164.4637  steps/s=74.86  prediction: \"@btwphones thanks! its going well so far\" => \"0awoehet   aeo     oas  ut  boa t a te e\"\n",
      "batch 21817  loss=162.0614  steps/s=105.40  prediction: \"his wtf\n",
      "\n",
      "ill dm u a link around the 25th\" => \"eng t i  tt t it i      l     l dil     \"\n",
      "batch 21818  loss=183.4081  steps/s=96.11  prediction: \"d cost tracking\n",
      "\n",
      "https://t.co/GwHAwU1n1Z\" => \" to sotoen  c   es t ooccsn/\n",
      "cnn:\n",
      "GtH/Gt\"\n",
      "batch 21819  loss=169.0814  steps/s=96.14  prediction: \"hange your brain. something to think abt\" => \"et  ow  sowr  r norr r r  or  no  isa to\"\n",
      "batch 21821  loss=177.3478  steps/s=64.55  prediction: \"ouchdaily @pixqc https://t.co/1PFB9wT8Ra\" => \"nr horl  wura r nsqr q qntht  oo .o.F tF\"\n",
      "batch 21822  loss=172.4274  steps/s=106.40  prediction: \" cube, or.. uh.. https://t.co/6h2JJ5sHCE\" => \"toe   c e  e  e  .  e .. . ...e//.. / th\"\n",
      "batch 21823  loss=205.7245  steps/s=83.64  prediction: \"icCapital COMMENCE OPERATION BRAIN DRAIN\" => \"tes o hr,ior. t. MOOCEENENOPPOREJJOIONEE\"\n",
      "batch 21824  loss=212.0442  steps/s=98.71  prediction: \"neMTB MAP REDUCE https://t.co/jLiH5PIrhH\" => \"d ihttic aeCOOPBRPDRODUDUTTINNBBA:I/DDcj\"\n",
      "batch 21825  loss=182.4099  steps/s=40.89  prediction: \"y: @allgarbled @tszzl it was too le epic\" => \": @Oeeeaceae ECNDDEEUt:U:E/:/::/:o5oH55P\"\n",
      "batch 21827  loss=178.7554  steps/s=116.47  prediction: \"y\n",
      "\n",
      "gotta tie everything back to the goal\" => \":\n",
      "ieioenl  eoeet ettteleya yacy  tiie  t\"\n",
      "batch 21828  loss=178.5025  steps/s=91.41  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"s.ceneee i eN`t GF/FFNGG/GB3GG3tpp::/tXp\"\n",
      "batch 21829  loss=164.7949  steps/s=94.65  prediction: \"ep/useful and you become Christian again\" => \" ly  denisd e en  eee  ee eeu ue  oe  ee\"\n",
      "batch 21830  loss=170.9750  steps/s=98.04  prediction: \"cies and come up w better ways to learn'\" => \"hn gensifie   nomlpafcrphwhbewswwbbapmwl\"\n",
      "batch 21831  loss=195.5371  steps/s=50.13  prediction: \" @Laz4rz IM FREE https://t.co/6zRFYN5bNS\" => \"tpanftien  e ci c cc ee nc  a wc ea ewYw\"\n",
      "batch 21832  loss=166.4334  steps/s=96.18  prediction: \" the dark forest from the 3 body problem\" => \"the temeete er   t eorf r   hr t   ro   \"\n",
      "batch 21833  loss=174.4919  steps/s=90.95  prediction: \" abt \"resumes\" and \"teapot\" or some shit\" => \"tteean   ter asne\"a\"s \"  t arta\"t\"\" ores\"\n",
      "batch 21834  loss=165.8858  steps/s=98.53  prediction: \"o make a significant impact on your life\" => \"umur  dni  aa an i iiniai  i  na nn  ini\"\n",
      "batch 21837  loss=166.5750  steps/s=92.16  prediction: \"rd it means theyre giving you a discount\" => \"e 2  fe nd ia  hwm wvgmpwoydhrlrvprcvvfv\"\n",
      "batch 21838  loss=190.1925  steps/s=86.34  prediction: \"ask` and `runit` https://t.co/5IfTNK9bBl\" => \"n  ee ref  d    n `r``int   tn t ///tt K\"\n",
      "batch 21840  loss=174.4743  steps/s=93.71  prediction: \"ers in 1990, seems like it to me anyways\" => \" e e  g t  ng  ni999910 0me mo t t  tt s\"\n",
      "batch 21841  loss=163.5024  steps/s=94.83  prediction: \"resy you can already talk to one of them\" => \"epln:e nn n9 e e,0,msmik,0k,k,eamyclklyw\"\n",
      "batch 21842  loss=173.1996  steps/s=101.99  prediction: \" super awesome, wait why multiple chats?\" => \"ttaat sra   s  s  r, w  s,weauaew p    t\"\n",
      "batch 21843  loss=169.5746  steps/s=75.31  prediction: \"aulg We like memoizing physical patterns\" => \"ns  r drera ne e  w  w  smw impli l  p t\"\n",
      "batch 21844  loss=172.6692  steps/s=94.27  prediction: \"code base to get something super complex\" => \"hm q ts naha rs mpucldswkpwawhmrmhbulwmw\"\n",
      "batch 21845  loss=164.6256  steps/s=102.53  prediction: \"fied unc classic https://t.co/IHefKwXtw6\" => \" rh en@ao or al vphcfcs:g/:aiclufHfH:XKw\"\n",
      "batch 21846  loss=196.8612  steps/s=11.26  prediction: \"reply: @Wooltard the gradients must flow\" => \"eply: @aotnr a  vphcfcs:g/:aicluHHfH:XKðŸ›‘\"\n",
      "batch 21847  loss=169.9196  steps/s=98.54  prediction: \"ich is a suuuuper good thing to practice\" => \"nl so tcs l ssh hssuu s  uuuuu  ho  oo  \"\n",
      "batch 21848  loss=169.1277  steps/s=95.55  prediction: \" is a no go\n",
      "\n",
      "dang that sounds like a lot\" => \"tn e besn  no  no  no g  g  oaot ao t  a\"\n",
      "batch 21849  loss=185.6199  steps/s=29.97  prediction: \"ply: @jaivinwylde top tier game for sure\" => \"ly: @t n er th akxnckacg,,kwkcbybkpbrbgu\"\n",
      "batch 21850  loss=165.3791  steps/s=125.70  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"ngess toe c eae  ig r\n",
      "a gaagalod\n",
      "oo todt\"\n",
      "batch 21851  loss=161.8953  steps/s=60.45  prediction: \" @sunsettler you https://t.co/HelJ0L823U\" => \"tcun   e  l wln  io r\n",
      "a gaag\n",
      "tod io tedd\"\n",
      "batch 21853  loss=176.8020  steps/s=102.03  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"erc  ntne na   eue ath  l alet a gs soP \"\n",
      "batch 21854  loss=175.4148  steps/s=94.91  prediction: \"morrow, hope it goes well for you brotha\" => \"edes   fom h  etmfwfw,,,,ypvi,w,,ghy,b \n",
      "\"\n",
      "batch 21855  loss=174.9346  steps/s=92.15  prediction: \"p in the readme\n",
      "\n",
      "https://t.co/dWiO4erSb1\" => \"ltje@t\n",
      " nent   Uvmmywhothys:::/.c::/WWOO\"\n",
      "batch 21856  loss=171.8681  steps/s=92.73  prediction: \"g Seatbelt doesn't want you to know this\" => \" a  oe    ng    s)'S''Bi,'t'cb\n",
      "B\n",
      "',dk'nb\"\n",
      "batch 21857  loss=182.3937  steps/s=33.30  prediction: \"ly: @sujantkumarkv Will do man will do ðŸ’ª\" => \"y: @t nbte  telt''oeee't't n e  onttt  o\"\n",
      "batch 21858  loss=160.2370  steps/s=102.18  prediction: \"ke yourself tbh\n",
      "\n",
      "https://t.co/IKpBO4oWKV\" => \"e   oto teha eh e t  tbeteht\n",
      "h t/otthht\n",
      "\"\n",
      "batch 21859  loss=172.6567  steps/s=107.14  prediction: \"is not concrete enough to put into words\" => \"nt an bond es  stno e r t  toc noetot eo\"\n",
      "batch 21860  loss=162.7722  steps/s=103.51  prediction: \" got chicken bone broth from walmart lol\" => \"to  oo  oi  i tc i    o     o  oo   o   \"\n",
      "batch 21862  loss=168.6977  steps/s=99.87  prediction: \"is God for sure. but ive grown confident\" => \"n     sef    s  s e s  s   s   r  e roe \"\n",
      "batch 21863  loss=184.3775  steps/s=99.57  prediction: \"gABAP why?? cause its fun and i like fun\" => \" BAP whe e t An PGJcJw?hGpJJJvlGpGlkvGcg\"\n",
      "batch 21864  loss=173.5097  steps/s=98.36  prediction: \"ple of this. Hows your RL journey going?\" => \"ly: @Paeis  n nojhHcxHxHLphGRLxRLRjxjmHl\"\n",
      "batch 21865  loss=187.3126  steps/s=94.52  prediction: \"er did failed\n",
      "\n",
      "ðŸ“ˆ My hit rate is only abâ€¦\" => \"  rnd ginr t e;e\n",
      "\n",
      "  d\n",
      "ðŸ“ˆ MM\n",
      "\n",
      "\n",
      "eMir tyt ry\"\n",
      "batch 21866  loss=175.7928  steps/s=103.78  prediction: \"rol you. why would they want to do that?\" => \"eble:tc s eo tr crpwnylw.mlcb.nt.lwpwuu.\"\n",
      "batch 21867  loss=225.6042  steps/s=99.94  prediction: \"AN JUST DO STUFF https://t.co/UdEgzl0ETY\" => \"BBEFU  U UY ST  TSS SFT F  FFF :t/t /:E/\"\n",
      "batch 21868  loss=169.6688  steps/s=103.71  prediction: \"ly useful ngl. incredible. well done bro\" => \"y: lessseseeesln eln  nl l nnl. l llleee\"\n",
      "batch 21869  loss=178.2792  steps/s=94.26  prediction: \"xperience that will make me live longer)\" => \"plf(  (itiee teet a t al  eal me l  l e \"\n",
      "batch 21870  loss=171.7394  steps/s=102.21  prediction: \"lay this game\n",
      "\n",
      "happy wheels was gold too\" => \"yy  eet t t  ea llap h ap \n",
      "\n",
      " pap  wwe  e\"\n",
      "batch 21871  loss=174.1880  steps/s=47.61  prediction: \"y: @01beigecamry https://t.co/qAESPOcfdy\" => \": @lepe t t  ma lhap h ap\n",
      "\n",
      "\n",
      " paps w e  y\"\n",
      "batch 21872  loss=170.9841  steps/s=104.06  prediction: \"s is pretty cool https://t.co/2VR6GTbI3d\" => \" Doae  n e    s iot   ot o http //2/ V/2\"\n",
      "batch 21873  loss=181.4262  steps/s=93.10  prediction: \"e gets servers/multiplayer working too..\" => \" tii  g t  ie sergtt /e/le t/tt ltrse/io\"\n",
      "batch 21874  loss=187.7497  steps/s=93.10  prediction: \"ee no signup btw https://t.co/HKTjZzE5ue\" => \" m feben    e  euee n  itptbptp/ ://KKKZ\"\n",
      "batch 21875  loss=172.1200  steps/s=104.43  prediction: \" ad optimization, marketing agencies etc\" => \"t ee l tel t oo oz iaa, ti ,maiao ntn  a\"\n",
      "batch 21876  loss=183.9291  steps/s=100.52  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`Fh  stae oto  [10,0,0ai, so,  ao so  to\"\n",
      "batch 21877  loss=165.4669  steps/s=10.17  prediction: \"reply: @Wooltard https://t.co/x3yGuXvGqf\" => \"eply: @0 ,g]  i brb,0sg/1,egebwbrowbhwyg\"\n",
      "batch 21878  loss=161.9715  steps/s=106.80  prediction: \"ey fumbled it. flipped it and tumbled it\" => \"   o eees b t titt eet iti dd   i  d  tt\"\n",
      "batch 21879  loss=187.3047  steps/s=100.98  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"e eia   ueR]D   NDOðŸ«¡EOðŸ«¡NEðŸ«¡ðŸ«¡EpðŸ«¡:uD::EO:V2\"\n",
      "batch 21880  loss=171.3586  steps/s=98.97  prediction: \" if they'll give you access to that zone\" => \"tn ie\n",
      "   \n",
      " t  e' i  i ii e se i ee to t \"\n",
      "batch 21881  loss=164.2176  steps/s=90.78  prediction: \" cs maps btw? would love to see pictures\" => \"toy  n   o                  w w  o  oo  \"\n",
      "batch 21882  loss=170.1203  steps/s=101.29  prediction: \"an explanation that made sense to me lol\" => \"td  o  oen  f ae it  t x nt  ananae  e t\"\n",
      "batch 21883  loss=173.0596  steps/s=101.14  prediction: \" is interesting play between those three\" => \"tt  n e      se  sert te es inw aese et \"\n",
      "batch 21885  loss=164.0459  steps/s=100.35  prediction: \"s after monads.. https://t.co/V7s73DqEAF\" => \" aos  ooes as   s    ass s ..tst//t/o/s7\"\n",
      "batch 21886  loss=178.4620  steps/s=89.88  prediction: \" it can be! Nice https://t.co/7gl6yX5jXL\" => \"tf eedc.itea.tet . !e!!N Ncc  /teht// c6\"\n",
      "batch 21887  loss=171.5527  steps/s=93.31  prediction: \" ppl twist your arm behind your back lol\" => \"trtnt et iwi t ntttrt r ire  r ureriit  \"\n",
      "batch 21888  loss=187.9382  steps/s=10.05  prediction: \"reply: @balabisxyz @yacineMTB Usefulness\" => \"eply: @ieg pt  twnsfwphblwpwmgyhurluywub\"\n",
      "batch 21889  loss=173.4707  steps/s=104.21  prediction: \" in the post, only read the abstract tho\" => \"tt   i aen  e  ne  i, n  te  ae  eet t e\"\n",
      "batch 21890  loss=169.3677  steps/s=95.76  prediction: \"mes there are 10x rewards for doing this\" => \"en ae\n",
      "  ment mei010mvf10x00xxx1dxx0rwwfw\"\n",
      "batch 21891  loss=168.0613  steps/s=97.62  prediction: \"r when drunk (intuition-mode), but theyâ€¦\" => \"eae s fo nl wdsr,w,(w(y(c,wf(-k((-),)(),\"\n",
      "batch 21892  loss=163.3633  steps/s=97.53  prediction: \"for his mission\n",
      "\n",
      "https://t.co/5SzCEV8nPe\" => \" r    otem t   evwltn\n",
      ".s.f.r:/w5gz::5SCC\"\n",
      "batch 21893  loss=206.4840  steps/s=91.35  prediction: \"B11A9A19A26B19B10B29A13A33A35B33B32A8A13\" => \"17 A1AA ABA1A19191929A1213131BB13A3A333B\"\n",
      "batch 21894  loss=185.1522  steps/s=67.30  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"ei i ne to y5@h @k@t7bks0e29316u505u9620\"\n",
      "batch 21895  loss=174.2171  steps/s=89.12  prediction: \"t gotta watch out for the poison lizards\" => \" fu   sy  uhe2 jywjkjh09cforu1btcp5p9inf\"\n",
      "batch 21897  loss=171.6235  steps/s=87.17  prediction: \"ll send you a link to it around the 25th\" => \"y   e  yess  e st  o   l  l    o  o t  t\"\n",
      "batch 21898  loss=178.8905  steps/s=86.60  prediction: \"ttler its simple https://t.co/vEQ91Otjxr\" => \" ei  cs  @e @2ervickcwky:fwar:hpk:Qhs:EQ\"\n",
      "batch 21899  loss=173.2538  steps/s=99.61  prediction: \"th `sudo service NetworkManager restart`\" => \" e   te n r wshn``uuNwNwNvNrNwNMkMcMmMer\"\n",
      "batch 21900  loss=192.2199  steps/s=87.58  prediction: \"ro @jayhenrybiz480 Thanks for the advice\" => \"ebay  o oe  iv` zvzz8zz880TTkn4rsrTr80ea\"\n",
      "batch 21901  loss=177.4708  steps/s=87.32  prediction: \"interesting\n",
      "what was actually happening?\" => \"ng rn   ie ingn istergsirertwag was sagu\"\n",
      "batch 21902  loss=163.4839  steps/s=88.95  prediction: \"us things that make your life easier ig?\" => \"st bibiiiioi it is t t ta    tt  ii   a \"\n",
      "batch 21903  loss=177.2815  steps/s=75.63  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" eee ta nhsr eeeT*@wMTkMTMTBj:jk:.:o/x9/\"\n",
      "batch 21904  loss=173.2555  steps/s=96.57  prediction: \"lex code across multiple (simple!) Files\" => \"ym  lno nn p ro exx loem crco s mple mpl\"\n",
      "batch 21905  loss=158.4422  steps/s=93.86  prediction: \"and run it in the front end of a browser\" => \"nd coeed  t   e      n      n    nn t t \"\n",
      "batch 21906  loss=169.0743  steps/s=93.46  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"eilu thits u eeofmwlw\n",
      "plf.w:\n",
      "g\n",
      ".p::/J..C\"\n",
      "batch 21907  loss=185.7762  steps/s=97.98  prediction: \"________11hz togglesite is super helpful\" => \"d_x_______o____ _  _o_g 1g tt ss es se s\"\n",
      "batch 21908  loss=181.1182  steps/s=100.76  prediction: \"ard players used to get through the race\" => \"ne     et  slle p are e  tereeo t t t  t\"\n",
      "batch 21909  loss=171.6459  steps/s=83.52  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \" ndo rarpa e se r  e re etee erhtr  tr  \"\n",
      "batch 21910  loss=166.1161  steps/s=97.22  prediction: \"ob/business but.. its fun to think about\" => \" l o  n no    i b b b bssb uts  nu son t\"\n",
      "batch 21912  loss=170.3354  steps/s=93.05  prediction: \"that there were pink cubes at some point\" => \"his   e a woi  nowokhophargchalprwkkcrwe\"\n",
      "batch 21913  loss=172.6744  steps/s=92.02  prediction: \"reading the code, most are from zig init\" => \"epla  et e ei y 4_4_tupd,hgcybla,y,g,cmb\"\n",
      "batch 21914  loss=168.7636  steps/s=97.72  prediction: \"t investment for your time generally imo\" => \"hbe    oecn\n",
      "n s osovvyv\n",
      "u,mbfvpviybcsulðŸ›‘\"\n",
      "batch 21915  loss=173.7613  steps/s=100.21  prediction: \"reat book, glad youre enjoying it so far\" => \"epltg  l  lu t nIfkrvyfmbgy,njgkdmj,kujðŸ›‘\"\n",
      "batch 21916  loss=168.4168  steps/s=53.97  prediction: \"@yacineMTB so youre no longer locked in?\" => \"lacineM   s g og a yo   alo yynr i i  o \"\n",
      "batch 21918  loss=172.2312  steps/s=104.57  prediction: \"a, thats super coool!!!!! how did it go?\" => \"n  eteret sst t s s s !!!!!o!!!!!!  oo i\"\n",
      "batch 21919  loss=187.6338  steps/s=96.63  prediction: \"chine Uphill, both ways, in the snow too\" => \"o s byuiine  oo IUpdMtM,!UycupUauc,p!l!a\"\n",
      "batch 21920  loss=175.9950  steps/s=46.29  prediction: \": @yacineMTB jak creep is a real problem\" => \" @Jonyn  ee  oneIupbi!c!!!ycupgsub,p!kba\"\n",
      "batch 21921  loss=176.0654  steps/s=92.04  prediction: \"e building an army of tiny little robots\" => \"poo oo  l n  in  ai   n  i       l    n \"\n",
      "batch 21922  loss=169.4984  steps/s=90.36  prediction: \" stream but i do my actual job and stuff\" => \"toot   to   e  t e    m tm   t t ao tut \"\n",
      "batch 21923  loss=163.1501  steps/s=94.10  prediction: \"s after monads.. https://t.co/V7s73DqEAF\" => \" sos   besnasse s  a ts. s...tst//s/o/s7\"\n",
      "batch 21924  loss=178.7915  steps/s=99.06  prediction: \"r you choose is not technically infinite\" => \"eao  iohir  er rvu1dbwm\n",
      "cbv\n",
      "ieyiuvghveve\"\n",
      "batch 21926  loss=170.6821  steps/s=71.66  prediction: \"oulda made stock cert flags instead, rip\" => \"   anaar  oea hoaou te e  c ocicief  i i\"\n",
      "batch 21927  loss=172.9754  steps/s=95.25  prediction: \"building logic gates and RAM and whatnot\" => \"li   rl be  b b  lgi  gga gg ig RRM  dd \"\n",
      "batch 21928  loss=164.1830  steps/s=96.73  prediction: \"nse and you can't efficiently work withâ€¦\" => \"gea d etondtdo tuhk'k'.ykc'm'k'dhecfdcak\"\n",
      "batch 21930  loss=193.8017  steps/s=93.11  prediction: \"A\n",
      "this session is sponsored by diet coke\" => \"1BeEHHHe    s HnAA   sssssnos s  s soeos\"\n",
      "batch 21931  loss=167.7598  steps/s=90.65  prediction: \"avorite password what would it be?? haha\" => \" eat  p y   i  a oa awswtwwowoww wow ?  \"\n",
      "batch 21932  loss=176.2870  steps/s=87.54  prediction: \"ath dependence can be used strategically\" => \"  av e    p h tew e ae e  cad b  b b ha \"\n",
      "batch 21933  loss=163.7475  steps/s=85.03  prediction: \"d go hella hard w some music\n",
      "\n",
      "super cool\" => \" to ui    hol  d  e aa e  sa    uu u \n",
      "cs\"\n",
      "batch 21934  loss=179.6457  steps/s=103.24  prediction: \"s in generatingâ€¦ https://t.co/Bx4y0mujmB\" => \" aoee   nen  ne eangâ€¦ en tt gt//t //t44/\"\n",
      "batch 21935  loss=172.5523  steps/s=107.85  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"t r oeer   s, n 3e, ts â€¦te stest/c  cthQ\"\n",
      "batch 21936  loss=172.8269  steps/s=106.81  prediction: \"d virus that makes ppl cracked at scale?\" => \" me  niiier o n   a   ai    pa  paa    k\"\n",
      "batch 21937  loss=169.5289  steps/s=98.58  prediction: \" 3d, chess, jiuâ€¦ https://t.co/AQdCVgAphw\" => \"t)r oeer   L, n 3e, ts â€¦t, st/st/c  hthA\"\n",
      "batch 21938  loss=181.8386  steps/s=75.85  prediction: \"rchived_videos @LimkarRohit @discord LOL\" => \"ei-wM i enhe hL3â€¦3@â€¦r@â€¦@,s:pR:R@Q.@V@AV:\"\n",
      "batch 21939  loss=167.4585  steps/s=98.93  prediction: \" a lot of chess is abt how to think less\" => \"tnt  ohnhtot   t o    t s     hs  o  ho \"\n",
      "batch 21940  loss=174.6381  steps/s=93.80  prediction: \"ve gradient it lives in? Something else?\" => \"erootn tn een iet it  iv  iit niSS  Seei\"\n",
      "batch 21941  loss=169.2506  steps/s=101.23  prediction: \"ind groups of ppl who love what you love\" => \"ns     nt t  si      p  p f po po   o   \"\n",
      "batch 21942  loss=172.1988  steps/s=100.24  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"ni r t eg n ti i tzeimnzmimi me c  WW669\"\n",
      "batch 21943  loss=186.4025  steps/s=72.63  prediction: \"ludwigABAP @p0nnnpppppppppp Luffy is a g\" => \"yd i et g tgt  i tgeipnptim: We6969D7D8D\"\n",
      "batch 21944  loss=165.7336  steps/s=104.31  prediction: \"nsettler cant spell family without AI :D\" => \"g izei  mis  A  ck0a0h:n:t.s.sL/6l.LDVD8\"\n",
      "batch 21945  loss=174.6843  steps/s=76.31  prediction: \"love spending 30mins debugging a typo :D\" => \"ytwis   n  ae nPpnp lptptppeiif cu t  I:\"\n",
      "batch 21946  loss=169.9044  steps/s=100.21  prediction: \"ys end up thinking \"nah they would justâ€¦\" => \"  is  it ao   enti n   t  t  n\"n t t h  \"\n",
      "batch 21947  loss=169.8920  steps/s=96.03  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" toome  th t  t s t  t thth t /ttc //ttt\"\n",
      "batch 21948  loss=164.7632  steps/s=95.82  prediction: \" the time. personally i havent done this\" => \"the tet   b  e t t eet ill  ell n een en\"\n",
      "batch 21949  loss=174.3568  steps/s=90.29  prediction: \"u actually did the work so youre chillin\" => \" waaetttu y a a ty yay a aly lyd  e yorl\"\n",
      "batch 21950  loss=176.3160  steps/s=88.43  prediction: \"hat\n",
      "\n",
      "also webcodec sounds useful. but no\" => \"et  t   tto  \n",
      "tott  aooc ssooo  sedueuso\"\n",
      "batch 21951  loss=168.3952  steps/s=91.65  prediction: \"it seems like using a spoon vs a scalpel\" => \"n   o   re ee neis  s ii    s o  nn ne s\"\n",
      "batch 21952  loss=170.6595  steps/s=90.76  prediction: \"t immensely and give you new information\" => \"hicg  pere h   nchlpvyhatdinmheveryvlayd\"\n",
      "batch 21953  loss=172.3933  steps/s=98.03  prediction: \"me killer robots https://t.co/zFAdKu373p\" => \"e ei  e  uas  e mvkcoulldbrbQgbdâ€mt:s::/\"\n",
      "batch 21954  loss=169.8338  steps/s=99.06  prediction: \"s w java and python and studying for fun\" => \" artts tast g    atat  nad n nn  yanyttd\"\n",
      "batch 21955  loss=172.8558  steps/s=102.15  prediction: \"ant use it for what i need to work on :(\" => \"nd     an r ntt  er r a  e rea et t e  o\"\n",
      "batch 21956  loss=169.7960  steps/s=106.07  prediction: \"think you can do cdn type stuff w em btw\" => \"he   lentaa ttenkIj)\n",
      "IkIyubkckId\n",
      "rglkdg\n",
      "\"\n",
      "batch 21957  loss=168.4475  steps/s=99.76  prediction: \"iterate certain ppl, but those are large\" => \"nilfl  aa    c c  taie etat tpppeb  e t \"\n",
      "batch 21959  loss=202.0587  steps/s=96.48  prediction: \"oing the deadline thing\n",
      "Works super well\" => \" n att ltitittntt etldlddadeWneWWWWeWg\n",
      "n\"\n",
      "batch 21960  loss=194.1025  steps/s=103.84  prediction: \"/t.co/gufhF6ZVD6 https://t.co/0ldvn5Oi6t\" => \"/..  tomeeo//tt h6/ZD66D6DDDsDF:V/c/0tp0\"\n",
      "batch 21961  loss=183.4223  steps/s=106.63  prediction: \"great great thurs\n",
      "key was blocking x lol\" => \" o oet ott tren Vp!cgpfa\n",
      "ps/ufr\n",
      "coltwuin\"\n",
      "batch 21962  loss=182.4328  steps/s=108.42  prediction: \"h @tsoding Musializer looked pretty cool\" => \"eopsinon atsassnsutsiauMgruis kler zelok\"\n",
      "batch 21963  loss=169.7736  steps/s=113.05  prediction: \"avorite password what would it be?? haha\" => \"teno i  yn  i e  oa ptsaswwowoww wow ?  \"\n",
      "batch 21964  loss=170.8026  steps/s=107.30  prediction: \"atrophy, you have to like, keep doing it\" => \"r   to et ttt  h hhh a oo t eoe o   e o \"\n",
      "batch 21965  loss=176.8923  steps/s=35.56  prediction: \"ly: @elonmusk @yacineMTB necessary being\" => \"y: @tttttet  hah hhh a oo  oeo  o eke o \"\n",
      "batch 21966  loss=173.9023  steps/s=123.68  prediction: \"r model architecture not based on tokens\" => \"epty  ebnih o delylckm,Mkfuurcrnmnrbhbkr\"\n",
      "batch 21967  loss=164.5173  steps/s=81.21  prediction: \"but openai is cringe so obviously sonnet\" => \"ettote  nbt   eiticii e  irierc e so  oo\"\n",
      "batch 21968  loss=179.7147  steps/s=100.15  prediction: \"hnote uuuh i have a license for thse sir\" => \"eottpatnnint   utuh i i  v ivvs s snoeno\"\n",
      "batch 21969  loss=175.3365  steps/s=93.01  prediction: \"meone should make a zig finetune dataset\" => \"aney s itnoe  tizzz@lmnbhyuzzmzffhftuzez\"\n",
      "batch 21970  loss=182.8324  steps/s=111.84  prediction: \"w! I love hearing what works/what doesnt\" => \"ahn @atirtietnkn!wIzlmnIw!eI!lrfIoheulwh\"\n",
      "batch 21971  loss=178.9109  steps/s=91.42  prediction: \"@kyutai_labs Its like reverse Christmas!\" => \"yerpP_A  nk @taa_____taat ks k se e eCCe\"\n",
      "batch 21972  loss=172.6695  steps/s=105.21  prediction: \"s of industry water cooler conversations\" => \"taof dh!n onothdo as os ostoa so crt tas\"\n",
      "batch 21973  loss=171.3381  steps/s=106.05  prediction: \"think he got the joke lol\n",
      "1000% worth it\" => \" e r @e thse  euIuIuIcIunjnk10n%%\n",
      "1atj%h\"\n",
      "batch 21974  loss=177.2142  steps/s=106.36  prediction: \" of why i used to get work sniped looool\" => \"@u e hef ga   wo  h u  oe o  t  we  io t\"\n",
      "batch 21975  loss=181.5827  steps/s=101.85  prediction: \"t lower level stuff\n",
      "\n",
      "if you progressiveâ€¦\" => \" too sou  a  eo fv\n",
      "lufwiwsyavfivpgufm\n",
      "gr\"\n",
      "batch 21976  loss=173.5323  steps/s=85.59  prediction: \"ler @tunahorse21 https://t.co/rMWnBjrYC0\" => \"ys  senrtat e  ousfe222 22 2p o/ro/rerWB\"\n",
      "batch 21978  loss=169.2908  steps/s=98.37  prediction: \"ewit reddit type tactics/tricks/hacks BS\" => \" _raii e t i diddit t t dt tttt /ettccs/\"\n",
      "batch 21979  loss=177.7510  steps/s=92.28  prediction: \"ME but you do not follow CHRIST? curious\" => \"TB yl lou too     oo  o too  oo toHHo RT\"\n",
      "batch 21980  loss=171.8220  steps/s=94.47  prediction: \" to use. code is linked in another reply\" => \"toe     per   n\n",
      "pe  o ee o eois so ineei\"\n",
      "batch 21981  loss=178.4465  steps/s=20.68  prediction: \"eply: @HSVSphere https://t.co/wKZyTYhIYH\" => \" ly: @tr ee    spe  o es o eois so ineei\"\n",
      "batch 21982  loss=167.8858  steps/s=126.16  prediction: \"almost as bad as jan blocking his bishop\" => \"nl tse thsttosl ll  s  an b andb n oebl \"\n",
      "batch 21983  loss=178.9986  steps/s=93.58  prediction: \"you are a poster https://t.co/i3qCy3rrAj\" => \":u  ei atca a   ae  s  aso sottsis /i3s3\"\n",
      "batch 21984  loss=165.7890  steps/s=96.61  prediction: \"nd stop you from seeking rewards in life\" => \"g  te teo n u dtwibeIiIwafh:s:s.cyh.gfw.\"\n",
      "batch 21985  loss=171.8375  steps/s=99.00  prediction: \" works when I ask it for complex changes\" => \"toa   w e www w    w     k  k    i   oxl\"\n",
      "batch 21986  loss=165.0780  steps/s=93.34  prediction: \" of the best habits of all time for sure\" => \"tf  ta te  e tt  bb te hb tb tt  e  ot t\"\n",
      "batch 21987  loss=185.0511  steps/s=93.52  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" aneout  fo ltf  u urf lr a  t  ere re r\"\n",
      "batch 21988  loss=166.3569  steps/s=71.33  prediction: \"enisnikulin its the lichess of photoshop\" => \" t n ned n  u  t ul rte ree een  se p  p\"\n",
      "batch 21989  loss=160.8575  steps/s=96.13  prediction: \"his is the same w similar things in life\" => \"engst thint \n",
      "hsn sth e s e  is  siit s i\"\n",
      "batch 21990  loss=163.2078  steps/s=95.26  prediction: \"dless memory related errors (impossible)\" => \" oo es  es m mn se ee rrere rresrer  els\"\n",
      "batch 21991  loss=162.1830  steps/s=92.98  prediction: \"s\n",
      "\n",
      "so super frictionless, it sounds like\" => \" \n",
      "r  ion ne  ute sur t srserss  io ssiti\"\n",
      "batch 21992  loss=163.8021  steps/s=89.43  prediction: \"ll send you a link to it around the 25th\" => \"y    n yes  ee  i  i   l         t  t  t\"\n",
      "batch 21993  loss=162.5134  steps/s=95.38  prediction: \"randomly via ssh https://t.co/3MxqH9R1Ya\" => \"enn  lee@Tr to  kbcvx:/bv.by,pM::/bl.:v3\"\n",
      "batch 21994  loss=198.1096  steps/s=93.72  prediction: \"ackwards buttons https://t.co/JO2nBFplUJ\" => \"nk  o   ded o   rrabbtoaaa b ttcs///ttcJ\"\n",
      "batch 21995  loss=174.4790  steps/s=94.73  prediction: \"k checked him out, followed, thanks mate\" => \"iiat\n",
      "    thekktch ckouheo  o eo ,eh,oho,\"\n",
      "batch 21996  loss=163.1829  steps/s=101.66  prediction: \"the world more, become more dysfnctional\" => \"hi   r e tiente w,ahvfh\n",
      "tl,.wb\n",
      "ld.n^vwbr\"\n",
      "batch 21997  loss=166.6989  steps/s=100.28  prediction: \"ire effing timeline is circle tool posts\" => \"ne en  n  i eetieee nnie   eine  iei e i\"\n",
      "batch 21998  loss=159.8293  steps/s=101.20  prediction: \"r, it felt a little linkediny over there\" => \"e l :s ra fo  d IYmYc,@r,hfdIguI,vgvv,vw\"\n",
      "batch 21999  loss=180.7327  steps/s=101.11  prediction: \"sec to like 500k\n",
      "https://t.co/X8cRVe4eRM\" => \" d s  t0 s  000esskeks0kk kt00k0/t ct Xt\"\n",
      "batch 22000  loss=170.8587  steps/s=103.15  prediction: \"te how much some debuffs will damage yoâ€¦\" => \" p d alo hod   sdbr''pbsahpap\n",
      "gwiucphgâ€¦d\"\n",
      "batch 22001  loss=167.5221  steps/s=98.18  prediction: \"s of industry water cooler conversations\" => \" f a tson  nnt to us os ostoa tr  st trn\"\n",
      "batch 22002  loss=172.4980  steps/s=83.71  prediction: \"amebedan @jaivinwylde stochastic success\" => \"ne iot  ndo stnan awaowooococstrtastaers\"\n",
      "batch 22003  loss=177.9431  steps/s=104.31  prediction: \" just signed up as a beta tester hehhehe\" => \"tut  n l d j@  tusisais t  o atse te tes\"\n",
      "batch 22004  loss=161.3815  steps/s=97.98  prediction: \"etter but pretty good time bender though\" => \" t  ot t boett e ttt   otette t o  o ttt\"\n",
      "batch 22005  loss=164.5464  steps/s=96.60  prediction: \"audio visualizer https://t.co/LXNYBAABrh\" => \"ntona  n n  iii aiiii  i ii  t//////////\"\n",
      "batch 22007  loss=165.5968  steps/s=100.82  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n id  a thad  tt id d AAAAAAid dit t d d\"\n",
      "batch 22008  loss=171.3916  steps/s=97.89  prediction: \"r cool. i wish llms were better with zig\" => \"etey:e btiats pewvfkc..g.gm.fA.l.vbuwAwu\"\n",
      "batch 22009  loss=167.6257  steps/s=67.09  prediction: \"justalexoki its tpot, all lowercase only\" => \"est  oeer su i si i w ww i le t weee e t\"\n",
      "batch 22010  loss=163.6328  steps/s=17.87  prediction: \"reply: @gizmobly https://t.co/Wh2FZDx4RL\" => \"eply: @jer th e wcfwc.hgb,w,ch.l.mbuzAzu\"\n",
      "batch 22011  loss=173.4739  steps/s=161.06  prediction: \"r_fusion based\n",
      "i cant read apparently xD\" => \"eely: @.tims  ltwimpA://b,\n",
      ",/W.2FZDx4RLu\"\n",
      "batch 22012  loss=167.2238  steps/s=102.81  prediction: \" component that approximates transformsâ€¦\" => \"toueo    hwoooonnnet tan pppptpaoattaata\"\n",
      "batch 22013  loss=170.1577  steps/s=99.35  prediction: \"ace to your list https://t.co/dwHsPF5vJC\" => \"ni toe  mmod   oo t t  tttt tt ////s H//\"\n",
      "batch 22014  loss=173.1285  steps/s=60.82  prediction: \" @llamapuckey never visit sf without jug\" => \"tmupea   eo o  to t t ttttt /t ////sHFFt\"\n",
      "batch 22015  loss=170.7377  steps/s=105.26  prediction: \"probably\n",
      "\n",
      "30mb can be a lot for frontend\" => \"lot  t a     ej p11j1sp30a30y3\n",
      "33030ckbw\"\n",
      "batch 22017  loss=165.8487  steps/s=103.29  prediction: \"ting up prints, never had a problem w it\" => \"hons s wee  i  nww,orkggv,w0gvw,0vmvn,g,\"\n",
      "batch 22018  loss=160.6829  steps/s=103.02  prediction: \"emely hard to avoid being pressured into\" => \" e i lexe le  rea l ao      d ei e ie  r\"\n",
      "batch 22019  loss=171.1504  steps/s=103.85  prediction: \"correctly yet... https://t.co/fivCYqBVcO\" => \"ompedoei a  e  esbxpbx/::/:sxx:/xiCCYCYq\"\n",
      "batch 22021  loss=171.6296  steps/s=98.64  prediction: \"ed to potential feature list, thanks bro\" => \"   itadd dne  odedtte  eottetltietttt t \"\n",
      "batch 22022  loss=170.0090  steps/s=103.60  prediction: \"ang out in tunisia every once in a while\" => \"nd e t taotev t  na init ti  nie inn inn\"\n",
      "batch 22023  loss=170.6958  steps/s=102.68  prediction: \"enjoyable is such a gargantuan advantage\" => \"  i  ta\n",
      "ngn nis s s iass aig  g gsn n u \"\n",
      "batch 22024  loss=157.8740  steps/s=99.45  prediction: \" glitches\n",
      "your game is looking great btw\" => \"toos e   g  e le g  e g  e ea   ig  g gg\"\n",
      "batch 22025  loss=166.6986  steps/s=102.76  prediction: \" and can be much more useful to increase\" => \"trsra rsaan   ahn  aa b e me   c    me u\"\n",
      "batch 22026  loss=152.6974  steps/s=103.40  prediction: \"veryone in the past was a caveman/moron\"\" => \"e  j   e ea e neee n  e   ae aaaa  a a a\"\n",
      "batch 22027  loss=155.2226  steps/s=100.43  prediction: \"utomatically imagine letters as colored?\" => \"s  y odo oaaaaoa    aaaiaatte      e  e \"\n",
      "batch 22028  loss=187.6768  steps/s=71.50  prediction: \"ludwigABAP Madlad\n",
      "Reminds me of baritone\" => \"ys  uu  d aaAa aaiai aitiemee e  e o  ee\"\n",
      "batch 22029  loss=191.8130  steps/s=112.54  prediction: \"en Globe I think\n",
      "https://t.co/vEGaP2CbwO\" => \"  ro uert lllel  l ii ne ttt  //ta oo/oE\"\n",
      "batch 22030  loss=168.8315  steps/s=103.19  prediction: \"nt do that\n",
      "now it doesnt do that\n",
      "\n",
      "repeat\" => \"  det den o d tt   do d  t oott t  t\n",
      "tt\n",
      "\"\n",
      "batch 22031  loss=167.0629  steps/s=103.81  prediction: \"an explanation that made sense to me lol\" => \"ng ro eetn nt te ot tt n nt ea anae  e t\"\n",
      "batch 22032  loss=167.8014  steps/s=103.00  prediction: \"r?\n",
      "Learn how to learn =&gt; e^x engineer\" => \"e e   \n",
      " eer? \n",
      "1rL)L?wckbw/=&)w;=&&&;;;^^\"\n",
      "batch 22033  loss=189.2537  steps/s=29.95  prediction: \"ly: @morew4rd Gettin there, yup\n",
      "Soooooon\" => \"y  @0e  rh Lrnnnooeaenr===&=&;&;^e^^^^en\"\n",
      "batch 22034  loss=168.7633  steps/s=107.32  prediction: \"mpactful on actual success for me though\" => \"elhison fmsaothtðŸ˜bQ#ygkvbhp$rá´p$pð—¯ÉªkfÊ€Êœv\"\n",
      "batch 22035  loss=173.7652  steps/s=97.37  prediction: \"ded something to edit gifs/clips quickly\" => \"  ee ne  ede  e t tee  o s f s  ti sc is\"\n",
      "batch 22036  loss=172.5620  steps/s=101.11  prediction: \"ice more grift\n",
      "Been my experience lately\" => \"nk e  o y o  ro   oe  e      eeeee ee ee\"\n",
      "batch 22037  loss=157.3181  steps/s=102.99  prediction: \"quote a lot bc it seems to come up a lot\" => \"ues  s jin boibt       t t   t tt    o  \"\n",
      "batch 22038  loss=162.5335  steps/s=102.71  prediction: \"in the game loop https://t.co/OETAGx1sHy\" => \"n t e ae e      e  e   t t t//tt/tp////t\"\n",
      "batch 22039  loss=197.4742  steps/s=101.07  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"nneaei e   to i i t7 @\n",
      "nd77 n''  s 's (n\"\n",
      "batch 22040  loss=178.9033  steps/s=99.22  prediction: \"pany \"AI startup inc\" and make a paradox\" => \"lntl tttt  ytestg@@7'\"Ad7rdAId(parAI\"AIA\"\n",
      "batch 22042  loss=173.9257  steps/s=98.79  prediction: \"[listen to tpod] https://t.co/T4E8ws1uTP\" => \"wan  ioao ort   ]i[]lb\"dc\":ald]p4]]4E8xx\"\n",
      "batch 22043  loss=168.3411  steps/s=102.80  prediction: \"ead to insanity\n",
      "\n",
      "https://t.co/FLccrhEiEd\" => \" rnolssss laas  isii\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ts\n",
      "nstt\n",
      "///ttcc\"\n",
      "batch 22044  loss=164.5255  steps/s=104.46  prediction: \"Heaven and Earth (ideas and matter) meet\" => \"ea H  an  wre o E.HEHv(vwEwEvEw(H(H(E(/)\"\n",
      "batch 22045  loss=168.1783  steps/s=103.98  prediction: \" arena for a bit https://t.co/F7Pt4JHj3q\" => \"tre enaia taa ne  a r   tts  nhte //tt J\"\n",
      "batch 22046  loss=158.1286  steps/s=105.02  prediction: \"velsio im hyped to see what youre cookin\" => \"eravellnele  ee         t  e  e ee et  o\"\n",
      "batch 22047  loss=164.0527  steps/s=106.23  prediction: \"ols is kinda like cookie clicker but irl\" => \"nl ii io d i tnito isio  ok cic kei kil \"\n",
      "batch 22048  loss=166.1106  steps/s=110.29  prediction: \"at you mentioned. Variety and reloading.\" => \"nee   t  t nn   tt ennnineVV Vten  rneii\"\n",
      "batch 22049  loss=163.8866  steps/s=110.02  prediction: \"d hire my friends to do research with me\" => \" t    so mo e re nr   d  rr er s ir r  r\"\n",
      "batch 22050  loss=178.1060  steps/s=107.35  prediction: \"nvestor\n",
      "\n",
      "Simpleagreementforfuture Equity\" => \"gem ro   tte \n",
      "nn\n",
      "\n",
      "\n",
      "eelern\n",
      "ererfmrfrffouf\"\n",
      "batch 22051  loss=169.0349  steps/s=109.69  prediction: \"ers in 1990, seems like it to me anyways\" => \"   a  g i  n   n199990  0mes s e s  i  e\"\n",
      "batch 22052  loss=170.3500  steps/s=105.67  prediction: \"n @grapplingdev HA i love it, lets do it\" => \"gtnoedn erl ane@anaaeg e g l iilivv     \"\n",
      "batch 22053  loss=163.0948  steps/s=105.24  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"ng es aensi   e  ra     go l ged gdd ott\"\n",
      "batch 22054  loss=170.8367  steps/s=106.51  prediction: \" my life a lot\n",
      "lots of great ppl on here\" => \"@a e n  mnm e m a l l t  o  l lt  l l l \"\n",
      "batch 22055  loss=193.5904  steps/s=106.94  prediction: \" that outputs its own weights and biases\" => \"@ha tin   tou\n",
      "t attotts ts  tsas oss ie \"\n",
      "batch 22056  loss=204.1477  steps/s=95.24  prediction: \"0x_0 @EsotericCofe any plans to hop over\" => \"x77ayph se0 nELnECEtpComC Ceaahuawmpupbu\"\n",
      "batch 22057  loss=186.5068  steps/s=50.81  prediction: \"y: @zyx_db great stuff brotha, good day?\" => \": @st  t 0t0 _t CttCCwCCwCt nsanpsis  o \"\n",
      "batch 22058  loss=167.9206  steps/s=112.68  prediction: \" and hard to correct (pride)\n",
      "\n",
      "i had this\" => \"tnd ten eaa d raddr  d rrrd c rrdr d er\n",
      "\"\n",
      "batch 22059  loss=161.1010  steps/s=101.43  prediction: \"irak seems fine to me (i am brainwashed)\" => \"ned a  d  r    rerr  e r (e ((  i aa aih\"\n",
      "batch 22060  loss=164.8158  steps/s=107.47  prediction: \"ould color their pill white for the lolz\" => \"n dutestc c  ocoh   o li hii r ii  h th \"\n",
      "batch 22061  loss=163.3715  steps/s=110.34  prediction: \"it got like 2x fps rendering ocean waves\" => \"ns  w we e i  t e   e    ie  ee e  eere \"\n",
      "batch 22062  loss=175.1453  steps/s=68.51  prediction: \"@startupmillyair https://t.co/QgfnCndCQA\" => \"sunro  r  le  t e  ie ee re   e en eneeC\"\n",
      "batch 22063  loss=171.4163  steps/s=113.01  prediction: \"my camera by accident so maybe thats why\" => \"e ta     b teso ys/.mcyhwsy.wf.\n",
      ".byb/Cf\n",
      "\"\n",
      "batch 22064  loss=192.2718  steps/s=69.46  prediction: \" more to 400! Been a crazy two weeks lol\" => \"te   mema  eb4 c aa a  ea  y ma  a at  y\"\n",
      "batch 22065  loss=223.6029  steps/s=17.41  prediction: \"reply: @calbch its the year of the monad\" => \"epta: @a nl e0t B0!.Bcymwsyzrfzbguwvukf\n",
      "\"\n",
      "batch 22066  loss=162.3150  steps/s=133.61  prediction: \" a while before I add it to the site tho\" => \"t dl  y le l   b    e e a  e  e     t tt\"\n",
      "batch 22067  loss=166.0898  steps/s=109.94  prediction: \"e model outputs the ad timestamps. Cropâ€¦\" => \" iedhn amd\n",
      " mo m t u dut u t tme ttm e t\"\n",
      "batch 22068  loss=167.7452  steps/s=111.38  prediction: \"n theres ppl who dont code like this????\" => \" i ron e he n epeh e opepe pe d tod oo o\"\n",
      "batch 22069  loss=168.8148  steps/s=110.84  prediction: \"tly overlooking\n",
      "\n",
      "https://t.co/LodKIC2izF\" => \"heio     su ru  k.\n",
      "kvvfyu:/:yk:\n",
      "LL.LK:L/\"\n",
      "batch 22070  loss=169.3947  steps/s=104.83  prediction: \"coder trust me bro im high iq, see above\" => \"orcon   v  a ei j~\n",
      "jyv/v:./:..://IC2Izq,\"\n",
      "batch 22071  loss=173.6152  steps/s=104.90  prediction: \"ental growth is king. get that bread son\" => \" t d geer e    ta  rr  irigghgt g   t  e\"\n",
      "batch 22072  loss=161.2825  steps/s=99.62  prediction: \"ko I have no idea why it was working tbh\" => \" o07aenonte e  t e e i tnt i  w w t twao\"\n",
      "batch 22073  loss=173.8387  steps/s=81.74  prediction: \"xqc unironically how much I was drinking\" => \" c b cnen n i  a n w    iw w  wra w w nk\"\n",
      "batch 22074  loss=166.9581  steps/s=112.02  prediction: \"most rather just.. not have a device tbh\" => \"edteten e   rs  mIpI)njjck).j\n",
      "IIjdI\n",
      "wIwj\"\n",
      "batch 22075  loss=164.3646  steps/s=78.21  prediction: \"yperpriorai nice acct. right here brutha\" => \":eol  nthtra  ht ....t. t.  at h  e hete\"\n",
      "batch 22076  loss=171.7972  steps/s=113.02  prediction: \"t w pears n bananas n stuff\n",
      "\n",
      "eat by pool\" => \"hsh  tl  wait  tmaxbdhwupbw\n",
      "wmpgicmtdff\n",
      "\"\n",
      "batch 22079  loss=165.3466  steps/s=104.65  prediction: \" bc random twitter guy said itd be funny\" => \"te a ma b be a  t mtte t  tie   d ittde \"\n",
      "batch 22080  loss=171.2773  steps/s=101.44  prediction: \"rd\n",
      "sound dingboard\n",
      "multiplayer dingboard\" => \"e nt  @ t      okkvkvhkubkvklhvPtBwbwulB\"\n",
      "batch 22081  loss=171.7244  steps/s=45.12  prediction: \"y: @mallocmyheart cuda is fun, enjoy man\" => \"  @iaso\n",
      "seon nn dd\n",
      "onddaddnaiorrdanrbiai\"\n",
      "batch 22082  loss=185.4102  steps/s=105.25  prediction: \"o\n",
      "Learn by doing, get compounding skills\" => \"uStrse1ao s  re r ey etye ,, gt  go noii\"\n",
      "batch 22083  loss=170.2924  steps/s=103.26  prediction: \"just think your program into existence?\"\" => \"est    d  t nt tt   n r orr  out  roii t\"\n",
      "batch 22084  loss=176.9856  steps/s=89.07  prediction: \"UBalis welcome to circle tool gang, king\" => \"nE\" g @hceo  al w\"yjljjmejbwkckxyrkgrxj?\"\n",
      "batch 22085  loss=174.5298  steps/s=96.17  prediction: \"ased. Me neither. This is the way to go.\" => \"n  e t nndnB e e  ei  reieii       t   t\"\n",
      "batch 22086  loss=174.8613  steps/s=100.35  prediction: \"te abstractions) https://t.co/JXebRWgl8S\" => \" Ba c  hche s  a(\"yu(w)b)b))(:k:w::.cJXJ\"\n",
      "batch 22087  loss=166.4999  steps/s=101.08  prediction: \"als and make smaller and smaller circles\" => \"nl t e len ndaea e msmem alln  ma lma ll\"\n",
      "batch 22088  loss=172.1299  steps/s=98.60  prediction: \"keep that in mind\n",
      "idk what brypto is btw\" => \"e   plen tl t n e   en n  i i t di  i d \"\n",
      "batch 22089  loss=178.4839  steps/s=105.16  prediction: \"iing is to touch grass\n",
      "get some new data\" => \"nni ot ti ti ii ttiit t tgotsgtts gggtss\"\n",
      "batch 22090  loss=175.4486  steps/s=108.46  prediction: \"ger and crazier, more ambitious programs\" => \" tn  eeaee too eBuB,dsbtcz\n",
      "zc,ð—±zvuw,zmcr\"\n",
      "batch 22091  loss=183.0476  steps/s=107.65  prediction: \"p mode ACTIVATED https://t.co/uIh2EE8mgV\" => \"lte aPtto@t tCteVBPEDkywBwP:bkCPCVIVED2D\"\n",
      "batch 22092  loss=220.3221  steps/s=105.76  prediction: \"r_io ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡ á´„á´€á´˜s Éªs á´›Êœá´‡ É´á´‡á´¡ ÊŸá´á´¡á´‡Ê€á´„á´€sá´‡\" => \"ette:  sti_ r_i á´¡á´‡Ê€á´„á´€Ê€á´„á´€á´˜.á´˜á´˜ÊœÉªÉªÊœá´›á´›Êœá´›É´É´á´‡á´\"\n",
      "batch 22093  loss=185.8050  steps/s=94.68  prediction: \"builds mcdonalds just wants to grill man\" => \"etei  bei @ á´€dd do   d ss st t tt tts á´€s\"\n",
      "batch 22094  loss=178.9022  steps/s=108.99  prediction: \"ur enemy when they are making a mistake\"\" => \"t ennuert ury oe y enee  yh ny me ma ma \"\n",
      "batch 22095  loss=166.7429  steps/s=110.08  prediction: \"h4 then 2. h5 every game against him lol\" => \"e s    th h4.        e      e e  e      \"\n",
      "batch 22096  loss=169.3526  steps/s=109.51  prediction: \"e but it really is super flawed probably\" => \" lid ctele et  t  eeell ll   eeee ei  ap\"\n",
      "batch 22098  loss=166.8633  steps/s=106.66  prediction: \"nt get too random with high stakes stuff\" => \"g , ett nt et  t t t oo d t   t t h th s\"\n",
      "batch 22099  loss=184.3329  steps/s=98.93  prediction: \"a @teodor_io teo mercy killed anime pfps\" => \"nmaa tat ernt ot o too tmh h  k    ssa f\"\n",
      "batch 22100  loss=162.0687  steps/s=105.16  prediction: \"ki my highschool teacher taught it to me\" => \"edg ya t ee  ii ho hohooh ch ae t  tht  \"\n",
      "batch 22101  loss=174.9691  steps/s=105.51  prediction: \"at's definitely part of the current meta\" => \"n dal aeddre   te  t eett at  fe tt t t \"\n",
      "batch 22102  loss=174.2484  steps/s=58.65  prediction: \": @djcows you can make the jungle levels\" => \" @L ton  io tein.bfpTyTpuf.po.bcydc.pr.n\"\n",
      "batch 22103  loss=170.0206  steps/s=112.08  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" i tu thr et  e .blfwhp,ypndp.ymCyCugCuC\"\n",
      "batch 22104  loss=164.0675  steps/s=106.46  prediction: \"es this for leaking my info 12 yrs ago ðŸ˜¤\" => \"   eedeiese e s   e  e e  i             \"\n",
      "batch 22105  loss=173.8307  steps/s=106.79  prediction: \"igABAP has selo made the circle tool yet\" => \"nAoel got w   nli   ll        e   e  o  \"\n",
      "batch 22106  loss=162.7116  steps/s=103.30  prediction: \" @discord I made my own bot from scratch\" => \"@aidiid  gdd s sod  m   e      o   oo  o\"\n",
      "batch 22108  loss=191.8578  steps/s=110.07  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"nn r erriad e e ##ennn  ts ni/n  /tt/tZ/\"\n",
      "batch 22110  loss=211.8083  steps/s=102.22  prediction: \"EVER GIVE UP!!!!!!\n",
      "Another key attribute\" => \"s  Sst o intxMyoM@xRNGINRhGPVEIVPIVPVEP2\"\n",
      "batch 22111  loss=161.3335  steps/s=109.15  prediction: \" the dark forest from the 3 body problem\" => \"@he t  eete er e t eerf te tor t  tro   \"\n",
      "batch 22112  loss=163.7919  steps/s=107.10  prediction: \"ols is kinda like cookie clicker but irl\" => \" l #i oo   istniio itoo  ookcicokii kil \"\n",
      "batch 22114  loss=170.3062  steps/s=109.25  prediction: \"son but thats OK https://t.co/f85X6nDeZy\" => \"t   lr ooa  e t9r t so  sttsth  at tst6t\"\n",
      "batch 22115  loss=173.0089  steps/s=109.66  prediction: \" kache who made dingboard w llms (afaik)\" => \"tiie nthenffe  maimiii  iia wwe dwm ama \"\n",
      "batch 22117  loss=164.6017  steps/s=100.38  prediction: \"hag_ its good to be on the outside again\" => \"erg  xh h  h   tadiide b    ol  dme aiai\"\n",
      "batch 22118  loss=165.9356  steps/s=109.92  prediction: \" velocity\n",
      "\n",
      "so falling players hit harder\" => \"taa een ee o tococo to   llael p ey  ire\"\n",
      "batch 22119  loss=199.6889  steps/s=105.65  prediction: \"1 AAAAAA MY EYES https://t.co/r2a6f3Rhs7\" => \"0y   nn te  oera1v0M0SMY/MYsSY\n",
      "S:ES:S2:6\"\n",
      "batch 22120  loss=164.0575  steps/s=110.35  prediction: \"more efficient parameters in the network\" => \"ere )n  ghmtint )vhvvypfwcdh,ovpmsvfmnvy\"\n",
      "batch 22121  loss=163.9282  steps/s=108.93  prediction: \"erful tool, extremely extremely powerful\" => \" y e melme eleeere  lr extyxtxeeemele ee\"\n",
      "batch 22122  loss=164.1268  steps/s=102.32  prediction: \"nomic than discord id switch immediately\" => \"g hoa  eae  m e  mao  o o odicc iim tiii\"\n",
      "batch 22123  loss=169.3982  steps/s=100.06  prediction: \"f children will build my programs for me\" => \" thetieo, ce   teg,fgyw,f\n",
      "y\n",
      "/fw,wnfw,bud\"\n",
      "batch 22124  loss=169.4475  steps/s=99.02  prediction: \"o much caffeine) https://t.co/Q6lpwY18Mb\" => \" aah otetoo     hffhfh h t tft ////QQQQQ\"\n",
      "batch 22125  loss=194.9319  steps/s=109.79  prediction: \"ainly used @dnbt777 's script (very useâ€¦\" => \"nn att e  sio i i 77 @\n",
      "nd77 '''  s 's (n\"\n",
      "batch 22126  loss=178.3970  steps/s=108.53  prediction: \"ncy, and bitcoin was invented by midwits\" => \"gealiteenht  inctnn aincii  itdiii dn d \"\n",
      "batch 22127  loss=168.7433  steps/s=100.81  prediction: \"s of industry water cooler conversations\" => \" fos  hon  not toaus os ootoatto ns otas\"\n",
      "batch 22128  loss=211.8663  steps/s=102.02  prediction: \"/t.co/RNKp7R32Zo https://t.co/g4GtDNNbM1\" => \"/5oh is    tdt tNNRNZo3ZZoZonnsr cata4GG\"\n",
      "batch 22129  loss=186.8046  steps/s=103.13  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/..e  ehe  EE\n",
      "//QQQQCCQQCC ZZZ . ax.o(x.\"\n",
      "batch 22131  loss=168.4158  steps/s=100.66  prediction: \" about it and in 1 weekend jumped up 200\" => \"t d  ea  ad     a  n  e   a  e  e  ene d\"\n",
      "batch 22134  loss=167.7142  steps/s=97.58  prediction: \"you can control the models, and its free\" => \" u  eccco  coo coo co  ooo  le  od  lds \"\n",
      "batch 22135  loss=163.0011  steps/s=102.48  prediction: \"s but I strongly believe in it long term\" => \" ao  a w  o s s s g s sg  tb i n  ie le \"\n",
      "batch 22136  loss=159.9423  steps/s=110.43  prediction: \"eed\n",
      "\n",
      "Trust is our most valuable resource\" => \" nsed  ndede  sdees u r rs s  us  t loer\"\n",
      "batch 22138  loss=166.7983  steps/s=107.79  prediction: \"e WAY more effective\n",
      "\n",
      "global optima gang\" => \" vi iie enwee  e e   ce  ff e e ee ie oa\"\n",
      "batch 22139  loss=161.1824  steps/s=96.00  prediction: \"going into space man its truly beautiful\" => \" o  aid est e e rpf%pkelbcbbá´„á´¡fkvbkfá´¡khd\"\n",
      "batch 22140  loss=209.6029  steps/s=109.16  prediction: \"S GOING TO WIN\n",
      "whoever ships video first\" => \" mO ia Oe I  OIOWNNN W I I   W  e  oisss\"\n",
      "batch 22141  loss=180.7036  steps/s=101.56  prediction: \"for whatever they click on,play it w VLC\" => \" r t  v_de f\n",
      "a subb\n",
      "d_b)dbl_f...t,awV,p.\"\n",
      "batch 22142  loss=169.6676  steps/s=86.24  prediction: \"y childhood dude https://t.co/iS7aCvZ2nH\" => \" to ee  ln o   d  hh thht d dhd /tt/tt/t\"\n",
      "batch 22143  loss=173.6828  steps/s=98.21  prediction: \"maybe\n",
      "\n",
      "Looking forward to seeing it man!\" => \"eko  a@ mc ba beUGLU.GIGGUUILwmbtpkL\n",
      "gLv\"\n",
      "batch 22145  loss=168.2259  steps/s=102.72  prediction: \"re super super cool\n",
      "\n",
      "etched blew me away\" => \"epl  ir t nhe takMhfMnBrTspprdmktbb\n",
      "\n",
      "gqo\"\n",
      "batch 22146  loss=184.5324  steps/s=91.27  prediction: \", no\n",
      "If anyone else does let us know lol\" => \" mo    ann   nn   ony  ooeo ee  le  ooe \"\n",
      "batch 22147  loss=160.7886  steps/s=100.44  prediction: \"through hoops\n",
      "\n",
      "its harder, until its not\" => \" enve eahr eoeshavá´„,á´€d,dbj,mfkwvjá´€,bkjdj\"\n",
      "batch 22148  loss=160.2741  steps/s=103.56  prediction: \" What are your personal long term games?\" => \"tE lhal la a  a  r to ooor ono e ntl t t\"\n",
      "batch 22149  loss=164.0402  steps/s=46.40  prediction: \"y: @mayfer easy, just ask it what to ask\" => \": @latl  eha  a  r po ooor ono e nt  e a\"\n",
      "batch 22150  loss=191.2076  steps/s=112.04  prediction: \"/t.co/fzyvZotgbj https://t.co/mdkuFi0aQ3\" => \"/..co  s tot ///z/.oo/zZZtotto:t/tt:o///\"\n",
      "batch 22151  loss=177.5114  steps/s=105.28  prediction: \"e in milan venice florence.. sorrento rn\" => \" try on \n",
      "\n",
      "in   iin lllniene ie l ee.cn  \"\n",
      "batch 22152  loss=164.1944  steps/s=52.48  prediction: \"doomslide its over needleinhaystack bros\" => \" n   on  mlle nein  elnnene... i eerce c\"\n",
      "batch 22153  loss=175.2295  steps/s=105.55  prediction: \"ruck is this you https://t.co/TaMoSJicnx\" => \"epllt  toe  u s kvuygiv.dlad:vmb.:dMT.MT\"\n",
      "batch 22154  loss=181.9792  steps/s=116.25  prediction: \"you get used to it and overcome the fear\" => \":u  eroat  o  ut u g   t  t  e      eto \"\n",
      "batch 22155  loss=166.1273  steps/s=105.21  prediction: \"ingly, doable) youre in for a goood time\" => \"ng  s ( (rsr  i rrrly))yr rr yo oo   ooo\"\n",
      "batch 22156  loss=158.6031  steps/s=117.15  prediction: \"ody wake up??\n",
      "Youve killed us all skooks\" => \"neno ne one   ep?o ???ee ee e kule l u k\"\n",
      "batch 22157  loss=172.5824  steps/s=107.61  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"saoloo_dee can nve Ie  ell   e    i  o  \"\n",
      "batch 22158  loss=174.9122  steps/s=99.48  prediction: \"y based. how do you compile zig to wasm?\" => \":t  an  aana a ll e  e  l    i i  i  i t\"\n",
      "batch 22159  loss=168.4963  steps/s=112.87  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"@at  e  alel lt t  e =etete   a  t ht t \"\n",
      "batch 22160  loss=177.7794  steps/s=108.67  prediction: \"\n",
      "\n",
      "I will send u the link around the 25th\" => \"\n",
      "th n eio  c cnt6ðŸ«¡krðŸ«¡.ðŸ«¡I:k/w..bzHH00TTJ5\"\n",
      "batch 22161  loss=165.7395  steps/s=103.65  prediction: \" by talking abt half done projects. BOOM\" => \"tede n eng  neen    a    a a    a    o  \"\n",
      "batch 22162  loss=157.5943  steps/s=89.63  prediction: \"us im in, gonna do this rn, on the rocks\" => \"tu nean  b  a nn   n  a  o  o    n  oo  \"\n",
      "batch 22163  loss=160.1901  steps/s=101.08  prediction: \"s of lib arts classes they make you take\" => \" worsesessseee e  ss  l s ss a aa   se e\"\n",
      "batch 22166  loss=163.3379  steps/s=106.08  prediction: \"er fisherman\n",
      "congrats on the giant catch\" => \" eesa e eess rmsrara raaa t o  to    t t\"\n",
      "batch 22167  loss=176.4489  steps/s=89.16  prediction: \"nks!! feels good to be doing these again\" => \"  cy   sme seem !efoeosoo to  gotn  ecat\"\n",
      "batch 22168  loss=167.0584  steps/s=108.50  prediction: \"re advanced in the art of shape rotating\" => \"eplrt 5n t i  toI,bIwy,\n",
      "vy*,\n",
      "Iy,uIdvlðŸ«¡f,\"\n",
      "batch 22169  loss=164.8608  steps/s=95.05  prediction: \"ike the programming skillset example is.\" => \"ne  oh uheth   egg  hm iog iil  e   tmel\"\n",
      "batch 22170  loss=168.4536  steps/s=105.29  prediction: \"put work in, etc https://t.co/8ZjkHbRuMG\" => \"ltolorietnswrke g,,ygccÉª\n",
      ",yy::/j.fdR88Zj\"\n",
      "batch 22171  loss=218.8061  steps/s=109.62  prediction: \"Y DONT KNOW ME SON\n",
      "THEY DONT KNOW ME SON\" => \"ep  aADaarETOKT EEONNNONHEHOYODTNTO MEWS\"\n",
      "batch 22172  loss=213.6864  steps/s=100.20  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"mgbIz @z NWSzMPWOWLFWEFSTFOTH:/NO.:7K57O\"\n",
      "batch 22173  loss=190.3190  steps/s=110.55  prediction: \" I know!!! I laughed so hard when it hit\" => \"@fte ra t ta ! I!  ! !    h h    d. 5 e \"\n",
      "batch 22174  loss=168.1039  steps/s=111.92  prediction: \"ings will continue until morale improves\" => \"ng APen eTi l  lel l ni llnl  ln ii in l\"\n",
      "batch 22176  loss=168.5474  steps/s=115.90  prediction: \" to me except this feels 100x better fug\" => \"thet  tsn n me  e  xtee ttt stex0xs000  \"\n",
      "batch 22177  loss=172.9654  steps/s=83.23  prediction: \"c ig lisp and haskell are in the 10% lol\" => \"ooto is tan@qcexq@pg@p@xpgfck1pcxpb\n",
      "lf%d\"\n",
      "batch 22178  loss=166.0753  steps/s=108.76  prediction: \"il of the recall/visualization over time\" => \"nl hpioe te t e he ethell iilazlio  ova \"\n",
      "batch 22179  loss=171.3192  steps/s=108.24  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"eth i rauoa t  afgvcy\n",
      "me:v1l:py:JZN.JZ4J\"\n",
      "batch 22181  loss=178.4691  steps/s=110.41  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"to   se el e  ml   u n  e  l  au  lllrr \"\n",
      "batch 22182  loss=164.1938  steps/s=111.54  prediction: \" time on their hands + survivorship bias\" => \"thmo t  mee t te t e he eh   r      riri\"\n",
      "batch 22183  loss=176.6568  steps/s=27.51  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly: @o mh  h he e e heh h + r      riri\"\n",
      "batch 22184  loss=182.2012  steps/s=72.97  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @o e o    e e h heh r + r s   iriri\"\n",
      "batch 22185  loss=159.6011  steps/s=129.54  prediction: \"interested to hear how well it works our\" => \"n   en en ide ee  te e   te  e   w w o  \"\n",
      "batch 22187  loss=167.4078  steps/s=103.40  prediction: \"e soda\n",
      "\n",
      "actually nvm this one tastes meh\" => \" io enmenae\n",
      "   e \n",
      "ae    l\n",
      "\n",
      "aal tt l  t m\"\n",
      "batch 22189  loss=174.9053  steps/s=57.77  prediction: \" @justalexoki You have alerted the horde\" => \"tNa eane  d\n",
      "\n",
      "lol \n",
      "a l  a t ate  tos  s e\"\n",
      "batch 22190  loss=168.7332  steps/s=114.09  prediction: \"be allocate some time to do fun projects\" => \"e  no   n   aeoao  o oot aoo to e  oe o \"\n",
      "batch 22191  loss=172.8887  steps/s=88.91  prediction: \"qc Based, a true warrior of the zig army\" => \"c r  oio ttn em t te too  o  o  e  tee  \"\n",
      "batch 22193  loss=169.5261  steps/s=110.43  prediction: \"BAP lud the goat herder back at it again\" => \"AP @lueiae  A d t er t o ar  e  r  a t  \"\n",
      "batch 22194  loss=169.7701  steps/s=113.15  prediction: \"s message is NOT approved by square gang\" => \" bu lid dms t iP ie Oa ea r  a pra aqa a\"\n",
      "batch 22195  loss=192.4608  steps/s=114.23  prediction: \"ackwards buttons https://t.co/JO2nBFplUJ\" => \"nt      tOdeob  roarbeoba  b ttcs//ttoB2\"\n",
      "batch 22196  loss=164.3049  steps/s=103.46  prediction: \"g his own CAD thing and calls it dingcad\" => \" io  b  \n",
      "ao nae Dw\n",
      "NCADCADNCADbuCADwADC,\"\n",
      "batch 22197  loss=170.7345  steps/s=98.63  prediction: \"ke getting flashbanged by your teammates\" => \"  g iiett iti   tt gn a nga ln   d  ayaa\"\n",
      "batch 22198  loss=159.7134  steps/s=112.83  prediction: \"half done git repos\n",
      "\n",
      "not a fan not a fan\" => \"ev auo   h    h  f       oe oo n   n n n\"\n",
      "batch 22199  loss=170.7296  steps/s=112.15  prediction: \"of the way there https://t.co/hsxVe0znFZ\" => \"r  t  t   t  e tth te het  t  ht htt/th/\"\n",
      "batch 22200  loss=160.4473  steps/s=116.06  prediction: \"t information so you can grow\n",
      "\n",
      "Or u fade\" => \" tooy ea an  t  ycpa$acullu\n",
      "yfdhcafi_fOc\"\n",
      "batch 22201  loss=172.4456  steps/s=124.37  prediction: \"ezm progressive overload builds strength\" => \" mi  on  m or rnssoioovoi roo oaa ar s a\"\n",
      "batch 22202  loss=218.6186  steps/s=115.63  prediction: \"t.co/zMbF6BWCeb\n",
      "\n",
      "https://t.co/HoFIFw5SV9\" => \"  t:/o .//#6r6e zM6MWFWhWChs ps:.cF.FoFH\"\n",
      "batch 22203  loss=181.5062  steps/s=115.50  prediction: \"ks never knows\n",
      "Or... something like that\" => \"  k n n to n ock k o on...r  .  nienet o\"\n",
      "batch 22205  loss=173.8163  steps/s=115.07  prediction: \"ding blocks that make it up, recursively\" => \" shoi il i  l t t il t t ll k  tt tiu ee\"\n",
      "batch 22206  loss=198.2262  steps/s=111.06  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \" e   re=ieei\"t  \"g3\"l3\"\"p=\"m==\"f=.ljj&.j\"\n",
      "batch 22207  loss=172.9867  steps/s=86.73  prediction: \"ve feedback loop\n",
      "https://t.co/SvrkOEyyVo\" => \"er o   otti t  eiep te p eo  t pe ptp/oo\"\n",
      "batch 22208  loss=183.0013  steps/s=115.35  prediction: \" me to launch within 24 hours https://tâ€¦\" => \"tosh noo     ehnu      u  h hi h httth h\"\n",
      "batch 22209  loss=187.4013  steps/s=109.30  prediction: \"e77 build things people want/ need maybe\" => \" 7io  c  @7 i 7 i  iil     lnpnentpp p n\"\n",
      "batch 22210  loss=167.2317  steps/s=100.92  prediction: \"w zooming forward on an electric scooter\" => \" oo   n  m n atelwmzlzmbuzwbzfwcwzð—²umomd\"\n",
      "batch 22211  loss=164.8779  steps/s=110.58  prediction: \" by talking abt half done projects. BOOM\" => \"tuee nieng  neen    a a  a a    a    o  \"\n",
      "batch 22212  loss=176.5462  steps/s=112.05  prediction: \"ng an os in zig\n",
      "\n",
      "schizo giz arc when????\" => \"  i  b  gilno     in iizgngz   z z izc c\"\n",
      "batch 22213  loss=169.3001  steps/s=111.24  prediction: \"is the platonic form of a platonic form?\" => \"n  r  tien  atet    io    faao i of i fo\"\n",
      "batch 22214  loss=159.2519  steps/s=110.26  prediction: \"ive sum game players\n",
      "tautologically true\" => \"ne b  itis ie  si    m     aaaatalloaaal\"\n",
      "batch 22215  loss=168.0194  steps/s=100.93  prediction: \"b, octane, trending on artstation 4k HD\"\" => \"u cined,  ae,,  ,enen ane  o an ant no a\"\n",
      "batch 22216  loss=162.9651  steps/s=101.95  prediction: \"hings way easier\n",
      "https://t.co/SoZ8VeXTFk\" => \"engeeaam mtt t   ia iataai  stt ts t/teZ\"\n",
      "batch 22217  loss=164.0724  steps/s=109.50  prediction: \"erful tool, extremely extremely powerful\" => \" yenemelne eleeere  lr extxxxxexemeleree\"\n",
      "batch 22218  loss=164.6644  steps/s=114.09  prediction: \"to it so you can share with your friends\" => \"  t  gong d temggmg,xgnfxxpmykfucugxonhp\"\n",
      "batch 22220  loss=163.8872  steps/s=115.61  prediction: \" to make it better before (if) I release\" => \"toee  a at  e ee t a et re e  tr ferere)\"\n",
      "batch 22221  loss=177.1488  steps/s=109.35  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"mobny @@tn P A i@m@zNzwmxbpfkrkygif)uIi,\"\n",
      "batch 22222  loss=163.2784  steps/s=115.06  prediction: \" the past two months and its so worth it\" => \"toi tot  ae t et   t t e  t t t s s so t\"\n",
      "batch 22223  loss=175.4034  steps/s=107.26  prediction: \"ctus infobalking https://t.co/B3UT9nTonq\" => \"ossee aoten e  okwvkfwnfhb:yk:k:w.B:UB9U\"\n",
      "batch 22225  loss=162.4033  steps/s=110.84  prediction: \"rself w any song\n",
      "https://t.co/9JcQChQaDl\" => \"e ne wiyta wo tokdvkw:/*p.^f/B3UwyB9JBqC\"\n",
      "batch 22227  loss=186.6057  steps/s=41.46  prediction: \"ly: @yacineMTB sounds like an anime move\" => \"y: @s no  n s s s  t s s///ttt///JJ/QQJQ\"\n",
      "batch 22228  loss=165.3548  steps/s=105.82  prediction: \"ion, which allows better problem solving\" => \"nn  teaceoatooc co taw owote tor  r t et\"\n",
      "batch 22229  loss=176.4581  steps/s=69.77  prediction: \"@MalekiRe cool vr platform bro\n",
      "\n",
      "followed\" => \"yozrIaretaecr whwoltwl owotelboro l b et\"\n",
      "batch 22230  loss=188.0254  steps/s=132.89  prediction: \"racticing self control leads to strength\" => \"eyty en  te til slohccwfurfpbmsmbfhbfsvl\"\n",
      "batch 22231  loss=162.9993  steps/s=102.69  prediction: \"atterns so we should do (description ofâ€¦\" => \"ne h t s tt s   ttt    o h  ss  d dso oi\"\n",
      "batch 22233  loss=161.6892  steps/s=86.03  prediction: \"ick and no login and as free as possible\" => \"nkso  ut nu  u n  un   o no nn  o   s  e\"\n",
      "batch 22234  loss=210.7367  steps/s=97.64  prediction: \" --. .. ...- . / -.-- --- ..- / ..- .--.\" => \"@-ent /t  e e/tt / /n- as/ .es  e /  i-e\"\n",
      "batch 22235  loss=159.3918  steps/s=100.58  prediction: \"interested to hear how well it works our\" => \"ng  en  n idt en  t  e   eeeee  ww w w  \"\n",
      "batch 22236  loss=164.8888  steps/s=103.59  prediction: \"is God for sure. but ive grown confident\" => \"n     sef i  s  s   s  s       r    roe \"\n",
      "batch 22237  loss=186.5829  steps/s=27.20  prediction: \"eply: @bozo10n you can just build things\" => \" ly: @sefi   ss s   s      u   o     oe \"\n",
      "batch 22238  loss=180.0730  steps/s=109.65  prediction: \"s\n",
      "\n",
      "delta time based on system clock yeah\" => \" \n",
      "s  aonphs st\n",
      "ta eee i easa sesslctc s \"\n",
      "batch 22239  loss=155.4397  steps/s=101.58  prediction: \"us things that make your life easier ig?\" => \"rtiuiiii ioi ttit  t t t    tt        e \"\n",
      "batch 22240  loss=165.7106  steps/s=102.97  prediction: \"w zooming forward on an electric scooter\" => \"hyu o n  tin atelwmzlzmbuzwbzfwcwf*umold\"\n",
      "batch 22241  loss=166.7431  steps/s=103.92  prediction: \" been some adventure man. God bless him.\" => \"tu   t se s  see  eve ven een e e e  e e\"\n",
      "batch 22242  loss=170.6336  steps/s=107.21  prediction: \"on adding sound!\n",
      "https://t.co/7jVECuxgpx\" => \"u g   l  a oin Rdngnd dnnn d tnodso/t 7/\"\n",
      "batch 22243  loss=176.0096  steps/s=102.55  prediction: \"you gotta gamify reporting spam bots lol\" => \" u  lg htta  o  yg ga toy gog gamgap p  \"\n",
      "batch 22244  loss=176.7333  steps/s=100.51  prediction: \" in the work\n",
      "\n",
      "love it, happy for you man\" => \"tn   i ii   tt in ei\n",
      " \n",
      "oroeo \n",
      "ta ppp y  \"\n",
      "batch 22245  loss=162.6254  steps/s=111.13  prediction: \"he made a banger\n",
      "https://t.co/kgZADTL0ag\" => \"e  ss  i he   e aee a heap t /t//eg///tA\"\n",
      "batch 22246  loss=183.4988  steps/s=77.56  prediction: \"ing = uppercase\n",
      "not thinking = lowercase\" => \"ng  hhn     aa eaerttth////t////kDTLL==g\"\n",
      "batch 22247  loss=166.8853  steps/s=96.88  prediction: \" clearer at n=1k https://t.co/Hh0lTOJpkl\" => \"totnte  alel le ttre ==t=tt r / ccHHtHtH\"\n",
      "batch 22248  loss=171.7977  steps/s=109.31  prediction: \"and learn faster\n",
      "\n",
      "need to shorten em tho\" => \"nd t lse aoa   eenleaaeens\n",
      "aee nn ne e t\"\n",
      "batch 22249  loss=176.6250  steps/s=108.04  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e nr or m we  rempkThowkukprhpnhwmk\n",
      "mdwT\"\n",
      "batch 22250  loss=201.6424  steps/s=11.95  prediction: \"reply: @Brycicle77 polnareff could never\" => \"e ly: rCo  es  smpkThowkukprhpnhwmk\n",
      "mdwT\"\n",
      "batch 22251  loss=182.7850  steps/s=107.41  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/.cttl hE  Es //QQQQWWWZZWW((Z (((xno5x5\"\n",
      "batch 22252  loss=185.8765  steps/s=52.35  prediction: \"asbasmn i gotchu https://t.co/dWiO4erSb1\" => \"n wa  mn t  o  t(( (xtZ( / :.:5. 5xne1))\"\n",
      "batch 22253  loss=175.9046  steps/s=109.27  prediction: \"mcignore feature https://t.co/oLseuf2uxS\" => \"eoti maeme ono acowc.fc/ghgfph:WfO.cpS:L\"\n",
      "batch 22254  loss=178.8327  steps/s=56.12  prediction: \" @andrew_pynch you gotta bro, its fun af\" => \"tth a   Qo  e anee hettte////t/ot//ose/u\"\n",
      "batch 22255  loss=188.8256  steps/s=114.58  prediction: \"n.. animate it bros. that's 60fps almost\" => \" .  an  ghte..am....ee .i sb 'h'6at's'66\"\n",
      "batch 22256  loss=165.1898  steps/s=94.58  prediction: \"ust store those. skip the whole ML stuff\" => \"teut  sttta  tn esss  st t  t  tht e  t \"\n",
      "batch 22257  loss=172.4921  steps/s=101.24  prediction: \"t help or foxes? https://t.co/lxdEvnjCOv\" => \"han   it betr oex,vxp,?vxffxxbbxxs:?v::c\"\n",
      "batch 22259  loss=162.8398  steps/s=110.26  prediction: \"ng signals from constant individual lies\" => \"  re ait  tees g   sg asa   n ni inainn \"\n",
      "batch 22260  loss=175.2572  steps/s=67.43  prediction: \"@squirtle_says yacine what have you done\" => \"lscenaiesaie sm  n sn nsn  aninini lills\"\n",
      "batch 22261  loss=159.2498  steps/s=108.29  prediction: \"ob/business but.. its fun to think about\" => \"nl o  n n     i b bsb b s  uts  ns s   t\"\n",
      "batch 22262  loss=207.0373  steps/s=73.95  prediction: \"z this SLAPS WTF https://t.co/f7t5zeDo0U\" => \"mgz n @zae  z eeAPLFPSFWeWTFb:b7:7:7z57/\"\n",
      "batch 22263  loss=169.0813  steps/s=91.28  prediction: \"ly harder than the last. repeat forever.\" => \"y: @RLe hto e t   rtht   ha l thehe hte \"\n",
      "batch 22264  loss=174.7825  steps/s=38.26  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y: @R n ht  e err atht   ha l teerethter\"\n",
      "batch 22265  loss=158.3962  steps/s=102.19  prediction: \"people, i just post a weird mix of stuff\" => \"lrn t  ocke tua dT.wk,fvf,,fvjjc,T,hj,jn\"\n",
      "batch 22267  loss=161.9276  steps/s=94.73  prediction: \" not abt to read through all of its code\" => \"tos ts  b  o  n  s t   a t to oh   o   t\"\n",
      "batch 22268  loss=180.1135  steps/s=35.07  prediction: \"ly: template btw https://t.co/UNx1gbqDHQ\" => \"y: @os oit o  e    t   a t ao oh   o   t\"\n",
      "batch 22269  loss=171.3676  steps/s=101.05  prediction: \"tuff goes for you\n",
      "gpu stuff is super fun\" => \"hft   st th eoesmbwxcwwukgd}a/f/f\n",
      "gmybr\n",
      "\"\n",
      "batch 22270  loss=171.3041  steps/s=67.78  prediction: \"ttler @1Mortrix you got doorbell ditched\" => \"hit ats un r aes@1M1Mwwuxgx4a/f/f\n",
      "gbynx\n",
      "\"\n",
      "batch 22271  loss=165.0082  steps/s=98.44  prediction: \" wanted to include infinite programs too\" => \"ten  n wont    ni t o i  tntiee i iiit  \"\n",
      "batch 22272  loss=177.7940  steps/s=84.34  prediction: \"r for imbalances\n",
      "https://t.co/DdYbJD37dq\" => \"eteggsnior  s   mjMspwrup/::/fn:DYDbYYbD\"\n",
      "batch 22273  loss=162.3532  steps/s=107.46  prediction: \"cast he became push hands world champion\" => \"ole eo oo ot  u bmgop:cpm/mp/pbmbmmdpuwk\"\n",
      "batch 22275  loss=173.6102  steps/s=12.11  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"eply: ggo  t  n bmgop:cpm.mp/pbmbmmdpuwk\"\n",
      "batch 22276  loss=170.9408  steps/s=140.60  prediction: \" a game of chess https://t.co/USjWySv3W9\" => \"t s  a oa og    esse    hsshsot/tt/US/SS\"\n",
      "batch 22277  loss=174.1033  steps/s=86.48  prediction: \"yan I have fun. does that make me a CEO?\" => \":cia aamy c    aae  e f hsthstt/tt/m /9 \"\n",
      "batch 22278  loss=191.4809  steps/s=107.45  prediction: \"sed off todo list looks sooooo good\n",
      "HYPE\" => \"   s t te  tt tots t  s oeo s to o s sds\"\n",
      "batch 22279  loss=171.7229  steps/s=109.07  prediction: \"om gpt10 how strong could you make gpt2?\" => \" eyh a taetta   0 0ot ot oto t  oo l  o \"\n",
      "batch 22280  loss=180.7016  steps/s=97.62  prediction: \"t just means youre on par with a supergm\" => \" af se@i ncomonnIjIj@jjljn2mcIyOjkOjgp2?\"\n",
      "batch 22281  loss=177.3252  steps/s=69.83  prediction: \"@IterIntellectus https://t.co/7QXmzFoC4o\" => \"lteekcoet1 e  s tss otot p o t    rpQap \"\n",
      "batch 22282  loss=171.8145  steps/s=106.33  prediction: \"ive and do the bare minimum you may getâ€¦\" => \"neao   tinf  ap d d se  ra r  ii ie m  i\"\n",
      "batch 22283  loss=158.1745  steps/s=112.24  prediction: \"to fall back on. build stuff on the side\" => \"  tuiyhtrna2sryi21jyðŸ’ª`j;|ð—°**j`bjdkjmj.ð—ªg\"\n",
      "batch 22284  loss=164.2662  steps/s=105.68  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sa  emme sse e  eamt  â€¦ttt s tttt ///tt\"\n",
      "batch 22285  loss=166.1055  steps/s=110.52  prediction: \" who have it wrong\n",
      "shes just too high iq\" => \"tam tilh wt  t  hi   hs wsh s  ho  hst  \"\n",
      "batch 22286  loss=166.3437  steps/s=96.63  prediction: \"did it again w feedback itd be the paper\" => \" nt  ebd d  iid  d aia a d d d eaea b e \"\n",
      "batch 22287  loss=169.2929  steps/s=106.19  prediction: \"ait to see what you cook up with giz inc\" => \"td di i t aie  w weata ae  e w  w   p ep\"\n",
      "batch 22288  loss=168.0492  steps/s=25.81  prediction: \"ply: @sunsettler https://t.co/NxD7kZc8w1\" => \"ly: @  n  ne et knrwcy,:d/g.ynynxwckZzyw\"\n",
      "batch 22289  loss=171.3458  steps/s=119.91  prediction: \"rld\" excuse me?? https://t.co/885p1kCMZZ\" => \"ee coreim ti   owpr\"\"\"xxx\"x:xmx??xxfo5::\"\n",
      "batch 22291  loss=160.5531  steps/s=114.22  prediction: \"o make a comeback. would be great to see\" => \"nte   etto  o  m  e ee o    o   a     e \"\n",
      "batch 22292  loss=158.1079  steps/s=92.21  prediction: \"ed, shit randomly doesnt work\n",
      "\n",
      "i love it\" => \"   eeaneae e de i d  do oo   oo do o eo \"\n",
      "batch 22293  loss=179.7054  steps/s=113.80  prediction: \"amming you can make bigger leaps though.\" => \"ne  20, n2t t a   ogn gonm mnn  rigeageg\"\n",
      "batch 22294  loss=167.0859  steps/s=116.71  prediction: \"ta but those with a data engine: iteratâ€¦\" => \"  t  aiohn einneyAbAgbpdcwyIbeosdIp:l:cd\"\n",
      "batch 22295  loss=162.9542  steps/s=116.40  prediction: \"s a natively written zig matmul function\" => \" th s  sivvvv  tit t i  e tttttti     mt\"\n",
      "batch 22296  loss=170.1307  steps/s=99.45  prediction: \"us example like this for numerous toolsâ€¦\" => \"tt t neaerm  enmlmelmale e le e  e  ue r\"\n",
      "batch 22297  loss=180.7644  steps/s=79.77  prediction: \"s Thanks @Laz4rz for telling me abt them\" => \" trt   elwaika  ai erz@ezz ze or lr l te\"\n",
      "batch 22298  loss=164.2138  steps/s=108.86  prediction: \"ews on the internet\n",
      "id say it worked lol\" => \"   ai tie @ ten in e  ern tnerteetent te\"\n",
      "batch 22299  loss=164.9155  steps/s=105.27  prediction: \"s\n",
      "\n",
      "probably gets more views bc of it tho\" => \" \n",
      "ffenysa\n",
      " yaaaaay ysa  o   s  ee b  oo \"\n",
      "batch 22300  loss=169.8552  steps/s=108.09  prediction: \"that can run for under $1000 of compute?\" => \"he s antc n e n vrevfmdl$v$e$1$1rcdids$1\"\n",
      "batch 22301  loss=182.8586  steps/s=86.26  prediction: \"eigecamry @sunsettler shredded that shit\" => \" c   tah tth n n @ u u r $ r r r r outu \"\n",
      "batch 22302  loss=170.2034  steps/s=113.00  prediction: \"od simclusters chosen principle engineer\" => \" i  ttee  ooo uo c rsceo seosccie epniip\"\n",
      "batch 22304  loss=171.7580  steps/s=114.11  prediction: \" and functional, genius place for a blog\" => \"tnd m    et  n  unu,nine ,un li uu le la\"\n",
      "batch 22305  loss=236.0323  steps/s=113.91  prediction: \"ONE\n",
      "FREEDOOOOOM\n",
      "\n",
      "https://t.co/MAxrYM3cut\" => \"O HHGENN DOOE OO\n",
      "E\n",
      "OOEOOO O  //OMM///:tY\"\n",
      "batch 22306  loss=182.2150  steps/s=96.96  prediction: \"alexoki if ur not top tier, ur slop tier\" => \"nl     tlEO OE  \n",
      " \n",
      "t t\n",
      "////   t tr 33 tt\"\n",
      "batch 22307  loss=164.2304  steps/s=115.36  prediction: \"so i havent used anything like webgl yet\" => \"  se sso g ss s  e s    e nn t ie n e ie\"\n",
      "batch 22308  loss=165.2416  steps/s=110.93  prediction: \"ful info have you learned from it so far\" => \" n  noegtati sewb@wi\n",
      "cá´w\n",
      "ðŸ˜wb,w.ch\n",
      "vAJvnu\"\n",
      "batch 22309  loss=160.0176  steps/s=114.89  prediction: \"uture w her, and what that would be like\" => \"s  oniete n u re   u e w  w ah tahat t  \"\n",
      "batch 22310  loss=185.2441  steps/s=111.22  prediction: \"lda is better than 3D Zelda\n",
      "\n",
      "its vanilla\" => \"y  @tnta heteeh  ett e teDtetDa ee  e it\"\n",
      "batch 22311  loss=160.0261  steps/s=114.86  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"em21 iim i e tngkpv@Zck3dkmlkslâ€¦Dl\n",
      "DuvmZ\"\n",
      "batch 22312  loss=156.0727  steps/s=112.79  prediction: \"utomatically imagine letters as colored?\" => \"s  o oto ooaaaoa    aaalaalele     e  e \"\n",
      "batch 22313  loss=162.6244  steps/s=115.62  prediction: \"etting criminals https://t.co/I80KU5YP6D\" => \" h naeiain aniii iniiiti n  tttt////t/KK\"\n",
      "batch 22314  loss=165.7517  steps/s=108.57  prediction: \"an wrong something something bla bla bla\" => \"nd ai ten n rnan n mm mtnn nontmsothtgh \"\n",
      "batch 22315  loss=159.1047  steps/s=115.05  prediction: \"rand plan\n",
      "\n",
      "reture your parents type shit\" => \"em21 ein i e tngkpvdâ€¦vk)dkwlybwb\"vwb\"vPy\"\n",
      "batch 22316  loss=165.0360  steps/s=114.79  prediction: \"what's needed to  step out of reactivitâ€¦\" => \" at  l\" tt tumonu)\"]b)\"h\"ðŸ˜¢'h#)'|\")w)\")'h\"\n",
      "batch 22317  loss=183.6573  steps/s=77.95  prediction: \"calbach_ thanks! hope its useful for you\" => \"hlee  eewhot m  u!\"\"!)!\"\"\"'fu)',dlwv\")â€¦ðŸ›‘\"\n",
      "batch 22318  loss=172.5646  steps/s=117.33  prediction: \"e and remember as much as possible after\" => \" stl a     a mame e amm me    e m s ee e\"\n",
      "batch 22319  loss=160.0085  steps/s=112.76  prediction: \"his is the same w similar things in life\" => \"es eg tiintstisn sth e s e  is  hiit s i\"\n",
      "batch 22321  loss=169.0100  steps/s=107.43  prediction: \" make no?\n",
      "\n",
      "maybe @yacineMTB can add this\" => \"tuke sss   ee  m \n",
      "    me @y @ neya  aB e\"\n",
      "batch 22322  loss=178.3651  steps/s=102.73  prediction: \" does mclaurin and exp mclaurin only rn)\" => \"to   se el e  Il   u s  e  l  au  lllrr \"\n",
      "batch 22323  loss=182.1876  steps/s=95.03  prediction: \"gram rlly helped https://t.co/ymqE5CrUM0\" => \" a    a  iegd d ,fsyrm.miyyyhmdr.:fks.q:\"\n",
      "batch 22324  loss=165.5338  steps/s=98.22  prediction: \"s called it tho, dont practice deception\" => \" bh     ste  et le itt  t ot  o   otct i\"\n",
      "batch 22325  loss=167.4977  steps/s=85.82  prediction: \" the code in my head like an interpreter\" => \"thintin thn he  thd  h n  d  i    e e  i\"\n",
      "batch 22326  loss=166.7208  steps/s=93.87  prediction: \"\n",
      "\n",
      "Iâ€™ll go first: https://t.co/n3wNQetA5s\" => \"\n",
      "ip  e@ tte a oâ€™s:Iâ€™Y.Iâ€™Iâ€™fIâ€™lfkf3QNQk53\"\n",
      "batch 22328  loss=173.9821  steps/s=93.72  prediction: \"/t.co/NFBmGb3hps\n",
      "https://t.co/W9XoyMgkGV\" => \"t.cineeteioeâ€™t/ t///BBBB333s:pht:pps.t/t\"\n",
      "batch 22329  loss=181.8815  steps/s=94.47  prediction: \" for circle gang https://t.co/zux9O8ry7V\" => \"trmcaipn an r  e cirnc/hctgs:/st.ss/zttz\"\n",
      "batch 22330  loss=171.6622  steps/s=80.28  prediction: \"d some memories for me\n",
      "\n",
      "also, cubes oooo\" => \" fon  tu ele  em  meeo e momo\n",
      "meso\n",
      "s os \"\n",
      "batch 22331  loss=184.6165  steps/s=86.50  prediction: \" lol positive feedback loops are awesome\" => \"tes ta  sot  eet aee doodioo oopee aeipe\"\n",
      "batch 22333  loss=174.7521  steps/s=89.14  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"hioe     e t    r)m)bnh)):)//h..w//DRRRD\"\n",
      "batch 22335  loss=159.9158  steps/s=91.23  prediction: \" adding the context into the computation\" => \"tnd t  uoe o    e o e idnt o te tn oto t\"\n",
      "batch 22337  loss=162.3636  steps/s=93.36  prediction: \" pried the shift key off w a screwdriver\" => \"tar e aeanpee    tee e   t e t f e e f f\"\n",
      "batch 22338  loss=178.1234  steps/s=109.93  prediction: \"p was the ultimate signal the whole time\" => \"loa  noe bd te  dbvbwvuklx,fpbwwsflfwmym\"\n",
      "batch 22339  loss=175.1463  steps/s=112.33  prediction: \"xes this (whether you want it to or not)\" => \",dp eis oii s eshew( whtwewwe ta t io  r\"\n",
      "batch 22340  loss=175.2518  steps/s=108.57  prediction: \"rse21 help poor sama out, he needs ideas\" => \"e epnto_  l2ho  @21ix(x21y2u21y(mgl$h(,n\"\n",
      "batch 22341  loss=172.8614  steps/s=39.14  prediction: \"y: @benfleming__ its lifechanging really\" => \": @canthi he h r  rae  aoo  o o  o na  e\"\n",
      "batch 22342  loss=183.5769  steps/s=125.38  prediction: \"? i actually dont know anything abt groq\" => \" Wh  t ntTe e ntgw_MTBMwBTtur,kisgpch%kg\"\n",
      "batch 22343  loss=166.6981  steps/s=92.51  prediction: \"tony learns domain expansion in season 5\" => \"  t oe n g atnhtdokkrkgww!mki,gimglxxrxg\"\n",
      "batch 22344  loss=166.4105  steps/s=91.77  prediction: \"e WAY more effective\n",
      "\n",
      "global optima gang\" => \" li in nenwie  e e   fe  ff e e ee ie oa\"\n",
      "batch 22346  loss=199.1797  steps/s=26.71  prediction: \"ply: @ns123abc mad growth, what happened\" => \"ly: @ar   A  At m'WAY'WA,vw/v/'w,avbW,v,\"\n",
      "batch 22347  loss=177.2414  steps/s=127.09  prediction: \"Lets go. Hoppin on now. The grind begins\" => \"  Sht   ahm LM sHLy.gH.dHbH/vbpTbY.bT.vT\"\n",
      "batch 22349  loss=173.7549  steps/s=92.03  prediction: \"an!\n",
      "Gpt 4o came in clutch for the images\" => \"nd oMT tnng   nma4    n  n c  c c  e  i \"\n",
      "batch 22350  loss=165.5217  steps/s=88.19  prediction: \" apart and send each one off to an agent\" => \"tnd   at  a a  t a e d da  eenn  o  fof \"\n",
      "batch 22351  loss=162.4949  steps/s=95.85  prediction: \"oud to yourself, or in your imagination)\" => \"  h ont  t to o toul uo o  o  ro oo oort\"\n",
      "batch 22352  loss=176.9902  steps/s=83.09  prediction: \"wphones @netcapgirl @yacineMTB kiki take\" => \"hrcs  eated rse f,bc@ps,@y,@T@,MTBMTMTBg\"\n",
      "batch 22354  loss=169.5557  steps/s=105.31  prediction: \"\"\n",
      "\n",
      "evil often follows. Cain murders Abel\" => \" \n",
      "e it \"fhe i  oiofofiofof en loC Ca   l\"\n",
      "batch 22355  loss=180.7988  steps/s=106.76  prediction: \"om fixing algos\n",
      "\n",
      "https://t.co/WN11hLPlkB\" => \"ue xx nx fn    x   oo og\n",
      " \n",
      "t ss//s//NN11\"\n",
      "batch 22356  loss=170.6091  steps/s=95.28  prediction: \"ot wrong, youve just seen enough 'demos'\" => \"uhonsso  w oonrn uuo uou   seuee o gu n \"\n",
      "batch 22357  loss=186.5667  steps/s=90.80  prediction: \"cicle77 welcome aboard the zig train bro\" => \"hessi  @oscl ytl75wjpp::ab..,j.czvhz'zkk\"\n",
      "batch 22358  loss=182.1556  steps/s=82.09  prediction: \"@gizmobly @XEng lol why did he block you\" => \"tizwor_iot wn  we oo e e e oeg e heno n \"\n",
      "batch 22359  loss=170.5159  steps/s=121.31  prediction: \"e code a bit in /ai-tools/multicoder lol\" => \" so tttnood     at  io i  et t  a /ii oo\"\n",
      "batch 22360  loss=162.9085  steps/s=102.72  prediction: \"hag_ its good to be on the outside again\" => \"et ttt ahhg  ih it  io io o ot otdeiiioi\"\n",
      "batch 22361  loss=171.8064  steps/s=103.60  prediction: \"ex Only if you get a lobotomy afterwards\" => \" pto e tn g   oooy  to t  o otooi toaiaðŸ›‘\"\n",
      "batch 22362  loss=161.7648  steps/s=116.22  prediction: \"cond while avoiding exhausting the first\" => \"hms  yan  a  nn ksykdycvy#dk9yccxhkuwdid\"\n",
      "batch 22364  loss=189.8260  steps/s=115.77  prediction: \"arning #studying https://t.co/dc8Zt3S2XY\" => \"rn ri tei t e n ##ennn  ts ninn  /tt/t8/\"\n",
      "batch 22365  loss=176.6788  steps/s=111.59  prediction: \"he gba also used triangle waves\n",
      "Probably\" => \"e kI ntne ta    let ss  t a atggtgsas e \"\n",
      "batch 22366  loss=165.7677  steps/s=101.63  prediction: \"tard Interesting can you elaborate more?\" => \"hna\n",
      "Idia d  o e Ibwerwbcbdsavfv\n",
      "PvPswPvw\"\n",
      "batch 22367  loss=162.5509  steps/s=116.71  prediction: \"If are not one, you stand out like crazy\" => \"   ee tem be   no  oe    o   o   ont  e \"\n",
      "batch 22368  loss=182.8661  steps/s=91.70  prediction: \"eigecamry @sunsettler shredded that shit\" => \" n  e ee ao e  no  ot et oe  o e dtt  d \"\n",
      "batch 22369  loss=170.8342  steps/s=116.01  prediction: \" my life\n",
      "I thank Jesus for the pro strat\" => \"ta m    d t        eIeI  e JJeee   se tr\"\n",
      "batch 22370  loss=170.5897  steps/s=116.57  prediction: \"ize mistake cels https://t.co/Wl69rVD7A8\" => \"ni i t eg n t  e tietmt mimi ce ce 6W66c\"\n",
      "batch 22371  loss=184.6246  steps/s=111.68  prediction: \"tic strategy\n",
      "Positional chess type stuff\" => \" ce ioi  so   s PSPFSxaPhS.\n",
      "PpW/tPchDPA8\"\n",
      "batch 22372  loss=166.8682  steps/s=104.96  prediction: \"AM much more energy and thoughts flowing\" => \"P9q\n",
      " eaae e     m e e erer  ene  t ehtn \"\n",
      "batch 22373  loss=167.5473  steps/s=112.19  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"    ondoono  on  o n   nn o no  NeNe eer\"\n",
      "batch 22374  loss=163.6399  steps/s=110.43  prediction: \"arpertony lichess? and what time control\" => \"nn rlr y @ @l  errryr  nnl hee ee   e nt\"\n",
      "batch 22375  loss=192.2027  steps/s=112.85  prediction: \".03$ a day you can help a webdev in need\" => \" x/  sqenewt_ ao3$yqx_.03$3jNp.d3h0.$3ac\"\n",
      "batch 22376  loss=188.1480  steps/s=110.10  prediction: \" was truly L tier. not L tier but L tier\" => \"@or w0 t_ trr nts oy ay  L .L oeeL. LL L\"\n",
      "batch 22377  loss=166.0436  steps/s=115.26  prediction: \"sed to sound like the opposite of curses\" => \"td t lbetsds dsesd        e  ot o oe e  \"\n",
      "batch 22378  loss=163.1488  steps/s=112.00  prediction: \"like a really really interesting project\" => \"yce dllosllee   lee lla eell eelller  re\"\n",
      "batch 22379  loss=163.8258  steps/s=111.37  prediction: \" a massive scale https://t.co/rMKBSw6Nai\" => \"t d a  to ss  a sea   staesttts ///e st/\"\n",
      "batch 22380  loss=170.2424  steps/s=116.31  prediction: \"the community give me energy to do these\" => \" e rtsaand thn rykNl,\n",
      "bvwgfvkmudkdyphgvv\"\n",
      "batch 22383  loss=158.4570  steps/s=114.41  prediction: \"dit on my phone)\n",
      "https://t.co/iWZ4An9PaZ\" => \" n e ete te e       t  ot tt ttto/t//tt/\"\n",
      "batch 22384  loss=176.3531  steps/s=102.62  prediction: \"oin same here same here\n",
      "\n",
      "many yrs wasted\" => \" n t  e te  o eme he he/etee/e//e\n",
      "/ynPan\"\n",
      "batch 22387  loss=169.9511  steps/s=112.15  prediction: \" windows update almost bricked my laptop\" => \"thei d  ing a d ww d  a    d as a d a   \"\n",
      "batch 22388  loss=181.0549  steps/s=110.92  prediction: \"s of data w LLMs\n",
      "https://t.co/L3J9BQN9jV\" => \"to pn n  ao  tw aaoL LLLLLtstt/t//c///tJ\"\n",
      "batch 22389  loss=165.1575  steps/s=114.63  prediction: \"l else being equal)\n",
      "\n",
      "but really\n",
      "\n",
      "idk bro\" => \"yies ntersn seanlsellellble e eeell\n",
      "\n",
      "\n",
      "ue\"\n",
      "batch 22390  loss=168.1498  steps/s=97.95  prediction: \"t progress/mistakes made/lessons learned\" => \" wo   e    o eis//,p,fg/mw/mfkwpkktkgv,f\"\n",
      "batch 22393  loss=177.6198  steps/s=29.97  prediction: \"ply: @Wooltard @eigenrobot Poor things ðŸ˜¢\" => \"ly: @oenfeao eis//hp,fg/mw/mfkwpkkgk,vdf\"\n",
      "batch 22394  loss=161.6187  steps/s=110.12  prediction: \"l think its cool https://t.co/YHY6oJDAQ3\" => \"yse it ut    tt    tt    tt tttt///YYYYY\"\n",
      "batch 22395  loss=158.9341  steps/s=108.13  prediction: \"e forever with a simple 5min interaction\" => \" son ne eoheeetfe  i e  e  eee   mii  i \"\n",
      "batch 22396  loss=180.7762  steps/s=22.09  prediction: \"eply: @mynamebedan head completely empty\" => \" ly: @eoee eee  e  i e ee  iei m mii  i \"\n",
      "batch 22397  loss=157.1262  steps/s=129.70  prediction: \"es absolute security\n",
      "its like proving H0\" => \" sere nesesee essuurusutuu ssies  sriii \"\n",
      "batch 22398  loss=193.7524  steps/s=33.50  prediction: \"ply: @01beigecamry DAYUM this looks good\" => \"ly: @      i en vgDADudUMv\n",
      "bfbpuc\n",
      "f'wyH0\"\n",
      "batch 22399  loss=168.1143  steps/s=107.79  prediction: \" from scratch, and a bit of transformers\" => \"ton  m oprop  pcpc or cc aaaa a a f   ar\"\n",
      "batch 22400  loss=181.0795  steps/s=109.43  prediction: \"s man. i try to keep it real as they say\" => \" aap ep ahe   tnan   r  t   r  a   te ea\"\n",
      "batch 22401  loss=183.2698  steps/s=111.80  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tn eemtn.    t  $7 6 t7tt tt . .ttt /tt/\"\n",
      "batch 22402  loss=160.2078  steps/s=112.15  prediction: \"s, but eventually this catches up to you\" => \"  a   bdenn  l eee eltlll e t e  ett t  \"\n",
      "batch 22403  loss=157.7003  steps/s=102.80  prediction: \"ed hard at improving, mostly by studying\" => \"  ao   w rwr  dd  rr  or  a  t    s   y \"\n",
      "batch 22404  loss=167.1506  steps/s=111.77  prediction: \"st went from rome to naples two days ago\" => \"  h i eaeel t r   t  e    e       o   t \"\n",
      "batch 22405  loss=157.7841  steps/s=113.09  prediction: \"did it again w feedback itd be the paper\" => \" fe  ead d   di  i a a a   e  e b b   e \"\n",
      "batch 22406  loss=171.5460  steps/s=115.73  prediction: \" 10% is figuring out a fix + applying it\" => \"t6smrr i s i i   i r     i i i +++ + g i\"\n",
      "batch 22407  loss=175.9882  steps/s=110.38  prediction: \"ight go back to ML stuff instead of this\" => \"nhcTm  ih i g gt t     t t t  s  t fofti\"\n",
      "batch 22408  loss=171.5305  steps/s=108.76  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"t g msga b aa  o kt a t  t t  /t// t/999\"\n",
      "batch 22409  loss=167.9586  steps/s=112.92  prediction: \"error signals, weakening backpropagation\" => \" senee fe fn es ere renreae  enkka enggg\"\n",
      "batch 22411  loss=166.9010  steps/s=71.79  prediction: \"@yacineMTB You want us to find our moms?\" => \"lacierMei nsn w eweeeene as kenakaoaagoo\"\n",
      "batch 22412  loss=155.9632  steps/s=117.68  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sh  en e ssa eD e  t  tttt s tt/t ////U\"\n",
      "batch 22413  loss=155.7139  steps/s=113.41  prediction: \"ernet becomes, say, 100x more addictive?\" => \"  tneth enennetee    ee  ee   00e  0e   \"\n",
      "batch 22414  loss=168.0201  steps/s=113.81  prediction: \"k out\n",
      "\n",
      "more of an adventure that way tbh\" => \"eow uooos tt \n",
      "\n",
      "no o   o   o  t  te tt a \"\n",
      "batch 22415  loss=154.6925  steps/s=115.03  prediction: \"d high level info sometimes.\n",
      "Definitelyâ€¦\" => \" \"t a oa e  ve ee l  el o  eeeeiieiee ee\"\n",
      "batch 22416  loss=159.6193  steps/s=113.01  prediction: \"n and id 100% recommend it over The Goal\" => \" led d   oon   dd 0000    n         e ee\"\n",
      "batch 22417  loss=158.9773  steps/s=112.96  prediction: \"ions you choose, like oregon or whatever\" => \"tn rf ntfoeo tcocsooe   eooeeoo ooo or e\"\n",
      "batch 22418  loss=172.5023  steps/s=58.52  prediction: \"ludwigABAP its all slop tier, always was\" => \"yd toon   io sicoiool  seo oe o oo   ere\"\n",
      "batch 22419  loss=157.2447  steps/s=130.57  prediction: \"secret instructions on the 25th (a link)\" => \"  e u lr e re eccerrsc tr    t st t t t \"\n",
      "batch 22420  loss=171.2317  steps/s=102.89  prediction: \"s Chat with your cat in the hat on a mat\" => \" coet wisie itritui o  oo    t  t th t  \"\n",
      "batch 22421  loss=168.1875  steps/s=115.78  prediction: \"you have ffmpeg installed on your system\" => \":u tntent    a t    t a  e a e    o e  y\"\n",
      "batch 22422  loss=161.7235  steps/s=108.57  prediction: \"ki You fool\n",
      "You cannot kill the replydra\" => \"en   xteaffoof fYoY u ll ln  l   ll t l \"\n",
      "batch 22424  loss=163.7342  steps/s=109.73  prediction: \"oing on there lately\n",
      "\n",
      "ah the ol # method\" => \" n  pnpioe   o g o n lonelllehelltehlte#\"\n",
      "batch 22425  loss=176.7411  steps/s=84.33  prediction: \"atedro @gizmobly https://t.co/IFzJo2qtyj\" => \"ne oa  tot  mo   ltel  \n",
      "tht eh #lt  hteo\"\n",
      "batch 22426  loss=169.8625  steps/s=117.92  prediction: \" at like 8pm\n",
      "\n",
      "Every restaurant offers it\" => \"tn e n  f e eef  8k   e  e eeee rrrr  ef\"\n",
      "batch 22427  loss=154.8224  steps/s=107.75  prediction: \"velsio im hyped to see what youre cookin\" => \"erllvlene@ee eel i   e     e    ee et to\"\n",
      "batch 22428  loss=203.1387  steps/s=105.99  prediction: \"re @ludwigABAP @sebby_builds hood braces\" => \"epl  n HS   8etgAPvPB@PBA_A_b@_bd_bfbfbg\"\n",
      "batch 22429  loss=170.5930  steps/s=115.37  prediction: \"16, now we play the long game https://tâ€¦\" => \"6 ruud mo ot h s6,k@.w.w.qfx.16,.bfw16g6\"\n",
      "batch 22430  loss=159.8780  steps/s=112.21  prediction: \"for this is real\n",
      "https://t.co/6C7sVlSNIc\" => \" r n  @ ms l  cc@,+â€œÉ´wð—¶wá´}ma]\n",
      "C[dVfdå§fgf\"\n",
      "batch 22431  loss=157.6479  steps/s=115.01  prediction: \", or if claude is in an india region tho\" => \" ao  n ooin i i  i i  i  i ini  anii  i \"\n",
      "batch 22433  loss=150.7430  steps/s=115.13  prediction: \"ts effortless to read/follow works in it\" => \"h  he  ti tee ettete tte e eo or  o  owo\"\n",
      "batch 22434  loss=158.1555  steps/s=114.85  prediction: \"cuda skills, so its a fun way to do both\" => \"ots,  isgie  ttl46v_pv7vmp.mbgyvpmyxcHkg\"\n",
      "batch 22435  loss=155.3322  steps/s=115.65  prediction: \"ink not tho, I believe in synthetic data\" => \"ng  ot thiniItt It         n    i  ie ee\"\n",
      "batch 22437  loss=152.6178  steps/s=111.11  prediction: \"h\n",
      "Also good to know abt the muting thing\" => \"eA dsdsots ooooo oo  oo  o    t   t  ttt\"\n",
      "batch 22438  loss=167.8352  steps/s=109.93  prediction: \"minds me of this https://t.co/smr7iYjZBU\" => \"end  ee al  yenevITcTpy:vckf:wvZbv7\n",
      "Yj::\"\n",
      "batch 22439  loss=157.4017  steps/s=109.34  prediction: \" glitches\n",
      "your game is looking great btw\" => \"toi  a   g  e le ee e es e is  oog ggogg\"\n",
      "batch 22440  loss=157.0388  steps/s=112.90  prediction: \"ave been trying to compress these lately\" => \"ne  l o lo ll  n e      t  o  te    ee  \"\n",
      "batch 22441  loss=175.5857  steps/s=109.64  prediction: \"the man just liked big words and spirals\" => \"ha k  g  n  n n kt t  te m s  tss se  e \"\n",
      "batch 22442  loss=159.8889  steps/s=115.82  prediction: \"ys a bad thing just good to keep in mind\" => \": sllan laaasaa aaa s  s    tt     to   \"\n",
      "batch 22444  loss=157.8459  steps/s=111.51  prediction: \"ably do this for all future projects tbh\" => \"nts    seed bob o o  o   l   rr   u u  r\"\n",
      "batch 22445  loss=176.0503  steps/s=102.50  prediction: \"amebedan @jaivinwylde stochastic success\" => \"ne   l  slo bon n ll i ull   rro  s r ts\"\n",
      "batch 22446  loss=157.5056  steps/s=116.57  prediction: \"engthen the habit over reps\n",
      "Cool thought\" => \" tioertfoetteh ttht t hehetht erer  o oC\"\n",
      "batch 22447  loss=153.9991  steps/s=112.81  prediction: \" to get tons of llms to output good code\" => \"theet eiett gt to  too t    t lo ot o  o\"\n",
      "batch 22448  loss=160.4016  steps/s=113.84  prediction: \"u a why/a vision for hard work over time\" => \"sgo   ov wh   vi oi    i a   o oa r r  o\"\n",
      "batch 22449  loss=143.8552  steps/s=111.01  prediction: \"ure the first man on mars thats so crazy\" => \"s  eey te  e  et e   e             s   s\"\n",
      "batch 22450  loss=163.5781  steps/s=113.24  prediction: \"helpful\n",
      "Been using it more n more lately\" => \"e  d s    d lu ueeueeue e    n e   ne   \"\n",
      "batch 22451  loss=182.3451  steps/s=111.99  prediction: \"a have hella nostalgia in like 10yrs bro\" => \"nb  se  c   r   rana heaga  a leneaon n \"\n",
      "batch 22452  loss=172.7248  steps/s=116.99  prediction: \"unity widget'\n",
      "\n",
      "It's based on the animalâ€¦\" => \"sdei mem  n w me'ie't''t't' t d dt ttt e\"\n",
      "batch 22453  loss=163.6039  steps/s=116.36  prediction: \"im definitely not an expert in it though\" => \"n  oe   sisiii nii  i  e  ee      t  ntt\"\n",
      "batch 22454  loss=206.3266  steps/s=41.77  prediction: \"ly: @MewerChewer thanks man, no problemo\" => \"y: @Yu eieiiiin i n e  e  e   n   t  itt\"\n",
      "batch 22455  loss=156.6506  steps/s=133.80  prediction: \"y be a way to do it without grad descent\" => \":bhhethht a              t  t  tt t  o  \"\n",
      "batch 22456  loss=168.7676  steps/s=116.18  prediction: \"ike a power law? https://t.co/dMp2BtnE5R\" => \"neio ii    oe e  l      ?    t///////po/\"\n",
      "batch 22457  loss=186.6975  steps/s=107.53  prediction: \" wtf is a monoidal field\n",
      "\n",
      "i want to know\" => \"thokakrarae awr  a  a o//attotdpdattEdd \"\n",
      "batch 22458  loss=168.9384  steps/s=114.19  prediction: \"n=1)\n",
      "2 their goals are their vidya (n=2)\" => \"gthei 1   nin rnee er    arr  aree rrr a\"\n",
      "batch 22459  loss=159.5845  steps/s=113.07  prediction: \" rivals\n",
      "\n",
      "but idk, i dont know the theory\" => \"tet oi  dooo   i o  d   dd d    i t io o\"\n",
      "batch 22460  loss=172.4001  steps/s=107.07  prediction: \"@MentavaInc Ill keep this in mind, ty ty\" => \"lyMtic_tie   nenI III        t    i  t  \"\n",
      "batch 22461  loss=155.7064  steps/s=116.26  prediction: \"add an axiom like \"a set cannot containâ€¦\" => \"n  na erlnt  ed d e a  i   aaa a   annoa\"\n",
      "batch 22462  loss=159.9037  steps/s=113.39  prediction: \"s with analogies https://t.co/lJzQjjdUCR\" => \" ih  ea  na  a ai  i ttttias  ttsts/t/sJ\"\n",
      "batch 22463  loss=165.4949  steps/s=106.98  prediction: \"ore descriptive titles for the rest lool\" => \" kre  eeenee   rieiiii iiee i t re e  et\"\n",
      "batch 22464  loss=158.0869  steps/s=112.15  prediction: \" seen in a while\n",
      "https://t.co/TWiRoMqfMz\" => \"teo ems Ist      eee  ee   h t//et//itW/\"\n",
      "batch 22465  loss=158.2372  steps/s=111.99  prediction: \"lions of random steps beforesetting ep=0\" => \"ykee wn i li  i  l  om  s ss oo ese et t\"\n",
      "batch 22468  loss=152.4906  steps/s=114.91  prediction: \"o make a comeback. would be great to see\" => \"nto   tsoe        e  a o              e \"\n",
      "batch 22469  loss=173.2020  steps/s=110.61  prediction: \"pl\n",
      "\n",
      "those who know base 4\n",
      "Those who dont\" => \"ly:i os nfepl \n",
      "e@1@,,T,M4M4,Twy4,T144TT4\"\n",
      "batch 22470  loss=176.4638  steps/s=107.79  prediction: \"minglunatic @kuberdenis im also catholic\" => \"elei otsese M n dw@,,@,@4TTdTwy4yTb4f.fp\"\n",
      "batch 22471  loss=218.5710  steps/s=111.94  prediction: \"AL SIGNAL SIGNAL https://t.co/RSwiem8aPe\" => \"P  LLGNGGSSLNALLGALGNAL  L  t s t/t//S//\"\n",
      "batch 22472  loss=175.2809  steps/s=113.85  prediction: \" wonder what else you could fast-preview\" => \"tana  asiadi     ee  ee     o  eo   uue \"\n",
      "batch 22473  loss=161.1112  steps/s=115.45  prediction: \"stion, why do they cluster where they do\" => \" e r  guo to  o  to   ty      e eh ree  \"\n",
      "batch 22474  loss=187.1569  steps/s=22.65  prediction: \"eply: @Brycicle77 &gt; If you are\n",
      "im not\" => \" ly: @ouo  o  n  to   ty      e eh reee \"\n",
      "batch 22475  loss=150.7048  steps/s=119.75  prediction: \"rotator\n",
      "these patterns are pretty useful\" => \"emlnsn eoen a o bIvwm(,Iv\n",
      "rqkqw,b\n",
      "wqwwb\n",
      "\"\n",
      "batch 22476  loss=153.1059  steps/s=108.21  prediction: \"unny for your runway\n",
      "\n",
      "Idk just a thought\" => \"sd ree  m nn  errr uyrrr ny  \n",
      "uu   u\n",
      "uu \"\n",
      "batch 22479  loss=186.0445  steps/s=20.71  prediction: \"eply: @Laz4rz probability theorists btfo\" => \" ly: @te ayn  y rr uyrry nu  \n",
      "uu   u uu \"\n",
      "batch 22480  loss=158.3374  steps/s=108.70  prediction: \"ol shit way more than alcohol and gaming\" => \" i i d iod               o oa hoo a aao \"\n",
      "batch 22481  loss=168.2247  steps/s=110.38  prediction: \"nce\n",
      "\n",
      "5 depends on not missing ANY of 1-4\" => \"de(ot     n   tn  nn n n  nnnnnn n      \"\n",
      "batch 22483  loss=146.6498  steps/s=96.09  prediction: \" the atmosphere, such a great experience\" => \"the t eot e    e e eeee  h e     e ee ee\"\n",
      "batch 22484  loss=155.9462  steps/s=102.87  prediction: \"fundamentals is a smart smart smart move\" => \" nne i t  ore  nyIv)kbkvlyb(gkmf))b)(b(b\"\n",
      "batch 22485  loss=171.9171  steps/s=102.88  prediction: \"rk\n",
      "super surprised to find this on my TL\" => \"e bemer m wes neXpCThXAATTACTkCTubk\n",
      "mAwT\"\n",
      "batch 22486  loss=169.6036  steps/s=22.43  prediction: \"ply: @sunsettler https://t.co/gCxzVkTiTl\" => \"ly: amens nes  erpbThXAATTACTkCTubk\n",
      "mTwT\"\n",
      "batch 22487  loss=162.5778  steps/s=102.43  prediction: \"rings out there that would just ruin ppl\" => \"enbe a l iis   thpd'110:b.bv/k/xbxjjjhkðŸ›‘\"\n",
      "batch 22488  loss=142.5397  steps/s=87.59  prediction: \" of the tier lists of all time, for sure\" => \"tn  ie io     ne ee t    l lll     i    \"\n",
      "batch 22489  loss=154.5398  steps/s=102.53  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"  ntont  tt fff nin ioi   oiioro roorr r\"\n",
      "batch 22490  loss=209.4509  steps/s=113.15  prediction: \"RAFT clone?????? https://t.co/LpT9VeD8p0\" => \"L . aa n ll la  ??? o?? ????  toop///tt9\"\n",
      "batch 22491  loss=165.9176  steps/s=111.58  prediction: \" was pretty fun. https://t.co/feOXQYys44\" => \"tan tien e a   et t tt  tt t..//.tt/////\"\n",
      "batch 22492  loss=149.4730  steps/s=112.55  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \"nsi ini t t t   t t  t      e    ee  ee \"\n",
      "batch 22493  loss=179.1908  steps/s=105.85  prediction: \"y based. how do you compile zig to wasm?\" => \" do in  tet   dsd..  do e   e    ee ee  \"\n",
      "batch 22494  loss=162.6357  steps/s=116.42  prediction: \" but vanilla obsidian seems very mid imo\" => \"tedewev ree r eeu vua e ub balalaa ill i\"\n",
      "batch 22495  loss=163.8494  steps/s=116.16  prediction: \"discovering new unseen fundamentals, too\" => \" n one   g cdiid n eee nneeeeunnnne nnen\"\n",
      "batch 22496  loss=168.5795  steps/s=116.52  prediction: \"w, weve been going for a few weeks or so\" => \"e  o i titrsaKln,w,...vb,bcgv,dbmvc,bTâ˜ f\"\n",
      "batch 22498  loss=185.9548  steps/s=58.08  prediction: \": @IterIntellectus here have another one\" => \" @Taeri  er n/i ,w,vu.vb,bcgv,dkmvc,bT/f\"\n",
      "batch 22499  loss=163.0939  steps/s=126.73  prediction: \"ree simple moves to DESTROY any opponent\" => \"epla rou sarn$  h1fDuá´‡bbObwg.,vDESTRODES\"\n",
      "batch 22500  loss=163.7339  steps/s=115.65  prediction: \"s it and im unaware (would love to know)\" => \" aoust  t h      a  aia a a  u u o al   \"\n",
      "batch 22501  loss=155.3943  steps/s=99.19  prediction: \"p infested regions of their latent space\" => \"lo   oeochinmknty]yfuÊŸcfðŸŽ‰smyguQcpâ™‚á´„mfcð—±Éª\"\n",
      "batch 22502  loss=176.8074  steps/s=102.94  prediction: \"sted this first)\n",
      "https://t.co/7AHwatHv6Y\" => \" ro   os to  hh sss ttiist tstt//tt///HH\"\n",
      "batch 22503  loss=196.3465  steps/s=31.79  prediction: \"ply: @thevalidcode as \n",
      "per\n",
      "my last\n",
      "email\" => \"ly: inee e an(em(kw()wh:/bb:cW(7AHi7AH)6\"\n",
      "batch 22504  loss=167.7166  steps/s=112.38  prediction: \"ooks like from someone elses perspective\" => \"ukh wet  te   le   o   ooe  oee s seseee\"\n",
      "batch 22506  loss=166.6308  steps/s=113.69  prediction: \"is new wave of RL stuff im seeing lately\" => \"n ar  oen  tt t  e   w    f         e   \"\n",
      "batch 22507  loss=165.7973  steps/s=104.85  prediction: \"n getting rid of the phone really is key\" => \"gbeeua   g   tti g  gt  e  e  h e       \"\n",
      "batch 22508  loss=192.8368  steps/s=12.50  prediction: \"reply: @zestular https://t.co/tCxMmjViHQ\" => \"eply: ts s i yn wbckI,g,,bczg,yvbropybQe\"\n",
      "batch 22510  loss=170.8261  steps/s=129.37  prediction: \"unctional adults that they interact with\" => \"sd ien n idn u  u s n tatdat ntan thte a\"\n",
      "batch 22511  loss=185.8472  steps/s=88.33  prediction: \"rew4rd Great phrase, will use this ty ty\" => \"eply  @ e  rtco Gcmycmg,ca,c,hwyabmpfuke\"\n",
      "batch 22512  loss=161.0972  steps/s=112.44  prediction: \"ably do this for all future projects tbh\" => \"nlyels n od bob b o  o   l   rrl  l r  r\"\n",
      "batch 22513  loss=170.0005  steps/s=100.59  prediction: \" this long lost treasure of a song, damn\" => \"the  rer  mnininno     tt  tetre o     s\"\n",
      "batch 22514  loss=162.4181  steps/s=102.78  prediction: \"about things that have significant value\" => \"noy\"\n",
      " oonk tttet taaa t tats sisi tiaa a\"\n",
      "batch 22515  loss=185.5563  steps/s=97.02  prediction: \"me stuff DONE ðŸ«¡\n",
      "\n",
      "https://t.co/svmf1V2brD\" => \"e.ee  eeaaeoCADONEfðŸ«¡DOONDðŸ«¡ðŸ«¡EIðŸ«¡rpD::/d:E1\"\n",
      "batch 22516  loss=201.3038  steps/s=72.40  prediction: \"x140201 @teodor_io start with the Gospel\" => \"p6  \n",
      "trffe 0tO  \n",
      "\n",
      "\n",
      "ottt_/tt/t ///ththVtG\"\n",
      "batch 22517  loss=195.5076  steps/s=25.80  prediction: \"reply: @daltonc its a form of rumination\" => \"eply: @a nrE0ðŸ«¡hnN@f_D:_E_ON:/Av.c1V2b.G1\"\n",
      "batch 22518  loss=150.6051  steps/s=126.53  prediction: \"better tools\n",
      "is a positive feedback loop\" => \"e tt  bettt b  tt    t  tiii ii eee e   \"\n",
      "batch 22519  loss=169.9689  steps/s=112.16  prediction: \" they synergize\n",
      "\n",
      "https://t.co/Hz8BAjnXt0\" => \"toet D    h  Dne         ett e/e/zz/tzzz\"\n",
      "batch 22520  loss=155.8279  steps/s=99.15  prediction: \"calization does this too, and I suspectâ€¦\" => \"ant ut ttel\n",
      " \n",
      " gV9z,zvzb5v)\n",
      "4pvy,{zv.vIk\"\n",
      "batch 22521  loss=165.5347  steps/s=111.30  prediction: \"you really need to make your own company\" => \" u autnia waae l a e  eee eo    e  o   e\"\n",
      "batch 22522  loss=178.7173  steps/s=59.18  prediction: \": @teodor_io funny number go up type shi\" => \" @lunmin Bdl _nnP\"mhwvT,k,,w\"IkIIypuck,w\"\n",
      "batch 22523  loss=175.9074  steps/s=130.32  prediction: \"vinwylde the r in rgb stood for retarded\" => \"en Heae wheieit n  n t e r o  o  r ro ro\"\n",
      "batch 22524  loss=191.8940  steps/s=82.40  prediction: \"x140201 @teodor_io start with the Gospel\" => \"p4 iejewwhn0e@e @r o   _ o oo r  t roed \"\n",
      "batch 22525  loss=164.9156  steps/s=107.41  prediction: \"having kids, etc) may be only palliative\" => \"en   aaa      hii   i      a      y    l\"\n",
      "batch 22526  loss=155.8349  steps/s=116.29  prediction: \"e readme was a good read on ai reasoning\" => \" ru s   ah    ae e e eea  aaa a  oa   ao\"\n",
      "batch 22528  loss=157.6956  steps/s=111.63  prediction: \"e 25th\n",
      "\n",
      "or should i make a  : D gc?? hmm\" => \" re  ei teth 5ntoh    h                 \"\n",
      "batch 22529  loss=163.2590  steps/s=111.85  prediction: \"it and got it and MAAAN did it feel GOOD\" => \"n  t ia  h d  tt id d d AAAA d dit t d d\"\n",
      "batch 22530  loss=153.7007  steps/s=98.42  prediction: \"ressures me to say things I dont believe\" => \"eplsoee dejoi.phwvá´pQá´‡gvljIwj.bjyjpá´€jjbu\"\n",
      "batch 22531  loss=157.3859  steps/s=110.20  prediction: \"rger abstractions which eventually haveâ€¦\" => \"eeaifni iinn m  b.jj.w4gmFjXbj\n",
      "jFvFvjjâ€¦j\"\n",
      "batch 22532  loss=195.8439  steps/s=56.92  prediction: \": @0x77er some likes are worth 100 likes\" => \" @yufbi  ien mb mwjj.wvgmyjubj\n",
      "juv01j0â€¦ðŸ›‘\"\n",
      "batch 22533  loss=158.7824  steps/s=116.40  prediction: \"d building things with skills new to you\" => \" ao    n  in iniingiin  iiiii iii   s  s\"\n",
      "batch 22535  loss=183.7789  steps/s=103.95  prediction: \"ch @btwphones Awesome awesome\n",
      "LES GET IT\" => \"ooand  aa de _aebv@pAcpmpmArkAbALELdLESm\"\n",
      "batch 22536  loss=163.7427  steps/s=112.08  prediction: \"t 200hrs in around the same time you did\" => \" fe    onnt   t ri    to i  a t t  o e m\"\n",
      "batch 22538  loss=166.4610  steps/s=106.56  prediction: \" as the old boss\n",
      "https://t.co/m0RBda6RqC\" => \"tms  e ss ee s      ss  oosss/t//ss////R\"\n",
      "batch 22539  loss=182.1787  steps/s=92.34  prediction: \"ach_ @pixqc that's smart. will try this.\" => \"nt mhe te a   so s  hst/st's.stt.t.6tqCC\"\n",
      "batch 22540  loss=153.1728  steps/s=109.99  prediction: \"got the bit order backwards or something\" => \" n  se atn e we \n",
      "'pmpkpI'kd.I/pSIbk0kfpI\"\n",
      "batch 22541  loss=161.5286  steps/s=96.13  prediction: \"ee time lately\n",
      "\n",
      "it has a long ways to go\" => \" n o h aer e  a eee tet eae aa  lal l o \"\n",
      "batch 22542  loss=183.4086  steps/s=107.99  prediction: \"reward functions\n",
      "https://t.co/KAmykVYFyw\" => \"epl   @a dinew evtvmuMcMck:y\n",
      "Kfbf::/:..V\"\n",
      "batch 22543  loss=168.4756  steps/s=110.02  prediction: \"no effing reason https://t.co/HJrNuCKtjY\" => \"gt emort ferf nf efs f  es ent /to////JJ\"\n",
      "batch 22544  loss=155.9752  steps/s=109.34  prediction: \"velsio's\n",
      "\n",
      "just gotta keep building, bros\" => \"e glas   ee lssssss ss    e   tt  eeee  \"\n",
      "batch 22545  loss=157.7729  steps/s=97.81  prediction: \"m parts of your brain will want to do it\" => \"eae    fahoi - gvmI,q,'-(-vmv(u-/-).)-y-\"\n",
      "batch 22546  loss=174.2204  steps/s=78.72  prediction: \"hniacus specialized chips are the future\" => \"eos  rts  r st s  r  i  rrr  arw  o to t\"\n",
      "batch 22547  loss=158.1782  steps/s=99.81  prediction: \" in Christianity\n",
      "\n",
      "This made me Christian\" => \"ts tiiit iciiieiniinninniinii iiie ii  i\"\n",
      "batch 22548  loss=168.6116  steps/s=97.16  prediction: \"ased. Me neither. This is the way to go.\" => \"n  on_i td  ie en.e.. .iie is  h   hi  t\"\n",
      "batch 22549  loss=174.7013  steps/s=103.99  prediction: \"an esopost to english translator service\" => \"nd . ee  ese et ee e ni sn thst t  tr os\"\n",
      "batch 22550  loss=177.3125  steps/s=98.66  prediction: \"/t.co/YpddagC5uf https://t.co/GdftPhw7eI\" => \"/.c :30 : tt.pt//tt55ht5ttpC//pp.c/tdGtt\"\n",
      "batch 22551  loss=158.4393  steps/s=107.60  prediction: \"ther w loops or propogating at C. Wouldâ€¦\" => \" eneu titutetr t  r  r o oroo opooo o go\"\n",
      "batch 22552  loss=173.5270  steps/s=71.72  prediction: \"lamapuckey bang. https://t.co/YsmeYwFyJa\" => \"yr   teec t  o  r or rotpopoo o. ooot  o\"\n",
      "batch 22553  loss=161.2029  steps/s=111.76  prediction: \" job stuff, and Tsunami scripts came inâ€¦\" => \"tut i  do   d  d               sa      a\"\n",
      "batch 22554  loss=151.6376  steps/s=93.92  prediction: \" figuring it out. it just clicked for me\" => \"tor n f  ft  it iii  it itt  it   t  t  \"\n",
      "batch 22556  loss=144.2371  steps/s=106.74  prediction: \"on your end, try a different browser idk\" => \"n fheghbie    e               r  r rr rr\"\n",
      "batch 22557  loss=168.3855  steps/s=111.89  prediction: \"dnt learn just from reading the paper ðŸ‘ŒðŸ‘Œ\" => \" tne une fe u u   tu   rr   rt    r  e  \"\n",
      "batch 22558  loss=144.3661  steps/s=89.08  prediction: \"oo much context switching to twitter idk\" => \"nk oeeeto  o  otoo  tt  tttttt ttttttt t\"\n",
      "batch 22559  loss=162.5214  steps/s=115.19  prediction: \"insanely OP\n",
      "One idea is to build usefulâ€¦\" => \"ngsee ees inlnnsnnOOnOO   e e     ie i  \"\n",
      "batch 22560  loss=144.2744  steps/s=116.73  prediction: \"ed, excited to see how it goes for you ðŸ«¡\" => \"  ead ene  eedbeeee eeeee   ee e  oo  oo\"\n",
      "batch 22562  loss=147.2998  steps/s=109.03  prediction: \" random people you dont really know well\" => \"tem    oinn   io  o  oo ooo o oo   oll  \"\n",
      "batch 22563  loss=165.1146  steps/s=60.36  prediction: \"@levelsio @yacineMTB dang stole my reply\" => \"ludyie nno  n nn  oo e  ooo   olll e l  \"\n",
      "batch 22564  loss=186.6929  steps/s=115.12  prediction: \"o/8s7B0THB9l bro no half completed stuff\" => \"nBeasassahe////sBBBB9oo ooo  o  o  o   o\"\n",
      "batch 22565  loss=143.8233  steps/s=99.28  prediction: \"e distance fromâ€¦ https://t.co/7UBvLKTbzK\" => \" sh  enge s   e         ttt ttttttt/////\"\n",
      "batch 22566  loss=145.5559  steps/s=101.51  prediction: \" bigger\n",
      "#indiehackers #SaaS #engineering\" => \"tuodoni ggggi igiiiiii########e##SSSeeee\"\n",
      "batch 22567  loss=146.8680  steps/s=108.71  prediction: \"ight any pros youd get in the short term\" => \"nh ee leth n   y                 t    t \"\n",
      "batch 22568  loss=135.9537  steps/s=109.35  prediction: \"e\n",
      "graphics programming is so awesome man\" => \" hs eeegi p   i p rprrrrmrmmmgi m m  mo \"\n",
      "batch 22569  loss=146.6450  steps/s=100.19  prediction: \"e context, like words, strengthen ideas?\" => \" so e     t eo t  e e      , e  eteeeeee\"\n",
      "batch 22570  loss=138.0274  steps/s=104.83  prediction: \"system is non being at the limit of time\" => \"  o  yan sfs s ssn n   n  n   i i   i  i\"\n",
      "batch 22571  loss=143.8610  steps/s=91.28  prediction: \"o actually understand the program better\" => \"na o sn e a      aaaaa  a ttt   t   r rt\"\n",
      "batch 22572  loss=142.3923  steps/s=111.35  prediction: \"ow is that i know nothing\n",
      "- some guy idk\" => \"na  lt el a a        t t  t n  n n  n n \"\n",
      "batch 22573  loss=149.2589  steps/s=109.39  prediction: \"e that's typical https://t.co/6ztEEOl2Jy\" => \" taem   mh t  t s t tttttt tttttt/t//t//\"\n",
      "batch 22574  loss=159.1002  steps/s=107.50  prediction: \"uth is the global maxima strat long term\" => \"t  tt tih sttthth  t     aa  aaalaaaataa\"\n",
      "batch 22575  loss=136.6165  steps/s=107.08  prediction: \"ck and forth as much as possible I think\" => \"o i e yim      n        a           s s \"\n",
      "batch 22576  loss=140.9621  steps/s=104.87  prediction: \" does blade+motor=tablesaw or battlebot?\" => \"tenrereer  teee  ee+ooooetoaeoeoaaaboabb\"\n",
      "batch 22578  loss=146.4073  steps/s=91.97  prediction: \"verything app\n",
      "may take like a decade tho\" => \"e yleenl tnt eht e  y a a     a    a    \"\n",
      "batch 22579  loss=140.9997  steps/s=103.37  prediction: \"it got like 2x fps rendering ocean waves\" => \"ns  w w  o    i            e  e e  eeeee\"\n",
      "batch 22580  loss=200.3463  steps/s=82.09  prediction: \"ypt0x_0 just two\n",
      "https://t.co/dwD1M5Vl3g\" => \" e  ao io  0x e t   et eert   e/nn  neee\"\n",
      "batch 22581  loss=158.1866  steps/s=102.30  prediction: \"u actually did the work so youre chillin\" => \"twaittcty yaata  a            o   o    o\"\n",
      "batch 22582  loss=164.4878  steps/s=82.49  prediction: \"grammer extra respectfully:\n",
      "\n",
      "skill issue\" => \" o e   cwr  rrrr rr rrrr err eelllllllll\"\n",
      "batch 22583  loss=147.0974  steps/s=102.62  prediction: \"arning goes deep\n",
      "https://t.co/5gxT7SWDZu\" => \"nn e  e boar e e eeeee e eee ttete////tt\"\n",
      "batch 22584  loss=164.7987  steps/s=105.53  prediction: \" aka a blocktard https://t.co/19XRE918ej\" => \"tstnnagaoaha a   k ttpp//ttt::////p:/9/9\"\n",
      "batch 22585  loss=163.8482  steps/s=82.94  prediction: \"ples for Tsunami\n",
      "https://t.co/9Rp88uJPNT\" => \"ly: @ n nookl el    sssstt//t/////R/8888\"\n",
      "batch 22586  loss=156.7549  steps/s=83.47  prediction: \"ler \"twitch swims in the mariana trench\"\" => \"ya esesse ets r  stistsstttttt ttttpttta\"\n",
      "batch 22587  loss=140.1659  steps/s=99.97  prediction: \"ful for learning https://t.co/B7rPa9oFnr\" => \" nt   ia nnne   P3x575936k5:6Bkkkv8B7:PE\"\n",
      "batch 22588  loss=211.7208  steps/s=85.65  prediction: \"/t.co/SQHvZhhDZC https://t.co/BOo98KAChK\" => \"t.cer   //plf///ZhZZZhZZZh//ttBt//B/Bo//\"\n",
      "batch 22589  loss=185.9324  steps/s=58.24  prediction: \" @Brycicle77 are you a zombies kinda guy\" => \"typt efh// lS  nZhD hhtp h//t/Bt/to9ooKK\"\n",
      "batch 22590  loss=184.7846  steps/s=118.41  prediction: \"uZp\n",
      "\n",
      "see 'illustrative examples' section\" => \" e t:/ /t/soZZ \n",
      "isutuuutteieieelesesese \"\n",
      "batch 22591  loss=157.6843  steps/s=87.32  prediction: \"arpertony lichess? and what time control\" => \"re oe toeto@er elrrer e aa  as  s   a  t\"\n",
      "batch 22592  loss=170.4789  steps/s=96.85  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"/.ctI ehE  I\n",
      "///tW tWWW/WW  (  ( a.xx  .\"\n",
      "batch 22593  loss=151.5916  steps/s=104.98  prediction: \" inference than gpus\n",
      "\n",
      "but what do i know\" => \"ts e    eraine rnnnnen nnne e ee t    t \"\n",
      "batch 22594  loss=163.3197  steps/s=103.77  prediction: \"] [1,0] basis to new\n",
      "\n",
      "so theyre the same\" => \"`[ot@ rt n 0  1]0 1 0     s    so     te\"\n",
      "batch 22595  loss=181.1437  steps/s=21.46  prediction: \"eply: @mynamebedan head completely empty\" => \" ly: @0i 1m[[1 ,0   0s    s    so    tte\"\n",
      "batch 22596  loss=156.7673  steps/s=114.40  prediction: \"ing ctrl z and y\n",
      "https://t.co/empwLqmTzo\" => \"ng TB e dand  d         t t  ttt/t//////\"\n",
      "batch 22597  loss=163.5728  steps/s=101.30  prediction: \"ded techniques too, lmk if you know more\" => \" ngge  eenneeeIed eeeeeee      o  o    o\"\n",
      "batch 22598  loss=144.3491  steps/s=95.12  prediction: \"stion, why do they cluster where they do\" => \"   r  o uet  oo       yy      e   eheee \"\n",
      "batch 22599  loss=145.9010  steps/s=109.92  prediction: \" a while before I add it to the site tho\" => \"t ty  y le    ll      e e         t   t \"\n",
      "batch 22600  loss=186.2455  steps/s=43.10  prediction: \"ly: @justalexoki https://t.co/FpTBTJakMN\" => \"y: @y l  l     b  e   e           t   tt\"\n",
      "batch 22602  loss=175.1699  steps/s=116.03  prediction: \" @0xluffyb unfunded? then do it unfunded\" => \"tyua li  ebeeb b  edd d tt  o  t tt tttðŸ›‘\"\n",
      "batch 22603  loss=145.3385  steps/s=113.18  prediction: \"just point to concepts and arent reality\" => \"ust    i is   ot   oo  o t  tnn n  nnn t\"\n",
      "batch 22604  loss=157.3416  steps/s=114.61  prediction: \"/t.co/PAlC1foxCr https://t.co/nBdFZv8APN\" => \"/.ccrc sea /s:///tCCC/tCCCC//ttt:///..//\"\n",
      "batch 22605  loss=165.5450  steps/s=116.34  prediction: \"vars} complexity (O(f(n)) type stuff)\n",
      "-â€¦\" => \"elyaeaoaiher  e er e ( ((((((())))))) ))\"\n",
      "batch 22607  loss=144.5552  steps/s=116.47  prediction: \"d its helped man. i shpuld sleep too lol\" => \" ieh a   hd n nn                lplp    \"\n",
      "batch 22608  loss=181.4365  steps/s=71.01  prediction: \"@ludwigABAP ever thought of moving here?\" => \"jeliath i  dd    e          l l  eee  l \"\n",
      "batch 22609  loss=229.6413  steps/s=120.25  prediction: \"ONE\n",
      "FREEDOOOOOM\n",
      "\n",
      "https://t.co/MAxrYM3cut\" => \"U HUAANNKDDOOEOOEEOOOEOOO\n",
      "O t \n",
      " tM\n",
      "MMt/t\"\n",
      "batch 22610  loss=159.0394  steps/s=111.28  prediction: \"like a really really interesting project\" => \"yze lll  lee lelllelllaelllleeeee errere\"\n",
      "batch 22611  loss=160.4783  steps/s=111.95  prediction: \" joining man, looking forward to thurs!!\" => \"@ue  nteaenon on  nonoononnnooooo  oo  o\"\n",
      "batch 22612  loss=150.5948  steps/s=117.08  prediction: \"y with any industry/niche and ill run it\" => \" ne tein  iy in yyyyynnyynnnnnn  nnn n  \"\n",
      "batch 22613  loss=150.0529  steps/s=108.30  prediction: \"ple deep q network has achieved insanity\" => \"ly:w e ssesp ee e ee   e      h  h   iii\"\n",
      "batch 22614  loss=158.1803  steps/s=113.27  prediction: \"he making a dingboard clone or something\" => \"e pogAg  gg  i i g      ag       oo    o\"\n",
      "batch 22615  loss=168.5926  steps/s=76.53  prediction: \"helscom a new $500k logo should fix this\" => \"e p sni@gm    ii        ogo    o oo  oo \"\n",
      "batch 22616  loss=150.2149  steps/s=125.96  prediction: \"n og returns\n",
      "truly a legendary 5-9 today\" => \"gahe oo g  e  enne rrr  lln    r e    i \"\n",
      "batch 22617  loss=158.4619  steps/s=106.03  prediction: \" who build cool stuff get followers here\" => \"@htssepd  be d d ol   l     o  ff  ffll \"\n",
      "batch 22618  loss=165.5703  steps/s=115.06  prediction: \"/t.co/fzQa4ZPpET https://t.co/3KIrfnnFDf\" => \"thchr   tttit///tt444tptttp/t/t/////////\"\n",
      "batch 22619  loss=150.8109  steps/s=87.91  prediction: \"is such a great productivity improvement\" => \"n  a  atta                    t i ttiiii\"\n",
      "batch 22620  loss=143.9413  steps/s=84.80  prediction: \"credibly cool to see this project evolve\" => \"oialt7i cacd  ic     t    t  t t tee  te\"\n",
      "batch 22621  loss=174.4292  steps/s=64.20  prediction: \"@archived_videos https://t.co/4cNUTtDQAn\" => \"lrdwniri   d  c  ooo ttt  s  t c eeeevve\"\n",
      "batch 22622  loss=136.9958  steps/s=107.42  prediction: \"atterns so we should do (description ofâ€¦\" => \"n ah t s  s s    ss                 ooo \"\n",
      "batch 22623  loss=153.0013  steps/s=109.35  prediction: \"he pot of gold at the end of the rainbow\" => \"e k t tnepo tot   o      t          t   \"\n",
      "batch 22624  loss=143.6492  steps/s=106.76  prediction: \"to finding more\n",
      "\n",
      "improve your algorithms\" => \"  nto  rnet fffQiiiiioi oioiioro roorror\"\n",
      "batch 22625  loss=152.4386  steps/s=84.31  prediction: \"tas So far pretty useful\n",
      "Only read 4 tho\" => \" lntont n t   e r    r eeeuueuuluy ee   \"\n",
      "batch 22626  loss=169.0429  steps/s=106.84  prediction: \"/t.co/hjQfCWaZxw (banger on 1.25x speed)\" => \"t.cl  ehh  TT///th t/tt/tt  a  . axxx  .\"\n",
      "batch 22627  loss=158.9222  steps/s=105.47  prediction: \"Logit transform: https://t.co/MtjBY3y5n5\" => \" aoo w   n  ttoo     tt  t:t::::/:t/tt/t\"\n",
      "batch 22628  loss=143.1871  steps/s=103.26  prediction: \"f a nix rollback could fix their problem\" => \" 1m t  a nteWeee:/YYYYYYxYL.pLbMXjBY3X1X\"\n",
      "batch 22629  loss=153.4616  steps/s=109.82  prediction: \"aster i u know its just abt authenticity\" => \"n  t etttt  t tt  t    t   t    ttt ttt \"\n",
      "batch 22630  loss=164.7241  steps/s=43.65  prediction: \"ly: @justalexoki mj team probably grinds\" => \"y  @t nt rt   i   t    t   t    tt  ttti\"\n",
      "batch 22631  loss=162.0228  steps/s=110.97  prediction: \"ed in joining, repeat these instructions\" => \"  e  @etneneeeieinnie enee    eneteettet\"\n",
      "batch 22632  loss=178.2282  steps/s=87.37  prediction: \"one a bit longer https://t.co/FW0ba56vWt\" => \"u th aeteiininn   et    tee  netsertttss\"\n",
      "batch 22633  loss=142.5207  steps/s=99.54  prediction: \" sets? that sounds right but im not sure\" => \"teooe saos tttttts tssss stt    tt     t\"\n",
      "batch 22634  loss=153.9480  steps/s=106.04  prediction: \" developing a SPECIFIC understanding ofâ€¦\" => \"tun  ed  de  eoe     e  CCC CCCICIIn  nn\"\n",
      "batch 22635  loss=159.3419  steps/s=103.26  prediction: \"ly easy actually https://t.co/H2M3XYMGwC\" => \"y: o e lt e aaa aaal a lllttltt  tt/////\"\n",
      "batch 22636  loss=155.7733  steps/s=99.18  prediction: \"w i remember :)\n",
      "\n",
      "https://t.co/DWORUuCOBl\" => \"htne s   etete \n",
      "  e  e\n",
      "\n",
      "eee\n",
      "\n",
      "::tt::///tt\"\n",
      "batch 22637  loss=148.5911  steps/s=108.86  prediction: \"me ;) later bros https://t.co/fRfASkQYqP\" => \"anea ger   b  t          ttt tt/tt//////\"\n",
      "batch 22638  loss=152.1433  steps/s=94.60  prediction: \"artnership sucks https://t.co/BfrMTM0WDO\" => \"nd thet prtarreerrssppssssttssss//tt////\"\n",
      "batch 22640  loss=140.8605  steps/s=109.94  prediction: \"nd an area of pi https://t.co/JBM4t62fUZ\" => \"g  h ae   an aan a    a          //tt///\"\n",
      "batch 22641  loss=153.6940  steps/s=98.04  prediction: \"lf of that was way off. all good tho nbd\" => \"y o  m e  a   t          fff            \"\n",
      "batch 22642  loss=149.8144  steps/s=110.83  prediction: \"like there's more of a person there, idk\" => \"ykei  e estlleleee   ee e e       e   re\"\n",
      "batch 22643  loss=141.9329  steps/s=109.80  prediction: \"resent them in (i.e. \"jimmy shot a ballâ€¦\" => \"epln a@ai ogn ayYY@'\"YY(vYYYY\"jXX*****â€¦U\"\n",
      "batch 22644  loss=177.6742  steps/s=101.22  prediction: \"er CERN/physics bros you know what to do\" => \" stp otseeette    iis    is    o        \"\n",
      "batch 22645  loss=137.3979  steps/s=113.25  prediction: \"but for now ill run whatever ppl ask for\" => \"et   n t       n                        \"\n",
      "batch 22646  loss=144.8492  steps/s=107.69  prediction: \"st flows through. dunno but good thought\" => \" an nso w  wss         uuuuuuuooo o  ooo\"\n",
      "batch 22647  loss=172.9966  steps/s=110.23  prediction: \" cool\n",
      "\n",
      "ez follow\n",
      "https://t.co/F6AUVWpskt\" => \"toni is  soo  oooooooooo\n",
      "\n",
      "\n",
      "tttttttttt///\"\n",
      "batch 22648  loss=142.1164  steps/s=100.73  prediction: \"igh quality outputs with infinite tokens\" => \"nhno  ndr  duu  uu uu  uuttitttiitititii\"\n",
      "batch 22649  loss=183.0285  steps/s=107.77  prediction: \"would show this: https://t.co/WGynENtvIQ\" => \"ond/ttulne woo   oww sht ssh tt/:/ttts//\"\n",
      "batch 22650  loss=168.9243  steps/s=94.27  prediction: \"y_codes i gotchu\n",
      "https://t.co/INKeGUxuff\" => \":arnbr wswooosht ho tht/h:://t:///NNoIIG\"\n",
      "batch 22651  loss=157.2924  steps/s=106.20  prediction: \"nds like a super cool premise for a game\" => \"d \n",
      "thrnednnn  s   u    p p ooppoo  ooo  \"\n",
      "batch 22653  loss=146.4559  steps/s=106.26  prediction: \"this. or you can win by trading seats wâ€¦\" => \"hen utcan nnn n                         \"\n",
      "batch 22654  loss=160.0647  steps/s=102.62  prediction: \"ge w git commits\n",
      "https://t.co/aMMtiAGLQh\" => \" tm i c sot      tt ttt ttttttttttsttttt\"\n",
      "batch 22655  loss=148.3354  steps/s=110.99  prediction: \"I figure if we just do it, ppl will join\" => \" ghldbi bl uiii                         \"\n",
      "batch 22656  loss=183.0986  steps/s=104.09  prediction: \"Ts GOOOOOOOOOOO\n",
      "\n",
      "https://t.co/2Np3fEI715\" => \"B I dOd  m\n",
      "dOOOOOOOOOOO\n",
      "\n",
      "\n",
      "\n",
      "GsOO \n",
      "/stt/tt\"\n",
      "batch 22657  loss=188.7320  steps/s=103.64  prediction: \"n @juweerubyjane https://t.co/9aZomtRmaO\" => \"gt  dim  u\n",
      "e  esje es ettst:/t//t//t//tZ\"\n",
      "batch 22658  loss=148.1149  steps/s=105.40  prediction: \"oo much context switching to twitter idk\" => \" lMeaeeue  o    ot ttttttttttttttttttt t\"\n",
      "batch 22659  loss=145.8650  steps/s=109.85  prediction: \"acticing recalling\n",
      "What happens is theyâ€¦\" => \"ntr t e   f f iciiicicciaiagiaapnaaaaaah\"\n",
      "batch 22660  loss=182.1464  steps/s=110.68  prediction: \"feditor.mp3\" type=\"application/json\"&gt;\" => \" ed  re   o;a   ;O.Wl3=\".Wp3=kjOO.=O3O.â€¦\"\n",
      "batch 22661  loss=199.3261  steps/s=12.28  prediction: \"reply: @0xluffyb https://t.co/Qs8R6GnjEa\" => \"eply: @dt o;a   ;O.Wl3=\".Wp3=kjOR.=&jO.â€¦\"\n",
      "batch 22662  loss=178.1982  steps/s=146.64  prediction: \" only $10.76 btw\n",
      "https://t.co/Ted2IYelrf\" => \"tf eec na  n     t   ttt ttttt/////t////\"\n",
      "batch 22663  loss=148.4967  steps/s=103.02  prediction: \" end of chess, just like everyone feared\" => \"@te at aae    s   ss ss  s    eeeeeeeeee\"\n",
      "batch 22665  loss=145.6462  steps/s=102.59  prediction: \" pool (at least once seems cold tho ngl)\" => \"trot of  ooo  ot   t    ee    e eeee e o\"\n",
      "batch 22666  loss=162.2812  steps/s=107.16  prediction: \"ur P(innovation)\n",
      "https://t.co/y1VfXBO4lC\" => \"s  i nnssess   ononnnnonntnntttttottttt/\"\n",
      "batch 22667  loss=141.0161  steps/s=112.62  prediction: \" on bookmarks from people similar to you\" => \"tf    beo   oo oooooooooo ooo  o     o  \"\n",
      "batch 22668  loss=166.5168  steps/s=111.61  prediction: \"rselves w builders i think\n",
      "\n",
      "and to build\" => \"etsy  oiaselvn  ;gO,,Ov)vOOIbI:P(jvv;E;1\"\n",
      "batch 22669  loss=130.7659  steps/s=93.69  prediction: \" just do what i tell them the first time\" => \"tus ot ts a   t  i    t  t t  t t  t te \"\n",
      "batch 22670  loss=144.0667  steps/s=108.14  prediction: \"cuda skills, so its a fun way to do both\" => \"onc  ai n e   ss   s  s   s             \"\n",
      "batch 22671  loss=174.6457  steps/s=65.03  prediction: \"xluffyb interest is a powerful thing man\" => \"tu e  aysy s    s ss  s                o\"\n",
      "batch 22672  loss=138.1276  steps/s=112.59  prediction: \"his is the same w similar things in life\" => \"eng t thi tihisssss       s    i i  ii  \"\n",
      "batch 22674  loss=145.9722  steps/s=107.92  prediction: \"the man stretches his mind and his limbs\" => \" i  n xth  l  ett  te  ss  s     in  ii \"\n",
      "batch 22675  loss=170.4871  steps/s=96.97  prediction: \"e got a logo now https://t.co/PPHmUNsJ4b\" => \" ano @nlon t tte    o   t     t s  iPP s\"\n",
      "batch 22676  loss=162.5759  steps/s=91.94  prediction: \"rthko I dont either man\n",
      "\n",
      "its numpy magic\" => \"eutisi bebmot d lIjxOO)O:OOO.I:/PkH\n",
      "UNvJ\"\n",
      "batch 22677  loss=154.0162  steps/s=101.88  prediction: \"per solid learning loop, love it love it\" => \"lrt:@  d o dd  l ee   nnnn n    oo   oo \"\n",
      "batch 22678  loss=137.3039  steps/s=106.14  prediction: \"learning is by doing stuff. For anything\" => \"ya  hntinn    b          i              \"\n",
      "batch 22679  loss=144.9146  steps/s=114.10  prediction: \" You can hide these with adblock i think\" => \"tos ses oesl ooo    e e     e  e e     h\"\n",
      "batch 22680  loss=201.3781  steps/s=110.32  prediction: \"1 AAAAAA MY EYES https://t.co/r2a6f3Rhs7\" => \"234Y c nteadQ4t01IEx0Sk/OMOvAIMS6,YES2:6\"\n",
      "batch 22681  loss=152.6815  steps/s=106.18  prediction: \"s the magic of doing things from scratch\" => \" go  w n c0M  t  a    t i  i  o tt os  r\"\n",
      "batch 22682  loss=143.4811  steps/s=96.16  prediction: \" adventure over the comfort of certainty\" => \"@teI sete eeeeeeeeee eeee oe  ooo oo r  \"\n",
      "batch 22683  loss=141.9876  steps/s=109.60  prediction: \"e rotators\n",
      "\n",
      "we color c, e, f, g the same\" => \" t o  ota  r oaoooooororoo oo  ,  , ,   \"\n",
      "batch 22684  loss=144.1855  steps/s=103.68  prediction: \"have become too big and are rotting away\" => \"ev  iesecise e mee                      \"\n",
      "batch 22685  loss=154.4939  steps/s=107.75  prediction: \" ðŸ¤” I need to work on my marketing skills\" => \"tNt at n ae                   o         \"\n",
      "batch 22686  loss=151.4540  steps/s=100.34  prediction: \"tony no but id be down rn for some games\" => \"  uly nnen nn t  o  o   o            o  \"\n",
      "batch 22687  loss=177.0505  steps/s=106.56  prediction: \"Incredibly based\n",
      "https://t.co/IOxblXKnJv\" => \"   er nr  nI  b bb dd b  d ttt  tttoo///\"\n",
      "batch 22688  loss=143.2246  steps/s=100.03  prediction: \" drag down/demotivate other team members\" => \"@or  a ded   dd  ddddddoooo  ettee eteem\"\n",
      "batch 22689  loss=173.6078  steps/s=70.76  prediction: \"rpertony @kuberdenis its 10 in base 1955\" => \"eel sn@raT]Q_t  NI@9S99910f9b10@y\n",
      "1095.:\"\n",
      "batch 22690  loss=150.6643  steps/s=103.67  prediction: \" improve a processing unit's ability toâ€¦\" => \"tn e rasircaa ar rpa  s      ssss i iiii\"\n",
      "batch 22691  loss=157.8433  steps/s=93.63  prediction: \"bly same, llms are so much faster though\" => \"uyi irem aaam amlm s lss    s s  s t itt\"\n",
      "batch 22692  loss=140.4182  steps/s=106.92  prediction: \"but openai is cringe so obviously sonnet\" => \"uii sa  nnla    a   i i  i  s ooso o ooo\"\n",
      "batch 22693  loss=149.6754  steps/s=94.08  prediction: \" runs the output https://t.co/D0dRtXhLQp\" => \"tet  t i at ttt uuttttttttttttttttttt///\"\n",
      "batch 22694  loss=150.1922  steps/s=89.32  prediction: \"ining data. The loss went down over time\" => \"ngte   ntn tndnnanaa a    e         n   \"\n",
      "batch 22696  loss=180.5827  steps/s=39.29  prediction: \"ly: @Campr_Dante https://t.co/Cin8Wc4sMW\" => \"y  @reneeg  anatataa a    t n    e  o e \"\n",
      "batch 22697  loss=160.5134  steps/s=128.04  prediction: \"workin on whips?\n",
      "https://t.co/MV03p530Vm\" => \"ork  agttr o   o  ?h?oh hhhhtthh/t/tt//V\"\n",
      "batch 22698  loss=188.4278  steps/s=21.76  prediction: \"eply: @newpantswhodis @pixqc and haskell\" => \" ly: @bh hoho  o???hhoh hhtt/toh///pt/VV\"\n",
      "batch 22699  loss=151.5180  steps/s=111.82  prediction: \" on life event stuff\n",
      "- made progress onâ€¦\" => \"tn prmeeprosr pe ee e  f  f fff  ee se s\"\n",
      "batch 22700  loss=155.8727  steps/s=109.03  prediction: \" off with a basic template and modify it\" => \"tn ttot  tf t  t  t    t a    eeaa a  d \"\n",
      "batch 22701  loss=143.9700  steps/s=110.79  prediction: \"dates/incentives to fund ai safety stuff\" => \"  i  antanaeeenaaneeeentenn nn  n   ts f\"\n",
      "batch 22702  loss=143.9780  steps/s=98.37  prediction: \"ding blocks that make it up, recursively\" => \" niliyil i l  l      t    t    t      u \"\n",
      "batch 22703  loss=141.1779  steps/s=99.12  prediction: \"u ship cool things and make ppl have fun\" => \"twene sepss                             \"\n",
      "batch 22704  loss=153.9720  steps/s=104.30  prediction: \"worried too man xD\n",
      "\n",
      "its goood to be back\" => \"ork  teae  wo  oo    o     ooo   o     o\"\n",
      "batch 22705  loss=176.1714  steps/s=80.53  prediction: \"gABAP @sebby_builds Yup\n",
      "Thoughts on why?\" => \" BA owt sw oo n  sbb i   \n",
      "ooooooooo    o\"\n",
      "batch 22706  loss=146.7337  steps/s=123.72  prediction: \"feels better than giving to the homeless\" => \"i  t r   ariwi gPf@v~^â€œf-/!Yfb!TYDw\n",
      "T,Dð˜\"\n",
      "batch 22707  loss=134.7403  steps/s=108.24  prediction: \"tput something as unexpected as possible\" => \" s  t no tot ttt     o      ee eeeeee  s\"\n",
      "batch 22708  loss=175.8917  steps/s=103.79  prediction: \"ere @jaivinwylde prime rgb lore revealed\" => \"   o tnSottee  si ii e  eeee  ee  sse  e\"\n",
      "batch 22709  loss=155.3633  steps/s=104.30  prediction: \"el editor and gameplay, that sounds cool\" => \" la a ethl     d     aa  aaa  aaa   a   \"\n",
      "batch 22710  loss=148.1808  steps/s=99.77  prediction: \" level to master\n",
      "https://t.co/ojDDbHwX6X\" => \"@etenof tmeee    eeeeeetertttt ttttto//D\"\n",
      "batch 22711  loss=163.6319  steps/s=96.34  prediction: \"h @tsoding Musializer looked pretty cool\" => \"ea   sen oss snnsssstis ioii o leoooooo \"\n",
      "batch 22712  loss=153.3323  steps/s=109.04  prediction: \"stone cpus in it https://t.co/UsFG7LjU6T\" => \" :n  r e enMn re   e        t t tt/t//U/\"\n",
      "batch 22713  loss=146.4213  steps/s=100.76  prediction: \"ng term\n",
      "\n",
      "Best signal to work on for sure\" => \"  foor    t    tttt e t      t       o o\"\n",
      "batch 22714  loss=147.3627  steps/s=108.07  prediction: \"be allocate some time to do fun projects\" => \"u i o   n     o                   o     \"\n",
      "batch 22715  loss=141.0505  steps/s=111.85  prediction: \" life you have to put in work to do this\" => \"tod  trntte   i   o e  e   o       o    \"\n",
      "batch 22716  loss=151.3731  steps/s=110.98  prediction: \"an easily try em\n",
      "https://t.co/XbnCKZYbBa\" => \"nd o ,   t      y   y   tttttttt////////\"\n",
      "batch 22717  loss=190.0250  steps/s=99.07  prediction: \"l chevron attack\n",
      "bh6 h4 h5\n",
      "kid destroyed\" => \"ytt  a s cc y ea  ttttt/ttht///h/ ZZbbbb\"\n",
      "batch 22718  loss=143.2727  steps/s=112.23  prediction: \"snt even intentionally trying to do that\" => \" t vt n nn /t en  nnntnnnnnnnntttn tt tt\"\n",
      "batch 22719  loss=151.2689  steps/s=114.43  prediction: \"nt do that\n",
      "now it doesnt do that\n",
      "\n",
      "repeat\" => \"  tu  e n  ot tt tt tt oot o tt tt ttttt\"\n",
      "batch 22720  loss=154.2570  steps/s=105.78  prediction: \"d 2) completed results, and thats IT. Iâ€¦\" => \" an f )oiono oaen  e el le     tet a tst\"\n",
      "batch 22721  loss=176.8473  steps/s=103.65  prediction: \"nthwave channel: https://t.co/0b7orVHqb3\" => \"g ry tedeearnnaeeneahnhe:::::ht::///tt//\"\n",
      "batch 22722  loss=146.4128  steps/s=102.51  prediction: \"lex code across multiple (simple!) Files\" => \"ym o no cm o o    c  o   ll   ll lll lll\"\n",
      "batch 22723  loss=130.5501  steps/s=108.05  prediction: \" local optima solution they got stuck in\" => \"tide etl htt t t  ttooooooooooooottttttt\"\n",
      "batch 22724  loss=146.0966  steps/s=83.49  prediction: \"elete post but it works on anyone's post\" => \" stet@ t etleettt  ttt  tt  o  o    oon \"\n",
      "batch 22725  loss=149.0855  steps/s=104.10  prediction: \"he case for some regions outside the US.\" => \"em  t  te    she s se e eee sossoos  eee\"\n",
      "batch 22726  loss=144.0976  steps/s=100.32  prediction: \"you really need to make your own company\" => \" u tet    ta ae    e  e    e            \"\n",
      "batch 22727  loss=159.4816  steps/s=103.99  prediction: \" people who find their work fun win more\" => \"tron   w ono      e   e  e       w  wnw \"\n",
      "batch 22728  loss=139.0214  steps/s=109.11  prediction: \"d work that into my current program haha\" => \" th   ooh      w               r rrrrrrr\"\n",
      "batch 22729  loss=147.0047  steps/s=100.89  prediction: \"rmations\n",
      "\n",
      "thats my understanding anyways\" => \"ea   n  DPog    &C@;v;C&CCC&SAb&6;;b;&&&\"\n",
      "batch 22730  loss=146.5487  steps/s=105.08  prediction: \"800km high view.\n",
      "https://t.co/bGCVZbuoNU\" => \"01k)n  s at           h ht ttt/////t////\"\n",
      "batch 22731  loss=157.4340  steps/s=111.15  prediction: \"ds are youll find another\n",
      "\n",
      "Never give up\" => \"    o doono  od  o d   o    oe  \n",
      "e\n",
      "e ee \"\n",
      "batch 22732  loss=159.7584  steps/s=107.76  prediction: \"igure out how to improve your work ethic\" => \"nAots ur se ouo oo  oo too   ooro oooor \"\n",
      "batch 22733  loss=149.7530  steps/s=90.83  prediction: \"in was really good\n",
      "\n",
      "goated artist indeed\" => \"n  etra  r a  aa     oa  oooogooooot\n",
      " tt\"\n",
      "batch 22734  loss=146.9427  steps/s=110.45  prediction: \"feels better than giving to the homeless\" => \" ect fo    t@  g|@É´pâ€ðŸ˜Žð—¶bá´›ÉªKðŸ˜¤á´˜b|'ykbð—±â€w')\"\n",
      "batch 22735  loss=155.9854  steps/s=110.87  prediction: \"ct\n",
      "\n",
      "also, interesting advice in the clip\" => \"oiae t beoloet rooteettintii iii  iii e \"\n",
      "batch 22736  loss=167.8612  steps/s=96.55  prediction: \"_malachi @AnthonyMachula @yacineMTB soon\" => \"py cf ilca\n",
      "ja cnntnnnttnincaaiii  e eiii\"\n",
      "batch 22737  loss=138.1933  steps/s=107.26  prediction: \"through hoops\n",
      "\n",
      "its harder, until its not\" => \" inveueah  oohhthohhhhhhhhh             \"\n",
      "batch 22738  loss=144.4485  steps/s=107.92  prediction: \"s a way of acting, btw)\n",
      "\n",
      "Ok this is allâ€¦\" => \" tr tn at  ( a a   a aa       t     t  i\"\n",
      "batch 22740  loss=147.5318  steps/s=102.68  prediction: \" about it and in 1 weekend jumped up 200\" => \"t dnsia  an a   a  a        ee  e   eeee\"\n",
      "batch 22741  loss=149.3065  steps/s=105.28  prediction: \"radient descent) https://t.co/35KY9s0MqK\" => \"ettnt e(e \n",
      "v eh wwyy/m/))k(z((::(9..Iq33\"\n",
      "batch 22742  loss=144.2821  steps/s=99.04  prediction: \"ventually succeed if I keep doing this,â€¦\" => \"e to n e ten  nneee e  e e eeeee        \"\n",
      "batch 22743  loss=175.1151  steps/s=114.65  prediction: \"ived did. Its pribably more fun that way\" => \"ne ov k  o i    i d    iib b bb         \"\n",
      "batch 22744  loss=178.1622  steps/s=98.12  prediction: \"row)\n",
      "\n",
      "deletes 10 lines backwards in nvim\" => \"ebin s  o o\n",
      "  F0(uk1100,I)jwv.)Ikk\"p10(I\"\n",
      "batch 22745  loss=156.2765  steps/s=35.86  prediction: \"ly: @gizmobly probably\n",
      "especially if bjj\" => \"y: @dFwi rrerr \n",
      "0000eee\n",
      "ee  ee ls  s  nn\"\n",
      "batch 22746  loss=179.0132  steps/s=49.20  prediction: \"eply: @ludwigsonneck Did you learn/grow?\" => \" ly: @wiroeeerrr000leeesee  la ls  s  nn\"\n",
      "batch 22747  loss=144.3404  steps/s=121.91  prediction: \" own instead of relying on school for it\" => \"af owng  nnoon n n       o  n    o  o oo\"\n",
      "batch 22748  loss=135.4645  steps/s=100.53  prediction: \"you into thinking hes an anime character\" => \" u  es tr o t n  i   iin n  n  nn nn  n \"\n",
      "batch 22749  loss=157.4036  steps/s=107.83  prediction: \"i bet CS2 lets you. idk abt valorant tho\" => \"nkooe e\n",
      " e\n",
      "\n",
      "  \n",
      "e   e    e               \"\n",
      "batch 22750  loss=168.0895  steps/s=108.68  prediction: \"zmobly poor lud gonna end up with hrgirl\" => \"eobGb @S2thPS@ sPj@..zk.kOMTpwbjgL/:ðŸŽ‰0(I\"\n",
      "batch 22751  loss=155.9695  steps/s=106.14  prediction: \"mann hypothesis\n",
      "\n",
      "https://t.co/JZNuVj47KX\" => \"akn  o  nhe th hhhtthhhhttttttttt/t/////\"\n",
      "batch 22752  loss=148.6071  steps/s=86.48  prediction: \" literally can\n",
      "not good for computer tho\" => \"titi an e te  llyllll\n",
      "t\n",
      "toooooooooo tooo\"\n",
      "batch 22753  loss=137.0818  steps/s=100.78  prediction: \"ive impact on me yrs after i had to stop\" => \"ne i   s  tsiii                         \"\n",
      "batch 22754  loss=157.0524  steps/s=101.52  prediction: \" right now its just learning on the side\" => \"tet r aot r   t t   t t t   i n  nnt    \"\n",
      "batch 22755  loss=142.4243  steps/s=86.67  prediction: \"ait to see what you cook up with giz inc\" => \"nn mtt    t    t  t t      uo  oo   i   \"\n",
      "batch 22756  loss=168.9320  steps/s=72.63  prediction: \"achaIchbiah Gm\n",
      "\n",
      "Thanks for the read man!\" => \"nc tat  b  t twa     o o o    o     i i \"\n",
      "batch 22757  loss=146.3389  steps/s=100.11  prediction: \"han automating friction out of your work\" => \"eteeon n netttt  ta  tttt i ti t ono ou \"\n",
      "batch 22758  loss=138.8081  steps/s=102.48  prediction: \"to save this for later in case I forget\"\" => \"  e te lio  s s                         \"\n",
      "batch 22759  loss=148.2382  steps/s=102.09  prediction: \"eed you on my side during the robot wars\" => \" d ogstbn\n",
      "ao  o  oon nn   n  n  e    o  \"\n",
      "batch 22760  loss=148.1706  steps/s=43.84  prediction: \"y: @yacineMTB its simple\n",
      "they move to ny\" => \": @aesonnn o  n  o   e    ne e  oo   o  \"\n",
      "batch 22761  loss=142.7457  steps/s=100.20  prediction: \"going into space man its truly beautiful\" => \" n  aid enn  ni   n                    t\"\n",
      "batch 22762  loss=194.5221  steps/s=22.22  prediction: \"eply: @notmoeezm https://t.co/QC3FvkVoGr\" => \" ly: @iim in ni   n                t   t\"\n",
      "batch 22763  loss=212.9181  steps/s=27.45  prediction: \"reply: @gizmobly https://t.co/3IsLgGqovS\" => \"epl : @aett\n",
      "er e==%=%%://=.%%/QC3FkqVPG=\"\n",
      "batch 22764  loss=144.9805  steps/s=114.11  prediction: \"nd an area of pi https://t.co/Vfa458mJ2r\" => \"g e tel nnnn  a                /////////\"\n",
      "batch 22765  loss=152.0959  steps/s=97.87  prediction: \" make work games\n",
      "https://t.co/WVxkHR6btx\" => \"tad  aan  a       k    a    a //////so//\"\n",
      "batch 22767  loss=152.3073  steps/s=111.59  prediction: \" hit ctrl+k in discord or shift + ? in x\" => \"tadpia  i  t tt  i iiii   ii       i    \"\n",
      "batch 22768  loss=137.1120  steps/s=102.97  prediction: \"o do it. I shouldn't feel any relief ofâ€¦\" => \" sonini i t       t                   ee\"\n",
      "batch 22769  loss=155.1435  steps/s=73.05  prediction: \"kaysh No I have to run the code manually\" => \"ero  ti t t o  I   o       n  eeee eeeel\"\n",
      "batch 22770  loss=151.1154  steps/s=100.94  prediction: \"ses to use them, only uses open src ones\" => \" dsssfsselluseeese   ee      e  see   s \"\n",
      "batch 22772  loss=147.5328  steps/s=109.35  prediction: \" loss (erroneously a vector) as a scalar\" => \"tot ehd  gg   neoooooo  ee              \"\n",
      "batch 22773  loss=169.1027  steps/s=96.83  prediction: \"/t.co/G1n1qlriEC https://t.co/adJ8KDD8mI\" => \"/.c ts   ///t///t111111ttq:t//tt.///t///\"\n",
      "batch 22774  loss=157.9457  steps/s=92.39  prediction: \"eaply making synthetic training data? :)\" => \" l   @en ng n   nn  hnnnn ntntin tiiii a\"\n",
      "batch 22775  loss=159.8001  steps/s=93.14  prediction: \"st??\n",
      "So far, yes https://t.co/8qbn7MZluz\" => \" : eprntet?Sf ? f  f rs  s  sttttt////t/\"\n",
      "batch 22776  loss=149.3848  steps/s=83.24  prediction: \"maaaaan\n",
      "that mitch guy seems interesting\" => \"erete i eaaaaataaatathtt t    ts  eeesse\"\n",
      "batch 22777  loss=159.0011  steps/s=96.43  prediction: \"you get used to it and overcome the fear\" => \":u an oat     tt t t t   tt  t      e e \"\n",
      "batch 22778  loss=171.8887  steps/s=79.29  prediction: \"ttler @yacineMTB https://t.co/x9bosQw3vl\" => \" ee  sa  ot gee  t t  tt   ttt o/ooee oo\"\n",
      "batch 22779  loss=160.6133  steps/s=115.16  prediction: \"abt reality/life\n",
      "https://t.co/h3inQcxhb2\" => \"nl t    fe     l t etttliittttttt//ttt//\"\n",
      "batch 22780  loss=178.3314  steps/s=117.48  prediction: \"load this prompt https://t.co/Ug4apoNeat\" => \"yt  o ok ao   o    tttttt ttppttttt/ttpt\"\n",
      "batch 22781  loss=150.7985  steps/s=113.19  prediction: \"ly beautiful\n",
      "Love seeing stuff like this\" => \"y:  Nntanana aneaeeleeeeeeeeeeeeeeeee e \"\n",
      "batch 22783  loss=149.3906  steps/s=105.67  prediction: \"BAP lud the goat herder back at it again\" => \"AP @ neaiA uA t eee eee  eeee    e   ii \"\n",
      "batch 22784  loss=151.0779  steps/s=113.91  prediction: \"ready having better days from this stuff\" => \"epl :gidectSv n PbDS00TmAv2TNGPA:KIvk330\"\n",
      "batch 22786  loss=170.4215  steps/s=93.40  prediction: \"mobly @amix011 May do this in the future\" => \"erk  ginidayy aea ie 1 y  d d    i  t tt\"\n",
      "batch 22787  loss=155.5599  steps/s=112.69  prediction: \"f you can read graphs youre already ngmi\" => \" yht mad ih0bei 0bPSM0T1vM2TpPPA:pIvk330\"\n",
      "batch 22788  loss=139.6479  steps/s=102.64  prediction: \"ything rewarding that follows from that)\" => \":iiaaeiegh ierrigrrrrrrg      t  r    o \"\n",
      "batch 22789  loss=150.0222  steps/s=98.74  prediction: \". so idk\n",
      "\n",
      "would like to hear suggestions\" => \" hi an etH\n",
      "\n",
      "we n0b@+-vf@(JIIx-,VbIIRp,+c\"\n",
      "batch 22791  loss=149.3879  steps/s=94.17  prediction: \"ions you choose, like oregon or whatever\" => \"nn ro nntooftooons oe   eoo ooo o o oeeo\"\n",
      "batch 22792  loss=142.7312  steps/s=97.37  prediction: \"ing ive wanted in life lol, complete 180\" => \"ng tve yent tvin n  i    i    l lll llll\"\n",
      "batch 22793  loss=149.5137  steps/s=96.00  prediction: \"on today\n",
      "LFG!!!!\n",
      "https://t.co/FW0ba55Y6V\" => \"   on n n  fnX Go!!!!!!!!!t\n",
      "ttttoF/tttt5\"\n",
      "batch 22794  loss=152.1461  steps/s=96.16  prediction: \"ls so satisfying https://t.co/mM5acJxydL\" => \"y  osaas sssass ss ssssttst////t//////t/\"\n",
      "batch 22795  loss=160.7957  steps/s=96.80  prediction: \"a, thats super coool!!!!! how did it go?\" => \"n  at  es t s s   s   oooo!!!!!!!!! o  o\"\n",
      "batch 22796  loss=154.3370  steps/s=97.29  prediction: \"cay principles, and it ended up formingâ€¦\" => \"ol fint in  n  nc   n     dd   d de   d \"\n",
      "batch 22797  loss=162.8961  steps/s=94.39  prediction: \"he thing, no? All you need is prediction\" => \"i   t to t ehnf t  o   ?    n ne        \"\n",
      "batch 22798  loss=178.6462  steps/s=27.55  prediction: \"ply: @cto_junior https://t.co/BLe9cxo4Bp\" => \"ly: @i eoeen  n o  o   e    n  ee       \"\n",
      "batch 22799  loss=148.4615  steps/s=99.30  prediction: \" pile of scrollable gem content on x\n",
      "\n",
      "xâ€¦\" => \"taiegat t iti etii o  o ool ole l o ee o\"\n",
      "batch 22800  loss=150.7738  steps/s=96.28  prediction: \"tll program all my ML experiments for me\" => \" en ten ed tn  ta  l   ll  ml lm mm     \"\n",
      "batch 22801  loss=155.4135  steps/s=94.09  prediction: \"procrastination\n",
      "\n",
      "I LIVE for that feeling\" => \"lod:n   nrr nr  riorr\n",
      "oi\n",
      "\n",
      "I\n",
      "IIooI o tt t\"\n",
      "batch 22804  loss=193.9830  steps/s=104.38  prediction: \" llm techniques: https://t.co/XbnCKZYbBa\" => \"tikeye ayytmmy m mhtq:::t: :::/t:ttt////\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m xtokens \u001b[38;5;241m=\u001b[39m post_tokens[x_start:x_end]\n\u001b[1;32m     61\u001b[0m ytokens \u001b[38;5;241m=\u001b[39m post_tokens[y_start:y_end]\n\u001b[0;32m---> 62\u001b[0m loss, rnn_params, opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     64\u001b[0m subsequences \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, count, mu, nu)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "keys = random.split(random.PRNGKey(198123), 10)\n",
    "\n",
    "model_dim = vocab_size # C\n",
    "input_shape = (model_dim,)\n",
    "hidden_shape = (64*16,)\n",
    "output_shape = (vocab_size,) # logits\n",
    "\n",
    "\n",
    "#embedding_params = init_embedding_params(keys[0], model_dim)\n",
    "\n",
    "#rnn_params = init_rnn_params(keys[1], input_shape, hidden_shape, output_shape)\n",
    "#rnn_params.update({\"embedding_params\" : embedding_params})\n",
    "\n",
    "\n",
    "scheduler = optax.schedules.linear_onecycle_schedule(\n",
    "  transition_steps=100_000,\n",
    "  peak_value=0.003,\n",
    "  pct_start = 0.3,\n",
    "  pct_final = 0.9,\n",
    "  div_factor = 1.25,\n",
    "  final_div_factor=10,\n",
    ")\n",
    "optimizer = optax.chain(\n",
    "  optax.scale_by_adam(),\n",
    "  optax.scale_by_schedule(scheduler),\n",
    "  optax.scale(-1), # params += -learning_rate x grads\n",
    ")\n",
    "opt_state = optimizer.init(rnn_params)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(rnn_params, xtokens, ytokens, opt_state):\n",
    "  loss, grads = jax.value_and_grad(get_loss)(rnn_params, xtokens, ytokens)\n",
    "  param_updates, updated_opt_state = optimizer.update(grads, opt_state, rnn_params)\n",
    "  updated_params = optax.apply_updates(rnn_params, param_updates)\n",
    "  return loss, updated_params, updated_opt_state\n",
    "\n",
    "\n",
    "batches = 100000 # num of post samples to train on\n",
    "print_every = 1\n",
    "post_limit = -1\n",
    "post_indices = random.choice(keys[3], len(post_token_sets[:post_limit]), shape=(batches,), replace=True) # 1 post per batch\n",
    "print(f'Training on {len(post_indices)} posts')\n",
    "last_time = time.time()\n",
    "for batch in range(batches):\n",
    "  batch_loss = 0\n",
    "  subsequences = 0\n",
    "  post_idx = post_indices[batch]\n",
    "  post_tokens = post_token_sets[post_idx]\n",
    "  \n",
    "  max_subsequence = sequence_length\n",
    "  for pos, _ in enumerate(post_tokens):\n",
    "    if pos < sequence_length:\n",
    "      continue # for now. later make it predict the empty sequence\n",
    "    x_end = pos\n",
    "    x_start = max(0, pos - sequence_length)\n",
    "    y_start = x_start + 1\n",
    "    y_end = x_end + 1\n",
    "    xtokens = post_tokens[x_start:x_end]\n",
    "    ytokens = post_tokens[y_start:y_end]\n",
    "    loss, rnn_params, opt_state = train_step(rnn_params, xtokens, ytokens, opt_state)\n",
    "    batch_loss += loss\n",
    "    subsequences += 1\n",
    "  \n",
    "  if subsequences == 0: continue\n",
    "  if batch % print_every == 0:\n",
    "    batch_time = time.time() - last_time\n",
    "    last_time = time.time()\n",
    "    subsequences_per_sec = subsequences/batch_time\n",
    "    logits = forward(rnn_params, embed_tokens(xtokens))\n",
    "    yhat = decode(jnp.argmax(logits, axis=-1))\n",
    "    print(f'batch {batch:4.0f}  loss={batch_loss/subsequences:3.4f}  steps/s={subsequences_per_sec:0.2f}  prediction: \"{decode(xtokens)}\" => \"{yhat}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(xchars):\n",
    "  xbow = embed_chars(xchars)\n",
    "  logits = forward(rnn_params, xbow)\n",
    "  yhatbow = jnp.argmax(logits, axis=-1)\n",
    "  yhatbow_chars = decode(yhatbow)\n",
    "  return yhatbow_chars\n",
    "\n",
    "text = 'post: elon is '\n",
    "print(text, end='')\n",
    "for i in range(100):\n",
    "  current_input = text[-sequence_length:] # final $seq_length chars\n",
    "  next_char = inference(current_input)[-1]\n",
    "  text += next_char\n",
    "  print(next_char, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
